{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SimEc for recommender systems\n",
    "Tasks like product recommendation or drug-target interaction prediction essentially consist of having to predict missing entries in a large matrix containing pairwise relations, e.g., the user ratings of some items or whether or not a drug interacts with a certain protein. Besides the sparse matrix containing the pairwise relations, generally one can also construct some feature vectors for the items and users (drugs / proteins), e.g., based on textual descriptions. These can come in especially handy when predictions need to be made, e.g., for new items that did not receive any user ratings so far. In the following we will only talk about items and users but of course this extends to other problem setups as well like drug-target interaction prediction. We distinguish between 3 tasks with increasing difficulty:\n",
    "- **T1**: Predict missing ratings for existing items and users\n",
    "- **T2a** and **T2b**: Predict ratings for new items and existing users (a) or new users and existing items (b)\n",
    "- **T3**: Predict ratings for new items and new users\n",
    "\n",
    "For tasks T2a/b and T3, feature vectors describing items and/or users are required. \n",
    "\n",
    "There are several methods that can be used to solve some or all of the above tasks. These include:\n",
    "##### Baseline Methods\n",
    "- **Predict average**: This is a no-brainer: simply fill all the missing values by averages. For example, an item rating from a user can be predicted based on the average rating the user usually gives (he might in general be more or less critical than other users) and the average rating the item got from other users (it might be better or worse than the average item) or for new items and users just predict the overall average rating (solves **T1, T2a/b, T3**).\n",
    "- **SVD of the ratings matrix**: By factorizing the ratings matrix using (iterative) singular value decomposition (SVD), one can compute a low rank approximation of the ratings matrix and use these approximate values as predictions for the missing values (solves **T1**). This can also be combined with the average ratings from above, i.e., the low rank approximation can be used to predict the residuals.\n",
    "- **SVD + Regression**: Given some feature vectors for items or users and the low rank approximation of the ratings matrix computed above, using a regression model, the mapping from the items' feature vectors to their rating vectors can be learned (or respectively for users). This is an extension of the above method to additionally solve either **T2a** or **T2b**, or **T3** if models are learned for both sides of the factorization.\n",
    "- **Regression/Classification model**: This approach is completely different from the so-called latent factor models discussed above. Here we train an ordinary regression or classification model (depending on the form of the pairwise data, e.g. continuous ratings or binary interactions) by using as input the concatenation of the feature vectors of an item and a user and as the target their rating. One possible realization of such a model could involve two neural networks to map the individual feature vectors into some lower dimensional embedding space. This approach can be used to solve all tasks **T1, T2a/b, T3** provided corresponding feature vectors are available.\n",
    "\n",
    "##### Similarity Encoder Models\n",
    "- **Factorization of the ratings matrix using the identity matrix as input**: By training a SimEc to factorize the ratings matrix using the identity matrix as input, we can recreate the solution obtained with SVD (while possibly better handling missing values when computing the decomposition). Correspondingly, this only solves **T1**.\n",
    "- **Factorization of the ratings matrix using feature vectors as input**: By using either item or user feature vectors as input when factorizing the ratings matrix, we can additionally solve **T2a** or **T2b**.\n",
    "- **Train a second SimEc with feature vectors and fixed last layer weights**: After training, e.g., a SimEc with item feature vectors as input to decompose the ratings matrix, we can use this SimEc to compute the item embeddings $Y$. We can then construct a second SimEc, which uses user feature vectors as input to factorize the ratings matrix. However, here we fix the weights of the last layer by setting them to the transpose of the embedding matrix computed for the items. After this SimEc is trained, we can now use both SimEcs to compute item and user embeddings respectively and then compute the scalar product of the embedding vectors to predict the ratings. This approach can then also be used to predict the ratings given the feature vectors for new items and users, i.e., it can be used to solve all tasks **T1, T2a/b, T3**.\n",
    "\n",
    "If the rating matrix contains explicit ratings (i.e. likes and dislikes), all available entries can be used to train the above models. If the pairwise relations in the matrix only represent implicit feedback or binary interactions (e.g. the user listens to music by certain artists, which means he likes them, but we don't know if he doesn't listen to other artists because he doesn't know them or because he doesn't like them), then we can use the given entries in the matrix as positive examples and additionally take a random sample of the missing entries and use them as negative examples. In the latter case, it might be more useful to use classification instead of regression models and also when training the SimEc it could be helpful to apply a non-linearity on the output before computing the error of the model.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "In this notebook we work with the [movielens dataset](https://grouplens.org/datasets/movielens/10m/) and additionally pull some information about the individual movies from [the movie database](https://api.themoviedb.org/) using their API.\n",
    "\n",
    "Since we only have additional information about the movies, not the users, we focus on solving tasks **T1** and **T2a** here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:00:34.508783Z",
     "start_time": "2018-04-14T20:00:32.007020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "np.random.seed(28)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(28)\n",
    "import keras\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from simec import SimilarityEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:00:34.558797Z",
     "start_time": "2018-04-14T20:00:34.510858Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/recsys/tmdb_data\"):\n",
    "    os.mkdir(\"data/recsys/tmdb_data\")\n",
    "\n",
    "def parse_tmdb(tmdbid, apikey):\n",
    "    movie_data = {}\n",
    "    if os.path.exists(\"data/recsys/tmdb_data/%r.json\" % tmdbid):\n",
    "        with open(\"data/recsys/tmdb_data/%r.json\" % tmdbid) as f:\n",
    "            movie_data = json.load(f)\n",
    "    # for a movie with tmdbid get:\n",
    "    # genres:name, original language en y/n, id, title, overview, release_date-->year,\n",
    "    # keywords:keywords:name, credits:cast:name[:10], credits:crew:(\"job\": \"Director\"):name\n",
    "    if not movie_data:\n",
    "        r = requests.get(\"https://api.themoviedb.org/3/movie/%r?api_key=%s&language=en-US&append_to_response=keywords,credits\" % (tmdbid, apikey))\n",
    "        if r.status_code != 200:\n",
    "            print(\"something went wrong when accessing tmdb with id %r!\" % tmdbid)\n",
    "            print(r.text)\n",
    "        else:\n",
    "            movie_json = r.json()\n",
    "            movie_data['tmdbid'] = movie_json['id']\n",
    "            movie_data['title'] = movie_json['title']\n",
    "            movie_data['overview'] = movie_json['overview']\n",
    "            movie_data['release_date'] = movie_json['release_date']\n",
    "            movie_data['year'] = movie_json[\"release_date\"].split(\"-\")[0]\n",
    "            movie_data['original_en'] = str(movie_json['original_language'] == \"en\")\n",
    "            movie_data['genres'] = [g[\"name\"] for g in movie_json['genres']]\n",
    "            movie_data['keywords'] = [k[\"name\"] for k in movie_json['keywords']['keywords']]\n",
    "            movie_data['cast'] = [c[\"name\"] for c in movie_json['credits']['cast'][:10]]\n",
    "            movie_data['directors'] = [c[\"name\"] for c in movie_json['credits']['crew'] if c[\"job\"] == \"Director\"]\n",
    "            print(\"got data for %s\" % movie_json['title'])\n",
    "            with open(\"data/recsys/tmdb_data/%r.json\" % tmdbid, \"w\") as f:\n",
    "                json.dump(movie_data, f, indent=2)\n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:00:34.892024Z",
     "start_time": "2018-04-14T20:00:34.560296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franzi/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got data for 10608 movies\n"
     ]
    }
   ],
   "source": [
    "# get movielens data from: https://grouplens.org/datasets/movielens/10m/\n",
    "# load all possible movies (in the 10m dataset)\n",
    "df_movies = pd.read_csv(\"data/recsys/ml-10M100K/movies.dat\", sep=\"::\", names=[\"movieId\",\"title\",\"genres\"])\n",
    "# get corresponding tmdbids (only in 20m dataset)\n",
    "df_links = pd.read_csv(\"data/recsys/ml-20m/links.csv\")\n",
    "df_links = df_links.dropna()\n",
    "df_links = df_links.astype(int) \n",
    "map_movieids = dict(zip(df_links.movieId, df_links.tmdbId))\n",
    "# get additional details from themoviedb.org (assumes api key is stored at data/recsys/tmdb_apikey.txt)\n",
    "if os.path.exists(\"data/recsys/tmdb_data.json\"):\n",
    "    with open(\"data/recsys/tmdb_data.json\") as f:\n",
    "        movies_data = json.load(f)\n",
    "else:\n",
    "    movies_data = {}\n",
    "    with open('data/recsys/tmdb_apikey.txt') as f:\n",
    "        apikey = f.read().strip()\n",
    "    for movieid in df_movies.movieId:\n",
    "        if movieid in map_movieids:\n",
    "            m = parse_tmdb(map_movieids[movieid], apikey)\n",
    "            if m:\n",
    "                # careful: when loading the json later the ids will be strings as well anyways\n",
    "                movies_data[str(movieid)] = m\n",
    "            else:\n",
    "                print(\"error with movie id: %i\" % movieid)\n",
    "    with open(\"data/recsys/tmdb_data.json\", \"w\") as f:\n",
    "        json.dump(movies_data, f, indent=2)\n",
    "print(\"got data for %i movies\" % len(movies_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:01:12.899091Z",
     "start_time": "2018-04-14T20:00:34.895336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed 0 lines\n",
      "parsed 1000000 lines\n",
      "parsed 2000000 lines\n",
      "parsed 3000000 lines\n",
      "parsed 4000000 lines\n",
      "parsed 5000000 lines\n",
      "parsed 6000000 lines\n",
      "parsed 7000000 lines\n",
      "parsed 8000000 lines\n",
      "parsed 9000000 lines\n",
      "parsed 10000000 lines\n",
      "10604 movies, 69878 users, and 9989664 ratings\n"
     ]
    }
   ],
   "source": [
    "# load pairwise data and generate a dict with {(movieid, userid): rating}\n",
    "movieids = set()\n",
    "userids = set()\n",
    "tuple_ratings = {}\n",
    "rating_pairs = []\n",
    "with open(\"data/recsys/ml-10M100K/ratings.dat\") as f:\n",
    "    for i, l in enumerate(f.readlines()):\n",
    "        if not i % 1000000:\n",
    "            print(\"parsed %i lines\" % i)\n",
    "        u, m, r, t = l.strip().split(\"::\")\n",
    "        # only consider ratings for movies where we have external data available\n",
    "        if m in movies_data:\n",
    "            # in addition to the ratings, also get a list of all users and movies\n",
    "            if u not in userids:\n",
    "                userids.add(u)\n",
    "            if m not in movieids:\n",
    "                movieids.add(m)\n",
    "            tuple_ratings[(m,u)] = float(r)\n",
    "            rating_pairs.append((m,u))\n",
    "        #else:\n",
    "        #    print(\"warning, skipping rating for movie with id %r\" % m)\n",
    "# shuffle all movie and user ids (important so we can split data into train and test sets)\n",
    "# this list additionally functions as a mapping from a (matrix) index to the actual id\n",
    "np.random.seed(13)\n",
    "map_index2movieid = np.random.permutation(sorted(movieids))\n",
    "map_index2userid = np.random.permutation(sorted(userids))\n",
    "# also get a shuffeled list of all rating pairs\n",
    "rating_pairs = np.random.permutation(rating_pairs)\n",
    "print(\"%i movies, %i users, and %i ratings\" % (len(movieids), len(userids), len(rating_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:01:12.972903Z",
     "start_time": "2018-04-14T20:01:12.900853Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we have different scenarios: either we're only missing some individual ratings or entire movies/users\n",
    "def split_traintest(scenario):\n",
    "    print(\"generating train/test splits for scenario %r\" % scenario)\n",
    "    if scenario == \"T1\":\n",
    "        # missing ratings\n",
    "        rating_pairs_train = rating_pairs[:int(0.7*len(rating_pairs))]\n",
    "        rating_pairs_test = rating_pairs[int(0.7*len(rating_pairs)):]\n",
    "        map_index2movieid_train = map_index2movieid\n",
    "        map_index2userid_train = map_index2userid\n",
    "    else:\n",
    "        rating_pairs_train = []\n",
    "        rating_pairs_test = []\n",
    "        if scenario == \"T2a\":\n",
    "            # missing movies\n",
    "            map_index2movieid_train = map_index2movieid[:int(0.7*len(map_index2movieid))]\n",
    "            map_index2userid_train = map_index2userid\n",
    "        elif scenario == \"T2b\":\n",
    "            # missing users\n",
    "            map_index2movieid_train = map_index2movieid\n",
    "            map_index2userid_train = map_index2userid[:int(0.7*len(map_index2userid))]\n",
    "        elif scenario == \"T3\":\n",
    "            # missing movies and users\n",
    "            map_index2movieid_train = map_index2movieid[:int(0.85*len(map_index2movieid))]\n",
    "            map_index2userid_train = map_index2userid[:int(0.8*len(map_index2userid))]\n",
    "        else:\n",
    "            raise Exception(\"unknown scenario %r, use either T1, T2a, T2b, or T3!\" % scenario)\n",
    "        movieids_train_set = set(map_index2movieid_train)\n",
    "        userids_train_set = set(map_index2userid_train)\n",
    "        rating_pairs_train = []\n",
    "        rating_pairs_test = []\n",
    "        for (m, u) in rating_pairs:\n",
    "            if u in userids_train_set and m in movieids_train_set:\n",
    "                rating_pairs_train.append((m, u))\n",
    "            else:\n",
    "                rating_pairs_test.append((m, u))\n",
    "    print(\"got %i training and %i test ratings\" % (len(rating_pairs_train), len(rating_pairs_test)))\n",
    "    # create mappings from the actual id to the index\n",
    "    map_movieid2index_train = {m: i for i, m in enumerate(map_index2movieid_train)}\n",
    "    map_userid2index_train = {u: i for i, u in enumerate(map_index2userid_train)}\n",
    "    return rating_pairs_train, rating_pairs_test, map_index2userid_train,\\\n",
    "           map_index2movieid_train, map_userid2index_train, map_movieid2index_train\n",
    "\n",
    "def make_train_matrix(tuple_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train):\n",
    "    # transform training ratings into a sparse matrix for convenience\n",
    "    print(\"transforming dict with %i ratings into sparse matrix\" % len(rating_pairs_train))\n",
    "    ratings_matrix = lil_matrix((len(map_movieid2index_train),len(map_userid2index_train)))\n",
    "    for (m, u) in rating_pairs_train:\n",
    "        ratings_matrix[map_movieid2index_train[m],map_userid2index_train[u]] = tuple_ratings[(m, u)]\n",
    "    ratings_matrix = csr_matrix(ratings_matrix)\n",
    "    return ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:01:13.030001Z",
     "start_time": "2018-04-14T20:01:12.975075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeansModel():\n",
    "    \"\"\"\n",
    "    A very simple baseline model, which predicts the rating a user would give to a movie as:\n",
    "        mean + user_mean + movie_mean\n",
    "    \"\"\"\n",
    "    def __init__(self, shrinkage=1.):\n",
    "        self.mean = None\n",
    "        self.mean_users = {}\n",
    "        self.mean_movies = {}\n",
    "        # shrinkage decreases the influence of the individual user/movie means\n",
    "        # --> mean + shrinkage*user_mean + shrinkage*movie_mean\n",
    "        # it should always be between 0 and 1; 0 means individual means are ignored\n",
    "        self.shrinkage = max(0., min(1., shrinkage))\n",
    "\n",
    "    def fit(self, tuple_ratings, rating_pairs_train):\n",
    "        # overall mean based on all training ratings\n",
    "        self.mean = np.mean([tuple_ratings[(m, u)] for (m, u) in rating_pairs_train])\n",
    "        # means for movies and users\n",
    "        if self.shrinkage:\n",
    "            mean_users = defaultdict(list)\n",
    "            mean_movies = defaultdict(list)\n",
    "            for (m, u) in rating_pairs_train:\n",
    "                mean_users[u].append(tuple_ratings[(m, u)])\n",
    "                mean_movies[m].append(tuple_ratings[(m, u)])\n",
    "            self.mean_users = {u: np.mean(mean_users[u])-self.mean for u in mean_users}\n",
    "            self.mean_movies = {m: np.mean(mean_movies[m])-self.mean for m in mean_movies}\n",
    "    \n",
    "    def predict(self, m, u, residuals=None):\n",
    "        \"\"\"\n",
    "        generate rating prediction for a user u and movie m\n",
    "        \"\"\"\n",
    "        rating = self.mean\n",
    "        if u in self.mean_users:\n",
    "            rating += self.shrinkage*self.mean_users[u]\n",
    "        if m in self.mean_movies:\n",
    "            rating += self.shrinkage*self.mean_movies[m]\n",
    "        if residuals and (m, u) in residuals:\n",
    "            rating += residuals[(m, u)]\n",
    "        return rating\n",
    "    \n",
    "    def compute_residuals(self, tuple_ratings, rating_pairs_train):\n",
    "        \"\"\"\n",
    "        for all ratings, subtract the respective average ratings to get residuals\n",
    "        \"\"\"\n",
    "        return {(m, u): tuple_ratings[(m, u)] - (self.mean+self.shrinkage*(self.mean_users[u]+self.mean_movies[m]))\n",
    "                                  for (m, u) in rating_pairs_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T00:50:10.485317Z",
     "start_time": "2018-03-31T00:38:04.864972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario u'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T1: RMSE: 1.06044; MAE: 0.85552\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T1: RMSE: 1.02330; MAE: 0.82574\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T1: RMSE: 0.91333; MAE: 0.71937\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T1: RMSE: 0.88074; MAE: 0.68157\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T1: RMSE: 0.88614; MAE: 0.68404\n",
      "generating train/test splits for scenario u'T2a'\n",
      "got 7064138 training and 2925526 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T2a: RMSE: 1.05938; MAE: 0.85143\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T2a: RMSE: 1.04342; MAE: 0.83821\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T2a: RMSE: 0.99569; MAE: 0.79322\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T2a: RMSE: 0.97628; MAE: 0.76558\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T2a: RMSE: 0.97610; MAE: 0.76332\n",
      "generating train/test splits for scenario u'T2b'\n",
      "got 7015197 training and 2974467 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T2b: RMSE: 1.05763; MAE: 0.85382\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T2b: RMSE: 1.03627; MAE: 0.83724\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T2b: RMSE: 0.97058; MAE: 0.77542\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T2b: RMSE: 0.94101; MAE: 0.73810\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T2b: RMSE: 0.93976; MAE: 0.73544\n",
      "generating train/test splits for scenario u'T3'\n",
      "got 6827065 training and 3162599 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T3: RMSE: 1.05580; MAE: 0.85198\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T3: RMSE: 1.03854; MAE: 0.83850\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T3: RMSE: 0.98629; MAE: 0.78893\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T3: RMSE: 0.96390; MAE: 0.75888\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T3: RMSE: 0.96327; MAE: 0.75657\n"
     ]
    }
   ],
   "source": [
    "for scenario in [\"T1\", \"T2a\", \"T2b\", \"T3\"]:\n",
    "    # get train/test data\n",
    "    rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "    for shrinkage in [0., 0.1, 0.5, 0.9, 1.]:\n",
    "        # initalize means model\n",
    "        mmodel = MeansModel(shrinkage)\n",
    "        print(\"fitting model with shrinkage=%.1f\" % shrinkage)\n",
    "        mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "        # get a vector with target ratings for test tuples\n",
    "        y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "        # get the corresponding predictions\n",
    "        y_pred = np.array([mmodel.predict(m, u) for (m, u) in rating_pairs_test])\n",
    "        print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:03:32.862354Z",
     "start_time": "2018-04-14T20:01:13.031315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario u'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "computing residuals\n",
      "transforming dict with 6992764 ratings into sparse matrix\n"
     ]
    }
   ],
   "source": [
    "scenario = \"T1\"\n",
    "# get train/test data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T18:09:08.704375Z",
     "start_time": "2018-04-14T18:06:50.300093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,u'eigenvalue')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEMCAYAAADHxQ0LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEiOUOCLiOQIBb6ISI5Q4IuI5Ij/D7gkIk3zRVsAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f979d8090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inspect eigenvalues of matrix\n",
    "eigenvals = svds(ratings_matrix, k=1000, return_singular_vectors=False)\n",
    "eigenvals = sorted(eigenvals, reverse=True)\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(eigenvals)+1), eigenvals)\n",
    "plt.xlabel(\"eigenvalue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T18:09:20.882633Z",
     "start_time": "2018-04-14T18:09:08.706938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10604, 100), (100, 100), (100, 69878))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get eigenvalues and -vectors for some relevant dimensions\n",
    "e_dim = 100\n",
    "U, s, Vh = svds(ratings_matrix, k=e_dim)\n",
    "S = np.zeros((e_dim, e_dim))\n",
    "S = np.diag(s)\n",
    "U.shape, S.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T18:09:53.052907Z",
     "start_time": "2018-04-14T18:09:20.885965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.85891; MAE: 0.65994\n"
     ]
    }
   ],
   "source": [
    "# construct approximation of residual ratings\n",
    "print(\"get approximations\")\n",
    "temp = np.dot(U, np.dot(S, Vh))\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_train[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T20:52:21.767137Z",
     "start_time": "2018-04-14T20:40:40.966602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 7s 683us/step - loss: 0.0075\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 7s 650us/step - loss: 0.0074\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.0075\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 0.0075\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 7s 635us/step - loss: 0.0075\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 7s 651us/step - loss: 0.0075\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 0.0075\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 7s 644us/step - loss: 0.0075\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 7s 650us/step - loss: 0.0075\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 7s 649us/step - loss: 0.0075\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 7s 644us/step - loss: 0.0075\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 0.0075\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 7s 648us/step - loss: 0.0075\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 7s 657us/step - loss: 0.0075\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 7s 650us/step - loss: 0.0075\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.0075\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 7s 641us/step - loss: 0.0075\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 7s 645us/step - loss: 0.0075\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 7s 645us/step - loss: 0.0075\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 7s 651us/step - loss: 0.0075\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.87770; MAE: 0.67674\n",
      "0.5\n",
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 7s 675us/step - loss: 0.2058\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 7s 644us/step - loss: 0.1194\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 7s 646us/step - loss: 0.0222\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 7s 647us/step - loss: 0.0120\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 7s 650us/step - loss: 0.0093\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.0084\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.0081\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 7s 641us/step - loss: 0.0081\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 7s 646us/step - loss: 0.0081\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 7s 645us/step - loss: 0.0083\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.0084\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 0.0087\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 7s 645us/step - loss: 0.0105\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 7s 640us/step - loss: 0.0111\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 7s 640us/step - loss: 0.0100\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 7s 644us/step - loss: 0.0098\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 7s 641us/step - loss: 0.0100\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 7s 635us/step - loss: 0.0127\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 0.0163\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 0.0135\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.88828; MAE: 0.68539\n",
      "1.0\n",
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 7s 676us/step - loss: 1.9013 1s - loss: 2\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 7s 641us/step - loss: 5.4738\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.8203\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 7s 635us/step - loss: 0.4484\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 7s 654us/step - loss: 0.2607\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 0.1481\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 7s 640us/step - loss: 0.0824\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 0.0459\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 7s 638us/step - loss: 0.0277\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 0.0185\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 0.0135\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 7s 640us/step - loss: 0.0108\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 7s 656us/step - loss: 0.0096\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 7s 641us/step - loss: 0.0094\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 7s 635us/step - loss: 0.0094\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 7s 632us/step - loss: 0.0099\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 0.0108\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 7s 639us/step - loss: 0.0134\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 7s 634us/step - loss: 0.4216\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 7s 625us/step - loss: 0.4628\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.95732; MAE: 0.72505\n",
      "5.0\n",
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 7s 669us/step - loss: 1897.5406\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 7s 637us/step - loss: 14135.9172\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 7s 635us/step - loss: 128.0643\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 7s 645us/step - loss: 89.5244\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 79.3868\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 7s 641us/step - loss: 104.0957\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 7s 642us/step - loss: 94.2649\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 7s 644us/step - loss: 71.6321\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 7s 634us/step - loss: 74.2094\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 118.9179\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 7s 635us/step - loss: 150.0352\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 740.5337\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 7s 634us/step - loss: 1507.3360\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 7s 648us/step - loss: 2873.4288\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 7s 636us/step - loss: 3472.8253\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 7s 637us/step - loss: 3820.3512\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 7s 643us/step - loss: 3433.0306\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 7s 632us/step - loss: 3693.1086\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 7s 638us/step - loss: 3541.4980\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 7s 660us/step - loss: 3279.3861\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 57.11730; MAE: 43.86594\n",
      "10.0\n",
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 7s 689us/step - loss: 10968.0256\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 7s 655us/step - loss: 55070.6640\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 7s 650us/step - loss: 1268.0974\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 7s 650us/step - loss: 539.3682\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 7s 649us/step - loss: 489.7423\n",
      "Epoch 6/20\n",
      " 2432/10604 [=====>........................] - ETA: 5s - loss: 519.9342"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4a16ef30074c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     model = SimilarityEncoder(ratings_matrix.shape[0], e_dim, ratings_matrix.shape[1], mask_value=-100,\n\u001b[1;32m     11\u001b[0m                               opt=l)\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get approximations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franzi/Documents/code/simec/simec.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, S, epochs, verbose)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output dims of targets don't match (%r != %r)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# store the model we need for the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franzi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/franzi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1192\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/home/franzi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franzi/anaconda2/lib/python2.7/site-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [[1,2],j] or [[1,2],1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mextracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mextracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franzi/anaconda2/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franzi/anaconda2/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    548\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m            \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m            indptr, indices, data)\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# train simec with identiy matrix as input to predict residuals\n",
    "e_dim = 100\n",
    "X = np.eye(ratings_matrix.shape[0], dtype=np.float16)\n",
    "R = -100*np.ones(ratings_matrix.shape, dtype=np.float16)\n",
    "R[ratings_matrix.nonzero()] = ratings_matrix[ratings_matrix.nonzero()]\n",
    "for l in [0.1]:\n",
    "    print l\n",
    "    model = SimilarityEncoder(ratings_matrix.shape[0], e_dim, ratings_matrix.shape[1], mask_value=-100,\n",
    "                              opt=0.05)\n",
    "    model.fit(X, ratings_matrix, epochs=20)\n",
    "    print(\"get approximations\")\n",
    "    temp = np.array(model.predict(X), dtype=np.float16)\n",
    "    # get dict with residuals for missing test ratings\n",
    "    print(\"get residual ratings\")\n",
    "    residual_ratings_test = {(m, u): temp[map_movieid2index_train[m], map_userid2index_train[u]]\n",
    "                                     for (m, u) in rating_pairs_test}\n",
    "    del temp\n",
    "    print(\"predict test ratings\")\n",
    "    # get the corresponding predictions\n",
    "    y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "    print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))\n",
    "del R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
