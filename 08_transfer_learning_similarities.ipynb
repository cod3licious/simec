{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Image Classification with Similarity Pre-training\n",
    "\n",
    "If only a few labeled training examples are available, it can often be beneficial to use pre-training, i.e., first train the neural network on an different task with more training data so that the weights of the network already capture e.g. basic image statistics, and then fine tune the network with the given labeled examples for the real task.\n",
    "\n",
    "In the past it has been shown that, at least for image classification tasks, it is more helpful to use the labels of a different task when performing the pre-training than e.g. an unsupervised method such as Auto-Encoders, as only with labels the model is able to learn the distinction between important image patches (e.g. faces) and irrelevant pixels (see also [this blog post](http://karpathy.github.io/2014/07/03/feature-learning-escapades/)). This is no different when performing the pre-training with a SimEc, i.e., with a data driven similarity function such as a linear kernel, the pre-training is not very effective, while if a similarity function is available that captures class related differences (here simulated by computing a weighted average between the linear kernel and the class based similarity matrix), then pre-training can be about as effective as with a classifier that was trained on other labels.\n",
    "\n",
    "In this notebook we compare pre-training with a classifier (clf), an Auto-Encoder (AE) as well as a Similarity Encoder (SimEc) on the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T11:00:33.259162Z",
     "start_time": "2019-07-31T11:00:32.435596Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, division, print_function, absolute_import\n",
    "from builtins import range\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "import random\n",
    "random.seed(28)\n",
    "import numpy as np\n",
    "np.random.seed(28)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "torch.manual_seed(28)\n",
    "torch.cuda.manual_seed(28)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from simec_torch import SimilarityEncoder, Dense\n",
    "from utils import check_similarity_match\n",
    "from utils_plotting import get_colors\n",
    "from utils_torch import examine_param_space\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T11:00:33.313602Z",
     "start_time": "2019-07-31T11:00:33.260927Z"
    }
   },
   "outputs": [],
   "source": [
    "## basic CNN for classification\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, padding=2)  # b x 3 x 32 x 32 --> b x 16 x 32 x 32\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.maxp1 = nn.MaxPool2d(2, return_indices=True)  #           --> b x 16 x 16 x 16\n",
    "        self.mp1id = None\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, padding=1)  #                 --> b x 8 x 16 x 16\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.maxp2 = nn.MaxPool2d(2, return_indices=True)  #           --> b x 8 x 8 x 8\n",
    "        self.mp2id = None\n",
    "        self.nonlin1 = Dense(512, 512, activation=torch.tanh)\n",
    "        self.nonlin2 = Dense(512, 512, activation=torch.tanh)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x, self.mp1id = self.maxp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x, self.mp2id = self.maxp2(x)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.nonlin1(x)\n",
    "        x = self.nonlin2(x)\n",
    "        return x\n",
    "\n",
    "## classifier based on CNN\n",
    "class CLF(nn.Module):\n",
    "    def __init__(self, cnn, n_classes=10):\n",
    "        super(CLF, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lastlayer = nn.Sequential(\n",
    "            nn.Linear(512, n_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.lastlayer(x)\n",
    "        return x\n",
    "\n",
    "## AE based on CNN\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, cnn):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = cnn\n",
    "        self.nonlin1 = Dense(512, 512, activation=torch.tanh)\n",
    "        self.nonlin2 = Dense(512, 512, activation=torch.tanh)\n",
    "        self.maxup2 = nn.MaxUnpool2d(2)  #         b x 8 x 8 x 8 --> b x 8 x 16 x 16\n",
    "        self.convt2 = nn.ConvTranspose2d(8, 16, 3, padding=1)  # --> b x 16 x 16 x 16\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.maxup1 = nn.MaxUnpool2d(2)  #                       --> b x 16 x 32 x 32\n",
    "        self.convt1 = nn.ConvTranspose2d(16, 3, 5, padding=2)  # --> b x 3 x 32 x 32 \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.nonlin1(x)\n",
    "        x = self.nonlin2(x)\n",
    "        x = x.view(-1, 8, 8, 8)\n",
    "        x = self.maxup2(x, self.encoder.mp2id)\n",
    "        x = self.convt2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxup1(x, self.encoder.mp1id)\n",
    "        x = self.convt1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "## AE with only a single linear layer\n",
    "class AE1L(nn.Module):\n",
    "    def __init__(self, cnn):\n",
    "        super(AE1L, self).__init__()\n",
    "        self.encoder = cnn\n",
    "        self.lastlayer = nn.Linear(512, 3*32*32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.lastlayer(x)\n",
    "        x = x.view(-1, 3, 32, 32)\n",
    "        return x\n",
    "    \n",
    "def compare_state_dicts(sd1, sd2):\n",
    "    # check if the state dicts of two models are the same\n",
    "    is_equal = True\n",
    "    for p in sd1:\n",
    "        if not torch.all(torch.eq(sd1[p], sd2[p])):\n",
    "            is_equal = False\n",
    "            break\n",
    "    print(is_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T11:00:34.348244Z",
     "start_time": "2019-07-31T11:00:33.315655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                        std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = datasets.CIFAR10('./data/cifar10', train=True, download=True, transform=img_transform)\n",
    "test_dataset = datasets.CIFAR10('./data/cifar10', train=False, transform=img_transform)\n",
    "\n",
    "# get indices for training, validation, and test data\n",
    "n_valid = 5000\n",
    "np.random.seed(15)\n",
    "indices = np.random.permutation(len(train_dataset))\n",
    "indices, indices_val = indices[:-n_valid], indices[-n_valid:]\n",
    "indices_test = np.random.permutation(len(test_dataset))\n",
    "\n",
    "# get some loaders\n",
    "train_loader_all = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, sampler=SubsetRandomSampler(indices), **kwargs\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, sampler=SubsetRandomSampler(indices_val), **kwargs\n",
    ")\n",
    "test_loader_all = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, sampler=SubsetRandomSampler(indices_test), **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T11:00:36.398280Z",
     "start_time": "2019-07-31T11:00:34.349460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '       horse              dog             deer             ship             deer    ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 5 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader_all)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:5]))\n",
    "# print labels\n",
    "plt.title(' '.join('%12s    ' % classes[labels[j]] for j in range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a regular classifier with more and more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T11:00:36.434921Z",
     "start_time": "2019-07-31T11:00:36.400463Z"
    }
   },
   "outputs": [],
   "source": [
    "n_training_examples = [25, 50, 100, 250, 500, 750, 1000, 2500, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000]\n",
    "\n",
    "def train_clf(model, epoch, train_loader, optimizer, lr_scheduler):\n",
    "    criterion = nn.NLLLoss()\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # for t1 the loss still expects the labels to be between 0 and 4\n",
    "        if target.min() > 4:\n",
    "            target -= 5\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('[epoch %d] loss: %.7f' % (epoch + 1, running_loss / (batch_idx + 1)))\n",
    "    lr_scheduler.step(running_loss)\n",
    "\n",
    "    \n",
    "def test_clf(model, test_loader):\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if target.min() > 4:\n",
    "                target -= 5\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.sampler)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.sampler),\n",
    "        100. * correct / len(test_loader.sampler)))\n",
    "    return correct / len(test_loader.sampler)\n",
    "\n",
    "\n",
    "def clf_with_ntrain(n_train, cnn_dict=None, frozen=False):\n",
    "    test_accs = []\n",
    "    for seed in [11, 12, 13]:\n",
    "        print(\"## seed:\", seed)\n",
    "        # get train_loader with specific number of training examples\n",
    "        np.random.seed(seed)\n",
    "        tindices = np.random.permutation(indices)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=32, sampler=SubsetRandomSampler(tindices[:n_train]), **kwargs\n",
    "        )\n",
    "        # pretrained cnn?\n",
    "        cnn = CNN()\n",
    "        if cnn_dict is not None:\n",
    "            cnn.load_state_dict(cnn_dict)\n",
    "        if frozen:\n",
    "            for p in cnn.parameters():\n",
    "                p.requires_grad = False    \n",
    "        model = CLF(cnn).to(device)\n",
    "        print(\"Validation accuracy before training:\")\n",
    "        _ = test_clf(model, valid_loader)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=0, eps=0., verbose=True)\n",
    "\n",
    "        best_acc = 0\n",
    "        best_model = None\n",
    "\n",
    "        for epoch in range(50):\n",
    "            train_clf(model, epoch, train_loader, optimizer, lr_scheduler)\n",
    "            val_acc = test_clf(model, valid_loader)\n",
    "            if val_acc >= best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_model = deepcopy(model.state_dict())\n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        print(\"Validation:\")\n",
    "        _ = test_clf(model, valid_loader)\n",
    "        print(\"Test\")\n",
    "        test_accs.append(test_clf(model, test_loader_all))\n",
    "    return np.mean(test_accs), np.std(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T01:26:50.320695Z",
     "start_time": "2019-07-23T22:53:45.557852Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3131, Accuracy: 361/5000 (7%)\n",
      "[epoch 1] loss: 2.3259628\n",
      "Test set: Average loss: 2.3548, Accuracy: 589/5000 (12%)\n",
      "[epoch 2] loss: 2.0239921\n",
      "Test set: Average loss: 2.5436, Accuracy: 563/5000 (11%)\n",
      "[epoch 3] loss: 1.8023823\n",
      "Test set: Average loss: 2.6773, Accuracy: 741/5000 (15%)\n",
      "[epoch 4] loss: 1.5832568\n",
      "Test set: Average loss: 2.6831, Accuracy: 835/5000 (17%)\n",
      "[epoch 5] loss: 1.3261188\n",
      "Test set: Average loss: 2.6736, Accuracy: 792/5000 (16%)\n",
      "[epoch 6] loss: 1.0498534\n",
      "Test set: Average loss: 2.7315, Accuracy: 725/5000 (14%)\n",
      "[epoch 7] loss: 0.7848161\n",
      "Test set: Average loss: 2.8717, Accuracy: 724/5000 (14%)\n",
      "[epoch 8] loss: 0.5575764\n",
      "Test set: Average loss: 3.0718, Accuracy: 701/5000 (14%)\n",
      "[epoch 9] loss: 0.3745236\n",
      "Test set: Average loss: 3.3395, Accuracy: 713/5000 (14%)\n",
      "[epoch 10] loss: 0.2431545\n",
      "Test set: Average loss: 3.6719, Accuracy: 751/5000 (15%)\n",
      "[epoch 11] loss: 0.1573123\n",
      "Test set: Average loss: 4.0251, Accuracy: 771/5000 (15%)\n",
      "[epoch 12] loss: 0.0994908\n",
      "Test set: Average loss: 4.3799, Accuracy: 789/5000 (16%)\n",
      "[epoch 13] loss: 0.0620288\n",
      "Test set: Average loss: 4.7278, Accuracy: 783/5000 (16%)\n",
      "[epoch 14] loss: 0.0380739\n",
      "Test set: Average loss: 5.0570, Accuracy: 785/5000 (16%)\n",
      "[epoch 15] loss: 0.0226436\n",
      "Test set: Average loss: 5.3637, Accuracy: 783/5000 (16%)\n",
      "[epoch 16] loss: 0.0136785\n",
      "Test set: Average loss: 5.6441, Accuracy: 781/5000 (16%)\n",
      "[epoch 17] loss: 0.0086423\n",
      "Test set: Average loss: 5.8965, Accuracy: 780/5000 (16%)\n",
      "[epoch 18] loss: 0.0056780\n",
      "Test set: Average loss: 6.1225, Accuracy: 772/5000 (15%)\n",
      "[epoch 19] loss: 0.0038711\n",
      "Test set: Average loss: 6.3249, Accuracy: 768/5000 (15%)\n",
      "[epoch 20] loss: 0.0027515\n",
      "Test set: Average loss: 6.5067, Accuracy: 768/5000 (15%)\n",
      "[epoch 21] loss: 0.0020385\n",
      "Test set: Average loss: 6.6703, Accuracy: 776/5000 (16%)\n",
      "[epoch 22] loss: 0.0015667\n",
      "Test set: Average loss: 6.8176, Accuracy: 775/5000 (16%)\n",
      "[epoch 23] loss: 0.0012406\n",
      "Test set: Average loss: 6.9503, Accuracy: 776/5000 (16%)\n",
      "[epoch 24] loss: 0.0010067\n",
      "Test set: Average loss: 7.0699, Accuracy: 776/5000 (16%)\n",
      "[epoch 25] loss: 0.0008332\n",
      "Test set: Average loss: 7.1779, Accuracy: 776/5000 (16%)\n",
      "[epoch 26] loss: 0.0007016\n",
      "Test set: Average loss: 7.2753, Accuracy: 774/5000 (15%)\n",
      "[epoch 27] loss: 0.0005995\n",
      "Test set: Average loss: 7.3633, Accuracy: 769/5000 (15%)\n",
      "[epoch 28] loss: 0.0005190\n",
      "Test set: Average loss: 7.4427, Accuracy: 767/5000 (15%)\n",
      "[epoch 29] loss: 0.0004548\n",
      "Test set: Average loss: 7.5145, Accuracy: 770/5000 (15%)\n",
      "[epoch 30] loss: 0.0004029\n",
      "Test set: Average loss: 7.5794, Accuracy: 769/5000 (15%)\n",
      "[epoch 31] loss: 0.0003606\n",
      "Test set: Average loss: 7.6380, Accuracy: 771/5000 (15%)\n",
      "[epoch 32] loss: 0.0003257\n",
      "Test set: Average loss: 7.6910, Accuracy: 772/5000 (15%)\n",
      "[epoch 33] loss: 0.0002967\n",
      "Test set: Average loss: 7.7389, Accuracy: 772/5000 (15%)\n",
      "[epoch 34] loss: 0.0002724\n",
      "Test set: Average loss: 7.7823, Accuracy: 772/5000 (15%)\n",
      "[epoch 35] loss: 0.0002519\n",
      "Test set: Average loss: 7.8215, Accuracy: 772/5000 (15%)\n",
      "[epoch 36] loss: 0.0002345\n",
      "Test set: Average loss: 7.8570, Accuracy: 771/5000 (15%)\n",
      "[epoch 37] loss: 0.0002193\n",
      "Test set: Average loss: 7.8891, Accuracy: 770/5000 (15%)\n",
      "[epoch 38] loss: 0.0002064\n",
      "Test set: Average loss: 7.9181, Accuracy: 769/5000 (15%)\n",
      "[epoch 39] loss: 0.0001950\n",
      "Test set: Average loss: 7.9444, Accuracy: 771/5000 (15%)\n",
      "[epoch 40] loss: 0.0001852\n",
      "Test set: Average loss: 7.9683, Accuracy: 770/5000 (15%)\n",
      "[epoch 41] loss: 0.0001764\n",
      "Test set: Average loss: 7.9899, Accuracy: 771/5000 (15%)\n",
      "[epoch 42] loss: 0.0001687\n",
      "Test set: Average loss: 8.0095, Accuracy: 771/5000 (15%)\n",
      "[epoch 43] loss: 0.0001619\n",
      "Test set: Average loss: 8.0272, Accuracy: 771/5000 (15%)\n",
      "[epoch 44] loss: 0.0001558\n",
      "Test set: Average loss: 8.0433, Accuracy: 770/5000 (15%)\n",
      "[epoch 45] loss: 0.0001502\n",
      "Test set: Average loss: 8.0580, Accuracy: 769/5000 (15%)\n",
      "[epoch 46] loss: 0.0001452\n",
      "Test set: Average loss: 8.0712, Accuracy: 767/5000 (15%)\n",
      "[epoch 47] loss: 0.0001406\n",
      "Test set: Average loss: 8.0833, Accuracy: 767/5000 (15%)\n",
      "[epoch 48] loss: 0.0001365\n",
      "Test set: Average loss: 8.0943, Accuracy: 767/5000 (15%)\n",
      "[epoch 49] loss: 0.0001327\n",
      "Test set: Average loss: 8.1044, Accuracy: 767/5000 (15%)\n",
      "[epoch 50] loss: 0.0001295\n",
      "Test set: Average loss: 8.1135, Accuracy: 768/5000 (15%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6831, Accuracy: 835/5000 (17%)\n",
      "Test\n",
      "Test set: Average loss: 2.6594, Accuracy: 1713/10000 (17%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3091, Accuracy: 353/5000 (7%)\n",
      "[epoch 1] loss: 2.3011065\n",
      "Test set: Average loss: 2.3313, Accuracy: 596/5000 (12%)\n",
      "[epoch 2] loss: 1.9718766\n",
      "Test set: Average loss: 2.4763, Accuracy: 659/5000 (13%)\n",
      "[epoch 3] loss: 1.7214866\n",
      "Test set: Average loss: 2.6246, Accuracy: 719/5000 (14%)\n",
      "[epoch 4] loss: 1.4948268\n",
      "Test set: Average loss: 2.7323, Accuracy: 735/5000 (15%)\n",
      "[epoch 5] loss: 1.2623398\n",
      "Test set: Average loss: 2.8176, Accuracy: 752/5000 (15%)\n",
      "[epoch 6] loss: 1.0233351\n",
      "Test set: Average loss: 2.9113, Accuracy: 788/5000 (16%)\n",
      "[epoch 7] loss: 0.8039324\n",
      "Test set: Average loss: 3.0414, Accuracy: 804/5000 (16%)\n",
      "[epoch 8] loss: 0.6078486\n",
      "Test set: Average loss: 3.2009, Accuracy: 789/5000 (16%)\n",
      "[epoch 9] loss: 0.4241167\n",
      "Test set: Average loss: 3.4029, Accuracy: 763/5000 (15%)\n",
      "[epoch 10] loss: 0.2775501\n",
      "Test set: Average loss: 3.6457, Accuracy: 761/5000 (15%)\n",
      "[epoch 11] loss: 0.1780570\n",
      "Test set: Average loss: 3.9083, Accuracy: 767/5000 (15%)\n",
      "[epoch 12] loss: 0.1114173\n",
      "Test set: Average loss: 4.1707, Accuracy: 755/5000 (15%)\n",
      "[epoch 13] loss: 0.0673784\n",
      "Test set: Average loss: 4.4124, Accuracy: 756/5000 (15%)\n",
      "[epoch 14] loss: 0.0394167\n",
      "Test set: Average loss: 4.6236, Accuracy: 770/5000 (15%)\n",
      "[epoch 15] loss: 0.0227375\n",
      "Test set: Average loss: 4.8075, Accuracy: 767/5000 (15%)\n",
      "[epoch 16] loss: 0.0133755\n",
      "Test set: Average loss: 4.9704, Accuracy: 767/5000 (15%)\n",
      "[epoch 17] loss: 0.0082319\n",
      "Test set: Average loss: 5.1171, Accuracy: 772/5000 (15%)\n",
      "[epoch 18] loss: 0.0053418\n",
      "Test set: Average loss: 5.2503, Accuracy: 767/5000 (15%)\n",
      "[epoch 19] loss: 0.0036475\n",
      "Test set: Average loss: 5.3716, Accuracy: 776/5000 (16%)\n",
      "[epoch 20] loss: 0.0026103\n",
      "Test set: Average loss: 5.4825, Accuracy: 776/5000 (16%)\n",
      "[epoch 21] loss: 0.0019496\n",
      "Test set: Average loss: 5.5840, Accuracy: 777/5000 (16%)\n",
      "[epoch 22] loss: 0.0015128\n",
      "Test set: Average loss: 5.6770, Accuracy: 777/5000 (16%)\n",
      "[epoch 23] loss: 0.0012136\n",
      "Test set: Average loss: 5.7624, Accuracy: 781/5000 (16%)\n",
      "[epoch 24] loss: 0.0010007\n",
      "Test set: Average loss: 5.8410, Accuracy: 780/5000 (16%)\n",
      "[epoch 25] loss: 0.0008430\n",
      "Test set: Average loss: 5.9136, Accuracy: 783/5000 (16%)\n",
      "[epoch 26] loss: 0.0007224\n",
      "Test set: Average loss: 5.9808, Accuracy: 784/5000 (16%)\n",
      "[epoch 27] loss: 0.0006270\n",
      "Test set: Average loss: 6.0431, Accuracy: 784/5000 (16%)\n",
      "[epoch 28] loss: 0.0005499\n",
      "Test set: Average loss: 6.1012, Accuracy: 783/5000 (16%)\n",
      "[epoch 29] loss: 0.0004866\n",
      "Test set: Average loss: 6.1555, Accuracy: 781/5000 (16%)\n",
      "[epoch 30] loss: 0.0004342\n",
      "Test set: Average loss: 6.2063, Accuracy: 780/5000 (16%)\n",
      "[epoch 31] loss: 0.0003904\n",
      "Test set: Average loss: 6.2540, Accuracy: 779/5000 (16%)\n",
      "[epoch 32] loss: 0.0003534\n",
      "Test set: Average loss: 6.2988, Accuracy: 776/5000 (16%)\n",
      "[epoch 33] loss: 0.0003219\n",
      "Test set: Average loss: 6.3410, Accuracy: 774/5000 (15%)\n",
      "[epoch 34] loss: 0.0002950\n",
      "Test set: Average loss: 6.3808, Accuracy: 776/5000 (16%)\n",
      "[epoch 35] loss: 0.0002717\n",
      "Test set: Average loss: 6.4183, Accuracy: 775/5000 (16%)\n",
      "[epoch 36] loss: 0.0002517\n",
      "Test set: Average loss: 6.4536, Accuracy: 774/5000 (15%)\n",
      "[epoch 37] loss: 0.0002340\n",
      "Test set: Average loss: 6.4870, Accuracy: 769/5000 (15%)\n",
      "[epoch 38] loss: 0.0002186\n",
      "Test set: Average loss: 6.5185, Accuracy: 765/5000 (15%)\n",
      "[epoch 39] loss: 0.0002048\n",
      "Test set: Average loss: 6.5482, Accuracy: 761/5000 (15%)\n",
      "[epoch 40] loss: 0.0001926\n",
      "Test set: Average loss: 6.5763, Accuracy: 761/5000 (15%)\n",
      "[epoch 41] loss: 0.0001817\n",
      "Test set: Average loss: 6.6028, Accuracy: 760/5000 (15%)\n",
      "[epoch 42] loss: 0.0001720\n",
      "Test set: Average loss: 6.6278, Accuracy: 760/5000 (15%)\n",
      "[epoch 43] loss: 0.0001631\n",
      "Test set: Average loss: 6.6514, Accuracy: 760/5000 (15%)\n",
      "[epoch 44] loss: 0.0001552\n",
      "Test set: Average loss: 6.6737, Accuracy: 761/5000 (15%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] loss: 0.0001479\n",
      "Test set: Average loss: 6.6948, Accuracy: 758/5000 (15%)\n",
      "[epoch 46] loss: 0.0001413\n",
      "Test set: Average loss: 6.7147, Accuracy: 758/5000 (15%)\n",
      "[epoch 47] loss: 0.0001353\n",
      "Test set: Average loss: 6.7334, Accuracy: 758/5000 (15%)\n",
      "[epoch 48] loss: 0.0001299\n",
      "Test set: Average loss: 6.7512, Accuracy: 758/5000 (15%)\n",
      "[epoch 49] loss: 0.0001249\n",
      "Test set: Average loss: 6.7679, Accuracy: 758/5000 (15%)\n",
      "[epoch 50] loss: 0.0001203\n",
      "Test set: Average loss: 6.7838, Accuracy: 757/5000 (15%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0414, Accuracy: 804/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 3.0349, Accuracy: 1617/10000 (16%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 581/5000 (12%)\n",
      "[epoch 1] loss: 2.2725379\n",
      "Test set: Average loss: 2.3834, Accuracy: 531/5000 (11%)\n",
      "[epoch 2] loss: 1.9128057\n",
      "Test set: Average loss: 2.6608, Accuracy: 545/5000 (11%)\n",
      "[epoch 3] loss: 1.7305446\n",
      "Test set: Average loss: 2.7070, Accuracy: 688/5000 (14%)\n",
      "[epoch 4] loss: 1.5193002\n",
      "Test set: Average loss: 2.7108, Accuracy: 716/5000 (14%)\n",
      "[epoch 5] loss: 1.3199401\n",
      "Test set: Average loss: 2.7052, Accuracy: 721/5000 (14%)\n",
      "[epoch 6] loss: 1.0874630\n",
      "Test set: Average loss: 2.7858, Accuracy: 700/5000 (14%)\n",
      "[epoch 7] loss: 0.8955489\n",
      "Test set: Average loss: 2.9222, Accuracy: 715/5000 (14%)\n",
      "[epoch 8] loss: 0.7250426\n",
      "Test set: Average loss: 3.0584, Accuracy: 724/5000 (14%)\n",
      "[epoch 9] loss: 0.5502970\n",
      "Test set: Average loss: 3.2825, Accuracy: 737/5000 (15%)\n",
      "[epoch 10] loss: 0.4220529\n",
      "Test set: Average loss: 3.6073, Accuracy: 769/5000 (15%)\n",
      "[epoch 11] loss: 0.3235128\n",
      "Test set: Average loss: 3.9373, Accuracy: 770/5000 (15%)\n",
      "[epoch 12] loss: 0.2489225\n",
      "Test set: Average loss: 4.2127, Accuracy: 781/5000 (16%)\n",
      "[epoch 13] loss: 0.1871598\n",
      "Test set: Average loss: 4.4542, Accuracy: 764/5000 (15%)\n",
      "[epoch 14] loss: 0.1346360\n",
      "Test set: Average loss: 4.6860, Accuracy: 747/5000 (15%)\n",
      "[epoch 15] loss: 0.0924147\n",
      "Test set: Average loss: 4.9006, Accuracy: 706/5000 (14%)\n",
      "[epoch 16] loss: 0.0629016\n",
      "Test set: Average loss: 5.0913, Accuracy: 672/5000 (13%)\n",
      "[epoch 17] loss: 0.0475179\n",
      "Test set: Average loss: 5.2479, Accuracy: 627/5000 (13%)\n",
      "[epoch 18] loss: 0.0379796\n",
      "Test set: Average loss: 5.3658, Accuracy: 613/5000 (12%)\n",
      "[epoch 19] loss: 0.0280957\n",
      "Test set: Average loss: 5.4611, Accuracy: 604/5000 (12%)\n",
      "[epoch 20] loss: 0.0192854\n",
      "Test set: Average loss: 5.5515, Accuracy: 613/5000 (12%)\n",
      "[epoch 21] loss: 0.0132330\n",
      "Test set: Average loss: 5.6436, Accuracy: 633/5000 (13%)\n",
      "[epoch 22] loss: 0.0093955\n",
      "Test set: Average loss: 5.7378, Accuracy: 640/5000 (13%)\n",
      "[epoch 23] loss: 0.0069468\n",
      "Test set: Average loss: 5.8336, Accuracy: 658/5000 (13%)\n",
      "[epoch 24] loss: 0.0053307\n",
      "Test set: Average loss: 5.9301, Accuracy: 665/5000 (13%)\n",
      "[epoch 25] loss: 0.0042047\n",
      "Test set: Average loss: 6.0263, Accuracy: 679/5000 (14%)\n",
      "[epoch 26] loss: 0.0033862\n",
      "Test set: Average loss: 6.1212, Accuracy: 690/5000 (14%)\n",
      "[epoch 27] loss: 0.0027735\n",
      "Test set: Average loss: 6.2142, Accuracy: 702/5000 (14%)\n",
      "[epoch 28] loss: 0.0023044\n",
      "Test set: Average loss: 6.3043, Accuracy: 704/5000 (14%)\n",
      "[epoch 29] loss: 0.0019380\n",
      "Test set: Average loss: 6.3908, Accuracy: 705/5000 (14%)\n",
      "[epoch 30] loss: 0.0016490\n",
      "Test set: Average loss: 6.4731, Accuracy: 709/5000 (14%)\n",
      "[epoch 31] loss: 0.0014194\n",
      "Test set: Average loss: 6.5507, Accuracy: 715/5000 (14%)\n",
      "[epoch 32] loss: 0.0012352\n",
      "Test set: Average loss: 6.6233, Accuracy: 709/5000 (14%)\n",
      "[epoch 33] loss: 0.0010862\n",
      "Test set: Average loss: 6.6909, Accuracy: 711/5000 (14%)\n",
      "[epoch 34] loss: 0.0009647\n",
      "Test set: Average loss: 6.7534, Accuracy: 710/5000 (14%)\n",
      "[epoch 35] loss: 0.0008646\n",
      "Test set: Average loss: 6.8111, Accuracy: 705/5000 (14%)\n",
      "[epoch 36] loss: 0.0007812\n",
      "Test set: Average loss: 6.8641, Accuracy: 701/5000 (14%)\n",
      "[epoch 37] loss: 0.0007112\n",
      "Test set: Average loss: 6.9127, Accuracy: 700/5000 (14%)\n",
      "[epoch 38] loss: 0.0006519\n",
      "Test set: Average loss: 6.9573, Accuracy: 699/5000 (14%)\n",
      "[epoch 39] loss: 0.0006010\n",
      "Test set: Average loss: 6.9980, Accuracy: 698/5000 (14%)\n",
      "[epoch 40] loss: 0.0005576\n",
      "Test set: Average loss: 7.0354, Accuracy: 694/5000 (14%)\n",
      "[epoch 41] loss: 0.0005199\n",
      "Test set: Average loss: 7.0696, Accuracy: 697/5000 (14%)\n",
      "[epoch 42] loss: 0.0004872\n",
      "Test set: Average loss: 7.1008, Accuracy: 703/5000 (14%)\n",
      "[epoch 43] loss: 0.0004587\n",
      "Test set: Average loss: 7.1295, Accuracy: 704/5000 (14%)\n",
      "[epoch 44] loss: 0.0004336\n",
      "Test set: Average loss: 7.1558, Accuracy: 706/5000 (14%)\n",
      "[epoch 45] loss: 0.0004118\n",
      "Test set: Average loss: 7.1799, Accuracy: 704/5000 (14%)\n",
      "[epoch 46] loss: 0.0003924\n",
      "Test set: Average loss: 7.2020, Accuracy: 703/5000 (14%)\n",
      "[epoch 47] loss: 0.0003751\n",
      "Test set: Average loss: 7.2224, Accuracy: 701/5000 (14%)\n",
      "[epoch 48] loss: 0.0003597\n",
      "Test set: Average loss: 7.2411, Accuracy: 700/5000 (14%)\n",
      "[epoch 49] loss: 0.0003460\n",
      "Test set: Average loss: 7.2584, Accuracy: 701/5000 (14%)\n",
      "[epoch 50] loss: 0.0003337\n",
      "Test set: Average loss: 7.2743, Accuracy: 699/5000 (14%)\n",
      "Validation:\n",
      "Test set: Average loss: 4.2127, Accuracy: 781/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 4.1851, Accuracy: 1533/10000 (15%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3056, Accuracy: 442/5000 (9%)\n",
      "[epoch 1] loss: 2.2795725\n",
      "Test set: Average loss: 2.3914, Accuracy: 483/5000 (10%)\n",
      "[epoch 2] loss: 1.9729041\n",
      "Test set: Average loss: 2.5608, Accuracy: 686/5000 (14%)\n",
      "[epoch 3] loss: 1.7687774\n",
      "Test set: Average loss: 2.5373, Accuracy: 860/5000 (17%)\n",
      "[epoch 4] loss: 1.5033976\n",
      "Test set: Average loss: 2.4464, Accuracy: 1070/5000 (21%)\n",
      "[epoch 5] loss: 1.1999972\n",
      "Test set: Average loss: 2.4866, Accuracy: 1047/5000 (21%)\n",
      "[epoch 6] loss: 0.9172316\n",
      "Test set: Average loss: 2.6386, Accuracy: 1029/5000 (21%)\n",
      "[epoch 7] loss: 0.6924538\n",
      "Test set: Average loss: 2.9325, Accuracy: 981/5000 (20%)\n",
      "[epoch 8] loss: 0.4533847\n",
      "Test set: Average loss: 3.0473, Accuracy: 1045/5000 (21%)\n",
      "[epoch 9] loss: 0.2786824\n",
      "Test set: Average loss: 3.2905, Accuracy: 1011/5000 (20%)\n",
      "[epoch 10] loss: 0.1957814\n",
      "Test set: Average loss: 3.6577, Accuracy: 959/5000 (19%)\n",
      "[epoch 11] loss: 0.1185520\n",
      "Test set: Average loss: 4.0090, Accuracy: 983/5000 (20%)\n",
      "[epoch 12] loss: 0.0673660\n",
      "Test set: Average loss: 4.3616, Accuracy: 970/5000 (19%)\n",
      "[epoch 13] loss: 0.0385474\n",
      "Test set: Average loss: 4.6499, Accuracy: 989/5000 (20%)\n",
      "[epoch 14] loss: 0.0234706\n",
      "Test set: Average loss: 4.8793, Accuracy: 986/5000 (20%)\n",
      "[epoch 15] loss: 0.0147431\n",
      "Test set: Average loss: 5.0688, Accuracy: 996/5000 (20%)\n",
      "[epoch 16] loss: 0.0092876\n",
      "Test set: Average loss: 5.2152, Accuracy: 1002/5000 (20%)\n",
      "[epoch 17] loss: 0.0065269\n",
      "Test set: Average loss: 5.3427, Accuracy: 1004/5000 (20%)\n",
      "[epoch 18] loss: 0.0048917\n",
      "Test set: Average loss: 5.4476, Accuracy: 1002/5000 (20%)\n",
      "[epoch 19] loss: 0.0037697\n",
      "Test set: Average loss: 5.5285, Accuracy: 1005/5000 (20%)\n",
      "[epoch 20] loss: 0.0028360\n",
      "Test set: Average loss: 5.5942, Accuracy: 999/5000 (20%)\n",
      "[epoch 21] loss: 0.0022474\n",
      "Test set: Average loss: 5.6489, Accuracy: 1003/5000 (20%)\n",
      "[epoch 22] loss: 0.0018167\n",
      "Test set: Average loss: 5.6955, Accuracy: 1004/5000 (20%)\n",
      "[epoch 23] loss: 0.0015079\n",
      "Test set: Average loss: 5.7350, Accuracy: 1003/5000 (20%)\n",
      "[epoch 24] loss: 0.0013421\n",
      "Test set: Average loss: 5.7672, Accuracy: 1000/5000 (20%)\n",
      "[epoch 25] loss: 0.0011181\n",
      "Test set: Average loss: 5.7939, Accuracy: 996/5000 (20%)\n",
      "[epoch 26] loss: 0.0010844\n",
      "Test set: Average loss: 5.8164, Accuracy: 1002/5000 (20%)\n",
      "[epoch 27] loss: 0.0009891\n",
      "Test set: Average loss: 5.8355, Accuracy: 1005/5000 (20%)\n",
      "[epoch 28] loss: 0.0008699\n",
      "Test set: Average loss: 5.8523, Accuracy: 1010/5000 (20%)\n",
      "[epoch 29] loss: 0.0009016\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.8665, Accuracy: 1019/5000 (20%)\n",
      "[epoch 30] loss: 0.0007903\n",
      "Test set: Average loss: 5.8677, Accuracy: 1020/5000 (20%)\n",
      "[epoch 31] loss: 0.0007816\n",
      "Test set: Average loss: 5.8688, Accuracy: 1022/5000 (20%)\n",
      "[epoch 32] loss: 0.0008057\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.8698, Accuracy: 1022/5000 (20%)\n",
      "[epoch 33] loss: 0.0007044\n",
      "Test set: Average loss: 5.8699, Accuracy: 1022/5000 (20%)\n",
      "[epoch 34] loss: 0.0007535\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0007334\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 36] loss: 0.0007299\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 37] loss: 0.0007828\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 38] loss: 0.0008023\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 39] loss: 0.0007909\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 40] loss: 0.0007410\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 41] loss: 0.0008111\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 42] loss: 0.0007697\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 43] loss: 0.0007849\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 44] loss: 0.0007723\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 45] loss: 0.0007655\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 46] loss: 0.0007358\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 47] loss: 0.0007495\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 48] loss: 0.0007973\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 49] loss: 0.0007884\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "[epoch 50] loss: 0.0007424\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 5.8700, Accuracy: 1022/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4464, Accuracy: 1070/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 2.4215, Accuracy: 2138/10000 (21%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 553/5000 (11%)\n",
      "[epoch 1] loss: 2.2623062\n",
      "Test set: Average loss: 2.3644, Accuracy: 547/5000 (11%)\n",
      "[epoch 2] loss: 1.9653229\n",
      "Test set: Average loss: 2.3857, Accuracy: 715/5000 (14%)\n",
      "[epoch 3] loss: 1.6597276\n",
      "Test set: Average loss: 2.3929, Accuracy: 800/5000 (16%)\n",
      "[epoch 4] loss: 1.4720602\n",
      "Test set: Average loss: 2.5096, Accuracy: 792/5000 (16%)\n",
      "[epoch 5] loss: 1.2089296\n",
      "Test set: Average loss: 2.6092, Accuracy: 920/5000 (18%)\n",
      "[epoch 6] loss: 0.9333265\n",
      "Test set: Average loss: 2.7751, Accuracy: 963/5000 (19%)\n",
      "[epoch 7] loss: 0.7926442\n",
      "Test set: Average loss: 2.8614, Accuracy: 933/5000 (19%)\n",
      "[epoch 8] loss: 0.5753166\n",
      "Test set: Average loss: 2.9745, Accuracy: 892/5000 (18%)\n",
      "[epoch 9] loss: 0.4427978\n",
      "Test set: Average loss: 3.1631, Accuracy: 936/5000 (19%)\n",
      "[epoch 10] loss: 0.3716431\n",
      "Test set: Average loss: 3.3407, Accuracy: 962/5000 (19%)\n",
      "[epoch 11] loss: 0.2393794\n",
      "Test set: Average loss: 3.5826, Accuracy: 918/5000 (18%)\n",
      "[epoch 12] loss: 0.1669947\n",
      "Test set: Average loss: 3.7478, Accuracy: 906/5000 (18%)\n",
      "[epoch 13] loss: 0.1074424\n",
      "Test set: Average loss: 3.8909, Accuracy: 914/5000 (18%)\n",
      "[epoch 14] loss: 0.0696103\n",
      "Test set: Average loss: 4.0201, Accuracy: 909/5000 (18%)\n",
      "[epoch 15] loss: 0.0445803\n",
      "Test set: Average loss: 4.1978, Accuracy: 915/5000 (18%)\n",
      "[epoch 16] loss: 0.0284031\n",
      "Test set: Average loss: 4.4104, Accuracy: 901/5000 (18%)\n",
      "[epoch 17] loss: 0.0196419\n",
      "Test set: Average loss: 4.6124, Accuracy: 884/5000 (18%)\n",
      "[epoch 18] loss: 0.0142077\n",
      "Test set: Average loss: 4.7696, Accuracy: 873/5000 (17%)\n",
      "[epoch 19] loss: 0.0106662\n",
      "Test set: Average loss: 4.8911, Accuracy: 879/5000 (18%)\n",
      "[epoch 20] loss: 0.0069770\n",
      "Test set: Average loss: 4.9916, Accuracy: 888/5000 (18%)\n",
      "[epoch 21] loss: 0.0049267\n",
      "Test set: Average loss: 5.0838, Accuracy: 892/5000 (18%)\n",
      "[epoch 22] loss: 0.0040242\n",
      "Test set: Average loss: 5.1647, Accuracy: 875/5000 (18%)\n",
      "[epoch 23] loss: 0.0030166\n",
      "Test set: Average loss: 5.2392, Accuracy: 884/5000 (18%)\n",
      "[epoch 24] loss: 0.0028144\n",
      "Test set: Average loss: 5.3053, Accuracy: 879/5000 (18%)\n",
      "[epoch 25] loss: 0.0023444\n",
      "Test set: Average loss: 5.3624, Accuracy: 864/5000 (17%)\n",
      "[epoch 26] loss: 0.0022976\n",
      "Test set: Average loss: 5.4116, Accuracy: 864/5000 (17%)\n",
      "[epoch 27] loss: 0.0020668\n",
      "Test set: Average loss: 5.4525, Accuracy: 864/5000 (17%)\n",
      "[epoch 28] loss: 0.0018453\n",
      "Test set: Average loss: 5.4892, Accuracy: 866/5000 (17%)\n",
      "[epoch 29] loss: 0.0016935\n",
      "Test set: Average loss: 5.5199, Accuracy: 865/5000 (17%)\n",
      "[epoch 30] loss: 0.0015532\n",
      "Test set: Average loss: 5.5476, Accuracy: 867/5000 (17%)\n",
      "[epoch 31] loss: 0.0014305\n",
      "Test set: Average loss: 5.5714, Accuracy: 864/5000 (17%)\n",
      "[epoch 32] loss: 0.0012791\n",
      "Test set: Average loss: 5.5906, Accuracy: 866/5000 (17%)\n",
      "[epoch 33] loss: 0.0012406\n",
      "Test set: Average loss: 5.6069, Accuracy: 865/5000 (17%)\n",
      "[epoch 34] loss: 0.0011368\n",
      "Test set: Average loss: 5.6203, Accuracy: 868/5000 (17%)\n",
      "[epoch 35] loss: 0.0011146\n",
      "Test set: Average loss: 5.6310, Accuracy: 870/5000 (17%)\n",
      "[epoch 36] loss: 0.0010604\n",
      "Test set: Average loss: 5.6391, Accuracy: 868/5000 (17%)\n",
      "[epoch 37] loss: 0.0009609\n",
      "Test set: Average loss: 5.6466, Accuracy: 866/5000 (17%)\n",
      "[epoch 38] loss: 0.0009293\n",
      "Test set: Average loss: 5.6527, Accuracy: 867/5000 (17%)\n",
      "[epoch 39] loss: 0.0009291\n",
      "Test set: Average loss: 5.6579, Accuracy: 869/5000 (17%)\n",
      "[epoch 40] loss: 0.0008965\n",
      "Test set: Average loss: 5.6626, Accuracy: 869/5000 (17%)\n",
      "[epoch 41] loss: 0.0008617\n",
      "Test set: Average loss: 5.6662, Accuracy: 871/5000 (17%)\n",
      "[epoch 42] loss: 0.0008249\n",
      "Test set: Average loss: 5.6690, Accuracy: 871/5000 (17%)\n",
      "[epoch 43] loss: 0.0008067\n",
      "Test set: Average loss: 5.6714, Accuracy: 866/5000 (17%)\n",
      "[epoch 44] loss: 0.0008003\n",
      "Test set: Average loss: 5.6736, Accuracy: 870/5000 (17%)\n",
      "[epoch 45] loss: 0.0007751\n",
      "Test set: Average loss: 5.6750, Accuracy: 869/5000 (17%)\n",
      "[epoch 46] loss: 0.0007368\n",
      "Test set: Average loss: 5.6771, Accuracy: 869/5000 (17%)\n",
      "[epoch 47] loss: 0.0007585\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.6796, Accuracy: 869/5000 (17%)\n",
      "[epoch 48] loss: 0.0007130\n",
      "Test set: Average loss: 5.6799, Accuracy: 869/5000 (17%)\n",
      "[epoch 49] loss: 0.0007209\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.6802, Accuracy: 869/5000 (17%)\n",
      "[epoch 50] loss: 0.0007226\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.6802, Accuracy: 869/5000 (17%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7751, Accuracy: 963/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 2.7537, Accuracy: 1979/10000 (20%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3048, Accuracy: 499/5000 (10%)\n",
      "[epoch 1] loss: 2.2498606\n",
      "Test set: Average loss: 2.4098, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 1.9389116\n",
      "Test set: Average loss: 2.4568, Accuracy: 714/5000 (14%)\n",
      "[epoch 3] loss: 1.6723886\n",
      "Test set: Average loss: 2.3966, Accuracy: 778/5000 (16%)\n",
      "[epoch 4] loss: 1.4148474\n",
      "Test set: Average loss: 2.3996, Accuracy: 846/5000 (17%)\n",
      "[epoch 5] loss: 1.1850298\n",
      "Test set: Average loss: 2.5577, Accuracy: 880/5000 (18%)\n",
      "[epoch 6] loss: 0.9202076\n",
      "Test set: Average loss: 2.8271, Accuracy: 909/5000 (18%)\n",
      "[epoch 7] loss: 0.6356780\n",
      "Test set: Average loss: 3.0105, Accuracy: 913/5000 (18%)\n",
      "[epoch 8] loss: 0.4762838\n",
      "Test set: Average loss: 3.1022, Accuracy: 919/5000 (18%)\n",
      "[epoch 9] loss: 0.3258061\n",
      "Test set: Average loss: 3.3488, Accuracy: 892/5000 (18%)\n",
      "[epoch 10] loss: 0.2850950\n",
      "Test set: Average loss: 3.6492, Accuracy: 907/5000 (18%)\n",
      "[epoch 11] loss: 0.1644434\n",
      "Test set: Average loss: 4.0528, Accuracy: 911/5000 (18%)\n",
      "[epoch 12] loss: 0.1855294\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.1796, Accuracy: 927/5000 (19%)\n",
      "[epoch 13] loss: 0.0575246\n",
      "Test set: Average loss: 4.1794, Accuracy: 924/5000 (18%)\n",
      "[epoch 14] loss: 0.0612658\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.1798, Accuracy: 930/5000 (19%)\n",
      "[epoch 15] loss: 0.0556489\n",
      "Test set: Average loss: 4.1799, Accuracy: 928/5000 (19%)\n",
      "[epoch 16] loss: 0.0551203\n",
      "Test set: Average loss: 4.1800, Accuracy: 926/5000 (19%)\n",
      "[epoch 17] loss: 0.0566353\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.1801, Accuracy: 926/5000 (19%)\n",
      "[epoch 18] loss: 0.0602593\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 19] loss: 0.0514205\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 20] loss: 0.0504181\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 21] loss: 0.0497206\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 22] loss: 0.0617274\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 23] loss: 0.0556157\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 24] loss: 0.0579423\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 25] loss: 0.0529673\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 26] loss: 0.0527958\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 27] loss: 0.0536698\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 28] loss: 0.0570766\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 29] loss: 0.0531651\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 30] loss: 0.0552600\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 31] loss: 0.0524985\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 32] loss: 0.0564559\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 33] loss: 0.0548446\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 34] loss: 0.0560838\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 35] loss: 0.0542802\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 36] loss: 0.0546498\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 37] loss: 0.0504499\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 38] loss: 0.0546020\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 39] loss: 0.0523219\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 40] loss: 0.0559857\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 41] loss: 0.0615027\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 42] loss: 0.0513699\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 43] loss: 0.0475107\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 44] loss: 0.0489849\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 45] loss: 0.0560510\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 46] loss: 0.0528322\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 47] loss: 0.0544055\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 48] loss: 0.0559576\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 49] loss: 0.0527060\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "[epoch 50] loss: 0.0558407\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 4.1801, Accuracy: 927/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 4.1798, Accuracy: 930/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 4.0793, Accuracy: 1806/10000 (18%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3079, Accuracy: 479/5000 (10%)\n",
      "[epoch 1] loss: 2.2920039\n",
      "Test set: Average loss: 2.3765, Accuracy: 676/5000 (14%)\n",
      "[epoch 2] loss: 2.0409051\n",
      "Test set: Average loss: 2.3630, Accuracy: 819/5000 (16%)\n",
      "[epoch 3] loss: 1.7069964\n",
      "Test set: Average loss: 2.3880, Accuracy: 964/5000 (19%)\n",
      "[epoch 4] loss: 1.6255817\n",
      "Test set: Average loss: 2.6483, Accuracy: 811/5000 (16%)\n",
      "[epoch 5] loss: 1.4524394\n",
      "Test set: Average loss: 2.4902, Accuracy: 1051/5000 (21%)\n",
      "[epoch 6] loss: 1.2305623\n",
      "Test set: Average loss: 2.6340, Accuracy: 1038/5000 (21%)\n",
      "[epoch 7] loss: 0.9234129\n",
      "Test set: Average loss: 2.6341, Accuracy: 1012/5000 (20%)\n",
      "[epoch 8] loss: 1.5740706\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.0813, Accuracy: 996/5000 (20%)\n",
      "[epoch 9] loss: 0.6690101\n",
      "Test set: Average loss: 3.1039, Accuracy: 976/5000 (20%)\n",
      "[epoch 10] loss: 0.8466179\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0146, Accuracy: 1008/5000 (20%)\n",
      "[epoch 11] loss: 0.6637637\n",
      "Test set: Average loss: 3.0001, Accuracy: 1011/5000 (20%)\n",
      "[epoch 12] loss: 0.5555912\n",
      "Test set: Average loss: 2.9823, Accuracy: 1022/5000 (20%)\n",
      "[epoch 13] loss: 0.6029748\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.9653, Accuracy: 1030/5000 (21%)\n",
      "[epoch 14] loss: 0.7234332\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.9634, Accuracy: 1030/5000 (21%)\n",
      "[epoch 15] loss: 0.6662804\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.9633, Accuracy: 1031/5000 (21%)\n",
      "[epoch 16] loss: 0.7133749\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 17] loss: 0.6427864\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 18] loss: 0.6557515\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 19] loss: 0.6674170\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 20] loss: 0.7044077\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 21] loss: 0.7599970\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 22] loss: 0.7119451\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 23] loss: 0.7231526\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 24] loss: 0.6768522\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-17.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 25] loss: 0.5946286\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 26] loss: 0.7573260\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 27] loss: 0.5777168\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 28] loss: 0.6565621\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 29] loss: 0.6805914\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 30] loss: 0.7662243\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 31] loss: 0.6448515\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 32] loss: 0.6920633\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 33] loss: 0.6259791\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 34] loss: 0.6876372\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 35] loss: 0.6493282\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 36] loss: 0.7323562\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 37] loss: 0.7458332\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 38] loss: 0.6111279\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 39] loss: 0.6401069\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 40] loss: 0.5624423\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 41] loss: 0.6323823\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 42] loss: 0.6451189\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 43] loss: 0.6263101\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 44] loss: 0.6342784\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 45] loss: 0.6781245\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 46] loss: 0.6517632\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.9656, Accuracy: 1031/5000 (21%)\n",
      "[epoch 47] loss: 0.7699248\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 48] loss: 0.6876967\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 49] loss: 0.6421155\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "[epoch 50] loss: 1.6778869\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.9632, Accuracy: 1031/5000 (21%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4902, Accuracy: 1051/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 2.4216, Accuracy: 2139/10000 (21%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3004, Accuracy: 540/5000 (11%)\n",
      "[epoch 1] loss: 2.3458626\n",
      "Test set: Average loss: 2.2874, Accuracy: 742/5000 (15%)\n",
      "[epoch 2] loss: 2.0529314\n",
      "Test set: Average loss: 2.2550, Accuracy: 830/5000 (17%)\n",
      "[epoch 3] loss: 2.0944591\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2648, Accuracy: 1006/5000 (20%)\n",
      "[epoch 4] loss: 1.8359798\n",
      "Test set: Average loss: 2.2633, Accuracy: 1002/5000 (20%)\n",
      "[epoch 5] loss: 2.0766841\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.2503, Accuracy: 1024/5000 (20%)\n",
      "[epoch 6] loss: 1.7675173\n",
      "Test set: Average loss: 2.2488, Accuracy: 1027/5000 (21%)\n",
      "[epoch 7] loss: 1.6844304\n",
      "Test set: Average loss: 2.2477, Accuracy: 1026/5000 (21%)\n",
      "[epoch 8] loss: 1.6870714\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.2466, Accuracy: 1025/5000 (20%)\n",
      "[epoch 9] loss: 1.6485105\n",
      "Test set: Average loss: 2.2464, Accuracy: 1024/5000 (20%)\n",
      "[epoch 10] loss: 1.8344640\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1024/5000 (20%)\n",
      "[epoch 11] loss: 1.7593336\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1024/5000 (20%)\n",
      "[epoch 12] loss: 1.7425064\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 13] loss: 1.7618212\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 14] loss: 1.6888034\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 15] loss: 1.6685426\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 16] loss: 1.8761038\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 17] loss: 1.6806635\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 18] loss: 1.6819896\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 19] loss: 1.6752619\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 20] loss: 1.9109255\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 21] loss: 1.7968738\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 22] loss: 1.7697368\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 23] loss: 1.6935332\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 24] loss: 1.8939703\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 25] loss: 1.7069130\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 26] loss: 1.6942985\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 27] loss: 1.7295031\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 28] loss: 1.8020370\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 29] loss: 1.8359096\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 30] loss: 1.7530652\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 31] loss: 1.7739000\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 32] loss: 1.7210010\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 33] loss: 1.5749112\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 34] loss: 1.9035912\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 35] loss: 1.7108397\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 36] loss: 1.7523423\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 37] loss: 1.8015946\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 38] loss: 1.9468872\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 39] loss: 1.7417078\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 40] loss: 1.7112124\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 41] loss: 1.6922768\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 42] loss: 1.6138071\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 43] loss: 1.6394092\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 44] loss: 2.0988940\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 45] loss: 1.6672677\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 46] loss: 1.7076561\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 47] loss: 1.7048031\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 48] loss: 1.6831562\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 49] loss: 1.7805693\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "[epoch 50] loss: 1.7365853\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 2.2463, Accuracy: 1025/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2488, Accuracy: 1027/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 2.2309, Accuracy: 2138/10000 (21%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3079, Accuracy: 539/5000 (11%)\n",
      "[epoch 1] loss: 2.3248788\n",
      "Test set: Average loss: 2.3368, Accuracy: 753/5000 (15%)\n",
      "[epoch 2] loss: 2.0581036\n",
      "Test set: Average loss: 2.2935, Accuracy: 877/5000 (18%)\n",
      "[epoch 3] loss: 1.9965823\n",
      "Test set: Average loss: 2.3576, Accuracy: 857/5000 (17%)\n",
      "[epoch 4] loss: 1.7420849\n",
      "Test set: Average loss: 2.2968, Accuracy: 978/5000 (20%)\n",
      "[epoch 5] loss: 1.3973794\n",
      "Test set: Average loss: 2.5395, Accuracy: 919/5000 (18%)\n",
      "[epoch 6] loss: 1.3435018\n",
      "Test set: Average loss: 2.7974, Accuracy: 892/5000 (18%)\n",
      "[epoch 7] loss: 0.9543481\n",
      "Test set: Average loss: 2.5184, Accuracy: 1004/5000 (20%)\n",
      "[epoch 8] loss: 0.8483768\n",
      "Test set: Average loss: 2.5492, Accuracy: 1094/5000 (22%)\n",
      "[epoch 9] loss: 0.7802566\n",
      "Test set: Average loss: 2.7985, Accuracy: 1106/5000 (22%)\n",
      "[epoch 10] loss: 0.6185964\n",
      "Test set: Average loss: 3.1453, Accuracy: 1018/5000 (20%)\n",
      "[epoch 11] loss: 0.5347039\n",
      "Test set: Average loss: 3.2627, Accuracy: 1069/5000 (21%)\n",
      "[epoch 12] loss: 0.3841259\n",
      "Test set: Average loss: 3.1340, Accuracy: 1094/5000 (22%)\n",
      "[epoch 13] loss: 0.3624259\n",
      "Test set: Average loss: 3.1466, Accuracy: 1070/5000 (21%)\n",
      "[epoch 14] loss: 0.4839094\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.4701, Accuracy: 1064/5000 (21%)\n",
      "[epoch 15] loss: 0.2762478\n",
      "Test set: Average loss: 3.4665, Accuracy: 1067/5000 (21%)\n",
      "[epoch 16] loss: 0.1807775\n",
      "Test set: Average loss: 3.4368, Accuracy: 1055/5000 (21%)\n",
      "[epoch 17] loss: 0.1427893\n",
      "Test set: Average loss: 3.4289, Accuracy: 1075/5000 (22%)\n",
      "[epoch 18] loss: 0.1691230\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.4218, Accuracy: 1085/5000 (22%)\n",
      "[epoch 19] loss: 0.1440751\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.4196, Accuracy: 1086/5000 (22%)\n",
      "[epoch 20] loss: 0.1156662\n",
      "Test set: Average loss: 3.4192, Accuracy: 1086/5000 (22%)\n",
      "[epoch 21] loss: 0.1653463\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.4190, Accuracy: 1086/5000 (22%)\n",
      "[epoch 22] loss: 0.1105039\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 23] loss: 0.1481895\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 24] loss: 0.1104891\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 25] loss: 0.1552165\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 26] loss: 0.1255445\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 27] loss: 0.1369255\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 28] loss: 0.1151710\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 29] loss: 0.1827460\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 30] loss: 0.1135921\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 31] loss: 0.1708445\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 32] loss: 0.1177415\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 33] loss: 1.4808749\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 34] loss: 0.1135687\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 35] loss: 0.1649373\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 36] loss: 0.1405462\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 37] loss: 0.1313713\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 38] loss: 0.1444016\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 39] loss: 0.1409663\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 40] loss: 0.1178600\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 41] loss: 0.1242445\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 42] loss: 0.1519280\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 43] loss: 0.1306676\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 44] loss: 0.1232979\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 45] loss: 0.1716197\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 46] loss: 0.1505568\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 47] loss: 0.1150223\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 48] loss: 0.1226595\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 49] loss: 0.1330352\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "[epoch 50] loss: 0.1443941\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 3.4189, Accuracy: 1086/5000 (22%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7985, Accuracy: 1106/5000 (22%)\n",
      "Test\n",
      "Test set: Average loss: 2.7758, Accuracy: 2207/10000 (22%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 587/5000 (12%)\n",
      "[epoch 1] loss: 2.2933942\n",
      "Test set: Average loss: 2.2071, Accuracy: 1028/5000 (21%)\n",
      "[epoch 2] loss: 2.0096363\n",
      "Test set: Average loss: 2.1275, Accuracy: 1258/5000 (25%)\n",
      "[epoch 3] loss: 1.7403138\n",
      "Test set: Average loss: 2.1249, Accuracy: 1176/5000 (24%)\n",
      "[epoch 4] loss: 1.4653279\n",
      "Test set: Average loss: 2.0808, Accuracy: 1328/5000 (27%)\n",
      "[epoch 5] loss: 1.1942800\n",
      "Test set: Average loss: 2.1899, Accuracy: 1440/5000 (29%)\n",
      "[epoch 6] loss: 0.9330606\n",
      "Test set: Average loss: 2.3081, Accuracy: 1406/5000 (28%)\n",
      "[epoch 7] loss: 0.6721661\n",
      "Test set: Average loss: 2.4153, Accuracy: 1426/5000 (29%)\n",
      "[epoch 8] loss: 0.5311363\n",
      "Test set: Average loss: 2.7024, Accuracy: 1378/5000 (28%)\n",
      "[epoch 9] loss: 0.3575566\n",
      "Test set: Average loss: 3.0457, Accuracy: 1407/5000 (28%)\n",
      "[epoch 10] loss: 0.2846871\n",
      "Test set: Average loss: 3.0532, Accuracy: 1366/5000 (27%)\n",
      "[epoch 11] loss: 0.1987048\n",
      "Test set: Average loss: 3.5546, Accuracy: 1293/5000 (26%)\n",
      "[epoch 12] loss: 0.1756242\n",
      "Test set: Average loss: 3.5620, Accuracy: 1419/5000 (28%)\n",
      "[epoch 13] loss: 0.1254596\n",
      "Test set: Average loss: 3.4987, Accuracy: 1347/5000 (27%)\n",
      "[epoch 14] loss: 0.0753598\n",
      "Test set: Average loss: 3.8162, Accuracy: 1363/5000 (27%)\n",
      "[epoch 15] loss: 0.0467299\n",
      "Test set: Average loss: 3.8227, Accuracy: 1429/5000 (29%)\n",
      "[epoch 16] loss: 0.0292576\n",
      "Test set: Average loss: 3.9201, Accuracy: 1403/5000 (28%)\n",
      "[epoch 17] loss: 0.0167885\n",
      "Test set: Average loss: 4.0682, Accuracy: 1415/5000 (28%)\n",
      "[epoch 18] loss: 0.0117046\n",
      "Test set: Average loss: 4.1545, Accuracy: 1435/5000 (29%)\n",
      "[epoch 19] loss: 0.0075774\n",
      "Test set: Average loss: 4.1879, Accuracy: 1410/5000 (28%)\n",
      "[epoch 20] loss: 0.0064352\n",
      "Test set: Average loss: 4.2116, Accuracy: 1408/5000 (28%)\n",
      "[epoch 21] loss: 0.0053758\n",
      "Test set: Average loss: 4.2341, Accuracy: 1431/5000 (29%)\n",
      "[epoch 22] loss: 0.0047850\n",
      "Test set: Average loss: 4.2719, Accuracy: 1431/5000 (29%)\n",
      "[epoch 23] loss: 0.0042034\n",
      "Test set: Average loss: 4.3110, Accuracy: 1415/5000 (28%)\n",
      "[epoch 24] loss: 0.0037890\n",
      "Test set: Average loss: 4.3398, Accuracy: 1415/5000 (28%)\n",
      "[epoch 25] loss: 0.0035352\n",
      "Test set: Average loss: 4.3676, Accuracy: 1415/5000 (28%)\n",
      "[epoch 26] loss: 0.0032559\n",
      "Test set: Average loss: 4.3955, Accuracy: 1410/5000 (28%)\n",
      "[epoch 27] loss: 0.0030673\n",
      "Test set: Average loss: 4.4150, Accuracy: 1408/5000 (28%)\n",
      "[epoch 28] loss: 0.0028555\n",
      "Test set: Average loss: 4.4425, Accuracy: 1405/5000 (28%)\n",
      "[epoch 29] loss: 0.0026776\n",
      "Test set: Average loss: 4.4587, Accuracy: 1413/5000 (28%)\n",
      "[epoch 30] loss: 0.0025191\n",
      "Test set: Average loss: 4.4777, Accuracy: 1409/5000 (28%)\n",
      "[epoch 31] loss: 0.0023791\n",
      "Test set: Average loss: 4.4975, Accuracy: 1416/5000 (28%)\n",
      "[epoch 32] loss: 0.0022626\n",
      "Test set: Average loss: 4.5210, Accuracy: 1404/5000 (28%)\n",
      "[epoch 33] loss: 0.0021481\n",
      "Test set: Average loss: 4.5341, Accuracy: 1405/5000 (28%)\n",
      "[epoch 34] loss: 0.0020535\n",
      "Test set: Average loss: 4.5542, Accuracy: 1407/5000 (28%)\n",
      "[epoch 35] loss: 0.0019673\n",
      "Test set: Average loss: 4.5704, Accuracy: 1416/5000 (28%)\n",
      "[epoch 36] loss: 0.0018662\n",
      "Test set: Average loss: 4.5905, Accuracy: 1404/5000 (28%)\n",
      "[epoch 37] loss: 0.0017688\n",
      "Test set: Average loss: 4.6072, Accuracy: 1403/5000 (28%)\n",
      "[epoch 38] loss: 0.0017078\n",
      "Test set: Average loss: 4.6197, Accuracy: 1413/5000 (28%)\n",
      "[epoch 39] loss: 0.0016141\n",
      "Test set: Average loss: 4.6295, Accuracy: 1411/5000 (28%)\n",
      "[epoch 40] loss: 0.0015579\n",
      "Test set: Average loss: 4.6425, Accuracy: 1412/5000 (28%)\n",
      "[epoch 41] loss: 0.0015075\n",
      "Test set: Average loss: 4.6668, Accuracy: 1413/5000 (28%)\n",
      "[epoch 42] loss: 0.0014233\n",
      "Test set: Average loss: 4.6803, Accuracy: 1408/5000 (28%)\n",
      "[epoch 43] loss: 0.0013760\n",
      "Test set: Average loss: 4.6946, Accuracy: 1412/5000 (28%)\n",
      "[epoch 44] loss: 0.0013265\n",
      "Test set: Average loss: 4.7048, Accuracy: 1407/5000 (28%)\n",
      "[epoch 45] loss: 0.0012885\n",
      "Test set: Average loss: 4.7183, Accuracy: 1412/5000 (28%)\n",
      "[epoch 46] loss: 0.0012311\n",
      "Test set: Average loss: 4.7334, Accuracy: 1410/5000 (28%)\n",
      "[epoch 47] loss: 0.0011877\n",
      "Test set: Average loss: 4.7465, Accuracy: 1410/5000 (28%)\n",
      "[epoch 48] loss: 0.0011349\n",
      "Test set: Average loss: 4.7592, Accuracy: 1412/5000 (28%)\n",
      "[epoch 49] loss: 0.0011092\n",
      "Test set: Average loss: 4.7766, Accuracy: 1408/5000 (28%)\n",
      "[epoch 50] loss: 0.0010707\n",
      "Test set: Average loss: 4.7848, Accuracy: 1411/5000 (28%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1899, Accuracy: 1440/5000 (29%)\n",
      "Test\n",
      "Test set: Average loss: 2.1732, Accuracy: 2792/10000 (28%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 539/5000 (11%)\n",
      "[epoch 1] loss: 2.2378636\n",
      "Test set: Average loss: 2.1035, Accuracy: 1101/5000 (22%)\n",
      "[epoch 2] loss: 1.8687165\n",
      "Test set: Average loss: 1.9712, Accuracy: 1360/5000 (27%)\n",
      "[epoch 3] loss: 1.5881682\n",
      "Test set: Average loss: 1.9823, Accuracy: 1510/5000 (30%)\n",
      "[epoch 4] loss: 1.3107443\n",
      "Test set: Average loss: 1.9895, Accuracy: 1522/5000 (30%)\n",
      "[epoch 5] loss: 1.0931553\n",
      "Test set: Average loss: 2.0187, Accuracy: 1502/5000 (30%)\n",
      "[epoch 6] loss: 0.8674385\n",
      "Test set: Average loss: 2.2172, Accuracy: 1566/5000 (31%)\n",
      "[epoch 7] loss: 0.6653418\n",
      "Test set: Average loss: 2.3314, Accuracy: 1520/5000 (30%)\n",
      "[epoch 8] loss: 0.4873414\n",
      "Test set: Average loss: 2.4225, Accuracy: 1622/5000 (32%)\n",
      "[epoch 9] loss: 0.3924071\n",
      "Test set: Average loss: 2.6176, Accuracy: 1533/5000 (31%)\n",
      "[epoch 10] loss: 0.2459835\n",
      "Test set: Average loss: 2.7685, Accuracy: 1570/5000 (31%)\n",
      "[epoch 11] loss: 0.1602720\n",
      "Test set: Average loss: 2.9299, Accuracy: 1558/5000 (31%)\n",
      "[epoch 12] loss: 0.1026210\n",
      "Test set: Average loss: 3.1027, Accuracy: 1546/5000 (31%)\n",
      "[epoch 13] loss: 0.0678768\n",
      "Test set: Average loss: 3.2551, Accuracy: 1526/5000 (31%)\n",
      "[epoch 14] loss: 0.0400169\n",
      "Test set: Average loss: 3.3754, Accuracy: 1581/5000 (32%)\n",
      "[epoch 15] loss: 0.0286613\n",
      "Test set: Average loss: 3.5126, Accuracy: 1540/5000 (31%)\n",
      "[epoch 16] loss: 0.0195467\n",
      "Test set: Average loss: 3.5834, Accuracy: 1561/5000 (31%)\n",
      "[epoch 17] loss: 0.0144577\n",
      "Test set: Average loss: 3.6096, Accuracy: 1588/5000 (32%)\n",
      "[epoch 18] loss: 0.0110050\n",
      "Test set: Average loss: 3.6532, Accuracy: 1569/5000 (31%)\n",
      "[epoch 19] loss: 0.0093610\n",
      "Test set: Average loss: 3.7212, Accuracy: 1574/5000 (31%)\n",
      "[epoch 20] loss: 0.0079096\n",
      "Test set: Average loss: 3.7763, Accuracy: 1566/5000 (31%)\n",
      "[epoch 21] loss: 0.0068997\n",
      "Test set: Average loss: 3.7988, Accuracy: 1574/5000 (31%)\n",
      "[epoch 22] loss: 0.0061855\n",
      "Test set: Average loss: 3.8288, Accuracy: 1558/5000 (31%)\n",
      "[epoch 23] loss: 0.0055511\n",
      "Test set: Average loss: 3.8692, Accuracy: 1575/5000 (32%)\n",
      "[epoch 24] loss: 0.0051397\n",
      "Test set: Average loss: 3.9070, Accuracy: 1574/5000 (31%)\n",
      "[epoch 25] loss: 0.0047074\n",
      "Test set: Average loss: 3.9397, Accuracy: 1558/5000 (31%)\n",
      "[epoch 26] loss: 0.0043963\n",
      "Test set: Average loss: 3.9586, Accuracy: 1561/5000 (31%)\n",
      "[epoch 27] loss: 0.0040119\n",
      "Test set: Average loss: 3.9884, Accuracy: 1566/5000 (31%)\n",
      "[epoch 28] loss: 0.0037285\n",
      "Test set: Average loss: 4.0086, Accuracy: 1563/5000 (31%)\n",
      "[epoch 29] loss: 0.0034983\n",
      "Test set: Average loss: 4.0373, Accuracy: 1560/5000 (31%)\n",
      "[epoch 30] loss: 0.0032338\n",
      "Test set: Average loss: 4.0553, Accuracy: 1556/5000 (31%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0030468\n",
      "Test set: Average loss: 4.0759, Accuracy: 1564/5000 (31%)\n",
      "[epoch 32] loss: 0.0028666\n",
      "Test set: Average loss: 4.0983, Accuracy: 1559/5000 (31%)\n",
      "[epoch 33] loss: 0.0027137\n",
      "Test set: Average loss: 4.1219, Accuracy: 1560/5000 (31%)\n",
      "[epoch 34] loss: 0.0025546\n",
      "Test set: Average loss: 4.1344, Accuracy: 1564/5000 (31%)\n",
      "[epoch 35] loss: 0.0024468\n",
      "Test set: Average loss: 4.1563, Accuracy: 1560/5000 (31%)\n",
      "[epoch 36] loss: 0.0023086\n",
      "Test set: Average loss: 4.1786, Accuracy: 1551/5000 (31%)\n",
      "[epoch 37] loss: 0.0021914\n",
      "Test set: Average loss: 4.1952, Accuracy: 1554/5000 (31%)\n",
      "[epoch 38] loss: 0.0020728\n",
      "Test set: Average loss: 4.2076, Accuracy: 1558/5000 (31%)\n",
      "[epoch 39] loss: 0.0019807\n",
      "Test set: Average loss: 4.2211, Accuracy: 1553/5000 (31%)\n",
      "[epoch 40] loss: 0.0018929\n",
      "Test set: Average loss: 4.2406, Accuracy: 1548/5000 (31%)\n",
      "[epoch 41] loss: 0.0018123\n",
      "Test set: Average loss: 4.2574, Accuracy: 1551/5000 (31%)\n",
      "[epoch 42] loss: 0.0017294\n",
      "Test set: Average loss: 4.2760, Accuracy: 1542/5000 (31%)\n",
      "[epoch 43] loss: 0.0016582\n",
      "Test set: Average loss: 4.2882, Accuracy: 1539/5000 (31%)\n",
      "[epoch 44] loss: 0.0015877\n",
      "Test set: Average loss: 4.2992, Accuracy: 1546/5000 (31%)\n",
      "[epoch 45] loss: 0.0015286\n",
      "Test set: Average loss: 4.3105, Accuracy: 1540/5000 (31%)\n",
      "[epoch 46] loss: 0.0014566\n",
      "Test set: Average loss: 4.3282, Accuracy: 1545/5000 (31%)\n",
      "[epoch 47] loss: 0.0014006\n",
      "Test set: Average loss: 4.3432, Accuracy: 1548/5000 (31%)\n",
      "[epoch 48] loss: 0.0013466\n",
      "Test set: Average loss: 4.3569, Accuracy: 1541/5000 (31%)\n",
      "[epoch 49] loss: 0.0012970\n",
      "Test set: Average loss: 4.3733, Accuracy: 1537/5000 (31%)\n",
      "[epoch 50] loss: 0.0012528\n",
      "Test set: Average loss: 4.3815, Accuracy: 1541/5000 (31%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4225, Accuracy: 1622/5000 (32%)\n",
      "Test\n",
      "Test set: Average loss: 2.4210, Accuracy: 3236/10000 (32%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2961, Accuracy: 533/5000 (11%)\n",
      "[epoch 1] loss: 2.2640587\n",
      "Test set: Average loss: 2.1756, Accuracy: 1013/5000 (20%)\n",
      "[epoch 2] loss: 1.9721439\n",
      "Test set: Average loss: 2.0149, Accuracy: 1324/5000 (26%)\n",
      "[epoch 3] loss: 1.6662701\n",
      "Test set: Average loss: 2.0323, Accuracy: 1374/5000 (27%)\n",
      "[epoch 4] loss: 1.3478999\n",
      "Test set: Average loss: 2.0695, Accuracy: 1465/5000 (29%)\n",
      "[epoch 5] loss: 1.1214124\n",
      "Test set: Average loss: 2.1698, Accuracy: 1490/5000 (30%)\n",
      "[epoch 6] loss: 0.8079830\n",
      "Test set: Average loss: 2.3033, Accuracy: 1508/5000 (30%)\n",
      "[epoch 7] loss: 0.6169034\n",
      "Test set: Average loss: 2.4785, Accuracy: 1483/5000 (30%)\n",
      "[epoch 8] loss: 0.4179061\n",
      "Test set: Average loss: 2.7310, Accuracy: 1527/5000 (31%)\n",
      "[epoch 9] loss: 0.3078114\n",
      "Test set: Average loss: 3.1614, Accuracy: 1472/5000 (29%)\n",
      "[epoch 10] loss: 0.2370111\n",
      "Test set: Average loss: 3.1748, Accuracy: 1407/5000 (28%)\n",
      "[epoch 11] loss: 0.1508628\n",
      "Test set: Average loss: 3.2926, Accuracy: 1487/5000 (30%)\n",
      "[epoch 12] loss: 0.1034307\n",
      "Test set: Average loss: 3.5227, Accuracy: 1482/5000 (30%)\n",
      "[epoch 13] loss: 0.0809947\n",
      "Test set: Average loss: 3.6125, Accuracy: 1477/5000 (30%)\n",
      "[epoch 14] loss: 0.0408272\n",
      "Test set: Average loss: 3.7090, Accuracy: 1525/5000 (30%)\n",
      "[epoch 15] loss: 0.0323788\n",
      "Test set: Average loss: 3.8183, Accuracy: 1492/5000 (30%)\n",
      "[epoch 16] loss: 0.0185642\n",
      "Test set: Average loss: 3.9149, Accuracy: 1495/5000 (30%)\n",
      "[epoch 17] loss: 0.0120954\n",
      "Test set: Average loss: 4.0082, Accuracy: 1470/5000 (29%)\n",
      "[epoch 18] loss: 0.0095976\n",
      "Test set: Average loss: 4.0633, Accuracy: 1472/5000 (29%)\n",
      "[epoch 19] loss: 0.0071654\n",
      "Test set: Average loss: 4.0946, Accuracy: 1485/5000 (30%)\n",
      "[epoch 20] loss: 0.0062509\n",
      "Test set: Average loss: 4.1235, Accuracy: 1487/5000 (30%)\n",
      "[epoch 21] loss: 0.0052099\n",
      "Test set: Average loss: 4.1577, Accuracy: 1476/5000 (30%)\n",
      "[epoch 22] loss: 0.0046416\n",
      "Test set: Average loss: 4.1735, Accuracy: 1478/5000 (30%)\n",
      "[epoch 23] loss: 0.0042101\n",
      "Test set: Average loss: 4.2093, Accuracy: 1482/5000 (30%)\n",
      "[epoch 24] loss: 0.0038420\n",
      "Test set: Average loss: 4.2440, Accuracy: 1489/5000 (30%)\n",
      "[epoch 25] loss: 0.0035773\n",
      "Test set: Average loss: 4.2726, Accuracy: 1490/5000 (30%)\n",
      "[epoch 26] loss: 0.0033116\n",
      "Test set: Average loss: 4.2954, Accuracy: 1483/5000 (30%)\n",
      "[epoch 27] loss: 0.0030977\n",
      "Test set: Average loss: 4.3166, Accuracy: 1483/5000 (30%)\n",
      "[epoch 28] loss: 0.0028889\n",
      "Test set: Average loss: 4.3362, Accuracy: 1485/5000 (30%)\n",
      "[epoch 29] loss: 0.0027057\n",
      "Test set: Average loss: 4.3627, Accuracy: 1483/5000 (30%)\n",
      "[epoch 30] loss: 0.0025674\n",
      "Test set: Average loss: 4.3842, Accuracy: 1484/5000 (30%)\n",
      "[epoch 31] loss: 0.0024206\n",
      "Test set: Average loss: 4.4040, Accuracy: 1477/5000 (30%)\n",
      "[epoch 32] loss: 0.0022814\n",
      "Test set: Average loss: 4.4239, Accuracy: 1481/5000 (30%)\n",
      "[epoch 33] loss: 0.0021700\n",
      "Test set: Average loss: 4.4407, Accuracy: 1483/5000 (30%)\n",
      "[epoch 34] loss: 0.0020715\n",
      "Test set: Average loss: 4.4573, Accuracy: 1480/5000 (30%)\n",
      "[epoch 35] loss: 0.0019611\n",
      "Test set: Average loss: 4.4773, Accuracy: 1480/5000 (30%)\n",
      "[epoch 36] loss: 0.0018575\n",
      "Test set: Average loss: 4.4940, Accuracy: 1479/5000 (30%)\n",
      "[epoch 37] loss: 0.0017931\n",
      "Test set: Average loss: 4.5134, Accuracy: 1482/5000 (30%)\n",
      "[epoch 38] loss: 0.0017116\n",
      "Test set: Average loss: 4.5293, Accuracy: 1481/5000 (30%)\n",
      "[epoch 39] loss: 0.0016448\n",
      "Test set: Average loss: 4.5408, Accuracy: 1481/5000 (30%)\n",
      "[epoch 40] loss: 0.0015652\n",
      "Test set: Average loss: 4.5565, Accuracy: 1483/5000 (30%)\n",
      "[epoch 41] loss: 0.0015029\n",
      "Test set: Average loss: 4.5731, Accuracy: 1484/5000 (30%)\n",
      "[epoch 42] loss: 0.0014319\n",
      "Test set: Average loss: 4.5873, Accuracy: 1487/5000 (30%)\n",
      "[epoch 43] loss: 0.0013872\n",
      "Test set: Average loss: 4.6082, Accuracy: 1481/5000 (30%)\n",
      "[epoch 44] loss: 0.0013252\n",
      "Test set: Average loss: 4.6182, Accuracy: 1486/5000 (30%)\n",
      "[epoch 45] loss: 0.0012811\n",
      "Test set: Average loss: 4.6257, Accuracy: 1486/5000 (30%)\n",
      "[epoch 46] loss: 0.0012302\n",
      "Test set: Average loss: 4.6439, Accuracy: 1485/5000 (30%)\n",
      "[epoch 47] loss: 0.0011931\n",
      "Test set: Average loss: 4.6593, Accuracy: 1480/5000 (30%)\n",
      "[epoch 48] loss: 0.0011448\n",
      "Test set: Average loss: 4.6703, Accuracy: 1482/5000 (30%)\n",
      "[epoch 49] loss: 0.0011016\n",
      "Test set: Average loss: 4.6836, Accuracy: 1483/5000 (30%)\n",
      "[epoch 50] loss: 0.0010648\n",
      "Test set: Average loss: 4.6918, Accuracy: 1483/5000 (30%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7310, Accuracy: 1527/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.7308, Accuracy: 3044/10000 (30%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 475/5000 (10%)\n",
      "[epoch 1] loss: 2.1943808\n",
      "Test set: Average loss: 2.0395, Accuracy: 1270/5000 (25%)\n",
      "[epoch 2] loss: 1.8305064\n",
      "Test set: Average loss: 1.9367, Accuracy: 1466/5000 (29%)\n",
      "[epoch 3] loss: 1.5599023\n",
      "Test set: Average loss: 1.8944, Accuracy: 1654/5000 (33%)\n",
      "[epoch 4] loss: 1.4301700\n",
      "Test set: Average loss: 1.8016, Accuracy: 1805/5000 (36%)\n",
      "[epoch 5] loss: 1.1812722\n",
      "Test set: Average loss: 1.8995, Accuracy: 1767/5000 (35%)\n",
      "[epoch 6] loss: 0.9545499\n",
      "Test set: Average loss: 2.0979, Accuracy: 1621/5000 (32%)\n",
      "[epoch 7] loss: 0.8719030\n",
      "Test set: Average loss: 2.3033, Accuracy: 1634/5000 (33%)\n",
      "[epoch 8] loss: 0.6590419\n",
      "Test set: Average loss: 2.3115, Accuracy: 1693/5000 (34%)\n",
      "[epoch 9] loss: 0.4730019\n",
      "Test set: Average loss: 2.6053, Accuracy: 1718/5000 (34%)\n",
      "[epoch 10] loss: 0.3402192\n",
      "Test set: Average loss: 2.7956, Accuracy: 1609/5000 (32%)\n",
      "[epoch 11] loss: 0.2561768\n",
      "Test set: Average loss: 3.0891, Accuracy: 1629/5000 (33%)\n",
      "[epoch 12] loss: 0.1960567\n",
      "Test set: Average loss: 3.1079, Accuracy: 1675/5000 (34%)\n",
      "[epoch 13] loss: 0.1189798\n",
      "Test set: Average loss: 3.4152, Accuracy: 1655/5000 (33%)\n",
      "[epoch 14] loss: 0.0793149\n",
      "Test set: Average loss: 3.5646, Accuracy: 1612/5000 (32%)\n",
      "[epoch 15] loss: 0.0477492\n",
      "Test set: Average loss: 3.6667, Accuracy: 1667/5000 (33%)\n",
      "[epoch 16] loss: 0.0275191\n",
      "Test set: Average loss: 3.7697, Accuracy: 1712/5000 (34%)\n",
      "[epoch 17] loss: 0.0176057\n",
      "Test set: Average loss: 3.8524, Accuracy: 1663/5000 (33%)\n",
      "[epoch 18] loss: 0.0124861\n",
      "Test set: Average loss: 3.9164, Accuracy: 1710/5000 (34%)\n",
      "[epoch 19] loss: 0.0087815\n",
      "Test set: Average loss: 4.0099, Accuracy: 1690/5000 (34%)\n",
      "[epoch 20] loss: 0.0074828\n",
      "Test set: Average loss: 4.0417, Accuracy: 1710/5000 (34%)\n",
      "[epoch 21] loss: 0.0062553\n",
      "Test set: Average loss: 4.1011, Accuracy: 1697/5000 (34%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22] loss: 0.0054497\n",
      "Test set: Average loss: 4.1314, Accuracy: 1701/5000 (34%)\n",
      "[epoch 23] loss: 0.0049183\n",
      "Test set: Average loss: 4.1857, Accuracy: 1697/5000 (34%)\n",
      "[epoch 24] loss: 0.0043999\n",
      "Test set: Average loss: 4.2086, Accuracy: 1696/5000 (34%)\n",
      "[epoch 25] loss: 0.0040907\n",
      "Test set: Average loss: 4.2567, Accuracy: 1685/5000 (34%)\n",
      "[epoch 26] loss: 0.0037571\n",
      "Test set: Average loss: 4.2874, Accuracy: 1690/5000 (34%)\n",
      "[epoch 27] loss: 0.0034286\n",
      "Test set: Average loss: 4.3167, Accuracy: 1689/5000 (34%)\n",
      "[epoch 28] loss: 0.0031706\n",
      "Test set: Average loss: 4.3425, Accuracy: 1691/5000 (34%)\n",
      "[epoch 29] loss: 0.0029440\n",
      "Test set: Average loss: 4.3765, Accuracy: 1687/5000 (34%)\n",
      "[epoch 30] loss: 0.0027504\n",
      "Test set: Average loss: 4.4019, Accuracy: 1685/5000 (34%)\n",
      "[epoch 31] loss: 0.0025931\n",
      "Test set: Average loss: 4.4250, Accuracy: 1687/5000 (34%)\n",
      "[epoch 32] loss: 0.0024326\n",
      "Test set: Average loss: 4.4507, Accuracy: 1685/5000 (34%)\n",
      "[epoch 33] loss: 0.0022930\n",
      "Test set: Average loss: 4.4785, Accuracy: 1692/5000 (34%)\n",
      "[epoch 34] loss: 0.0021419\n",
      "Test set: Average loss: 4.5000, Accuracy: 1694/5000 (34%)\n",
      "[epoch 35] loss: 0.0020324\n",
      "Test set: Average loss: 4.5246, Accuracy: 1686/5000 (34%)\n",
      "[epoch 36] loss: 0.0019228\n",
      "Test set: Average loss: 4.5448, Accuracy: 1693/5000 (34%)\n",
      "[epoch 37] loss: 0.0018125\n",
      "Test set: Average loss: 4.5638, Accuracy: 1681/5000 (34%)\n",
      "[epoch 38] loss: 0.0017184\n",
      "Test set: Average loss: 4.5862, Accuracy: 1688/5000 (34%)\n",
      "[epoch 39] loss: 0.0016429\n",
      "Test set: Average loss: 4.6037, Accuracy: 1687/5000 (34%)\n",
      "[epoch 40] loss: 0.0015564\n",
      "Test set: Average loss: 4.6301, Accuracy: 1688/5000 (34%)\n",
      "[epoch 41] loss: 0.0014850\n",
      "Test set: Average loss: 4.6455, Accuracy: 1684/5000 (34%)\n",
      "[epoch 42] loss: 0.0014261\n",
      "Test set: Average loss: 4.6609, Accuracy: 1691/5000 (34%)\n",
      "[epoch 43] loss: 0.0013531\n",
      "Test set: Average loss: 4.6828, Accuracy: 1684/5000 (34%)\n",
      "[epoch 44] loss: 0.0013001\n",
      "Test set: Average loss: 4.7013, Accuracy: 1682/5000 (34%)\n",
      "[epoch 45] loss: 0.0012449\n",
      "Test set: Average loss: 4.7123, Accuracy: 1681/5000 (34%)\n",
      "[epoch 46] loss: 0.0011861\n",
      "Test set: Average loss: 4.7356, Accuracy: 1679/5000 (34%)\n",
      "[epoch 47] loss: 0.0011325\n",
      "Test set: Average loss: 4.7446, Accuracy: 1685/5000 (34%)\n",
      "[epoch 48] loss: 0.0010929\n",
      "Test set: Average loss: 4.7655, Accuracy: 1682/5000 (34%)\n",
      "[epoch 49] loss: 0.0010508\n",
      "Test set: Average loss: 4.7813, Accuracy: 1685/5000 (34%)\n",
      "[epoch 50] loss: 0.0010111\n",
      "Test set: Average loss: 4.7934, Accuracy: 1683/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8016, Accuracy: 1805/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.7689, Accuracy: 3613/10000 (36%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 484/5000 (10%)\n",
      "[epoch 1] loss: 2.1864921\n",
      "Test set: Average loss: 2.0222, Accuracy: 1362/5000 (27%)\n",
      "[epoch 2] loss: 1.8156085\n",
      "Test set: Average loss: 1.9189, Accuracy: 1446/5000 (29%)\n",
      "[epoch 3] loss: 1.5262044\n",
      "Test set: Average loss: 1.8743, Accuracy: 1643/5000 (33%)\n",
      "[epoch 4] loss: 1.3060446\n",
      "Test set: Average loss: 1.9714, Accuracy: 1551/5000 (31%)\n",
      "[epoch 5] loss: 1.2059558\n",
      "Test set: Average loss: 1.8932, Accuracy: 1784/5000 (36%)\n",
      "[epoch 6] loss: 0.9659210\n",
      "Test set: Average loss: 2.0112, Accuracy: 1754/5000 (35%)\n",
      "[epoch 7] loss: 0.8322535\n",
      "Test set: Average loss: 2.2139, Accuracy: 1689/5000 (34%)\n",
      "[epoch 8] loss: 0.7028351\n",
      "Test set: Average loss: 2.2943, Accuracy: 1715/5000 (34%)\n",
      "[epoch 9] loss: 0.5011615\n",
      "Test set: Average loss: 2.4045, Accuracy: 1735/5000 (35%)\n",
      "[epoch 10] loss: 0.3217951\n",
      "Test set: Average loss: 2.7258, Accuracy: 1602/5000 (32%)\n",
      "[epoch 11] loss: 0.2453531\n",
      "Test set: Average loss: 2.7720, Accuracy: 1642/5000 (33%)\n",
      "[epoch 12] loss: 0.1573387\n",
      "Test set: Average loss: 2.9155, Accuracy: 1656/5000 (33%)\n",
      "[epoch 13] loss: 0.1287347\n",
      "Test set: Average loss: 3.1648, Accuracy: 1645/5000 (33%)\n",
      "[epoch 14] loss: 0.1053982\n",
      "Test set: Average loss: 3.2250, Accuracy: 1618/5000 (32%)\n",
      "[epoch 15] loss: 0.0627554\n",
      "Test set: Average loss: 3.4533, Accuracy: 1633/5000 (33%)\n",
      "[epoch 16] loss: 0.0432290\n",
      "Test set: Average loss: 3.5417, Accuracy: 1613/5000 (32%)\n",
      "[epoch 17] loss: 0.0325075\n",
      "Test set: Average loss: 3.6987, Accuracy: 1624/5000 (32%)\n",
      "[epoch 18] loss: 0.0172876\n",
      "Test set: Average loss: 3.7835, Accuracy: 1617/5000 (32%)\n",
      "[epoch 19] loss: 0.0120093\n",
      "Test set: Average loss: 3.8141, Accuracy: 1643/5000 (33%)\n",
      "[epoch 20] loss: 0.0084719\n",
      "Test set: Average loss: 3.8976, Accuracy: 1617/5000 (32%)\n",
      "[epoch 21] loss: 0.0067734\n",
      "Test set: Average loss: 3.9295, Accuracy: 1627/5000 (33%)\n",
      "[epoch 22] loss: 0.0057544\n",
      "Test set: Average loss: 3.9855, Accuracy: 1623/5000 (32%)\n",
      "[epoch 23] loss: 0.0051223\n",
      "Test set: Average loss: 4.0288, Accuracy: 1625/5000 (32%)\n",
      "[epoch 24] loss: 0.0045328\n",
      "Test set: Average loss: 4.0648, Accuracy: 1614/5000 (32%)\n",
      "[epoch 25] loss: 0.0041422\n",
      "Test set: Average loss: 4.0986, Accuracy: 1619/5000 (32%)\n",
      "[epoch 26] loss: 0.0037562\n",
      "Test set: Average loss: 4.1354, Accuracy: 1620/5000 (32%)\n",
      "[epoch 27] loss: 0.0035353\n",
      "Test set: Average loss: 4.1654, Accuracy: 1610/5000 (32%)\n",
      "[epoch 28] loss: 0.0032405\n",
      "Test set: Average loss: 4.1934, Accuracy: 1618/5000 (32%)\n",
      "[epoch 29] loss: 0.0030157\n",
      "Test set: Average loss: 4.2284, Accuracy: 1610/5000 (32%)\n",
      "[epoch 30] loss: 0.0028148\n",
      "Test set: Average loss: 4.2492, Accuracy: 1612/5000 (32%)\n",
      "[epoch 31] loss: 0.0026045\n",
      "Test set: Average loss: 4.2802, Accuracy: 1617/5000 (32%)\n",
      "[epoch 32] loss: 0.0024088\n",
      "Test set: Average loss: 4.3007, Accuracy: 1611/5000 (32%)\n",
      "[epoch 33] loss: 0.0022799\n",
      "Test set: Average loss: 4.3238, Accuracy: 1610/5000 (32%)\n",
      "[epoch 34] loss: 0.0021716\n",
      "Test set: Average loss: 4.3483, Accuracy: 1618/5000 (32%)\n",
      "[epoch 35] loss: 0.0020352\n",
      "Test set: Average loss: 4.3698, Accuracy: 1617/5000 (32%)\n",
      "[epoch 36] loss: 0.0019228\n",
      "Test set: Average loss: 4.3923, Accuracy: 1613/5000 (32%)\n",
      "[epoch 37] loss: 0.0018245\n",
      "Test set: Average loss: 4.4157, Accuracy: 1614/5000 (32%)\n",
      "[epoch 38] loss: 0.0017440\n",
      "Test set: Average loss: 4.4311, Accuracy: 1617/5000 (32%)\n",
      "[epoch 39] loss: 0.0016470\n",
      "Test set: Average loss: 4.4576, Accuracy: 1616/5000 (32%)\n",
      "[epoch 40] loss: 0.0015690\n",
      "Test set: Average loss: 4.4734, Accuracy: 1618/5000 (32%)\n",
      "[epoch 41] loss: 0.0014752\n",
      "Test set: Average loss: 4.4895, Accuracy: 1609/5000 (32%)\n",
      "[epoch 42] loss: 0.0014384\n",
      "Test set: Average loss: 4.5155, Accuracy: 1605/5000 (32%)\n",
      "[epoch 43] loss: 0.0013524\n",
      "Test set: Average loss: 4.5250, Accuracy: 1619/5000 (32%)\n",
      "[epoch 44] loss: 0.0013188\n",
      "Test set: Average loss: 4.5428, Accuracy: 1622/5000 (32%)\n",
      "[epoch 45] loss: 0.0012451\n",
      "Test set: Average loss: 4.5651, Accuracy: 1608/5000 (32%)\n",
      "[epoch 46] loss: 0.0011826\n",
      "Test set: Average loss: 4.5803, Accuracy: 1621/5000 (32%)\n",
      "[epoch 47] loss: 0.0011450\n",
      "Test set: Average loss: 4.5958, Accuracy: 1618/5000 (32%)\n",
      "[epoch 48] loss: 0.0011047\n",
      "Test set: Average loss: 4.6119, Accuracy: 1616/5000 (32%)\n",
      "[epoch 49] loss: 0.0010446\n",
      "Test set: Average loss: 4.6271, Accuracy: 1613/5000 (32%)\n",
      "[epoch 50] loss: 0.0010151\n",
      "Test set: Average loss: 4.6405, Accuracy: 1615/5000 (32%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8932, Accuracy: 1784/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.8611, Accuracy: 3549/10000 (35%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 462/5000 (9%)\n",
      "[epoch 1] loss: 2.2334926\n",
      "Test set: Average loss: 2.0872, Accuracy: 1267/5000 (25%)\n",
      "[epoch 2] loss: 1.9306687\n",
      "Test set: Average loss: 1.9634, Accuracy: 1410/5000 (28%)\n",
      "[epoch 3] loss: 1.7094750\n",
      "Test set: Average loss: 1.8843, Accuracy: 1661/5000 (33%)\n",
      "[epoch 4] loss: 1.4798973\n",
      "Test set: Average loss: 1.8796, Accuracy: 1711/5000 (34%)\n",
      "[epoch 5] loss: 1.2205746\n",
      "Test set: Average loss: 1.9190, Accuracy: 1769/5000 (35%)\n",
      "[epoch 6] loss: 0.9942026\n",
      "Test set: Average loss: 2.0348, Accuracy: 1788/5000 (36%)\n",
      "[epoch 7] loss: 0.7760822\n",
      "Test set: Average loss: 2.3507, Accuracy: 1698/5000 (34%)\n",
      "[epoch 8] loss: 0.6549162\n",
      "Test set: Average loss: 2.3730, Accuracy: 1697/5000 (34%)\n",
      "[epoch 9] loss: 0.4851052\n",
      "Test set: Average loss: 2.3994, Accuracy: 1871/5000 (37%)\n",
      "[epoch 10] loss: 0.3520366\n",
      "Test set: Average loss: 2.7825, Accuracy: 1689/5000 (34%)\n",
      "[epoch 11] loss: 0.2287503\n",
      "Test set: Average loss: 2.9803, Accuracy: 1781/5000 (36%)\n",
      "[epoch 12] loss: 0.1819291\n",
      "Test set: Average loss: 3.2116, Accuracy: 1690/5000 (34%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] loss: 0.1566315\n",
      "Test set: Average loss: 3.3324, Accuracy: 1660/5000 (33%)\n",
      "[epoch 14] loss: 0.0927795\n",
      "Test set: Average loss: 3.4029, Accuracy: 1739/5000 (35%)\n",
      "[epoch 15] loss: 0.0644883\n",
      "Test set: Average loss: 3.7022, Accuracy: 1671/5000 (33%)\n",
      "[epoch 16] loss: 0.0391438\n",
      "Test set: Average loss: 3.8290, Accuracy: 1702/5000 (34%)\n",
      "[epoch 17] loss: 0.0244912\n",
      "Test set: Average loss: 3.8177, Accuracy: 1739/5000 (35%)\n",
      "[epoch 18] loss: 0.0151069\n",
      "Test set: Average loss: 3.9172, Accuracy: 1737/5000 (35%)\n",
      "[epoch 19] loss: 0.0091509\n",
      "Test set: Average loss: 3.9669, Accuracy: 1757/5000 (35%)\n",
      "[epoch 20] loss: 0.0069617\n",
      "Test set: Average loss: 4.0305, Accuracy: 1744/5000 (35%)\n",
      "[epoch 21] loss: 0.0059597\n",
      "Test set: Average loss: 4.0794, Accuracy: 1746/5000 (35%)\n",
      "[epoch 22] loss: 0.0050751\n",
      "Test set: Average loss: 4.1174, Accuracy: 1753/5000 (35%)\n",
      "[epoch 23] loss: 0.0045038\n",
      "Test set: Average loss: 4.1631, Accuracy: 1752/5000 (35%)\n",
      "[epoch 24] loss: 0.0040954\n",
      "Test set: Average loss: 4.1914, Accuracy: 1749/5000 (35%)\n",
      "[epoch 25] loss: 0.0037877\n",
      "Test set: Average loss: 4.2221, Accuracy: 1751/5000 (35%)\n",
      "[epoch 26] loss: 0.0033928\n",
      "Test set: Average loss: 4.2676, Accuracy: 1746/5000 (35%)\n",
      "[epoch 27] loss: 0.0032115\n",
      "Test set: Average loss: 4.2868, Accuracy: 1747/5000 (35%)\n",
      "[epoch 28] loss: 0.0029380\n",
      "Test set: Average loss: 4.3142, Accuracy: 1748/5000 (35%)\n",
      "[epoch 29] loss: 0.0027789\n",
      "Test set: Average loss: 4.3414, Accuracy: 1742/5000 (35%)\n",
      "[epoch 30] loss: 0.0025452\n",
      "Test set: Average loss: 4.3695, Accuracy: 1753/5000 (35%)\n",
      "[epoch 31] loss: 0.0023949\n",
      "Test set: Average loss: 4.3926, Accuracy: 1744/5000 (35%)\n",
      "[epoch 32] loss: 0.0022400\n",
      "Test set: Average loss: 4.4160, Accuracy: 1746/5000 (35%)\n",
      "[epoch 33] loss: 0.0021060\n",
      "Test set: Average loss: 4.4380, Accuracy: 1752/5000 (35%)\n",
      "[epoch 34] loss: 0.0019877\n",
      "Test set: Average loss: 4.4620, Accuracy: 1749/5000 (35%)\n",
      "[epoch 35] loss: 0.0018926\n",
      "Test set: Average loss: 4.4801, Accuracy: 1748/5000 (35%)\n",
      "[epoch 36] loss: 0.0017801\n",
      "Test set: Average loss: 4.4981, Accuracy: 1754/5000 (35%)\n",
      "[epoch 37] loss: 0.0017025\n",
      "Test set: Average loss: 4.5213, Accuracy: 1749/5000 (35%)\n",
      "[epoch 38] loss: 0.0016223\n",
      "Test set: Average loss: 4.5427, Accuracy: 1742/5000 (35%)\n",
      "[epoch 39] loss: 0.0015353\n",
      "Test set: Average loss: 4.5615, Accuracy: 1743/5000 (35%)\n",
      "[epoch 40] loss: 0.0014732\n",
      "Test set: Average loss: 4.5795, Accuracy: 1750/5000 (35%)\n",
      "[epoch 41] loss: 0.0013964\n",
      "Test set: Average loss: 4.5930, Accuracy: 1748/5000 (35%)\n",
      "[epoch 42] loss: 0.0013375\n",
      "Test set: Average loss: 4.6136, Accuracy: 1751/5000 (35%)\n",
      "[epoch 43] loss: 0.0012805\n",
      "Test set: Average loss: 4.6336, Accuracy: 1747/5000 (35%)\n",
      "[epoch 44] loss: 0.0012264\n",
      "Test set: Average loss: 4.6475, Accuracy: 1749/5000 (35%)\n",
      "[epoch 45] loss: 0.0011764\n",
      "Test set: Average loss: 4.6591, Accuracy: 1750/5000 (35%)\n",
      "[epoch 46] loss: 0.0011305\n",
      "Test set: Average loss: 4.6834, Accuracy: 1749/5000 (35%)\n",
      "[epoch 47] loss: 0.0010893\n",
      "Test set: Average loss: 4.6983, Accuracy: 1743/5000 (35%)\n",
      "[epoch 48] loss: 0.0010450\n",
      "Test set: Average loss: 4.7083, Accuracy: 1753/5000 (35%)\n",
      "[epoch 49] loss: 0.0010032\n",
      "Test set: Average loss: 4.7224, Accuracy: 1746/5000 (35%)\n",
      "[epoch 50] loss: 0.0009669\n",
      "Test set: Average loss: 4.7379, Accuracy: 1746/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3994, Accuracy: 1871/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 2.3551, Accuracy: 3649/10000 (36%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 444/5000 (9%)\n",
      "[epoch 1] loss: 2.1515337\n",
      "Test set: Average loss: 2.0186, Accuracy: 1222/5000 (24%)\n",
      "[epoch 2] loss: 1.8084723\n",
      "Test set: Average loss: 1.8952, Accuracy: 1450/5000 (29%)\n",
      "[epoch 3] loss: 1.5783522\n",
      "Test set: Average loss: 1.7842, Accuracy: 1769/5000 (35%)\n",
      "[epoch 4] loss: 1.3944805\n",
      "Test set: Average loss: 1.8154, Accuracy: 1793/5000 (36%)\n",
      "[epoch 5] loss: 1.1397695\n",
      "Test set: Average loss: 1.9321, Accuracy: 1765/5000 (35%)\n",
      "[epoch 6] loss: 0.9089297\n",
      "Test set: Average loss: 2.0396, Accuracy: 1914/5000 (38%)\n",
      "[epoch 7] loss: 0.6898621\n",
      "Test set: Average loss: 2.2562, Accuracy: 1836/5000 (37%)\n",
      "[epoch 8] loss: 0.5423455\n",
      "Test set: Average loss: 2.4234, Accuracy: 1839/5000 (37%)\n",
      "[epoch 9] loss: 0.4060298\n",
      "Test set: Average loss: 2.7146, Accuracy: 1863/5000 (37%)\n",
      "[epoch 10] loss: 0.2887650\n",
      "Test set: Average loss: 3.0079, Accuracy: 1802/5000 (36%)\n",
      "[epoch 11] loss: 0.2063433\n",
      "Test set: Average loss: 3.2141, Accuracy: 1763/5000 (35%)\n",
      "[epoch 12] loss: 0.1748426\n",
      "Test set: Average loss: 3.4062, Accuracy: 1795/5000 (36%)\n",
      "[epoch 13] loss: 0.1173242\n",
      "Test set: Average loss: 3.6048, Accuracy: 1785/5000 (36%)\n",
      "[epoch 14] loss: 0.0998140\n",
      "Test set: Average loss: 3.6905, Accuracy: 1793/5000 (36%)\n",
      "[epoch 15] loss: 0.0522146\n",
      "Test set: Average loss: 3.8969, Accuracy: 1799/5000 (36%)\n",
      "[epoch 16] loss: 0.0264954\n",
      "Test set: Average loss: 3.9794, Accuracy: 1786/5000 (36%)\n",
      "[epoch 17] loss: 0.0144276\n",
      "Test set: Average loss: 3.9652, Accuracy: 1839/5000 (37%)\n",
      "[epoch 18] loss: 0.0082587\n",
      "Test set: Average loss: 4.0660, Accuracy: 1812/5000 (36%)\n",
      "[epoch 19] loss: 0.0065411\n",
      "Test set: Average loss: 4.1225, Accuracy: 1848/5000 (37%)\n",
      "[epoch 20] loss: 0.0054448\n",
      "Test set: Average loss: 4.1718, Accuracy: 1844/5000 (37%)\n",
      "[epoch 21] loss: 0.0044889\n",
      "Test set: Average loss: 4.2277, Accuracy: 1854/5000 (37%)\n",
      "[epoch 22] loss: 0.0040145\n",
      "Test set: Average loss: 4.2617, Accuracy: 1854/5000 (37%)\n",
      "[epoch 23] loss: 0.0035610\n",
      "Test set: Average loss: 4.3059, Accuracy: 1850/5000 (37%)\n",
      "[epoch 24] loss: 0.0031868\n",
      "Test set: Average loss: 4.3442, Accuracy: 1865/5000 (37%)\n",
      "[epoch 25] loss: 0.0028951\n",
      "Test set: Average loss: 4.3732, Accuracy: 1854/5000 (37%)\n",
      "[epoch 26] loss: 0.0026733\n",
      "Test set: Average loss: 4.4138, Accuracy: 1853/5000 (37%)\n",
      "[epoch 27] loss: 0.0025287\n",
      "Test set: Average loss: 4.4413, Accuracy: 1854/5000 (37%)\n",
      "[epoch 28] loss: 0.0022751\n",
      "Test set: Average loss: 4.4721, Accuracy: 1858/5000 (37%)\n",
      "[epoch 29] loss: 0.0021691\n",
      "Test set: Average loss: 4.5015, Accuracy: 1853/5000 (37%)\n",
      "[epoch 30] loss: 0.0019913\n",
      "Test set: Average loss: 4.5245, Accuracy: 1853/5000 (37%)\n",
      "[epoch 31] loss: 0.0018626\n",
      "Test set: Average loss: 4.5524, Accuracy: 1847/5000 (37%)\n",
      "[epoch 32] loss: 0.0017608\n",
      "Test set: Average loss: 4.5767, Accuracy: 1854/5000 (37%)\n",
      "[epoch 33] loss: 0.0016497\n",
      "Test set: Average loss: 4.6012, Accuracy: 1857/5000 (37%)\n",
      "[epoch 34] loss: 0.0015435\n",
      "Test set: Average loss: 4.6253, Accuracy: 1853/5000 (37%)\n",
      "[epoch 35] loss: 0.0014606\n",
      "Test set: Average loss: 4.6449, Accuracy: 1855/5000 (37%)\n",
      "[epoch 36] loss: 0.0013714\n",
      "Test set: Average loss: 4.6727, Accuracy: 1848/5000 (37%)\n",
      "[epoch 37] loss: 0.0013053\n",
      "Test set: Average loss: 4.6889, Accuracy: 1848/5000 (37%)\n",
      "[epoch 38] loss: 0.0012291\n",
      "Test set: Average loss: 4.7089, Accuracy: 1851/5000 (37%)\n",
      "[epoch 39] loss: 0.0011632\n",
      "Test set: Average loss: 4.7284, Accuracy: 1848/5000 (37%)\n",
      "[epoch 40] loss: 0.0011248\n",
      "Test set: Average loss: 4.7498, Accuracy: 1850/5000 (37%)\n",
      "[epoch 41] loss: 0.0010633\n",
      "Test set: Average loss: 4.7696, Accuracy: 1851/5000 (37%)\n",
      "[epoch 42] loss: 0.0010232\n",
      "Test set: Average loss: 4.7863, Accuracy: 1850/5000 (37%)\n",
      "[epoch 43] loss: 0.0009853\n",
      "Test set: Average loss: 4.8031, Accuracy: 1853/5000 (37%)\n",
      "[epoch 44] loss: 0.0009407\n",
      "Test set: Average loss: 4.8211, Accuracy: 1849/5000 (37%)\n",
      "[epoch 45] loss: 0.0008946\n",
      "Test set: Average loss: 4.8395, Accuracy: 1850/5000 (37%)\n",
      "[epoch 46] loss: 0.0008687\n",
      "Test set: Average loss: 4.8572, Accuracy: 1838/5000 (37%)\n",
      "[epoch 47] loss: 0.0008213\n",
      "Test set: Average loss: 4.8738, Accuracy: 1842/5000 (37%)\n",
      "[epoch 48] loss: 0.0007881\n",
      "Test set: Average loss: 4.8912, Accuracy: 1843/5000 (37%)\n",
      "[epoch 49] loss: 0.0007589\n",
      "Test set: Average loss: 4.9052, Accuracy: 1840/5000 (37%)\n",
      "[epoch 50] loss: 0.0007322\n",
      "Test set: Average loss: 4.9217, Accuracy: 1840/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0396, Accuracy: 1914/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 1.9996, Accuracy: 3901/10000 (39%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3078, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 2.1409294\n",
      "Test set: Average loss: 2.0049, Accuracy: 1280/5000 (26%)\n",
      "[epoch 2] loss: 1.7310775\n",
      "Test set: Average loss: 1.8500, Accuracy: 1641/5000 (33%)\n",
      "[epoch 3] loss: 1.4823096\n",
      "Test set: Average loss: 1.8883, Accuracy: 1708/5000 (34%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 1.2302463\n",
      "Test set: Average loss: 1.9840, Accuracy: 1680/5000 (34%)\n",
      "[epoch 5] loss: 1.0275507\n",
      "Test set: Average loss: 1.9978, Accuracy: 1855/5000 (37%)\n",
      "[epoch 6] loss: 0.7870050\n",
      "Test set: Average loss: 2.2506, Accuracy: 1738/5000 (35%)\n",
      "[epoch 7] loss: 0.6746248\n",
      "Test set: Average loss: 2.2507, Accuracy: 1918/5000 (38%)\n",
      "[epoch 8] loss: 0.4878711\n",
      "Test set: Average loss: 2.4134, Accuracy: 1911/5000 (38%)\n",
      "[epoch 9] loss: 0.3405696\n",
      "Test set: Average loss: 2.6650, Accuracy: 1854/5000 (37%)\n",
      "[epoch 10] loss: 0.2543207\n",
      "Test set: Average loss: 2.8086, Accuracy: 1905/5000 (38%)\n",
      "[epoch 11] loss: 0.2181538\n",
      "Test set: Average loss: 3.1976, Accuracy: 1792/5000 (36%)\n",
      "[epoch 12] loss: 0.1560949\n",
      "Test set: Average loss: 3.4043, Accuracy: 1876/5000 (38%)\n",
      "[epoch 13] loss: 0.1368562\n",
      "Test set: Average loss: 3.4591, Accuracy: 1866/5000 (37%)\n",
      "[epoch 14] loss: 0.0684452\n",
      "Test set: Average loss: 3.5498, Accuracy: 1888/5000 (38%)\n",
      "[epoch 15] loss: 0.0324701\n",
      "Test set: Average loss: 3.6999, Accuracy: 1856/5000 (37%)\n",
      "[epoch 16] loss: 0.0205947\n",
      "Test set: Average loss: 3.8118, Accuracy: 1852/5000 (37%)\n",
      "[epoch 17] loss: 0.0137778\n",
      "Test set: Average loss: 3.9103, Accuracy: 1855/5000 (37%)\n",
      "[epoch 18] loss: 0.0091917\n",
      "Test set: Average loss: 3.9649, Accuracy: 1854/5000 (37%)\n",
      "[epoch 19] loss: 0.0070102\n",
      "Test set: Average loss: 4.0180, Accuracy: 1858/5000 (37%)\n",
      "[epoch 20] loss: 0.0058190\n",
      "Test set: Average loss: 4.0832, Accuracy: 1862/5000 (37%)\n",
      "[epoch 21] loss: 0.0052586\n",
      "Test set: Average loss: 4.1244, Accuracy: 1857/5000 (37%)\n",
      "[epoch 22] loss: 0.0045181\n",
      "Test set: Average loss: 4.1654, Accuracy: 1854/5000 (37%)\n",
      "[epoch 23] loss: 0.0041678\n",
      "Test set: Average loss: 4.2058, Accuracy: 1865/5000 (37%)\n",
      "[epoch 24] loss: 0.0036843\n",
      "Test set: Average loss: 4.2423, Accuracy: 1863/5000 (37%)\n",
      "[epoch 25] loss: 0.0033475\n",
      "Test set: Average loss: 4.2829, Accuracy: 1857/5000 (37%)\n",
      "[epoch 26] loss: 0.0030886\n",
      "Test set: Average loss: 4.3142, Accuracy: 1865/5000 (37%)\n",
      "[epoch 27] loss: 0.0028300\n",
      "Test set: Average loss: 4.3416, Accuracy: 1857/5000 (37%)\n",
      "[epoch 28] loss: 0.0026126\n",
      "Test set: Average loss: 4.3782, Accuracy: 1869/5000 (37%)\n",
      "[epoch 29] loss: 0.0024348\n",
      "Test set: Average loss: 4.4060, Accuracy: 1862/5000 (37%)\n",
      "[epoch 30] loss: 0.0022377\n",
      "Test set: Average loss: 4.4331, Accuracy: 1861/5000 (37%)\n",
      "[epoch 31] loss: 0.0021110\n",
      "Test set: Average loss: 4.4595, Accuracy: 1862/5000 (37%)\n",
      "[epoch 32] loss: 0.0019582\n",
      "Test set: Average loss: 4.4845, Accuracy: 1865/5000 (37%)\n",
      "[epoch 33] loss: 0.0018254\n",
      "Test set: Average loss: 4.5086, Accuracy: 1863/5000 (37%)\n",
      "[epoch 34] loss: 0.0017313\n",
      "Test set: Average loss: 4.5332, Accuracy: 1857/5000 (37%)\n",
      "[epoch 35] loss: 0.0016054\n",
      "Test set: Average loss: 4.5580, Accuracy: 1855/5000 (37%)\n",
      "[epoch 36] loss: 0.0015103\n",
      "Test set: Average loss: 4.5785, Accuracy: 1863/5000 (37%)\n",
      "[epoch 37] loss: 0.0014402\n",
      "Test set: Average loss: 4.6019, Accuracy: 1852/5000 (37%)\n",
      "[epoch 38] loss: 0.0013710\n",
      "Test set: Average loss: 4.6229, Accuracy: 1863/5000 (37%)\n",
      "[epoch 39] loss: 0.0012957\n",
      "Test set: Average loss: 4.6441, Accuracy: 1861/5000 (37%)\n",
      "[epoch 40] loss: 0.0012250\n",
      "Test set: Average loss: 4.6629, Accuracy: 1855/5000 (37%)\n",
      "[epoch 41] loss: 0.0011665\n",
      "Test set: Average loss: 4.6849, Accuracy: 1854/5000 (37%)\n",
      "[epoch 42] loss: 0.0011134\n",
      "Test set: Average loss: 4.7022, Accuracy: 1858/5000 (37%)\n",
      "[epoch 43] loss: 0.0010639\n",
      "Test set: Average loss: 4.7214, Accuracy: 1854/5000 (37%)\n",
      "[epoch 44] loss: 0.0010130\n",
      "Test set: Average loss: 4.7400, Accuracy: 1854/5000 (37%)\n",
      "[epoch 45] loss: 0.0009699\n",
      "Test set: Average loss: 4.7573, Accuracy: 1852/5000 (37%)\n",
      "[epoch 46] loss: 0.0009399\n",
      "Test set: Average loss: 4.7744, Accuracy: 1858/5000 (37%)\n",
      "[epoch 47] loss: 0.0009132\n",
      "Test set: Average loss: 4.7920, Accuracy: 1847/5000 (37%)\n",
      "[epoch 48] loss: 0.0008721\n",
      "Test set: Average loss: 4.8111, Accuracy: 1853/5000 (37%)\n",
      "[epoch 49] loss: 0.0008268\n",
      "Test set: Average loss: 4.8275, Accuracy: 1852/5000 (37%)\n",
      "[epoch 50] loss: 0.0007774\n",
      "Test set: Average loss: 4.8432, Accuracy: 1850/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2507, Accuracy: 1918/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 2.1995, Accuracy: 3927/10000 (39%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 444/5000 (9%)\n",
      "[epoch 1] loss: 2.2106510\n",
      "Test set: Average loss: 2.0528, Accuracy: 1199/5000 (24%)\n",
      "[epoch 2] loss: 1.8803770\n",
      "Test set: Average loss: 1.8963, Accuracy: 1574/5000 (31%)\n",
      "[epoch 3] loss: 1.6123326\n",
      "Test set: Average loss: 1.8039, Accuracy: 1752/5000 (35%)\n",
      "[epoch 4] loss: 1.3807525\n",
      "Test set: Average loss: 1.8817, Accuracy: 1759/5000 (35%)\n",
      "[epoch 5] loss: 1.1467137\n",
      "Test set: Average loss: 1.9175, Accuracy: 1793/5000 (36%)\n",
      "[epoch 6] loss: 0.9761419\n",
      "Test set: Average loss: 2.0882, Accuracy: 1674/5000 (33%)\n",
      "[epoch 7] loss: 0.7328951\n",
      "Test set: Average loss: 2.2739, Accuracy: 1781/5000 (36%)\n",
      "[epoch 8] loss: 0.6101731\n",
      "Test set: Average loss: 2.6241, Accuracy: 1652/5000 (33%)\n",
      "[epoch 9] loss: 0.4501545\n",
      "Test set: Average loss: 2.7421, Accuracy: 1730/5000 (35%)\n",
      "[epoch 10] loss: 0.2776476\n",
      "Test set: Average loss: 3.0065, Accuracy: 1723/5000 (34%)\n",
      "[epoch 11] loss: 0.1559377\n",
      "Test set: Average loss: 3.2835, Accuracy: 1720/5000 (34%)\n",
      "[epoch 12] loss: 0.0947263\n",
      "Test set: Average loss: 3.5899, Accuracy: 1685/5000 (34%)\n",
      "[epoch 13] loss: 0.0660258\n",
      "Test set: Average loss: 3.7159, Accuracy: 1714/5000 (34%)\n",
      "[epoch 14] loss: 0.0470253\n",
      "Test set: Average loss: 3.8633, Accuracy: 1698/5000 (34%)\n",
      "[epoch 15] loss: 0.0310714\n",
      "Test set: Average loss: 4.0295, Accuracy: 1673/5000 (33%)\n",
      "[epoch 16] loss: 0.0220991\n",
      "Test set: Average loss: 4.1543, Accuracy: 1710/5000 (34%)\n",
      "[epoch 17] loss: 0.0132840\n",
      "Test set: Average loss: 4.2253, Accuracy: 1702/5000 (34%)\n",
      "[epoch 18] loss: 0.0085000\n",
      "Test set: Average loss: 4.2972, Accuracy: 1708/5000 (34%)\n",
      "[epoch 19] loss: 0.0066462\n",
      "Test set: Average loss: 4.3553, Accuracy: 1719/5000 (34%)\n",
      "[epoch 20] loss: 0.0054185\n",
      "Test set: Average loss: 4.4277, Accuracy: 1711/5000 (34%)\n",
      "[epoch 21] loss: 0.0046418\n",
      "Test set: Average loss: 4.4720, Accuracy: 1717/5000 (34%)\n",
      "[epoch 22] loss: 0.0041111\n",
      "Test set: Average loss: 4.5155, Accuracy: 1716/5000 (34%)\n",
      "[epoch 23] loss: 0.0035957\n",
      "Test set: Average loss: 4.5594, Accuracy: 1717/5000 (34%)\n",
      "[epoch 24] loss: 0.0032802\n",
      "Test set: Average loss: 4.6026, Accuracy: 1716/5000 (34%)\n",
      "[epoch 25] loss: 0.0029210\n",
      "Test set: Average loss: 4.6388, Accuracy: 1716/5000 (34%)\n",
      "[epoch 26] loss: 0.0027133\n",
      "Test set: Average loss: 4.6691, Accuracy: 1715/5000 (34%)\n",
      "[epoch 27] loss: 0.0025167\n",
      "Test set: Average loss: 4.7091, Accuracy: 1715/5000 (34%)\n",
      "[epoch 28] loss: 0.0023221\n",
      "Test set: Average loss: 4.7399, Accuracy: 1723/5000 (34%)\n",
      "[epoch 29] loss: 0.0021636\n",
      "Test set: Average loss: 4.7674, Accuracy: 1724/5000 (34%)\n",
      "[epoch 30] loss: 0.0019939\n",
      "Test set: Average loss: 4.7985, Accuracy: 1720/5000 (34%)\n",
      "[epoch 31] loss: 0.0018599\n",
      "Test set: Average loss: 4.8262, Accuracy: 1715/5000 (34%)\n",
      "[epoch 32] loss: 0.0017524\n",
      "Test set: Average loss: 4.8517, Accuracy: 1722/5000 (34%)\n",
      "[epoch 33] loss: 0.0016402\n",
      "Test set: Average loss: 4.8805, Accuracy: 1719/5000 (34%)\n",
      "[epoch 34] loss: 0.0015427\n",
      "Test set: Average loss: 4.9012, Accuracy: 1720/5000 (34%)\n",
      "[epoch 35] loss: 0.0014476\n",
      "Test set: Average loss: 4.9275, Accuracy: 1722/5000 (34%)\n",
      "[epoch 36] loss: 0.0014024\n",
      "Test set: Average loss: 4.9489, Accuracy: 1721/5000 (34%)\n",
      "[epoch 37] loss: 0.0012844\n",
      "Test set: Average loss: 4.9755, Accuracy: 1724/5000 (34%)\n",
      "[epoch 38] loss: 0.0012422\n",
      "Test set: Average loss: 4.9976, Accuracy: 1715/5000 (34%)\n",
      "[epoch 39] loss: 0.0011541\n",
      "Test set: Average loss: 5.0204, Accuracy: 1715/5000 (34%)\n",
      "[epoch 40] loss: 0.0011097\n",
      "Test set: Average loss: 5.0403, Accuracy: 1719/5000 (34%)\n",
      "[epoch 41] loss: 0.0010428\n",
      "Test set: Average loss: 5.0613, Accuracy: 1711/5000 (34%)\n",
      "[epoch 42] loss: 0.0010120\n",
      "Test set: Average loss: 5.0790, Accuracy: 1720/5000 (34%)\n",
      "[epoch 43] loss: 0.0009490\n",
      "Test set: Average loss: 5.1000, Accuracy: 1722/5000 (34%)\n",
      "[epoch 44] loss: 0.0009224\n",
      "Test set: Average loss: 5.1159, Accuracy: 1712/5000 (34%)\n",
      "[epoch 45] loss: 0.0008679\n",
      "Test set: Average loss: 5.1369, Accuracy: 1721/5000 (34%)\n",
      "[epoch 46] loss: 0.0008390\n",
      "Test set: Average loss: 5.1566, Accuracy: 1715/5000 (34%)\n",
      "[epoch 47] loss: 0.0008049\n",
      "Test set: Average loss: 5.1753, Accuracy: 1713/5000 (34%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 48] loss: 0.0007659\n",
      "Test set: Average loss: 5.1921, Accuracy: 1714/5000 (34%)\n",
      "[epoch 49] loss: 0.0007331\n",
      "Test set: Average loss: 5.2082, Accuracy: 1716/5000 (34%)\n",
      "[epoch 50] loss: 0.0007095\n",
      "Test set: Average loss: 5.2279, Accuracy: 1715/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9175, Accuracy: 1793/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.9040, Accuracy: 3690/10000 (37%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3047, Accuracy: 536/5000 (11%)\n",
      "[epoch 1] loss: 2.1509524\n",
      "Test set: Average loss: 1.9068, Accuracy: 1469/5000 (29%)\n",
      "[epoch 2] loss: 1.7460171\n",
      "Test set: Average loss: 1.9435, Accuracy: 1582/5000 (32%)\n",
      "[epoch 3] loss: 1.5340505\n",
      "Test set: Average loss: 1.8204, Accuracy: 1838/5000 (37%)\n",
      "[epoch 4] loss: 1.3793775\n",
      "Test set: Average loss: 1.8877, Accuracy: 1756/5000 (35%)\n",
      "[epoch 5] loss: 1.1582444\n",
      "Test set: Average loss: 1.8949, Accuracy: 1859/5000 (37%)\n",
      "[epoch 6] loss: 0.9427042\n",
      "Test set: Average loss: 1.9923, Accuracy: 1869/5000 (37%)\n",
      "[epoch 7] loss: 0.7964069\n",
      "Test set: Average loss: 2.2608, Accuracy: 1827/5000 (37%)\n",
      "[epoch 8] loss: 0.6716300\n",
      "Test set: Average loss: 2.5764, Accuracy: 1807/5000 (36%)\n",
      "[epoch 9] loss: 0.5565020\n",
      "Test set: Average loss: 2.7361, Accuracy: 1838/5000 (37%)\n",
      "[epoch 10] loss: 0.3884450\n",
      "Test set: Average loss: 2.8752, Accuracy: 1790/5000 (36%)\n",
      "[epoch 11] loss: 0.4154667\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.2393, Accuracy: 1810/5000 (36%)\n",
      "[epoch 12] loss: 0.1719990\n",
      "Test set: Average loss: 3.1298, Accuracy: 1824/5000 (36%)\n",
      "[epoch 13] loss: 0.1320479\n",
      "Test set: Average loss: 3.1476, Accuracy: 1839/5000 (37%)\n",
      "[epoch 14] loss: 0.1122539\n",
      "Test set: Average loss: 3.1907, Accuracy: 1848/5000 (37%)\n",
      "[epoch 15] loss: 0.1010601\n",
      "Test set: Average loss: 3.2152, Accuracy: 1840/5000 (37%)\n",
      "[epoch 16] loss: 0.0976124\n",
      "Test set: Average loss: 3.2531, Accuracy: 1849/5000 (37%)\n",
      "[epoch 17] loss: 0.0856436\n",
      "Test set: Average loss: 3.2824, Accuracy: 1835/5000 (37%)\n",
      "[epoch 18] loss: 0.0776711\n",
      "Test set: Average loss: 3.3197, Accuracy: 1824/5000 (36%)\n",
      "[epoch 19] loss: 0.0720814\n",
      "Test set: Average loss: 3.3525, Accuracy: 1839/5000 (37%)\n",
      "[epoch 20] loss: 0.0668552\n",
      "Test set: Average loss: 3.3853, Accuracy: 1826/5000 (37%)\n",
      "[epoch 21] loss: 0.0645584\n",
      "Test set: Average loss: 3.4144, Accuracy: 1817/5000 (36%)\n",
      "[epoch 22] loss: 0.0576954\n",
      "Test set: Average loss: 3.4499, Accuracy: 1833/5000 (37%)\n",
      "[epoch 23] loss: 0.0542994\n",
      "Test set: Average loss: 3.4790, Accuracy: 1839/5000 (37%)\n",
      "[epoch 24] loss: 0.0502057\n",
      "Test set: Average loss: 3.5161, Accuracy: 1842/5000 (37%)\n",
      "[epoch 25] loss: 0.0492376\n",
      "Test set: Average loss: 3.5463, Accuracy: 1832/5000 (37%)\n",
      "[epoch 26] loss: 0.0440994\n",
      "Test set: Average loss: 3.5741, Accuracy: 1834/5000 (37%)\n",
      "[epoch 27] loss: 0.0410860\n",
      "Test set: Average loss: 3.6047, Accuracy: 1846/5000 (37%)\n",
      "[epoch 28] loss: 0.0395058\n",
      "Test set: Average loss: 3.6310, Accuracy: 1847/5000 (37%)\n",
      "[epoch 29] loss: 0.0367274\n",
      "Test set: Average loss: 3.6659, Accuracy: 1837/5000 (37%)\n",
      "[epoch 30] loss: 0.0345019\n",
      "Test set: Average loss: 3.6919, Accuracy: 1843/5000 (37%)\n",
      "[epoch 31] loss: 0.0336605\n",
      "Test set: Average loss: 3.7190, Accuracy: 1843/5000 (37%)\n",
      "[epoch 32] loss: 0.0308757\n",
      "Test set: Average loss: 3.7468, Accuracy: 1850/5000 (37%)\n",
      "[epoch 33] loss: 0.0294284\n",
      "Test set: Average loss: 3.7743, Accuracy: 1841/5000 (37%)\n",
      "[epoch 34] loss: 0.0274744\n",
      "Test set: Average loss: 3.8014, Accuracy: 1841/5000 (37%)\n",
      "[epoch 35] loss: 0.0259960\n",
      "Test set: Average loss: 3.8261, Accuracy: 1845/5000 (37%)\n",
      "[epoch 36] loss: 0.0247544\n",
      "Test set: Average loss: 3.8507, Accuracy: 1844/5000 (37%)\n",
      "[epoch 37] loss: 0.0238984\n",
      "Test set: Average loss: 3.8780, Accuracy: 1835/5000 (37%)\n",
      "[epoch 38] loss: 0.0223645\n",
      "Test set: Average loss: 3.9051, Accuracy: 1843/5000 (37%)\n",
      "[epoch 39] loss: 0.0211522\n",
      "Test set: Average loss: 3.9325, Accuracy: 1839/5000 (37%)\n",
      "[epoch 40] loss: 0.0203128\n",
      "Test set: Average loss: 3.9513, Accuracy: 1837/5000 (37%)\n",
      "[epoch 41] loss: 0.0188735\n",
      "Test set: Average loss: 3.9789, Accuracy: 1846/5000 (37%)\n",
      "[epoch 42] loss: 0.0184315\n",
      "Test set: Average loss: 4.0023, Accuracy: 1837/5000 (37%)\n",
      "[epoch 43] loss: 0.0175245\n",
      "Test set: Average loss: 4.0213, Accuracy: 1841/5000 (37%)\n",
      "[epoch 44] loss: 0.0166028\n",
      "Test set: Average loss: 4.0455, Accuracy: 1843/5000 (37%)\n",
      "[epoch 45] loss: 0.0157633\n",
      "Test set: Average loss: 4.0701, Accuracy: 1842/5000 (37%)\n",
      "[epoch 46] loss: 0.0153815\n",
      "Test set: Average loss: 4.0914, Accuracy: 1841/5000 (37%)\n",
      "[epoch 47] loss: 0.0143673\n",
      "Test set: Average loss: 4.1119, Accuracy: 1835/5000 (37%)\n",
      "[epoch 48] loss: 0.0137995\n",
      "Test set: Average loss: 4.1313, Accuracy: 1844/5000 (37%)\n",
      "[epoch 49] loss: 0.0131633\n",
      "Test set: Average loss: 4.1542, Accuracy: 1835/5000 (37%)\n",
      "[epoch 50] loss: 0.0127926\n",
      "Test set: Average loss: 4.1749, Accuracy: 1837/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9923, Accuracy: 1869/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 1.9573, Accuracy: 3757/10000 (38%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 2.0702096\n",
      "Test set: Average loss: 1.9439, Accuracy: 1273/5000 (25%)\n",
      "[epoch 2] loss: 1.6844864\n",
      "Test set: Average loss: 1.7536, Accuracy: 1802/5000 (36%)\n",
      "[epoch 3] loss: 1.4477178\n",
      "Test set: Average loss: 1.7965, Accuracy: 1857/5000 (37%)\n",
      "[epoch 4] loss: 1.3544233\n",
      "Test set: Average loss: 1.8719, Accuracy: 1819/5000 (36%)\n",
      "[epoch 5] loss: 1.1413514\n",
      "Test set: Average loss: 1.8398, Accuracy: 1959/5000 (39%)\n",
      "[epoch 6] loss: 0.9300175\n",
      "Test set: Average loss: 2.0997, Accuracy: 1850/5000 (37%)\n",
      "[epoch 7] loss: 0.7985007\n",
      "Test set: Average loss: 2.1862, Accuracy: 1945/5000 (39%)\n",
      "[epoch 8] loss: 0.7293226\n",
      "Test set: Average loss: 2.4673, Accuracy: 1738/5000 (35%)\n",
      "[epoch 9] loss: 0.6028293\n",
      "Test set: Average loss: 2.4784, Accuracy: 1832/5000 (37%)\n",
      "[epoch 10] loss: 0.4897058\n",
      "Test set: Average loss: 2.6267, Accuracy: 1850/5000 (37%)\n",
      "[epoch 11] loss: 0.3813726\n",
      "Test set: Average loss: 2.8206, Accuracy: 1926/5000 (39%)\n",
      "[epoch 12] loss: 0.3719559\n",
      "Test set: Average loss: 2.9776, Accuracy: 1917/5000 (38%)\n",
      "[epoch 13] loss: 0.2871506\n",
      "Test set: Average loss: 3.1268, Accuracy: 1870/5000 (37%)\n",
      "[epoch 14] loss: 0.2114622\n",
      "Test set: Average loss: 3.1902, Accuracy: 1857/5000 (37%)\n",
      "[epoch 15] loss: 0.1485620\n",
      "Test set: Average loss: 3.4318, Accuracy: 1882/5000 (38%)\n",
      "[epoch 16] loss: 0.1000228\n",
      "Test set: Average loss: 3.6957, Accuracy: 1870/5000 (37%)\n",
      "[epoch 17] loss: 0.0700115\n",
      "Test set: Average loss: 3.8193, Accuracy: 1897/5000 (38%)\n",
      "[epoch 18] loss: 0.0537122\n",
      "Test set: Average loss: 3.7972, Accuracy: 1837/5000 (37%)\n",
      "[epoch 19] loss: 0.0376425\n",
      "Test set: Average loss: 4.0532, Accuracy: 1817/5000 (36%)\n",
      "[epoch 20] loss: 0.0211789\n",
      "Test set: Average loss: 4.0705, Accuracy: 1875/5000 (38%)\n",
      "[epoch 21] loss: 0.0110186\n",
      "Test set: Average loss: 4.1297, Accuracy: 1876/5000 (38%)\n",
      "[epoch 22] loss: 0.0080022\n",
      "Test set: Average loss: 4.2189, Accuracy: 1877/5000 (38%)\n",
      "[epoch 23] loss: 0.0063932\n",
      "Test set: Average loss: 4.2640, Accuracy: 1863/5000 (37%)\n",
      "[epoch 24] loss: 0.0054999\n",
      "Test set: Average loss: 4.3185, Accuracy: 1872/5000 (37%)\n",
      "[epoch 25] loss: 0.0047327\n",
      "Test set: Average loss: 4.3605, Accuracy: 1882/5000 (38%)\n",
      "[epoch 26] loss: 0.0041916\n",
      "Test set: Average loss: 4.4007, Accuracy: 1875/5000 (38%)\n",
      "[epoch 27] loss: 0.0038157\n",
      "Test set: Average loss: 4.4380, Accuracy: 1868/5000 (37%)\n",
      "[epoch 28] loss: 0.0035614\n",
      "Test set: Average loss: 4.4724, Accuracy: 1872/5000 (37%)\n",
      "[epoch 29] loss: 0.0032674\n",
      "Test set: Average loss: 4.5101, Accuracy: 1878/5000 (38%)\n",
      "[epoch 30] loss: 0.0029265\n",
      "Test set: Average loss: 4.5410, Accuracy: 1879/5000 (38%)\n",
      "[epoch 31] loss: 0.0027191\n",
      "Test set: Average loss: 4.5741, Accuracy: 1867/5000 (37%)\n",
      "[epoch 32] loss: 0.0025679\n",
      "Test set: Average loss: 4.5991, Accuracy: 1874/5000 (37%)\n",
      "[epoch 33] loss: 0.0023593\n",
      "Test set: Average loss: 4.6343, Accuracy: 1874/5000 (37%)\n",
      "[epoch 34] loss: 0.0022144\n",
      "Test set: Average loss: 4.6578, Accuracy: 1874/5000 (37%)\n",
      "[epoch 35] loss: 0.0020707\n",
      "Test set: Average loss: 4.6873, Accuracy: 1872/5000 (37%)\n",
      "[epoch 36] loss: 0.0019734\n",
      "Test set: Average loss: 4.7107, Accuracy: 1875/5000 (38%)\n",
      "[epoch 37] loss: 0.0018074\n",
      "Test set: Average loss: 4.7349, Accuracy: 1865/5000 (37%)\n",
      "[epoch 38] loss: 0.0017292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.7605, Accuracy: 1881/5000 (38%)\n",
      "[epoch 39] loss: 0.0016204\n",
      "Test set: Average loss: 4.7818, Accuracy: 1867/5000 (37%)\n",
      "[epoch 40] loss: 0.0015801\n",
      "Test set: Average loss: 4.8034, Accuracy: 1872/5000 (37%)\n",
      "[epoch 41] loss: 0.0014729\n",
      "Test set: Average loss: 4.8313, Accuracy: 1871/5000 (37%)\n",
      "[epoch 42] loss: 0.0014074\n",
      "Test set: Average loss: 4.8507, Accuracy: 1871/5000 (37%)\n",
      "[epoch 43] loss: 0.0012968\n",
      "Test set: Average loss: 4.8721, Accuracy: 1875/5000 (38%)\n",
      "[epoch 44] loss: 0.0012544\n",
      "Test set: Average loss: 4.8918, Accuracy: 1873/5000 (37%)\n",
      "[epoch 45] loss: 0.0011785\n",
      "Test set: Average loss: 4.9150, Accuracy: 1870/5000 (37%)\n",
      "[epoch 46] loss: 0.0011273\n",
      "Test set: Average loss: 4.9305, Accuracy: 1869/5000 (37%)\n",
      "[epoch 47] loss: 0.0010893\n",
      "Test set: Average loss: 4.9499, Accuracy: 1877/5000 (38%)\n",
      "[epoch 48] loss: 0.0010378\n",
      "Test set: Average loss: 4.9704, Accuracy: 1869/5000 (37%)\n",
      "[epoch 49] loss: 0.0009985\n",
      "Test set: Average loss: 4.9876, Accuracy: 1877/5000 (38%)\n",
      "[epoch 50] loss: 0.0009354\n",
      "Test set: Average loss: 5.0045, Accuracy: 1875/5000 (38%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8398, Accuracy: 1959/5000 (39%)\n",
      "Test\n",
      "Test set: Average loss: 1.8206, Accuracy: 3972/10000 (40%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 404/5000 (8%)\n",
      "[epoch 1] loss: 2.1335808\n",
      "Test set: Average loss: 2.0214, Accuracy: 1319/5000 (26%)\n",
      "[epoch 2] loss: 1.8146900\n",
      "Test set: Average loss: 1.8010, Accuracy: 1645/5000 (33%)\n",
      "[epoch 3] loss: 1.5612463\n",
      "Test set: Average loss: 1.7808, Accuracy: 1784/5000 (36%)\n",
      "[epoch 4] loss: 1.3348806\n",
      "Test set: Average loss: 1.8741, Accuracy: 1799/5000 (36%)\n",
      "[epoch 5] loss: 1.1612866\n",
      "Test set: Average loss: 1.9438, Accuracy: 1730/5000 (35%)\n",
      "[epoch 6] loss: 1.0410887\n",
      "Test set: Average loss: 2.1495, Accuracy: 1775/5000 (36%)\n",
      "[epoch 7] loss: 0.9450122\n",
      "Test set: Average loss: 2.2370, Accuracy: 1757/5000 (35%)\n",
      "[epoch 8] loss: 0.6984302\n",
      "Test set: Average loss: 2.3910, Accuracy: 1841/5000 (37%)\n",
      "[epoch 9] loss: 0.6368794\n",
      "Test set: Average loss: 2.5933, Accuracy: 1729/5000 (35%)\n",
      "[epoch 10] loss: 0.5524955\n",
      "Test set: Average loss: 2.7988, Accuracy: 1770/5000 (35%)\n",
      "[epoch 11] loss: 0.3778391\n",
      "Test set: Average loss: 3.0188, Accuracy: 1739/5000 (35%)\n",
      "[epoch 12] loss: 0.2599268\n",
      "Test set: Average loss: 3.3360, Accuracy: 1755/5000 (35%)\n",
      "[epoch 13] loss: 0.2634691\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.5618, Accuracy: 1712/5000 (34%)\n",
      "[epoch 14] loss: 0.1347436\n",
      "Test set: Average loss: 3.3725, Accuracy: 1765/5000 (35%)\n",
      "[epoch 15] loss: 0.0871399\n",
      "Test set: Average loss: 3.3859, Accuracy: 1773/5000 (35%)\n",
      "[epoch 16] loss: 0.0785031\n",
      "Test set: Average loss: 3.4082, Accuracy: 1778/5000 (36%)\n",
      "[epoch 17] loss: 0.0705791\n",
      "Test set: Average loss: 3.4386, Accuracy: 1770/5000 (35%)\n",
      "[epoch 18] loss: 0.0660974\n",
      "Test set: Average loss: 3.4581, Accuracy: 1775/5000 (36%)\n",
      "[epoch 19] loss: 0.0635463\n",
      "Test set: Average loss: 3.4819, Accuracy: 1769/5000 (35%)\n",
      "[epoch 20] loss: 0.0596503\n",
      "Test set: Average loss: 3.5014, Accuracy: 1774/5000 (35%)\n",
      "[epoch 21] loss: 0.0565828\n",
      "Test set: Average loss: 3.5293, Accuracy: 1776/5000 (36%)\n",
      "[epoch 22] loss: 0.0536206\n",
      "Test set: Average loss: 3.5511, Accuracy: 1780/5000 (36%)\n",
      "[epoch 23] loss: 0.0522889\n",
      "Test set: Average loss: 3.5710, Accuracy: 1776/5000 (36%)\n",
      "[epoch 24] loss: 0.0484103\n",
      "Test set: Average loss: 3.5920, Accuracy: 1775/5000 (36%)\n",
      "[epoch 25] loss: 0.0459507\n",
      "Test set: Average loss: 3.6123, Accuracy: 1777/5000 (36%)\n",
      "[epoch 26] loss: 0.0443270\n",
      "Test set: Average loss: 3.6384, Accuracy: 1775/5000 (36%)\n",
      "[epoch 27] loss: 0.0421729\n",
      "Test set: Average loss: 3.6544, Accuracy: 1787/5000 (36%)\n",
      "[epoch 28] loss: 0.0397305\n",
      "Test set: Average loss: 3.6802, Accuracy: 1790/5000 (36%)\n",
      "[epoch 29] loss: 0.0376908\n",
      "Test set: Average loss: 3.7015, Accuracy: 1788/5000 (36%)\n",
      "[epoch 30] loss: 0.0368384\n",
      "Test set: Average loss: 3.7270, Accuracy: 1784/5000 (36%)\n",
      "[epoch 31] loss: 0.0340434\n",
      "Test set: Average loss: 3.7438, Accuracy: 1782/5000 (36%)\n",
      "[epoch 32] loss: 0.0322475\n",
      "Test set: Average loss: 3.7680, Accuracy: 1786/5000 (36%)\n",
      "[epoch 33] loss: 0.0307878\n",
      "Test set: Average loss: 3.7932, Accuracy: 1786/5000 (36%)\n",
      "[epoch 34] loss: 0.0294230\n",
      "Test set: Average loss: 3.8090, Accuracy: 1789/5000 (36%)\n",
      "[epoch 35] loss: 0.0275689\n",
      "Test set: Average loss: 3.8315, Accuracy: 1786/5000 (36%)\n",
      "[epoch 36] loss: 0.0263346\n",
      "Test set: Average loss: 3.8535, Accuracy: 1786/5000 (36%)\n",
      "[epoch 37] loss: 0.0257080\n",
      "Test set: Average loss: 3.8818, Accuracy: 1780/5000 (36%)\n",
      "[epoch 38] loss: 0.0234108\n",
      "Test set: Average loss: 3.8962, Accuracy: 1781/5000 (36%)\n",
      "[epoch 39] loss: 0.0222572\n",
      "Test set: Average loss: 3.9234, Accuracy: 1782/5000 (36%)\n",
      "[epoch 40] loss: 0.0208789\n",
      "Test set: Average loss: 3.9428, Accuracy: 1780/5000 (36%)\n",
      "[epoch 41] loss: 0.0202597\n",
      "Test set: Average loss: 3.9678, Accuracy: 1779/5000 (36%)\n",
      "[epoch 42] loss: 0.0190068\n",
      "Test set: Average loss: 3.9870, Accuracy: 1774/5000 (35%)\n",
      "[epoch 43] loss: 0.0185123\n",
      "Test set: Average loss: 4.0046, Accuracy: 1779/5000 (36%)\n",
      "[epoch 44] loss: 0.0176172\n",
      "Test set: Average loss: 4.0348, Accuracy: 1776/5000 (36%)\n",
      "[epoch 45] loss: 0.0165428\n",
      "Test set: Average loss: 4.0463, Accuracy: 1772/5000 (35%)\n",
      "[epoch 46] loss: 0.0157020\n",
      "Test set: Average loss: 4.0692, Accuracy: 1775/5000 (36%)\n",
      "[epoch 47] loss: 0.0151652\n",
      "Test set: Average loss: 4.0918, Accuracy: 1778/5000 (36%)\n",
      "[epoch 48] loss: 0.0148516\n",
      "Test set: Average loss: 4.1085, Accuracy: 1779/5000 (36%)\n",
      "[epoch 49] loss: 0.0140923\n",
      "Test set: Average loss: 4.1294, Accuracy: 1769/5000 (35%)\n",
      "[epoch 50] loss: 0.0133636\n",
      "Test set: Average loss: 4.1536, Accuracy: 1776/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3910, Accuracy: 1841/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 2.3546, Accuracy: 3742/10000 (37%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3048, Accuracy: 487/5000 (10%)\n",
      "[epoch 1] loss: 1.9528614\n",
      "Test set: Average loss: 1.7288, Accuracy: 1844/5000 (37%)\n",
      "[epoch 2] loss: 1.6049276\n",
      "Test set: Average loss: 1.6472, Accuracy: 1961/5000 (39%)\n",
      "[epoch 3] loss: 1.4344152\n",
      "Test set: Average loss: 1.6169, Accuracy: 2111/5000 (42%)\n",
      "[epoch 4] loss: 1.2998466\n",
      "Test set: Average loss: 1.6344, Accuracy: 2175/5000 (44%)\n",
      "[epoch 5] loss: 1.2077362\n",
      "Test set: Average loss: 1.6605, Accuracy: 2116/5000 (42%)\n",
      "[epoch 6] loss: 1.0888726\n",
      "Test set: Average loss: 1.6411, Accuracy: 2264/5000 (45%)\n",
      "[epoch 7] loss: 1.0426209\n",
      "Test set: Average loss: 1.7156, Accuracy: 2308/5000 (46%)\n",
      "[epoch 8] loss: 0.9238907\n",
      "Test set: Average loss: 1.8008, Accuracy: 2175/5000 (44%)\n",
      "[epoch 9] loss: 0.8442150\n",
      "Test set: Average loss: 1.9937, Accuracy: 2088/5000 (42%)\n",
      "[epoch 10] loss: 0.8113860\n",
      "Test set: Average loss: 2.0633, Accuracy: 2139/5000 (43%)\n",
      "[epoch 11] loss: 0.7229331\n",
      "Test set: Average loss: 2.1047, Accuracy: 2081/5000 (42%)\n",
      "[epoch 12] loss: 0.7126311\n",
      "Test set: Average loss: 2.1366, Accuracy: 2179/5000 (44%)\n",
      "[epoch 13] loss: 0.6079247\n",
      "Test set: Average loss: 2.3218, Accuracy: 2135/5000 (43%)\n",
      "[epoch 14] loss: 0.5916806\n",
      "Test set: Average loss: 2.3981, Accuracy: 2134/5000 (43%)\n",
      "[epoch 15] loss: 0.5472759\n",
      "Test set: Average loss: 2.6080, Accuracy: 2120/5000 (42%)\n",
      "[epoch 16] loss: 0.4679189\n",
      "Test set: Average loss: 2.6600, Accuracy: 2077/5000 (42%)\n",
      "[epoch 17] loss: 0.4240095\n",
      "Test set: Average loss: 2.8330, Accuracy: 2117/5000 (42%)\n",
      "[epoch 18] loss: 0.3468145\n",
      "Test set: Average loss: 3.0350, Accuracy: 2084/5000 (42%)\n",
      "[epoch 19] loss: 0.3154558\n",
      "Test set: Average loss: 3.1655, Accuracy: 2066/5000 (41%)\n",
      "[epoch 20] loss: 0.5020065\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.1849, Accuracy: 2080/5000 (42%)\n",
      "[epoch 21] loss: 0.3452178\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0042, Accuracy: 2158/5000 (43%)\n",
      "[epoch 22] loss: 0.1291788\n",
      "Test set: Average loss: 3.0027, Accuracy: 2153/5000 (43%)\n",
      "[epoch 23] loss: 0.1252594\n",
      "Test set: Average loss: 3.0009, Accuracy: 2162/5000 (43%)\n",
      "[epoch 24] loss: 0.1231869\n",
      "Test set: Average loss: 3.0017, Accuracy: 2163/5000 (43%)\n",
      "[epoch 25] loss: 0.1208766\n",
      "Test set: Average loss: 3.0025, Accuracy: 2170/5000 (43%)\n",
      "[epoch 26] loss: 0.1150712\n",
      "Test set: Average loss: 3.0039, Accuracy: 2163/5000 (43%)\n",
      "[epoch 27] loss: 0.1130231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.0064, Accuracy: 2157/5000 (43%)\n",
      "[epoch 28] loss: 0.1137747\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0091, Accuracy: 2163/5000 (43%)\n",
      "[epoch 29] loss: 0.1094251\n",
      "Test set: Average loss: 3.0094, Accuracy: 2161/5000 (43%)\n",
      "[epoch 30] loss: 0.1087687\n",
      "Test set: Average loss: 3.0097, Accuracy: 2162/5000 (43%)\n",
      "[epoch 31] loss: 0.1084672\n",
      "Test set: Average loss: 3.0099, Accuracy: 2162/5000 (43%)\n",
      "[epoch 32] loss: 0.1085452\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 33] loss: 0.1083823\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 34] loss: 0.1085666\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 35] loss: 0.1105626\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 36] loss: 0.1108766\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 37] loss: 0.1083530\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 38] loss: 0.1081381\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 39] loss: 0.1082081\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 40] loss: 0.1083319\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 41] loss: 0.1092105\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 42] loss: 0.1103451\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 43] loss: 0.1086879\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 44] loss: 0.1081301\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 45] loss: 0.1082815\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 46] loss: 0.2488325\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 47] loss: 0.1082085\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 48] loss: 0.1084751\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 49] loss: 0.1084262\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "[epoch 50] loss: 0.1100820\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.0102, Accuracy: 2162/5000 (43%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7156, Accuracy: 2308/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.6947, Accuracy: 4558/10000 (46%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3051, Accuracy: 495/5000 (10%)\n",
      "[epoch 1] loss: 1.9038541\n",
      "Test set: Average loss: 1.6765, Accuracy: 1933/5000 (39%)\n",
      "[epoch 2] loss: 1.5688587\n",
      "Test set: Average loss: 1.6620, Accuracy: 1984/5000 (40%)\n",
      "[epoch 3] loss: 1.3856192\n",
      "Test set: Average loss: 1.6641, Accuracy: 2053/5000 (41%)\n",
      "[epoch 4] loss: 1.2883164\n",
      "Test set: Average loss: 1.6470, Accuracy: 2114/5000 (42%)\n",
      "[epoch 5] loss: 1.1703719\n",
      "Test set: Average loss: 1.6857, Accuracy: 2112/5000 (42%)\n",
      "[epoch 6] loss: 1.0110733\n",
      "Test set: Average loss: 1.8064, Accuracy: 2097/5000 (42%)\n",
      "[epoch 7] loss: 0.9985285\n",
      "Test set: Average loss: 2.0923, Accuracy: 1789/5000 (36%)\n",
      "[epoch 8] loss: 1.0099059\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9194, Accuracy: 1996/5000 (40%)\n",
      "[epoch 9] loss: 0.6023098\n",
      "Test set: Average loss: 1.9068, Accuracy: 2109/5000 (42%)\n",
      "[epoch 10] loss: 0.5432841\n",
      "Test set: Average loss: 1.9333, Accuracy: 2156/5000 (43%)\n",
      "[epoch 11] loss: 0.5132047\n",
      "Test set: Average loss: 1.9643, Accuracy: 2144/5000 (43%)\n",
      "[epoch 12] loss: 0.4918092\n",
      "Test set: Average loss: 2.0052, Accuracy: 2133/5000 (43%)\n",
      "[epoch 13] loss: 0.5669874\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0429, Accuracy: 2121/5000 (42%)\n",
      "[epoch 14] loss: 0.4420292\n",
      "Test set: Average loss: 2.0359, Accuracy: 2132/5000 (43%)\n",
      "[epoch 15] loss: 0.4378834\n",
      "Test set: Average loss: 2.0391, Accuracy: 2133/5000 (43%)\n",
      "[epoch 16] loss: 0.4435864\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0439, Accuracy: 2126/5000 (43%)\n",
      "[epoch 17] loss: 0.4280939\n",
      "Test set: Average loss: 2.0445, Accuracy: 2128/5000 (43%)\n",
      "[epoch 18] loss: 0.4391949\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 19] loss: 0.4297991\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 20] loss: 0.4328244\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 21] loss: 0.4315746\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 22] loss: 0.4316839\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 23] loss: 0.4322187\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 24] loss: 0.4296078\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 25] loss: 0.4342622\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 26] loss: 0.4280930\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 27] loss: 0.4293194\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 28] loss: 0.4293773\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 29] loss: 0.4316539\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 30] loss: 0.4305323\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 31] loss: 0.4301883\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 32] loss: 0.4350058\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 33] loss: 0.4307637\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 34] loss: 0.4286656\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 35] loss: 0.4323443\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 36] loss: 0.4300983\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 37] loss: 0.4298607\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 38] loss: 0.4323570\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 39] loss: 0.4279189\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 40] loss: 0.4331543\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.4292694\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 42] loss: 0.4278388\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 43] loss: 0.4365440\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 44] loss: 0.4324439\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 45] loss: 0.4295075\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 46] loss: 0.4326724\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 47] loss: 0.4300230\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 48] loss: 0.5277142\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 49] loss: 0.4289725\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "[epoch 50] loss: 0.4352037\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.0450, Accuracy: 2126/5000 (43%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9333, Accuracy: 2156/5000 (43%)\n",
      "Test\n",
      "Test set: Average loss: 1.8893, Accuracy: 4457/10000 (45%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3082, Accuracy: 482/5000 (10%)\n",
      "[epoch 1] loss: 2.0422681\n",
      "Test set: Average loss: 1.7836, Accuracy: 1747/5000 (35%)\n",
      "[epoch 2] loss: 1.6891975\n",
      "Test set: Average loss: 1.6567, Accuracy: 1929/5000 (39%)\n",
      "[epoch 3] loss: 1.5054383\n",
      "Test set: Average loss: 1.6485, Accuracy: 2023/5000 (40%)\n",
      "[epoch 4] loss: 1.3407802\n",
      "Test set: Average loss: 1.6690, Accuracy: 1976/5000 (40%)\n",
      "[epoch 5] loss: 1.2146294\n",
      "Test set: Average loss: 1.7092, Accuracy: 2099/5000 (42%)\n",
      "[epoch 6] loss: 1.1204639\n",
      "Test set: Average loss: 1.7478, Accuracy: 2156/5000 (43%)\n",
      "[epoch 7] loss: 0.9853407\n",
      "Test set: Average loss: 1.7651, Accuracy: 2173/5000 (43%)\n",
      "[epoch 8] loss: 0.9152597\n",
      "Test set: Average loss: 1.9053, Accuracy: 2079/5000 (42%)\n",
      "[epoch 9] loss: 0.8472128\n",
      "Test set: Average loss: 2.0451, Accuracy: 2109/5000 (42%)\n",
      "[epoch 10] loss: 0.7416503\n",
      "Test set: Average loss: 2.1223, Accuracy: 2115/5000 (42%)\n",
      "[epoch 11] loss: 0.6689220\n",
      "Test set: Average loss: 2.2066, Accuracy: 2057/5000 (41%)\n",
      "[epoch 12] loss: 0.6793928\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4811, Accuracy: 1994/5000 (40%)\n",
      "[epoch 13] loss: 0.4287963\n",
      "Test set: Average loss: 2.2887, Accuracy: 2136/5000 (43%)\n",
      "[epoch 14] loss: 0.3368324\n",
      "Test set: Average loss: 2.3225, Accuracy: 2149/5000 (43%)\n",
      "[epoch 15] loss: 0.3101171\n",
      "Test set: Average loss: 2.3630, Accuracy: 2134/5000 (43%)\n",
      "[epoch 16] loss: 0.2889798\n",
      "Test set: Average loss: 2.4040, Accuracy: 2121/5000 (42%)\n",
      "[epoch 17] loss: 0.2770350\n",
      "Test set: Average loss: 2.4506, Accuracy: 2141/5000 (43%)\n",
      "[epoch 18] loss: 0.2604302\n",
      "Test set: Average loss: 2.4969, Accuracy: 2149/5000 (43%)\n",
      "[epoch 19] loss: 0.2525228\n",
      "Test set: Average loss: 2.5424, Accuracy: 2136/5000 (43%)\n",
      "[epoch 20] loss: 0.2354216\n",
      "Test set: Average loss: 2.5832, Accuracy: 2145/5000 (43%)\n",
      "[epoch 21] loss: 0.2277086\n",
      "Test set: Average loss: 2.6219, Accuracy: 2126/5000 (43%)\n",
      "[epoch 22] loss: 0.2165499\n",
      "Test set: Average loss: 2.6753, Accuracy: 2139/5000 (43%)\n",
      "[epoch 23] loss: 0.2063391\n",
      "Test set: Average loss: 2.7168, Accuracy: 2136/5000 (43%)\n",
      "[epoch 24] loss: 0.1936112\n",
      "Test set: Average loss: 2.7769, Accuracy: 2122/5000 (42%)\n",
      "[epoch 25] loss: 0.1871953\n",
      "Test set: Average loss: 2.8079, Accuracy: 2134/5000 (43%)\n",
      "[epoch 26] loss: 0.1773003\n",
      "Test set: Average loss: 2.8566, Accuracy: 2121/5000 (42%)\n",
      "[epoch 27] loss: 0.1659908\n",
      "Test set: Average loss: 2.9122, Accuracy: 2118/5000 (42%)\n",
      "[epoch 28] loss: 0.1586748\n",
      "Test set: Average loss: 2.9661, Accuracy: 2112/5000 (42%)\n",
      "[epoch 29] loss: 0.3116920\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0220, Accuracy: 2113/5000 (42%)\n",
      "[epoch 30] loss: 0.3307921\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2110/5000 (42%)\n",
      "[epoch 31] loss: 0.1305993\n",
      "Test set: Average loss: 3.0204, Accuracy: 2109/5000 (42%)\n",
      "[epoch 32] loss: 0.1308360\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 33] loss: 0.2731178\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 34] loss: 0.1316878\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 35] loss: 0.1364002\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 36] loss: 0.1301679\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 37] loss: 0.1300168\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 38] loss: 0.1321073\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 39] loss: 0.1307005\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 40] loss: 0.1309368\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 41] loss: 0.1305433\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 42] loss: 0.1312339\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 43] loss: 0.1345560\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 44] loss: 0.1308113\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 45] loss: 0.1304203\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 46] loss: 0.1305505\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 47] loss: 0.1322476\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 48] loss: 0.1299787\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 49] loss: 0.1308726\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "[epoch 50] loss: 0.1316853\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.0205, Accuracy: 2109/5000 (42%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7651, Accuracy: 2173/5000 (43%)\n",
      "Test\n",
      "Test set: Average loss: 1.7695, Accuracy: 4348/10000 (43%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3023, Accuracy: 525/5000 (10%)\n",
      "[epoch 1] loss: 1.8195058\n",
      "Test set: Average loss: 1.6321, Accuracy: 2054/5000 (41%)\n",
      "[epoch 2] loss: 1.5062215\n",
      "Test set: Average loss: 1.5493, Accuracy: 2262/5000 (45%)\n",
      "[epoch 3] loss: 1.3586734\n",
      "Test set: Average loss: 1.5365, Accuracy: 2259/5000 (45%)\n",
      "[epoch 4] loss: 1.2295023\n",
      "Test set: Average loss: 1.5223, Accuracy: 2309/5000 (46%)\n",
      "[epoch 5] loss: 1.1817013\n",
      "Test set: Average loss: 1.5233, Accuracy: 2420/5000 (48%)\n",
      "[epoch 6] loss: 1.0800721\n",
      "Test set: Average loss: 1.5547, Accuracy: 2394/5000 (48%)\n",
      "[epoch 7] loss: 1.0314322\n",
      "Test set: Average loss: 1.6006, Accuracy: 2312/5000 (46%)\n",
      "[epoch 8] loss: 0.9889091\n",
      "Test set: Average loss: 1.5640, Accuracy: 2373/5000 (47%)\n",
      "[epoch 9] loss: 0.9229204\n",
      "Test set: Average loss: 1.6602, Accuracy: 2366/5000 (47%)\n",
      "[epoch 10] loss: 0.9196613\n",
      "Test set: Average loss: 1.6602, Accuracy: 2395/5000 (48%)\n",
      "[epoch 11] loss: 0.8463008\n",
      "Test set: Average loss: 1.7842, Accuracy: 2283/5000 (46%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] loss: 0.8499185\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7157, Accuracy: 2355/5000 (47%)\n",
      "[epoch 13] loss: 0.5711470\n",
      "Test set: Average loss: 1.6844, Accuracy: 2461/5000 (49%)\n",
      "[epoch 14] loss: 0.5255892\n",
      "Test set: Average loss: 1.7164, Accuracy: 2517/5000 (50%)\n",
      "[epoch 15] loss: 0.5052647\n",
      "Test set: Average loss: 1.7601, Accuracy: 2500/5000 (50%)\n",
      "[epoch 16] loss: 0.4903286\n",
      "Test set: Average loss: 1.7888, Accuracy: 2466/5000 (49%)\n",
      "[epoch 17] loss: 0.4784777\n",
      "Test set: Average loss: 1.8238, Accuracy: 2480/5000 (50%)\n",
      "[epoch 18] loss: 0.4647348\n",
      "Test set: Average loss: 1.8583, Accuracy: 2490/5000 (50%)\n",
      "[epoch 19] loss: 0.4560466\n",
      "Test set: Average loss: 1.8942, Accuracy: 2469/5000 (49%)\n",
      "[epoch 20] loss: 0.4426196\n",
      "Test set: Average loss: 1.9123, Accuracy: 2458/5000 (49%)\n",
      "[epoch 21] loss: 0.4291826\n",
      "Test set: Average loss: 1.9556, Accuracy: 2470/5000 (49%)\n",
      "[epoch 22] loss: 0.4172327\n",
      "Test set: Average loss: 1.9831, Accuracy: 2468/5000 (49%)\n",
      "[epoch 23] loss: 0.4073420\n",
      "Test set: Average loss: 2.0308, Accuracy: 2446/5000 (49%)\n",
      "[epoch 24] loss: 0.3963293\n",
      "Test set: Average loss: 2.0597, Accuracy: 2466/5000 (49%)\n",
      "[epoch 25] loss: 0.3888053\n",
      "Test set: Average loss: 2.0799, Accuracy: 2429/5000 (49%)\n",
      "[epoch 26] loss: 0.3778761\n",
      "Test set: Average loss: 2.1162, Accuracy: 2458/5000 (49%)\n",
      "[epoch 27] loss: 0.3666064\n",
      "Test set: Average loss: 2.1479, Accuracy: 2424/5000 (48%)\n",
      "[epoch 28] loss: 0.3572259\n",
      "Test set: Average loss: 2.1830, Accuracy: 2415/5000 (48%)\n",
      "[epoch 29] loss: 0.3484868\n",
      "Test set: Average loss: 2.2193, Accuracy: 2420/5000 (48%)\n",
      "[epoch 30] loss: 0.3362096\n",
      "Test set: Average loss: 2.2573, Accuracy: 2408/5000 (48%)\n",
      "[epoch 31] loss: 0.3236295\n",
      "Test set: Average loss: 2.2825, Accuracy: 2396/5000 (48%)\n",
      "[epoch 32] loss: 0.3162629\n",
      "Test set: Average loss: 2.3206, Accuracy: 2407/5000 (48%)\n",
      "[epoch 33] loss: 0.3058330\n",
      "Test set: Average loss: 2.3515, Accuracy: 2398/5000 (48%)\n",
      "[epoch 34] loss: 0.2953296\n",
      "Test set: Average loss: 2.4048, Accuracy: 2391/5000 (48%)\n",
      "[epoch 35] loss: 0.2862534\n",
      "Test set: Average loss: 2.4376, Accuracy: 2357/5000 (47%)\n",
      "[epoch 36] loss: 0.2780286\n",
      "Test set: Average loss: 2.4723, Accuracy: 2376/5000 (48%)\n",
      "[epoch 37] loss: 0.2686308\n",
      "Test set: Average loss: 2.5130, Accuracy: 2380/5000 (48%)\n",
      "[epoch 38] loss: 0.2603050\n",
      "Test set: Average loss: 2.5579, Accuracy: 2345/5000 (47%)\n",
      "[epoch 39] loss: 0.2500205\n",
      "Test set: Average loss: 2.5836, Accuracy: 2358/5000 (47%)\n",
      "[epoch 40] loss: 0.2426169\n",
      "Test set: Average loss: 2.6368, Accuracy: 2356/5000 (47%)\n",
      "[epoch 41] loss: 0.2337214\n",
      "Test set: Average loss: 2.6586, Accuracy: 2354/5000 (47%)\n",
      "[epoch 42] loss: 0.2236975\n",
      "Test set: Average loss: 2.7078, Accuracy: 2335/5000 (47%)\n",
      "[epoch 43] loss: 0.2165671\n",
      "Test set: Average loss: 2.7581, Accuracy: 2363/5000 (47%)\n",
      "[epoch 44] loss: 0.2068247\n",
      "Test set: Average loss: 2.7890, Accuracy: 2334/5000 (47%)\n",
      "[epoch 45] loss: 0.1981697\n",
      "Test set: Average loss: 2.8393, Accuracy: 2328/5000 (47%)\n",
      "[epoch 46] loss: 0.1971844\n",
      "Test set: Average loss: 2.8804, Accuracy: 2338/5000 (47%)\n",
      "[epoch 47] loss: 0.1845747\n",
      "Test set: Average loss: 2.9288, Accuracy: 2337/5000 (47%)\n",
      "[epoch 48] loss: 0.1752712\n",
      "Test set: Average loss: 2.9776, Accuracy: 2323/5000 (46%)\n",
      "[epoch 49] loss: 0.1669973\n",
      "Test set: Average loss: 3.0084, Accuracy: 2324/5000 (46%)\n",
      "[epoch 50] loss: 0.1599676\n",
      "Test set: Average loss: 3.0670, Accuracy: 2340/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7164, Accuracy: 2517/5000 (50%)\n",
      "Test\n",
      "Test set: Average loss: 1.6846, Accuracy: 5046/10000 (50%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2999, Accuracy: 516/5000 (10%)\n",
      "[epoch 1] loss: 1.8159704\n",
      "Test set: Average loss: 1.7656, Accuracy: 1806/5000 (36%)\n",
      "[epoch 2] loss: 1.5021836\n",
      "Test set: Average loss: 1.5511, Accuracy: 2271/5000 (45%)\n",
      "[epoch 3] loss: 1.3612663\n",
      "Test set: Average loss: 1.4901, Accuracy: 2364/5000 (47%)\n",
      "[epoch 4] loss: 1.2771997\n",
      "Test set: Average loss: 1.5284, Accuracy: 2312/5000 (46%)\n",
      "[epoch 5] loss: 1.1985500\n",
      "Test set: Average loss: 1.7179, Accuracy: 2191/5000 (44%)\n",
      "[epoch 6] loss: 1.1196897\n",
      "Test set: Average loss: 1.5835, Accuracy: 2259/5000 (45%)\n",
      "[epoch 7] loss: 1.0769358\n",
      "Test set: Average loss: 1.5919, Accuracy: 2358/5000 (47%)\n",
      "[epoch 8] loss: 1.0118890\n",
      "Test set: Average loss: 1.7468, Accuracy: 2292/5000 (46%)\n",
      "[epoch 9] loss: 0.9637329\n",
      "Test set: Average loss: 1.6646, Accuracy: 2341/5000 (47%)\n",
      "[epoch 10] loss: 0.9074577\n",
      "Test set: Average loss: 1.6718, Accuracy: 2295/5000 (46%)\n",
      "[epoch 11] loss: 0.8596427\n",
      "Test set: Average loss: 1.7251, Accuracy: 2349/5000 (47%)\n",
      "[epoch 12] loss: 0.8064980\n",
      "Test set: Average loss: 1.7665, Accuracy: 2375/5000 (48%)\n",
      "[epoch 13] loss: 0.7647790\n",
      "Test set: Average loss: 1.7933, Accuracy: 2359/5000 (47%)\n",
      "[epoch 14] loss: 0.7110010\n",
      "Test set: Average loss: 1.8934, Accuracy: 2390/5000 (48%)\n",
      "[epoch 15] loss: 0.6569232\n",
      "Test set: Average loss: 1.9384, Accuracy: 2360/5000 (47%)\n",
      "[epoch 16] loss: 0.6040247\n",
      "Test set: Average loss: 1.9716, Accuracy: 2345/5000 (47%)\n",
      "[epoch 17] loss: 0.5330573\n",
      "Test set: Average loss: 2.1216, Accuracy: 2362/5000 (47%)\n",
      "[epoch 18] loss: 0.4982977\n",
      "Test set: Average loss: 2.1660, Accuracy: 2337/5000 (47%)\n",
      "[epoch 19] loss: 0.4330268\n",
      "Test set: Average loss: 2.2250, Accuracy: 2357/5000 (47%)\n",
      "[epoch 20] loss: 0.3522739\n",
      "Test set: Average loss: 2.3580, Accuracy: 2329/5000 (47%)\n",
      "[epoch 21] loss: 0.3124228\n",
      "Test set: Average loss: 2.3896, Accuracy: 2310/5000 (46%)\n",
      "[epoch 22] loss: 0.2326574\n",
      "Test set: Average loss: 2.4996, Accuracy: 2319/5000 (46%)\n",
      "[epoch 23] loss: 0.1839036\n",
      "Test set: Average loss: 2.6362, Accuracy: 2415/5000 (48%)\n",
      "[epoch 24] loss: 0.1556044\n",
      "Test set: Average loss: 2.7284, Accuracy: 2365/5000 (47%)\n",
      "[epoch 25] loss: 0.0872223\n",
      "Test set: Average loss: 2.9160, Accuracy: 2306/5000 (46%)\n",
      "[epoch 26] loss: 0.0504591\n",
      "Test set: Average loss: 3.0520, Accuracy: 2340/5000 (47%)\n",
      "[epoch 27] loss: 0.0334925\n",
      "Test set: Average loss: 3.0872, Accuracy: 2387/5000 (48%)\n",
      "[epoch 28] loss: 0.1167435\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.3910, Accuracy: 2246/5000 (45%)\n",
      "[epoch 29] loss: 0.0298937\n",
      "Test set: Average loss: 3.1485, Accuracy: 2342/5000 (47%)\n",
      "[epoch 30] loss: 0.0143076\n",
      "Test set: Average loss: 3.1494, Accuracy: 2348/5000 (47%)\n",
      "[epoch 31] loss: 0.0125132\n",
      "Test set: Average loss: 3.1563, Accuracy: 2359/5000 (47%)\n",
      "[epoch 32] loss: 0.0115293\n",
      "Test set: Average loss: 3.1627, Accuracy: 2374/5000 (47%)\n",
      "[epoch 33] loss: 0.0108190\n",
      "Test set: Average loss: 3.1752, Accuracy: 2370/5000 (47%)\n",
      "[epoch 34] loss: 0.0102798\n",
      "Test set: Average loss: 3.1887, Accuracy: 2374/5000 (47%)\n",
      "[epoch 35] loss: 0.0098655\n",
      "Test set: Average loss: 3.2034, Accuracy: 2369/5000 (47%)\n",
      "[epoch 36] loss: 0.0094399\n",
      "Test set: Average loss: 3.2168, Accuracy: 2378/5000 (48%)\n",
      "[epoch 37] loss: 0.0090910\n",
      "Test set: Average loss: 3.2303, Accuracy: 2371/5000 (47%)\n",
      "[epoch 38] loss: 0.0087718\n",
      "Test set: Average loss: 3.2470, Accuracy: 2378/5000 (48%)\n",
      "[epoch 39] loss: 0.0083354\n",
      "Test set: Average loss: 3.2637, Accuracy: 2376/5000 (48%)\n",
      "[epoch 40] loss: 0.0080095\n",
      "Test set: Average loss: 3.2775, Accuracy: 2375/5000 (48%)\n",
      "[epoch 41] loss: 0.0076850\n",
      "Test set: Average loss: 3.2953, Accuracy: 2375/5000 (48%)\n",
      "[epoch 42] loss: 0.0073432\n",
      "Test set: Average loss: 3.3128, Accuracy: 2374/5000 (47%)\n",
      "[epoch 43] loss: 0.0071519\n",
      "Test set: Average loss: 3.3314, Accuracy: 2375/5000 (48%)\n",
      "[epoch 44] loss: 0.0067376\n",
      "Test set: Average loss: 3.3513, Accuracy: 2379/5000 (48%)\n",
      "[epoch 45] loss: 0.0064116\n",
      "Test set: Average loss: 3.3708, Accuracy: 2377/5000 (48%)\n",
      "[epoch 46] loss: 0.0061678\n",
      "Test set: Average loss: 3.3914, Accuracy: 2378/5000 (48%)\n",
      "[epoch 47] loss: 0.0058332\n",
      "Test set: Average loss: 3.4182, Accuracy: 2374/5000 (47%)\n",
      "[epoch 48] loss: 0.0055586\n",
      "Test set: Average loss: 3.4375, Accuracy: 2375/5000 (48%)\n",
      "[epoch 49] loss: 0.0053147\n",
      "Test set: Average loss: 3.4619, Accuracy: 2375/5000 (48%)\n",
      "[epoch 50] loss: 0.0050252\n",
      "Test set: Average loss: 3.4830, Accuracy: 2376/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6362, Accuracy: 2415/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 2.6209, Accuracy: 4804/10000 (48%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3048, Accuracy: 461/5000 (9%)\n",
      "[epoch 1] loss: 1.8192982\n",
      "Test set: Average loss: 1.7031, Accuracy: 1856/5000 (37%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] loss: 1.5344319\n",
      "Test set: Average loss: 1.5372, Accuracy: 2172/5000 (43%)\n",
      "[epoch 3] loss: 1.3935257\n",
      "Test set: Average loss: 1.5051, Accuracy: 2319/5000 (46%)\n",
      "[epoch 4] loss: 1.2884919\n",
      "Test set: Average loss: 1.4974, Accuracy: 2317/5000 (46%)\n",
      "[epoch 5] loss: 1.1919094\n",
      "Test set: Average loss: 1.5251, Accuracy: 2368/5000 (47%)\n",
      "[epoch 6] loss: 1.1267279\n",
      "Test set: Average loss: 1.4923, Accuracy: 2423/5000 (48%)\n",
      "[epoch 7] loss: 1.0659531\n",
      "Test set: Average loss: 1.5182, Accuracy: 2436/5000 (49%)\n",
      "[epoch 8] loss: 1.0143983\n",
      "Test set: Average loss: 1.6293, Accuracy: 2333/5000 (47%)\n",
      "[epoch 9] loss: 0.9493852\n",
      "Test set: Average loss: 1.6355, Accuracy: 2401/5000 (48%)\n",
      "[epoch 10] loss: 0.8922359\n",
      "Test set: Average loss: 1.7334, Accuracy: 2338/5000 (47%)\n",
      "[epoch 11] loss: 0.8515866\n",
      "Test set: Average loss: 1.6917, Accuracy: 2408/5000 (48%)\n",
      "[epoch 12] loss: 0.8160420\n",
      "Test set: Average loss: 1.7506, Accuracy: 2399/5000 (48%)\n",
      "[epoch 13] loss: 0.7652865\n",
      "Test set: Average loss: 1.8406, Accuracy: 2338/5000 (47%)\n",
      "[epoch 14] loss: 0.7083015\n",
      "Test set: Average loss: 1.8546, Accuracy: 2408/5000 (48%)\n",
      "[epoch 15] loss: 0.6684768\n",
      "Test set: Average loss: 1.9313, Accuracy: 2391/5000 (48%)\n",
      "[epoch 16] loss: 0.6274426\n",
      "Test set: Average loss: 1.9981, Accuracy: 2374/5000 (47%)\n",
      "[epoch 17] loss: 0.5864577\n",
      "Test set: Average loss: 2.0526, Accuracy: 2362/5000 (47%)\n",
      "[epoch 18] loss: 0.4962054\n",
      "Test set: Average loss: 2.2046, Accuracy: 2322/5000 (46%)\n",
      "[epoch 19] loss: 0.4377620\n",
      "Test set: Average loss: 2.1748, Accuracy: 2404/5000 (48%)\n",
      "[epoch 20] loss: 0.3659400\n",
      "Test set: Average loss: 2.2680, Accuracy: 2401/5000 (48%)\n",
      "[epoch 21] loss: 0.3051231\n",
      "Test set: Average loss: 2.4701, Accuracy: 2332/5000 (47%)\n",
      "[epoch 22] loss: 0.2852988\n",
      "Test set: Average loss: 2.4409, Accuracy: 2363/5000 (47%)\n",
      "[epoch 23] loss: 0.2485214\n",
      "Test set: Average loss: 2.5514, Accuracy: 2402/5000 (48%)\n",
      "[epoch 24] loss: 0.2077138\n",
      "Test set: Average loss: 2.6087, Accuracy: 2384/5000 (48%)\n",
      "[epoch 25] loss: 0.1245635\n",
      "Test set: Average loss: 2.7415, Accuracy: 2433/5000 (49%)\n",
      "[epoch 26] loss: 0.0647054\n",
      "Test set: Average loss: 2.8929, Accuracy: 2403/5000 (48%)\n",
      "[epoch 27] loss: 0.0417551\n",
      "Test set: Average loss: 2.9954, Accuracy: 2428/5000 (49%)\n",
      "[epoch 28] loss: 0.0217616\n",
      "Test set: Average loss: 3.0683, Accuracy: 2440/5000 (49%)\n",
      "[epoch 29] loss: 0.0140267\n",
      "Test set: Average loss: 3.1828, Accuracy: 2448/5000 (49%)\n",
      "[epoch 30] loss: 0.0104595\n",
      "Test set: Average loss: 3.2741, Accuracy: 2429/5000 (49%)\n",
      "[epoch 31] loss: 0.0083480\n",
      "Test set: Average loss: 3.3363, Accuracy: 2443/5000 (49%)\n",
      "[epoch 32] loss: 0.0068048\n",
      "Test set: Average loss: 3.4151, Accuracy: 2453/5000 (49%)\n",
      "[epoch 33] loss: 0.0056569\n",
      "Test set: Average loss: 3.4726, Accuracy: 2445/5000 (49%)\n",
      "[epoch 34] loss: 0.0047756\n",
      "Test set: Average loss: 3.5333, Accuracy: 2448/5000 (49%)\n",
      "[epoch 35] loss: 0.0040974\n",
      "Test set: Average loss: 3.6037, Accuracy: 2449/5000 (49%)\n",
      "[epoch 36] loss: 0.0035351\n",
      "Test set: Average loss: 3.6593, Accuracy: 2448/5000 (49%)\n",
      "[epoch 37] loss: 0.0030695\n",
      "Test set: Average loss: 3.7177, Accuracy: 2444/5000 (49%)\n",
      "[epoch 38] loss: 0.0026927\n",
      "Test set: Average loss: 3.7675, Accuracy: 2447/5000 (49%)\n",
      "[epoch 39] loss: 0.0023529\n",
      "Test set: Average loss: 3.8308, Accuracy: 2445/5000 (49%)\n",
      "[epoch 40] loss: 0.0020597\n",
      "Test set: Average loss: 3.8821, Accuracy: 2449/5000 (49%)\n",
      "[epoch 41] loss: 0.0018335\n",
      "Test set: Average loss: 3.9382, Accuracy: 2439/5000 (49%)\n",
      "[epoch 42] loss: 0.0016233\n",
      "Test set: Average loss: 3.9814, Accuracy: 2453/5000 (49%)\n",
      "[epoch 43] loss: 0.0014254\n",
      "Test set: Average loss: 4.0333, Accuracy: 2439/5000 (49%)\n",
      "[epoch 44] loss: 0.0012743\n",
      "Test set: Average loss: 4.0809, Accuracy: 2444/5000 (49%)\n",
      "[epoch 45] loss: 0.0011285\n",
      "Test set: Average loss: 4.1219, Accuracy: 2440/5000 (49%)\n",
      "[epoch 46] loss: 0.0010128\n",
      "Test set: Average loss: 4.1897, Accuracy: 2444/5000 (49%)\n",
      "[epoch 47] loss: 0.0008991\n",
      "Test set: Average loss: 4.2301, Accuracy: 2443/5000 (49%)\n",
      "[epoch 48] loss: 0.0008059\n",
      "Test set: Average loss: 4.2737, Accuracy: 2447/5000 (49%)\n",
      "[epoch 49] loss: 0.0007211\n",
      "Test set: Average loss: 4.3148, Accuracy: 2440/5000 (49%)\n",
      "[epoch 50] loss: 0.0006471\n",
      "Test set: Average loss: 4.3582, Accuracy: 2436/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.9814, Accuracy: 2453/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 3.8298, Accuracy: 4972/10000 (50%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3058, Accuracy: 465/5000 (9%)\n",
      "[epoch 1] loss: 1.7322829\n",
      "Test set: Average loss: 1.5480, Accuracy: 2184/5000 (44%)\n",
      "[epoch 2] loss: 1.4227549\n",
      "Test set: Average loss: 1.4581, Accuracy: 2332/5000 (47%)\n",
      "[epoch 3] loss: 1.2961464\n",
      "Test set: Average loss: 1.3694, Accuracy: 2604/5000 (52%)\n",
      "[epoch 4] loss: 1.2151208\n",
      "Test set: Average loss: 1.4103, Accuracy: 2549/5000 (51%)\n",
      "[epoch 5] loss: 1.1389568\n",
      "Test set: Average loss: 1.3775, Accuracy: 2561/5000 (51%)\n",
      "[epoch 6] loss: 1.0869890\n",
      "Test set: Average loss: 1.3780, Accuracy: 2649/5000 (53%)\n",
      "[epoch 7] loss: 1.0491721\n",
      "Test set: Average loss: 1.4514, Accuracy: 2599/5000 (52%)\n",
      "[epoch 8] loss: 1.0040201\n",
      "Test set: Average loss: 1.3913, Accuracy: 2631/5000 (53%)\n",
      "[epoch 9] loss: 0.9663924\n",
      "Test set: Average loss: 1.3863, Accuracy: 2619/5000 (52%)\n",
      "[epoch 10] loss: 0.9164989\n",
      "Test set: Average loss: 1.4122, Accuracy: 2638/5000 (53%)\n",
      "[epoch 11] loss: 0.8457499\n",
      "Test set: Average loss: 1.4444, Accuracy: 2642/5000 (53%)\n",
      "[epoch 12] loss: 0.7878946\n",
      "Test set: Average loss: 1.4908, Accuracy: 2629/5000 (53%)\n",
      "[epoch 13] loss: 0.7195248\n",
      "Test set: Average loss: 1.4824, Accuracy: 2678/5000 (54%)\n",
      "[epoch 14] loss: 0.6402029\n",
      "Test set: Average loss: 1.6013, Accuracy: 2625/5000 (52%)\n",
      "[epoch 15] loss: 0.5665594\n",
      "Test set: Average loss: 1.5547, Accuracy: 2680/5000 (54%)\n",
      "[epoch 16] loss: 0.4741850\n",
      "Test set: Average loss: 1.6894, Accuracy: 2675/5000 (54%)\n",
      "[epoch 17] loss: 0.3609665\n",
      "Test set: Average loss: 1.7343, Accuracy: 2664/5000 (53%)\n",
      "[epoch 18] loss: 0.2772808\n",
      "Test set: Average loss: 1.8232, Accuracy: 2698/5000 (54%)\n",
      "[epoch 19] loss: 0.1832008\n",
      "Test set: Average loss: 1.9497, Accuracy: 2642/5000 (53%)\n",
      "[epoch 20] loss: 0.1199201\n",
      "Test set: Average loss: 2.0235, Accuracy: 2673/5000 (53%)\n",
      "[epoch 21] loss: 0.0757630\n",
      "Test set: Average loss: 2.1133, Accuracy: 2698/5000 (54%)\n",
      "[epoch 22] loss: 0.0375291\n",
      "Test set: Average loss: 2.2296, Accuracy: 2688/5000 (54%)\n",
      "[epoch 23] loss: 0.0156047\n",
      "Test set: Average loss: 2.2936, Accuracy: 2722/5000 (54%)\n",
      "[epoch 24] loss: 0.0080019\n",
      "Test set: Average loss: 2.3757, Accuracy: 2747/5000 (55%)\n",
      "[epoch 25] loss: 0.0053507\n",
      "Test set: Average loss: 2.4612, Accuracy: 2736/5000 (55%)\n",
      "[epoch 26] loss: 0.0039446\n",
      "Test set: Average loss: 2.5305, Accuracy: 2732/5000 (55%)\n",
      "[epoch 27] loss: 0.0029875\n",
      "Test set: Average loss: 2.5990, Accuracy: 2735/5000 (55%)\n",
      "[epoch 28] loss: 0.0023355\n",
      "Test set: Average loss: 2.6616, Accuracy: 2730/5000 (55%)\n",
      "[epoch 29] loss: 0.0018335\n",
      "Test set: Average loss: 2.7306, Accuracy: 2739/5000 (55%)\n",
      "[epoch 30] loss: 0.0014524\n",
      "Test set: Average loss: 2.7901, Accuracy: 2732/5000 (55%)\n",
      "[epoch 31] loss: 0.0011556\n",
      "Test set: Average loss: 2.8563, Accuracy: 2725/5000 (54%)\n",
      "[epoch 32] loss: 0.0009217\n",
      "Test set: Average loss: 2.9196, Accuracy: 2744/5000 (55%)\n",
      "[epoch 33] loss: 0.0007320\n",
      "Test set: Average loss: 2.9776, Accuracy: 2734/5000 (55%)\n",
      "[epoch 34] loss: 0.0005905\n",
      "Test set: Average loss: 3.0329, Accuracy: 2734/5000 (55%)\n",
      "[epoch 35] loss: 0.0004771\n",
      "Test set: Average loss: 3.0967, Accuracy: 2728/5000 (55%)\n",
      "[epoch 36] loss: 0.0003831\n",
      "Test set: Average loss: 3.1579, Accuracy: 2741/5000 (55%)\n",
      "[epoch 37] loss: 0.0003069\n",
      "Test set: Average loss: 3.2101, Accuracy: 2737/5000 (55%)\n",
      "[epoch 38] loss: 0.0002470\n",
      "Test set: Average loss: 3.2679, Accuracy: 2718/5000 (54%)\n",
      "[epoch 39] loss: 0.0002003\n",
      "Test set: Average loss: 3.3284, Accuracy: 2734/5000 (55%)\n",
      "[epoch 40] loss: 0.0001620\n",
      "Test set: Average loss: 3.3876, Accuracy: 2728/5000 (55%)\n",
      "[epoch 41] loss: 0.0001311\n",
      "Test set: Average loss: 3.4308, Accuracy: 2733/5000 (55%)\n",
      "[epoch 42] loss: 0.0001060\n",
      "Test set: Average loss: 3.4864, Accuracy: 2723/5000 (54%)\n",
      "[epoch 43] loss: 0.0000862\n",
      "Test set: Average loss: 3.5513, Accuracy: 2716/5000 (54%)\n",
      "[epoch 44] loss: 0.0000698\n",
      "Test set: Average loss: 3.6043, Accuracy: 2726/5000 (55%)\n",
      "[epoch 45] loss: 0.0000569\n",
      "Test set: Average loss: 3.6530, Accuracy: 2734/5000 (55%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 46] loss: 0.0000463\n",
      "Test set: Average loss: 3.7131, Accuracy: 2720/5000 (54%)\n",
      "[epoch 47] loss: 0.0000379\n",
      "Test set: Average loss: 3.7592, Accuracy: 2726/5000 (55%)\n",
      "[epoch 48] loss: 0.0000309\n",
      "Test set: Average loss: 3.8120, Accuracy: 2727/5000 (55%)\n",
      "[epoch 49] loss: 0.0000252\n",
      "Test set: Average loss: 3.8652, Accuracy: 2718/5000 (54%)\n",
      "[epoch 50] loss: 0.0000207\n",
      "Test set: Average loss: 3.9156, Accuracy: 2713/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3757, Accuracy: 2747/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 2.2885, Accuracy: 5613/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 367/5000 (7%)\n",
      "[epoch 1] loss: 1.6915732\n",
      "Test set: Average loss: 1.5732, Accuracy: 2107/5000 (42%)\n",
      "[epoch 2] loss: 1.4231346\n",
      "Test set: Average loss: 1.4983, Accuracy: 2325/5000 (46%)\n",
      "[epoch 3] loss: 1.3058738\n",
      "Test set: Average loss: 1.3584, Accuracy: 2566/5000 (51%)\n",
      "[epoch 4] loss: 1.2254850\n",
      "Test set: Average loss: 1.4191, Accuracy: 2504/5000 (50%)\n",
      "[epoch 5] loss: 1.1640190\n",
      "Test set: Average loss: 1.3398, Accuracy: 2647/5000 (53%)\n",
      "[epoch 6] loss: 1.1225351\n",
      "Test set: Average loss: 1.3654, Accuracy: 2620/5000 (52%)\n",
      "[epoch 7] loss: 1.0659328\n",
      "Test set: Average loss: 1.3888, Accuracy: 2644/5000 (53%)\n",
      "[epoch 8] loss: 1.0346590\n",
      "Test set: Average loss: 1.3624, Accuracy: 2647/5000 (53%)\n",
      "[epoch 9] loss: 0.9799969\n",
      "Test set: Average loss: 1.4546, Accuracy: 2593/5000 (52%)\n",
      "[epoch 10] loss: 0.9429115\n",
      "Test set: Average loss: 1.3643, Accuracy: 2683/5000 (54%)\n",
      "[epoch 11] loss: 0.8741263\n",
      "Test set: Average loss: 1.3924, Accuracy: 2714/5000 (54%)\n",
      "[epoch 12] loss: 0.8166671\n",
      "Test set: Average loss: 1.3706, Accuracy: 2742/5000 (55%)\n",
      "[epoch 13] loss: 0.7365988\n",
      "Test set: Average loss: 1.4227, Accuracy: 2765/5000 (55%)\n",
      "[epoch 14] loss: 0.6689115\n",
      "Test set: Average loss: 1.4765, Accuracy: 2754/5000 (55%)\n",
      "[epoch 15] loss: 0.5858337\n",
      "Test set: Average loss: 1.5971, Accuracy: 2644/5000 (53%)\n",
      "[epoch 16] loss: 0.4925261\n",
      "Test set: Average loss: 1.6044, Accuracy: 2701/5000 (54%)\n",
      "[epoch 17] loss: 0.3881346\n",
      "Test set: Average loss: 1.6401, Accuracy: 2715/5000 (54%)\n",
      "[epoch 18] loss: 0.2789311\n",
      "Test set: Average loss: 1.7153, Accuracy: 2724/5000 (54%)\n",
      "[epoch 19] loss: 0.2063325\n",
      "Test set: Average loss: 1.8251, Accuracy: 2737/5000 (55%)\n",
      "[epoch 20] loss: 0.1301494\n",
      "Test set: Average loss: 1.9874, Accuracy: 2704/5000 (54%)\n",
      "[epoch 21] loss: 0.0725019\n",
      "Test set: Average loss: 2.0224, Accuracy: 2766/5000 (55%)\n",
      "[epoch 22] loss: 0.0449883\n",
      "Test set: Average loss: 2.1342, Accuracy: 2749/5000 (55%)\n",
      "[epoch 23] loss: 0.0227614\n",
      "Test set: Average loss: 2.2278, Accuracy: 2772/5000 (55%)\n",
      "[epoch 24] loss: 0.0142126\n",
      "Test set: Average loss: 2.2754, Accuracy: 2783/5000 (56%)\n",
      "[epoch 25] loss: 0.0110852\n",
      "Test set: Average loss: 2.3483, Accuracy: 2794/5000 (56%)\n",
      "[epoch 26] loss: 0.0805885\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.9774, Accuracy: 2357/5000 (47%)\n",
      "[epoch 27] loss: 0.1918350\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.1902, Accuracy: 2704/5000 (54%)\n",
      "[epoch 28] loss: 0.0409253\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2710/5000 (54%)\n",
      "[epoch 29] loss: 0.0382821\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 30] loss: 0.0380562\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 31] loss: 0.0380315\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 32] loss: 0.0380085\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 33] loss: 0.0380395\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 34] loss: 0.0380082\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 35] loss: 0.0380661\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 36] loss: 0.0380208\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 37] loss: 0.0380239\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 38] loss: 0.0380775\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 39] loss: 0.0380046\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 40] loss: 0.0380723\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 41] loss: 0.0380359\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 42] loss: 0.0380710\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 43] loss: 0.0380393\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 44] loss: 0.0380010\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 45] loss: 0.0380536\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 46] loss: 0.0380029\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 47] loss: 0.0380334\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 48] loss: 0.0380227\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 49] loss: 0.0380337\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "[epoch 50] loss: 0.0381212\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.1860, Accuracy: 2711/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3483, Accuracy: 2794/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 2.3460, Accuracy: 5656/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3075, Accuracy: 572/5000 (11%)\n",
      "[epoch 1] loss: 1.7223602\n",
      "Test set: Average loss: 1.4911, Accuracy: 2279/5000 (46%)\n",
      "[epoch 2] loss: 1.4622725\n",
      "Test set: Average loss: 1.4945, Accuracy: 2290/5000 (46%)\n",
      "[epoch 3] loss: 1.3328631\n",
      "Test set: Average loss: 1.4135, Accuracy: 2483/5000 (50%)\n",
      "[epoch 4] loss: 1.2645434\n",
      "Test set: Average loss: 1.3830, Accuracy: 2509/5000 (50%)\n",
      "[epoch 5] loss: 1.1927007\n",
      "Test set: Average loss: 1.3453, Accuracy: 2630/5000 (53%)\n",
      "[epoch 6] loss: 1.1497684\n",
      "Test set: Average loss: 1.3940, Accuracy: 2594/5000 (52%)\n",
      "[epoch 7] loss: 1.0928154\n",
      "Test set: Average loss: 1.3804, Accuracy: 2628/5000 (53%)\n",
      "[epoch 8] loss: 1.0462233\n",
      "Test set: Average loss: 1.3882, Accuracy: 2633/5000 (53%)\n",
      "[epoch 9] loss: 1.0070935\n",
      "Test set: Average loss: 1.3925, Accuracy: 2644/5000 (53%)\n",
      "[epoch 10] loss: 0.9562255\n",
      "Test set: Average loss: 1.3665, Accuracy: 2755/5000 (55%)\n",
      "[epoch 11] loss: 0.9071979\n",
      "Test set: Average loss: 1.4377, Accuracy: 2654/5000 (53%)\n",
      "[epoch 12] loss: 0.8294422\n",
      "Test set: Average loss: 1.4238, Accuracy: 2694/5000 (54%)\n",
      "[epoch 13] loss: 0.7677743\n",
      "Test set: Average loss: 1.4629, Accuracy: 2685/5000 (54%)\n",
      "[epoch 14] loss: 0.7003051\n",
      "Test set: Average loss: 1.4638, Accuracy: 2714/5000 (54%)\n",
      "[epoch 15] loss: 0.6047507\n",
      "Test set: Average loss: 1.5815, Accuracy: 2644/5000 (53%)\n",
      "[epoch 16] loss: 0.5173868\n",
      "Test set: Average loss: 1.5970, Accuracy: 2751/5000 (55%)\n",
      "[epoch 17] loss: 0.4262758\n",
      "Test set: Average loss: 1.6570, Accuracy: 2690/5000 (54%)\n",
      "[epoch 18] loss: 0.3169125\n",
      "Test set: Average loss: 1.7482, Accuracy: 2712/5000 (54%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] loss: 0.2190271\n",
      "Test set: Average loss: 1.8531, Accuracy: 2696/5000 (54%)\n",
      "[epoch 20] loss: 0.1465736\n",
      "Test set: Average loss: 1.9266, Accuracy: 2732/5000 (55%)\n",
      "[epoch 21] loss: 0.1052896\n",
      "Test set: Average loss: 2.0731, Accuracy: 2710/5000 (54%)\n",
      "[epoch 22] loss: 0.0852391\n",
      "Test set: Average loss: 2.1519, Accuracy: 2747/5000 (55%)\n",
      "[epoch 23] loss: 0.0362808\n",
      "Test set: Average loss: 2.1699, Accuracy: 2791/5000 (56%)\n",
      "[epoch 24] loss: 0.0396568\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3645, Accuracy: 2728/5000 (55%)\n",
      "[epoch 25] loss: 0.0165675\n",
      "Test set: Average loss: 2.2680, Accuracy: 2790/5000 (56%)\n",
      "[epoch 26] loss: 0.0096784\n",
      "Test set: Average loss: 2.2755, Accuracy: 2798/5000 (56%)\n",
      "[epoch 27] loss: 0.0080827\n",
      "Test set: Average loss: 2.2871, Accuracy: 2801/5000 (56%)\n",
      "[epoch 28] loss: 0.0070763\n",
      "Test set: Average loss: 2.2982, Accuracy: 2805/5000 (56%)\n",
      "[epoch 29] loss: 0.0063021\n",
      "Test set: Average loss: 2.3142, Accuracy: 2804/5000 (56%)\n",
      "[epoch 30] loss: 0.0056732\n",
      "Test set: Average loss: 2.3292, Accuracy: 2809/5000 (56%)\n",
      "[epoch 31] loss: 0.0051403\n",
      "Test set: Average loss: 2.3463, Accuracy: 2812/5000 (56%)\n",
      "[epoch 32] loss: 0.0046640\n",
      "Test set: Average loss: 2.3624, Accuracy: 2810/5000 (56%)\n",
      "[epoch 33] loss: 0.0042463\n",
      "Test set: Average loss: 2.3799, Accuracy: 2818/5000 (56%)\n",
      "[epoch 34] loss: 0.0038452\n",
      "Test set: Average loss: 2.4026, Accuracy: 2807/5000 (56%)\n",
      "[epoch 35] loss: 0.0034867\n",
      "Test set: Average loss: 2.4233, Accuracy: 2809/5000 (56%)\n",
      "[epoch 36] loss: 0.0031464\n",
      "Test set: Average loss: 2.4465, Accuracy: 2802/5000 (56%)\n",
      "[epoch 37] loss: 0.0028394\n",
      "Test set: Average loss: 2.4707, Accuracy: 2799/5000 (56%)\n",
      "[epoch 38] loss: 0.0025434\n",
      "Test set: Average loss: 2.4967, Accuracy: 2791/5000 (56%)\n",
      "[epoch 39] loss: 0.0022823\n",
      "Test set: Average loss: 2.5207, Accuracy: 2799/5000 (56%)\n",
      "[epoch 40] loss: 0.0020363\n",
      "Test set: Average loss: 2.5532, Accuracy: 2795/5000 (56%)\n",
      "[epoch 41] loss: 0.0018038\n",
      "Test set: Average loss: 2.5789, Accuracy: 2785/5000 (56%)\n",
      "[epoch 42] loss: 0.0015924\n",
      "Test set: Average loss: 2.6124, Accuracy: 2791/5000 (56%)\n",
      "[epoch 43] loss: 0.0013993\n",
      "Test set: Average loss: 2.6469, Accuracy: 2788/5000 (56%)\n",
      "[epoch 44] loss: 0.0012252\n",
      "Test set: Average loss: 2.6794, Accuracy: 2780/5000 (56%)\n",
      "[epoch 45] loss: 0.0010717\n",
      "Test set: Average loss: 2.7178, Accuracy: 2781/5000 (56%)\n",
      "[epoch 46] loss: 0.0009294\n",
      "Test set: Average loss: 2.7574, Accuracy: 2787/5000 (56%)\n",
      "[epoch 47] loss: 0.0008073\n",
      "Test set: Average loss: 2.7895, Accuracy: 2787/5000 (56%)\n",
      "[epoch 48] loss: 0.0006937\n",
      "Test set: Average loss: 2.8306, Accuracy: 2780/5000 (56%)\n",
      "[epoch 49] loss: 0.0005974\n",
      "Test set: Average loss: 2.8700, Accuracy: 2781/5000 (56%)\n",
      "[epoch 50] loss: 0.0005137\n",
      "Test set: Average loss: 2.9071, Accuracy: 2789/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3799, Accuracy: 2818/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 2.3465, Accuracy: 5577/10000 (56%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 1.6524442\n",
      "Test set: Average loss: 1.4869, Accuracy: 2359/5000 (47%)\n",
      "[epoch 2] loss: 1.3955435\n",
      "Test set: Average loss: 1.4170, Accuracy: 2412/5000 (48%)\n",
      "[epoch 3] loss: 1.2856790\n",
      "Test set: Average loss: 1.4135, Accuracy: 2500/5000 (50%)\n",
      "[epoch 4] loss: 1.2174888\n",
      "Test set: Average loss: 1.3265, Accuracy: 2640/5000 (53%)\n",
      "[epoch 5] loss: 1.1606429\n",
      "Test set: Average loss: 1.3144, Accuracy: 2688/5000 (54%)\n",
      "[epoch 6] loss: 1.1078724\n",
      "Test set: Average loss: 1.2798, Accuracy: 2753/5000 (55%)\n",
      "[epoch 7] loss: 1.0656405\n",
      "Test set: Average loss: 1.2901, Accuracy: 2789/5000 (56%)\n",
      "[epoch 8] loss: 1.0215410\n",
      "Test set: Average loss: 1.2719, Accuracy: 2797/5000 (56%)\n",
      "[epoch 9] loss: 0.9659849\n",
      "Test set: Average loss: 1.2902, Accuracy: 2845/5000 (57%)\n",
      "[epoch 10] loss: 0.9184933\n",
      "Test set: Average loss: 1.3185, Accuracy: 2757/5000 (55%)\n",
      "[epoch 11] loss: 0.8634083\n",
      "Test set: Average loss: 1.3559, Accuracy: 2739/5000 (55%)\n",
      "[epoch 12] loss: 0.8088758\n",
      "Test set: Average loss: 1.2980, Accuracy: 2862/5000 (57%)\n",
      "[epoch 13] loss: 0.7377217\n",
      "Test set: Average loss: 1.4501, Accuracy: 2809/5000 (56%)\n",
      "[epoch 14] loss: 0.6572920\n",
      "Test set: Average loss: 1.3824, Accuracy: 2835/5000 (57%)\n",
      "[epoch 15] loss: 0.5547868\n",
      "Test set: Average loss: 1.4226, Accuracy: 2833/5000 (57%)\n",
      "[epoch 16] loss: 0.4571075\n",
      "Test set: Average loss: 1.5369, Accuracy: 2843/5000 (57%)\n",
      "[epoch 17] loss: 0.3686095\n",
      "Test set: Average loss: 1.5780, Accuracy: 2886/5000 (58%)\n",
      "[epoch 18] loss: 0.2540506\n",
      "Test set: Average loss: 1.6517, Accuracy: 2851/5000 (57%)\n",
      "[epoch 19] loss: 0.1654924\n",
      "Test set: Average loss: 1.7493, Accuracy: 2861/5000 (57%)\n",
      "[epoch 20] loss: 0.1067240\n",
      "Test set: Average loss: 1.9017, Accuracy: 2834/5000 (57%)\n",
      "[epoch 21] loss: 0.0919197\n",
      "Test set: Average loss: 1.9697, Accuracy: 2842/5000 (57%)\n",
      "[epoch 22] loss: 0.1153389\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0909, Accuracy: 2793/5000 (56%)\n",
      "[epoch 23] loss: 0.0415908\n",
      "Test set: Average loss: 2.0063, Accuracy: 2865/5000 (57%)\n",
      "[epoch 24] loss: 0.0179075\n",
      "Test set: Average loss: 2.0172, Accuracy: 2880/5000 (58%)\n",
      "[epoch 25] loss: 0.0134850\n",
      "Test set: Average loss: 2.0327, Accuracy: 2881/5000 (58%)\n",
      "[epoch 26] loss: 0.0109041\n",
      "Test set: Average loss: 2.0499, Accuracy: 2893/5000 (58%)\n",
      "[epoch 27] loss: 0.0090433\n",
      "Test set: Average loss: 2.0691, Accuracy: 2897/5000 (58%)\n",
      "[epoch 28] loss: 0.0076501\n",
      "Test set: Average loss: 2.0890, Accuracy: 2902/5000 (58%)\n",
      "[epoch 29] loss: 0.0064758\n",
      "Test set: Average loss: 2.1103, Accuracy: 2913/5000 (58%)\n",
      "[epoch 30] loss: 0.0054762\n",
      "Test set: Average loss: 2.1390, Accuracy: 2898/5000 (58%)\n",
      "[epoch 31] loss: 0.0046403\n",
      "Test set: Average loss: 2.1620, Accuracy: 2905/5000 (58%)\n",
      "[epoch 32] loss: 0.0039236\n",
      "Test set: Average loss: 2.1881, Accuracy: 2908/5000 (58%)\n",
      "[epoch 33] loss: 0.0032967\n",
      "Test set: Average loss: 2.2199, Accuracy: 2909/5000 (58%)\n",
      "[epoch 34] loss: 0.0027500\n",
      "Test set: Average loss: 2.2517, Accuracy: 2910/5000 (58%)\n",
      "[epoch 35] loss: 0.0022928\n",
      "Test set: Average loss: 2.2849, Accuracy: 2904/5000 (58%)\n",
      "[epoch 36] loss: 0.0018978\n",
      "Test set: Average loss: 2.3196, Accuracy: 2919/5000 (58%)\n",
      "[epoch 37] loss: 0.0015608\n",
      "Test set: Average loss: 2.3621, Accuracy: 2918/5000 (58%)\n",
      "[epoch 38] loss: 0.0012772\n",
      "Test set: Average loss: 2.3974, Accuracy: 2907/5000 (58%)\n",
      "[epoch 39] loss: 0.0010398\n",
      "Test set: Average loss: 2.4343, Accuracy: 2922/5000 (58%)\n",
      "[epoch 40] loss: 0.0008481\n",
      "Test set: Average loss: 2.4771, Accuracy: 2924/5000 (58%)\n",
      "[epoch 41] loss: 0.0006829\n",
      "Test set: Average loss: 2.5248, Accuracy: 2915/5000 (58%)\n",
      "[epoch 42] loss: 0.0005501\n",
      "Test set: Average loss: 2.5679, Accuracy: 2925/5000 (58%)\n",
      "[epoch 43] loss: 0.0004410\n",
      "Test set: Average loss: 2.6214, Accuracy: 2931/5000 (59%)\n",
      "[epoch 44] loss: 0.0003529\n",
      "Test set: Average loss: 2.6632, Accuracy: 2936/5000 (59%)\n",
      "[epoch 45] loss: 0.0002811\n",
      "Test set: Average loss: 2.7070, Accuracy: 2936/5000 (59%)\n",
      "[epoch 46] loss: 0.0002235\n",
      "Test set: Average loss: 2.7564, Accuracy: 2916/5000 (58%)\n",
      "[epoch 47] loss: 0.0001769\n",
      "Test set: Average loss: 2.8043, Accuracy: 2933/5000 (59%)\n",
      "[epoch 48] loss: 0.0001401\n",
      "Test set: Average loss: 2.8575, Accuracy: 2923/5000 (58%)\n",
      "[epoch 49] loss: 0.0001112\n",
      "Test set: Average loss: 2.9078, Accuracy: 2921/5000 (58%)\n",
      "[epoch 50] loss: 0.0000877\n",
      "Test set: Average loss: 2.9623, Accuracy: 2932/5000 (59%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7070, Accuracy: 2936/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 2.6795, Accuracy: 5910/10000 (59%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 456/5000 (9%)\n",
      "[epoch 1] loss: 1.6436299\n",
      "Test set: Average loss: 1.4905, Accuracy: 2300/5000 (46%)\n",
      "[epoch 2] loss: 1.3891991\n",
      "Test set: Average loss: 1.4015, Accuracy: 2462/5000 (49%)\n",
      "[epoch 3] loss: 1.2774250\n",
      "Test set: Average loss: 1.3419, Accuracy: 2606/5000 (52%)\n",
      "[epoch 4] loss: 1.2001444\n",
      "Test set: Average loss: 1.3024, Accuracy: 2709/5000 (54%)\n",
      "[epoch 5] loss: 1.1408859\n",
      "Test set: Average loss: 1.2763, Accuracy: 2772/5000 (55%)\n",
      "[epoch 6] loss: 1.0917276\n",
      "Test set: Average loss: 1.3057, Accuracy: 2769/5000 (55%)\n",
      "[epoch 7] loss: 1.0431871\n",
      "Test set: Average loss: 1.3338, Accuracy: 2748/5000 (55%)\n",
      "[epoch 8] loss: 0.9896441\n",
      "Test set: Average loss: 1.2633, Accuracy: 2831/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 0.9355420\n",
      "Test set: Average loss: 1.2728, Accuracy: 2873/5000 (57%)\n",
      "[epoch 10] loss: 0.8920042\n",
      "Test set: Average loss: 1.2587, Accuracy: 2922/5000 (58%)\n",
      "[epoch 11] loss: 0.8216602\n",
      "Test set: Average loss: 1.3006, Accuracy: 2868/5000 (57%)\n",
      "[epoch 12] loss: 0.7499757\n",
      "Test set: Average loss: 1.3190, Accuracy: 2906/5000 (58%)\n",
      "[epoch 13] loss: 0.6690566\n",
      "Test set: Average loss: 1.3370, Accuracy: 2952/5000 (59%)\n",
      "[epoch 14] loss: 0.5778443\n",
      "Test set: Average loss: 1.4014, Accuracy: 2916/5000 (58%)\n",
      "[epoch 15] loss: 0.4845432\n",
      "Test set: Average loss: 1.4621, Accuracy: 2895/5000 (58%)\n",
      "[epoch 16] loss: 0.3788987\n",
      "Test set: Average loss: 1.5064, Accuracy: 2967/5000 (59%)\n",
      "[epoch 17] loss: 0.2719559\n",
      "Test set: Average loss: 1.6195, Accuracy: 2898/5000 (58%)\n",
      "[epoch 18] loss: 0.1903385\n",
      "Test set: Average loss: 1.7404, Accuracy: 2921/5000 (58%)\n",
      "[epoch 19] loss: 0.1269999\n",
      "Test set: Average loss: 1.8383, Accuracy: 2920/5000 (58%)\n",
      "[epoch 20] loss: 0.0708443\n",
      "Test set: Average loss: 1.9116, Accuracy: 2931/5000 (59%)\n",
      "[epoch 21] loss: 0.0740605\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0941, Accuracy: 2833/5000 (57%)\n",
      "[epoch 22] loss: 0.0383820\n",
      "Test set: Average loss: 1.9707, Accuracy: 2986/5000 (60%)\n",
      "[epoch 23] loss: 0.0163330\n",
      "Test set: Average loss: 1.9801, Accuracy: 2999/5000 (60%)\n",
      "[epoch 24] loss: 0.0122539\n",
      "Test set: Average loss: 1.9999, Accuracy: 2999/5000 (60%)\n",
      "[epoch 25] loss: 0.0098970\n",
      "Test set: Average loss: 2.0164, Accuracy: 3010/5000 (60%)\n",
      "[epoch 26] loss: 0.0081960\n",
      "Test set: Average loss: 2.0357, Accuracy: 3011/5000 (60%)\n",
      "[epoch 27] loss: 0.0069080\n",
      "Test set: Average loss: 2.0550, Accuracy: 3010/5000 (60%)\n",
      "[epoch 28] loss: 0.0058273\n",
      "Test set: Average loss: 2.0766, Accuracy: 3011/5000 (60%)\n",
      "[epoch 29] loss: 0.0049615\n",
      "Test set: Average loss: 2.1005, Accuracy: 3005/5000 (60%)\n",
      "[epoch 30] loss: 0.0042001\n",
      "Test set: Average loss: 2.1285, Accuracy: 3005/5000 (60%)\n",
      "[epoch 31] loss: 0.0035499\n",
      "Test set: Average loss: 2.1567, Accuracy: 3002/5000 (60%)\n",
      "[epoch 32] loss: 0.0029839\n",
      "Test set: Average loss: 2.1924, Accuracy: 2995/5000 (60%)\n",
      "[epoch 33] loss: 0.0025015\n",
      "Test set: Average loss: 2.2222, Accuracy: 3007/5000 (60%)\n",
      "[epoch 34] loss: 0.0020779\n",
      "Test set: Average loss: 2.2538, Accuracy: 2995/5000 (60%)\n",
      "[epoch 35] loss: 0.0017129\n",
      "Test set: Average loss: 2.2974, Accuracy: 2999/5000 (60%)\n",
      "[epoch 36] loss: 0.0014097\n",
      "Test set: Average loss: 2.3364, Accuracy: 3002/5000 (60%)\n",
      "[epoch 37] loss: 0.0011541\n",
      "Test set: Average loss: 2.3754, Accuracy: 2994/5000 (60%)\n",
      "[epoch 38] loss: 0.0009364\n",
      "Test set: Average loss: 2.4191, Accuracy: 2991/5000 (60%)\n",
      "[epoch 39] loss: 0.0007582\n",
      "Test set: Average loss: 2.4634, Accuracy: 2980/5000 (60%)\n",
      "[epoch 40] loss: 0.0006109\n",
      "Test set: Average loss: 2.5076, Accuracy: 2979/5000 (60%)\n",
      "[epoch 41] loss: 0.0004865\n",
      "Test set: Average loss: 2.5567, Accuracy: 2991/5000 (60%)\n",
      "[epoch 42] loss: 0.0003892\n",
      "Test set: Average loss: 2.6036, Accuracy: 2987/5000 (60%)\n",
      "[epoch 43] loss: 0.0003102\n",
      "Test set: Average loss: 2.6491, Accuracy: 2988/5000 (60%)\n",
      "[epoch 44] loss: 0.0002460\n",
      "Test set: Average loss: 2.6996, Accuracy: 2990/5000 (60%)\n",
      "[epoch 45] loss: 0.0001947\n",
      "Test set: Average loss: 2.7409, Accuracy: 2986/5000 (60%)\n",
      "[epoch 46] loss: 0.0001541\n",
      "Test set: Average loss: 2.7950, Accuracy: 2970/5000 (59%)\n",
      "[epoch 47] loss: 0.0001212\n",
      "Test set: Average loss: 2.8489, Accuracy: 2980/5000 (60%)\n",
      "[epoch 48] loss: 0.0000954\n",
      "Test set: Average loss: 2.9020, Accuracy: 2980/5000 (60%)\n",
      "[epoch 49] loss: 0.0000750\n",
      "Test set: Average loss: 2.9517, Accuracy: 2993/5000 (60%)\n",
      "[epoch 50] loss: 0.0000586\n",
      "Test set: Average loss: 3.0007, Accuracy: 2978/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0766, Accuracy: 3011/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.0044, Accuracy: 6012/10000 (60%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3027, Accuracy: 367/5000 (7%)\n",
      "[epoch 1] loss: 1.6406399\n",
      "Test set: Average loss: 1.4576, Accuracy: 2331/5000 (47%)\n",
      "[epoch 2] loss: 1.3569345\n",
      "Test set: Average loss: 1.3269, Accuracy: 2631/5000 (53%)\n",
      "[epoch 3] loss: 1.2391563\n",
      "Test set: Average loss: 1.3763, Accuracy: 2589/5000 (52%)\n",
      "[epoch 4] loss: 1.1547857\n",
      "Test set: Average loss: 1.2265, Accuracy: 2837/5000 (57%)\n",
      "[epoch 5] loss: 1.1042137\n",
      "Test set: Average loss: 1.3298, Accuracy: 2731/5000 (55%)\n",
      "[epoch 6] loss: 1.0609253\n",
      "Test set: Average loss: 1.2491, Accuracy: 2793/5000 (56%)\n",
      "[epoch 7] loss: 1.0112587\n",
      "Test set: Average loss: 1.2498, Accuracy: 2841/5000 (57%)\n",
      "[epoch 8] loss: 0.9722074\n",
      "Test set: Average loss: 1.2230, Accuracy: 2895/5000 (58%)\n",
      "[epoch 9] loss: 0.9248843\n",
      "Test set: Average loss: 1.1975, Accuracy: 2935/5000 (59%)\n",
      "[epoch 10] loss: 0.8744940\n",
      "Test set: Average loss: 1.2427, Accuracy: 2884/5000 (58%)\n",
      "[epoch 11] loss: 0.8294339\n",
      "Test set: Average loss: 1.3364, Accuracy: 2836/5000 (57%)\n",
      "[epoch 12] loss: 0.7682714\n",
      "Test set: Average loss: 1.2872, Accuracy: 2883/5000 (58%)\n",
      "[epoch 13] loss: 0.7007283\n",
      "Test set: Average loss: 1.2923, Accuracy: 2893/5000 (58%)\n",
      "[epoch 14] loss: 0.6181129\n",
      "Test set: Average loss: 1.3139, Accuracy: 2980/5000 (60%)\n",
      "[epoch 15] loss: 0.5222170\n",
      "Test set: Average loss: 1.4120, Accuracy: 2887/5000 (58%)\n",
      "[epoch 16] loss: 0.4168438\n",
      "Test set: Average loss: 1.4469, Accuracy: 2962/5000 (59%)\n",
      "[epoch 17] loss: 0.3246005\n",
      "Test set: Average loss: 1.5102, Accuracy: 2952/5000 (59%)\n",
      "[epoch 18] loss: 0.2342140\n",
      "Test set: Average loss: 1.5824, Accuracy: 2944/5000 (59%)\n",
      "[epoch 19] loss: 0.1561463\n",
      "Test set: Average loss: 1.7079, Accuracy: 2931/5000 (59%)\n",
      "[epoch 20] loss: 0.0940767\n",
      "Test set: Average loss: 1.7772, Accuracy: 2922/5000 (58%)\n",
      "[epoch 21] loss: 0.0575292\n",
      "Test set: Average loss: 1.8999, Accuracy: 2957/5000 (59%)\n",
      "[epoch 22] loss: 0.0682481\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1313, Accuracy: 2775/5000 (56%)\n",
      "[epoch 23] loss: 0.0494456\n",
      "Test set: Average loss: 1.8944, Accuracy: 2987/5000 (60%)\n",
      "[epoch 24] loss: 0.0165700\n",
      "Test set: Average loss: 1.8959, Accuracy: 3006/5000 (60%)\n",
      "[epoch 25] loss: 0.0118666\n",
      "Test set: Average loss: 1.9097, Accuracy: 3010/5000 (60%)\n",
      "[epoch 26] loss: 0.0093150\n",
      "Test set: Average loss: 1.9197, Accuracy: 3019/5000 (60%)\n",
      "[epoch 27] loss: 0.0076060\n",
      "Test set: Average loss: 1.9390, Accuracy: 3027/5000 (61%)\n",
      "[epoch 28] loss: 0.0063237\n",
      "Test set: Average loss: 1.9526, Accuracy: 3027/5000 (61%)\n",
      "[epoch 29] loss: 0.0052978\n",
      "Test set: Average loss: 1.9735, Accuracy: 3030/5000 (61%)\n",
      "[epoch 30] loss: 0.0044698\n",
      "Test set: Average loss: 1.9961, Accuracy: 3039/5000 (61%)\n",
      "[epoch 31] loss: 0.0037711\n",
      "Test set: Average loss: 2.0198, Accuracy: 3031/5000 (61%)\n",
      "[epoch 32] loss: 0.0031758\n",
      "Test set: Average loss: 2.0454, Accuracy: 3033/5000 (61%)\n",
      "[epoch 33] loss: 0.0026655\n",
      "Test set: Average loss: 2.0705, Accuracy: 3035/5000 (61%)\n",
      "[epoch 34] loss: 0.0022370\n",
      "Test set: Average loss: 2.1004, Accuracy: 3041/5000 (61%)\n",
      "[epoch 35] loss: 0.0018556\n",
      "Test set: Average loss: 2.1342, Accuracy: 3034/5000 (61%)\n",
      "[epoch 36] loss: 0.0015387\n",
      "Test set: Average loss: 2.1701, Accuracy: 3045/5000 (61%)\n",
      "[epoch 37] loss: 0.0012665\n",
      "Test set: Average loss: 2.2019, Accuracy: 3045/5000 (61%)\n",
      "[epoch 38] loss: 0.0010410\n",
      "Test set: Average loss: 2.2405, Accuracy: 3051/5000 (61%)\n",
      "[epoch 39] loss: 0.0008483\n",
      "Test set: Average loss: 2.2787, Accuracy: 3047/5000 (61%)\n",
      "[epoch 40] loss: 0.0006919\n",
      "Test set: Average loss: 2.3200, Accuracy: 3041/5000 (61%)\n",
      "[epoch 41] loss: 0.0005596\n",
      "Test set: Average loss: 2.3568, Accuracy: 3049/5000 (61%)\n",
      "[epoch 42] loss: 0.0004501\n",
      "Test set: Average loss: 2.4004, Accuracy: 3054/5000 (61%)\n",
      "[epoch 43] loss: 0.0003606\n",
      "Test set: Average loss: 2.4414, Accuracy: 3047/5000 (61%)\n",
      "[epoch 44] loss: 0.0002888\n",
      "Test set: Average loss: 2.4896, Accuracy: 3053/5000 (61%)\n",
      "[epoch 45] loss: 0.0002307\n",
      "Test set: Average loss: 2.5313, Accuracy: 3049/5000 (61%)\n",
      "[epoch 46] loss: 0.0001839\n",
      "Test set: Average loss: 2.5783, Accuracy: 3051/5000 (61%)\n",
      "[epoch 47] loss: 0.0001458\n",
      "Test set: Average loss: 2.6243, Accuracy: 3041/5000 (61%)\n",
      "[epoch 48] loss: 0.0001158\n",
      "Test set: Average loss: 2.6677, Accuracy: 3047/5000 (61%)\n",
      "[epoch 49] loss: 0.0000912\n",
      "Test set: Average loss: 2.7150, Accuracy: 3051/5000 (61%)\n",
      "[epoch 50] loss: 0.0000721\n",
      "Test set: Average loss: 2.7675, Accuracy: 3042/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4004, Accuracy: 3054/5000 (61%)\n",
      "Test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3302, Accuracy: 6159/10000 (62%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2947, Accuracy: 702/5000 (14%)\n",
      "[epoch 1] loss: 1.6368277\n",
      "Test set: Average loss: 1.4937, Accuracy: 2317/5000 (46%)\n",
      "[epoch 2] loss: 1.3553355\n",
      "Test set: Average loss: 1.4091, Accuracy: 2463/5000 (49%)\n",
      "[epoch 3] loss: 1.2471182\n",
      "Test set: Average loss: 1.2899, Accuracy: 2682/5000 (54%)\n",
      "[epoch 4] loss: 1.1787716\n",
      "Test set: Average loss: 1.2751, Accuracy: 2766/5000 (55%)\n",
      "[epoch 5] loss: 1.1216909\n",
      "Test set: Average loss: 1.2959, Accuracy: 2683/5000 (54%)\n",
      "[epoch 6] loss: 1.0749202\n",
      "Test set: Average loss: 1.1970, Accuracy: 2908/5000 (58%)\n",
      "[epoch 7] loss: 1.0272085\n",
      "Test set: Average loss: 1.2652, Accuracy: 2838/5000 (57%)\n",
      "[epoch 8] loss: 0.9757226\n",
      "Test set: Average loss: 1.2434, Accuracy: 2865/5000 (57%)\n",
      "[epoch 9] loss: 0.9169928\n",
      "Test set: Average loss: 1.1985, Accuracy: 2943/5000 (59%)\n",
      "[epoch 10] loss: 0.8579117\n",
      "Test set: Average loss: 1.2073, Accuracy: 2937/5000 (59%)\n",
      "[epoch 11] loss: 0.7962660\n",
      "Test set: Average loss: 1.2716, Accuracy: 2849/5000 (57%)\n",
      "[epoch 12] loss: 0.7117669\n",
      "Test set: Average loss: 1.2959, Accuracy: 2956/5000 (59%)\n",
      "[epoch 13] loss: 0.6236954\n",
      "Test set: Average loss: 1.3117, Accuracy: 2977/5000 (60%)\n",
      "[epoch 14] loss: 0.5214175\n",
      "Test set: Average loss: 1.3171, Accuracy: 2951/5000 (59%)\n",
      "[epoch 15] loss: 0.4066958\n",
      "Test set: Average loss: 1.4781, Accuracy: 2902/5000 (58%)\n",
      "[epoch 16] loss: 0.3196376\n",
      "Test set: Average loss: 1.4759, Accuracy: 2966/5000 (59%)\n",
      "[epoch 17] loss: 0.2214857\n",
      "Test set: Average loss: 1.5921, Accuracy: 2943/5000 (59%)\n",
      "[epoch 18] loss: 0.1652088\n",
      "Test set: Average loss: 1.6828, Accuracy: 3007/5000 (60%)\n",
      "[epoch 19] loss: 0.1062128\n",
      "Test set: Average loss: 1.8141, Accuracy: 2963/5000 (59%)\n",
      "[epoch 20] loss: 0.0968488\n",
      "Test set: Average loss: 1.8978, Accuracy: 2908/5000 (58%)\n",
      "[epoch 21] loss: 0.1565376\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0046, Accuracy: 2914/5000 (58%)\n",
      "[epoch 22] loss: 0.0536123\n",
      "Test set: Average loss: 1.8407, Accuracy: 3023/5000 (60%)\n",
      "[epoch 23] loss: 0.0193028\n",
      "Test set: Average loss: 1.8545, Accuracy: 3035/5000 (61%)\n",
      "[epoch 24] loss: 0.0131781\n",
      "Test set: Average loss: 1.8723, Accuracy: 3048/5000 (61%)\n",
      "[epoch 25] loss: 0.0099390\n",
      "Test set: Average loss: 1.8935, Accuracy: 3058/5000 (61%)\n",
      "[epoch 26] loss: 0.0077533\n",
      "Test set: Average loss: 1.9144, Accuracy: 3071/5000 (61%)\n",
      "[epoch 27] loss: 0.0061340\n",
      "Test set: Average loss: 1.9403, Accuracy: 3068/5000 (61%)\n",
      "[epoch 28] loss: 0.0048749\n",
      "Test set: Average loss: 1.9593, Accuracy: 3075/5000 (62%)\n",
      "[epoch 29] loss: 0.0038764\n",
      "Test set: Average loss: 1.9863, Accuracy: 3084/5000 (62%)\n",
      "[epoch 30] loss: 0.0030826\n",
      "Test set: Average loss: 2.0179, Accuracy: 3084/5000 (62%)\n",
      "[epoch 31] loss: 0.0024252\n",
      "Test set: Average loss: 2.0502, Accuracy: 3082/5000 (62%)\n",
      "[epoch 32] loss: 0.0019102\n",
      "Test set: Average loss: 2.0875, Accuracy: 3087/5000 (62%)\n",
      "[epoch 33] loss: 0.0014867\n",
      "Test set: Average loss: 2.1231, Accuracy: 3077/5000 (62%)\n",
      "[epoch 34] loss: 0.0011573\n",
      "Test set: Average loss: 2.1620, Accuracy: 3086/5000 (62%)\n",
      "[epoch 35] loss: 0.0008905\n",
      "Test set: Average loss: 2.2040, Accuracy: 3084/5000 (62%)\n",
      "[epoch 36] loss: 0.0006846\n",
      "Test set: Average loss: 2.2447, Accuracy: 3095/5000 (62%)\n",
      "[epoch 37] loss: 0.0005217\n",
      "Test set: Average loss: 2.2926, Accuracy: 3092/5000 (62%)\n",
      "[epoch 38] loss: 0.0003964\n",
      "Test set: Average loss: 2.3318, Accuracy: 3088/5000 (62%)\n",
      "[epoch 39] loss: 0.0002988\n",
      "Test set: Average loss: 2.3910, Accuracy: 3090/5000 (62%)\n",
      "[epoch 40] loss: 0.0002259\n",
      "Test set: Average loss: 2.4423, Accuracy: 3089/5000 (62%)\n",
      "[epoch 41] loss: 0.0001684\n",
      "Test set: Average loss: 2.4851, Accuracy: 3092/5000 (62%)\n",
      "[epoch 42] loss: 0.0001261\n",
      "Test set: Average loss: 2.5407, Accuracy: 3085/5000 (62%)\n",
      "[epoch 43] loss: 0.0000940\n",
      "Test set: Average loss: 2.5832, Accuracy: 3091/5000 (62%)\n",
      "[epoch 44] loss: 0.0000698\n",
      "Test set: Average loss: 2.6386, Accuracy: 3093/5000 (62%)\n",
      "[epoch 45] loss: 0.0000519\n",
      "Test set: Average loss: 2.6998, Accuracy: 3097/5000 (62%)\n",
      "[epoch 46] loss: 0.0000385\n",
      "Test set: Average loss: 2.7531, Accuracy: 3098/5000 (62%)\n",
      "[epoch 47] loss: 0.0000284\n",
      "Test set: Average loss: 2.8055, Accuracy: 3088/5000 (62%)\n",
      "[epoch 48] loss: 0.0000210\n",
      "Test set: Average loss: 2.8575, Accuracy: 3083/5000 (62%)\n",
      "[epoch 49] loss: 0.0000155\n",
      "Test set: Average loss: 2.9125, Accuracy: 3090/5000 (62%)\n",
      "[epoch 50] loss: 0.0000114\n",
      "Test set: Average loss: 2.9710, Accuracy: 3093/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7531, Accuracy: 3098/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.8151, Accuracy: 6193/10000 (62%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3023, Accuracy: 513/5000 (10%)\n",
      "[epoch 1] loss: 1.5771660\n",
      "Test set: Average loss: 1.4134, Accuracy: 2458/5000 (49%)\n",
      "[epoch 2] loss: 1.3356872\n",
      "Test set: Average loss: 1.3306, Accuracy: 2576/5000 (52%)\n",
      "[epoch 3] loss: 1.2373400\n",
      "Test set: Average loss: 1.3520, Accuracy: 2613/5000 (52%)\n",
      "[epoch 4] loss: 1.1726675\n",
      "Test set: Average loss: 1.3510, Accuracy: 2610/5000 (52%)\n",
      "[epoch 5] loss: 1.1177990\n",
      "Test set: Average loss: 1.2507, Accuracy: 2830/5000 (57%)\n",
      "[epoch 6] loss: 1.0672294\n",
      "Test set: Average loss: 1.2396, Accuracy: 2801/5000 (56%)\n",
      "[epoch 7] loss: 1.0177548\n",
      "Test set: Average loss: 1.2048, Accuracy: 2876/5000 (58%)\n",
      "[epoch 8] loss: 0.9776637\n",
      "Test set: Average loss: 1.2208, Accuracy: 2886/5000 (58%)\n",
      "[epoch 9] loss: 0.9199196\n",
      "Test set: Average loss: 1.2299, Accuracy: 2881/5000 (58%)\n",
      "[epoch 10] loss: 0.8664218\n",
      "Test set: Average loss: 1.2291, Accuracy: 2954/5000 (59%)\n",
      "[epoch 11] loss: 0.8022814\n",
      "Test set: Average loss: 1.2234, Accuracy: 2916/5000 (58%)\n",
      "[epoch 12] loss: 0.7348636\n",
      "Test set: Average loss: 1.2120, Accuracy: 3003/5000 (60%)\n",
      "[epoch 13] loss: 0.6536368\n",
      "Test set: Average loss: 1.2840, Accuracy: 2953/5000 (59%)\n",
      "[epoch 14] loss: 0.5553218\n",
      "Test set: Average loss: 1.3019, Accuracy: 2999/5000 (60%)\n",
      "[epoch 15] loss: 0.4584503\n",
      "Test set: Average loss: 1.3768, Accuracy: 2961/5000 (59%)\n",
      "[epoch 16] loss: 0.3658096\n",
      "Test set: Average loss: 1.4588, Accuracy: 2972/5000 (59%)\n",
      "[epoch 17] loss: 0.2525493\n",
      "Test set: Average loss: 1.5441, Accuracy: 2949/5000 (59%)\n",
      "[epoch 18] loss: 0.1706429\n",
      "Test set: Average loss: 1.6140, Accuracy: 2992/5000 (60%)\n",
      "[epoch 19] loss: 0.1220851\n",
      "Test set: Average loss: 1.7721, Accuracy: 2956/5000 (59%)\n",
      "[epoch 20] loss: 0.1047393\n",
      "Test set: Average loss: 1.8665, Accuracy: 2953/5000 (59%)\n",
      "[epoch 21] loss: 0.0992933\n",
      "Test set: Average loss: 2.0203, Accuracy: 2884/5000 (58%)\n",
      "[epoch 22] loss: 0.1279299\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0134, Accuracy: 2942/5000 (59%)\n",
      "[epoch 23] loss: 0.0378412\n",
      "Test set: Average loss: 1.9549, Accuracy: 3009/5000 (60%)\n",
      "[epoch 24] loss: 0.0143878\n",
      "Test set: Average loss: 1.9664, Accuracy: 3023/5000 (60%)\n",
      "[epoch 25] loss: 0.0100613\n",
      "Test set: Average loss: 1.9806, Accuracy: 3036/5000 (61%)\n",
      "[epoch 26] loss: 0.0076907\n",
      "Test set: Average loss: 1.9929, Accuracy: 3031/5000 (61%)\n",
      "[epoch 27] loss: 0.0060839\n",
      "Test set: Average loss: 2.0088, Accuracy: 3042/5000 (61%)\n",
      "[epoch 28] loss: 0.0048779\n",
      "Test set: Average loss: 2.0349, Accuracy: 3040/5000 (61%)\n",
      "[epoch 29] loss: 0.0039432\n",
      "Test set: Average loss: 2.0541, Accuracy: 3039/5000 (61%)\n",
      "[epoch 30] loss: 0.0031713\n",
      "Test set: Average loss: 2.0796, Accuracy: 3047/5000 (61%)\n",
      "[epoch 31] loss: 0.0025479\n",
      "Test set: Average loss: 2.1106, Accuracy: 3039/5000 (61%)\n",
      "[epoch 32] loss: 0.0020300\n",
      "Test set: Average loss: 2.1414, Accuracy: 3042/5000 (61%)\n",
      "[epoch 33] loss: 0.0016146\n",
      "Test set: Average loss: 2.1754, Accuracy: 3058/5000 (61%)\n",
      "[epoch 34] loss: 0.0012682\n",
      "Test set: Average loss: 2.2060, Accuracy: 3053/5000 (61%)\n",
      "[epoch 35] loss: 0.0009914\n",
      "Test set: Average loss: 2.2474, Accuracy: 3055/5000 (61%)\n",
      "[epoch 36] loss: 0.0007675\n",
      "Test set: Average loss: 2.2885, Accuracy: 3057/5000 (61%)\n",
      "[epoch 37] loss: 0.0005940\n",
      "Test set: Average loss: 2.3304, Accuracy: 3053/5000 (61%)\n",
      "[epoch 38] loss: 0.0004539\n",
      "Test set: Average loss: 2.3717, Accuracy: 3055/5000 (61%)\n",
      "[epoch 39] loss: 0.0003467\n",
      "Test set: Average loss: 2.4207, Accuracy: 3061/5000 (61%)\n",
      "[epoch 40] loss: 0.0002643\n",
      "Test set: Average loss: 2.4673, Accuracy: 3063/5000 (61%)\n",
      "[epoch 41] loss: 0.0001992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5205, Accuracy: 3059/5000 (61%)\n",
      "[epoch 42] loss: 0.0001497\n",
      "Test set: Average loss: 2.5663, Accuracy: 3067/5000 (61%)\n",
      "[epoch 43] loss: 0.0001126\n",
      "Test set: Average loss: 2.6177, Accuracy: 3066/5000 (61%)\n",
      "[epoch 44] loss: 0.0000842\n",
      "Test set: Average loss: 2.6703, Accuracy: 3064/5000 (61%)\n",
      "[epoch 45] loss: 0.0000627\n",
      "Test set: Average loss: 2.7235, Accuracy: 3061/5000 (61%)\n",
      "[epoch 46] loss: 0.0000468\n",
      "Test set: Average loss: 2.7746, Accuracy: 3066/5000 (61%)\n",
      "[epoch 47] loss: 0.0000348\n",
      "Test set: Average loss: 2.8261, Accuracy: 3072/5000 (61%)\n",
      "[epoch 48] loss: 0.0000257\n",
      "Test set: Average loss: 2.8858, Accuracy: 3063/5000 (61%)\n",
      "[epoch 49] loss: 0.0000191\n",
      "Test set: Average loss: 2.9389, Accuracy: 3066/5000 (61%)\n",
      "[epoch 50] loss: 0.0000141\n",
      "Test set: Average loss: 2.9925, Accuracy: 3057/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8261, Accuracy: 3072/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.8172, Accuracy: 6192/10000 (62%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3075, Accuracy: 405/5000 (8%)\n",
      "[epoch 1] loss: 1.6033831\n",
      "Test set: Average loss: 1.4718, Accuracy: 2380/5000 (48%)\n",
      "[epoch 2] loss: 1.3331977\n",
      "Test set: Average loss: 1.3480, Accuracy: 2597/5000 (52%)\n",
      "[epoch 3] loss: 1.2130247\n",
      "Test set: Average loss: 1.2953, Accuracy: 2720/5000 (54%)\n",
      "[epoch 4] loss: 1.1331167\n",
      "Test set: Average loss: 1.2089, Accuracy: 2857/5000 (57%)\n",
      "[epoch 5] loss: 1.0762544\n",
      "Test set: Average loss: 1.1953, Accuracy: 2905/5000 (58%)\n",
      "[epoch 6] loss: 1.0269258\n",
      "Test set: Average loss: 1.2328, Accuracy: 2831/5000 (57%)\n",
      "[epoch 7] loss: 0.9854631\n",
      "Test set: Average loss: 1.2540, Accuracy: 2831/5000 (57%)\n",
      "[epoch 8] loss: 0.9313092\n",
      "Test set: Average loss: 1.2829, Accuracy: 2852/5000 (57%)\n",
      "[epoch 9] loss: 0.8781531\n",
      "Test set: Average loss: 1.1810, Accuracy: 2980/5000 (60%)\n",
      "[epoch 10] loss: 0.8159270\n",
      "Test set: Average loss: 1.2212, Accuracy: 2973/5000 (59%)\n",
      "[epoch 11] loss: 0.7539404\n",
      "Test set: Average loss: 1.1936, Accuracy: 2981/5000 (60%)\n",
      "[epoch 12] loss: 0.6651664\n",
      "Test set: Average loss: 1.2053, Accuracy: 3033/5000 (61%)\n",
      "[epoch 13] loss: 0.5804878\n",
      "Test set: Average loss: 1.2938, Accuracy: 3023/5000 (60%)\n",
      "[epoch 14] loss: 0.4795053\n",
      "Test set: Average loss: 1.3009, Accuracy: 3033/5000 (61%)\n",
      "[epoch 15] loss: 0.3878586\n",
      "Test set: Average loss: 1.3351, Accuracy: 3094/5000 (62%)\n",
      "[epoch 16] loss: 0.2900253\n",
      "Test set: Average loss: 1.4635, Accuracy: 3010/5000 (60%)\n",
      "[epoch 17] loss: 0.1917724\n",
      "Test set: Average loss: 1.5355, Accuracy: 3014/5000 (60%)\n",
      "[epoch 18] loss: 0.1498431\n",
      "Test set: Average loss: 1.6403, Accuracy: 3030/5000 (61%)\n",
      "[epoch 19] loss: 0.1012710\n",
      "Test set: Average loss: 1.7211, Accuracy: 3018/5000 (60%)\n",
      "[epoch 20] loss: 0.1066368\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8434, Accuracy: 3013/5000 (60%)\n",
      "[epoch 21] loss: 0.0436174\n",
      "Test set: Average loss: 1.7542, Accuracy: 3075/5000 (62%)\n",
      "[epoch 22] loss: 0.0164384\n",
      "Test set: Average loss: 1.7604, Accuracy: 3097/5000 (62%)\n",
      "[epoch 23] loss: 0.0115404\n",
      "Test set: Average loss: 1.7751, Accuracy: 3106/5000 (62%)\n",
      "[epoch 24] loss: 0.0088699\n",
      "Test set: Average loss: 1.7916, Accuracy: 3111/5000 (62%)\n",
      "[epoch 25] loss: 0.0070256\n",
      "Test set: Average loss: 1.8080, Accuracy: 3116/5000 (62%)\n",
      "[epoch 26] loss: 0.0056501\n",
      "Test set: Average loss: 1.8292, Accuracy: 3137/5000 (63%)\n",
      "[epoch 27] loss: 0.0045388\n",
      "Test set: Average loss: 1.8525, Accuracy: 3139/5000 (63%)\n",
      "[epoch 28] loss: 0.0036648\n",
      "Test set: Average loss: 1.8784, Accuracy: 3135/5000 (63%)\n",
      "[epoch 29] loss: 0.0029199\n",
      "Test set: Average loss: 1.9068, Accuracy: 3138/5000 (63%)\n",
      "[epoch 30] loss: 0.0023174\n",
      "Test set: Average loss: 1.9404, Accuracy: 3139/5000 (63%)\n",
      "[epoch 31] loss: 0.0018315\n",
      "Test set: Average loss: 1.9771, Accuracy: 3144/5000 (63%)\n",
      "[epoch 32] loss: 0.0014232\n",
      "Test set: Average loss: 2.0137, Accuracy: 3151/5000 (63%)\n",
      "[epoch 33] loss: 0.0011098\n",
      "Test set: Average loss: 2.0534, Accuracy: 3153/5000 (63%)\n",
      "[epoch 34] loss: 0.0008531\n",
      "Test set: Average loss: 2.0928, Accuracy: 3159/5000 (63%)\n",
      "[epoch 35] loss: 0.0006547\n",
      "Test set: Average loss: 2.1391, Accuracy: 3155/5000 (63%)\n",
      "[epoch 36] loss: 0.0004986\n",
      "Test set: Average loss: 2.1813, Accuracy: 3154/5000 (63%)\n",
      "[epoch 37] loss: 0.0003764\n",
      "Test set: Average loss: 2.2286, Accuracy: 3150/5000 (63%)\n",
      "[epoch 38] loss: 0.0002838\n",
      "Test set: Average loss: 2.2737, Accuracy: 3142/5000 (63%)\n",
      "[epoch 39] loss: 0.0002135\n",
      "Test set: Average loss: 2.3255, Accuracy: 3155/5000 (63%)\n",
      "[epoch 40] loss: 0.0001592\n",
      "Test set: Average loss: 2.3753, Accuracy: 3154/5000 (63%)\n",
      "[epoch 41] loss: 0.0001189\n",
      "Test set: Average loss: 2.4279, Accuracy: 3142/5000 (63%)\n",
      "[epoch 42] loss: 0.0000888\n",
      "Test set: Average loss: 2.4820, Accuracy: 3142/5000 (63%)\n",
      "[epoch 43] loss: 0.0000658\n",
      "Test set: Average loss: 2.5322, Accuracy: 3136/5000 (63%)\n",
      "[epoch 44] loss: 0.0000487\n",
      "Test set: Average loss: 2.5823, Accuracy: 3138/5000 (63%)\n",
      "[epoch 45] loss: 0.0000360\n",
      "Test set: Average loss: 2.6361, Accuracy: 3144/5000 (63%)\n",
      "[epoch 46] loss: 0.0000265\n",
      "Test set: Average loss: 2.6885, Accuracy: 3127/5000 (63%)\n",
      "[epoch 47] loss: 0.0000195\n",
      "Test set: Average loss: 2.7415, Accuracy: 3127/5000 (63%)\n",
      "[epoch 48] loss: 0.0000144\n",
      "Test set: Average loss: 2.7985, Accuracy: 3133/5000 (63%)\n",
      "[epoch 49] loss: 0.0000105\n",
      "Test set: Average loss: 2.8540, Accuracy: 3132/5000 (63%)\n",
      "[epoch 50] loss: 0.0000077\n",
      "Test set: Average loss: 2.9036, Accuracy: 3129/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0928, Accuracy: 3159/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.0748, Accuracy: 6322/10000 (63%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3075, Accuracy: 459/5000 (9%)\n",
      "[epoch 1] loss: 1.5484116\n",
      "Test set: Average loss: 1.5071, Accuracy: 2313/5000 (46%)\n",
      "[epoch 2] loss: 1.3067495\n",
      "Test set: Average loss: 1.3155, Accuracy: 2679/5000 (54%)\n",
      "[epoch 3] loss: 1.2113947\n",
      "Test set: Average loss: 1.2499, Accuracy: 2781/5000 (56%)\n",
      "[epoch 4] loss: 1.1519845\n",
      "Test set: Average loss: 1.2960, Accuracy: 2766/5000 (55%)\n",
      "[epoch 5] loss: 1.0968802\n",
      "Test set: Average loss: 1.2191, Accuracy: 2897/5000 (58%)\n",
      "[epoch 6] loss: 1.0375739\n",
      "Test set: Average loss: 1.1771, Accuracy: 2961/5000 (59%)\n",
      "[epoch 7] loss: 0.9838915\n",
      "Test set: Average loss: 1.1817, Accuracy: 2952/5000 (59%)\n",
      "[epoch 8] loss: 0.9202398\n",
      "Test set: Average loss: 1.2360, Accuracy: 2879/5000 (58%)\n",
      "[epoch 9] loss: 0.8551898\n",
      "Test set: Average loss: 1.1572, Accuracy: 3032/5000 (61%)\n",
      "[epoch 10] loss: 0.7772873\n",
      "Test set: Average loss: 1.1615, Accuracy: 3113/5000 (62%)\n",
      "[epoch 11] loss: 0.6927470\n",
      "Test set: Average loss: 1.1794, Accuracy: 3096/5000 (62%)\n",
      "[epoch 12] loss: 0.5917655\n",
      "Test set: Average loss: 1.2412, Accuracy: 3079/5000 (62%)\n",
      "[epoch 13] loss: 0.4888102\n",
      "Test set: Average loss: 1.3055, Accuracy: 3036/5000 (61%)\n",
      "[epoch 14] loss: 0.3710442\n",
      "Test set: Average loss: 1.3939, Accuracy: 3094/5000 (62%)\n",
      "[epoch 15] loss: 0.2630881\n",
      "Test set: Average loss: 1.5026, Accuracy: 3077/5000 (62%)\n",
      "[epoch 16] loss: 0.1889537\n",
      "Test set: Average loss: 1.6213, Accuracy: 3056/5000 (61%)\n",
      "[epoch 17] loss: 0.1473848\n",
      "Test set: Average loss: 1.7752, Accuracy: 2975/5000 (60%)\n",
      "[epoch 18] loss: 0.1386383\n",
      "Test set: Average loss: 1.8091, Accuracy: 3066/5000 (61%)\n",
      "[epoch 19] loss: 0.1300598\n",
      "Test set: Average loss: 1.9551, Accuracy: 3041/5000 (61%)\n",
      "[epoch 20] loss: 0.1174148\n",
      "Test set: Average loss: 1.9812, Accuracy: 3021/5000 (60%)\n",
      "[epoch 21] loss: 0.0944565\n",
      "Test set: Average loss: 2.1239, Accuracy: 2954/5000 (59%)\n",
      "[epoch 22] loss: 0.1143857\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1149, Accuracy: 3072/5000 (61%)\n",
      "[epoch 23] loss: 0.0368940\n",
      "Test set: Average loss: 2.0443, Accuracy: 3116/5000 (62%)\n",
      "[epoch 24] loss: 0.0106935\n",
      "Test set: Average loss: 2.0502, Accuracy: 3110/5000 (62%)\n",
      "[epoch 25] loss: 0.0069055\n",
      "Test set: Average loss: 2.0576, Accuracy: 3122/5000 (62%)\n",
      "[epoch 26] loss: 0.0050731\n",
      "Test set: Average loss: 2.0729, Accuracy: 3131/5000 (63%)\n",
      "[epoch 27] loss: 0.0038117\n",
      "Test set: Average loss: 2.0904, Accuracy: 3136/5000 (63%)\n",
      "[epoch 28] loss: 0.0029168\n",
      "Test set: Average loss: 2.1089, Accuracy: 3146/5000 (63%)\n",
      "[epoch 29] loss: 0.0022394\n",
      "Test set: Average loss: 2.1300, Accuracy: 3141/5000 (63%)\n",
      "[epoch 30] loss: 0.0016992\n",
      "Test set: Average loss: 2.1588, Accuracy: 3146/5000 (63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0012970\n",
      "Test set: Average loss: 2.1920, Accuracy: 3149/5000 (63%)\n",
      "[epoch 32] loss: 0.0009680\n",
      "Test set: Average loss: 2.2227, Accuracy: 3153/5000 (63%)\n",
      "[epoch 33] loss: 0.0007194\n",
      "Test set: Average loss: 2.2644, Accuracy: 3149/5000 (63%)\n",
      "[epoch 34] loss: 0.0005288\n",
      "Test set: Average loss: 2.3040, Accuracy: 3155/5000 (63%)\n",
      "[epoch 35] loss: 0.0003864\n",
      "Test set: Average loss: 2.3459, Accuracy: 3164/5000 (63%)\n",
      "[epoch 36] loss: 0.0002796\n",
      "Test set: Average loss: 2.3930, Accuracy: 3168/5000 (63%)\n",
      "[epoch 37] loss: 0.0002008\n",
      "Test set: Average loss: 2.4421, Accuracy: 3171/5000 (63%)\n",
      "[epoch 38] loss: 0.0001434\n",
      "Test set: Average loss: 2.4888, Accuracy: 3161/5000 (63%)\n",
      "[epoch 39] loss: 0.0001012\n",
      "Test set: Average loss: 2.5417, Accuracy: 3173/5000 (63%)\n",
      "[epoch 40] loss: 0.0000716\n",
      "Test set: Average loss: 2.5936, Accuracy: 3173/5000 (63%)\n",
      "[epoch 41] loss: 0.0000504\n",
      "Test set: Average loss: 2.6502, Accuracy: 3182/5000 (64%)\n",
      "[epoch 42] loss: 0.0000352\n",
      "Test set: Average loss: 2.7093, Accuracy: 3178/5000 (64%)\n",
      "[epoch 43] loss: 0.0000246\n",
      "Test set: Average loss: 2.7644, Accuracy: 3173/5000 (63%)\n",
      "[epoch 44] loss: 0.0000170\n",
      "Test set: Average loss: 2.8261, Accuracy: 3180/5000 (64%)\n",
      "[epoch 45] loss: 0.0000118\n",
      "Test set: Average loss: 2.8848, Accuracy: 3176/5000 (64%)\n",
      "[epoch 46] loss: 0.0000082\n",
      "Test set: Average loss: 2.9441, Accuracy: 3176/5000 (64%)\n",
      "[epoch 47] loss: 0.0000057\n",
      "Test set: Average loss: 2.9997, Accuracy: 3181/5000 (64%)\n",
      "[epoch 48] loss: 0.0000039\n",
      "Test set: Average loss: 3.0619, Accuracy: 3176/5000 (64%)\n",
      "[epoch 49] loss: 0.0000027\n",
      "Test set: Average loss: 3.1201, Accuracy: 3187/5000 (64%)\n",
      "[epoch 50] loss: 0.0000018\n",
      "Test set: Average loss: 3.1718, Accuracy: 3175/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1201, Accuracy: 3187/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.9993, Accuracy: 6373/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 455/5000 (9%)\n",
      "[epoch 1] loss: 1.5502075\n",
      "Test set: Average loss: 1.3271, Accuracy: 2597/5000 (52%)\n",
      "[epoch 2] loss: 1.2991273\n",
      "Test set: Average loss: 1.4001, Accuracy: 2518/5000 (50%)\n",
      "[epoch 3] loss: 1.2009257\n",
      "Test set: Average loss: 1.2672, Accuracy: 2775/5000 (56%)\n",
      "[epoch 4] loss: 1.1370852\n",
      "Test set: Average loss: 1.2267, Accuracy: 2834/5000 (57%)\n",
      "[epoch 5] loss: 1.0845426\n",
      "Test set: Average loss: 1.1653, Accuracy: 2952/5000 (59%)\n",
      "[epoch 6] loss: 1.0275419\n",
      "Test set: Average loss: 1.2047, Accuracy: 2896/5000 (58%)\n",
      "[epoch 7] loss: 0.9747674\n",
      "Test set: Average loss: 1.1527, Accuracy: 2983/5000 (60%)\n",
      "[epoch 8] loss: 0.9122354\n",
      "Test set: Average loss: 1.1139, Accuracy: 3130/5000 (63%)\n",
      "[epoch 9] loss: 0.8437351\n",
      "Test set: Average loss: 1.1511, Accuracy: 3042/5000 (61%)\n",
      "[epoch 10] loss: 0.7611058\n",
      "Test set: Average loss: 1.1479, Accuracy: 3084/5000 (62%)\n",
      "[epoch 11] loss: 0.6739170\n",
      "Test set: Average loss: 1.1887, Accuracy: 3077/5000 (62%)\n",
      "[epoch 12] loss: 0.5827715\n",
      "Test set: Average loss: 1.2172, Accuracy: 3045/5000 (61%)\n",
      "[epoch 13] loss: 0.4694087\n",
      "Test set: Average loss: 1.2623, Accuracy: 3112/5000 (62%)\n",
      "[epoch 14] loss: 0.3711552\n",
      "Test set: Average loss: 1.3824, Accuracy: 3059/5000 (61%)\n",
      "[epoch 15] loss: 0.2709223\n",
      "Test set: Average loss: 1.4453, Accuracy: 3100/5000 (62%)\n",
      "[epoch 16] loss: 0.1989292\n",
      "Test set: Average loss: 1.6077, Accuracy: 2981/5000 (60%)\n",
      "[epoch 17] loss: 0.1663026\n",
      "Test set: Average loss: 1.7126, Accuracy: 3003/5000 (60%)\n",
      "[epoch 18] loss: 0.1544649\n",
      "Test set: Average loss: 1.7683, Accuracy: 3038/5000 (61%)\n",
      "[epoch 19] loss: 0.1237462\n",
      "Test set: Average loss: 1.9535, Accuracy: 2973/5000 (59%)\n",
      "[epoch 20] loss: 0.1356332\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0366, Accuracy: 2953/5000 (59%)\n",
      "[epoch 21] loss: 0.0557319\n",
      "Test set: Average loss: 1.8448, Accuracy: 3092/5000 (62%)\n",
      "[epoch 22] loss: 0.0167679\n",
      "Test set: Average loss: 1.8451, Accuracy: 3108/5000 (62%)\n",
      "[epoch 23] loss: 0.0106368\n",
      "Test set: Average loss: 1.8537, Accuracy: 3118/5000 (62%)\n",
      "[epoch 24] loss: 0.0076990\n",
      "Test set: Average loss: 1.8699, Accuracy: 3132/5000 (63%)\n",
      "[epoch 25] loss: 0.0058047\n",
      "Test set: Average loss: 1.8894, Accuracy: 3146/5000 (63%)\n",
      "[epoch 26] loss: 0.0043882\n",
      "Test set: Average loss: 1.9151, Accuracy: 3152/5000 (63%)\n",
      "[epoch 27] loss: 0.0033266\n",
      "Test set: Average loss: 1.9448, Accuracy: 3157/5000 (63%)\n",
      "[epoch 28] loss: 0.0025228\n",
      "Test set: Average loss: 1.9760, Accuracy: 3165/5000 (63%)\n",
      "[epoch 29] loss: 0.0018851\n",
      "Test set: Average loss: 2.0156, Accuracy: 3169/5000 (63%)\n",
      "[epoch 30] loss: 0.0013992\n",
      "Test set: Average loss: 2.0547, Accuracy: 3154/5000 (63%)\n",
      "[epoch 31] loss: 0.0010293\n",
      "Test set: Average loss: 2.0931, Accuracy: 3164/5000 (63%)\n",
      "[epoch 32] loss: 0.0007523\n",
      "Test set: Average loss: 2.1420, Accuracy: 3160/5000 (63%)\n",
      "[epoch 33] loss: 0.0005437\n",
      "Test set: Average loss: 2.1854, Accuracy: 3159/5000 (63%)\n",
      "[epoch 34] loss: 0.0003900\n",
      "Test set: Average loss: 2.2385, Accuracy: 3152/5000 (63%)\n",
      "[epoch 35] loss: 0.0002814\n",
      "Test set: Average loss: 2.2910, Accuracy: 3169/5000 (63%)\n",
      "[epoch 36] loss: 0.0001988\n",
      "Test set: Average loss: 2.3473, Accuracy: 3166/5000 (63%)\n",
      "[epoch 37] loss: 0.0001402\n",
      "Test set: Average loss: 2.3960, Accuracy: 3168/5000 (63%)\n",
      "[epoch 38] loss: 0.0000984\n",
      "Test set: Average loss: 2.4632, Accuracy: 3159/5000 (63%)\n",
      "[epoch 39] loss: 0.0000695\n",
      "Test set: Average loss: 2.5129, Accuracy: 3178/5000 (64%)\n",
      "[epoch 40] loss: 0.0000484\n",
      "Test set: Average loss: 2.5656, Accuracy: 3176/5000 (64%)\n",
      "[epoch 41] loss: 0.0000337\n",
      "Test set: Average loss: 2.6266, Accuracy: 3171/5000 (63%)\n",
      "[epoch 42] loss: 0.0000234\n",
      "Test set: Average loss: 2.6914, Accuracy: 3168/5000 (63%)\n",
      "[epoch 43] loss: 0.0000162\n",
      "Test set: Average loss: 2.7439, Accuracy: 3169/5000 (63%)\n",
      "[epoch 44] loss: 0.0000112\n",
      "Test set: Average loss: 2.8086, Accuracy: 3177/5000 (64%)\n",
      "[epoch 45] loss: 0.0000077\n",
      "Test set: Average loss: 2.8657, Accuracy: 3174/5000 (63%)\n",
      "[epoch 46] loss: 0.0000053\n",
      "Test set: Average loss: 2.9225, Accuracy: 3174/5000 (63%)\n",
      "[epoch 47] loss: 0.0000036\n",
      "Test set: Average loss: 2.9837, Accuracy: 3179/5000 (64%)\n",
      "[epoch 48] loss: 0.0000025\n",
      "Test set: Average loss: 3.0464, Accuracy: 3174/5000 (63%)\n",
      "[epoch 49] loss: 0.0000017\n",
      "Test set: Average loss: 3.1005, Accuracy: 3176/5000 (64%)\n",
      "[epoch 50] loss: 0.0000012\n",
      "Test set: Average loss: 3.1502, Accuracy: 3174/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9837, Accuracy: 3179/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.9710, Accuracy: 6457/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3018, Accuracy: 518/5000 (10%)\n",
      "[epoch 1] loss: 1.5626189\n",
      "Test set: Average loss: 1.4821, Accuracy: 2310/5000 (46%)\n",
      "[epoch 2] loss: 1.3060743\n",
      "Test set: Average loss: 1.3375, Accuracy: 2614/5000 (52%)\n",
      "[epoch 3] loss: 1.2093359\n",
      "Test set: Average loss: 1.3680, Accuracy: 2571/5000 (51%)\n",
      "[epoch 4] loss: 1.1285253\n",
      "Test set: Average loss: 1.2194, Accuracy: 2867/5000 (57%)\n",
      "[epoch 5] loss: 1.0706032\n",
      "Test set: Average loss: 1.1848, Accuracy: 2946/5000 (59%)\n",
      "[epoch 6] loss: 1.0169586\n",
      "Test set: Average loss: 1.2316, Accuracy: 2849/5000 (57%)\n",
      "[epoch 7] loss: 0.9572110\n",
      "Test set: Average loss: 1.1666, Accuracy: 3030/5000 (61%)\n",
      "[epoch 8] loss: 0.8973214\n",
      "Test set: Average loss: 1.1505, Accuracy: 3043/5000 (61%)\n",
      "[epoch 9] loss: 0.8471242\n",
      "Test set: Average loss: 1.1840, Accuracy: 3022/5000 (60%)\n",
      "[epoch 10] loss: 0.7642361\n",
      "Test set: Average loss: 1.1687, Accuracy: 3070/5000 (61%)\n",
      "[epoch 11] loss: 0.6856423\n",
      "Test set: Average loss: 1.2099, Accuracy: 3066/5000 (61%)\n",
      "[epoch 12] loss: 0.5908865\n",
      "Test set: Average loss: 1.1823, Accuracy: 3132/5000 (63%)\n",
      "[epoch 13] loss: 0.4813686\n",
      "Test set: Average loss: 1.3259, Accuracy: 3060/5000 (61%)\n",
      "[epoch 14] loss: 0.3788619\n",
      "Test set: Average loss: 1.3681, Accuracy: 3088/5000 (62%)\n",
      "[epoch 15] loss: 0.2887006\n",
      "Test set: Average loss: 1.4902, Accuracy: 3015/5000 (60%)\n",
      "[epoch 16] loss: 0.2117511\n",
      "Test set: Average loss: 1.5861, Accuracy: 3025/5000 (60%)\n",
      "[epoch 17] loss: 0.1704835\n",
      "Test set: Average loss: 1.6732, Accuracy: 3086/5000 (62%)\n",
      "[epoch 18] loss: 0.1464454\n",
      "Test set: Average loss: 1.7374, Accuracy: 3117/5000 (62%)\n",
      "[epoch 19] loss: 0.1386151\n",
      "Test set: Average loss: 1.8489, Accuracy: 3037/5000 (61%)\n",
      "[epoch 20] loss: 0.1189673\n",
      "Test set: Average loss: 1.8416, Accuracy: 3083/5000 (62%)\n",
      "[epoch 21] loss: 0.1111495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.1178, Accuracy: 2982/5000 (60%)\n",
      "[epoch 22] loss: 0.1446031\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0514, Accuracy: 3058/5000 (61%)\n",
      "[epoch 23] loss: 0.0451832\n",
      "Test set: Average loss: 1.9051, Accuracy: 3159/5000 (63%)\n",
      "[epoch 24] loss: 0.0137800\n",
      "Test set: Average loss: 1.9115, Accuracy: 3159/5000 (63%)\n",
      "[epoch 25] loss: 0.0087114\n",
      "Test set: Average loss: 1.9235, Accuracy: 3176/5000 (64%)\n",
      "[epoch 26] loss: 0.0062574\n",
      "Test set: Average loss: 1.9393, Accuracy: 3182/5000 (64%)\n",
      "[epoch 27] loss: 0.0046785\n",
      "Test set: Average loss: 1.9565, Accuracy: 3188/5000 (64%)\n",
      "[epoch 28] loss: 0.0035473\n",
      "Test set: Average loss: 1.9754, Accuracy: 3194/5000 (64%)\n",
      "[epoch 29] loss: 0.0027001\n",
      "Test set: Average loss: 2.0051, Accuracy: 3203/5000 (64%)\n",
      "[epoch 30] loss: 0.0020336\n",
      "Test set: Average loss: 2.0390, Accuracy: 3212/5000 (64%)\n",
      "[epoch 31] loss: 0.0015336\n",
      "Test set: Average loss: 2.0703, Accuracy: 3213/5000 (64%)\n",
      "[epoch 32] loss: 0.0011454\n",
      "Test set: Average loss: 2.1034, Accuracy: 3211/5000 (64%)\n",
      "[epoch 33] loss: 0.0008489\n",
      "Test set: Average loss: 2.1411, Accuracy: 3212/5000 (64%)\n",
      "[epoch 34] loss: 0.0006253\n",
      "Test set: Average loss: 2.1844, Accuracy: 3210/5000 (64%)\n",
      "[epoch 35] loss: 0.0004541\n",
      "Test set: Average loss: 2.2276, Accuracy: 3219/5000 (64%)\n",
      "[epoch 36] loss: 0.0003283\n",
      "Test set: Average loss: 2.2779, Accuracy: 3213/5000 (64%)\n",
      "[epoch 37] loss: 0.0002350\n",
      "Test set: Average loss: 2.3212, Accuracy: 3204/5000 (64%)\n",
      "[epoch 38] loss: 0.0001679\n",
      "Test set: Average loss: 2.3772, Accuracy: 3218/5000 (64%)\n",
      "[epoch 39] loss: 0.0001188\n",
      "Test set: Average loss: 2.4277, Accuracy: 3224/5000 (64%)\n",
      "[epoch 40] loss: 0.0000838\n",
      "Test set: Average loss: 2.4771, Accuracy: 3214/5000 (64%)\n",
      "[epoch 41] loss: 0.0000588\n",
      "Test set: Average loss: 2.5347, Accuracy: 3221/5000 (64%)\n",
      "[epoch 42] loss: 0.0000412\n",
      "Test set: Average loss: 2.5890, Accuracy: 3222/5000 (64%)\n",
      "[epoch 43] loss: 0.0000288\n",
      "Test set: Average loss: 2.6453, Accuracy: 3224/5000 (64%)\n",
      "[epoch 44] loss: 0.0000201\n",
      "Test set: Average loss: 2.7036, Accuracy: 3223/5000 (64%)\n",
      "[epoch 45] loss: 0.0000140\n",
      "Test set: Average loss: 2.7595, Accuracy: 3209/5000 (64%)\n",
      "[epoch 46] loss: 0.0000097\n",
      "Test set: Average loss: 2.8177, Accuracy: 3228/5000 (65%)\n",
      "[epoch 47] loss: 0.0000067\n",
      "Test set: Average loss: 2.8759, Accuracy: 3219/5000 (64%)\n",
      "[epoch 48] loss: 0.0000046\n",
      "Test set: Average loss: 2.9311, Accuracy: 3219/5000 (64%)\n",
      "[epoch 49] loss: 0.0000032\n",
      "Test set: Average loss: 2.9937, Accuracy: 3220/5000 (64%)\n",
      "[epoch 50] loss: 0.0000022\n",
      "Test set: Average loss: 3.0479, Accuracy: 3215/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8177, Accuracy: 3228/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.7812, Accuracy: 6392/10000 (64%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3023, Accuracy: 533/5000 (11%)\n",
      "[epoch 1] loss: 1.5175533\n",
      "Test set: Average loss: 1.3515, Accuracy: 2566/5000 (51%)\n",
      "[epoch 2] loss: 1.2551304\n",
      "Test set: Average loss: 1.2320, Accuracy: 2815/5000 (56%)\n",
      "[epoch 3] loss: 1.1568850\n",
      "Test set: Average loss: 1.1814, Accuracy: 2923/5000 (58%)\n",
      "[epoch 4] loss: 1.0974106\n",
      "Test set: Average loss: 1.1567, Accuracy: 2963/5000 (59%)\n",
      "[epoch 5] loss: 1.0435467\n",
      "Test set: Average loss: 1.1712, Accuracy: 2953/5000 (59%)\n",
      "[epoch 6] loss: 0.9829836\n",
      "Test set: Average loss: 1.1062, Accuracy: 3072/5000 (61%)\n",
      "[epoch 7] loss: 0.9315437\n",
      "Test set: Average loss: 1.1214, Accuracy: 3077/5000 (62%)\n",
      "[epoch 8] loss: 0.8688026\n",
      "Test set: Average loss: 1.1341, Accuracy: 3121/5000 (62%)\n",
      "[epoch 9] loss: 0.8021117\n",
      "Test set: Average loss: 1.1185, Accuracy: 3113/5000 (62%)\n",
      "[epoch 10] loss: 0.7179247\n",
      "Test set: Average loss: 1.1187, Accuracy: 3119/5000 (62%)\n",
      "[epoch 11] loss: 0.6334830\n",
      "Test set: Average loss: 1.1551, Accuracy: 3133/5000 (63%)\n",
      "[epoch 12] loss: 0.5366134\n",
      "Test set: Average loss: 1.2058, Accuracy: 3140/5000 (63%)\n",
      "[epoch 13] loss: 0.4282083\n",
      "Test set: Average loss: 1.2976, Accuracy: 3104/5000 (62%)\n",
      "[epoch 14] loss: 0.3330068\n",
      "Test set: Average loss: 1.3008, Accuracy: 3148/5000 (63%)\n",
      "[epoch 15] loss: 0.2488935\n",
      "Test set: Average loss: 1.4427, Accuracy: 3096/5000 (62%)\n",
      "[epoch 16] loss: 0.2068054\n",
      "Test set: Average loss: 1.5577, Accuracy: 3143/5000 (63%)\n",
      "[epoch 17] loss: 0.1650192\n",
      "Test set: Average loss: 1.7454, Accuracy: 3087/5000 (62%)\n",
      "[epoch 18] loss: 0.1400118\n",
      "Test set: Average loss: 1.7630, Accuracy: 3100/5000 (62%)\n",
      "[epoch 19] loss: 0.1510119\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7916, Accuracy: 3144/5000 (63%)\n",
      "[epoch 20] loss: 0.0514688\n",
      "Test set: Average loss: 1.7013, Accuracy: 3198/5000 (64%)\n",
      "[epoch 21] loss: 0.0184726\n",
      "Test set: Average loss: 1.7004, Accuracy: 3217/5000 (64%)\n",
      "[epoch 22] loss: 0.0117515\n",
      "Test set: Average loss: 1.7261, Accuracy: 3217/5000 (64%)\n",
      "[epoch 23] loss: 0.0083031\n",
      "Test set: Average loss: 1.7505, Accuracy: 3213/5000 (64%)\n",
      "[epoch 24] loss: 0.0059755\n",
      "Test set: Average loss: 1.7758, Accuracy: 3222/5000 (64%)\n",
      "[epoch 25] loss: 0.0043526\n",
      "Test set: Average loss: 1.8089, Accuracy: 3222/5000 (64%)\n",
      "[epoch 26] loss: 0.0031304\n",
      "Test set: Average loss: 1.8427, Accuracy: 3229/5000 (65%)\n",
      "[epoch 27] loss: 0.0022443\n",
      "Test set: Average loss: 1.8884, Accuracy: 3234/5000 (65%)\n",
      "[epoch 28] loss: 0.0015808\n",
      "Test set: Average loss: 1.9219, Accuracy: 3224/5000 (64%)\n",
      "[epoch 29] loss: 0.0011029\n",
      "Test set: Average loss: 1.9741, Accuracy: 3231/5000 (65%)\n",
      "[epoch 30] loss: 0.0007620\n",
      "Test set: Average loss: 2.0251, Accuracy: 3239/5000 (65%)\n",
      "[epoch 31] loss: 0.0005213\n",
      "Test set: Average loss: 2.0740, Accuracy: 3235/5000 (65%)\n",
      "[epoch 32] loss: 0.0003546\n",
      "Test set: Average loss: 2.1307, Accuracy: 3247/5000 (65%)\n",
      "[epoch 33] loss: 0.0002400\n",
      "Test set: Average loss: 2.1973, Accuracy: 3236/5000 (65%)\n",
      "[epoch 34] loss: 0.0001615\n",
      "Test set: Average loss: 2.2549, Accuracy: 3252/5000 (65%)\n",
      "[epoch 35] loss: 0.0001084\n",
      "Test set: Average loss: 2.3186, Accuracy: 3244/5000 (65%)\n",
      "[epoch 36] loss: 0.0000718\n",
      "Test set: Average loss: 2.3813, Accuracy: 3259/5000 (65%)\n",
      "[epoch 37] loss: 0.0000475\n",
      "Test set: Average loss: 2.4465, Accuracy: 3251/5000 (65%)\n",
      "[epoch 38] loss: 0.0000313\n",
      "Test set: Average loss: 2.5095, Accuracy: 3248/5000 (65%)\n",
      "[epoch 39] loss: 0.0000206\n",
      "Test set: Average loss: 2.5731, Accuracy: 3252/5000 (65%)\n",
      "[epoch 40] loss: 0.0000135\n",
      "Test set: Average loss: 2.6764, Accuracy: 3251/5000 (65%)\n",
      "[epoch 41] loss: 0.0000088\n",
      "Test set: Average loss: 2.7115, Accuracy: 3247/5000 (65%)\n",
      "[epoch 42] loss: 0.0000057\n",
      "Test set: Average loss: 2.7691, Accuracy: 3237/5000 (65%)\n",
      "[epoch 43] loss: 0.0000037\n",
      "Test set: Average loss: 2.8410, Accuracy: 3239/5000 (65%)\n",
      "[epoch 44] loss: 0.0000024\n",
      "Test set: Average loss: 2.9078, Accuracy: 3235/5000 (65%)\n",
      "[epoch 45] loss: 0.0000016\n",
      "Test set: Average loss: 2.9662, Accuracy: 3245/5000 (65%)\n",
      "[epoch 46] loss: 0.0000010\n",
      "Test set: Average loss: 3.0263, Accuracy: 3237/5000 (65%)\n",
      "[epoch 47] loss: 0.0000006\n",
      "Test set: Average loss: 3.0562, Accuracy: 3246/5000 (65%)\n",
      "[epoch 48] loss: 0.0000004\n",
      "Test set: Average loss: 3.0790, Accuracy: 3236/5000 (65%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.0783, Accuracy: 3236/5000 (65%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0900, Accuracy: 3245/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3813, Accuracy: 3259/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.3851, Accuracy: 6572/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 523/5000 (10%)\n",
      "[epoch 1] loss: 1.5058372\n",
      "Test set: Average loss: 1.4110, Accuracy: 2492/5000 (50%)\n",
      "[epoch 2] loss: 1.2655924\n",
      "Test set: Average loss: 1.2628, Accuracy: 2756/5000 (55%)\n",
      "[epoch 3] loss: 1.1709211\n",
      "Test set: Average loss: 1.2245, Accuracy: 2845/5000 (57%)\n",
      "[epoch 4] loss: 1.1086954\n",
      "Test set: Average loss: 1.1799, Accuracy: 2895/5000 (58%)\n",
      "[epoch 5] loss: 1.0565303\n",
      "Test set: Average loss: 1.1626, Accuracy: 2956/5000 (59%)\n",
      "[epoch 6] loss: 0.9989796\n",
      "Test set: Average loss: 1.2069, Accuracy: 2892/5000 (58%)\n",
      "[epoch 7] loss: 0.9469603\n",
      "Test set: Average loss: 1.0948, Accuracy: 3084/5000 (62%)\n",
      "[epoch 8] loss: 0.8932397\n",
      "Test set: Average loss: 1.1037, Accuracy: 3070/5000 (61%)\n",
      "[epoch 9] loss: 0.8185533\n",
      "Test set: Average loss: 1.0989, Accuracy: 3154/5000 (63%)\n",
      "[epoch 10] loss: 0.7486955\n",
      "Test set: Average loss: 1.1204, Accuracy: 3130/5000 (63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] loss: 0.6660076\n",
      "Test set: Average loss: 1.1956, Accuracy: 3049/5000 (61%)\n",
      "[epoch 12] loss: 0.5677293\n",
      "Test set: Average loss: 1.1816, Accuracy: 3123/5000 (62%)\n",
      "[epoch 13] loss: 0.4737629\n",
      "Test set: Average loss: 1.2259, Accuracy: 3128/5000 (63%)\n",
      "[epoch 14] loss: 0.3710905\n",
      "Test set: Average loss: 1.2911, Accuracy: 3154/5000 (63%)\n",
      "[epoch 15] loss: 0.2783268\n",
      "Test set: Average loss: 1.3913, Accuracy: 3130/5000 (63%)\n",
      "[epoch 16] loss: 0.2069162\n",
      "Test set: Average loss: 1.4847, Accuracy: 3129/5000 (63%)\n",
      "[epoch 17] loss: 0.1779403\n",
      "Test set: Average loss: 1.6321, Accuracy: 3123/5000 (62%)\n",
      "[epoch 18] loss: 0.1471177\n",
      "Test set: Average loss: 1.7189, Accuracy: 3135/5000 (63%)\n",
      "[epoch 19] loss: 0.1423009\n",
      "Test set: Average loss: 1.8341, Accuracy: 3108/5000 (62%)\n",
      "[epoch 20] loss: 0.1344248\n",
      "Test set: Average loss: 1.8326, Accuracy: 3103/5000 (62%)\n",
      "[epoch 21] loss: 0.1191497\n",
      "Test set: Average loss: 1.8801, Accuracy: 3119/5000 (62%)\n",
      "[epoch 22] loss: 0.1404960\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9505, Accuracy: 3063/5000 (61%)\n",
      "[epoch 23] loss: 0.0473971\n",
      "Test set: Average loss: 1.8448, Accuracy: 3148/5000 (63%)\n",
      "[epoch 24] loss: 0.0135436\n",
      "Test set: Average loss: 1.8490, Accuracy: 3145/5000 (63%)\n",
      "[epoch 25] loss: 0.0081658\n",
      "Test set: Average loss: 1.8679, Accuracy: 3165/5000 (63%)\n",
      "[epoch 26] loss: 0.0057350\n",
      "Test set: Average loss: 1.8848, Accuracy: 3173/5000 (63%)\n",
      "[epoch 27] loss: 0.0041531\n",
      "Test set: Average loss: 1.9112, Accuracy: 3185/5000 (64%)\n",
      "[epoch 28] loss: 0.0030114\n",
      "Test set: Average loss: 1.9285, Accuracy: 3199/5000 (64%)\n",
      "[epoch 29] loss: 0.0021753\n",
      "Test set: Average loss: 1.9616, Accuracy: 3193/5000 (64%)\n",
      "[epoch 30] loss: 0.0015630\n",
      "Test set: Average loss: 1.9947, Accuracy: 3193/5000 (64%)\n",
      "[epoch 31] loss: 0.0011111\n",
      "Test set: Average loss: 2.0269, Accuracy: 3197/5000 (64%)\n",
      "[epoch 32] loss: 0.0007803\n",
      "Test set: Average loss: 2.0720, Accuracy: 3204/5000 (64%)\n",
      "[epoch 33] loss: 0.0005444\n",
      "Test set: Average loss: 2.1172, Accuracy: 3193/5000 (64%)\n",
      "[epoch 34] loss: 0.0003733\n",
      "Test set: Average loss: 2.1757, Accuracy: 3206/5000 (64%)\n",
      "[epoch 35] loss: 0.0002560\n",
      "Test set: Average loss: 2.2246, Accuracy: 3203/5000 (64%)\n",
      "[epoch 36] loss: 0.0001732\n",
      "Test set: Average loss: 2.2749, Accuracy: 3208/5000 (64%)\n",
      "[epoch 37] loss: 0.0001165\n",
      "Test set: Average loss: 2.3343, Accuracy: 3210/5000 (64%)\n",
      "[epoch 38] loss: 0.0000778\n",
      "Test set: Average loss: 2.3927, Accuracy: 3199/5000 (64%)\n",
      "[epoch 39] loss: 0.0000519\n",
      "Test set: Average loss: 2.4551, Accuracy: 3213/5000 (64%)\n",
      "[epoch 40] loss: 0.0000342\n",
      "Test set: Average loss: 2.5200, Accuracy: 3213/5000 (64%)\n",
      "[epoch 41] loss: 0.0000226\n",
      "Test set: Average loss: 2.5788, Accuracy: 3205/5000 (64%)\n",
      "[epoch 42] loss: 0.0000149\n",
      "Test set: Average loss: 2.6449, Accuracy: 3204/5000 (64%)\n",
      "[epoch 43] loss: 0.0000098\n",
      "Test set: Average loss: 2.7029, Accuracy: 3212/5000 (64%)\n",
      "[epoch 44] loss: 0.0000064\n",
      "Test set: Average loss: 2.7729, Accuracy: 3218/5000 (64%)\n",
      "[epoch 45] loss: 0.0000042\n",
      "Test set: Average loss: 2.8294, Accuracy: 3214/5000 (64%)\n",
      "[epoch 46] loss: 0.0000027\n",
      "Test set: Average loss: 2.8975, Accuracy: 3210/5000 (64%)\n",
      "[epoch 47] loss: 0.0000017\n",
      "Test set: Average loss: 2.9570, Accuracy: 3221/5000 (64%)\n",
      "[epoch 48] loss: 0.0000011\n",
      "Test set: Average loss: 3.0082, Accuracy: 3221/5000 (64%)\n",
      "[epoch 49] loss: 0.0000007\n",
      "Test set: Average loss: 3.0544, Accuracy: 3208/5000 (64%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.0751, Accuracy: 3216/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0082, Accuracy: 3221/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 3.0369, Accuracy: 6529/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3021, Accuracy: 479/5000 (10%)\n",
      "[epoch 1] loss: 1.5407475\n",
      "Test set: Average loss: 1.3465, Accuracy: 2574/5000 (51%)\n",
      "[epoch 2] loss: 1.2928012\n",
      "Test set: Average loss: 1.3428, Accuracy: 2627/5000 (53%)\n",
      "[epoch 3] loss: 1.2129495\n",
      "Test set: Average loss: 1.2638, Accuracy: 2760/5000 (55%)\n",
      "[epoch 4] loss: 1.1522549\n",
      "Test set: Average loss: 1.2138, Accuracy: 2829/5000 (57%)\n",
      "[epoch 5] loss: 1.0986828\n",
      "Test set: Average loss: 1.1924, Accuracy: 2907/5000 (58%)\n",
      "[epoch 6] loss: 1.0473964\n",
      "Test set: Average loss: 1.1792, Accuracy: 2903/5000 (58%)\n",
      "[epoch 7] loss: 0.9981989\n",
      "Test set: Average loss: 1.1278, Accuracy: 3015/5000 (60%)\n",
      "[epoch 8] loss: 0.9430040\n",
      "Test set: Average loss: 1.1197, Accuracy: 3083/5000 (62%)\n",
      "[epoch 9] loss: 0.8896060\n",
      "Test set: Average loss: 1.1616, Accuracy: 3012/5000 (60%)\n",
      "[epoch 10] loss: 0.8264975\n",
      "Test set: Average loss: 1.1471, Accuracy: 3017/5000 (60%)\n",
      "[epoch 11] loss: 0.7526902\n",
      "Test set: Average loss: 1.1366, Accuracy: 3101/5000 (62%)\n",
      "[epoch 12] loss: 0.6703495\n",
      "Test set: Average loss: 1.1711, Accuracy: 3131/5000 (63%)\n",
      "[epoch 13] loss: 0.5898592\n",
      "Test set: Average loss: 1.1726, Accuracy: 3154/5000 (63%)\n",
      "[epoch 14] loss: 0.4837034\n",
      "Test set: Average loss: 1.2545, Accuracy: 3133/5000 (63%)\n",
      "[epoch 15] loss: 0.3952653\n",
      "Test set: Average loss: 1.3464, Accuracy: 3090/5000 (62%)\n",
      "[epoch 16] loss: 0.2993406\n",
      "Test set: Average loss: 1.4179, Accuracy: 3151/5000 (63%)\n",
      "[epoch 17] loss: 0.2227053\n",
      "Test set: Average loss: 1.5305, Accuracy: 3121/5000 (62%)\n",
      "[epoch 18] loss: 0.1782713\n",
      "Test set: Average loss: 1.6045, Accuracy: 3112/5000 (62%)\n",
      "[epoch 19] loss: 0.1491320\n",
      "Test set: Average loss: 1.6571, Accuracy: 3152/5000 (63%)\n",
      "[epoch 20] loss: 0.1585647\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7682, Accuracy: 3091/5000 (62%)\n",
      "[epoch 21] loss: 0.0531429\n",
      "Test set: Average loss: 1.6683, Accuracy: 3199/5000 (64%)\n",
      "[epoch 22] loss: 0.0206409\n",
      "Test set: Average loss: 1.6816, Accuracy: 3197/5000 (64%)\n",
      "[epoch 23] loss: 0.0132921\n",
      "Test set: Average loss: 1.7053, Accuracy: 3211/5000 (64%)\n",
      "[epoch 24] loss: 0.0094789\n",
      "Test set: Average loss: 1.7373, Accuracy: 3211/5000 (64%)\n",
      "[epoch 25] loss: 0.0069122\n",
      "Test set: Average loss: 1.7647, Accuracy: 3225/5000 (64%)\n",
      "[epoch 26] loss: 0.0050656\n",
      "Test set: Average loss: 1.8014, Accuracy: 3237/5000 (65%)\n",
      "[epoch 27] loss: 0.0036659\n",
      "Test set: Average loss: 1.8468, Accuracy: 3238/5000 (65%)\n",
      "[epoch 28] loss: 0.0026364\n",
      "Test set: Average loss: 1.8866, Accuracy: 3225/5000 (64%)\n",
      "[epoch 29] loss: 0.0018722\n",
      "Test set: Average loss: 1.9404, Accuracy: 3237/5000 (65%)\n",
      "[epoch 30] loss: 0.0013171\n",
      "Test set: Average loss: 1.9863, Accuracy: 3243/5000 (65%)\n",
      "[epoch 31] loss: 0.0009197\n",
      "Test set: Average loss: 2.0450, Accuracy: 3241/5000 (65%)\n",
      "[epoch 32] loss: 0.0006380\n",
      "Test set: Average loss: 2.0967, Accuracy: 3239/5000 (65%)\n",
      "[epoch 33] loss: 0.0004371\n",
      "Test set: Average loss: 2.1550, Accuracy: 3248/5000 (65%)\n",
      "[epoch 34] loss: 0.0002991\n",
      "Test set: Average loss: 2.2168, Accuracy: 3252/5000 (65%)\n",
      "[epoch 35] loss: 0.0002044\n",
      "Test set: Average loss: 2.2820, Accuracy: 3265/5000 (65%)\n",
      "[epoch 36] loss: 0.0001372\n",
      "Test set: Average loss: 2.3435, Accuracy: 3246/5000 (65%)\n",
      "[epoch 37] loss: 0.0000923\n",
      "Test set: Average loss: 2.4034, Accuracy: 3242/5000 (65%)\n",
      "[epoch 38] loss: 0.0000620\n",
      "Test set: Average loss: 2.4790, Accuracy: 3255/5000 (65%)\n",
      "[epoch 39] loss: 0.0000416\n",
      "Test set: Average loss: 2.5417, Accuracy: 3262/5000 (65%)\n",
      "[epoch 40] loss: 0.0000275\n",
      "Test set: Average loss: 2.6125, Accuracy: 3259/5000 (65%)\n",
      "[epoch 41] loss: 0.0000183\n",
      "Test set: Average loss: 2.6838, Accuracy: 3263/5000 (65%)\n",
      "[epoch 42] loss: 0.0000121\n",
      "Test set: Average loss: 2.7554, Accuracy: 3267/5000 (65%)\n",
      "[epoch 43] loss: 0.0000080\n",
      "Test set: Average loss: 2.8187, Accuracy: 3260/5000 (65%)\n",
      "[epoch 44] loss: 0.0000052\n",
      "Test set: Average loss: 2.8904, Accuracy: 3264/5000 (65%)\n",
      "[epoch 45] loss: 0.0000034\n",
      "Test set: Average loss: 2.9626, Accuracy: 3256/5000 (65%)\n",
      "[epoch 46] loss: 0.0000022\n",
      "Test set: Average loss: 3.0267, Accuracy: 3256/5000 (65%)\n",
      "[epoch 47] loss: 0.0000015\n",
      "Test set: Average loss: 3.0847, Accuracy: 3262/5000 (65%)\n",
      "[epoch 48] loss: 0.0000009\n",
      "Test set: Average loss: 3.1469, Accuracy: 3260/5000 (65%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 3.1802, Accuracy: 3267/5000 (65%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.2011, Accuracy: 3265/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1802, Accuracy: 3267/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 3.1403, Accuracy: 6529/10000 (65%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3049, Accuracy: 551/5000 (11%)\n",
      "[epoch 1] loss: 1.5117683\n",
      "Test set: Average loss: 1.3584, Accuracy: 2550/5000 (51%)\n",
      "[epoch 2] loss: 1.2504555\n",
      "Test set: Average loss: 1.2999, Accuracy: 2718/5000 (54%)\n",
      "[epoch 3] loss: 1.1465520\n",
      "Test set: Average loss: 1.1620, Accuracy: 2924/5000 (58%)\n",
      "[epoch 4] loss: 1.0711618\n",
      "Test set: Average loss: 1.1344, Accuracy: 3025/5000 (60%)\n",
      "[epoch 5] loss: 1.0052880\n",
      "Test set: Average loss: 1.1104, Accuracy: 3070/5000 (61%)\n",
      "[epoch 6] loss: 0.9467859\n",
      "Test set: Average loss: 1.1052, Accuracy: 3058/5000 (61%)\n",
      "[epoch 7] loss: 0.8888623\n",
      "Test set: Average loss: 1.1117, Accuracy: 3071/5000 (61%)\n",
      "[epoch 8] loss: 0.8263773\n",
      "Test set: Average loss: 1.0927, Accuracy: 3149/5000 (63%)\n",
      "[epoch 9] loss: 0.7479835\n",
      "Test set: Average loss: 1.0628, Accuracy: 3214/5000 (64%)\n",
      "[epoch 10] loss: 0.6718677\n",
      "Test set: Average loss: 1.0865, Accuracy: 3182/5000 (64%)\n",
      "[epoch 11] loss: 0.5784373\n",
      "Test set: Average loss: 1.1433, Accuracy: 3206/5000 (64%)\n",
      "[epoch 12] loss: 0.4895564\n",
      "Test set: Average loss: 1.1603, Accuracy: 3226/5000 (65%)\n",
      "[epoch 13] loss: 0.4010225\n",
      "Test set: Average loss: 1.2465, Accuracy: 3229/5000 (65%)\n",
      "[epoch 14] loss: 0.3163029\n",
      "Test set: Average loss: 1.3485, Accuracy: 3193/5000 (64%)\n",
      "[epoch 15] loss: 0.2555706\n",
      "Test set: Average loss: 1.4882, Accuracy: 3170/5000 (63%)\n",
      "[epoch 16] loss: 0.2230426\n",
      "Test set: Average loss: 1.5105, Accuracy: 3187/5000 (64%)\n",
      "[epoch 17] loss: 0.1947476\n",
      "Test set: Average loss: 1.5578, Accuracy: 3194/5000 (64%)\n",
      "[epoch 18] loss: 0.1767375\n",
      "Test set: Average loss: 1.6888, Accuracy: 3141/5000 (63%)\n",
      "[epoch 19] loss: 0.1713588\n",
      "Test set: Average loss: 1.7536, Accuracy: 3132/5000 (63%)\n",
      "[epoch 20] loss: 0.1482083\n",
      "Test set: Average loss: 1.9040, Accuracy: 3125/5000 (62%)\n",
      "[epoch 21] loss: 0.1600055\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9051, Accuracy: 3137/5000 (63%)\n",
      "[epoch 22] loss: 0.0629642\n",
      "Test set: Average loss: 1.7623, Accuracy: 3245/5000 (65%)\n",
      "[epoch 23] loss: 0.0194782\n",
      "Test set: Average loss: 1.7679, Accuracy: 3254/5000 (65%)\n",
      "[epoch 24] loss: 0.0111814\n",
      "Test set: Average loss: 1.7861, Accuracy: 3267/5000 (65%)\n",
      "[epoch 25] loss: 0.0073943\n",
      "Test set: Average loss: 1.8081, Accuracy: 3287/5000 (66%)\n",
      "[epoch 26] loss: 0.0051199\n",
      "Test set: Average loss: 1.8390, Accuracy: 3292/5000 (66%)\n",
      "[epoch 27] loss: 0.0035097\n",
      "Test set: Average loss: 1.8718, Accuracy: 3281/5000 (66%)\n",
      "[epoch 28] loss: 0.0024058\n",
      "Test set: Average loss: 1.9194, Accuracy: 3301/5000 (66%)\n",
      "[epoch 29] loss: 0.0016321\n",
      "Test set: Average loss: 1.9679, Accuracy: 3305/5000 (66%)\n",
      "[epoch 30] loss: 0.0010912\n",
      "Test set: Average loss: 2.0166, Accuracy: 3304/5000 (66%)\n",
      "[epoch 31] loss: 0.0007229\n",
      "Test set: Average loss: 2.0772, Accuracy: 3302/5000 (66%)\n",
      "[epoch 32] loss: 0.0004726\n",
      "Test set: Average loss: 2.1399, Accuracy: 3306/5000 (66%)\n",
      "[epoch 33] loss: 0.0003065\n",
      "Test set: Average loss: 2.2053, Accuracy: 3307/5000 (66%)\n",
      "[epoch 34] loss: 0.0001981\n",
      "Test set: Average loss: 2.2662, Accuracy: 3307/5000 (66%)\n",
      "[epoch 35] loss: 0.0001264\n",
      "Test set: Average loss: 2.3359, Accuracy: 3306/5000 (66%)\n",
      "[epoch 36] loss: 0.0000803\n",
      "Test set: Average loss: 2.4078, Accuracy: 3304/5000 (66%)\n",
      "[epoch 37] loss: 0.0000514\n",
      "Test set: Average loss: 2.4800, Accuracy: 3306/5000 (66%)\n",
      "[epoch 38] loss: 0.0000329\n",
      "Test set: Average loss: 2.5467, Accuracy: 3301/5000 (66%)\n",
      "[epoch 39] loss: 0.0000203\n",
      "Test set: Average loss: 2.6269, Accuracy: 3301/5000 (66%)\n",
      "[epoch 40] loss: 0.0000126\n",
      "Test set: Average loss: 2.6942, Accuracy: 3300/5000 (66%)\n",
      "[epoch 41] loss: 0.0000079\n",
      "Test set: Average loss: 2.7735, Accuracy: 3307/5000 (66%)\n",
      "[epoch 42] loss: 0.0000049\n",
      "Test set: Average loss: 2.8503, Accuracy: 3300/5000 (66%)\n",
      "[epoch 43] loss: 0.0000031\n",
      "Test set: Average loss: 2.9674, Accuracy: 3302/5000 (66%)\n",
      "[epoch 44] loss: 0.0000019\n",
      "Test set: Average loss: 2.9962, Accuracy: 3295/5000 (66%)\n",
      "[epoch 45] loss: 0.0000011\n",
      "Test set: Average loss: 3.0575, Accuracy: 3293/5000 (66%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Test set: Average loss: 3.1076, Accuracy: 3303/5000 (66%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 3.1383, Accuracy: 3295/5000 (66%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.1598, Accuracy: 3284/5000 (66%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.1600, Accuracy: 3290/5000 (66%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.1707, Accuracy: 3282/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7735, Accuracy: 3307/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.6821, Accuracy: 6697/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 502/5000 (10%)\n",
      "[epoch 1] loss: 1.4850237\n",
      "Test set: Average loss: 1.3060, Accuracy: 2667/5000 (53%)\n",
      "[epoch 2] loss: 1.2381573\n",
      "Test set: Average loss: 1.2386, Accuracy: 2849/5000 (57%)\n",
      "[epoch 3] loss: 1.1476306\n",
      "Test set: Average loss: 1.2157, Accuracy: 2862/5000 (57%)\n",
      "[epoch 4] loss: 1.0880201\n",
      "Test set: Average loss: 1.1552, Accuracy: 2930/5000 (59%)\n",
      "[epoch 5] loss: 1.0321281\n",
      "Test set: Average loss: 1.1427, Accuracy: 3009/5000 (60%)\n",
      "[epoch 6] loss: 0.9770585\n",
      "Test set: Average loss: 1.0907, Accuracy: 3099/5000 (62%)\n",
      "[epoch 7] loss: 0.9328253\n",
      "Test set: Average loss: 1.0575, Accuracy: 3154/5000 (63%)\n",
      "[epoch 8] loss: 0.8811751\n",
      "Test set: Average loss: 1.0616, Accuracy: 3129/5000 (63%)\n",
      "[epoch 9] loss: 0.8219672\n",
      "Test set: Average loss: 1.0797, Accuracy: 3164/5000 (63%)\n",
      "[epoch 10] loss: 0.7677900\n",
      "Test set: Average loss: 1.0869, Accuracy: 3181/5000 (64%)\n",
      "[epoch 11] loss: 0.6911204\n",
      "Test set: Average loss: 1.1409, Accuracy: 3160/5000 (63%)\n",
      "[epoch 12] loss: 0.6086447\n",
      "Test set: Average loss: 1.1360, Accuracy: 3190/5000 (64%)\n",
      "[epoch 13] loss: 0.5211349\n",
      "Test set: Average loss: 1.2028, Accuracy: 3175/5000 (64%)\n",
      "[epoch 14] loss: 0.4301040\n",
      "Test set: Average loss: 1.2386, Accuracy: 3149/5000 (63%)\n",
      "[epoch 15] loss: 0.3509885\n",
      "Test set: Average loss: 1.3527, Accuracy: 3091/5000 (62%)\n",
      "[epoch 16] loss: 0.2772222\n",
      "Test set: Average loss: 1.4231, Accuracy: 3169/5000 (63%)\n",
      "[epoch 17] loss: 0.2219653\n",
      "Test set: Average loss: 1.4840, Accuracy: 3139/5000 (63%)\n",
      "[epoch 18] loss: 0.2075822\n",
      "Test set: Average loss: 1.6143, Accuracy: 3156/5000 (63%)\n",
      "[epoch 19] loss: 0.1665322\n",
      "Test set: Average loss: 1.6860, Accuracy: 3134/5000 (63%)\n",
      "[epoch 20] loss: 0.1698931\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6796, Accuracy: 3141/5000 (63%)\n",
      "[epoch 21] loss: 0.0572895\n",
      "Test set: Average loss: 1.6180, Accuracy: 3250/5000 (65%)\n",
      "[epoch 22] loss: 0.0214603\n",
      "Test set: Average loss: 1.6310, Accuracy: 3264/5000 (65%)\n",
      "[epoch 23] loss: 0.0132808\n",
      "Test set: Average loss: 1.6568, Accuracy: 3261/5000 (65%)\n",
      "[epoch 24] loss: 0.0090209\n",
      "Test set: Average loss: 1.6826, Accuracy: 3283/5000 (66%)\n",
      "[epoch 25] loss: 0.0062860\n",
      "Test set: Average loss: 1.7157, Accuracy: 3285/5000 (66%)\n",
      "[epoch 26] loss: 0.0043806\n",
      "Test set: Average loss: 1.7584, Accuracy: 3299/5000 (66%)\n",
      "[epoch 27] loss: 0.0030042\n",
      "Test set: Average loss: 1.8022, Accuracy: 3321/5000 (66%)\n",
      "[epoch 28] loss: 0.0020559\n",
      "Test set: Average loss: 1.8565, Accuracy: 3318/5000 (66%)\n",
      "[epoch 29] loss: 0.0013739\n",
      "Test set: Average loss: 1.9101, Accuracy: 3299/5000 (66%)\n",
      "[epoch 30] loss: 0.0009061\n",
      "Test set: Average loss: 1.9683, Accuracy: 3320/5000 (66%)\n",
      "[epoch 31] loss: 0.0005993\n",
      "Test set: Average loss: 2.0341, Accuracy: 3314/5000 (66%)\n",
      "[epoch 32] loss: 0.0003902\n",
      "Test set: Average loss: 2.0971, Accuracy: 3314/5000 (66%)\n",
      "[epoch 33] loss: 0.0002515\n",
      "Test set: Average loss: 2.1663, Accuracy: 3307/5000 (66%)\n",
      "[epoch 34] loss: 0.0001619\n",
      "Test set: Average loss: 2.2383, Accuracy: 3310/5000 (66%)\n",
      "[epoch 35] loss: 0.0001037\n",
      "Test set: Average loss: 2.3047, Accuracy: 3306/5000 (66%)\n",
      "[epoch 36] loss: 0.0000658\n",
      "Test set: Average loss: 2.3846, Accuracy: 3302/5000 (66%)\n",
      "[epoch 37] loss: 0.0000418\n",
      "Test set: Average loss: 2.4590, Accuracy: 3305/5000 (66%)\n",
      "[epoch 38] loss: 0.0000264\n",
      "Test set: Average loss: 2.5324, Accuracy: 3305/5000 (66%)\n",
      "[epoch 39] loss: 0.0000164\n",
      "Test set: Average loss: 2.6093, Accuracy: 3299/5000 (66%)\n",
      "[epoch 40] loss: 0.0000103\n",
      "Test set: Average loss: 2.6958, Accuracy: 3289/5000 (66%)\n",
      "[epoch 41] loss: 0.0000064\n",
      "Test set: Average loss: 2.7739, Accuracy: 3295/5000 (66%)\n",
      "[epoch 42] loss: 0.0000040\n",
      "Test set: Average loss: 2.8488, Accuracy: 3286/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 43] loss: 0.0000024\n",
      "Test set: Average loss: 2.9203, Accuracy: 3300/5000 (66%)\n",
      "[epoch 44] loss: 0.0000015\n",
      "Test set: Average loss: 2.9995, Accuracy: 3286/5000 (66%)\n",
      "[epoch 45] loss: 0.0000009\n",
      "Test set: Average loss: 3.0598, Accuracy: 3283/5000 (66%)\n",
      "[epoch 46] loss: 0.0000006\n",
      "Test set: Average loss: 3.0966, Accuracy: 3294/5000 (66%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 3.1200, Accuracy: 3284/5000 (66%)\n",
      "[epoch 48] loss: 0.0004615\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2385, Accuracy: 3228/5000 (65%)\n",
      "[epoch 49] loss: 0.0006889\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.1944, Accuracy: 3262/5000 (65%)\n",
      "[epoch 50] loss: 0.0000741\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.1935, Accuracy: 3264/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8022, Accuracy: 3321/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.8373, Accuracy: 6535/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 526/5000 (11%)\n",
      "[epoch 1] loss: 1.5168931\n",
      "Test set: Average loss: 1.3967, Accuracy: 2510/5000 (50%)\n",
      "[epoch 2] loss: 1.2727260\n",
      "Test set: Average loss: 1.3336, Accuracy: 2587/5000 (52%)\n",
      "[epoch 3] loss: 1.1705789\n",
      "Test set: Average loss: 1.1850, Accuracy: 2909/5000 (58%)\n",
      "[epoch 4] loss: 1.0945822\n",
      "Test set: Average loss: 1.1665, Accuracy: 2962/5000 (59%)\n",
      "[epoch 5] loss: 1.0367568\n",
      "Test set: Average loss: 1.1292, Accuracy: 3031/5000 (61%)\n",
      "[epoch 6] loss: 0.9782786\n",
      "Test set: Average loss: 1.0873, Accuracy: 3113/5000 (62%)\n",
      "[epoch 7] loss: 0.9179695\n",
      "Test set: Average loss: 1.1074, Accuracy: 3065/5000 (61%)\n",
      "[epoch 8] loss: 0.8510951\n",
      "Test set: Average loss: 1.0691, Accuracy: 3157/5000 (63%)\n",
      "[epoch 9] loss: 0.7864816\n",
      "Test set: Average loss: 1.0899, Accuracy: 3147/5000 (63%)\n",
      "[epoch 10] loss: 0.7093535\n",
      "Test set: Average loss: 1.0735, Accuracy: 3155/5000 (63%)\n",
      "[epoch 11] loss: 0.6239168\n",
      "Test set: Average loss: 1.1526, Accuracy: 3172/5000 (63%)\n",
      "[epoch 12] loss: 0.5345454\n",
      "Test set: Average loss: 1.2348, Accuracy: 3150/5000 (63%)\n",
      "[epoch 13] loss: 0.4390958\n",
      "Test set: Average loss: 1.2362, Accuracy: 3187/5000 (64%)\n",
      "[epoch 14] loss: 0.3499430\n",
      "Test set: Average loss: 1.3454, Accuracy: 3165/5000 (63%)\n",
      "[epoch 15] loss: 0.2778473\n",
      "Test set: Average loss: 1.3689, Accuracy: 3194/5000 (64%)\n",
      "[epoch 16] loss: 0.2341772\n",
      "Test set: Average loss: 1.5454, Accuracy: 3136/5000 (63%)\n",
      "[epoch 17] loss: 0.1982411\n",
      "Test set: Average loss: 1.6179, Accuracy: 3126/5000 (63%)\n",
      "[epoch 18] loss: 0.1833433\n",
      "Test set: Average loss: 1.7212, Accuracy: 3147/5000 (63%)\n",
      "[epoch 19] loss: 0.1720710\n",
      "Test set: Average loss: 1.7035, Accuracy: 3118/5000 (62%)\n",
      "[epoch 20] loss: 0.1591903\n",
      "Test set: Average loss: 1.8831, Accuracy: 3058/5000 (61%)\n",
      "[epoch 21] loss: 0.1603050\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9177, Accuracy: 3114/5000 (62%)\n",
      "[epoch 22] loss: 0.0535823\n",
      "Test set: Average loss: 1.7734, Accuracy: 3212/5000 (64%)\n",
      "[epoch 23] loss: 0.0169088\n",
      "Test set: Average loss: 1.7902, Accuracy: 3228/5000 (65%)\n",
      "[epoch 24] loss: 0.0101138\n",
      "Test set: Average loss: 1.8081, Accuracy: 3233/5000 (65%)\n",
      "[epoch 25] loss: 0.0068931\n",
      "Test set: Average loss: 1.8355, Accuracy: 3249/5000 (65%)\n",
      "[epoch 26] loss: 0.0047903\n",
      "Test set: Average loss: 1.8703, Accuracy: 3237/5000 (65%)\n",
      "[epoch 27] loss: 0.0033143\n",
      "Test set: Average loss: 1.9080, Accuracy: 3239/5000 (65%)\n",
      "[epoch 28] loss: 0.0022566\n",
      "Test set: Average loss: 1.9501, Accuracy: 3244/5000 (65%)\n",
      "[epoch 29] loss: 0.0015200\n",
      "Test set: Average loss: 1.9997, Accuracy: 3246/5000 (65%)\n",
      "[epoch 30] loss: 0.0010060\n",
      "Test set: Average loss: 2.0549, Accuracy: 3251/5000 (65%)\n",
      "[epoch 31] loss: 0.0006583\n",
      "Test set: Average loss: 2.1124, Accuracy: 3252/5000 (65%)\n",
      "[epoch 32] loss: 0.0004270\n",
      "Test set: Average loss: 2.1744, Accuracy: 3255/5000 (65%)\n",
      "[epoch 33] loss: 0.0002750\n",
      "Test set: Average loss: 2.2403, Accuracy: 3263/5000 (65%)\n",
      "[epoch 34] loss: 0.0001748\n",
      "Test set: Average loss: 2.3039, Accuracy: 3255/5000 (65%)\n",
      "[epoch 35] loss: 0.0001112\n",
      "Test set: Average loss: 2.3699, Accuracy: 3260/5000 (65%)\n",
      "[epoch 36] loss: 0.0000699\n",
      "Test set: Average loss: 2.4464, Accuracy: 3250/5000 (65%)\n",
      "[epoch 37] loss: 0.0000437\n",
      "Test set: Average loss: 2.5110, Accuracy: 3260/5000 (65%)\n",
      "[epoch 38] loss: 0.0000272\n",
      "Test set: Average loss: 2.5990, Accuracy: 3262/5000 (65%)\n",
      "[epoch 39] loss: 0.0000170\n",
      "Test set: Average loss: 2.6711, Accuracy: 3264/5000 (65%)\n",
      "[epoch 40] loss: 0.0000105\n",
      "Test set: Average loss: 2.7499, Accuracy: 3256/5000 (65%)\n",
      "[epoch 41] loss: 0.0000065\n",
      "Test set: Average loss: 2.8195, Accuracy: 3262/5000 (65%)\n",
      "[epoch 42] loss: 0.0000040\n",
      "Test set: Average loss: 2.9005, Accuracy: 3268/5000 (65%)\n",
      "[epoch 43] loss: 0.0000024\n",
      "Test set: Average loss: 2.9707, Accuracy: 3268/5000 (65%)\n",
      "[epoch 44] loss: 0.0000015\n",
      "Test set: Average loss: 3.0434, Accuracy: 3265/5000 (65%)\n",
      "[epoch 45] loss: 0.0000009\n",
      "Test set: Average loss: 3.1017, Accuracy: 3270/5000 (65%)\n",
      "[epoch 46] loss: 0.0000005\n",
      "Test set: Average loss: 3.1446, Accuracy: 3248/5000 (65%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 3.1587, Accuracy: 3264/5000 (65%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.1741, Accuracy: 3256/5000 (65%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.1806, Accuracy: 3245/5000 (65%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.1947, Accuracy: 3254/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1017, Accuracy: 3270/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 3.0551, Accuracy: 6615/10000 (66%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3001, Accuracy: 668/5000 (13%)\n",
      "[epoch 1] loss: 1.4824955\n",
      "Test set: Average loss: 1.3137, Accuracy: 2671/5000 (53%)\n",
      "[epoch 2] loss: 1.2158142\n",
      "Test set: Average loss: 1.1931, Accuracy: 2848/5000 (57%)\n",
      "[epoch 3] loss: 1.1080834\n",
      "Test set: Average loss: 1.1155, Accuracy: 3008/5000 (60%)\n",
      "[epoch 4] loss: 1.0305818\n",
      "Test set: Average loss: 1.0799, Accuracy: 3101/5000 (62%)\n",
      "[epoch 5] loss: 0.9725431\n",
      "Test set: Average loss: 1.0489, Accuracy: 3149/5000 (63%)\n",
      "[epoch 6] loss: 0.9130454\n",
      "Test set: Average loss: 1.0773, Accuracy: 3141/5000 (63%)\n",
      "[epoch 7] loss: 0.8542963\n",
      "Test set: Average loss: 1.0135, Accuracy: 3264/5000 (65%)\n",
      "[epoch 8] loss: 0.7899404\n",
      "Test set: Average loss: 1.0448, Accuracy: 3232/5000 (65%)\n",
      "[epoch 9] loss: 0.7247345\n",
      "Test set: Average loss: 1.1101, Accuracy: 3208/5000 (64%)\n",
      "[epoch 10] loss: 0.6509338\n",
      "Test set: Average loss: 1.0331, Accuracy: 3297/5000 (66%)\n",
      "[epoch 11] loss: 0.5750844\n",
      "Test set: Average loss: 1.0577, Accuracy: 3340/5000 (67%)\n",
      "[epoch 12] loss: 0.5012193\n",
      "Test set: Average loss: 1.1232, Accuracy: 3312/5000 (66%)\n",
      "[epoch 13] loss: 0.4289667\n",
      "Test set: Average loss: 1.1650, Accuracy: 3306/5000 (66%)\n",
      "[epoch 14] loss: 0.3512252\n",
      "Test set: Average loss: 1.2230, Accuracy: 3312/5000 (66%)\n",
      "[epoch 15] loss: 0.3000349\n",
      "Test set: Average loss: 1.3365, Accuracy: 3275/5000 (66%)\n",
      "[epoch 16] loss: 0.2665973\n",
      "Test set: Average loss: 1.4025, Accuracy: 3273/5000 (65%)\n",
      "[epoch 17] loss: 0.2341417\n",
      "Test set: Average loss: 1.5152, Accuracy: 3258/5000 (65%)\n",
      "[epoch 18] loss: 0.2046136\n",
      "Test set: Average loss: 1.5904, Accuracy: 3218/5000 (64%)\n",
      "[epoch 19] loss: 0.2003523\n",
      "Test set: Average loss: 1.5680, Accuracy: 3237/5000 (65%)\n",
      "[epoch 20] loss: 0.1889387\n",
      "Test set: Average loss: 1.6362, Accuracy: 3254/5000 (65%)\n",
      "[epoch 21] loss: 0.1790582\n",
      "Test set: Average loss: 1.7033, Accuracy: 3248/5000 (65%)\n",
      "[epoch 22] loss: 0.1754069\n",
      "Test set: Average loss: 1.8086, Accuracy: 3171/5000 (63%)\n",
      "[epoch 23] loss: 0.1703739\n",
      "Test set: Average loss: 1.7892, Accuracy: 3252/5000 (65%)\n",
      "[epoch 24] loss: 0.1823428\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7920, Accuracy: 3218/5000 (64%)\n",
      "[epoch 25] loss: 0.0645078\n",
      "Test set: Average loss: 1.7117, Accuracy: 3331/5000 (67%)\n",
      "[epoch 26] loss: 0.0210762\n",
      "Test set: Average loss: 1.7175, Accuracy: 3327/5000 (67%)\n",
      "[epoch 27] loss: 0.0115180\n",
      "Test set: Average loss: 1.7446, Accuracy: 3333/5000 (67%)\n",
      "[epoch 28] loss: 0.0073890\n",
      "Test set: Average loss: 1.7647, Accuracy: 3349/5000 (67%)\n",
      "[epoch 29] loss: 0.0048991\n",
      "Test set: Average loss: 1.8040, Accuracy: 3347/5000 (67%)\n",
      "[epoch 30] loss: 0.0032449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.8459, Accuracy: 3362/5000 (67%)\n",
      "[epoch 31] loss: 0.0021538\n",
      "Test set: Average loss: 1.8828, Accuracy: 3360/5000 (67%)\n",
      "[epoch 32] loss: 0.0014189\n",
      "Test set: Average loss: 1.9341, Accuracy: 3372/5000 (67%)\n",
      "[epoch 33] loss: 0.0009067\n",
      "Test set: Average loss: 1.9886, Accuracy: 3381/5000 (68%)\n",
      "[epoch 34] loss: 0.0005795\n",
      "Test set: Average loss: 2.0497, Accuracy: 3387/5000 (68%)\n",
      "[epoch 35] loss: 0.0003678\n",
      "Test set: Average loss: 2.1163, Accuracy: 3388/5000 (68%)\n",
      "[epoch 36] loss: 0.0002315\n",
      "Test set: Average loss: 2.1685, Accuracy: 3393/5000 (68%)\n",
      "[epoch 37] loss: 0.0001453\n",
      "Test set: Average loss: 2.2509, Accuracy: 3381/5000 (68%)\n",
      "[epoch 38] loss: 0.0000899\n",
      "Test set: Average loss: 2.3129, Accuracy: 3387/5000 (68%)\n",
      "[epoch 39] loss: 0.0000555\n",
      "Test set: Average loss: 2.3764, Accuracy: 3387/5000 (68%)\n",
      "[epoch 40] loss: 0.0000340\n",
      "Test set: Average loss: 2.4504, Accuracy: 3390/5000 (68%)\n",
      "[epoch 41] loss: 0.0000208\n",
      "Test set: Average loss: 2.5340, Accuracy: 3383/5000 (68%)\n",
      "[epoch 42] loss: 0.0000126\n",
      "Test set: Average loss: 2.6049, Accuracy: 3396/5000 (68%)\n",
      "[epoch 43] loss: 0.0000077\n",
      "Test set: Average loss: 2.6829, Accuracy: 3395/5000 (68%)\n",
      "[epoch 44] loss: 0.0000046\n",
      "Test set: Average loss: 2.7605, Accuracy: 3391/5000 (68%)\n",
      "[epoch 45] loss: 0.0000027\n",
      "Test set: Average loss: 2.8353, Accuracy: 3382/5000 (68%)\n",
      "[epoch 46] loss: 0.0000016\n",
      "Test set: Average loss: 2.9075, Accuracy: 3396/5000 (68%)\n",
      "[epoch 47] loss: 0.0000010\n",
      "Test set: Average loss: 2.9739, Accuracy: 3391/5000 (68%)\n",
      "[epoch 48] loss: 0.0000006\n",
      "Test set: Average loss: 3.0200, Accuracy: 3384/5000 (68%)\n",
      "[epoch 49] loss: 0.0000004\n",
      "Test set: Average loss: 3.0519, Accuracy: 3376/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0630, Accuracy: 3380/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9075, Accuracy: 3396/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.8050, Accuracy: 6766/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3057, Accuracy: 422/5000 (8%)\n",
      "[epoch 1] loss: 1.4576922\n",
      "Test set: Average loss: 1.3051, Accuracy: 2635/5000 (53%)\n",
      "[epoch 2] loss: 1.2188954\n",
      "Test set: Average loss: 1.2080, Accuracy: 2851/5000 (57%)\n",
      "[epoch 3] loss: 1.1287991\n",
      "Test set: Average loss: 1.1891, Accuracy: 2881/5000 (58%)\n",
      "[epoch 4] loss: 1.0645581\n",
      "Test set: Average loss: 1.1660, Accuracy: 2928/5000 (59%)\n",
      "[epoch 5] loss: 1.0016210\n",
      "Test set: Average loss: 1.0830, Accuracy: 3089/5000 (62%)\n",
      "[epoch 6] loss: 0.9396359\n",
      "Test set: Average loss: 1.1200, Accuracy: 3019/5000 (60%)\n",
      "[epoch 7] loss: 0.8808189\n",
      "Test set: Average loss: 1.0548, Accuracy: 3189/5000 (64%)\n",
      "[epoch 8] loss: 0.8142333\n",
      "Test set: Average loss: 1.0606, Accuracy: 3199/5000 (64%)\n",
      "[epoch 9] loss: 0.7523010\n",
      "Test set: Average loss: 1.0783, Accuracy: 3184/5000 (64%)\n",
      "[epoch 10] loss: 0.6773823\n",
      "Test set: Average loss: 1.0684, Accuracy: 3220/5000 (64%)\n",
      "[epoch 11] loss: 0.6042351\n",
      "Test set: Average loss: 1.0782, Accuracy: 3294/5000 (66%)\n",
      "[epoch 12] loss: 0.5175161\n",
      "Test set: Average loss: 1.1536, Accuracy: 3272/5000 (65%)\n",
      "[epoch 13] loss: 0.4413964\n",
      "Test set: Average loss: 1.2443, Accuracy: 3241/5000 (65%)\n",
      "[epoch 14] loss: 0.3830794\n",
      "Test set: Average loss: 1.2286, Accuracy: 3266/5000 (65%)\n",
      "[epoch 15] loss: 0.3187488\n",
      "Test set: Average loss: 1.3628, Accuracy: 3218/5000 (64%)\n",
      "[epoch 16] loss: 0.2732188\n",
      "Test set: Average loss: 1.3457, Accuracy: 3255/5000 (65%)\n",
      "[epoch 17] loss: 0.2352307\n",
      "Test set: Average loss: 1.5384, Accuracy: 3181/5000 (64%)\n",
      "[epoch 18] loss: 0.2083662\n",
      "Test set: Average loss: 1.5809, Accuracy: 3191/5000 (64%)\n",
      "[epoch 19] loss: 0.2013087\n",
      "Test set: Average loss: 1.6201, Accuracy: 3234/5000 (65%)\n",
      "[epoch 20] loss: 0.1908021\n",
      "Test set: Average loss: 1.7024, Accuracy: 3185/5000 (64%)\n",
      "[epoch 21] loss: 0.1888649\n",
      "Test set: Average loss: 1.7505, Accuracy: 3211/5000 (64%)\n",
      "[epoch 22] loss: 0.1739890\n",
      "Test set: Average loss: 1.7935, Accuracy: 3197/5000 (64%)\n",
      "[epoch 23] loss: 0.1771187\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7669, Accuracy: 3212/5000 (64%)\n",
      "[epoch 24] loss: 0.0672791\n",
      "Test set: Average loss: 1.6914, Accuracy: 3335/5000 (67%)\n",
      "[epoch 25] loss: 0.0222335\n",
      "Test set: Average loss: 1.7064, Accuracy: 3333/5000 (67%)\n",
      "[epoch 26] loss: 0.0126812\n",
      "Test set: Average loss: 1.7321, Accuracy: 3361/5000 (67%)\n",
      "[epoch 27] loss: 0.0080635\n",
      "Test set: Average loss: 1.7599, Accuracy: 3369/5000 (67%)\n",
      "[epoch 28] loss: 0.0053474\n",
      "Test set: Average loss: 1.7990, Accuracy: 3366/5000 (67%)\n",
      "[epoch 29] loss: 0.0035551\n",
      "Test set: Average loss: 1.8379, Accuracy: 3376/5000 (68%)\n",
      "[epoch 30] loss: 0.0023358\n",
      "Test set: Average loss: 1.8852, Accuracy: 3384/5000 (68%)\n",
      "[epoch 31] loss: 0.0015267\n",
      "Test set: Average loss: 1.9394, Accuracy: 3378/5000 (68%)\n",
      "[epoch 32] loss: 0.0009753\n",
      "Test set: Average loss: 1.9860, Accuracy: 3377/5000 (68%)\n",
      "[epoch 33] loss: 0.0006260\n",
      "Test set: Average loss: 2.0450, Accuracy: 3375/5000 (68%)\n",
      "[epoch 34] loss: 0.0003986\n",
      "Test set: Average loss: 2.1162, Accuracy: 3397/5000 (68%)\n",
      "[epoch 35] loss: 0.0002449\n",
      "Test set: Average loss: 2.1782, Accuracy: 3387/5000 (68%)\n",
      "[epoch 36] loss: 0.0001535\n",
      "Test set: Average loss: 2.2357, Accuracy: 3397/5000 (68%)\n",
      "[epoch 37] loss: 0.0000954\n",
      "Test set: Average loss: 2.3110, Accuracy: 3395/5000 (68%)\n",
      "[epoch 38] loss: 0.0000587\n",
      "Test set: Average loss: 2.3889, Accuracy: 3393/5000 (68%)\n",
      "[epoch 39] loss: 0.0000357\n",
      "Test set: Average loss: 2.4614, Accuracy: 3391/5000 (68%)\n",
      "[epoch 40] loss: 0.0000235\n",
      "Test set: Average loss: 2.5658, Accuracy: 3404/5000 (68%)\n",
      "[epoch 41] loss: 0.0000177\n",
      "Test set: Average loss: 2.6025, Accuracy: 3395/5000 (68%)\n",
      "[epoch 42] loss: 0.0000089\n",
      "Test set: Average loss: 2.6615, Accuracy: 3408/5000 (68%)\n",
      "[epoch 43] loss: 0.0000059\n",
      "Test set: Average loss: 2.7254, Accuracy: 3411/5000 (68%)\n",
      "[epoch 44] loss: 0.0000038\n",
      "Test set: Average loss: 2.8005, Accuracy: 3405/5000 (68%)\n",
      "[epoch 45] loss: 0.0000023\n",
      "Test set: Average loss: 2.8653, Accuracy: 3406/5000 (68%)\n",
      "[epoch 46] loss: 0.0000014\n",
      "Test set: Average loss: 2.9446, Accuracy: 3400/5000 (68%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 2.9965, Accuracy: 3402/5000 (68%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 3.0341, Accuracy: 3390/5000 (68%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.0567, Accuracy: 3398/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0659, Accuracy: 3396/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7254, Accuracy: 3411/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.5822, Accuracy: 6864/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 524/5000 (10%)\n",
      "[epoch 1] loss: 1.4648465\n",
      "Test set: Average loss: 1.2802, Accuracy: 2696/5000 (54%)\n",
      "[epoch 2] loss: 1.2084461\n",
      "Test set: Average loss: 1.2011, Accuracy: 2893/5000 (58%)\n",
      "[epoch 3] loss: 1.1189987\n",
      "Test set: Average loss: 1.1237, Accuracy: 3015/5000 (60%)\n",
      "[epoch 4] loss: 1.0474515\n",
      "Test set: Average loss: 1.1322, Accuracy: 3018/5000 (60%)\n",
      "[epoch 5] loss: 0.9954573\n",
      "Test set: Average loss: 1.1244, Accuracy: 3080/5000 (62%)\n",
      "[epoch 6] loss: 0.9307814\n",
      "Test set: Average loss: 1.0985, Accuracy: 3104/5000 (62%)\n",
      "[epoch 7] loss: 0.8765434\n",
      "Test set: Average loss: 1.0390, Accuracy: 3189/5000 (64%)\n",
      "[epoch 8] loss: 0.8100593\n",
      "Test set: Average loss: 1.0869, Accuracy: 3183/5000 (64%)\n",
      "[epoch 9] loss: 0.7410860\n",
      "Test set: Average loss: 1.0651, Accuracy: 3262/5000 (65%)\n",
      "[epoch 10] loss: 0.6638421\n",
      "Test set: Average loss: 1.0668, Accuracy: 3284/5000 (66%)\n",
      "[epoch 11] loss: 0.5745471\n",
      "Test set: Average loss: 1.1361, Accuracy: 3253/5000 (65%)\n",
      "[epoch 12] loss: 0.4887923\n",
      "Test set: Average loss: 1.1751, Accuracy: 3278/5000 (66%)\n",
      "[epoch 13] loss: 0.4156898\n",
      "Test set: Average loss: 1.2339, Accuracy: 3233/5000 (65%)\n",
      "[epoch 14] loss: 0.3420916\n",
      "Test set: Average loss: 1.2893, Accuracy: 3218/5000 (64%)\n",
      "[epoch 15] loss: 0.2865980\n",
      "Test set: Average loss: 1.4120, Accuracy: 3215/5000 (64%)\n",
      "[epoch 16] loss: 0.2567161\n",
      "Test set: Average loss: 1.4543, Accuracy: 3246/5000 (65%)\n",
      "[epoch 17] loss: 0.2203363\n",
      "Test set: Average loss: 1.5359, Accuracy: 3236/5000 (65%)\n",
      "[epoch 18] loss: 0.2043821\n",
      "Test set: Average loss: 1.5535, Accuracy: 3237/5000 (65%)\n",
      "[epoch 19] loss: 0.1929320\n",
      "Test set: Average loss: 1.6799, Accuracy: 3195/5000 (64%)\n",
      "[epoch 20] loss: 0.1692638\n",
      "Test set: Average loss: 1.7208, Accuracy: 3212/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21] loss: 0.1774753\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7879, Accuracy: 3175/5000 (64%)\n",
      "[epoch 22] loss: 0.0654311\n",
      "Test set: Average loss: 1.6653, Accuracy: 3316/5000 (66%)\n",
      "[epoch 23] loss: 0.0226304\n",
      "Test set: Average loss: 1.6763, Accuracy: 3317/5000 (66%)\n",
      "[epoch 24] loss: 0.0125069\n",
      "Test set: Average loss: 1.7018, Accuracy: 3317/5000 (66%)\n",
      "[epoch 25] loss: 0.0081161\n",
      "Test set: Average loss: 1.7321, Accuracy: 3335/5000 (67%)\n",
      "[epoch 26] loss: 0.0053732\n",
      "Test set: Average loss: 1.7759, Accuracy: 3344/5000 (67%)\n",
      "[epoch 27] loss: 0.0035613\n",
      "Test set: Average loss: 1.8196, Accuracy: 3335/5000 (67%)\n",
      "[epoch 28] loss: 0.0023226\n",
      "Test set: Average loss: 1.8783, Accuracy: 3342/5000 (67%)\n",
      "[epoch 29] loss: 0.0015095\n",
      "Test set: Average loss: 1.9330, Accuracy: 3337/5000 (67%)\n",
      "[epoch 30] loss: 0.0009630\n",
      "Test set: Average loss: 1.9831, Accuracy: 3361/5000 (67%)\n",
      "[epoch 31] loss: 0.0006042\n",
      "Test set: Average loss: 2.0541, Accuracy: 3347/5000 (67%)\n",
      "[epoch 32] loss: 0.0003944\n",
      "Test set: Average loss: 2.1275, Accuracy: 3345/5000 (67%)\n",
      "[epoch 33] loss: 0.0002419\n",
      "Test set: Average loss: 2.1856, Accuracy: 3354/5000 (67%)\n",
      "[epoch 34] loss: 0.0001480\n",
      "Test set: Average loss: 2.2581, Accuracy: 3345/5000 (67%)\n",
      "[epoch 35] loss: 0.0000922\n",
      "Test set: Average loss: 2.3306, Accuracy: 3336/5000 (67%)\n",
      "[epoch 36] loss: 0.0000566\n",
      "Test set: Average loss: 2.4093, Accuracy: 3337/5000 (67%)\n",
      "[epoch 37] loss: 0.0000345\n",
      "Test set: Average loss: 2.4828, Accuracy: 3335/5000 (67%)\n",
      "[epoch 38] loss: 0.0000206\n",
      "Test set: Average loss: 2.5650, Accuracy: 3324/5000 (66%)\n",
      "[epoch 39] loss: 0.0000123\n",
      "Test set: Average loss: 2.6491, Accuracy: 3328/5000 (67%)\n",
      "[epoch 40] loss: 0.0000073\n",
      "Test set: Average loss: 2.7288, Accuracy: 3327/5000 (67%)\n",
      "[epoch 41] loss: 0.0000043\n",
      "Test set: Average loss: 2.8083, Accuracy: 3321/5000 (66%)\n",
      "[epoch 42] loss: 0.0000025\n",
      "Test set: Average loss: 2.8882, Accuracy: 3322/5000 (66%)\n",
      "[epoch 43] loss: 0.0000015\n",
      "Test set: Average loss: 2.9666, Accuracy: 3328/5000 (67%)\n",
      "[epoch 44] loss: 0.0000009\n",
      "Test set: Average loss: 3.0259, Accuracy: 3319/5000 (66%)\n",
      "[epoch 45] loss: 0.0000005\n",
      "Test set: Average loss: 3.0692, Accuracy: 3322/5000 (66%)\n",
      "[epoch 46] loss: 0.0000003\n",
      "Test set: Average loss: 3.0860, Accuracy: 3316/5000 (66%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 3.0990, Accuracy: 3320/5000 (66%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.1172, Accuracy: 3311/5000 (66%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.1257, Accuracy: 3314/5000 (66%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.1323, Accuracy: 3318/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9831, Accuracy: 3361/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.9581, Accuracy: 6713/10000 (67%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3054, Accuracy: 476/5000 (10%)\n",
      "[epoch 1] loss: 1.4759298\n",
      "Test set: Average loss: 1.3362, Accuracy: 2647/5000 (53%)\n",
      "[epoch 2] loss: 1.2252538\n",
      "Test set: Average loss: 1.2649, Accuracy: 2774/5000 (55%)\n",
      "[epoch 3] loss: 1.1349823\n",
      "Test set: Average loss: 1.1498, Accuracy: 2987/5000 (60%)\n",
      "[epoch 4] loss: 1.0602106\n",
      "Test set: Average loss: 1.1391, Accuracy: 3000/5000 (60%)\n",
      "[epoch 5] loss: 1.0066789\n",
      "Test set: Average loss: 1.1026, Accuracy: 3037/5000 (61%)\n",
      "[epoch 6] loss: 0.9401634\n",
      "Test set: Average loss: 1.0724, Accuracy: 3146/5000 (63%)\n",
      "[epoch 7] loss: 0.8821201\n",
      "Test set: Average loss: 1.0509, Accuracy: 3192/5000 (64%)\n",
      "[epoch 8] loss: 0.8220568\n",
      "Test set: Average loss: 1.0059, Accuracy: 3255/5000 (65%)\n",
      "[epoch 9] loss: 0.7499549\n",
      "Test set: Average loss: 1.0087, Accuracy: 3275/5000 (66%)\n",
      "[epoch 10] loss: 0.6884074\n",
      "Test set: Average loss: 1.0728, Accuracy: 3244/5000 (65%)\n",
      "[epoch 11] loss: 0.6177786\n",
      "Test set: Average loss: 1.0587, Accuracy: 3252/5000 (65%)\n",
      "[epoch 12] loss: 0.5422897\n",
      "Test set: Average loss: 1.1118, Accuracy: 3265/5000 (65%)\n",
      "[epoch 13] loss: 0.4716014\n",
      "Test set: Average loss: 1.1216, Accuracy: 3316/5000 (66%)\n",
      "[epoch 14] loss: 0.4008364\n",
      "Test set: Average loss: 1.2156, Accuracy: 3244/5000 (65%)\n",
      "[epoch 15] loss: 0.3496167\n",
      "Test set: Average loss: 1.2879, Accuracy: 3235/5000 (65%)\n",
      "[epoch 16] loss: 0.3078973\n",
      "Test set: Average loss: 1.3439, Accuracy: 3227/5000 (65%)\n",
      "[epoch 17] loss: 0.2632664\n",
      "Test set: Average loss: 1.4224, Accuracy: 3251/5000 (65%)\n",
      "[epoch 18] loss: 0.2319231\n",
      "Test set: Average loss: 1.4970, Accuracy: 3208/5000 (64%)\n",
      "[epoch 19] loss: 0.2154077\n",
      "Test set: Average loss: 1.6065, Accuracy: 3220/5000 (64%)\n",
      "[epoch 20] loss: 0.2241377\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5734, Accuracy: 3224/5000 (64%)\n",
      "[epoch 21] loss: 0.0840526\n",
      "Test set: Average loss: 1.4808, Accuracy: 3337/5000 (67%)\n",
      "[epoch 22] loss: 0.0353056\n",
      "Test set: Average loss: 1.4947, Accuracy: 3364/5000 (67%)\n",
      "[epoch 23] loss: 0.0203574\n",
      "Test set: Average loss: 1.5297, Accuracy: 3343/5000 (67%)\n",
      "[epoch 24] loss: 0.0128496\n",
      "Test set: Average loss: 1.5610, Accuracy: 3353/5000 (67%)\n",
      "[epoch 25] loss: 0.0083881\n",
      "Test set: Average loss: 1.5935, Accuracy: 3359/5000 (67%)\n",
      "[epoch 26] loss: 0.0054138\n",
      "Test set: Average loss: 1.6529, Accuracy: 3361/5000 (67%)\n",
      "[epoch 27] loss: 0.0034974\n",
      "Test set: Average loss: 1.7038, Accuracy: 3366/5000 (67%)\n",
      "[epoch 28] loss: 0.0022006\n",
      "Test set: Average loss: 1.7532, Accuracy: 3372/5000 (67%)\n",
      "[epoch 29] loss: 0.0014675\n",
      "Test set: Average loss: 1.8148, Accuracy: 3369/5000 (67%)\n",
      "[epoch 30] loss: 0.0008805\n",
      "Test set: Average loss: 1.8810, Accuracy: 3373/5000 (67%)\n",
      "[epoch 31] loss: 0.0005537\n",
      "Test set: Average loss: 1.9488, Accuracy: 3374/5000 (67%)\n",
      "[epoch 32] loss: 0.0003418\n",
      "Test set: Average loss: 2.0170, Accuracy: 3367/5000 (67%)\n",
      "[epoch 33] loss: 0.0002091\n",
      "Test set: Average loss: 2.1014, Accuracy: 3376/5000 (68%)\n",
      "[epoch 34] loss: 0.0001277\n",
      "Test set: Average loss: 2.1681, Accuracy: 3378/5000 (68%)\n",
      "[epoch 35] loss: 0.0000758\n",
      "Test set: Average loss: 2.2508, Accuracy: 3368/5000 (67%)\n",
      "[epoch 36] loss: 0.0000456\n",
      "Test set: Average loss: 2.3242, Accuracy: 3383/5000 (68%)\n",
      "[epoch 37] loss: 0.0000267\n",
      "Test set: Average loss: 2.4041, Accuracy: 3387/5000 (68%)\n",
      "[epoch 38] loss: 0.0000155\n",
      "Test set: Average loss: 2.4817, Accuracy: 3383/5000 (68%)\n",
      "[epoch 39] loss: 0.0000091\n",
      "Test set: Average loss: 2.5694, Accuracy: 3388/5000 (68%)\n",
      "[epoch 40] loss: 0.0000052\n",
      "Test set: Average loss: 2.6543, Accuracy: 3385/5000 (68%)\n",
      "[epoch 41] loss: 0.0000030\n",
      "Test set: Average loss: 2.7408, Accuracy: 3377/5000 (68%)\n",
      "[epoch 42] loss: 0.0000017\n",
      "Test set: Average loss: 2.8385, Accuracy: 3366/5000 (67%)\n",
      "[epoch 43] loss: 0.0000010\n",
      "Test set: Average loss: 2.8879, Accuracy: 3372/5000 (67%)\n",
      "[epoch 44] loss: 0.0000005\n",
      "Test set: Average loss: 2.9324, Accuracy: 3372/5000 (67%)\n",
      "[epoch 45] loss: 0.0000003\n",
      "Test set: Average loss: 2.9713, Accuracy: 3355/5000 (67%)\n",
      "[epoch 46] loss: 0.0000002\n",
      "Test set: Average loss: 2.9735, Accuracy: 3370/5000 (67%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 2.9995, Accuracy: 3359/5000 (67%)\n",
      "[epoch 48] loss: 0.0009346\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0906, Accuracy: 3308/5000 (66%)\n",
      "[epoch 49] loss: 0.0000601\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0862, Accuracy: 3302/5000 (66%)\n",
      "[epoch 50] loss: 0.0000242\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0858, Accuracy: 3301/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5694, Accuracy: 3388/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6582, Accuracy: 6828/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3021, Accuracy: 501/5000 (10%)\n",
      "[epoch 1] loss: 1.4510271\n",
      "Test set: Average loss: 1.3540, Accuracy: 2587/5000 (52%)\n",
      "[epoch 2] loss: 1.2289248\n",
      "Test set: Average loss: 1.2006, Accuracy: 2903/5000 (58%)\n",
      "[epoch 3] loss: 1.1285070\n",
      "Test set: Average loss: 1.1258, Accuracy: 3033/5000 (61%)\n",
      "[epoch 4] loss: 1.0567168\n",
      "Test set: Average loss: 1.1357, Accuracy: 3027/5000 (61%)\n",
      "[epoch 5] loss: 0.9928342\n",
      "Test set: Average loss: 1.1667, Accuracy: 2986/5000 (60%)\n",
      "[epoch 6] loss: 0.9329168\n",
      "Test set: Average loss: 1.0792, Accuracy: 3128/5000 (63%)\n",
      "[epoch 7] loss: 0.8747659\n",
      "Test set: Average loss: 1.0173, Accuracy: 3255/5000 (65%)\n",
      "[epoch 8] loss: 0.8079551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0108, Accuracy: 3266/5000 (65%)\n",
      "[epoch 9] loss: 0.7446944\n",
      "Test set: Average loss: 0.9952, Accuracy: 3327/5000 (67%)\n",
      "[epoch 10] loss: 0.6784031\n",
      "Test set: Average loss: 1.0974, Accuracy: 3200/5000 (64%)\n",
      "[epoch 11] loss: 0.6114726\n",
      "Test set: Average loss: 1.0634, Accuracy: 3340/5000 (67%)\n",
      "[epoch 12] loss: 0.5318478\n",
      "Test set: Average loss: 1.0807, Accuracy: 3339/5000 (67%)\n",
      "[epoch 13] loss: 0.4615470\n",
      "Test set: Average loss: 1.1773, Accuracy: 3256/5000 (65%)\n",
      "[epoch 14] loss: 0.3929105\n",
      "Test set: Average loss: 1.2404, Accuracy: 3254/5000 (65%)\n",
      "[epoch 15] loss: 0.3439654\n",
      "Test set: Average loss: 1.2966, Accuracy: 3299/5000 (66%)\n",
      "[epoch 16] loss: 0.2965317\n",
      "Test set: Average loss: 1.3148, Accuracy: 3292/5000 (66%)\n",
      "[epoch 17] loss: 0.2564313\n",
      "Test set: Average loss: 1.6173, Accuracy: 3150/5000 (63%)\n",
      "[epoch 18] loss: 0.2522118\n",
      "Test set: Average loss: 1.4532, Accuracy: 3291/5000 (66%)\n",
      "[epoch 19] loss: 0.2091790\n",
      "Test set: Average loss: 1.5300, Accuracy: 3298/5000 (66%)\n",
      "[epoch 20] loss: 0.2089619\n",
      "Test set: Average loss: 1.5907, Accuracy: 3267/5000 (65%)\n",
      "[epoch 21] loss: 0.2128855\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6376, Accuracy: 3248/5000 (65%)\n",
      "[epoch 22] loss: 0.0755344\n",
      "Test set: Average loss: 1.5403, Accuracy: 3375/5000 (68%)\n",
      "[epoch 23] loss: 0.0300271\n",
      "Test set: Average loss: 1.5618, Accuracy: 3374/5000 (67%)\n",
      "[epoch 24] loss: 0.0169302\n",
      "Test set: Average loss: 1.5838, Accuracy: 3380/5000 (68%)\n",
      "[epoch 25] loss: 0.0107107\n",
      "Test set: Average loss: 1.6255, Accuracy: 3368/5000 (67%)\n",
      "[epoch 26] loss: 0.0069083\n",
      "Test set: Average loss: 1.6665, Accuracy: 3371/5000 (67%)\n",
      "[epoch 27] loss: 0.0044158\n",
      "Test set: Average loss: 1.7106, Accuracy: 3371/5000 (67%)\n",
      "[epoch 28] loss: 0.0027912\n",
      "Test set: Average loss: 1.7712, Accuracy: 3376/5000 (68%)\n",
      "[epoch 29] loss: 0.0017406\n",
      "Test set: Average loss: 1.8377, Accuracy: 3372/5000 (67%)\n",
      "[epoch 30] loss: 0.0010801\n",
      "Test set: Average loss: 1.8967, Accuracy: 3375/5000 (68%)\n",
      "[epoch 31] loss: 0.0006619\n",
      "Test set: Average loss: 1.9692, Accuracy: 3389/5000 (68%)\n",
      "[epoch 32] loss: 0.0003987\n",
      "Test set: Average loss: 2.0464, Accuracy: 3378/5000 (68%)\n",
      "[epoch 33] loss: 0.0002404\n",
      "Test set: Average loss: 2.1276, Accuracy: 3385/5000 (68%)\n",
      "[epoch 34] loss: 0.0001430\n",
      "Test set: Average loss: 2.2007, Accuracy: 3383/5000 (68%)\n",
      "[epoch 35] loss: 0.0000844\n",
      "Test set: Average loss: 2.2893, Accuracy: 3382/5000 (68%)\n",
      "[epoch 36] loss: 0.0000497\n",
      "Test set: Average loss: 2.3725, Accuracy: 3369/5000 (67%)\n",
      "[epoch 37] loss: 0.0000292\n",
      "Test set: Average loss: 2.4608, Accuracy: 3364/5000 (67%)\n",
      "[epoch 38] loss: 0.0000167\n",
      "Test set: Average loss: 2.5546, Accuracy: 3372/5000 (67%)\n",
      "[epoch 39] loss: 0.0000096\n",
      "Test set: Average loss: 2.6425, Accuracy: 3362/5000 (67%)\n",
      "[epoch 40] loss: 0.0000055\n",
      "Test set: Average loss: 2.7331, Accuracy: 3365/5000 (67%)\n",
      "[epoch 41] loss: 0.0000032\n",
      "Test set: Average loss: 2.8224, Accuracy: 3350/5000 (67%)\n",
      "[epoch 42] loss: 0.0000018\n",
      "Test set: Average loss: 2.9108, Accuracy: 3360/5000 (67%)\n",
      "[epoch 43] loss: 0.0000010\n",
      "Test set: Average loss: 2.9829, Accuracy: 3351/5000 (67%)\n",
      "[epoch 44] loss: 0.0000006\n",
      "Test set: Average loss: 3.0399, Accuracy: 3351/5000 (67%)\n",
      "[epoch 45] loss: 0.0000003\n",
      "Test set: Average loss: 3.0682, Accuracy: 3352/5000 (67%)\n",
      "[epoch 46] loss: 0.0000002\n",
      "Test set: Average loss: 3.0826, Accuracy: 3340/5000 (67%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 3.1209, Accuracy: 3345/5000 (67%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.1411, Accuracy: 3337/5000 (67%)\n",
      "[epoch 49] loss: 0.0000001\n",
      "Test set: Average loss: 3.1510, Accuracy: 3342/5000 (67%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.1663, Accuracy: 3338/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9692, Accuracy: 3389/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.9416, Accuracy: 6854/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3047, Accuracy: 589/5000 (12%)\n",
      "[epoch 1] loss: 1.4322817\n",
      "Test set: Average loss: 1.2866, Accuracy: 2722/5000 (54%)\n",
      "[epoch 2] loss: 1.1878119\n",
      "Test set: Average loss: 1.1941, Accuracy: 2919/5000 (58%)\n",
      "[epoch 3] loss: 1.0967330\n",
      "Test set: Average loss: 1.1818, Accuracy: 2891/5000 (58%)\n",
      "[epoch 4] loss: 1.0352019\n",
      "Test set: Average loss: 1.0842, Accuracy: 3099/5000 (62%)\n",
      "[epoch 5] loss: 0.9709215\n",
      "Test set: Average loss: 1.0272, Accuracy: 3176/5000 (64%)\n",
      "[epoch 6] loss: 0.9109911\n",
      "Test set: Average loss: 1.0471, Accuracy: 3198/5000 (64%)\n",
      "[epoch 7] loss: 0.8395232\n",
      "Test set: Average loss: 1.0349, Accuracy: 3217/5000 (64%)\n",
      "[epoch 8] loss: 0.7712566\n",
      "Test set: Average loss: 1.0182, Accuracy: 3275/5000 (66%)\n",
      "[epoch 9] loss: 0.6861214\n",
      "Test set: Average loss: 1.0561, Accuracy: 3265/5000 (65%)\n",
      "[epoch 10] loss: 0.6056074\n",
      "Test set: Average loss: 1.0828, Accuracy: 3271/5000 (65%)\n",
      "[epoch 11] loss: 0.5190326\n",
      "Test set: Average loss: 1.1470, Accuracy: 3285/5000 (66%)\n",
      "[epoch 12] loss: 0.4335536\n",
      "Test set: Average loss: 1.2459, Accuracy: 3259/5000 (65%)\n",
      "[epoch 13] loss: 0.3589472\n",
      "Test set: Average loss: 1.2632, Accuracy: 3291/5000 (66%)\n",
      "[epoch 14] loss: 0.3025283\n",
      "Test set: Average loss: 1.4120, Accuracy: 3214/5000 (64%)\n",
      "[epoch 15] loss: 0.2509434\n",
      "Test set: Average loss: 1.4287, Accuracy: 3279/5000 (66%)\n",
      "[epoch 16] loss: 0.2331044\n",
      "Test set: Average loss: 1.5657, Accuracy: 3203/5000 (64%)\n",
      "[epoch 17] loss: 0.2064581\n",
      "Test set: Average loss: 1.6121, Accuracy: 3219/5000 (64%)\n",
      "[epoch 18] loss: 0.1894491\n",
      "Test set: Average loss: 1.6283, Accuracy: 3202/5000 (64%)\n",
      "[epoch 19] loss: 0.1810002\n",
      "Test set: Average loss: 1.7118, Accuracy: 3233/5000 (65%)\n",
      "[epoch 20] loss: 0.1867650\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7228, Accuracy: 3214/5000 (64%)\n",
      "[epoch 21] loss: 0.0736776\n",
      "Test set: Average loss: 1.6522, Accuracy: 3290/5000 (66%)\n",
      "[epoch 22] loss: 0.0256265\n",
      "Test set: Average loss: 1.6731, Accuracy: 3295/5000 (66%)\n",
      "[epoch 23] loss: 0.0137474\n",
      "Test set: Average loss: 1.6972, Accuracy: 3299/5000 (66%)\n",
      "[epoch 24] loss: 0.0084292\n",
      "Test set: Average loss: 1.7341, Accuracy: 3316/5000 (66%)\n",
      "[epoch 25] loss: 0.0053542\n",
      "Test set: Average loss: 1.7800, Accuracy: 3319/5000 (66%)\n",
      "[epoch 26] loss: 0.0033748\n",
      "Test set: Average loss: 1.8322, Accuracy: 3315/5000 (66%)\n",
      "[epoch 27] loss: 0.0021087\n",
      "Test set: Average loss: 1.8854, Accuracy: 3320/5000 (66%)\n",
      "[epoch 28] loss: 0.0012939\n",
      "Test set: Average loss: 1.9527, Accuracy: 3329/5000 (67%)\n",
      "[epoch 29] loss: 0.0007853\n",
      "Test set: Average loss: 2.0216, Accuracy: 3328/5000 (67%)\n",
      "[epoch 30] loss: 0.0004754\n",
      "Test set: Average loss: 2.0917, Accuracy: 3327/5000 (67%)\n",
      "[epoch 31] loss: 0.0002793\n",
      "Test set: Average loss: 2.1648, Accuracy: 3351/5000 (67%)\n",
      "[epoch 32] loss: 0.0001655\n",
      "Test set: Average loss: 2.2464, Accuracy: 3350/5000 (67%)\n",
      "[epoch 33] loss: 0.0000972\n",
      "Test set: Average loss: 2.3198, Accuracy: 3348/5000 (67%)\n",
      "[epoch 34] loss: 0.0000560\n",
      "Test set: Average loss: 2.4097, Accuracy: 3347/5000 (67%)\n",
      "[epoch 35] loss: 0.0000323\n",
      "Test set: Average loss: 2.4874, Accuracy: 3359/5000 (67%)\n",
      "[epoch 36] loss: 0.0000186\n",
      "Test set: Average loss: 2.5739, Accuracy: 3360/5000 (67%)\n",
      "[epoch 37] loss: 0.0000105\n",
      "Test set: Average loss: 2.6663, Accuracy: 3372/5000 (67%)\n",
      "[epoch 38] loss: 0.0000061\n",
      "Test set: Average loss: 2.7489, Accuracy: 3365/5000 (67%)\n",
      "[epoch 39] loss: 0.0000033\n",
      "Test set: Average loss: 2.8219, Accuracy: 3366/5000 (67%)\n",
      "[epoch 40] loss: 0.0000019\n",
      "Test set: Average loss: 2.9181, Accuracy: 3369/5000 (67%)\n",
      "[epoch 41] loss: 0.0000010\n",
      "Test set: Average loss: 2.9920, Accuracy: 3364/5000 (67%)\n",
      "[epoch 42] loss: 0.0000006\n",
      "Test set: Average loss: 3.0434, Accuracy: 3366/5000 (67%)\n",
      "[epoch 43] loss: 0.0000003\n",
      "Test set: Average loss: 3.0484, Accuracy: 3355/5000 (67%)\n",
      "[epoch 44] loss: 0.0000002\n",
      "Test set: Average loss: 3.0823, Accuracy: 3337/5000 (67%)\n",
      "[epoch 45] loss: 0.0000002\n",
      "Test set: Average loss: 3.1163, Accuracy: 3333/5000 (67%)\n",
      "[epoch 46] loss: 0.0000001\n",
      "Test set: Average loss: 3.1199, Accuracy: 3337/5000 (67%)\n",
      "[epoch 47] loss: 0.0007076\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2114, Accuracy: 3304/5000 (66%)\n",
      "[epoch 48] loss: 0.0000149\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2090, Accuracy: 3301/5000 (66%)\n",
      "[epoch 49] loss: 0.0000104\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.2086, Accuracy: 3301/5000 (66%)\n",
      "[epoch 50] loss: 0.0000102\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2086, Accuracy: 3301/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6663, Accuracy: 3372/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.6275, Accuracy: 6748/10000 (67%)\n"
     ]
    }
   ],
   "source": [
    "# CLF without pretraining\n",
    "test_accuracies_clf = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_clf.append(clf_with_ntrain(n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T04:07:28.723800Z",
     "start_time": "2019-07-24T01:26:50.323871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4454981\n",
      "[epoch 2] loss: 1.2212617\n",
      "[epoch 3] loss: 1.1181397\n",
      "[epoch 4] loss: 1.0538822\n",
      "[epoch 5] loss: 0.9856029\n",
      "[epoch 6] loss: 0.9331732\n",
      "[epoch 7] loss: 0.8780911\n",
      "[epoch 8] loss: 0.8181462\n",
      "[epoch 9] loss: 0.7465368\n",
      "[epoch 10] loss: 0.6757347\n",
      "[epoch 11] loss: 0.6025199\n",
      "[epoch 12] loss: 0.5288562\n",
      "[epoch 13] loss: 0.4501681\n",
      "[epoch 14] loss: 0.3848621\n",
      "[epoch 15] loss: 0.3314582\n",
      "[epoch 16] loss: 0.2860832\n",
      "[epoch 17] loss: 0.2456506\n",
      "[epoch 18] loss: 0.2355626\n",
      "[epoch 19] loss: 0.2053205\n",
      "[epoch 20] loss: 0.2009631\n",
      "[epoch 21] loss: 0.2054669\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[epoch 22] loss: 0.0807047\n",
      "[epoch 23] loss: 0.0286470\n",
      "[epoch 24] loss: 0.0158217\n",
      "[epoch 25] loss: 0.0099141\n",
      "[epoch 26] loss: 0.0063574\n",
      "[epoch 27] loss: 0.0040761\n",
      "[epoch 28] loss: 0.0025702\n",
      "[epoch 29] loss: 0.0015967\n",
      "[epoch 30] loss: 0.0009818\n",
      "[epoch 31] loss: 0.0005992\n",
      "[epoch 32] loss: 0.0003624\n",
      "[epoch 33] loss: 0.0002164\n",
      "[epoch 34] loss: 0.0001285\n",
      "[epoch 35] loss: 0.0000751\n",
      "[epoch 36] loss: 0.0000442\n",
      "[epoch 37] loss: 0.0000254\n",
      "[epoch 38] loss: 0.0000147\n",
      "[epoch 39] loss: 0.0000084\n",
      "[epoch 40] loss: 0.0000048\n",
      "[epoch 41] loss: 0.0000027\n",
      "[epoch 42] loss: 0.0000015\n",
      "[epoch 43] loss: 0.0000008\n",
      "[epoch 44] loss: 0.0000005\n",
      "[epoch 45] loss: 0.0000003\n",
      "[epoch 46] loss: 0.0000002\n",
      "[epoch 47] loss: 0.0000002\n",
      "[epoch 48] loss: 0.0000001\n",
      "[epoch 49] loss: 0.0011866\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[epoch 50] loss: 0.0000600\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.1004, Accuracy: 6736/10000 (67%)\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4203, Accuracy: 423/5000 (8%)\n",
      "[epoch 1] loss: 2.4329758\n",
      "Test set: Average loss: 2.3141, Accuracy: 639/5000 (13%)\n",
      "[epoch 2] loss: 1.7551444\n",
      "Test set: Average loss: 2.2263, Accuracy: 869/5000 (17%)\n",
      "[epoch 3] loss: 1.2630105\n",
      "Test set: Average loss: 2.1514, Accuracy: 1114/5000 (22%)\n",
      "[epoch 4] loss: 0.9015741\n",
      "Test set: Average loss: 2.0876, Accuracy: 1316/5000 (26%)\n",
      "[epoch 5] loss: 0.6450011\n",
      "Test set: Average loss: 2.0338, Accuracy: 1462/5000 (29%)\n",
      "[epoch 6] loss: 0.4670484\n",
      "Test set: Average loss: 1.9894, Accuracy: 1575/5000 (32%)\n",
      "[epoch 7] loss: 0.3438205\n",
      "Test set: Average loss: 1.9537, Accuracy: 1650/5000 (33%)\n",
      "[epoch 8] loss: 0.2577628\n",
      "Test set: Average loss: 1.9258, Accuracy: 1737/5000 (35%)\n",
      "[epoch 9] loss: 0.1971333\n",
      "Test set: Average loss: 1.9045, Accuracy: 1796/5000 (36%)\n",
      "[epoch 10] loss: 0.1534625\n",
      "Test set: Average loss: 1.8886, Accuracy: 1836/5000 (37%)\n",
      "[epoch 11] loss: 0.1214672\n",
      "Test set: Average loss: 1.8769, Accuracy: 1861/5000 (37%)\n",
      "[epoch 12] loss: 0.0976275\n",
      "Test set: Average loss: 1.8686, Accuracy: 1884/5000 (38%)\n",
      "[epoch 13] loss: 0.0795292\n",
      "Test set: Average loss: 1.8628, Accuracy: 1912/5000 (38%)\n",
      "[epoch 14] loss: 0.0655729\n",
      "Test set: Average loss: 1.8591, Accuracy: 1935/5000 (39%)\n",
      "[epoch 15] loss: 0.0546827\n",
      "Test set: Average loss: 1.8570, Accuracy: 1948/5000 (39%)\n",
      "[epoch 16] loss: 0.0461008\n",
      "Test set: Average loss: 1.8562, Accuracy: 1965/5000 (39%)\n",
      "[epoch 17] loss: 0.0392939\n",
      "Test set: Average loss: 1.8565, Accuracy: 1972/5000 (39%)\n",
      "[epoch 18] loss: 0.0338523\n",
      "Test set: Average loss: 1.8575, Accuracy: 1990/5000 (40%)\n",
      "[epoch 19] loss: 0.0294527\n",
      "Test set: Average loss: 1.8591, Accuracy: 2005/5000 (40%)\n",
      "[epoch 20] loss: 0.0258535\n",
      "Test set: Average loss: 1.8612, Accuracy: 2018/5000 (40%)\n",
      "[epoch 21] loss: 0.0228836\n",
      "Test set: Average loss: 1.8637, Accuracy: 2022/5000 (40%)\n",
      "[epoch 22] loss: 0.0204160\n",
      "Test set: Average loss: 1.8663, Accuracy: 2028/5000 (41%)\n",
      "[epoch 23] loss: 0.0183508\n",
      "Test set: Average loss: 1.8691, Accuracy: 2029/5000 (41%)\n",
      "[epoch 24] loss: 0.0166097\n",
      "Test set: Average loss: 1.8720, Accuracy: 2030/5000 (41%)\n",
      "[epoch 25] loss: 0.0151309\n",
      "Test set: Average loss: 1.8750, Accuracy: 2034/5000 (41%)\n",
      "[epoch 26] loss: 0.0138656\n",
      "Test set: Average loss: 1.8779, Accuracy: 2034/5000 (41%)\n",
      "[epoch 27] loss: 0.0127764\n",
      "Test set: Average loss: 1.8808, Accuracy: 2039/5000 (41%)\n",
      "[epoch 28] loss: 0.0118335\n",
      "Test set: Average loss: 1.8837, Accuracy: 2045/5000 (41%)\n",
      "[epoch 29] loss: 0.0110133\n",
      "Test set: Average loss: 1.8865, Accuracy: 2049/5000 (41%)\n",
      "[epoch 30] loss: 0.0102969\n",
      "Test set: Average loss: 1.8892, Accuracy: 2056/5000 (41%)\n",
      "[epoch 31] loss: 0.0096681\n",
      "Test set: Average loss: 1.8918, Accuracy: 2053/5000 (41%)\n",
      "[epoch 32] loss: 0.0091136\n",
      "Test set: Average loss: 1.8944, Accuracy: 2056/5000 (41%)\n",
      "[epoch 33] loss: 0.0086222\n",
      "Test set: Average loss: 1.8969, Accuracy: 2058/5000 (41%)\n",
      "[epoch 34] loss: 0.0081838\n",
      "Test set: Average loss: 1.8993, Accuracy: 2055/5000 (41%)\n",
      "[epoch 35] loss: 0.0077908\n",
      "Test set: Average loss: 1.9017, Accuracy: 2055/5000 (41%)\n",
      "[epoch 36] loss: 0.0074366\n",
      "Test set: Average loss: 1.9040, Accuracy: 2053/5000 (41%)\n",
      "[epoch 37] loss: 0.0071159\n",
      "Test set: Average loss: 1.9062, Accuracy: 2054/5000 (41%)\n",
      "[epoch 38] loss: 0.0068244\n",
      "Test set: Average loss: 1.9083, Accuracy: 2054/5000 (41%)\n",
      "[epoch 39] loss: 0.0065588\n",
      "Test set: Average loss: 1.9103, Accuracy: 2049/5000 (41%)\n",
      "[epoch 40] loss: 0.0063158\n",
      "Test set: Average loss: 1.9123, Accuracy: 2050/5000 (41%)\n",
      "[epoch 41] loss: 0.0060930\n",
      "Test set: Average loss: 1.9141, Accuracy: 2048/5000 (41%)\n",
      "[epoch 42] loss: 0.0058880\n",
      "Test set: Average loss: 1.9159, Accuracy: 2052/5000 (41%)\n",
      "[epoch 43] loss: 0.0056989\n",
      "Test set: Average loss: 1.9175, Accuracy: 2051/5000 (41%)\n",
      "[epoch 44] loss: 0.0055241\n",
      "Test set: Average loss: 1.9191, Accuracy: 2050/5000 (41%)\n",
      "[epoch 45] loss: 0.0053618\n",
      "Test set: Average loss: 1.9205, Accuracy: 2049/5000 (41%)\n",
      "[epoch 46] loss: 0.0052111\n",
      "Test set: Average loss: 1.9219, Accuracy: 2052/5000 (41%)\n",
      "[epoch 47] loss: 0.0050706\n",
      "Test set: Average loss: 1.9232, Accuracy: 2055/5000 (41%)\n",
      "[epoch 48] loss: 0.0049395\n",
      "Test set: Average loss: 1.9244, Accuracy: 2052/5000 (41%)\n",
      "[epoch 49] loss: 0.0048166\n",
      "Test set: Average loss: 1.9256, Accuracy: 2053/5000 (41%)\n",
      "[epoch 50] loss: 0.0047012\n",
      "Test set: Average loss: 1.9267, Accuracy: 2054/5000 (41%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8969, Accuracy: 2058/5000 (41%)\n",
      "Test\n",
      "Test set: Average loss: 1.8770, Accuracy: 4110/10000 (41%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5192, Accuracy: 400/5000 (8%)\n",
      "[epoch 1] loss: 2.2319496\n",
      "Test set: Average loss: 2.4137, Accuracy: 598/5000 (12%)\n",
      "[epoch 2] loss: 1.5823876\n",
      "Test set: Average loss: 2.3211, Accuracy: 810/5000 (16%)\n",
      "[epoch 3] loss: 1.0938981\n",
      "Test set: Average loss: 2.2438, Accuracy: 1019/5000 (20%)\n",
      "[epoch 4] loss: 0.7624211\n",
      "Test set: Average loss: 2.1799, Accuracy: 1198/5000 (24%)\n",
      "[epoch 5] loss: 0.5341960\n",
      "Test set: Average loss: 2.1278, Accuracy: 1346/5000 (27%)\n",
      "[epoch 6] loss: 0.3797339\n",
      "Test set: Average loss: 2.0864, Accuracy: 1427/5000 (29%)\n",
      "[epoch 7] loss: 0.2748982\n",
      "Test set: Average loss: 2.0539, Accuracy: 1508/5000 (30%)\n",
      "[epoch 8] loss: 0.2029669\n",
      "Test set: Average loss: 2.0287, Accuracy: 1574/5000 (31%)\n",
      "[epoch 9] loss: 0.1529231\n",
      "Test set: Average loss: 2.0094, Accuracy: 1625/5000 (32%)\n",
      "[epoch 10] loss: 0.1175013\n",
      "Test set: Average loss: 1.9947, Accuracy: 1672/5000 (33%)\n",
      "[epoch 11] loss: 0.0921331\n",
      "Test set: Average loss: 1.9839, Accuracy: 1712/5000 (34%)\n",
      "[epoch 12] loss: 0.0736802\n",
      "Test set: Average loss: 1.9761, Accuracy: 1729/5000 (35%)\n",
      "[epoch 13] loss: 0.0599561\n",
      "Test set: Average loss: 1.9707, Accuracy: 1738/5000 (35%)\n",
      "[epoch 14] loss: 0.0495251\n",
      "Test set: Average loss: 1.9673, Accuracy: 1754/5000 (35%)\n",
      "[epoch 15] loss: 0.0414314\n",
      "Test set: Average loss: 1.9654, Accuracy: 1773/5000 (35%)\n",
      "[epoch 16] loss: 0.0350357\n",
      "Test set: Average loss: 1.9648, Accuracy: 1791/5000 (36%)\n",
      "[epoch 17] loss: 0.0299416\n",
      "Test set: Average loss: 1.9652, Accuracy: 1815/5000 (36%)\n",
      "[epoch 18] loss: 0.0258690\n",
      "Test set: Average loss: 1.9664, Accuracy: 1824/5000 (36%)\n",
      "[epoch 19] loss: 0.0225861\n",
      "Test set: Average loss: 1.9682, Accuracy: 1843/5000 (37%)\n",
      "[epoch 20] loss: 0.0199137\n",
      "Test set: Average loss: 1.9705, Accuracy: 1851/5000 (37%)\n",
      "[epoch 21] loss: 0.0177141\n",
      "Test set: Average loss: 1.9731, Accuracy: 1854/5000 (37%)\n",
      "[epoch 22] loss: 0.0158845\n",
      "Test set: Average loss: 1.9761, Accuracy: 1855/5000 (37%)\n",
      "[epoch 23] loss: 0.0143497\n",
      "Test set: Average loss: 1.9792, Accuracy: 1856/5000 (37%)\n",
      "[epoch 24] loss: 0.0130515\n",
      "Test set: Average loss: 1.9824, Accuracy: 1859/5000 (37%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25] loss: 0.0119451\n",
      "Test set: Average loss: 1.9857, Accuracy: 1860/5000 (37%)\n",
      "[epoch 26] loss: 0.0109966\n",
      "Test set: Average loss: 1.9890, Accuracy: 1859/5000 (37%)\n",
      "[epoch 27] loss: 0.0101791\n",
      "Test set: Average loss: 1.9923, Accuracy: 1863/5000 (37%)\n",
      "[epoch 28] loss: 0.0094711\n",
      "Test set: Average loss: 1.9956, Accuracy: 1867/5000 (37%)\n",
      "[epoch 29] loss: 0.0088550\n",
      "Test set: Average loss: 1.9989, Accuracy: 1871/5000 (37%)\n",
      "[epoch 30] loss: 0.0083156\n",
      "Test set: Average loss: 2.0020, Accuracy: 1870/5000 (37%)\n",
      "[epoch 31] loss: 0.0078402\n",
      "Test set: Average loss: 2.0051, Accuracy: 1874/5000 (37%)\n",
      "[epoch 32] loss: 0.0074189\n",
      "Test set: Average loss: 2.0081, Accuracy: 1873/5000 (37%)\n",
      "[epoch 33] loss: 0.0070436\n",
      "Test set: Average loss: 2.0110, Accuracy: 1873/5000 (37%)\n",
      "[epoch 34] loss: 0.0067078\n",
      "Test set: Average loss: 2.0137, Accuracy: 1875/5000 (38%)\n",
      "[epoch 35] loss: 0.0064064\n",
      "Test set: Average loss: 2.0164, Accuracy: 1878/5000 (38%)\n",
      "[epoch 36] loss: 0.0061351\n",
      "Test set: Average loss: 2.0189, Accuracy: 1881/5000 (38%)\n",
      "[epoch 37] loss: 0.0058901\n",
      "Test set: Average loss: 2.0214, Accuracy: 1880/5000 (38%)\n",
      "[epoch 38] loss: 0.0056680\n",
      "Test set: Average loss: 2.0237, Accuracy: 1878/5000 (38%)\n",
      "[epoch 39] loss: 0.0054659\n",
      "Test set: Average loss: 2.0259, Accuracy: 1876/5000 (38%)\n",
      "[epoch 40] loss: 0.0052812\n",
      "Test set: Average loss: 2.0280, Accuracy: 1879/5000 (38%)\n",
      "[epoch 41] loss: 0.0051118\n",
      "Test set: Average loss: 2.0300, Accuracy: 1881/5000 (38%)\n",
      "[epoch 42] loss: 0.0049557\n",
      "Test set: Average loss: 2.0319, Accuracy: 1880/5000 (38%)\n",
      "[epoch 43] loss: 0.0048115\n",
      "Test set: Average loss: 2.0337, Accuracy: 1881/5000 (38%)\n",
      "[epoch 44] loss: 0.0046779\n",
      "Test set: Average loss: 2.0354, Accuracy: 1881/5000 (38%)\n",
      "[epoch 45] loss: 0.0045536\n",
      "Test set: Average loss: 2.0370, Accuracy: 1881/5000 (38%)\n",
      "[epoch 46] loss: 0.0044381\n",
      "Test set: Average loss: 2.0386, Accuracy: 1879/5000 (38%)\n",
      "[epoch 47] loss: 0.0043300\n",
      "Test set: Average loss: 2.0401, Accuracy: 1878/5000 (38%)\n",
      "[epoch 48] loss: 0.0042288\n",
      "Test set: Average loss: 2.0415, Accuracy: 1877/5000 (38%)\n",
      "[epoch 49] loss: 0.0041339\n",
      "Test set: Average loss: 2.0428, Accuracy: 1876/5000 (38%)\n",
      "[epoch 50] loss: 0.0040444\n",
      "Test set: Average loss: 2.0441, Accuracy: 1878/5000 (38%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0370, Accuracy: 1881/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 2.0257, Accuracy: 3864/10000 (39%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4100, Accuracy: 567/5000 (11%)\n",
      "[epoch 1] loss: 2.5181510\n",
      "Test set: Average loss: 2.3288, Accuracy: 645/5000 (13%)\n",
      "[epoch 2] loss: 1.8052666\n",
      "Test set: Average loss: 2.2581, Accuracy: 823/5000 (16%)\n",
      "[epoch 3] loss: 1.3013726\n",
      "Test set: Average loss: 2.1983, Accuracy: 1007/5000 (20%)\n",
      "[epoch 4] loss: 0.9380128\n",
      "Test set: Average loss: 2.1491, Accuracy: 1136/5000 (23%)\n",
      "[epoch 5] loss: 0.6762526\n",
      "Test set: Average loss: 2.1102, Accuracy: 1213/5000 (24%)\n",
      "[epoch 6] loss: 0.4878183\n",
      "Test set: Average loss: 2.0807, Accuracy: 1245/5000 (25%)\n",
      "[epoch 7] loss: 0.3565239\n",
      "Test set: Average loss: 2.0595, Accuracy: 1270/5000 (25%)\n",
      "[epoch 8] loss: 0.2645057\n",
      "Test set: Average loss: 2.0454, Accuracy: 1263/5000 (25%)\n",
      "[epoch 9] loss: 0.1992835\n",
      "Test set: Average loss: 2.0371, Accuracy: 1268/5000 (25%)\n",
      "[epoch 10] loss: 0.1522504\n",
      "Test set: Average loss: 2.0335, Accuracy: 1276/5000 (26%)\n",
      "[epoch 11] loss: 0.1180393\n",
      "Test set: Average loss: 2.0334, Accuracy: 1282/5000 (26%)\n",
      "[epoch 12] loss: 0.0929547\n",
      "Test set: Average loss: 2.0360, Accuracy: 1266/5000 (25%)\n",
      "[epoch 13] loss: 0.0743322\n",
      "Test set: Average loss: 2.0406, Accuracy: 1265/5000 (25%)\n",
      "[epoch 14] loss: 0.0603365\n",
      "Test set: Average loss: 2.0465, Accuracy: 1268/5000 (25%)\n",
      "[epoch 15] loss: 0.0496977\n",
      "Test set: Average loss: 2.0534, Accuracy: 1271/5000 (25%)\n",
      "[epoch 16] loss: 0.0415232\n",
      "Test set: Average loss: 2.0609, Accuracy: 1277/5000 (26%)\n",
      "[epoch 17] loss: 0.0351746\n",
      "Test set: Average loss: 2.0687, Accuracy: 1278/5000 (26%)\n",
      "[epoch 18] loss: 0.0301887\n",
      "Test set: Average loss: 2.0767, Accuracy: 1286/5000 (26%)\n",
      "[epoch 19] loss: 0.0262242\n",
      "Test set: Average loss: 2.0846, Accuracy: 1291/5000 (26%)\n",
      "[epoch 20] loss: 0.0230295\n",
      "Test set: Average loss: 2.0924, Accuracy: 1290/5000 (26%)\n",
      "[epoch 21] loss: 0.0204196\n",
      "Test set: Average loss: 2.1000, Accuracy: 1294/5000 (26%)\n",
      "[epoch 22] loss: 0.0182621\n",
      "Test set: Average loss: 2.1072, Accuracy: 1295/5000 (26%)\n",
      "[epoch 23] loss: 0.0164600\n",
      "Test set: Average loss: 2.1142, Accuracy: 1299/5000 (26%)\n",
      "[epoch 24] loss: 0.0149402\n",
      "Test set: Average loss: 2.1208, Accuracy: 1298/5000 (26%)\n",
      "[epoch 25] loss: 0.0136476\n",
      "Test set: Average loss: 2.1270, Accuracy: 1296/5000 (26%)\n",
      "[epoch 26] loss: 0.0125405\n",
      "Test set: Average loss: 2.1329, Accuracy: 1294/5000 (26%)\n",
      "[epoch 27] loss: 0.0115857\n",
      "Test set: Average loss: 2.1385, Accuracy: 1296/5000 (26%)\n",
      "[epoch 28] loss: 0.0107573\n",
      "Test set: Average loss: 2.1437, Accuracy: 1300/5000 (26%)\n",
      "[epoch 29] loss: 0.0100343\n",
      "Test set: Average loss: 2.1486, Accuracy: 1297/5000 (26%)\n",
      "[epoch 30] loss: 0.0094000\n",
      "Test set: Average loss: 2.1531, Accuracy: 1302/5000 (26%)\n",
      "[epoch 31] loss: 0.0088402\n",
      "Test set: Average loss: 2.1574, Accuracy: 1301/5000 (26%)\n",
      "[epoch 32] loss: 0.0083432\n",
      "Test set: Average loss: 2.1615, Accuracy: 1301/5000 (26%)\n",
      "[epoch 33] loss: 0.0078984\n",
      "Test set: Average loss: 2.1652, Accuracy: 1302/5000 (26%)\n",
      "[epoch 34] loss: 0.0074988\n",
      "Test set: Average loss: 2.1688, Accuracy: 1304/5000 (26%)\n",
      "[epoch 35] loss: 0.0071398\n",
      "Test set: Average loss: 2.1722, Accuracy: 1302/5000 (26%)\n",
      "[epoch 36] loss: 0.0068171\n",
      "Test set: Average loss: 2.1754, Accuracy: 1300/5000 (26%)\n",
      "[epoch 37] loss: 0.0065260\n",
      "Test set: Average loss: 2.1784, Accuracy: 1299/5000 (26%)\n",
      "[epoch 38] loss: 0.0062621\n",
      "Test set: Average loss: 2.1813, Accuracy: 1297/5000 (26%)\n",
      "[epoch 39] loss: 0.0060215\n",
      "Test set: Average loss: 2.1840, Accuracy: 1297/5000 (26%)\n",
      "[epoch 40] loss: 0.0058016\n",
      "Test set: Average loss: 2.1866, Accuracy: 1294/5000 (26%)\n",
      "[epoch 41] loss: 0.0055999\n",
      "Test set: Average loss: 2.1891, Accuracy: 1295/5000 (26%)\n",
      "[epoch 42] loss: 0.0054144\n",
      "Test set: Average loss: 2.1914, Accuracy: 1295/5000 (26%)\n",
      "[epoch 43] loss: 0.0052434\n",
      "Test set: Average loss: 2.1937, Accuracy: 1295/5000 (26%)\n",
      "[epoch 44] loss: 0.0050852\n",
      "Test set: Average loss: 2.1959, Accuracy: 1294/5000 (26%)\n",
      "[epoch 45] loss: 0.0049386\n",
      "Test set: Average loss: 2.1979, Accuracy: 1294/5000 (26%)\n",
      "[epoch 46] loss: 0.0048024\n",
      "Test set: Average loss: 2.1999, Accuracy: 1296/5000 (26%)\n",
      "[epoch 47] loss: 0.0046755\n",
      "Test set: Average loss: 2.2018, Accuracy: 1296/5000 (26%)\n",
      "[epoch 48] loss: 0.0045572\n",
      "Test set: Average loss: 2.2036, Accuracy: 1298/5000 (26%)\n",
      "[epoch 49] loss: 0.0044466\n",
      "Test set: Average loss: 2.2054, Accuracy: 1304/5000 (26%)\n",
      "[epoch 50] loss: 0.0043431\n",
      "Test set: Average loss: 2.2071, Accuracy: 1303/5000 (26%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2054, Accuracy: 1304/5000 (26%)\n",
      "Test\n",
      "Test set: Average loss: 2.2179, Accuracy: 2511/10000 (25%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4025, Accuracy: 512/5000 (10%)\n",
      "[epoch 1] loss: 2.3925529\n",
      "Test set: Average loss: 2.2174, Accuracy: 940/5000 (19%)\n",
      "[epoch 2] loss: 1.5420281\n",
      "Test set: Average loss: 2.0865, Accuracy: 1317/5000 (26%)\n",
      "[epoch 3] loss: 1.0108413\n",
      "Test set: Average loss: 1.9816, Accuracy: 1566/5000 (31%)\n",
      "[epoch 4] loss: 0.7121639\n",
      "Test set: Average loss: 1.9054, Accuracy: 1695/5000 (34%)\n",
      "[epoch 5] loss: 0.4770555\n",
      "Test set: Average loss: 1.8447, Accuracy: 1788/5000 (36%)\n",
      "[epoch 6] loss: 0.3520758\n",
      "Test set: Average loss: 1.7989, Accuracy: 1860/5000 (37%)\n",
      "[epoch 7] loss: 0.2412497\n",
      "Test set: Average loss: 1.7622, Accuracy: 1914/5000 (38%)\n",
      "[epoch 8] loss: 0.1906134\n",
      "Test set: Average loss: 1.7328, Accuracy: 1954/5000 (39%)\n",
      "[epoch 9] loss: 0.1503310\n",
      "Test set: Average loss: 1.7087, Accuracy: 1998/5000 (40%)\n",
      "[epoch 10] loss: 0.1163722\n",
      "Test set: Average loss: 1.6894, Accuracy: 2026/5000 (41%)\n",
      "[epoch 11] loss: 0.0906266\n",
      "Test set: Average loss: 1.6745, Accuracy: 2048/5000 (41%)\n",
      "[epoch 12] loss: 0.0723625\n",
      "Test set: Average loss: 1.6631, Accuracy: 2082/5000 (42%)\n",
      "[epoch 13] loss: 0.0608708\n",
      "Test set: Average loss: 1.6538, Accuracy: 2089/5000 (42%)\n",
      "[epoch 14] loss: 0.0500847\n",
      "Test set: Average loss: 1.6476, Accuracy: 2102/5000 (42%)\n",
      "[epoch 15] loss: 0.0423093\n",
      "Test set: Average loss: 1.6434, Accuracy: 2122/5000 (42%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 0.0373196\n",
      "Test set: Average loss: 1.6407, Accuracy: 2132/5000 (43%)\n",
      "[epoch 17] loss: 0.0323341\n",
      "Test set: Average loss: 1.6386, Accuracy: 2139/5000 (43%)\n",
      "[epoch 18] loss: 0.0292754\n",
      "Test set: Average loss: 1.6372, Accuracy: 2146/5000 (43%)\n",
      "[epoch 19] loss: 0.0270954\n",
      "Test set: Average loss: 1.6365, Accuracy: 2160/5000 (43%)\n",
      "[epoch 20] loss: 0.0241164\n",
      "Test set: Average loss: 1.6360, Accuracy: 2161/5000 (43%)\n",
      "[epoch 21] loss: 0.0223833\n",
      "Test set: Average loss: 1.6360, Accuracy: 2161/5000 (43%)\n",
      "[epoch 22] loss: 0.0217443\n",
      "Test set: Average loss: 1.6364, Accuracy: 2165/5000 (43%)\n",
      "[epoch 23] loss: 0.0193364\n",
      "Test set: Average loss: 1.6366, Accuracy: 2171/5000 (43%)\n",
      "[epoch 24] loss: 0.0179647\n",
      "Test set: Average loss: 1.6371, Accuracy: 2181/5000 (44%)\n",
      "[epoch 25] loss: 0.0177871\n",
      "Test set: Average loss: 1.6373, Accuracy: 2185/5000 (44%)\n",
      "[epoch 26] loss: 0.0163408\n",
      "Test set: Average loss: 1.6377, Accuracy: 2191/5000 (44%)\n",
      "[epoch 27] loss: 0.0156019\n",
      "Test set: Average loss: 1.6380, Accuracy: 2191/5000 (44%)\n",
      "[epoch 28] loss: 0.0150424\n",
      "Test set: Average loss: 1.6386, Accuracy: 2193/5000 (44%)\n",
      "[epoch 29] loss: 0.0139915\n",
      "Test set: Average loss: 1.6390, Accuracy: 2194/5000 (44%)\n",
      "[epoch 30] loss: 0.0133170\n",
      "Test set: Average loss: 1.6395, Accuracy: 2195/5000 (44%)\n",
      "[epoch 31] loss: 0.0128899\n",
      "Test set: Average loss: 1.6401, Accuracy: 2194/5000 (44%)\n",
      "[epoch 32] loss: 0.0123165\n",
      "Test set: Average loss: 1.6405, Accuracy: 2196/5000 (44%)\n",
      "[epoch 33] loss: 0.0121913\n",
      "Test set: Average loss: 1.6412, Accuracy: 2197/5000 (44%)\n",
      "[epoch 34] loss: 0.0114790\n",
      "Test set: Average loss: 1.6418, Accuracy: 2203/5000 (44%)\n",
      "[epoch 35] loss: 0.0109164\n",
      "Test set: Average loss: 1.6425, Accuracy: 2202/5000 (44%)\n",
      "[epoch 36] loss: 0.0108057\n",
      "Test set: Average loss: 1.6432, Accuracy: 2201/5000 (44%)\n",
      "[epoch 37] loss: 0.0106274\n",
      "Test set: Average loss: 1.6439, Accuracy: 2203/5000 (44%)\n",
      "[epoch 38] loss: 0.0100653\n",
      "Test set: Average loss: 1.6445, Accuracy: 2203/5000 (44%)\n",
      "[epoch 39] loss: 0.0099063\n",
      "Test set: Average loss: 1.6453, Accuracy: 2203/5000 (44%)\n",
      "[epoch 40] loss: 0.0094230\n",
      "Test set: Average loss: 1.6458, Accuracy: 2205/5000 (44%)\n",
      "[epoch 41] loss: 0.0095496\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6465, Accuracy: 2204/5000 (44%)\n",
      "[epoch 42] loss: 0.0092043\n",
      "Test set: Average loss: 1.6465, Accuracy: 2204/5000 (44%)\n",
      "[epoch 43] loss: 0.0087585\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 44] loss: 0.0091128\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 45] loss: 0.0090723\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 46] loss: 0.0089504\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 47] loss: 0.0091006\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 48] loss: 0.0091656\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 49] loss: 0.0089262\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "[epoch 50] loss: 0.0091609\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.6466, Accuracy: 2204/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6458, Accuracy: 2205/5000 (44%)\n",
      "Test\n",
      "Test set: Average loss: 1.6145, Accuracy: 4530/10000 (45%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3988, Accuracy: 645/5000 (13%)\n",
      "[epoch 1] loss: 2.4630734\n",
      "Test set: Average loss: 2.1987, Accuracy: 1126/5000 (23%)\n",
      "[epoch 2] loss: 1.5490174\n",
      "Test set: Average loss: 2.0353, Accuracy: 1513/5000 (30%)\n",
      "[epoch 3] loss: 0.9855799\n",
      "Test set: Average loss: 1.9098, Accuracy: 1758/5000 (35%)\n",
      "[epoch 4] loss: 0.6816396\n",
      "Test set: Average loss: 1.8170, Accuracy: 1912/5000 (38%)\n",
      "[epoch 5] loss: 0.4567527\n",
      "Test set: Average loss: 1.7488, Accuracy: 2020/5000 (40%)\n",
      "[epoch 6] loss: 0.3152941\n",
      "Test set: Average loss: 1.6972, Accuracy: 2091/5000 (42%)\n",
      "[epoch 7] loss: 0.2224179\n",
      "Test set: Average loss: 1.6570, Accuracy: 2143/5000 (43%)\n",
      "[epoch 8] loss: 0.1658560\n",
      "Test set: Average loss: 1.6259, Accuracy: 2183/5000 (44%)\n",
      "[epoch 9] loss: 0.1182886\n",
      "Test set: Average loss: 1.6002, Accuracy: 2224/5000 (44%)\n",
      "[epoch 10] loss: 0.0945711\n",
      "Test set: Average loss: 1.5807, Accuracy: 2256/5000 (45%)\n",
      "[epoch 11] loss: 0.0737098\n",
      "Test set: Average loss: 1.5664, Accuracy: 2276/5000 (46%)\n",
      "[epoch 12] loss: 0.0622701\n",
      "Test set: Average loss: 1.5564, Accuracy: 2297/5000 (46%)\n",
      "[epoch 13] loss: 0.0509411\n",
      "Test set: Average loss: 1.5492, Accuracy: 2317/5000 (46%)\n",
      "[epoch 14] loss: 0.0427795\n",
      "Test set: Average loss: 1.5447, Accuracy: 2329/5000 (47%)\n",
      "[epoch 15] loss: 0.0373836\n",
      "Test set: Average loss: 1.5419, Accuracy: 2340/5000 (47%)\n",
      "[epoch 16] loss: 0.0329101\n",
      "Test set: Average loss: 1.5407, Accuracy: 2350/5000 (47%)\n",
      "[epoch 17] loss: 0.0291786\n",
      "Test set: Average loss: 1.5404, Accuracy: 2353/5000 (47%)\n",
      "[epoch 18] loss: 0.0258588\n",
      "Test set: Average loss: 1.5406, Accuracy: 2358/5000 (47%)\n",
      "[epoch 19] loss: 0.0233078\n",
      "Test set: Average loss: 1.5411, Accuracy: 2363/5000 (47%)\n",
      "[epoch 20] loss: 0.0219835\n",
      "Test set: Average loss: 1.5418, Accuracy: 2365/5000 (47%)\n",
      "[epoch 21] loss: 0.0207581\n",
      "Test set: Average loss: 1.5427, Accuracy: 2363/5000 (47%)\n",
      "[epoch 22] loss: 0.0191280\n",
      "Test set: Average loss: 1.5435, Accuracy: 2365/5000 (47%)\n",
      "[epoch 23] loss: 0.0177639\n",
      "Test set: Average loss: 1.5444, Accuracy: 2371/5000 (47%)\n",
      "[epoch 24] loss: 0.0168052\n",
      "Test set: Average loss: 1.5453, Accuracy: 2374/5000 (47%)\n",
      "[epoch 25] loss: 0.0152204\n",
      "Test set: Average loss: 1.5463, Accuracy: 2376/5000 (48%)\n",
      "[epoch 26] loss: 0.0144698\n",
      "Test set: Average loss: 1.5472, Accuracy: 2382/5000 (48%)\n",
      "[epoch 27] loss: 0.0139810\n",
      "Test set: Average loss: 1.5482, Accuracy: 2384/5000 (48%)\n",
      "[epoch 28] loss: 0.0128097\n",
      "Test set: Average loss: 1.5492, Accuracy: 2384/5000 (48%)\n",
      "[epoch 29] loss: 0.0123821\n",
      "Test set: Average loss: 1.5501, Accuracy: 2382/5000 (48%)\n",
      "[epoch 30] loss: 0.0122759\n",
      "Test set: Average loss: 1.5512, Accuracy: 2378/5000 (48%)\n",
      "[epoch 31] loss: 0.0114026\n",
      "Test set: Average loss: 1.5522, Accuracy: 2375/5000 (48%)\n",
      "[epoch 32] loss: 0.0112328\n",
      "Test set: Average loss: 1.5533, Accuracy: 2378/5000 (48%)\n",
      "[epoch 33] loss: 0.0106607\n",
      "Test set: Average loss: 1.5543, Accuracy: 2378/5000 (48%)\n",
      "[epoch 34] loss: 0.0102918\n",
      "Test set: Average loss: 1.5553, Accuracy: 2377/5000 (48%)\n",
      "[epoch 35] loss: 0.0099896\n",
      "Test set: Average loss: 1.5564, Accuracy: 2377/5000 (48%)\n",
      "[epoch 36] loss: 0.0100152\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5575, Accuracy: 2379/5000 (48%)\n",
      "[epoch 37] loss: 0.0096746\n",
      "Test set: Average loss: 1.5576, Accuracy: 2379/5000 (48%)\n",
      "[epoch 38] loss: 0.0095842\n",
      "Test set: Average loss: 1.5577, Accuracy: 2378/5000 (48%)\n",
      "[epoch 39] loss: 0.0095597\n",
      "Test set: Average loss: 1.5578, Accuracy: 2378/5000 (48%)\n",
      "[epoch 40] loss: 0.0092778\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 41] loss: 0.0096870\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 42] loss: 0.0091676\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 43] loss: 0.0093484\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 44] loss: 0.0096319\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 45] loss: 0.0094780\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 46] loss: 0.0094165\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 47] loss: 0.0096636\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 48] loss: 0.0095388\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 49] loss: 0.0094276\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "[epoch 50] loss: 0.0091216\n",
      "Test set: Average loss: 1.5579, Accuracy: 2378/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5492, Accuracy: 2384/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 1.5241, Accuracy: 4810/10000 (48%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3608, Accuracy: 667/5000 (13%)\n",
      "[epoch 1] loss: 2.4061157\n",
      "Test set: Average loss: 2.1775, Accuracy: 1060/5000 (21%)\n",
      "[epoch 2] loss: 1.5359423\n",
      "Test set: Average loss: 2.0365, Accuracy: 1454/5000 (29%)\n",
      "[epoch 3] loss: 0.9820428\n",
      "Test set: Average loss: 1.9340, Accuracy: 1700/5000 (34%)\n",
      "[epoch 4] loss: 0.6589474\n",
      "Test set: Average loss: 1.8623, Accuracy: 1766/5000 (35%)\n",
      "[epoch 5] loss: 0.4545093\n",
      "Test set: Average loss: 1.8127, Accuracy: 1822/5000 (36%)\n",
      "[epoch 6] loss: 0.3069997\n",
      "Test set: Average loss: 1.7767, Accuracy: 1874/5000 (37%)\n",
      "[epoch 7] loss: 0.2201804\n",
      "Test set: Average loss: 1.7503, Accuracy: 1902/5000 (38%)\n",
      "[epoch 8] loss: 0.1613786\n",
      "Test set: Average loss: 1.7316, Accuracy: 1931/5000 (39%)\n",
      "[epoch 9] loss: 0.1222608\n",
      "Test set: Average loss: 1.7179, Accuracy: 1954/5000 (39%)\n",
      "[epoch 10] loss: 0.0990252\n",
      "Test set: Average loss: 1.7083, Accuracy: 1978/5000 (40%)\n",
      "[epoch 11] loss: 0.0758120\n",
      "Test set: Average loss: 1.7012, Accuracy: 1995/5000 (40%)\n",
      "[epoch 12] loss: 0.0590897\n",
      "Test set: Average loss: 1.6963, Accuracy: 2012/5000 (40%)\n",
      "[epoch 13] loss: 0.0519974\n",
      "Test set: Average loss: 1.6932, Accuracy: 2011/5000 (40%)\n",
      "[epoch 14] loss: 0.0426492\n",
      "Test set: Average loss: 1.6909, Accuracy: 2020/5000 (40%)\n",
      "[epoch 15] loss: 0.0373686\n",
      "Test set: Average loss: 1.6896, Accuracy: 2028/5000 (41%)\n",
      "[epoch 16] loss: 0.0332837\n",
      "Test set: Average loss: 1.6888, Accuracy: 2029/5000 (41%)\n",
      "[epoch 17] loss: 0.0289573\n",
      "Test set: Average loss: 1.6885, Accuracy: 2038/5000 (41%)\n",
      "[epoch 18] loss: 0.0259743\n",
      "Test set: Average loss: 1.6886, Accuracy: 2042/5000 (41%)\n",
      "[epoch 19] loss: 0.0237459\n",
      "Test set: Average loss: 1.6893, Accuracy: 2048/5000 (41%)\n",
      "[epoch 20] loss: 0.0217946\n",
      "Test set: Average loss: 1.6904, Accuracy: 2048/5000 (41%)\n",
      "[epoch 21] loss: 0.0199770\n",
      "Test set: Average loss: 1.6921, Accuracy: 2042/5000 (41%)\n",
      "[epoch 22] loss: 0.0182806\n",
      "Test set: Average loss: 1.6939, Accuracy: 2044/5000 (41%)\n",
      "[epoch 23] loss: 0.0168712\n",
      "Test set: Average loss: 1.6958, Accuracy: 2049/5000 (41%)\n",
      "[epoch 24] loss: 0.0160663\n",
      "Test set: Average loss: 1.6977, Accuracy: 2054/5000 (41%)\n",
      "[epoch 25] loss: 0.0151810\n",
      "Test set: Average loss: 1.6995, Accuracy: 2056/5000 (41%)\n",
      "[epoch 26] loss: 0.0147742\n",
      "Test set: Average loss: 1.7016, Accuracy: 2057/5000 (41%)\n",
      "[epoch 27] loss: 0.0135556\n",
      "Test set: Average loss: 1.7038, Accuracy: 2058/5000 (41%)\n",
      "[epoch 28] loss: 0.0130227\n",
      "Test set: Average loss: 1.7060, Accuracy: 2059/5000 (41%)\n",
      "[epoch 29] loss: 0.0126262\n",
      "Test set: Average loss: 1.7081, Accuracy: 2058/5000 (41%)\n",
      "[epoch 30] loss: 0.0116516\n",
      "Test set: Average loss: 1.7101, Accuracy: 2060/5000 (41%)\n",
      "[epoch 31] loss: 0.0115328\n",
      "Test set: Average loss: 1.7119, Accuracy: 2064/5000 (41%)\n",
      "[epoch 32] loss: 0.0110627\n",
      "Test set: Average loss: 1.7135, Accuracy: 2066/5000 (41%)\n",
      "[epoch 33] loss: 0.0104805\n",
      "Test set: Average loss: 1.7149, Accuracy: 2065/5000 (41%)\n",
      "[epoch 34] loss: 0.0101013\n",
      "Test set: Average loss: 1.7163, Accuracy: 2068/5000 (41%)\n",
      "[epoch 35] loss: 0.0097186\n",
      "Test set: Average loss: 1.7175, Accuracy: 2065/5000 (41%)\n",
      "[epoch 36] loss: 0.0096687\n",
      "Test set: Average loss: 1.7186, Accuracy: 2068/5000 (41%)\n",
      "[epoch 37] loss: 0.0092991\n",
      "Test set: Average loss: 1.7198, Accuracy: 2069/5000 (41%)\n",
      "[epoch 38] loss: 0.0088459\n",
      "Test set: Average loss: 1.7211, Accuracy: 2067/5000 (41%)\n",
      "[epoch 39] loss: 0.0086375\n",
      "Test set: Average loss: 1.7223, Accuracy: 2070/5000 (41%)\n",
      "[epoch 40] loss: 0.0086672\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7236, Accuracy: 2073/5000 (41%)\n",
      "[epoch 41] loss: 0.0082743\n",
      "Test set: Average loss: 1.7237, Accuracy: 2073/5000 (41%)\n",
      "[epoch 42] loss: 0.0081108\n",
      "Test set: Average loss: 1.7238, Accuracy: 2073/5000 (41%)\n",
      "[epoch 43] loss: 0.0081292\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 44] loss: 0.0082791\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 45] loss: 0.0084493\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 46] loss: 0.0081255\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 47] loss: 0.0081634\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 48] loss: 0.0083145\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 49] loss: 0.0079030\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "[epoch 50] loss: 0.0082143\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7240, Accuracy: 2074/5000 (41%)\n",
      "Test\n",
      "Test set: Average loss: 1.7421, Accuracy: 4063/10000 (41%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4131, Accuracy: 515/5000 (10%)\n",
      "[epoch 1] loss: 2.1772665\n",
      "Test set: Average loss: 2.0900, Accuracy: 1388/5000 (28%)\n",
      "[epoch 2] loss: 1.2335210\n",
      "Test set: Average loss: 1.9040, Accuracy: 1689/5000 (34%)\n",
      "[epoch 3] loss: 0.7680042\n",
      "Test set: Average loss: 1.7927, Accuracy: 1893/5000 (38%)\n",
      "[epoch 4] loss: 0.5395172\n",
      "Test set: Average loss: 1.7036, Accuracy: 2012/5000 (40%)\n",
      "[epoch 5] loss: 0.3812328\n",
      "Test set: Average loss: 1.6401, Accuracy: 2091/5000 (42%)\n",
      "[epoch 6] loss: 0.2861517\n",
      "Test set: Average loss: 1.5951, Accuracy: 2166/5000 (43%)\n",
      "[epoch 7] loss: 0.2012431\n",
      "Test set: Average loss: 1.5708, Accuracy: 2204/5000 (44%)\n",
      "[epoch 8] loss: 0.1546934\n",
      "Test set: Average loss: 1.5472, Accuracy: 2231/5000 (45%)\n",
      "[epoch 9] loss: 0.1270816\n",
      "Test set: Average loss: 1.5244, Accuracy: 2279/5000 (46%)\n",
      "[epoch 10] loss: 0.1049551\n",
      "Test set: Average loss: 1.5060, Accuracy: 2311/5000 (46%)\n",
      "[epoch 11] loss: 0.0999313\n",
      "Test set: Average loss: 1.4938, Accuracy: 2348/5000 (47%)\n",
      "[epoch 12] loss: 0.0723022\n",
      "Test set: Average loss: 1.4794, Accuracy: 2352/5000 (47%)\n",
      "[epoch 13] loss: 0.0654854\n",
      "Test set: Average loss: 1.4707, Accuracy: 2374/5000 (47%)\n",
      "[epoch 14] loss: 0.0521263\n",
      "Test set: Average loss: 1.4654, Accuracy: 2388/5000 (48%)\n",
      "[epoch 15] loss: 0.0473803\n",
      "Test set: Average loss: 1.4622, Accuracy: 2413/5000 (48%)\n",
      "[epoch 16] loss: 0.0426081\n",
      "Test set: Average loss: 1.4610, Accuracy: 2424/5000 (48%)\n",
      "[epoch 17] loss: 0.0444583\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4596, Accuracy: 2439/5000 (49%)\n",
      "[epoch 18] loss: 0.0325649\n",
      "Test set: Average loss: 1.4594, Accuracy: 2437/5000 (49%)\n",
      "[epoch 19] loss: 0.0353509\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.4593, Accuracy: 2434/5000 (49%)\n",
      "[epoch 20] loss: 0.0336926\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 21] loss: 0.0320639\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 22] loss: 0.0314415\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 23] loss: 0.0354825\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 24] loss: 0.0332585\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 25] loss: 0.0310328\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 26] loss: 0.0378345\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 27] loss: 0.0346639\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] loss: 0.0474439\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 29] loss: 0.0351953\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 30] loss: 0.0324059\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 31] loss: 0.0328699\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 32] loss: 0.0346958\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 33] loss: 1.7289691\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 34] loss: 0.0340168\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 35] loss: 0.0357322\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 36] loss: 0.0377676\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 37] loss: 0.0342479\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 38] loss: 0.0356547\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.4639, Accuracy: 2428/5000 (49%)\n",
      "[epoch 39] loss: 0.0379167\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 40] loss: 0.0316657\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 41] loss: 0.0335919\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 42] loss: 0.0363588\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 43] loss: 0.0343139\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 44] loss: 0.0325735\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 45] loss: 0.0352572\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 46] loss: 0.0341552\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 47] loss: 0.0361014\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 48] loss: 0.0340094\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 49] loss: 1.7578667\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "[epoch 50] loss: 0.0363939\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.4592, Accuracy: 2434/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4596, Accuracy: 2439/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 1.4414, Accuracy: 4946/10000 (49%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3375, Accuracy: 697/5000 (14%)\n",
      "[epoch 1] loss: 2.1731415\n",
      "Test set: Average loss: 1.9651, Accuracy: 1589/5000 (32%)\n",
      "[epoch 2] loss: 1.2388219\n",
      "Test set: Average loss: 1.7297, Accuracy: 2165/5000 (43%)\n",
      "[epoch 3] loss: 0.7043554\n",
      "Test set: Average loss: 1.5820, Accuracy: 2410/5000 (48%)\n",
      "[epoch 4] loss: 0.4981156\n",
      "Test set: Average loss: 1.4827, Accuracy: 2520/5000 (50%)\n",
      "[epoch 5] loss: 1.6701652\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4237, Accuracy: 2593/5000 (52%)\n",
      "[epoch 6] loss: 0.3011782\n",
      "Test set: Average loss: 1.4187, Accuracy: 2600/5000 (52%)\n",
      "[epoch 7] loss: 0.2419075\n",
      "Test set: Average loss: 1.4144, Accuracy: 2617/5000 (52%)\n",
      "[epoch 8] loss: 0.2589101\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.4105, Accuracy: 2624/5000 (52%)\n",
      "[epoch 9] loss: 0.2136404\n",
      "Test set: Average loss: 1.4101, Accuracy: 2625/5000 (52%)\n",
      "[epoch 10] loss: 0.2472735\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.4097, Accuracy: 2627/5000 (53%)\n",
      "[epoch 11] loss: 0.2555663\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 12] loss: 0.2558007\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 13] loss: 0.2158778\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 14] loss: 0.2415314\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 15] loss: 0.2337998\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 16] loss: 0.2222502\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 17] loss: 0.2325170\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 18] loss: 1.2979636\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 19] loss: 0.2432641\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 20] loss: 0.2145046\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 21] loss: 0.2232295\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 22] loss: 0.2452980\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 23] loss: 0.2309602\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 24] loss: 0.2167024\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 25] loss: 0.2364743\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 26] loss: 0.2317119\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 27] loss: 0.2394572\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 28] loss: 0.2199287\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 29] loss: 0.2307809\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 30] loss: 0.2174043\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 31] loss: 0.2419142\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 32] loss: 0.2158798\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 33] loss: 0.2435947\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 34] loss: 0.2503433\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 35] loss: 0.2511355\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 36] loss: 0.2285787\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 37] loss: 0.2315280\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 38] loss: 0.2357167\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 39] loss: 0.2440481\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 40] loss: 1.5880951\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 41] loss: 0.2320045\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 42] loss: 0.2371680\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 43] loss: 0.2487468\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 44] loss: 0.2419668\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 45] loss: 1.6006001\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 46] loss: 0.2356195\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 47] loss: 0.2283465\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 48] loss: 0.2272747\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 49] loss: 0.2399035\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "[epoch 50] loss: 0.2291099\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4096, Accuracy: 2627/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.4038, Accuracy: 5300/10000 (53%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3833, Accuracy: 574/5000 (11%)\n",
      "[epoch 1] loss: 2.0890294\n",
      "Test set: Average loss: 2.0625, Accuracy: 1422/5000 (28%)\n",
      "[epoch 2] loss: 1.2307060\n",
      "Test set: Average loss: 1.8913, Accuracy: 1687/5000 (34%)\n",
      "[epoch 3] loss: 0.7864454\n",
      "Test set: Average loss: 1.7932, Accuracy: 1777/5000 (36%)\n",
      "[epoch 4] loss: 0.4611454\n",
      "Test set: Average loss: 1.7212, Accuracy: 1863/5000 (37%)\n",
      "[epoch 5] loss: 0.3418298\n",
      "Test set: Average loss: 1.6584, Accuracy: 1972/5000 (39%)\n",
      "[epoch 6] loss: 0.2876495\n",
      "Test set: Average loss: 1.6125, Accuracy: 2061/5000 (41%)\n",
      "[epoch 7] loss: 0.2071437\n",
      "Test set: Average loss: 1.5765, Accuracy: 2123/5000 (42%)\n",
      "[epoch 8] loss: 0.1584773\n",
      "Test set: Average loss: 1.5369, Accuracy: 2192/5000 (44%)\n",
      "[epoch 9] loss: 0.1145741\n",
      "Test set: Average loss: 1.5088, Accuracy: 2246/5000 (45%)\n",
      "[epoch 10] loss: 1.3144689\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4972, Accuracy: 2286/5000 (46%)\n",
      "[epoch 11] loss: 0.0855274\n",
      "Test set: Average loss: 1.4985, Accuracy: 2285/5000 (46%)\n",
      "[epoch 12] loss: 0.0810781\n",
      "Test set: Average loss: 1.4991, Accuracy: 2282/5000 (46%)\n",
      "[epoch 13] loss: 0.0846869\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.4993, Accuracy: 2286/5000 (46%)\n",
      "[epoch 14] loss: 0.0731480\n",
      "Test set: Average loss: 1.4993, Accuracy: 2285/5000 (46%)\n",
      "[epoch 15] loss: 0.0755530\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2284/5000 (46%)\n",
      "[epoch 16] loss: 0.0751572\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 17] loss: 0.0808195\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 18] loss: 0.0781670\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 19] loss: 0.0855182\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 20] loss: 0.0839837\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 21] loss: 0.0790230\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 22] loss: 0.0714936\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 23] loss: 0.0905366\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 24] loss: 0.0772996\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 25] loss: 0.0886881\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 26] loss: 0.0828842\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 27] loss: 0.0830585\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 28] loss: 0.0945257\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 29] loss: 0.0839682\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 30] loss: 0.0892957\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 31] loss: 0.0783139\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 32] loss: 0.0856024\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 33] loss: 0.0788773\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 34] loss: 0.0861473\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 35] loss: 0.0789781\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 36] loss: 0.0767791\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 37] loss: 0.0770549\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 38] loss: 0.0830238\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 39] loss: 0.0924432\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 40] loss: 0.0937691\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 41] loss: 0.0855587\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 42] loss: 0.0880478\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 43] loss: 0.0775541\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 44] loss: 0.0801071\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 45] loss: 0.0830148\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 46] loss: 0.0768691\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 47] loss: 0.0851082\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 48] loss: 0.0763561\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 49] loss: 0.0767393\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "[epoch 50] loss: 0.0737572\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.4992, Accuracy: 2285/5000 (46%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4993, Accuracy: 2286/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.5147, Accuracy: 4509/10000 (45%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4558, Accuracy: 592/5000 (12%)\n",
      "[epoch 1] loss: 2.0434659\n",
      "Test set: Average loss: 1.7303, Accuracy: 2188/5000 (44%)\n",
      "[epoch 2] loss: 0.9994962\n",
      "Test set: Average loss: 1.3882, Accuracy: 2670/5000 (53%)\n",
      "[epoch 3] loss: 0.5423876\n",
      "Test set: Average loss: 1.2413, Accuracy: 2907/5000 (58%)\n",
      "[epoch 4] loss: 0.3241899\n",
      "Test set: Average loss: 1.1810, Accuracy: 2996/5000 (60%)\n",
      "[epoch 5] loss: 0.2066196\n",
      "Test set: Average loss: 1.1577, Accuracy: 3011/5000 (60%)\n",
      "[epoch 6] loss: 0.1387915\n",
      "Test set: Average loss: 1.1528, Accuracy: 3029/5000 (61%)\n",
      "[epoch 7] loss: 0.0988632\n",
      "Test set: Average loss: 1.1492, Accuracy: 3041/5000 (61%)\n",
      "[epoch 8] loss: 0.0755436\n",
      "Test set: Average loss: 1.1483, Accuracy: 3035/5000 (61%)\n",
      "[epoch 9] loss: 0.0606841\n",
      "Test set: Average loss: 1.1466, Accuracy: 3037/5000 (61%)\n",
      "[epoch 10] loss: 0.0495642\n",
      "Test set: Average loss: 1.1478, Accuracy: 3050/5000 (61%)\n",
      "[epoch 11] loss: 0.0420002\n",
      "Test set: Average loss: 1.1515, Accuracy: 3042/5000 (61%)\n",
      "[epoch 12] loss: 0.0359978\n",
      "Test set: Average loss: 1.1528, Accuracy: 3046/5000 (61%)\n",
      "[epoch 13] loss: 0.0314253\n",
      "Test set: Average loss: 1.1545, Accuracy: 3045/5000 (61%)\n",
      "[epoch 14] loss: 0.0278858\n",
      "Test set: Average loss: 1.1558, Accuracy: 3051/5000 (61%)\n",
      "[epoch 15] loss: 0.0250394\n",
      "Test set: Average loss: 1.1589, Accuracy: 3043/5000 (61%)\n",
      "[epoch 16] loss: 0.0225845\n",
      "Test set: Average loss: 1.1600, Accuracy: 3053/5000 (61%)\n",
      "[epoch 17] loss: 0.0203911\n",
      "Test set: Average loss: 1.1628, Accuracy: 3048/5000 (61%)\n",
      "[epoch 18] loss: 0.0186780\n",
      "Test set: Average loss: 1.1648, Accuracy: 3051/5000 (61%)\n",
      "[epoch 19] loss: 0.0170739\n",
      "Test set: Average loss: 1.1676, Accuracy: 3049/5000 (61%)\n",
      "[epoch 20] loss: 0.0156799\n",
      "Test set: Average loss: 1.1695, Accuracy: 3049/5000 (61%)\n",
      "[epoch 21] loss: 0.0145343\n",
      "Test set: Average loss: 1.1725, Accuracy: 3047/5000 (61%)\n",
      "[epoch 22] loss: 0.0135043\n",
      "Test set: Average loss: 1.1747, Accuracy: 3045/5000 (61%)\n",
      "[epoch 23] loss: 0.0125045\n",
      "Test set: Average loss: 1.1772, Accuracy: 3045/5000 (61%)\n",
      "[epoch 24] loss: 0.0117211\n",
      "Test set: Average loss: 1.1797, Accuracy: 3043/5000 (61%)\n",
      "[epoch 25] loss: 0.0109488\n",
      "Test set: Average loss: 1.1820, Accuracy: 3043/5000 (61%)\n",
      "[epoch 26] loss: 0.0102996\n",
      "Test set: Average loss: 1.1839, Accuracy: 3038/5000 (61%)\n",
      "[epoch 27] loss: 0.0096781\n",
      "Test set: Average loss: 1.1863, Accuracy: 3038/5000 (61%)\n",
      "[epoch 28] loss: 0.0090906\n",
      "Test set: Average loss: 1.1882, Accuracy: 3037/5000 (61%)\n",
      "[epoch 29] loss: 0.0086542\n",
      "Test set: Average loss: 1.1902, Accuracy: 3037/5000 (61%)\n",
      "[epoch 30] loss: 0.0081883\n",
      "Test set: Average loss: 1.1930, Accuracy: 3034/5000 (61%)\n",
      "[epoch 31] loss: 0.0077373\n",
      "Test set: Average loss: 1.1951, Accuracy: 3034/5000 (61%)\n",
      "[epoch 32] loss: 0.0073705\n",
      "Test set: Average loss: 1.1971, Accuracy: 3037/5000 (61%)\n",
      "[epoch 33] loss: 0.0069620\n",
      "Test set: Average loss: 1.1989, Accuracy: 3035/5000 (61%)\n",
      "[epoch 34] loss: 0.0066765\n",
      "Test set: Average loss: 1.2008, Accuracy: 3033/5000 (61%)\n",
      "[epoch 35] loss: 0.0063611\n",
      "Test set: Average loss: 1.2030, Accuracy: 3033/5000 (61%)\n",
      "[epoch 36] loss: 0.0060687\n",
      "Test set: Average loss: 1.2049, Accuracy: 3034/5000 (61%)\n",
      "[epoch 37] loss: 0.0058452\n",
      "Test set: Average loss: 1.2069, Accuracy: 3033/5000 (61%)\n",
      "[epoch 38] loss: 0.0055634\n",
      "Test set: Average loss: 1.2086, Accuracy: 3033/5000 (61%)\n",
      "[epoch 39] loss: 0.0053254\n",
      "Test set: Average loss: 1.2102, Accuracy: 3035/5000 (61%)\n",
      "[epoch 40] loss: 0.0051519\n",
      "Test set: Average loss: 1.2121, Accuracy: 3038/5000 (61%)\n",
      "[epoch 41] loss: 0.0049251\n",
      "Test set: Average loss: 1.2139, Accuracy: 3038/5000 (61%)\n",
      "[epoch 42] loss: 0.0047098\n",
      "Test set: Average loss: 1.2153, Accuracy: 3039/5000 (61%)\n",
      "[epoch 43] loss: 0.0045530\n",
      "Test set: Average loss: 1.2169, Accuracy: 3041/5000 (61%)\n",
      "[epoch 44] loss: 0.0043833\n",
      "Test set: Average loss: 1.2186, Accuracy: 3042/5000 (61%)\n",
      "[epoch 45] loss: 0.0042170\n",
      "Test set: Average loss: 1.2205, Accuracy: 3041/5000 (61%)\n",
      "[epoch 46] loss: 0.0040599\n",
      "Test set: Average loss: 1.2223, Accuracy: 3040/5000 (61%)\n",
      "[epoch 47] loss: 0.0039234\n",
      "Test set: Average loss: 1.2238, Accuracy: 3041/5000 (61%)\n",
      "[epoch 48] loss: 0.0038135\n",
      "Test set: Average loss: 1.2255, Accuracy: 3042/5000 (61%)\n",
      "[epoch 49] loss: 0.0036745\n",
      "Test set: Average loss: 1.2272, Accuracy: 3040/5000 (61%)\n",
      "[epoch 50] loss: 0.0035768\n",
      "Test set: Average loss: 1.2285, Accuracy: 3044/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1600, Accuracy: 3053/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 1.1466, Accuracy: 6092/10000 (61%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5057, Accuracy: 375/5000 (8%)\n",
      "[epoch 1] loss: 2.1254026\n",
      "Test set: Average loss: 1.7624, Accuracy: 2113/5000 (42%)\n",
      "[epoch 2] loss: 1.0452767\n",
      "Test set: Average loss: 1.4022, Accuracy: 2622/5000 (52%)\n",
      "[epoch 3] loss: 0.5598700\n",
      "Test set: Average loss: 1.2401, Accuracy: 2910/5000 (58%)\n",
      "[epoch 4] loss: 0.3350762\n",
      "Test set: Average loss: 1.1768, Accuracy: 3009/5000 (60%)\n",
      "[epoch 5] loss: 0.2015732\n",
      "Test set: Average loss: 1.1534, Accuracy: 3048/5000 (61%)\n",
      "[epoch 6] loss: 0.1354951\n",
      "Test set: Average loss: 1.1550, Accuracy: 3030/5000 (61%)\n",
      "[epoch 7] loss: 0.0951368\n",
      "Test set: Average loss: 1.1543, Accuracy: 3046/5000 (61%)\n",
      "[epoch 8] loss: 0.0734027\n",
      "Test set: Average loss: 1.1569, Accuracy: 3049/5000 (61%)\n",
      "[epoch 9] loss: 0.0586164\n",
      "Test set: Average loss: 1.1591, Accuracy: 3040/5000 (61%)\n",
      "[epoch 10] loss: 0.0481276\n",
      "Test set: Average loss: 1.1622, Accuracy: 3041/5000 (61%)\n",
      "[epoch 11] loss: 0.0406260\n",
      "Test set: Average loss: 1.1640, Accuracy: 3048/5000 (61%)\n",
      "[epoch 12] loss: 0.0348551\n",
      "Test set: Average loss: 1.1679, Accuracy: 3053/5000 (61%)\n",
      "[epoch 13] loss: 0.0303449\n",
      "Test set: Average loss: 1.1714, Accuracy: 3055/5000 (61%)\n",
      "[epoch 14] loss: 0.0268008\n",
      "Test set: Average loss: 1.1745, Accuracy: 3057/5000 (61%)\n",
      "[epoch 15] loss: 0.0239097\n",
      "Test set: Average loss: 1.1795, Accuracy: 3058/5000 (61%)\n",
      "[epoch 16] loss: 0.0215580\n",
      "Test set: Average loss: 1.1827, Accuracy: 3061/5000 (61%)\n",
      "[epoch 17] loss: 0.0194316\n",
      "Test set: Average loss: 1.1868, Accuracy: 3062/5000 (61%)\n",
      "[epoch 18] loss: 0.0178981\n",
      "Test set: Average loss: 1.1900, Accuracy: 3061/5000 (61%)\n",
      "[epoch 19] loss: 0.0164759\n",
      "Test set: Average loss: 1.1929, Accuracy: 3066/5000 (61%)\n",
      "[epoch 20] loss: 0.0152140\n",
      "Test set: Average loss: 1.1958, Accuracy: 3064/5000 (61%)\n",
      "[epoch 21] loss: 0.0140376\n",
      "Test set: Average loss: 1.1985, Accuracy: 3066/5000 (61%)\n",
      "[epoch 22] loss: 0.0130294\n",
      "Test set: Average loss: 1.2017, Accuracy: 3062/5000 (61%)\n",
      "[epoch 23] loss: 0.0121334\n",
      "Test set: Average loss: 1.2049, Accuracy: 3062/5000 (61%)\n",
      "[epoch 24] loss: 0.0114284\n",
      "Test set: Average loss: 1.2080, Accuracy: 3060/5000 (61%)\n",
      "[epoch 25] loss: 0.0106501\n",
      "Test set: Average loss: 1.2101, Accuracy: 3057/5000 (61%)\n",
      "[epoch 26] loss: 0.0100003\n",
      "Test set: Average loss: 1.2129, Accuracy: 3061/5000 (61%)\n",
      "[epoch 27] loss: 0.0094053\n",
      "Test set: Average loss: 1.2161, Accuracy: 3064/5000 (61%)\n",
      "[epoch 28] loss: 0.0088518\n",
      "Test set: Average loss: 1.2193, Accuracy: 3061/5000 (61%)\n",
      "[epoch 29] loss: 0.0084174\n",
      "Test set: Average loss: 1.2222, Accuracy: 3062/5000 (61%)\n",
      "[epoch 30] loss: 0.0079612\n",
      "Test set: Average loss: 1.2251, Accuracy: 3065/5000 (61%)\n",
      "[epoch 31] loss: 0.0075695\n",
      "Test set: Average loss: 1.2278, Accuracy: 3062/5000 (61%)\n",
      "[epoch 32] loss: 0.0071722\n",
      "Test set: Average loss: 1.2306, Accuracy: 3064/5000 (61%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] loss: 0.0068672\n",
      "Test set: Average loss: 1.2333, Accuracy: 3066/5000 (61%)\n",
      "[epoch 34] loss: 0.0065443\n",
      "Test set: Average loss: 1.2358, Accuracy: 3066/5000 (61%)\n",
      "[epoch 35] loss: 0.0062360\n",
      "Test set: Average loss: 1.2384, Accuracy: 3065/5000 (61%)\n",
      "[epoch 36] loss: 0.0060029\n",
      "Test set: Average loss: 1.2405, Accuracy: 3068/5000 (61%)\n",
      "[epoch 37] loss: 0.0057176\n",
      "Test set: Average loss: 1.2430, Accuracy: 3066/5000 (61%)\n",
      "[epoch 38] loss: 0.0054950\n",
      "Test set: Average loss: 1.2454, Accuracy: 3067/5000 (61%)\n",
      "[epoch 39] loss: 0.0052170\n",
      "Test set: Average loss: 1.2478, Accuracy: 3068/5000 (61%)\n",
      "[epoch 40] loss: 0.0050394\n",
      "Test set: Average loss: 1.2500, Accuracy: 3066/5000 (61%)\n",
      "[epoch 41] loss: 0.0048713\n",
      "Test set: Average loss: 1.2522, Accuracy: 3064/5000 (61%)\n",
      "[epoch 42] loss: 0.0046527\n",
      "Test set: Average loss: 1.2549, Accuracy: 3066/5000 (61%)\n",
      "[epoch 43] loss: 0.0045288\n",
      "Test set: Average loss: 1.2572, Accuracy: 3064/5000 (61%)\n",
      "[epoch 44] loss: 0.0043591\n",
      "Test set: Average loss: 1.2595, Accuracy: 3060/5000 (61%)\n",
      "[epoch 45] loss: 0.0041831\n",
      "Test set: Average loss: 1.2614, Accuracy: 3062/5000 (61%)\n",
      "[epoch 46] loss: 0.0040202\n",
      "Test set: Average loss: 1.2635, Accuracy: 3062/5000 (61%)\n",
      "[epoch 47] loss: 0.0038986\n",
      "Test set: Average loss: 1.2659, Accuracy: 3064/5000 (61%)\n",
      "[epoch 48] loss: 0.0037706\n",
      "Test set: Average loss: 1.2678, Accuracy: 3062/5000 (61%)\n",
      "[epoch 49] loss: 0.0036379\n",
      "Test set: Average loss: 1.2697, Accuracy: 3063/5000 (61%)\n",
      "[epoch 50] loss: 0.0035435\n",
      "Test set: Average loss: 1.2719, Accuracy: 3063/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2478, Accuracy: 3068/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 1.2266, Accuracy: 6144/10000 (61%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4368, Accuracy: 458/5000 (9%)\n",
      "[epoch 1] loss: 2.0842531\n",
      "Test set: Average loss: 1.7877, Accuracy: 1994/5000 (40%)\n",
      "[epoch 2] loss: 1.1022670\n",
      "Test set: Average loss: 1.4444, Accuracy: 2567/5000 (51%)\n",
      "[epoch 3] loss: 0.6316514\n",
      "Test set: Average loss: 1.2951, Accuracy: 2759/5000 (55%)\n",
      "[epoch 4] loss: 0.3744586\n",
      "Test set: Average loss: 1.2161, Accuracy: 2874/5000 (57%)\n",
      "[epoch 5] loss: 0.2388586\n",
      "Test set: Average loss: 1.1981, Accuracy: 2892/5000 (58%)\n",
      "[epoch 6] loss: 0.1569724\n",
      "Test set: Average loss: 1.1910, Accuracy: 2892/5000 (58%)\n",
      "[epoch 7] loss: 0.1107383\n",
      "Test set: Average loss: 1.1781, Accuracy: 2913/5000 (58%)\n",
      "[epoch 8] loss: 0.0835967\n",
      "Test set: Average loss: 1.1785, Accuracy: 2914/5000 (58%)\n",
      "[epoch 9] loss: 0.0668133\n",
      "Test set: Average loss: 1.1796, Accuracy: 2915/5000 (58%)\n",
      "[epoch 10] loss: 0.0551007\n",
      "Test set: Average loss: 1.1801, Accuracy: 2924/5000 (58%)\n",
      "[epoch 11] loss: 0.0463081\n",
      "Test set: Average loss: 1.1843, Accuracy: 2920/5000 (58%)\n",
      "[epoch 12] loss: 0.0398983\n",
      "Test set: Average loss: 1.1875, Accuracy: 2934/5000 (59%)\n",
      "[epoch 13] loss: 0.0351189\n",
      "Test set: Average loss: 1.1899, Accuracy: 2928/5000 (59%)\n",
      "[epoch 14] loss: 0.0310884\n",
      "Test set: Average loss: 1.1939, Accuracy: 2935/5000 (59%)\n",
      "[epoch 15] loss: 0.0278101\n",
      "Test set: Average loss: 1.1959, Accuracy: 2939/5000 (59%)\n",
      "[epoch 16] loss: 0.0251987\n",
      "Test set: Average loss: 1.1991, Accuracy: 2938/5000 (59%)\n",
      "[epoch 17] loss: 0.0228494\n",
      "Test set: Average loss: 1.2016, Accuracy: 2945/5000 (59%)\n",
      "[epoch 18] loss: 0.0208409\n",
      "Test set: Average loss: 1.2047, Accuracy: 2938/5000 (59%)\n",
      "[epoch 19] loss: 0.0192273\n",
      "Test set: Average loss: 1.2069, Accuracy: 2939/5000 (59%)\n",
      "[epoch 20] loss: 0.0177162\n",
      "Test set: Average loss: 1.2101, Accuracy: 2938/5000 (59%)\n",
      "[epoch 21] loss: 0.0164402\n",
      "Test set: Average loss: 1.2123, Accuracy: 2944/5000 (59%)\n",
      "[epoch 22] loss: 0.0152600\n",
      "Test set: Average loss: 1.2142, Accuracy: 2946/5000 (59%)\n",
      "[epoch 23] loss: 0.0142172\n",
      "Test set: Average loss: 1.2178, Accuracy: 2945/5000 (59%)\n",
      "[epoch 24] loss: 0.0133540\n",
      "Test set: Average loss: 1.2214, Accuracy: 2943/5000 (59%)\n",
      "[epoch 25] loss: 0.0124392\n",
      "Test set: Average loss: 1.2231, Accuracy: 2950/5000 (59%)\n",
      "[epoch 26] loss: 0.0117656\n",
      "Test set: Average loss: 1.2249, Accuracy: 2946/5000 (59%)\n",
      "[epoch 27] loss: 0.0110121\n",
      "Test set: Average loss: 1.2277, Accuracy: 2945/5000 (59%)\n",
      "[epoch 28] loss: 0.0104073\n",
      "Test set: Average loss: 1.2301, Accuracy: 2942/5000 (59%)\n",
      "[epoch 29] loss: 0.0098317\n",
      "Test set: Average loss: 1.2324, Accuracy: 2946/5000 (59%)\n",
      "[epoch 30] loss: 0.0092351\n",
      "Test set: Average loss: 1.2346, Accuracy: 2946/5000 (59%)\n",
      "[epoch 31] loss: 0.0087921\n",
      "Test set: Average loss: 1.2367, Accuracy: 2946/5000 (59%)\n",
      "[epoch 32] loss: 0.0083770\n",
      "Test set: Average loss: 1.2391, Accuracy: 2947/5000 (59%)\n",
      "[epoch 33] loss: 0.0080092\n",
      "Test set: Average loss: 1.2417, Accuracy: 2950/5000 (59%)\n",
      "[epoch 34] loss: 0.0076113\n",
      "Test set: Average loss: 1.2434, Accuracy: 2952/5000 (59%)\n",
      "[epoch 35] loss: 0.0072600\n",
      "Test set: Average loss: 1.2458, Accuracy: 2951/5000 (59%)\n",
      "[epoch 36] loss: 0.0069906\n",
      "Test set: Average loss: 1.2480, Accuracy: 2950/5000 (59%)\n",
      "[epoch 37] loss: 0.0066438\n",
      "Test set: Average loss: 1.2495, Accuracy: 2951/5000 (59%)\n",
      "[epoch 38] loss: 0.0063424\n",
      "Test set: Average loss: 1.2516, Accuracy: 2952/5000 (59%)\n",
      "[epoch 39] loss: 0.0061026\n",
      "Test set: Average loss: 1.2538, Accuracy: 2954/5000 (59%)\n",
      "[epoch 40] loss: 0.0058657\n",
      "Test set: Average loss: 1.2560, Accuracy: 2951/5000 (59%)\n",
      "[epoch 41] loss: 0.0056411\n",
      "Test set: Average loss: 1.2577, Accuracy: 2956/5000 (59%)\n",
      "[epoch 42] loss: 0.0054124\n",
      "Test set: Average loss: 1.2598, Accuracy: 2955/5000 (59%)\n",
      "[epoch 43] loss: 0.0052285\n",
      "Test set: Average loss: 1.2616, Accuracy: 2955/5000 (59%)\n",
      "[epoch 44] loss: 0.0050145\n",
      "Test set: Average loss: 1.2636, Accuracy: 2956/5000 (59%)\n",
      "[epoch 45] loss: 0.0048698\n",
      "Test set: Average loss: 1.2654, Accuracy: 2954/5000 (59%)\n",
      "[epoch 46] loss: 0.0046767\n",
      "Test set: Average loss: 1.2669, Accuracy: 2955/5000 (59%)\n",
      "[epoch 47] loss: 0.0045013\n",
      "Test set: Average loss: 1.2689, Accuracy: 2955/5000 (59%)\n",
      "[epoch 48] loss: 0.0043548\n",
      "Test set: Average loss: 1.2705, Accuracy: 2957/5000 (59%)\n",
      "[epoch 49] loss: 0.0042204\n",
      "Test set: Average loss: 1.2724, Accuracy: 2957/5000 (59%)\n",
      "[epoch 50] loss: 0.0040892\n",
      "Test set: Average loss: 1.2739, Accuracy: 2958/5000 (59%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2739, Accuracy: 2958/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 1.2554, Accuracy: 5932/10000 (59%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4169, Accuracy: 574/5000 (11%)\n",
      "[epoch 1] loss: 1.7253938\n",
      "Test set: Average loss: 1.3619, Accuracy: 2765/5000 (55%)\n",
      "[epoch 2] loss: 0.7520263\n",
      "Test set: Average loss: 1.1492, Accuracy: 3026/5000 (61%)\n",
      "[epoch 3] loss: 0.3877257\n",
      "Test set: Average loss: 1.1028, Accuracy: 3063/5000 (61%)\n",
      "[epoch 4] loss: 0.2149116\n",
      "Test set: Average loss: 1.0822, Accuracy: 3097/5000 (62%)\n",
      "[epoch 5] loss: 0.1265185\n",
      "Test set: Average loss: 1.0853, Accuracy: 3127/5000 (63%)\n",
      "[epoch 6] loss: 0.0836013\n",
      "Test set: Average loss: 1.0855, Accuracy: 3132/5000 (63%)\n",
      "[epoch 7] loss: 0.0595864\n",
      "Test set: Average loss: 1.0933, Accuracy: 3139/5000 (63%)\n",
      "[epoch 8] loss: 0.0458518\n",
      "Test set: Average loss: 1.0991, Accuracy: 3148/5000 (63%)\n",
      "[epoch 9] loss: 0.0365082\n",
      "Test set: Average loss: 1.1023, Accuracy: 3155/5000 (63%)\n",
      "[epoch 10] loss: 0.0302562\n",
      "Test set: Average loss: 1.1098, Accuracy: 3156/5000 (63%)\n",
      "[epoch 11] loss: 0.0251851\n",
      "Test set: Average loss: 1.1144, Accuracy: 3174/5000 (63%)\n",
      "[epoch 12] loss: 0.0214577\n",
      "Test set: Average loss: 1.1209, Accuracy: 3170/5000 (63%)\n",
      "[epoch 13] loss: 0.0187392\n",
      "Test set: Average loss: 1.1257, Accuracy: 3162/5000 (63%)\n",
      "[epoch 14] loss: 0.0164870\n",
      "Test set: Average loss: 1.1319, Accuracy: 3163/5000 (63%)\n",
      "[epoch 15] loss: 0.0145551\n",
      "Test set: Average loss: 1.1362, Accuracy: 3159/5000 (63%)\n",
      "[epoch 16] loss: 0.0129957\n",
      "Test set: Average loss: 1.1406, Accuracy: 3162/5000 (63%)\n",
      "[epoch 17] loss: 0.0117528\n",
      "Test set: Average loss: 1.1455, Accuracy: 3152/5000 (63%)\n",
      "[epoch 18] loss: 0.0106323\n",
      "Test set: Average loss: 1.1502, Accuracy: 3160/5000 (63%)\n",
      "[epoch 19] loss: 0.0097680\n",
      "Test set: Average loss: 1.1549, Accuracy: 3160/5000 (63%)\n",
      "[epoch 20] loss: 0.0088952\n",
      "Test set: Average loss: 1.1589, Accuracy: 3156/5000 (63%)\n",
      "[epoch 21] loss: 0.0081849\n",
      "Test set: Average loss: 1.1628, Accuracy: 3154/5000 (63%)\n",
      "[epoch 22] loss: 0.0075622\n",
      "Test set: Average loss: 1.1672, Accuracy: 3160/5000 (63%)\n",
      "[epoch 23] loss: 0.0070298\n",
      "Test set: Average loss: 1.1709, Accuracy: 3159/5000 (63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24] loss: 0.0065151\n",
      "Test set: Average loss: 1.1751, Accuracy: 3158/5000 (63%)\n",
      "[epoch 25] loss: 0.0061205\n",
      "Test set: Average loss: 1.1782, Accuracy: 3160/5000 (63%)\n",
      "[epoch 26] loss: 0.0056573\n",
      "Test set: Average loss: 1.1819, Accuracy: 3158/5000 (63%)\n",
      "[epoch 27] loss: 0.0053163\n",
      "Test set: Average loss: 1.1854, Accuracy: 3157/5000 (63%)\n",
      "[epoch 28] loss: 0.0049751\n",
      "Test set: Average loss: 1.1892, Accuracy: 3157/5000 (63%)\n",
      "[epoch 29] loss: 0.0046986\n",
      "Test set: Average loss: 1.1925, Accuracy: 3159/5000 (63%)\n",
      "[epoch 30] loss: 0.0044330\n",
      "Test set: Average loss: 1.1956, Accuracy: 3159/5000 (63%)\n",
      "[epoch 31] loss: 0.0041946\n",
      "Test set: Average loss: 1.1986, Accuracy: 3162/5000 (63%)\n",
      "[epoch 32] loss: 0.0039760\n",
      "Test set: Average loss: 1.2018, Accuracy: 3163/5000 (63%)\n",
      "[epoch 33] loss: 0.0037836\n",
      "Test set: Average loss: 1.2049, Accuracy: 3166/5000 (63%)\n",
      "[epoch 34] loss: 0.0035882\n",
      "Test set: Average loss: 1.2073, Accuracy: 3164/5000 (63%)\n",
      "[epoch 35] loss: 0.0033806\n",
      "Test set: Average loss: 1.2106, Accuracy: 3163/5000 (63%)\n",
      "[epoch 36] loss: 0.0032044\n",
      "Test set: Average loss: 1.2138, Accuracy: 3163/5000 (63%)\n",
      "[epoch 37] loss: 0.0030902\n",
      "Test set: Average loss: 1.2169, Accuracy: 3160/5000 (63%)\n",
      "[epoch 38] loss: 0.0029380\n",
      "Test set: Average loss: 1.2196, Accuracy: 3164/5000 (63%)\n",
      "[epoch 39] loss: 0.0027912\n",
      "Test set: Average loss: 1.2219, Accuracy: 3164/5000 (63%)\n",
      "[epoch 40] loss: 0.0027034\n",
      "Test set: Average loss: 1.2248, Accuracy: 3166/5000 (63%)\n",
      "[epoch 41] loss: 0.0025680\n",
      "Test set: Average loss: 1.2274, Accuracy: 3165/5000 (63%)\n",
      "[epoch 42] loss: 0.0024505\n",
      "Test set: Average loss: 1.2299, Accuracy: 3168/5000 (63%)\n",
      "[epoch 43] loss: 0.0023675\n",
      "Test set: Average loss: 1.2325, Accuracy: 3167/5000 (63%)\n",
      "[epoch 44] loss: 0.0022593\n",
      "Test set: Average loss: 1.2352, Accuracy: 3166/5000 (63%)\n",
      "[epoch 45] loss: 0.0021823\n",
      "Test set: Average loss: 1.2376, Accuracy: 3169/5000 (63%)\n",
      "[epoch 46] loss: 0.0020799\n",
      "Test set: Average loss: 1.2401, Accuracy: 3166/5000 (63%)\n",
      "[epoch 47] loss: 0.0020064\n",
      "Test set: Average loss: 1.2423, Accuracy: 3170/5000 (63%)\n",
      "[epoch 48] loss: 0.0019528\n",
      "Test set: Average loss: 1.2449, Accuracy: 3167/5000 (63%)\n",
      "[epoch 49] loss: 0.0018831\n",
      "Test set: Average loss: 1.2471, Accuracy: 3165/5000 (63%)\n",
      "[epoch 50] loss: 0.0018180\n",
      "Test set: Average loss: 1.2496, Accuracy: 3164/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1144, Accuracy: 3174/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 1.1110, Accuracy: 6332/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4494, Accuracy: 435/5000 (9%)\n",
      "[epoch 1] loss: 1.7707174\n",
      "Test set: Average loss: 1.3813, Accuracy: 2772/5000 (55%)\n",
      "[epoch 2] loss: 0.7096933\n",
      "Test set: Average loss: 1.1379, Accuracy: 3034/5000 (61%)\n",
      "[epoch 3] loss: 0.3724580\n",
      "Test set: Average loss: 1.1009, Accuracy: 3118/5000 (62%)\n",
      "[epoch 4] loss: 0.2097965\n",
      "Test set: Average loss: 1.0859, Accuracy: 3140/5000 (63%)\n",
      "[epoch 5] loss: 0.1245409\n",
      "Test set: Average loss: 1.0850, Accuracy: 3158/5000 (63%)\n",
      "[epoch 6] loss: 0.0815164\n",
      "Test set: Average loss: 1.0876, Accuracy: 3164/5000 (63%)\n",
      "[epoch 7] loss: 0.0591347\n",
      "Test set: Average loss: 1.0920, Accuracy: 3185/5000 (64%)\n",
      "[epoch 8] loss: 0.0450412\n",
      "Test set: Average loss: 1.1008, Accuracy: 3175/5000 (64%)\n",
      "[epoch 9] loss: 0.0364394\n",
      "Test set: Average loss: 1.1076, Accuracy: 3173/5000 (63%)\n",
      "[epoch 10] loss: 0.0299447\n",
      "Test set: Average loss: 1.1116, Accuracy: 3170/5000 (63%)\n",
      "[epoch 11] loss: 0.0250551\n",
      "Test set: Average loss: 1.1195, Accuracy: 3175/5000 (64%)\n",
      "[epoch 12] loss: 0.0215921\n",
      "Test set: Average loss: 1.1269, Accuracy: 3178/5000 (64%)\n",
      "[epoch 13] loss: 0.0186944\n",
      "Test set: Average loss: 1.1327, Accuracy: 3179/5000 (64%)\n",
      "[epoch 14] loss: 0.0163663\n",
      "Test set: Average loss: 1.1385, Accuracy: 3175/5000 (64%)\n",
      "[epoch 15] loss: 0.0144543\n",
      "Test set: Average loss: 1.1440, Accuracy: 3180/5000 (64%)\n",
      "[epoch 16] loss: 0.0131514\n",
      "Test set: Average loss: 1.1500, Accuracy: 3184/5000 (64%)\n",
      "[epoch 17] loss: 0.0116523\n",
      "Test set: Average loss: 1.1564, Accuracy: 3182/5000 (64%)\n",
      "[epoch 18] loss: 0.0105989\n",
      "Test set: Average loss: 1.1605, Accuracy: 3181/5000 (64%)\n",
      "[epoch 19] loss: 0.0096103\n",
      "Test set: Average loss: 1.1665, Accuracy: 3186/5000 (64%)\n",
      "[epoch 20] loss: 0.0088388\n",
      "Test set: Average loss: 1.1726, Accuracy: 3184/5000 (64%)\n",
      "[epoch 21] loss: 0.0081495\n",
      "Test set: Average loss: 1.1765, Accuracy: 3180/5000 (64%)\n",
      "[epoch 22] loss: 0.0074944\n",
      "Test set: Average loss: 1.1808, Accuracy: 3189/5000 (64%)\n",
      "[epoch 23] loss: 0.0069031\n",
      "Test set: Average loss: 1.1858, Accuracy: 3185/5000 (64%)\n",
      "[epoch 24] loss: 0.0065038\n",
      "Test set: Average loss: 1.1900, Accuracy: 3182/5000 (64%)\n",
      "[epoch 25] loss: 0.0060326\n",
      "Test set: Average loss: 1.1941, Accuracy: 3188/5000 (64%)\n",
      "[epoch 26] loss: 0.0056265\n",
      "Test set: Average loss: 1.1985, Accuracy: 3183/5000 (64%)\n",
      "[epoch 27] loss: 0.0052929\n",
      "Test set: Average loss: 1.2029, Accuracy: 3183/5000 (64%)\n",
      "[epoch 28] loss: 0.0050327\n",
      "Test set: Average loss: 1.2065, Accuracy: 3192/5000 (64%)\n",
      "[epoch 29] loss: 0.0046880\n",
      "Test set: Average loss: 1.2105, Accuracy: 3185/5000 (64%)\n",
      "[epoch 30] loss: 0.0043825\n",
      "Test set: Average loss: 1.2143, Accuracy: 3185/5000 (64%)\n",
      "[epoch 31] loss: 0.0041612\n",
      "Test set: Average loss: 1.2183, Accuracy: 3190/5000 (64%)\n",
      "[epoch 32] loss: 0.0039732\n",
      "Test set: Average loss: 1.2220, Accuracy: 3187/5000 (64%)\n",
      "[epoch 33] loss: 0.0037795\n",
      "Test set: Average loss: 1.2248, Accuracy: 3185/5000 (64%)\n",
      "[epoch 34] loss: 0.0035982\n",
      "Test set: Average loss: 1.2282, Accuracy: 3185/5000 (64%)\n",
      "[epoch 35] loss: 0.0033787\n",
      "Test set: Average loss: 1.2318, Accuracy: 3186/5000 (64%)\n",
      "[epoch 36] loss: 0.0032213\n",
      "Test set: Average loss: 1.2355, Accuracy: 3184/5000 (64%)\n",
      "[epoch 37] loss: 0.0030926\n",
      "Test set: Average loss: 1.2383, Accuracy: 3186/5000 (64%)\n",
      "[epoch 38] loss: 0.0029245\n",
      "Test set: Average loss: 1.2416, Accuracy: 3184/5000 (64%)\n",
      "[epoch 39] loss: 0.0028125\n",
      "Test set: Average loss: 1.2445, Accuracy: 3186/5000 (64%)\n",
      "[epoch 40] loss: 0.0026864\n",
      "Test set: Average loss: 1.2477, Accuracy: 3185/5000 (64%)\n",
      "[epoch 41] loss: 0.0026031\n",
      "Test set: Average loss: 1.2510, Accuracy: 3185/5000 (64%)\n",
      "[epoch 42] loss: 0.0024671\n",
      "Test set: Average loss: 1.2535, Accuracy: 3186/5000 (64%)\n",
      "[epoch 43] loss: 0.0023588\n",
      "Test set: Average loss: 1.2562, Accuracy: 3188/5000 (64%)\n",
      "[epoch 44] loss: 0.0023123\n",
      "Test set: Average loss: 1.2595, Accuracy: 3186/5000 (64%)\n",
      "[epoch 45] loss: 0.0021931\n",
      "Test set: Average loss: 1.2617, Accuracy: 3188/5000 (64%)\n",
      "[epoch 46] loss: 0.0021079\n",
      "Test set: Average loss: 1.2648, Accuracy: 3189/5000 (64%)\n",
      "[epoch 47] loss: 0.0020489\n",
      "Test set: Average loss: 1.2677, Accuracy: 3188/5000 (64%)\n",
      "[epoch 48] loss: 0.0019534\n",
      "Test set: Average loss: 1.2704, Accuracy: 3185/5000 (64%)\n",
      "[epoch 49] loss: 0.0018880\n",
      "Test set: Average loss: 1.2725, Accuracy: 3186/5000 (64%)\n",
      "[epoch 50] loss: 0.0018389\n",
      "Test set: Average loss: 1.2754, Accuracy: 3186/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2065, Accuracy: 3192/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 1.1833, Accuracy: 6400/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4141, Accuracy: 468/5000 (9%)\n",
      "[epoch 1] loss: 1.7707308\n",
      "Test set: Average loss: 1.3782, Accuracy: 2746/5000 (55%)\n",
      "[epoch 2] loss: 0.7673824\n",
      "Test set: Average loss: 1.1594, Accuracy: 3019/5000 (60%)\n",
      "[epoch 3] loss: 0.4107318\n",
      "Test set: Average loss: 1.1109, Accuracy: 3074/5000 (61%)\n",
      "[epoch 4] loss: 0.2273958\n",
      "Test set: Average loss: 1.0938, Accuracy: 3121/5000 (62%)\n",
      "[epoch 5] loss: 0.1378819\n",
      "Test set: Average loss: 1.0963, Accuracy: 3124/5000 (62%)\n",
      "[epoch 6] loss: 0.0909232\n",
      "Test set: Average loss: 1.0974, Accuracy: 3124/5000 (62%)\n",
      "[epoch 7] loss: 0.0666723\n",
      "Test set: Average loss: 1.1072, Accuracy: 3125/5000 (62%)\n",
      "[epoch 8] loss: 0.0506099\n",
      "Test set: Average loss: 1.1094, Accuracy: 3145/5000 (63%)\n",
      "[epoch 9] loss: 0.0395225\n",
      "Test set: Average loss: 1.1184, Accuracy: 3150/5000 (63%)\n",
      "[epoch 10] loss: 0.0325011\n",
      "Test set: Average loss: 1.1226, Accuracy: 3154/5000 (63%)\n",
      "[epoch 11] loss: 0.0272442\n",
      "Test set: Average loss: 1.1278, Accuracy: 3159/5000 (63%)\n",
      "[epoch 12] loss: 0.0232066\n",
      "Test set: Average loss: 1.1353, Accuracy: 3158/5000 (63%)\n",
      "[epoch 13] loss: 0.0201596\n",
      "Test set: Average loss: 1.1400, Accuracy: 3153/5000 (63%)\n",
      "[epoch 14] loss: 0.0176675\n",
      "Test set: Average loss: 1.1476, Accuracy: 3153/5000 (63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] loss: 0.0155884\n",
      "Test set: Average loss: 1.1520, Accuracy: 3146/5000 (63%)\n",
      "[epoch 16] loss: 0.0139649\n",
      "Test set: Average loss: 1.1566, Accuracy: 3149/5000 (63%)\n",
      "[epoch 17] loss: 0.0126669\n",
      "Test set: Average loss: 1.1618, Accuracy: 3147/5000 (63%)\n",
      "[epoch 18] loss: 0.0114234\n",
      "Test set: Average loss: 1.1675, Accuracy: 3145/5000 (63%)\n",
      "[epoch 19] loss: 0.0103021\n",
      "Test set: Average loss: 1.1718, Accuracy: 3144/5000 (63%)\n",
      "[epoch 20] loss: 0.0094148\n",
      "Test set: Average loss: 1.1771, Accuracy: 3146/5000 (63%)\n",
      "[epoch 21] loss: 0.0086974\n",
      "Test set: Average loss: 1.1824, Accuracy: 3144/5000 (63%)\n",
      "[epoch 22] loss: 0.0080211\n",
      "Test set: Average loss: 1.1858, Accuracy: 3147/5000 (63%)\n",
      "[epoch 23] loss: 0.0073675\n",
      "Test set: Average loss: 1.1900, Accuracy: 3148/5000 (63%)\n",
      "[epoch 24] loss: 0.0069205\n",
      "Test set: Average loss: 1.1952, Accuracy: 3147/5000 (63%)\n",
      "[epoch 25] loss: 0.0063951\n",
      "Test set: Average loss: 1.1979, Accuracy: 3151/5000 (63%)\n",
      "[epoch 26] loss: 0.0059870\n",
      "Test set: Average loss: 1.2027, Accuracy: 3154/5000 (63%)\n",
      "[epoch 27] loss: 0.0056130\n",
      "Test set: Average loss: 1.2063, Accuracy: 3152/5000 (63%)\n",
      "[epoch 28] loss: 0.0052530\n",
      "Test set: Average loss: 1.2105, Accuracy: 3153/5000 (63%)\n",
      "[epoch 29] loss: 0.0049576\n",
      "Test set: Average loss: 1.2141, Accuracy: 3155/5000 (63%)\n",
      "[epoch 30] loss: 0.0047004\n",
      "Test set: Average loss: 1.2167, Accuracy: 3155/5000 (63%)\n",
      "[epoch 31] loss: 0.0044483\n",
      "Test set: Average loss: 1.2210, Accuracy: 3155/5000 (63%)\n",
      "[epoch 32] loss: 0.0041823\n",
      "Test set: Average loss: 1.2236, Accuracy: 3159/5000 (63%)\n",
      "[epoch 33] loss: 0.0039607\n",
      "Test set: Average loss: 1.2270, Accuracy: 3155/5000 (63%)\n",
      "[epoch 34] loss: 0.0037841\n",
      "Test set: Average loss: 1.2302, Accuracy: 3158/5000 (63%)\n",
      "[epoch 35] loss: 0.0035993\n",
      "Test set: Average loss: 1.2334, Accuracy: 3158/5000 (63%)\n",
      "[epoch 36] loss: 0.0034099\n",
      "Test set: Average loss: 1.2364, Accuracy: 3155/5000 (63%)\n",
      "[epoch 37] loss: 0.0032337\n",
      "Test set: Average loss: 1.2394, Accuracy: 3156/5000 (63%)\n",
      "[epoch 38] loss: 0.0031037\n",
      "Test set: Average loss: 1.2427, Accuracy: 3155/5000 (63%)\n",
      "[epoch 39] loss: 0.0029679\n",
      "Test set: Average loss: 1.2453, Accuracy: 3155/5000 (63%)\n",
      "[epoch 40] loss: 0.0028219\n",
      "Test set: Average loss: 1.2485, Accuracy: 3156/5000 (63%)\n",
      "[epoch 41] loss: 0.0026958\n",
      "Test set: Average loss: 1.2513, Accuracy: 3155/5000 (63%)\n",
      "[epoch 42] loss: 0.0025845\n",
      "Test set: Average loss: 1.2542, Accuracy: 3151/5000 (63%)\n",
      "[epoch 43] loss: 0.0024845\n",
      "Test set: Average loss: 1.2569, Accuracy: 3156/5000 (63%)\n",
      "[epoch 44] loss: 0.0023838\n",
      "Test set: Average loss: 1.2594, Accuracy: 3157/5000 (63%)\n",
      "[epoch 45] loss: 0.0022903\n",
      "Test set: Average loss: 1.2625, Accuracy: 3154/5000 (63%)\n",
      "[epoch 46] loss: 0.0022188\n",
      "Test set: Average loss: 1.2652, Accuracy: 3152/5000 (63%)\n",
      "[epoch 47] loss: 0.0021141\n",
      "Test set: Average loss: 1.2674, Accuracy: 3151/5000 (63%)\n",
      "[epoch 48] loss: 0.0020528\n",
      "Test set: Average loss: 1.2698, Accuracy: 3151/5000 (63%)\n",
      "[epoch 49] loss: 0.0019648\n",
      "Test set: Average loss: 1.2726, Accuracy: 3153/5000 (63%)\n",
      "[epoch 50] loss: 0.0019176\n",
      "Test set: Average loss: 1.2749, Accuracy: 3153/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2236, Accuracy: 3159/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 1.2306, Accuracy: 6269/10000 (63%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3620, Accuracy: 568/5000 (11%)\n",
      "[epoch 1] loss: 1.4666923\n",
      "Test set: Average loss: 1.1774, Accuracy: 2965/5000 (59%)\n",
      "[epoch 2] loss: 0.5591745\n",
      "Test set: Average loss: 1.0692, Accuracy: 3125/5000 (62%)\n",
      "[epoch 3] loss: 0.2820050\n",
      "Test set: Average loss: 1.0522, Accuracy: 3187/5000 (64%)\n",
      "[epoch 4] loss: 0.1496503\n",
      "Test set: Average loss: 1.0429, Accuracy: 3206/5000 (64%)\n",
      "[epoch 5] loss: 0.0864518\n",
      "Test set: Average loss: 1.0444, Accuracy: 3215/5000 (64%)\n",
      "[epoch 6] loss: 0.0565374\n",
      "Test set: Average loss: 1.0534, Accuracy: 3210/5000 (64%)\n",
      "[epoch 7] loss: 0.0403621\n",
      "Test set: Average loss: 1.0650, Accuracy: 3217/5000 (64%)\n",
      "[epoch 8] loss: 0.0309342\n",
      "Test set: Average loss: 1.0726, Accuracy: 3223/5000 (64%)\n",
      "[epoch 9] loss: 0.0247469\n",
      "Test set: Average loss: 1.0826, Accuracy: 3224/5000 (64%)\n",
      "[epoch 10] loss: 0.0207566\n",
      "Test set: Average loss: 1.0918, Accuracy: 3222/5000 (64%)\n",
      "[epoch 11] loss: 0.0169985\n",
      "Test set: Average loss: 1.1002, Accuracy: 3232/5000 (65%)\n",
      "[epoch 12] loss: 0.0145998\n",
      "Test set: Average loss: 1.1081, Accuracy: 3228/5000 (65%)\n",
      "[epoch 13] loss: 0.0127335\n",
      "Test set: Average loss: 1.1156, Accuracy: 3232/5000 (65%)\n",
      "[epoch 14] loss: 0.0110309\n",
      "Test set: Average loss: 1.1231, Accuracy: 3229/5000 (65%)\n",
      "[epoch 15] loss: 0.0098533\n",
      "Test set: Average loss: 1.1295, Accuracy: 3233/5000 (65%)\n",
      "[epoch 16] loss: 0.0086264\n",
      "Test set: Average loss: 1.1350, Accuracy: 3234/5000 (65%)\n",
      "[epoch 17] loss: 0.0077427\n",
      "Test set: Average loss: 1.1419, Accuracy: 3228/5000 (65%)\n",
      "[epoch 18] loss: 0.0069804\n",
      "Test set: Average loss: 1.1471, Accuracy: 3226/5000 (65%)\n",
      "[epoch 19] loss: 0.0063093\n",
      "Test set: Average loss: 1.1532, Accuracy: 3227/5000 (65%)\n",
      "[epoch 20] loss: 0.0058385\n",
      "Test set: Average loss: 1.1594, Accuracy: 3230/5000 (65%)\n",
      "[epoch 21] loss: 0.0053311\n",
      "Test set: Average loss: 1.1650, Accuracy: 3228/5000 (65%)\n",
      "[epoch 22] loss: 0.0048839\n",
      "Test set: Average loss: 1.1697, Accuracy: 3230/5000 (65%)\n",
      "[epoch 23] loss: 0.0045379\n",
      "Test set: Average loss: 1.1753, Accuracy: 3231/5000 (65%)\n",
      "[epoch 24] loss: 0.0042793\n",
      "Test set: Average loss: 1.1798, Accuracy: 3231/5000 (65%)\n",
      "[epoch 25] loss: 0.0039022\n",
      "Test set: Average loss: 1.1844, Accuracy: 3232/5000 (65%)\n",
      "[epoch 26] loss: 0.0036684\n",
      "Test set: Average loss: 1.1894, Accuracy: 3231/5000 (65%)\n",
      "[epoch 27] loss: 0.0034257\n",
      "Test set: Average loss: 1.1942, Accuracy: 3235/5000 (65%)\n",
      "[epoch 28] loss: 0.0031734\n",
      "Test set: Average loss: 1.1977, Accuracy: 3238/5000 (65%)\n",
      "[epoch 29] loss: 0.0030016\n",
      "Test set: Average loss: 1.2024, Accuracy: 3235/5000 (65%)\n",
      "[epoch 30] loss: 0.0027965\n",
      "Test set: Average loss: 1.2067, Accuracy: 3239/5000 (65%)\n",
      "[epoch 31] loss: 0.0026552\n",
      "Test set: Average loss: 1.2105, Accuracy: 3237/5000 (65%)\n",
      "[epoch 32] loss: 0.0025087\n",
      "Test set: Average loss: 1.2143, Accuracy: 3237/5000 (65%)\n",
      "[epoch 33] loss: 0.0023684\n",
      "Test set: Average loss: 1.2183, Accuracy: 3236/5000 (65%)\n",
      "[epoch 34] loss: 0.0022560\n",
      "Test set: Average loss: 1.2225, Accuracy: 3233/5000 (65%)\n",
      "[epoch 35] loss: 0.0021396\n",
      "Test set: Average loss: 1.2254, Accuracy: 3238/5000 (65%)\n",
      "[epoch 36] loss: 0.0020345\n",
      "Test set: Average loss: 1.2297, Accuracy: 3236/5000 (65%)\n",
      "[epoch 37] loss: 0.0019294\n",
      "Test set: Average loss: 1.2329, Accuracy: 3239/5000 (65%)\n",
      "[epoch 38] loss: 0.0018538\n",
      "Test set: Average loss: 1.2363, Accuracy: 3238/5000 (65%)\n",
      "[epoch 39] loss: 0.0017500\n",
      "Test set: Average loss: 1.2397, Accuracy: 3236/5000 (65%)\n",
      "[epoch 40] loss: 0.0016911\n",
      "Test set: Average loss: 1.2430, Accuracy: 3237/5000 (65%)\n",
      "[epoch 41] loss: 0.0016290\n",
      "Test set: Average loss: 1.2461, Accuracy: 3239/5000 (65%)\n",
      "[epoch 42] loss: 0.0015482\n",
      "Test set: Average loss: 1.2497, Accuracy: 3238/5000 (65%)\n",
      "[epoch 43] loss: 0.0014822\n",
      "Test set: Average loss: 1.2527, Accuracy: 3236/5000 (65%)\n",
      "[epoch 44] loss: 0.0014059\n",
      "Test set: Average loss: 1.2559, Accuracy: 3237/5000 (65%)\n",
      "[epoch 45] loss: 0.0013779\n",
      "Test set: Average loss: 1.2586, Accuracy: 3235/5000 (65%)\n",
      "[epoch 46] loss: 0.0013054\n",
      "Test set: Average loss: 1.2618, Accuracy: 3237/5000 (65%)\n",
      "[epoch 47] loss: 0.0012446\n",
      "Test set: Average loss: 1.2648, Accuracy: 3237/5000 (65%)\n",
      "[epoch 48] loss: 0.0011982\n",
      "Test set: Average loss: 1.2676, Accuracy: 3235/5000 (65%)\n",
      "[epoch 49] loss: 0.0011516\n",
      "Test set: Average loss: 1.2705, Accuracy: 3233/5000 (65%)\n",
      "[epoch 50] loss: 0.0011140\n",
      "Test set: Average loss: 1.2734, Accuracy: 3236/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2461, Accuracy: 3239/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 1.2430, Accuracy: 6500/10000 (65%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4601, Accuracy: 498/5000 (10%)\n",
      "[epoch 1] loss: 1.5362378\n",
      "Test set: Average loss: 1.1902, Accuracy: 2936/5000 (59%)\n",
      "[epoch 2] loss: 0.5708004\n",
      "Test set: Average loss: 1.0905, Accuracy: 3099/5000 (62%)\n",
      "[epoch 3] loss: 0.2800405\n",
      "Test set: Average loss: 1.0606, Accuracy: 3162/5000 (63%)\n",
      "[epoch 4] loss: 0.1454127\n",
      "Test set: Average loss: 1.0661, Accuracy: 3180/5000 (64%)\n",
      "[epoch 5] loss: 0.0855829\n",
      "Test set: Average loss: 1.0742, Accuracy: 3193/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.0565510\n",
      "Test set: Average loss: 1.0904, Accuracy: 3180/5000 (64%)\n",
      "[epoch 7] loss: 0.0411499\n",
      "Test set: Average loss: 1.0998, Accuracy: 3186/5000 (64%)\n",
      "[epoch 8] loss: 0.0315376\n",
      "Test set: Average loss: 1.1101, Accuracy: 3179/5000 (64%)\n",
      "[epoch 9] loss: 0.0251262\n",
      "Test set: Average loss: 1.1230, Accuracy: 3187/5000 (64%)\n",
      "[epoch 10] loss: 0.0209145\n",
      "Test set: Average loss: 1.1325, Accuracy: 3187/5000 (64%)\n",
      "[epoch 11] loss: 0.0172123\n",
      "Test set: Average loss: 1.1419, Accuracy: 3189/5000 (64%)\n",
      "[epoch 12] loss: 0.0147266\n",
      "Test set: Average loss: 1.1521, Accuracy: 3190/5000 (64%)\n",
      "[epoch 13] loss: 0.0128524\n",
      "Test set: Average loss: 1.1601, Accuracy: 3193/5000 (64%)\n",
      "[epoch 14] loss: 0.0110642\n",
      "Test set: Average loss: 1.1680, Accuracy: 3192/5000 (64%)\n",
      "[epoch 15] loss: 0.0098260\n",
      "Test set: Average loss: 1.1756, Accuracy: 3185/5000 (64%)\n",
      "[epoch 16] loss: 0.0087810\n",
      "Test set: Average loss: 1.1831, Accuracy: 3193/5000 (64%)\n",
      "[epoch 17] loss: 0.0078714\n",
      "Test set: Average loss: 1.1903, Accuracy: 3194/5000 (64%)\n",
      "[epoch 18] loss: 0.0071215\n",
      "Test set: Average loss: 1.1979, Accuracy: 3194/5000 (64%)\n",
      "[epoch 19] loss: 0.0063903\n",
      "Test set: Average loss: 1.2035, Accuracy: 3187/5000 (64%)\n",
      "[epoch 20] loss: 0.0059301\n",
      "Test set: Average loss: 1.2105, Accuracy: 3187/5000 (64%)\n",
      "[epoch 21] loss: 0.0053499\n",
      "Test set: Average loss: 1.2169, Accuracy: 3194/5000 (64%)\n",
      "[epoch 22] loss: 0.0049348\n",
      "Test set: Average loss: 1.2223, Accuracy: 3195/5000 (64%)\n",
      "[epoch 23] loss: 0.0045707\n",
      "Test set: Average loss: 1.2268, Accuracy: 3196/5000 (64%)\n",
      "[epoch 24] loss: 0.0042172\n",
      "Test set: Average loss: 1.2333, Accuracy: 3195/5000 (64%)\n",
      "[epoch 25] loss: 0.0039597\n",
      "Test set: Average loss: 1.2381, Accuracy: 3188/5000 (64%)\n",
      "[epoch 26] loss: 0.0036902\n",
      "Test set: Average loss: 1.2441, Accuracy: 3199/5000 (64%)\n",
      "[epoch 27] loss: 0.0034456\n",
      "Test set: Average loss: 1.2484, Accuracy: 3201/5000 (64%)\n",
      "[epoch 28] loss: 0.0032191\n",
      "Test set: Average loss: 1.2530, Accuracy: 3201/5000 (64%)\n",
      "[epoch 29] loss: 0.0030112\n",
      "Test set: Average loss: 1.2571, Accuracy: 3198/5000 (64%)\n",
      "[epoch 30] loss: 0.0028592\n",
      "Test set: Average loss: 1.2621, Accuracy: 3198/5000 (64%)\n",
      "[epoch 31] loss: 0.0026768\n",
      "Test set: Average loss: 1.2671, Accuracy: 3196/5000 (64%)\n",
      "[epoch 32] loss: 0.0025083\n",
      "Test set: Average loss: 1.2712, Accuracy: 3199/5000 (64%)\n",
      "[epoch 33] loss: 0.0023851\n",
      "Test set: Average loss: 1.2754, Accuracy: 3196/5000 (64%)\n",
      "[epoch 34] loss: 0.0022720\n",
      "Test set: Average loss: 1.2912, Accuracy: 3194/5000 (64%)\n",
      "[epoch 35] loss: 0.0021490\n",
      "Test set: Average loss: 1.2828, Accuracy: 3197/5000 (64%)\n",
      "[epoch 36] loss: 0.0020290\n",
      "Test set: Average loss: 1.2867, Accuracy: 3197/5000 (64%)\n",
      "[epoch 37] loss: 0.0019610\n",
      "Test set: Average loss: 1.2905, Accuracy: 3197/5000 (64%)\n",
      "[epoch 38] loss: 0.0018451\n",
      "Test set: Average loss: 1.2947, Accuracy: 3197/5000 (64%)\n",
      "[epoch 39] loss: 0.0017713\n",
      "Test set: Average loss: 1.2981, Accuracy: 3196/5000 (64%)\n",
      "[epoch 40] loss: 0.0016928\n",
      "Test set: Average loss: 1.3015, Accuracy: 3195/5000 (64%)\n",
      "[epoch 41] loss: 0.0016149\n",
      "Test set: Average loss: 1.3053, Accuracy: 3196/5000 (64%)\n",
      "[epoch 42] loss: 0.0015338\n",
      "Test set: Average loss: 1.3091, Accuracy: 3193/5000 (64%)\n",
      "[epoch 43] loss: 0.0014834\n",
      "Test set: Average loss: 1.3129, Accuracy: 3195/5000 (64%)\n",
      "[epoch 44] loss: 0.0014233\n",
      "Test set: Average loss: 1.3157, Accuracy: 3198/5000 (64%)\n",
      "[epoch 45] loss: 0.0013649\n",
      "Test set: Average loss: 1.3190, Accuracy: 3198/5000 (64%)\n",
      "[epoch 46] loss: 0.0013125\n",
      "Test set: Average loss: 1.3224, Accuracy: 3197/5000 (64%)\n",
      "[epoch 47] loss: 0.0012616\n",
      "Test set: Average loss: 1.3262, Accuracy: 3198/5000 (64%)\n",
      "[epoch 48] loss: 0.0012004\n",
      "Test set: Average loss: 1.3288, Accuracy: 3194/5000 (64%)\n",
      "[epoch 49] loss: 0.0011625\n",
      "Test set: Average loss: 1.3317, Accuracy: 3195/5000 (64%)\n",
      "[epoch 50] loss: 0.0011247\n",
      "Test set: Average loss: 1.3345, Accuracy: 3195/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2530, Accuracy: 3201/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 1.2180, Accuracy: 6527/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4697, Accuracy: 374/5000 (7%)\n",
      "[epoch 1] loss: 1.6312625\n",
      "Test set: Average loss: 1.2441, Accuracy: 2928/5000 (59%)\n",
      "[epoch 2] loss: 0.6785693\n",
      "Test set: Average loss: 1.1040, Accuracy: 3067/5000 (61%)\n",
      "[epoch 3] loss: 0.3481709\n",
      "Test set: Average loss: 1.0665, Accuracy: 3152/5000 (63%)\n",
      "[epoch 4] loss: 0.1874959\n",
      "Test set: Average loss: 1.0573, Accuracy: 3172/5000 (63%)\n",
      "[epoch 5] loss: 0.1088672\n",
      "Test set: Average loss: 1.0622, Accuracy: 3175/5000 (64%)\n",
      "[epoch 6] loss: 0.0693215\n",
      "Test set: Average loss: 1.0721, Accuracy: 3182/5000 (64%)\n",
      "[epoch 7] loss: 0.0480979\n",
      "Test set: Average loss: 1.0820, Accuracy: 3189/5000 (64%)\n",
      "[epoch 8] loss: 0.0365457\n",
      "Test set: Average loss: 1.0905, Accuracy: 3181/5000 (64%)\n",
      "[epoch 9] loss: 0.0291803\n",
      "Test set: Average loss: 1.0998, Accuracy: 3178/5000 (64%)\n",
      "[epoch 10] loss: 0.0236973\n",
      "Test set: Average loss: 1.1096, Accuracy: 3183/5000 (64%)\n",
      "[epoch 11] loss: 0.0198973\n",
      "Test set: Average loss: 1.1176, Accuracy: 3186/5000 (64%)\n",
      "[epoch 12] loss: 0.0169686\n",
      "Test set: Average loss: 1.1264, Accuracy: 3196/5000 (64%)\n",
      "[epoch 13] loss: 0.0146989\n",
      "Test set: Average loss: 1.1336, Accuracy: 3187/5000 (64%)\n",
      "[epoch 14] loss: 0.0128694\n",
      "Test set: Average loss: 1.1394, Accuracy: 3195/5000 (64%)\n",
      "[epoch 15] loss: 0.0112510\n",
      "Test set: Average loss: 1.1481, Accuracy: 3187/5000 (64%)\n",
      "[epoch 16] loss: 0.0100761\n",
      "Test set: Average loss: 1.1541, Accuracy: 3187/5000 (64%)\n",
      "[epoch 17] loss: 0.0090385\n",
      "Test set: Average loss: 1.1604, Accuracy: 3188/5000 (64%)\n",
      "[epoch 18] loss: 0.0081389\n",
      "Test set: Average loss: 1.1665, Accuracy: 3189/5000 (64%)\n",
      "[epoch 19] loss: 0.0073870\n",
      "Test set: Average loss: 1.1727, Accuracy: 3186/5000 (64%)\n",
      "[epoch 20] loss: 0.0066934\n",
      "Test set: Average loss: 1.1783, Accuracy: 3193/5000 (64%)\n",
      "[epoch 21] loss: 0.0061325\n",
      "Test set: Average loss: 1.1834, Accuracy: 3195/5000 (64%)\n",
      "[epoch 22] loss: 0.0056642\n",
      "Test set: Average loss: 1.1884, Accuracy: 3192/5000 (64%)\n",
      "[epoch 23] loss: 0.0053025\n",
      "Test set: Average loss: 1.1940, Accuracy: 3193/5000 (64%)\n",
      "[epoch 24] loss: 0.0048202\n",
      "Test set: Average loss: 1.1980, Accuracy: 3194/5000 (64%)\n",
      "[epoch 25] loss: 0.0045219\n",
      "Test set: Average loss: 1.2036, Accuracy: 3192/5000 (64%)\n",
      "[epoch 26] loss: 0.0042012\n",
      "Test set: Average loss: 1.2077, Accuracy: 3194/5000 (64%)\n",
      "[epoch 27] loss: 0.0039548\n",
      "Test set: Average loss: 1.2117, Accuracy: 3190/5000 (64%)\n",
      "[epoch 28] loss: 0.0037082\n",
      "Test set: Average loss: 1.2159, Accuracy: 3190/5000 (64%)\n",
      "[epoch 29] loss: 0.0034685\n",
      "Test set: Average loss: 1.2195, Accuracy: 3190/5000 (64%)\n",
      "[epoch 30] loss: 0.0032434\n",
      "Test set: Average loss: 1.2243, Accuracy: 3189/5000 (64%)\n",
      "[epoch 31] loss: 0.0030787\n",
      "Test set: Average loss: 1.2283, Accuracy: 3193/5000 (64%)\n",
      "[epoch 32] loss: 0.0028920\n",
      "Test set: Average loss: 1.2318, Accuracy: 3188/5000 (64%)\n",
      "[epoch 33] loss: 0.0027660\n",
      "Test set: Average loss: 1.2358, Accuracy: 3189/5000 (64%)\n",
      "[epoch 34] loss: 0.0026221\n",
      "Test set: Average loss: 1.2402, Accuracy: 3187/5000 (64%)\n",
      "[epoch 35] loss: 0.0024500\n",
      "Test set: Average loss: 1.2430, Accuracy: 3194/5000 (64%)\n",
      "[epoch 36] loss: 0.0023284\n",
      "Test set: Average loss: 1.2471, Accuracy: 3195/5000 (64%)\n",
      "[epoch 37] loss: 0.0022346\n",
      "Test set: Average loss: 1.2505, Accuracy: 3194/5000 (64%)\n",
      "[epoch 38] loss: 0.0021166\n",
      "Test set: Average loss: 1.2541, Accuracy: 3191/5000 (64%)\n",
      "[epoch 39] loss: 0.0020343\n",
      "Test set: Average loss: 1.2573, Accuracy: 3191/5000 (64%)\n",
      "[epoch 40] loss: 0.0019167\n",
      "Test set: Average loss: 1.2605, Accuracy: 3190/5000 (64%)\n",
      "[epoch 41] loss: 0.0018589\n",
      "Test set: Average loss: 1.2632, Accuracy: 3194/5000 (64%)\n",
      "[epoch 42] loss: 0.0017574\n",
      "Test set: Average loss: 1.2672, Accuracy: 3190/5000 (64%)\n",
      "[epoch 43] loss: 0.0016922\n",
      "Test set: Average loss: 1.2703, Accuracy: 3191/5000 (64%)\n",
      "[epoch 44] loss: 0.0016336\n",
      "Test set: Average loss: 1.2730, Accuracy: 3191/5000 (64%)\n",
      "[epoch 45] loss: 0.0015520\n",
      "Test set: Average loss: 1.2759, Accuracy: 3189/5000 (64%)\n",
      "[epoch 46] loss: 0.0014984\n",
      "Test set: Average loss: 1.2793, Accuracy: 3192/5000 (64%)\n",
      "[epoch 47] loss: 0.0014296\n",
      "Test set: Average loss: 1.2821, Accuracy: 3193/5000 (64%)\n",
      "[epoch 48] loss: 0.0013726\n",
      "Test set: Average loss: 1.2852, Accuracy: 3191/5000 (64%)\n",
      "[epoch 49] loss: 0.0013242\n",
      "Test set: Average loss: 1.2876, Accuracy: 3189/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.0012840\n",
      "Test set: Average loss: 1.2905, Accuracy: 3191/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1264, Accuracy: 3196/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 1.1189, Accuracy: 6398/10000 (64%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5160, Accuracy: 395/5000 (8%)\n",
      "[epoch 1] loss: 1.4462136\n",
      "Test set: Average loss: 1.1432, Accuracy: 3013/5000 (60%)\n",
      "[epoch 2] loss: 0.5699476\n",
      "Test set: Average loss: 1.0667, Accuracy: 3161/5000 (63%)\n",
      "[epoch 3] loss: 0.2758760\n",
      "Test set: Average loss: 1.0423, Accuracy: 3218/5000 (64%)\n",
      "[epoch 4] loss: 0.1385920\n",
      "Test set: Average loss: 1.0547, Accuracy: 3234/5000 (65%)\n",
      "[epoch 5] loss: 0.0770199\n",
      "Test set: Average loss: 1.0673, Accuracy: 3245/5000 (65%)\n",
      "[epoch 6] loss: 0.0497765\n",
      "Test set: Average loss: 1.0787, Accuracy: 3253/5000 (65%)\n",
      "[epoch 7] loss: 0.0352557\n",
      "Test set: Average loss: 1.0933, Accuracy: 3236/5000 (65%)\n",
      "[epoch 8] loss: 0.0267338\n",
      "Test set: Average loss: 1.1056, Accuracy: 3243/5000 (65%)\n",
      "[epoch 9] loss: 0.0212168\n",
      "Test set: Average loss: 1.1171, Accuracy: 3238/5000 (65%)\n",
      "[epoch 10] loss: 0.0174417\n",
      "Test set: Average loss: 1.1267, Accuracy: 3232/5000 (65%)\n",
      "[epoch 11] loss: 0.0145162\n",
      "Test set: Average loss: 1.1381, Accuracy: 3242/5000 (65%)\n",
      "[epoch 12] loss: 0.0121805\n",
      "Test set: Average loss: 1.1468, Accuracy: 3238/5000 (65%)\n",
      "[epoch 13] loss: 0.0105401\n",
      "Test set: Average loss: 1.1569, Accuracy: 3243/5000 (65%)\n",
      "[epoch 14] loss: 0.0091392\n",
      "Test set: Average loss: 1.1648, Accuracy: 3236/5000 (65%)\n",
      "[epoch 15] loss: 0.0080904\n",
      "Test set: Average loss: 1.1728, Accuracy: 3240/5000 (65%)\n",
      "[epoch 16] loss: 0.0071123\n",
      "Test set: Average loss: 1.1808, Accuracy: 3240/5000 (65%)\n",
      "[epoch 17] loss: 0.0065571\n",
      "Test set: Average loss: 1.1877, Accuracy: 3243/5000 (65%)\n",
      "[epoch 18] loss: 0.0057500\n",
      "Test set: Average loss: 1.1942, Accuracy: 3243/5000 (65%)\n",
      "[epoch 19] loss: 0.0052418\n",
      "Test set: Average loss: 1.2016, Accuracy: 3239/5000 (65%)\n",
      "[epoch 20] loss: 0.0047086\n",
      "Test set: Average loss: 1.2081, Accuracy: 3246/5000 (65%)\n",
      "[epoch 21] loss: 0.0043673\n",
      "Test set: Average loss: 1.2141, Accuracy: 3247/5000 (65%)\n",
      "[epoch 22] loss: 0.0039764\n",
      "Test set: Average loss: 1.2197, Accuracy: 3245/5000 (65%)\n",
      "[epoch 23] loss: 0.0036980\n",
      "Test set: Average loss: 1.2253, Accuracy: 3246/5000 (65%)\n",
      "[epoch 24] loss: 0.0034435\n",
      "Test set: Average loss: 1.2307, Accuracy: 3241/5000 (65%)\n",
      "[epoch 25] loss: 0.0031699\n",
      "Test set: Average loss: 1.2359, Accuracy: 3243/5000 (65%)\n",
      "[epoch 26] loss: 0.0029412\n",
      "Test set: Average loss: 1.2415, Accuracy: 3241/5000 (65%)\n",
      "[epoch 27] loss: 0.0027342\n",
      "Test set: Average loss: 1.2469, Accuracy: 3245/5000 (65%)\n",
      "[epoch 28] loss: 0.0026130\n",
      "Test set: Average loss: 1.2516, Accuracy: 3241/5000 (65%)\n",
      "[epoch 29] loss: 0.0023978\n",
      "Test set: Average loss: 1.2561, Accuracy: 3242/5000 (65%)\n",
      "[epoch 30] loss: 0.0022665\n",
      "Test set: Average loss: 1.2609, Accuracy: 3242/5000 (65%)\n",
      "[epoch 31] loss: 0.0021236\n",
      "Test set: Average loss: 1.2657, Accuracy: 3241/5000 (65%)\n",
      "[epoch 32] loss: 0.0020145\n",
      "Test set: Average loss: 1.2700, Accuracy: 3244/5000 (65%)\n",
      "[epoch 33] loss: 0.0018839\n",
      "Test set: Average loss: 1.2746, Accuracy: 3242/5000 (65%)\n",
      "[epoch 34] loss: 0.0017917\n",
      "Test set: Average loss: 1.2786, Accuracy: 3246/5000 (65%)\n",
      "[epoch 35] loss: 0.0016826\n",
      "Test set: Average loss: 1.2831, Accuracy: 3243/5000 (65%)\n",
      "[epoch 36] loss: 0.0016064\n",
      "Test set: Average loss: 1.2870, Accuracy: 3243/5000 (65%)\n",
      "[epoch 37] loss: 0.0015349\n",
      "Test set: Average loss: 1.2910, Accuracy: 3243/5000 (65%)\n",
      "[epoch 38] loss: 0.0014686\n",
      "Test set: Average loss: 1.2949, Accuracy: 3244/5000 (65%)\n",
      "[epoch 39] loss: 0.0014082\n",
      "Test set: Average loss: 1.2984, Accuracy: 3244/5000 (65%)\n",
      "[epoch 40] loss: 0.0013204\n",
      "Test set: Average loss: 1.3025, Accuracy: 3243/5000 (65%)\n",
      "[epoch 41] loss: 0.0012672\n",
      "Test set: Average loss: 1.3061, Accuracy: 3243/5000 (65%)\n",
      "[epoch 42] loss: 0.0011914\n",
      "Test set: Average loss: 1.3099, Accuracy: 3245/5000 (65%)\n",
      "[epoch 43] loss: 0.0011540\n",
      "Test set: Average loss: 1.3135, Accuracy: 3246/5000 (65%)\n",
      "[epoch 44] loss: 0.0010947\n",
      "Test set: Average loss: 1.3168, Accuracy: 3244/5000 (65%)\n",
      "[epoch 45] loss: 0.0010504\n",
      "Test set: Average loss: 1.3204, Accuracy: 3246/5000 (65%)\n",
      "[epoch 46] loss: 0.0010041\n",
      "Test set: Average loss: 1.3237, Accuracy: 3243/5000 (65%)\n",
      "[epoch 47] loss: 0.0009640\n",
      "Test set: Average loss: 1.3271, Accuracy: 3244/5000 (65%)\n",
      "[epoch 48] loss: 0.0009318\n",
      "Test set: Average loss: 1.3305, Accuracy: 3243/5000 (65%)\n",
      "[epoch 49] loss: 0.0008928\n",
      "Test set: Average loss: 1.3335, Accuracy: 3244/5000 (65%)\n",
      "[epoch 50] loss: 0.0008685\n",
      "Test set: Average loss: 1.3368, Accuracy: 3245/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.0787, Accuracy: 3253/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 1.0580, Accuracy: 6535/10000 (65%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3860, Accuracy: 573/5000 (11%)\n",
      "[epoch 1] loss: 1.3342190\n",
      "Test set: Average loss: 1.1349, Accuracy: 3023/5000 (60%)\n",
      "[epoch 2] loss: 0.5118763\n",
      "Test set: Average loss: 1.0403, Accuracy: 3175/5000 (64%)\n",
      "[epoch 3] loss: 0.2455542\n",
      "Test set: Average loss: 1.0400, Accuracy: 3227/5000 (65%)\n",
      "[epoch 4] loss: 0.1244574\n",
      "Test set: Average loss: 1.0442, Accuracy: 3225/5000 (64%)\n",
      "[epoch 5] loss: 0.0691521\n",
      "Test set: Average loss: 1.0606, Accuracy: 3249/5000 (65%)\n",
      "[epoch 6] loss: 0.0446777\n",
      "Test set: Average loss: 1.0763, Accuracy: 3251/5000 (65%)\n",
      "[epoch 7] loss: 0.0315607\n",
      "Test set: Average loss: 1.0866, Accuracy: 3249/5000 (65%)\n",
      "[epoch 8] loss: 0.0244190\n",
      "Test set: Average loss: 1.1012, Accuracy: 3255/5000 (65%)\n",
      "[epoch 9] loss: 0.0195610\n",
      "Test set: Average loss: 1.1116, Accuracy: 3260/5000 (65%)\n",
      "[epoch 10] loss: 0.0157363\n",
      "Test set: Average loss: 1.1212, Accuracy: 3259/5000 (65%)\n",
      "[epoch 11] loss: 0.0135415\n",
      "Test set: Average loss: 1.1326, Accuracy: 3259/5000 (65%)\n",
      "[epoch 12] loss: 0.0113747\n",
      "Test set: Average loss: 1.1417, Accuracy: 3259/5000 (65%)\n",
      "[epoch 13] loss: 0.0099394\n",
      "Test set: Average loss: 1.1480, Accuracy: 3258/5000 (65%)\n",
      "[epoch 14] loss: 0.0084532\n",
      "Test set: Average loss: 1.1577, Accuracy: 3251/5000 (65%)\n",
      "[epoch 15] loss: 0.0074506\n",
      "Test set: Average loss: 1.1651, Accuracy: 3258/5000 (65%)\n",
      "[epoch 16] loss: 0.0065747\n",
      "Test set: Average loss: 1.1731, Accuracy: 3254/5000 (65%)\n",
      "[epoch 17] loss: 0.0059978\n",
      "Test set: Average loss: 1.1799, Accuracy: 3257/5000 (65%)\n",
      "[epoch 18] loss: 0.0053173\n",
      "Test set: Average loss: 1.1871, Accuracy: 3255/5000 (65%)\n",
      "[epoch 19] loss: 0.0049793\n",
      "Test set: Average loss: 1.1936, Accuracy: 3253/5000 (65%)\n",
      "[epoch 20] loss: 0.0044199\n",
      "Test set: Average loss: 1.2004, Accuracy: 3252/5000 (65%)\n",
      "[epoch 21] loss: 0.0040472\n",
      "Test set: Average loss: 1.2058, Accuracy: 3258/5000 (65%)\n",
      "[epoch 22] loss: 0.0037471\n",
      "Test set: Average loss: 1.2117, Accuracy: 3253/5000 (65%)\n",
      "[epoch 23] loss: 0.0034159\n",
      "Test set: Average loss: 1.2161, Accuracy: 3259/5000 (65%)\n",
      "[epoch 24] loss: 0.0031595\n",
      "Test set: Average loss: 1.2221, Accuracy: 3258/5000 (65%)\n",
      "[epoch 25] loss: 0.0029228\n",
      "Test set: Average loss: 1.2277, Accuracy: 3260/5000 (65%)\n",
      "[epoch 26] loss: 0.0027196\n",
      "Test set: Average loss: 1.2327, Accuracy: 3264/5000 (65%)\n",
      "[epoch 27] loss: 0.0025395\n",
      "Test set: Average loss: 1.2374, Accuracy: 3263/5000 (65%)\n",
      "[epoch 28] loss: 0.0023726\n",
      "Test set: Average loss: 1.2421, Accuracy: 3263/5000 (65%)\n",
      "[epoch 29] loss: 0.0022209\n",
      "Test set: Average loss: 1.2467, Accuracy: 3267/5000 (65%)\n",
      "[epoch 30] loss: 0.0020991\n",
      "Test set: Average loss: 1.2514, Accuracy: 3268/5000 (65%)\n",
      "[epoch 31] loss: 0.0019778\n",
      "Test set: Average loss: 1.2565, Accuracy: 3263/5000 (65%)\n",
      "[epoch 32] loss: 0.0018561\n",
      "Test set: Average loss: 1.2609, Accuracy: 3265/5000 (65%)\n",
      "[epoch 33] loss: 0.0017395\n",
      "Test set: Average loss: 1.2656, Accuracy: 3263/5000 (65%)\n",
      "[epoch 34] loss: 0.0016865\n",
      "Test set: Average loss: 1.2693, Accuracy: 3263/5000 (65%)\n",
      "[epoch 35] loss: 0.0015729\n",
      "Test set: Average loss: 1.2733, Accuracy: 3267/5000 (65%)\n",
      "[epoch 36] loss: 0.0015139\n",
      "Test set: Average loss: 1.2774, Accuracy: 3267/5000 (65%)\n",
      "[epoch 37] loss: 0.0014137\n",
      "Test set: Average loss: 1.2813, Accuracy: 3266/5000 (65%)\n",
      "[epoch 38] loss: 0.0013562\n",
      "Test set: Average loss: 1.2853, Accuracy: 3262/5000 (65%)\n",
      "[epoch 39] loss: 0.0012984\n",
      "Test set: Average loss: 1.2888, Accuracy: 3262/5000 (65%)\n",
      "[epoch 40] loss: 0.0012251\n",
      "Test set: Average loss: 1.2921, Accuracy: 3267/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.0011696\n",
      "Test set: Average loss: 1.2965, Accuracy: 3265/5000 (65%)\n",
      "[epoch 42] loss: 0.0011126\n",
      "Test set: Average loss: 1.2998, Accuracy: 3265/5000 (65%)\n",
      "[epoch 43] loss: 0.0010539\n",
      "Test set: Average loss: 1.3032, Accuracy: 3268/5000 (65%)\n",
      "[epoch 44] loss: 0.0010142\n",
      "Test set: Average loss: 1.3065, Accuracy: 3270/5000 (65%)\n",
      "[epoch 45] loss: 0.0009627\n",
      "Test set: Average loss: 1.3102, Accuracy: 3270/5000 (65%)\n",
      "[epoch 46] loss: 0.0009484\n",
      "Test set: Average loss: 1.3134, Accuracy: 3268/5000 (65%)\n",
      "[epoch 47] loss: 0.0008993\n",
      "Test set: Average loss: 1.3167, Accuracy: 3271/5000 (65%)\n",
      "[epoch 48] loss: 0.0008601\n",
      "Test set: Average loss: 1.3195, Accuracy: 3271/5000 (65%)\n",
      "[epoch 49] loss: 0.0008192\n",
      "Test set: Average loss: 1.3229, Accuracy: 3271/5000 (65%)\n",
      "[epoch 50] loss: 0.0007835\n",
      "Test set: Average loss: 1.3258, Accuracy: 3267/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3229, Accuracy: 3271/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 1.2953, Accuracy: 6559/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4030, Accuracy: 636/5000 (13%)\n",
      "[epoch 1] loss: 1.4074701\n",
      "Test set: Average loss: 1.1425, Accuracy: 3029/5000 (61%)\n",
      "[epoch 2] loss: 0.5778643\n",
      "Test set: Average loss: 1.0573, Accuracy: 3148/5000 (63%)\n",
      "[epoch 3] loss: 0.2859047\n",
      "Test set: Average loss: 1.0483, Accuracy: 3207/5000 (64%)\n",
      "[epoch 4] loss: 0.1414566\n",
      "Test set: Average loss: 1.0478, Accuracy: 3216/5000 (64%)\n",
      "[epoch 5] loss: 0.0793921\n",
      "Test set: Average loss: 1.0655, Accuracy: 3204/5000 (64%)\n",
      "[epoch 6] loss: 0.0503869\n",
      "Test set: Average loss: 1.0785, Accuracy: 3207/5000 (64%)\n",
      "[epoch 7] loss: 0.0348298\n",
      "Test set: Average loss: 1.0888, Accuracy: 3221/5000 (64%)\n",
      "[epoch 8] loss: 0.0264664\n",
      "Test set: Average loss: 1.1022, Accuracy: 3208/5000 (64%)\n",
      "[epoch 9] loss: 0.0209789\n",
      "Test set: Average loss: 1.1150, Accuracy: 3207/5000 (64%)\n",
      "[epoch 10] loss: 0.0171770\n",
      "Test set: Average loss: 1.1264, Accuracy: 3209/5000 (64%)\n",
      "[epoch 11] loss: 0.0142524\n",
      "Test set: Average loss: 1.1358, Accuracy: 3213/5000 (64%)\n",
      "[epoch 12] loss: 0.0122436\n",
      "Test set: Average loss: 1.1453, Accuracy: 3213/5000 (64%)\n",
      "[epoch 13] loss: 0.0106062\n",
      "Test set: Average loss: 1.1541, Accuracy: 3212/5000 (64%)\n",
      "[epoch 14] loss: 0.0091584\n",
      "Test set: Average loss: 1.1622, Accuracy: 3216/5000 (64%)\n",
      "[epoch 15] loss: 0.0080093\n",
      "Test set: Average loss: 1.1686, Accuracy: 3214/5000 (64%)\n",
      "[epoch 16] loss: 0.0071732\n",
      "Test set: Average loss: 1.1776, Accuracy: 3217/5000 (64%)\n",
      "[epoch 17] loss: 0.0063464\n",
      "Test set: Average loss: 1.1841, Accuracy: 3217/5000 (64%)\n",
      "[epoch 18] loss: 0.0057232\n",
      "Test set: Average loss: 1.1920, Accuracy: 3215/5000 (64%)\n",
      "[epoch 19] loss: 0.0052531\n",
      "Test set: Average loss: 1.1982, Accuracy: 3217/5000 (64%)\n",
      "[epoch 20] loss: 0.0047506\n",
      "Test set: Average loss: 1.2047, Accuracy: 3217/5000 (64%)\n",
      "[epoch 21] loss: 0.0043800\n",
      "Test set: Average loss: 1.2119, Accuracy: 3212/5000 (64%)\n",
      "[epoch 22] loss: 0.0040189\n",
      "Test set: Average loss: 1.2179, Accuracy: 3214/5000 (64%)\n",
      "[epoch 23] loss: 0.0036416\n",
      "Test set: Average loss: 1.2235, Accuracy: 3213/5000 (64%)\n",
      "[epoch 24] loss: 0.0034373\n",
      "Test set: Average loss: 1.2288, Accuracy: 3218/5000 (64%)\n",
      "[epoch 25] loss: 0.0031786\n",
      "Test set: Average loss: 1.2345, Accuracy: 3211/5000 (64%)\n",
      "[epoch 26] loss: 0.0029503\n",
      "Test set: Average loss: 1.2400, Accuracy: 3213/5000 (64%)\n",
      "[epoch 27] loss: 0.0027359\n",
      "Test set: Average loss: 1.2456, Accuracy: 3214/5000 (64%)\n",
      "[epoch 28] loss: 0.0025675\n",
      "Test set: Average loss: 1.2505, Accuracy: 3214/5000 (64%)\n",
      "[epoch 29] loss: 0.0024023\n",
      "Test set: Average loss: 1.2550, Accuracy: 3211/5000 (64%)\n",
      "[epoch 30] loss: 0.0022374\n",
      "Test set: Average loss: 1.2598, Accuracy: 3213/5000 (64%)\n",
      "[epoch 31] loss: 0.0021228\n",
      "Test set: Average loss: 1.2637, Accuracy: 3214/5000 (64%)\n",
      "[epoch 32] loss: 0.0019911\n",
      "Test set: Average loss: 1.2687, Accuracy: 3211/5000 (64%)\n",
      "[epoch 33] loss: 0.0018872\n",
      "Test set: Average loss: 1.2725, Accuracy: 3214/5000 (64%)\n",
      "[epoch 34] loss: 0.0018012\n",
      "Test set: Average loss: 1.2767, Accuracy: 3214/5000 (64%)\n",
      "[epoch 35] loss: 0.0016988\n",
      "Test set: Average loss: 1.2811, Accuracy: 3211/5000 (64%)\n",
      "[epoch 36] loss: 0.0016029\n",
      "Test set: Average loss: 1.2849, Accuracy: 3214/5000 (64%)\n",
      "[epoch 37] loss: 0.0015507\n",
      "Test set: Average loss: 1.2889, Accuracy: 3210/5000 (64%)\n",
      "[epoch 38] loss: 0.0014570\n",
      "Test set: Average loss: 1.2928, Accuracy: 3212/5000 (64%)\n",
      "[epoch 39] loss: 0.0013750\n",
      "Test set: Average loss: 1.2963, Accuracy: 3213/5000 (64%)\n",
      "[epoch 40] loss: 0.0013277\n",
      "Test set: Average loss: 1.3007, Accuracy: 3212/5000 (64%)\n",
      "[epoch 41] loss: 0.0012826\n",
      "Test set: Average loss: 1.3043, Accuracy: 3215/5000 (64%)\n",
      "[epoch 42] loss: 0.0011996\n",
      "Test set: Average loss: 1.3079, Accuracy: 3212/5000 (64%)\n",
      "[epoch 43] loss: 0.0011605\n",
      "Test set: Average loss: 1.3115, Accuracy: 3207/5000 (64%)\n",
      "[epoch 44] loss: 0.0010981\n",
      "Test set: Average loss: 1.3150, Accuracy: 3208/5000 (64%)\n",
      "[epoch 45] loss: 0.0010421\n",
      "Test set: Average loss: 1.3185, Accuracy: 3212/5000 (64%)\n",
      "[epoch 46] loss: 0.0009989\n",
      "Test set: Average loss: 1.3216, Accuracy: 3210/5000 (64%)\n",
      "[epoch 47] loss: 0.0009754\n",
      "Test set: Average loss: 1.3249, Accuracy: 3206/5000 (64%)\n",
      "[epoch 48] loss: 0.0009384\n",
      "Test set: Average loss: 1.3285, Accuracy: 3208/5000 (64%)\n",
      "[epoch 49] loss: 0.0008879\n",
      "Test set: Average loss: 1.3317, Accuracy: 3210/5000 (64%)\n",
      "[epoch 50] loss: 0.0008488\n",
      "Test set: Average loss: 1.3346, Accuracy: 3208/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.0888, Accuracy: 3221/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 1.0798, Accuracy: 6513/10000 (65%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4072, Accuracy: 684/5000 (14%)\n",
      "[epoch 1] loss: 1.0093786\n",
      "Test set: Average loss: 1.0692, Accuracy: 3147/5000 (63%)\n",
      "[epoch 2] loss: 0.3658645\n",
      "Test set: Average loss: 1.0124, Accuracy: 3255/5000 (65%)\n",
      "[epoch 3] loss: 0.1299787\n",
      "Test set: Average loss: 1.0405, Accuracy: 3308/5000 (66%)\n",
      "[epoch 4] loss: 0.0533093\n",
      "Test set: Average loss: 1.0747, Accuracy: 3315/5000 (66%)\n",
      "[epoch 5] loss: 0.0289199\n",
      "Test set: Average loss: 1.1067, Accuracy: 3305/5000 (66%)\n",
      "[epoch 6] loss: 0.0183124\n",
      "Test set: Average loss: 1.1294, Accuracy: 3316/5000 (66%)\n",
      "[epoch 7] loss: 0.0131611\n",
      "Test set: Average loss: 1.1505, Accuracy: 3307/5000 (66%)\n",
      "[epoch 8] loss: 0.0100591\n",
      "Test set: Average loss: 1.1708, Accuracy: 3305/5000 (66%)\n",
      "[epoch 9] loss: 0.0078710\n",
      "Test set: Average loss: 1.1877, Accuracy: 3316/5000 (66%)\n",
      "[epoch 10] loss: 0.0064028\n",
      "Test set: Average loss: 1.2054, Accuracy: 3307/5000 (66%)\n",
      "[epoch 11] loss: 0.0053084\n",
      "Test set: Average loss: 1.2191, Accuracy: 3306/5000 (66%)\n",
      "[epoch 12] loss: 0.1681731\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.2813, Accuracy: 3223/5000 (64%)\n",
      "[epoch 13] loss: 0.0204110\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.2293, Accuracy: 3296/5000 (66%)\n",
      "[epoch 14] loss: 0.0080868\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.2283, Accuracy: 3301/5000 (66%)\n",
      "[epoch 15] loss: 0.0079764\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 16] loss: 0.0078237\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 17] loss: 0.0079722\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 18] loss: 0.0078456\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 19] loss: 0.0078312\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 20] loss: 0.0078939\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 21] loss: 0.0078500\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 22] loss: 0.0078823\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 23] loss: 0.0080871\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 24] loss: 0.0078633\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 25] loss: 0.0078244\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 26] loss: 0.0078291\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 27] loss: 0.0078986\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 28] loss: 0.0078548\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 29] loss: 0.0078732\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 30] loss: 0.0078664\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 31] loss: 0.0078328\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 32] loss: 0.0078448\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 33] loss: 0.0078319\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 34] loss: 0.0078060\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 35] loss: 0.0078120\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 36] loss: 0.0078465\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 37] loss: 0.0078385\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 38] loss: 0.0078792\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 39] loss: 0.0079678\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 40] loss: 0.0078907\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 41] loss: 0.0079454\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 42] loss: 0.0078603\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 43] loss: 0.0078083\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 44] loss: 0.0078386\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 45] loss: 0.0079448\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 46] loss: 0.0078170\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 47] loss: 0.1463536\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 48] loss: 0.0078677\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 49] loss: 0.0079485\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "[epoch 50] loss: 0.0080411\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 1.2282, Accuracy: 3301/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1877, Accuracy: 3316/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.1668, Accuracy: 6673/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4436, Accuracy: 453/5000 (9%)\n",
      "[epoch 1] loss: 1.0058166\n",
      "Test set: Average loss: 1.0504, Accuracy: 3188/5000 (64%)\n",
      "[epoch 2] loss: 0.4282862\n",
      "Test set: Average loss: 1.0081, Accuracy: 3287/5000 (66%)\n",
      "[epoch 3] loss: 0.1703440\n",
      "Test set: Average loss: 1.0339, Accuracy: 3299/5000 (66%)\n",
      "[epoch 4] loss: 0.0598463\n",
      "Test set: Average loss: 1.0588, Accuracy: 3284/5000 (66%)\n",
      "[epoch 5] loss: 0.0309184\n",
      "Test set: Average loss: 1.0828, Accuracy: 3313/5000 (66%)\n",
      "[epoch 6] loss: 0.0201080\n",
      "Test set: Average loss: 1.1061, Accuracy: 3306/5000 (66%)\n",
      "[epoch 7] loss: 0.0143105\n",
      "Test set: Average loss: 1.1288, Accuracy: 3309/5000 (66%)\n",
      "[epoch 8] loss: 0.0108316\n",
      "Test set: Average loss: 1.1458, Accuracy: 3301/5000 (66%)\n",
      "[epoch 9] loss: 0.0084754\n",
      "Test set: Average loss: 1.1636, Accuracy: 3304/5000 (66%)\n",
      "[epoch 10] loss: 0.0070114\n",
      "Test set: Average loss: 1.1786, Accuracy: 3308/5000 (66%)\n",
      "[epoch 11] loss: 0.0057283\n",
      "Test set: Average loss: 1.1923, Accuracy: 3311/5000 (66%)\n",
      "[epoch 12] loss: 0.0049769\n",
      "Test set: Average loss: 1.2072, Accuracy: 3303/5000 (66%)\n",
      "[epoch 13] loss: 0.0041938\n",
      "Test set: Average loss: 1.2179, Accuracy: 3311/5000 (66%)\n",
      "[epoch 14] loss: 0.0035107\n",
      "Test set: Average loss: 1.2295, Accuracy: 3315/5000 (66%)\n",
      "[epoch 15] loss: 0.0030768\n",
      "Test set: Average loss: 1.2402, Accuracy: 3313/5000 (66%)\n",
      "[epoch 16] loss: 0.0027375\n",
      "Test set: Average loss: 1.2507, Accuracy: 3312/5000 (66%)\n",
      "[epoch 17] loss: 0.0023793\n",
      "Test set: Average loss: 1.2609, Accuracy: 3312/5000 (66%)\n",
      "[epoch 18] loss: 0.1601127\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4237, Accuracy: 3164/5000 (63%)\n",
      "[epoch 19] loss: 0.0258878\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.2886, Accuracy: 3264/5000 (65%)\n",
      "[epoch 20] loss: 0.0048383\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.2884, Accuracy: 3266/5000 (65%)\n",
      "[epoch 21] loss: 0.0047005\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 22] loss: 0.0046680\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 23] loss: 0.0047950\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 24] loss: 0.0046772\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 25] loss: 0.0046755\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 26] loss: 0.0046490\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 27] loss: 0.0047351\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 28] loss: 0.0046675\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 29] loss: 0.0046904\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 30] loss: 0.0047115\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 31] loss: 0.0047070\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 32] loss: 0.0046615\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 33] loss: 0.0046632\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 34] loss: 0.0046555\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0047128\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 36] loss: 0.0046630\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 37] loss: 0.0046465\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 38] loss: 0.0047397\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 39] loss: 0.0047236\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 40] loss: 0.0046489\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 41] loss: 0.0046418\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 42] loss: 0.0046785\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 43] loss: 0.0046748\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 44] loss: 0.0046581\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 45] loss: 0.0046828\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 46] loss: 0.0046709\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 47] loss: 0.1492503\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 48] loss: 0.0046683\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 49] loss: 0.0046747\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "[epoch 50] loss: 0.0046874\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.2883, Accuracy: 3267/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2295, Accuracy: 3315/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.2042, Accuracy: 6697/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5192, Accuracy: 436/5000 (9%)\n",
      "[epoch 1] loss: 1.0840884\n",
      "Test set: Average loss: 1.0233, Accuracy: 3221/5000 (64%)\n",
      "[epoch 2] loss: 0.3819949\n",
      "Test set: Average loss: 1.0156, Accuracy: 3267/5000 (65%)\n",
      "[epoch 3] loss: 0.1423585\n",
      "Test set: Average loss: 1.0336, Accuracy: 3307/5000 (66%)\n",
      "[epoch 4] loss: 0.0557252\n",
      "Test set: Average loss: 1.0509, Accuracy: 3315/5000 (66%)\n",
      "[epoch 5] loss: 0.0290009\n",
      "Test set: Average loss: 1.0812, Accuracy: 3304/5000 (66%)\n",
      "[epoch 6] loss: 0.0190803\n",
      "Test set: Average loss: 1.1069, Accuracy: 3321/5000 (66%)\n",
      "[epoch 7] loss: 0.0133023\n",
      "Test set: Average loss: 1.1250, Accuracy: 3299/5000 (66%)\n",
      "[epoch 8] loss: 0.0100925\n",
      "Test set: Average loss: 1.1456, Accuracy: 3312/5000 (66%)\n",
      "[epoch 9] loss: 0.0079258\n",
      "Test set: Average loss: 1.1607, Accuracy: 3310/5000 (66%)\n",
      "[epoch 10] loss: 0.0064204\n",
      "Test set: Average loss: 1.1757, Accuracy: 3319/5000 (66%)\n",
      "[epoch 11] loss: 0.0053221\n",
      "Test set: Average loss: 1.1908, Accuracy: 3315/5000 (66%)\n",
      "[epoch 12] loss: 0.0044991\n",
      "Test set: Average loss: 1.2036, Accuracy: 3313/5000 (66%)\n",
      "[epoch 13] loss: 0.0038055\n",
      "Test set: Average loss: 1.2155, Accuracy: 3313/5000 (66%)\n",
      "[epoch 14] loss: 0.0033087\n",
      "Test set: Average loss: 1.2264, Accuracy: 3306/5000 (66%)\n",
      "[epoch 15] loss: 0.0029048\n",
      "Test set: Average loss: 1.2374, Accuracy: 3309/5000 (66%)\n",
      "[epoch 16] loss: 0.0025360\n",
      "Test set: Average loss: 1.2477, Accuracy: 3305/5000 (66%)\n",
      "[epoch 17] loss: 0.0022555\n",
      "Test set: Average loss: 1.2584, Accuracy: 3311/5000 (66%)\n",
      "[epoch 18] loss: 0.0020098\n",
      "Test set: Average loss: 1.2683, Accuracy: 3308/5000 (66%)\n",
      "[epoch 19] loss: 0.2012779\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.3793, Accuracy: 3213/5000 (64%)\n",
      "[epoch 20] loss: 0.0203397\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.2680, Accuracy: 3282/5000 (66%)\n",
      "[epoch 21] loss: 0.0050959\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.2677, Accuracy: 3280/5000 (66%)\n",
      "[epoch 22] loss: 0.0049360\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 23] loss: 0.0049371\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 24] loss: 0.0049489\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 25] loss: 0.0049171\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 26] loss: 0.0049431\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 27] loss: 0.0049604\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 28] loss: 0.0049649\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 29] loss: 0.0049167\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 30] loss: 0.1769130\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 31] loss: 0.0049061\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 32] loss: 0.0049495\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 33] loss: 0.0049231\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 34] loss: 0.0049507\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 35] loss: 0.0049822\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 36] loss: 0.0049734\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 37] loss: 0.0049340\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 38] loss: 0.0049796\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 39] loss: 0.0049233\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 40] loss: 0.0049281\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 41] loss: 0.0049298\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 42] loss: 0.0049529\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 43] loss: 0.0049062\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 44] loss: 0.0049277\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 45] loss: 0.0049181\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 46] loss: 0.0049877\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47] loss: 0.0049292\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 48] loss: 0.0049394\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 49] loss: 0.0049639\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "[epoch 50] loss: 0.0049131\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.2676, Accuracy: 3280/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1069, Accuracy: 3321/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.0970, Accuracy: 6705/10000 (67%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4389, Accuracy: 540/5000 (11%)\n",
      "[epoch 1] loss: 0.7650790\n",
      "Test set: Average loss: 1.0155, Accuracy: 3258/5000 (65%)\n",
      "[epoch 2] loss: 0.1948188\n",
      "Test set: Average loss: 1.0462, Accuracy: 3338/5000 (67%)\n",
      "[epoch 3] loss: 0.0522885\n",
      "Test set: Average loss: 1.1155, Accuracy: 3318/5000 (66%)\n",
      "[epoch 4] loss: 0.0196902\n",
      "Test set: Average loss: 1.1519, Accuracy: 3340/5000 (67%)\n",
      "[epoch 5] loss: 0.0111215\n",
      "Test set: Average loss: 1.1903, Accuracy: 3327/5000 (67%)\n",
      "[epoch 6] loss: 0.0074690\n",
      "Test set: Average loss: 1.2252, Accuracy: 3324/5000 (66%)\n",
      "[epoch 7] loss: 0.0053976\n",
      "Test set: Average loss: 1.2542, Accuracy: 3322/5000 (66%)\n",
      "[epoch 8] loss: 0.0040977\n",
      "Test set: Average loss: 1.2762, Accuracy: 3321/5000 (66%)\n",
      "[epoch 9] loss: 0.0032165\n",
      "Test set: Average loss: 1.2992, Accuracy: 3328/5000 (67%)\n",
      "[epoch 10] loss: 0.0025794\n",
      "Test set: Average loss: 1.3209, Accuracy: 3322/5000 (66%)\n",
      "[epoch 11] loss: 0.0021078\n",
      "Test set: Average loss: 1.3411, Accuracy: 3329/5000 (67%)\n",
      "[epoch 12] loss: 0.0017439\n",
      "Test set: Average loss: 1.3586, Accuracy: 3326/5000 (67%)\n",
      "[epoch 13] loss: 0.0014660\n",
      "Test set: Average loss: 1.3742, Accuracy: 3317/5000 (66%)\n",
      "[epoch 14] loss: 0.0012446\n",
      "Test set: Average loss: 1.3921, Accuracy: 3317/5000 (66%)\n",
      "[epoch 15] loss: 0.0010688\n",
      "Test set: Average loss: 1.4082, Accuracy: 3314/5000 (66%)\n",
      "[epoch 16] loss: 0.0009247\n",
      "Test set: Average loss: 1.4224, Accuracy: 3313/5000 (66%)\n",
      "[epoch 17] loss: 0.0008058\n",
      "Test set: Average loss: 1.4376, Accuracy: 3309/5000 (66%)\n",
      "[epoch 18] loss: 0.0007026\n",
      "Test set: Average loss: 1.4496, Accuracy: 3312/5000 (66%)\n",
      "[epoch 19] loss: 0.0006167\n",
      "Test set: Average loss: 1.4633, Accuracy: 3308/5000 (66%)\n",
      "[epoch 20] loss: 0.0005457\n",
      "Test set: Average loss: 1.4769, Accuracy: 3311/5000 (66%)\n",
      "[epoch 21] loss: 0.0004831\n",
      "Test set: Average loss: 1.4902, Accuracy: 3310/5000 (66%)\n",
      "[epoch 22] loss: 0.0004301\n",
      "Test set: Average loss: 1.5025, Accuracy: 3311/5000 (66%)\n",
      "[epoch 23] loss: 0.0003884\n",
      "Test set: Average loss: 1.5145, Accuracy: 3309/5000 (66%)\n",
      "[epoch 24] loss: 0.0003431\n",
      "Test set: Average loss: 1.5263, Accuracy: 3310/5000 (66%)\n",
      "[epoch 25] loss: 0.0003073\n",
      "Test set: Average loss: 1.5383, Accuracy: 3316/5000 (66%)\n",
      "[epoch 26] loss: 0.0002759\n",
      "Test set: Average loss: 1.5505, Accuracy: 3313/5000 (66%)\n",
      "[epoch 27] loss: 0.0002476\n",
      "Test set: Average loss: 1.5604, Accuracy: 3308/5000 (66%)\n",
      "[epoch 28] loss: 0.0002234\n",
      "Test set: Average loss: 1.5717, Accuracy: 3311/5000 (66%)\n",
      "[epoch 29] loss: 0.0002020\n",
      "Test set: Average loss: 1.5839, Accuracy: 3310/5000 (66%)\n",
      "[epoch 30] loss: 0.0001821\n",
      "Test set: Average loss: 1.5937, Accuracy: 3310/5000 (66%)\n",
      "[epoch 31] loss: 0.0001649\n",
      "Test set: Average loss: 1.6035, Accuracy: 3316/5000 (66%)\n",
      "[epoch 32] loss: 0.0001494\n",
      "Test set: Average loss: 1.6155, Accuracy: 3313/5000 (66%)\n",
      "[epoch 33] loss: 0.0001357\n",
      "Test set: Average loss: 1.6258, Accuracy: 3314/5000 (66%)\n",
      "[epoch 34] loss: 0.0001229\n",
      "Test set: Average loss: 1.6368, Accuracy: 3315/5000 (66%)\n",
      "[epoch 35] loss: 0.0001120\n",
      "Test set: Average loss: 1.6467, Accuracy: 3316/5000 (66%)\n",
      "[epoch 36] loss: 0.0001021\n",
      "Test set: Average loss: 1.6579, Accuracy: 3311/5000 (66%)\n",
      "[epoch 37] loss: 0.0000926\n",
      "Test set: Average loss: 1.6655, Accuracy: 3317/5000 (66%)\n",
      "[epoch 38] loss: 0.0000843\n",
      "Test set: Average loss: 1.6771, Accuracy: 3314/5000 (66%)\n",
      "[epoch 39] loss: 0.0000773\n",
      "Test set: Average loss: 1.6883, Accuracy: 3313/5000 (66%)\n",
      "[epoch 40] loss: 0.0000701\n",
      "Test set: Average loss: 1.6975, Accuracy: 3318/5000 (66%)\n",
      "[epoch 41] loss: 0.0000646\n",
      "Test set: Average loss: 1.7062, Accuracy: 3319/5000 (66%)\n",
      "[epoch 42] loss: 0.0000585\n",
      "Test set: Average loss: 1.7174, Accuracy: 3319/5000 (66%)\n",
      "[epoch 43] loss: 0.0000534\n",
      "Test set: Average loss: 1.7277, Accuracy: 3315/5000 (66%)\n",
      "[epoch 44] loss: 0.0000488\n",
      "Test set: Average loss: 1.7383, Accuracy: 3315/5000 (66%)\n",
      "[epoch 45] loss: 0.0000446\n",
      "Test set: Average loss: 1.7475, Accuracy: 3317/5000 (66%)\n",
      "[epoch 46] loss: 0.0000408\n",
      "Test set: Average loss: 1.7571, Accuracy: 3312/5000 (66%)\n",
      "[epoch 47] loss: 0.0000376\n",
      "Test set: Average loss: 1.7667, Accuracy: 3317/5000 (66%)\n",
      "[epoch 48] loss: 0.0000341\n",
      "Test set: Average loss: 1.7761, Accuracy: 3312/5000 (66%)\n",
      "[epoch 49] loss: 0.0000312\n",
      "Test set: Average loss: 1.7870, Accuracy: 3318/5000 (66%)\n",
      "[epoch 50] loss: 0.0000287\n",
      "Test set: Average loss: 1.7967, Accuracy: 3315/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1519, Accuracy: 3340/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.1193, Accuracy: 6796/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4320, Accuracy: 450/5000 (9%)\n",
      "[epoch 1] loss: 0.7901201\n",
      "Test set: Average loss: 1.0194, Accuracy: 3282/5000 (66%)\n",
      "[epoch 2] loss: 0.2109305\n",
      "Test set: Average loss: 1.0251, Accuracy: 3328/5000 (67%)\n",
      "[epoch 3] loss: 0.0573717\n",
      "Test set: Average loss: 1.0825, Accuracy: 3350/5000 (67%)\n",
      "[epoch 4] loss: 0.0208902\n",
      "Test set: Average loss: 1.1306, Accuracy: 3354/5000 (67%)\n",
      "[epoch 5] loss: 0.0115210\n",
      "Test set: Average loss: 1.1690, Accuracy: 3344/5000 (67%)\n",
      "[epoch 6] loss: 0.0077024\n",
      "Test set: Average loss: 1.1959, Accuracy: 3352/5000 (67%)\n",
      "[epoch 7] loss: 0.0055333\n",
      "Test set: Average loss: 1.2247, Accuracy: 3348/5000 (67%)\n",
      "[epoch 8] loss: 0.0041999\n",
      "Test set: Average loss: 1.2511, Accuracy: 3352/5000 (67%)\n",
      "[epoch 9] loss: 0.0032769\n",
      "Test set: Average loss: 1.2691, Accuracy: 3348/5000 (67%)\n",
      "[epoch 10] loss: 0.0026272\n",
      "Test set: Average loss: 1.2908, Accuracy: 3349/5000 (67%)\n",
      "[epoch 11] loss: 0.0021501\n",
      "Test set: Average loss: 1.3099, Accuracy: 3352/5000 (67%)\n",
      "[epoch 12] loss: 0.0017805\n",
      "Test set: Average loss: 1.3279, Accuracy: 3351/5000 (67%)\n",
      "[epoch 13] loss: 0.0015016\n",
      "Test set: Average loss: 1.3454, Accuracy: 3349/5000 (67%)\n",
      "[epoch 14] loss: 0.0012799\n",
      "Test set: Average loss: 1.3613, Accuracy: 3343/5000 (67%)\n",
      "[epoch 15] loss: 0.0010974\n",
      "Test set: Average loss: 1.3744, Accuracy: 3351/5000 (67%)\n",
      "[epoch 16] loss: 0.0009487\n",
      "Test set: Average loss: 1.3889, Accuracy: 3352/5000 (67%)\n",
      "[epoch 17] loss: 0.0008208\n",
      "Test set: Average loss: 1.4049, Accuracy: 3348/5000 (67%)\n",
      "[epoch 18] loss: 0.0007156\n",
      "Test set: Average loss: 1.4165, Accuracy: 3351/5000 (67%)\n",
      "[epoch 19] loss: 0.0006301\n",
      "Test set: Average loss: 1.4293, Accuracy: 3346/5000 (67%)\n",
      "[epoch 20] loss: 0.0005566\n",
      "Test set: Average loss: 1.4423, Accuracy: 3350/5000 (67%)\n",
      "[epoch 21] loss: 0.0004966\n",
      "Test set: Average loss: 1.4541, Accuracy: 3349/5000 (67%)\n",
      "[epoch 22] loss: 0.0004383\n",
      "Test set: Average loss: 1.4659, Accuracy: 3347/5000 (67%)\n",
      "[epoch 23] loss: 0.0003902\n",
      "Test set: Average loss: 1.4774, Accuracy: 3349/5000 (67%)\n",
      "[epoch 24] loss: 0.0003491\n",
      "Test set: Average loss: 1.4894, Accuracy: 3352/5000 (67%)\n",
      "[epoch 25] loss: 0.0003130\n",
      "Test set: Average loss: 1.5012, Accuracy: 3345/5000 (67%)\n",
      "[epoch 26] loss: 0.0002815\n",
      "Test set: Average loss: 1.5123, Accuracy: 3345/5000 (67%)\n",
      "[epoch 27] loss: 0.0002521\n",
      "Test set: Average loss: 1.5234, Accuracy: 3344/5000 (67%)\n",
      "[epoch 28] loss: 0.0002276\n",
      "Test set: Average loss: 1.5348, Accuracy: 3343/5000 (67%)\n",
      "[epoch 29] loss: 0.0002056\n",
      "Test set: Average loss: 1.5447, Accuracy: 3345/5000 (67%)\n",
      "[epoch 30] loss: 0.0001861\n",
      "Test set: Average loss: 1.5559, Accuracy: 3348/5000 (67%)\n",
      "[epoch 31] loss: 0.0001678\n",
      "Test set: Average loss: 1.5665, Accuracy: 3346/5000 (67%)\n",
      "[epoch 32] loss: 0.0001518\n",
      "Test set: Average loss: 1.5761, Accuracy: 3349/5000 (67%)\n",
      "[epoch 33] loss: 0.0001378\n",
      "Test set: Average loss: 1.5871, Accuracy: 3346/5000 (67%)\n",
      "[epoch 34] loss: 0.0001250\n",
      "Test set: Average loss: 1.5980, Accuracy: 3343/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0001137\n",
      "Test set: Average loss: 1.6085, Accuracy: 3348/5000 (67%)\n",
      "[epoch 36] loss: 0.0001035\n",
      "Test set: Average loss: 1.6182, Accuracy: 3345/5000 (67%)\n",
      "[epoch 37] loss: 0.0000943\n",
      "Test set: Average loss: 1.6282, Accuracy: 3350/5000 (67%)\n",
      "[epoch 38] loss: 0.0000858\n",
      "Test set: Average loss: 1.6374, Accuracy: 3343/5000 (67%)\n",
      "[epoch 39] loss: 0.0000783\n",
      "Test set: Average loss: 1.6478, Accuracy: 3342/5000 (67%)\n",
      "[epoch 40] loss: 0.1171942\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9894, Accuracy: 3082/5000 (62%)\n",
      "[epoch 41] loss: 0.0139432\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.6095, Accuracy: 3317/5000 (66%)\n",
      "[epoch 42] loss: 0.0015766\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3323/5000 (66%)\n",
      "[epoch 43] loss: 0.0014336\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 44] loss: 0.0014216\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 45] loss: 0.0014225\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 46] loss: 0.0014202\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 47] loss: 0.0014176\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 48] loss: 0.0014211\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 49] loss: 0.0014203\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "[epoch 50] loss: 0.0014201\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.6093, Accuracy: 3324/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1306, Accuracy: 3354/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.1103, Accuracy: 6780/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.6062, Accuracy: 230/5000 (5%)\n",
      "[epoch 1] loss: 0.8311860\n",
      "Test set: Average loss: 0.9990, Accuracy: 3289/5000 (66%)\n",
      "[epoch 2] loss: 0.2276735\n",
      "Test set: Average loss: 1.0375, Accuracy: 3322/5000 (66%)\n",
      "[epoch 3] loss: 0.0630644\n",
      "Test set: Average loss: 1.0784, Accuracy: 3353/5000 (67%)\n",
      "[epoch 4] loss: 0.0223983\n",
      "Test set: Average loss: 1.1306, Accuracy: 3333/5000 (67%)\n",
      "[epoch 5] loss: 0.0121787\n",
      "Test set: Average loss: 1.1650, Accuracy: 3346/5000 (67%)\n",
      "[epoch 6] loss: 0.0080906\n",
      "Test set: Average loss: 1.1966, Accuracy: 3337/5000 (67%)\n",
      "[epoch 7] loss: 0.0058395\n",
      "Test set: Average loss: 1.2249, Accuracy: 3333/5000 (67%)\n",
      "[epoch 8] loss: 0.0044016\n",
      "Test set: Average loss: 1.2492, Accuracy: 3338/5000 (67%)\n",
      "[epoch 9] loss: 0.0034474\n",
      "Test set: Average loss: 1.2727, Accuracy: 3351/5000 (67%)\n",
      "[epoch 10] loss: 0.0027559\n",
      "Test set: Average loss: 1.2895, Accuracy: 3343/5000 (67%)\n",
      "[epoch 11] loss: 0.0022427\n",
      "Test set: Average loss: 1.3105, Accuracy: 3341/5000 (67%)\n",
      "[epoch 12] loss: 0.0018622\n",
      "Test set: Average loss: 1.3270, Accuracy: 3342/5000 (67%)\n",
      "[epoch 13] loss: 0.0015695\n",
      "Test set: Average loss: 1.3434, Accuracy: 3337/5000 (67%)\n",
      "[epoch 14] loss: 0.0013416\n",
      "Test set: Average loss: 1.3701, Accuracy: 3343/5000 (67%)\n",
      "[epoch 15] loss: 0.0011420\n",
      "Test set: Average loss: 1.3730, Accuracy: 3351/5000 (67%)\n",
      "[epoch 16] loss: 0.0009852\n",
      "Test set: Average loss: 1.3880, Accuracy: 3340/5000 (67%)\n",
      "[epoch 17] loss: 0.0008555\n",
      "Test set: Average loss: 1.4032, Accuracy: 3349/5000 (67%)\n",
      "[epoch 18] loss: 0.0007492\n",
      "Test set: Average loss: 1.4153, Accuracy: 3346/5000 (67%)\n",
      "[epoch 19] loss: 0.0006572\n",
      "Test set: Average loss: 1.4287, Accuracy: 3344/5000 (67%)\n",
      "[epoch 20] loss: 0.0005794\n",
      "Test set: Average loss: 1.4420, Accuracy: 3351/5000 (67%)\n",
      "[epoch 21] loss: 0.0005137\n",
      "Test set: Average loss: 1.4545, Accuracy: 3346/5000 (67%)\n",
      "[epoch 22] loss: 0.0004563\n",
      "Test set: Average loss: 1.4668, Accuracy: 3351/5000 (67%)\n",
      "[epoch 23] loss: 0.0004070\n",
      "Test set: Average loss: 1.4780, Accuracy: 3354/5000 (67%)\n",
      "[epoch 24] loss: 0.0003635\n",
      "Test set: Average loss: 1.4902, Accuracy: 3342/5000 (67%)\n",
      "[epoch 25] loss: 0.0003254\n",
      "Test set: Average loss: 1.5004, Accuracy: 3359/5000 (67%)\n",
      "[epoch 26] loss: 0.0002920\n",
      "Test set: Average loss: 1.5119, Accuracy: 3357/5000 (67%)\n",
      "[epoch 27] loss: 0.0002629\n",
      "Test set: Average loss: 1.5230, Accuracy: 3358/5000 (67%)\n",
      "[epoch 28] loss: 0.0002369\n",
      "Test set: Average loss: 1.5347, Accuracy: 3348/5000 (67%)\n",
      "[epoch 29] loss: 0.0002144\n",
      "Test set: Average loss: 1.5450, Accuracy: 3350/5000 (67%)\n",
      "[epoch 30] loss: 0.0001935\n",
      "Test set: Average loss: 1.5547, Accuracy: 3353/5000 (67%)\n",
      "[epoch 31] loss: 0.0001746\n",
      "Test set: Average loss: 1.5661, Accuracy: 3353/5000 (67%)\n",
      "[epoch 32] loss: 0.0001587\n",
      "Test set: Average loss: 1.5764, Accuracy: 3353/5000 (67%)\n",
      "[epoch 33] loss: 0.0001442\n",
      "Test set: Average loss: 1.5870, Accuracy: 3347/5000 (67%)\n",
      "[epoch 34] loss: 0.0001308\n",
      "Test set: Average loss: 1.5973, Accuracy: 3348/5000 (67%)\n",
      "[epoch 35] loss: 0.0001185\n",
      "Test set: Average loss: 1.6075, Accuracy: 3352/5000 (67%)\n",
      "[epoch 36] loss: 0.0001078\n",
      "Test set: Average loss: 1.6184, Accuracy: 3345/5000 (67%)\n",
      "[epoch 37] loss: 0.0000983\n",
      "Test set: Average loss: 1.6272, Accuracy: 3350/5000 (67%)\n",
      "[epoch 38] loss: 0.0000895\n",
      "Test set: Average loss: 1.6375, Accuracy: 3350/5000 (67%)\n",
      "[epoch 39] loss: 0.0000815\n",
      "Test set: Average loss: 1.6477, Accuracy: 3345/5000 (67%)\n",
      "[epoch 40] loss: 0.0000746\n",
      "Test set: Average loss: 1.6559, Accuracy: 3349/5000 (67%)\n",
      "[epoch 41] loss: 0.0000679\n",
      "Test set: Average loss: 1.6673, Accuracy: 3346/5000 (67%)\n",
      "[epoch 42] loss: 0.0000620\n",
      "Test set: Average loss: 1.6773, Accuracy: 3341/5000 (67%)\n",
      "[epoch 43] loss: 0.0000568\n",
      "Test set: Average loss: 1.6865, Accuracy: 3344/5000 (67%)\n",
      "[epoch 44] loss: 0.0000518\n",
      "Test set: Average loss: 1.6965, Accuracy: 3343/5000 (67%)\n",
      "[epoch 45] loss: 0.0000474\n",
      "Test set: Average loss: 1.7066, Accuracy: 3341/5000 (67%)\n",
      "[epoch 46] loss: 0.0000433\n",
      "Test set: Average loss: 1.7163, Accuracy: 3341/5000 (67%)\n",
      "[epoch 47] loss: 0.0000397\n",
      "Test set: Average loss: 1.7246, Accuracy: 3337/5000 (67%)\n",
      "[epoch 48] loss: 0.0000363\n",
      "Test set: Average loss: 1.7349, Accuracy: 3336/5000 (67%)\n",
      "[epoch 49] loss: 0.0000333\n",
      "Test set: Average loss: 1.7451, Accuracy: 3331/5000 (67%)\n",
      "[epoch 50] loss: 0.0000304\n",
      "Test set: Average loss: 1.7549, Accuracy: 3329/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5004, Accuracy: 3359/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.4699, Accuracy: 6786/10000 (68%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4765, Accuracy: 400/5000 (8%)\n",
      "[epoch 1] loss: 0.5491625\n",
      "Test set: Average loss: 1.0301, Accuracy: 3331/5000 (67%)\n",
      "[epoch 2] loss: 0.0926276\n",
      "Test set: Average loss: 1.1529, Accuracy: 3360/5000 (67%)\n",
      "[epoch 3] loss: 0.0213509\n",
      "Test set: Average loss: 1.2155, Accuracy: 3375/5000 (68%)\n",
      "[epoch 4] loss: 0.0075798\n",
      "Test set: Average loss: 1.2725, Accuracy: 3375/5000 (68%)\n",
      "[epoch 5] loss: 0.0044366\n",
      "Test set: Average loss: 1.3163, Accuracy: 3363/5000 (67%)\n",
      "[epoch 6] loss: 0.0029755\n",
      "Test set: Average loss: 1.3572, Accuracy: 3362/5000 (67%)\n",
      "[epoch 7] loss: 0.0021168\n",
      "Test set: Average loss: 1.3924, Accuracy: 3363/5000 (67%)\n",
      "[epoch 8] loss: 0.0015642\n",
      "Test set: Average loss: 1.4248, Accuracy: 3361/5000 (67%)\n",
      "[epoch 9] loss: 0.0011910\n",
      "Test set: Average loss: 1.4572, Accuracy: 3360/5000 (67%)\n",
      "[epoch 10] loss: 0.0009206\n",
      "Test set: Average loss: 1.4861, Accuracy: 3353/5000 (67%)\n",
      "[epoch 11] loss: 0.0007250\n",
      "Test set: Average loss: 1.5135, Accuracy: 3347/5000 (67%)\n",
      "[epoch 12] loss: 0.0005776\n",
      "Test set: Average loss: 1.5394, Accuracy: 3351/5000 (67%)\n",
      "[epoch 13] loss: 0.0004648\n",
      "Test set: Average loss: 1.5677, Accuracy: 3351/5000 (67%)\n",
      "[epoch 14] loss: 0.0003765\n",
      "Test set: Average loss: 1.5915, Accuracy: 3340/5000 (67%)\n",
      "[epoch 15] loss: 0.0003074\n",
      "Test set: Average loss: 1.6171, Accuracy: 3337/5000 (67%)\n",
      "[epoch 16] loss: 0.0002519\n",
      "Test set: Average loss: 1.6393, Accuracy: 3338/5000 (67%)\n",
      "[epoch 17] loss: 0.0002074\n",
      "Test set: Average loss: 1.6641, Accuracy: 3343/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0001713\n",
      "Test set: Average loss: 1.6873, Accuracy: 3345/5000 (67%)\n",
      "[epoch 19] loss: 0.0001420\n",
      "Test set: Average loss: 1.7089, Accuracy: 3339/5000 (67%)\n",
      "[epoch 20] loss: 0.0001180\n",
      "Test set: Average loss: 1.7335, Accuracy: 3336/5000 (67%)\n",
      "[epoch 21] loss: 0.0000983\n",
      "Test set: Average loss: 1.7555, Accuracy: 3337/5000 (67%)\n",
      "[epoch 22] loss: 0.0000818\n",
      "Test set: Average loss: 1.7781, Accuracy: 3334/5000 (67%)\n",
      "[epoch 23] loss: 0.0000685\n",
      "Test set: Average loss: 1.8002, Accuracy: 3334/5000 (67%)\n",
      "[epoch 24] loss: 0.0000573\n",
      "Test set: Average loss: 1.8223, Accuracy: 3336/5000 (67%)\n",
      "[epoch 25] loss: 0.0000479\n",
      "Test set: Average loss: 1.8439, Accuracy: 3336/5000 (67%)\n",
      "[epoch 26] loss: 0.0000402\n",
      "Test set: Average loss: 1.8685, Accuracy: 3337/5000 (67%)\n",
      "[epoch 27] loss: 0.0000337\n",
      "Test set: Average loss: 1.8875, Accuracy: 3337/5000 (67%)\n",
      "[epoch 28] loss: 0.0000283\n",
      "Test set: Average loss: 1.9085, Accuracy: 3338/5000 (67%)\n",
      "[epoch 29] loss: 0.0000238\n",
      "Test set: Average loss: 1.9318, Accuracy: 3336/5000 (67%)\n",
      "[epoch 30] loss: 0.0000200\n",
      "Test set: Average loss: 1.9530, Accuracy: 3336/5000 (67%)\n",
      "[epoch 31] loss: 0.0000168\n",
      "Test set: Average loss: 1.9745, Accuracy: 3333/5000 (67%)\n",
      "[epoch 32] loss: 0.0000142\n",
      "Test set: Average loss: 1.9974, Accuracy: 3336/5000 (67%)\n",
      "[epoch 33] loss: 0.0000119\n",
      "Test set: Average loss: 2.0190, Accuracy: 3338/5000 (67%)\n",
      "[epoch 34] loss: 0.0000100\n",
      "Test set: Average loss: 2.0387, Accuracy: 3335/5000 (67%)\n",
      "[epoch 35] loss: 0.0000084\n",
      "Test set: Average loss: 2.0595, Accuracy: 3336/5000 (67%)\n",
      "[epoch 36] loss: 0.0000071\n",
      "Test set: Average loss: 2.0813, Accuracy: 3337/5000 (67%)\n",
      "[epoch 37] loss: 0.0000060\n",
      "Test set: Average loss: 2.1029, Accuracy: 3330/5000 (67%)\n",
      "[epoch 38] loss: 0.0000050\n",
      "Test set: Average loss: 2.1238, Accuracy: 3337/5000 (67%)\n",
      "[epoch 39] loss: 0.0000042\n",
      "Test set: Average loss: 2.1469, Accuracy: 3337/5000 (67%)\n",
      "[epoch 40] loss: 0.0000036\n",
      "Test set: Average loss: 2.1661, Accuracy: 3339/5000 (67%)\n",
      "[epoch 41] loss: 0.0000030\n",
      "Test set: Average loss: 2.1851, Accuracy: 3333/5000 (67%)\n",
      "[epoch 42] loss: 0.0000025\n",
      "Test set: Average loss: 2.2045, Accuracy: 3333/5000 (67%)\n",
      "[epoch 43] loss: 0.0000021\n",
      "Test set: Average loss: 2.2244, Accuracy: 3330/5000 (67%)\n",
      "[epoch 44] loss: 0.0000017\n",
      "Test set: Average loss: 2.2435, Accuracy: 3328/5000 (67%)\n",
      "[epoch 45] loss: 0.0000015\n",
      "Test set: Average loss: 2.2600, Accuracy: 3327/5000 (67%)\n",
      "[epoch 46] loss: 0.0000012\n",
      "Test set: Average loss: 2.2741, Accuracy: 3334/5000 (67%)\n",
      "[epoch 47] loss: 0.0000010\n",
      "Test set: Average loss: 2.2888, Accuracy: 3326/5000 (67%)\n",
      "[epoch 48] loss: 0.0000008\n",
      "Test set: Average loss: 2.2989, Accuracy: 3320/5000 (66%)\n",
      "[epoch 49] loss: 0.0000007\n",
      "Test set: Average loss: 2.3097, Accuracy: 3317/5000 (66%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 2.3147, Accuracy: 3320/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2725, Accuracy: 3375/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.2489, Accuracy: 6784/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3783, Accuracy: 572/5000 (11%)\n",
      "[epoch 1] loss: 0.5356590\n",
      "Test set: Average loss: 1.0300, Accuracy: 3300/5000 (66%)\n",
      "[epoch 2] loss: 0.0892590\n",
      "Test set: Average loss: 1.1242, Accuracy: 3348/5000 (67%)\n",
      "[epoch 3] loss: 0.0201182\n",
      "Test set: Average loss: 1.2061, Accuracy: 3358/5000 (67%)\n",
      "[epoch 4] loss: 0.0074007\n",
      "Test set: Average loss: 1.2572, Accuracy: 3366/5000 (67%)\n",
      "[epoch 5] loss: 0.0043343\n",
      "Test set: Average loss: 1.3062, Accuracy: 3371/5000 (67%)\n",
      "[epoch 6] loss: 0.0029030\n",
      "Test set: Average loss: 1.3461, Accuracy: 3374/5000 (67%)\n",
      "[epoch 7] loss: 0.0020688\n",
      "Test set: Average loss: 1.3838, Accuracy: 3376/5000 (68%)\n",
      "[epoch 8] loss: 0.0015343\n",
      "Test set: Average loss: 1.4126, Accuracy: 3371/5000 (67%)\n",
      "[epoch 9] loss: 0.0011653\n",
      "Test set: Average loss: 1.4437, Accuracy: 3370/5000 (67%)\n",
      "[epoch 10] loss: 0.0009037\n",
      "Test set: Average loss: 1.4750, Accuracy: 3371/5000 (67%)\n",
      "[epoch 11] loss: 0.0007117\n",
      "Test set: Average loss: 1.4993, Accuracy: 3375/5000 (68%)\n",
      "[epoch 12] loss: 0.0005669\n",
      "Test set: Average loss: 1.5264, Accuracy: 3368/5000 (67%)\n",
      "[epoch 13] loss: 0.0004571\n",
      "Test set: Average loss: 1.5505, Accuracy: 3378/5000 (68%)\n",
      "[epoch 14] loss: 0.0003695\n",
      "Test set: Average loss: 1.5749, Accuracy: 3374/5000 (67%)\n",
      "[epoch 15] loss: 0.0003017\n",
      "Test set: Average loss: 1.5991, Accuracy: 3366/5000 (67%)\n",
      "[epoch 16] loss: 0.0002470\n",
      "Test set: Average loss: 1.6214, Accuracy: 3369/5000 (67%)\n",
      "[epoch 17] loss: 0.0002037\n",
      "Test set: Average loss: 1.6446, Accuracy: 3361/5000 (67%)\n",
      "[epoch 18] loss: 0.0001685\n",
      "Test set: Average loss: 1.6689, Accuracy: 3369/5000 (67%)\n",
      "[epoch 19] loss: 0.0001398\n",
      "Test set: Average loss: 1.6906, Accuracy: 3370/5000 (67%)\n",
      "[epoch 20] loss: 0.0001160\n",
      "Test set: Average loss: 1.7135, Accuracy: 3366/5000 (67%)\n",
      "[epoch 21] loss: 0.0000966\n",
      "Test set: Average loss: 1.7365, Accuracy: 3365/5000 (67%)\n",
      "[epoch 22] loss: 0.0000806\n",
      "Test set: Average loss: 1.7579, Accuracy: 3366/5000 (67%)\n",
      "[epoch 23] loss: 0.0000674\n",
      "Test set: Average loss: 1.7811, Accuracy: 3367/5000 (67%)\n",
      "[epoch 24] loss: 0.0000564\n",
      "Test set: Average loss: 1.8031, Accuracy: 3360/5000 (67%)\n",
      "[epoch 25] loss: 0.0000473\n",
      "Test set: Average loss: 1.8210, Accuracy: 3362/5000 (67%)\n",
      "[epoch 26] loss: 0.0000396\n",
      "Test set: Average loss: 1.8447, Accuracy: 3357/5000 (67%)\n",
      "[epoch 27] loss: 0.0000332\n",
      "Test set: Average loss: 1.8669, Accuracy: 3364/5000 (67%)\n",
      "[epoch 28] loss: 0.0000279\n",
      "Test set: Average loss: 1.8875, Accuracy: 3359/5000 (67%)\n",
      "[epoch 29] loss: 0.0000234\n",
      "Test set: Average loss: 1.9093, Accuracy: 3364/5000 (67%)\n",
      "[epoch 30] loss: 0.0000197\n",
      "Test set: Average loss: 1.9293, Accuracy: 3365/5000 (67%)\n",
      "[epoch 31] loss: 0.0000166\n",
      "Test set: Average loss: 1.9506, Accuracy: 3358/5000 (67%)\n",
      "[epoch 32] loss: 0.0000139\n",
      "Test set: Average loss: 1.9724, Accuracy: 3359/5000 (67%)\n",
      "[epoch 33] loss: 0.0000117\n",
      "Test set: Average loss: 1.9899, Accuracy: 3361/5000 (67%)\n",
      "[epoch 34] loss: 0.0000099\n",
      "Test set: Average loss: 2.0124, Accuracy: 3358/5000 (67%)\n",
      "[epoch 35] loss: 0.0000083\n",
      "Test set: Average loss: 2.0353, Accuracy: 3355/5000 (67%)\n",
      "[epoch 36] loss: 0.0000070\n",
      "Test set: Average loss: 2.0539, Accuracy: 3354/5000 (67%)\n",
      "[epoch 37] loss: 0.0000059\n",
      "Test set: Average loss: 2.0734, Accuracy: 3357/5000 (67%)\n",
      "[epoch 38] loss: 0.0000050\n",
      "Test set: Average loss: 2.0968, Accuracy: 3361/5000 (67%)\n",
      "[epoch 39] loss: 0.0000042\n",
      "Test set: Average loss: 2.1164, Accuracy: 3364/5000 (67%)\n",
      "[epoch 40] loss: 0.0000035\n",
      "Test set: Average loss: 2.1383, Accuracy: 3358/5000 (67%)\n",
      "[epoch 41] loss: 0.0000029\n",
      "Test set: Average loss: 2.1576, Accuracy: 3365/5000 (67%)\n",
      "[epoch 42] loss: 0.0000025\n",
      "Test set: Average loss: 2.1762, Accuracy: 3369/5000 (67%)\n",
      "[epoch 43] loss: 0.0000021\n",
      "Test set: Average loss: 2.1962, Accuracy: 3369/5000 (67%)\n",
      "[epoch 44] loss: 0.0000017\n",
      "Test set: Average loss: 2.2136, Accuracy: 3365/5000 (67%)\n",
      "[epoch 45] loss: 0.0000014\n",
      "Test set: Average loss: 2.2313, Accuracy: 3364/5000 (67%)\n",
      "[epoch 46] loss: 0.0000012\n",
      "Test set: Average loss: 2.2479, Accuracy: 3364/5000 (67%)\n",
      "[epoch 47] loss: 0.0000010\n",
      "Test set: Average loss: 2.2596, Accuracy: 3363/5000 (67%)\n",
      "[epoch 48] loss: 0.0000008\n",
      "Test set: Average loss: 2.2713, Accuracy: 3364/5000 (67%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 2.2812, Accuracy: 3358/5000 (67%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 2.2884, Accuracy: 3351/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5505, Accuracy: 3378/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.5279, Accuracy: 6820/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5382, Accuracy: 600/5000 (12%)\n",
      "[epoch 1] loss: 0.5694431\n",
      "Test set: Average loss: 1.0374, Accuracy: 3330/5000 (67%)\n",
      "[epoch 2] loss: 0.0995224\n",
      "Test set: Average loss: 1.1288, Accuracy: 3326/5000 (67%)\n",
      "[epoch 3] loss: 0.0217334\n",
      "Test set: Average loss: 1.2068, Accuracy: 3343/5000 (67%)\n",
      "[epoch 4] loss: 0.0081358\n",
      "Test set: Average loss: 1.2656, Accuracy: 3328/5000 (67%)\n",
      "[epoch 5] loss: 0.0046748\n",
      "Test set: Average loss: 1.3087, Accuracy: 3348/5000 (67%)\n",
      "[epoch 6] loss: 0.0031126\n",
      "Test set: Average loss: 1.3493, Accuracy: 3334/5000 (67%)\n",
      "[epoch 7] loss: 0.0022086\n",
      "Test set: Average loss: 1.3869, Accuracy: 3335/5000 (67%)\n",
      "[epoch 8] loss: 0.0016321\n",
      "Test set: Average loss: 1.4196, Accuracy: 3337/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 0.0012380\n",
      "Test set: Average loss: 1.4522, Accuracy: 3324/5000 (66%)\n",
      "[epoch 10] loss: 0.0009602\n",
      "Test set: Average loss: 1.4799, Accuracy: 3328/5000 (67%)\n",
      "[epoch 11] loss: 0.0007547\n",
      "Test set: Average loss: 1.5087, Accuracy: 3329/5000 (67%)\n",
      "[epoch 12] loss: 0.0006012\n",
      "Test set: Average loss: 1.5338, Accuracy: 3328/5000 (67%)\n",
      "[epoch 13] loss: 0.0004838\n",
      "Test set: Average loss: 1.5594, Accuracy: 3330/5000 (67%)\n",
      "[epoch 14] loss: 0.0003924\n",
      "Test set: Average loss: 1.5849, Accuracy: 3331/5000 (67%)\n",
      "[epoch 15] loss: 0.0003196\n",
      "Test set: Average loss: 1.6075, Accuracy: 3327/5000 (67%)\n",
      "[epoch 16] loss: 0.0002624\n",
      "Test set: Average loss: 1.6329, Accuracy: 3327/5000 (67%)\n",
      "[epoch 17] loss: 0.0002157\n",
      "Test set: Average loss: 1.6585, Accuracy: 3318/5000 (66%)\n",
      "[epoch 18] loss: 0.0001783\n",
      "Test set: Average loss: 1.6789, Accuracy: 3325/5000 (66%)\n",
      "[epoch 19] loss: 0.0001477\n",
      "Test set: Average loss: 1.7020, Accuracy: 3317/5000 (66%)\n",
      "[epoch 20] loss: 0.0001228\n",
      "Test set: Average loss: 1.7265, Accuracy: 3320/5000 (66%)\n",
      "[epoch 21] loss: 0.0001023\n",
      "Test set: Average loss: 1.7502, Accuracy: 3315/5000 (66%)\n",
      "[epoch 22] loss: 0.0000853\n",
      "Test set: Average loss: 1.7705, Accuracy: 3312/5000 (66%)\n",
      "[epoch 23] loss: 0.0000712\n",
      "Test set: Average loss: 1.7917, Accuracy: 3318/5000 (66%)\n",
      "[epoch 24] loss: 0.0000596\n",
      "Test set: Average loss: 1.8150, Accuracy: 3307/5000 (66%)\n",
      "[epoch 25] loss: 0.0000499\n",
      "Test set: Average loss: 1.8351, Accuracy: 3314/5000 (66%)\n",
      "[epoch 26] loss: 0.0000418\n",
      "Test set: Average loss: 1.8601, Accuracy: 3314/5000 (66%)\n",
      "[epoch 27] loss: 0.0000351\n",
      "Test set: Average loss: 1.8819, Accuracy: 3304/5000 (66%)\n",
      "[epoch 28] loss: 0.0000295\n",
      "Test set: Average loss: 1.9033, Accuracy: 3313/5000 (66%)\n",
      "[epoch 29] loss: 0.0000247\n",
      "Test set: Average loss: 1.9248, Accuracy: 3313/5000 (66%)\n",
      "[epoch 30] loss: 0.0000208\n",
      "Test set: Average loss: 1.9453, Accuracy: 3308/5000 (66%)\n",
      "[epoch 31] loss: 0.0000174\n",
      "Test set: Average loss: 1.9658, Accuracy: 3308/5000 (66%)\n",
      "[epoch 32] loss: 0.0000147\n",
      "Test set: Average loss: 1.9905, Accuracy: 3310/5000 (66%)\n",
      "[epoch 33] loss: 0.0000124\n",
      "Test set: Average loss: 2.0124, Accuracy: 3305/5000 (66%)\n",
      "[epoch 34] loss: 0.0000104\n",
      "Test set: Average loss: 2.0323, Accuracy: 3307/5000 (66%)\n",
      "[epoch 35] loss: 0.0000087\n",
      "Test set: Average loss: 2.0524, Accuracy: 3303/5000 (66%)\n",
      "[epoch 36] loss: 0.0000074\n",
      "Test set: Average loss: 2.0758, Accuracy: 3312/5000 (66%)\n",
      "[epoch 37] loss: 0.0000062\n",
      "Test set: Average loss: 2.0960, Accuracy: 3306/5000 (66%)\n",
      "[epoch 38] loss: 0.0000052\n",
      "Test set: Average loss: 2.1185, Accuracy: 3306/5000 (66%)\n",
      "[epoch 39] loss: 0.0000044\n",
      "Test set: Average loss: 2.1394, Accuracy: 3306/5000 (66%)\n",
      "[epoch 40] loss: 0.0000037\n",
      "Test set: Average loss: 2.1596, Accuracy: 3296/5000 (66%)\n",
      "[epoch 41] loss: 0.0000031\n",
      "Test set: Average loss: 2.1792, Accuracy: 3302/5000 (66%)\n",
      "[epoch 42] loss: 0.0000026\n",
      "Test set: Average loss: 2.1992, Accuracy: 3297/5000 (66%)\n",
      "[epoch 43] loss: 0.0000022\n",
      "Test set: Average loss: 2.2195, Accuracy: 3295/5000 (66%)\n",
      "[epoch 44] loss: 0.0000018\n",
      "Test set: Average loss: 2.2365, Accuracy: 3291/5000 (66%)\n",
      "[epoch 45] loss: 0.0000015\n",
      "Test set: Average loss: 2.2544, Accuracy: 3295/5000 (66%)\n",
      "[epoch 46] loss: 0.0000013\n",
      "Test set: Average loss: 2.2715, Accuracy: 3295/5000 (66%)\n",
      "[epoch 47] loss: 0.0000010\n",
      "Test set: Average loss: 2.2844, Accuracy: 3286/5000 (66%)\n",
      "[epoch 48] loss: 0.0000008\n",
      "Test set: Average loss: 2.2977, Accuracy: 3285/5000 (66%)\n",
      "[epoch 49] loss: 0.0000007\n",
      "Test set: Average loss: 2.3057, Accuracy: 3290/5000 (66%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 2.3140, Accuracy: 3287/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3087, Accuracy: 3348/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.2801, Accuracy: 6834/10000 (68%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5478, Accuracy: 345/5000 (7%)\n",
      "[epoch 1] loss: 0.4516664\n",
      "Test set: Average loss: 1.0810, Accuracy: 3296/5000 (66%)\n",
      "[epoch 2] loss: 0.0641161\n",
      "Test set: Average loss: 1.2145, Accuracy: 3345/5000 (67%)\n",
      "[epoch 3] loss: 0.0132333\n",
      "Test set: Average loss: 1.2822, Accuracy: 3369/5000 (67%)\n",
      "[epoch 4] loss: 0.0045870\n",
      "Test set: Average loss: 1.3503, Accuracy: 3399/5000 (68%)\n",
      "[epoch 5] loss: 0.0026136\n",
      "Test set: Average loss: 1.4025, Accuracy: 3394/5000 (68%)\n",
      "[epoch 6] loss: 0.0017127\n",
      "Test set: Average loss: 1.4473, Accuracy: 3389/5000 (68%)\n",
      "[epoch 7] loss: 0.0011830\n",
      "Test set: Average loss: 1.4898, Accuracy: 3383/5000 (68%)\n",
      "[epoch 8] loss: 0.0008428\n",
      "Test set: Average loss: 1.5316, Accuracy: 3387/5000 (68%)\n",
      "[epoch 9] loss: 0.0006135\n",
      "Test set: Average loss: 1.5724, Accuracy: 3391/5000 (68%)\n",
      "[epoch 10] loss: 0.0004516\n",
      "Test set: Average loss: 1.6077, Accuracy: 3385/5000 (68%)\n",
      "[epoch 11] loss: 0.0003365\n",
      "Test set: Average loss: 1.6478, Accuracy: 3385/5000 (68%)\n",
      "[epoch 12] loss: 0.0002535\n",
      "Test set: Average loss: 1.6835, Accuracy: 3389/5000 (68%)\n",
      "[epoch 13] loss: 0.0001916\n",
      "Test set: Average loss: 1.7227, Accuracy: 3381/5000 (68%)\n",
      "[epoch 14] loss: 0.0001459\n",
      "Test set: Average loss: 1.7525, Accuracy: 3383/5000 (68%)\n",
      "[epoch 15] loss: 0.0001111\n",
      "Test set: Average loss: 1.7898, Accuracy: 3379/5000 (68%)\n",
      "[epoch 16] loss: 0.0000851\n",
      "Test set: Average loss: 1.8236, Accuracy: 3383/5000 (68%)\n",
      "[epoch 17] loss: 0.0000654\n",
      "Test set: Average loss: 1.8632, Accuracy: 3377/5000 (68%)\n",
      "[epoch 18] loss: 0.0000502\n",
      "Test set: Average loss: 1.8955, Accuracy: 3382/5000 (68%)\n",
      "[epoch 19] loss: 0.0000387\n",
      "Test set: Average loss: 1.9289, Accuracy: 3378/5000 (68%)\n",
      "[epoch 20] loss: 0.0000299\n",
      "Test set: Average loss: 1.9673, Accuracy: 3367/5000 (67%)\n",
      "[epoch 21] loss: 0.0000230\n",
      "Test set: Average loss: 1.9963, Accuracy: 3376/5000 (68%)\n",
      "[epoch 22] loss: 0.0000178\n",
      "Test set: Average loss: 2.0310, Accuracy: 3377/5000 (68%)\n",
      "[epoch 23] loss: 0.0000137\n",
      "Test set: Average loss: 2.0656, Accuracy: 3372/5000 (67%)\n",
      "[epoch 24] loss: 0.0000106\n",
      "Test set: Average loss: 2.0972, Accuracy: 3377/5000 (68%)\n",
      "[epoch 25] loss: 0.0000082\n",
      "Test set: Average loss: 2.1296, Accuracy: 3366/5000 (67%)\n",
      "[epoch 26] loss: 0.0000063\n",
      "Test set: Average loss: 2.1648, Accuracy: 3371/5000 (67%)\n",
      "[epoch 27] loss: 0.0000049\n",
      "Test set: Average loss: 2.2023, Accuracy: 3360/5000 (67%)\n",
      "[epoch 28] loss: 0.0000038\n",
      "Test set: Average loss: 2.2316, Accuracy: 3363/5000 (67%)\n",
      "[epoch 29] loss: 0.0000029\n",
      "Test set: Average loss: 2.2622, Accuracy: 3360/5000 (67%)\n",
      "[epoch 30] loss: 0.0000022\n",
      "Test set: Average loss: 2.2932, Accuracy: 3356/5000 (67%)\n",
      "[epoch 31] loss: 0.0000017\n",
      "Test set: Average loss: 2.3229, Accuracy: 3358/5000 (67%)\n",
      "[epoch 32] loss: 0.0000013\n",
      "Test set: Average loss: 2.3523, Accuracy: 3355/5000 (67%)\n",
      "[epoch 33] loss: 0.0000010\n",
      "Test set: Average loss: 2.3716, Accuracy: 3356/5000 (67%)\n",
      "[epoch 34] loss: 0.0000007\n",
      "Test set: Average loss: 2.3918, Accuracy: 3358/5000 (67%)\n",
      "[epoch 35] loss: 0.0000005\n",
      "Test set: Average loss: 2.4093, Accuracy: 3349/5000 (67%)\n",
      "[epoch 36] loss: 0.0000004\n",
      "Test set: Average loss: 2.4128, Accuracy: 3340/5000 (67%)\n",
      "[epoch 37] loss: 0.0000003\n",
      "Test set: Average loss: 2.4184, Accuracy: 3346/5000 (67%)\n",
      "[epoch 38] loss: 0.0000002\n",
      "Test set: Average loss: 2.4197, Accuracy: 3345/5000 (67%)\n",
      "[epoch 39] loss: 0.0000002\n",
      "Test set: Average loss: 2.4153, Accuracy: 3339/5000 (67%)\n",
      "[epoch 40] loss: 0.0000002\n",
      "Test set: Average loss: 2.4203, Accuracy: 3327/5000 (67%)\n",
      "[epoch 41] loss: 0.0000002\n",
      "Test set: Average loss: 2.4185, Accuracy: 3334/5000 (67%)\n",
      "[epoch 42] loss: 0.0000002\n",
      "Test set: Average loss: 2.4268, Accuracy: 3329/5000 (67%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Test set: Average loss: 2.4396, Accuracy: 3346/5000 (67%)\n",
      "[epoch 44] loss: 0.0000001\n",
      "Test set: Average loss: 2.4452, Accuracy: 3320/5000 (66%)\n",
      "[epoch 45] loss: 0.0000001\n",
      "Test set: Average loss: 2.4694, Accuracy: 3328/5000 (67%)\n",
      "[epoch 46] loss: 0.2856273\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5545, Accuracy: 2573/5000 (51%)\n",
      "[epoch 47] loss: 1.0232988\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7478, Accuracy: 2968/5000 (59%)\n",
      "[epoch 48] loss: 0.5478297\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7164, Accuracy: 2998/5000 (60%)\n",
      "[epoch 49] loss: 0.5130992\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7152, Accuracy: 2997/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.5099953\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7151, Accuracy: 2997/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3503, Accuracy: 3399/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.3270, Accuracy: 6874/10000 (69%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5495, Accuracy: 391/5000 (8%)\n",
      "[epoch 1] loss: 0.4507175\n",
      "Test set: Average loss: 1.0698, Accuracy: 3335/5000 (67%)\n",
      "[epoch 2] loss: 0.0622353\n",
      "Test set: Average loss: 1.2032, Accuracy: 3347/5000 (67%)\n",
      "[epoch 3] loss: 0.0126972\n",
      "Test set: Average loss: 1.2914, Accuracy: 3360/5000 (67%)\n",
      "[epoch 4] loss: 0.0044759\n",
      "Test set: Average loss: 1.3543, Accuracy: 3357/5000 (67%)\n",
      "[epoch 5] loss: 0.0025621\n",
      "Test set: Average loss: 1.4090, Accuracy: 3357/5000 (67%)\n",
      "[epoch 6] loss: 0.0016838\n",
      "Test set: Average loss: 1.4587, Accuracy: 3359/5000 (67%)\n",
      "[epoch 7] loss: 0.0011606\n",
      "Test set: Average loss: 1.4963, Accuracy: 3359/5000 (67%)\n",
      "[epoch 8] loss: 0.0008273\n",
      "Test set: Average loss: 1.5393, Accuracy: 3359/5000 (67%)\n",
      "[epoch 9] loss: 0.0006020\n",
      "Test set: Average loss: 1.5839, Accuracy: 3350/5000 (67%)\n",
      "[epoch 10] loss: 0.0004442\n",
      "Test set: Average loss: 1.6192, Accuracy: 3348/5000 (67%)\n",
      "[epoch 11] loss: 0.0003310\n",
      "Test set: Average loss: 1.6589, Accuracy: 3352/5000 (67%)\n",
      "[epoch 12] loss: 0.0002497\n",
      "Test set: Average loss: 1.6927, Accuracy: 3349/5000 (67%)\n",
      "[epoch 13] loss: 0.0001889\n",
      "Test set: Average loss: 1.7305, Accuracy: 3350/5000 (67%)\n",
      "[epoch 14] loss: 0.0001437\n",
      "Test set: Average loss: 1.7613, Accuracy: 3345/5000 (67%)\n",
      "[epoch 15] loss: 0.0001098\n",
      "Test set: Average loss: 1.8019, Accuracy: 3357/5000 (67%)\n",
      "[epoch 16] loss: 0.0000840\n",
      "Test set: Average loss: 1.8380, Accuracy: 3351/5000 (67%)\n",
      "[epoch 17] loss: 0.0000645\n",
      "Test set: Average loss: 1.8698, Accuracy: 3351/5000 (67%)\n",
      "[epoch 18] loss: 0.0000496\n",
      "Test set: Average loss: 1.9065, Accuracy: 3338/5000 (67%)\n",
      "[epoch 19] loss: 0.0000382\n",
      "Test set: Average loss: 1.9427, Accuracy: 3342/5000 (67%)\n",
      "[epoch 20] loss: 0.0000295\n",
      "Test set: Average loss: 1.9750, Accuracy: 3349/5000 (67%)\n",
      "[epoch 21] loss: 0.0000227\n",
      "Test set: Average loss: 2.0102, Accuracy: 3345/5000 (67%)\n",
      "[epoch 22] loss: 0.0000175\n",
      "Test set: Average loss: 2.0451, Accuracy: 3347/5000 (67%)\n",
      "[epoch 23] loss: 0.0000135\n",
      "Test set: Average loss: 2.0773, Accuracy: 3348/5000 (67%)\n",
      "[epoch 24] loss: 0.0000105\n",
      "Test set: Average loss: 2.1152, Accuracy: 3343/5000 (67%)\n",
      "[epoch 25] loss: 0.0000081\n",
      "Test set: Average loss: 2.1480, Accuracy: 3341/5000 (67%)\n",
      "[epoch 26] loss: 0.0000062\n",
      "Test set: Average loss: 2.1825, Accuracy: 3352/5000 (67%)\n",
      "[epoch 27] loss: 0.0000048\n",
      "Test set: Average loss: 2.2151, Accuracy: 3338/5000 (67%)\n",
      "[epoch 28] loss: 0.0000037\n",
      "Test set: Average loss: 2.2479, Accuracy: 3340/5000 (67%)\n",
      "[epoch 29] loss: 0.0000029\n",
      "Test set: Average loss: 2.2819, Accuracy: 3334/5000 (67%)\n",
      "[epoch 30] loss: 0.0000022\n",
      "Test set: Average loss: 2.3138, Accuracy: 3334/5000 (67%)\n",
      "[epoch 31] loss: 0.0000017\n",
      "Test set: Average loss: 2.3440, Accuracy: 3343/5000 (67%)\n",
      "[epoch 32] loss: 0.0000013\n",
      "Test set: Average loss: 2.3713, Accuracy: 3334/5000 (67%)\n",
      "[epoch 33] loss: 0.0000010\n",
      "Test set: Average loss: 2.3968, Accuracy: 3341/5000 (67%)\n",
      "[epoch 34] loss: 0.0000007\n",
      "Test set: Average loss: 2.4147, Accuracy: 3330/5000 (67%)\n",
      "[epoch 35] loss: 0.0000005\n",
      "Test set: Average loss: 2.4258, Accuracy: 3332/5000 (67%)\n",
      "[epoch 36] loss: 0.0000004\n",
      "Test set: Average loss: 2.4328, Accuracy: 3333/5000 (67%)\n",
      "[epoch 37] loss: 0.0000003\n",
      "Test set: Average loss: 2.4380, Accuracy: 3334/5000 (67%)\n",
      "[epoch 38] loss: 0.0000002\n",
      "Test set: Average loss: 2.4393, Accuracy: 3330/5000 (67%)\n",
      "[epoch 39] loss: 0.0000002\n",
      "Test set: Average loss: 2.4415, Accuracy: 3345/5000 (67%)\n",
      "[epoch 40] loss: 0.0000002\n",
      "Test set: Average loss: 2.4409, Accuracy: 3330/5000 (67%)\n",
      "[epoch 41] loss: 0.0000002\n",
      "Test set: Average loss: 2.4520, Accuracy: 3326/5000 (67%)\n",
      "[epoch 42] loss: 0.0000001\n",
      "Test set: Average loss: 2.4523, Accuracy: 3304/5000 (66%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Test set: Average loss: 2.4651, Accuracy: 3326/5000 (67%)\n",
      "[epoch 44] loss: 0.0000001\n",
      "Test set: Average loss: 2.4704, Accuracy: 3319/5000 (66%)\n",
      "[epoch 45] loss: 0.0000001\n",
      "Test set: Average loss: 2.4883, Accuracy: 3308/5000 (66%)\n",
      "[epoch 46] loss: 0.1345131\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.8343, Accuracy: 2203/5000 (44%)\n",
      "[epoch 47] loss: 1.0946928\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9134, Accuracy: 3024/5000 (60%)\n",
      "[epoch 48] loss: 0.4405791\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8958, Accuracy: 3043/5000 (61%)\n",
      "[epoch 49] loss: 0.4045981\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8945, Accuracy: 3042/5000 (61%)\n",
      "[epoch 50] loss: 0.4015650\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8944, Accuracy: 3042/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2914, Accuracy: 3360/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.2719, Accuracy: 6839/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4516, Accuracy: 478/5000 (10%)\n",
      "[epoch 1] loss: 0.4474839\n",
      "Test set: Average loss: 1.0960, Accuracy: 3304/5000 (66%)\n",
      "[epoch 2] loss: 0.0626605\n",
      "Test set: Average loss: 1.2304, Accuracy: 3328/5000 (67%)\n",
      "[epoch 3] loss: 0.0155420\n",
      "Test set: Average loss: 1.3051, Accuracy: 3363/5000 (67%)\n",
      "[epoch 4] loss: 0.0044863\n",
      "Test set: Average loss: 1.3721, Accuracy: 3377/5000 (68%)\n",
      "[epoch 5] loss: 0.0025506\n",
      "Test set: Average loss: 1.4256, Accuracy: 3372/5000 (67%)\n",
      "[epoch 6] loss: 0.0016747\n",
      "Test set: Average loss: 1.4738, Accuracy: 3378/5000 (68%)\n",
      "[epoch 7] loss: 0.0011587\n",
      "Test set: Average loss: 1.5163, Accuracy: 3368/5000 (67%)\n",
      "[epoch 8] loss: 0.0008272\n",
      "Test set: Average loss: 1.5577, Accuracy: 3372/5000 (67%)\n",
      "[epoch 9] loss: 0.0006021\n",
      "Test set: Average loss: 1.5959, Accuracy: 3368/5000 (67%)\n",
      "[epoch 10] loss: 0.0004453\n",
      "Test set: Average loss: 1.6349, Accuracy: 3372/5000 (67%)\n",
      "[epoch 11] loss: 0.0003323\n",
      "Test set: Average loss: 1.6735, Accuracy: 3371/5000 (67%)\n",
      "[epoch 12] loss: 0.0002503\n",
      "Test set: Average loss: 1.7095, Accuracy: 3382/5000 (68%)\n",
      "[epoch 13] loss: 0.0001899\n",
      "Test set: Average loss: 1.7468, Accuracy: 3375/5000 (68%)\n",
      "[epoch 14] loss: 0.0001445\n",
      "Test set: Average loss: 1.7821, Accuracy: 3361/5000 (67%)\n",
      "[epoch 15] loss: 0.0001103\n",
      "Test set: Average loss: 1.8169, Accuracy: 3374/5000 (67%)\n",
      "[epoch 16] loss: 0.0000846\n",
      "Test set: Average loss: 1.8518, Accuracy: 3366/5000 (67%)\n",
      "[epoch 17] loss: 0.0000650\n",
      "Test set: Average loss: 1.8861, Accuracy: 3365/5000 (67%)\n",
      "[epoch 18] loss: 0.0000499\n",
      "Test set: Average loss: 1.9227, Accuracy: 3360/5000 (67%)\n",
      "[epoch 19] loss: 0.0000384\n",
      "Test set: Average loss: 1.9585, Accuracy: 3366/5000 (67%)\n",
      "[epoch 20] loss: 0.0000296\n",
      "Test set: Average loss: 1.9921, Accuracy: 3356/5000 (67%)\n",
      "[epoch 21] loss: 0.0000229\n",
      "Test set: Average loss: 2.0286, Accuracy: 3364/5000 (67%)\n",
      "[epoch 22] loss: 0.0000177\n",
      "Test set: Average loss: 2.0603, Accuracy: 3357/5000 (67%)\n",
      "[epoch 23] loss: 0.0000137\n",
      "Test set: Average loss: 2.0969, Accuracy: 3363/5000 (67%)\n",
      "[epoch 24] loss: 0.0000106\n",
      "Test set: Average loss: 2.1304, Accuracy: 3358/5000 (67%)\n",
      "[epoch 25] loss: 0.0000082\n",
      "Test set: Average loss: 2.1635, Accuracy: 3355/5000 (67%)\n",
      "[epoch 26] loss: 0.0000063\n",
      "Test set: Average loss: 2.1977, Accuracy: 3347/5000 (67%)\n",
      "[epoch 27] loss: 0.0000049\n",
      "Test set: Average loss: 2.2318, Accuracy: 3348/5000 (67%)\n",
      "[epoch 28] loss: 0.0000038\n",
      "Test set: Average loss: 2.2627, Accuracy: 3356/5000 (67%)\n",
      "[epoch 29] loss: 0.0000029\n",
      "Test set: Average loss: 2.2991, Accuracy: 3342/5000 (67%)\n",
      "[epoch 30] loss: 0.0000022\n",
      "Test set: Average loss: 2.3303, Accuracy: 3333/5000 (67%)\n",
      "[epoch 31] loss: 0.0000017\n",
      "Test set: Average loss: 2.3598, Accuracy: 3334/5000 (67%)\n",
      "[epoch 32] loss: 0.0000013\n",
      "Test set: Average loss: 2.3879, Accuracy: 3332/5000 (67%)\n",
      "[epoch 33] loss: 0.0000010\n",
      "Test set: Average loss: 2.4142, Accuracy: 3327/5000 (67%)\n",
      "[epoch 34] loss: 0.0000007\n",
      "Test set: Average loss: 2.4300, Accuracy: 3326/5000 (67%)\n",
      "[epoch 35] loss: 0.0000005\n",
      "Test set: Average loss: 2.4443, Accuracy: 3327/5000 (67%)\n",
      "[epoch 36] loss: 0.0000004\n",
      "Test set: Average loss: 2.4588, Accuracy: 3323/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] loss: 0.0000003\n",
      "Test set: Average loss: 2.4562, Accuracy: 3327/5000 (67%)\n",
      "[epoch 38] loss: 0.0000002\n",
      "Test set: Average loss: 2.4587, Accuracy: 3318/5000 (66%)\n",
      "[epoch 39] loss: 0.0000002\n",
      "Test set: Average loss: 2.4919, Accuracy: 3309/5000 (66%)\n",
      "[epoch 40] loss: 0.0000002\n",
      "Test set: Average loss: 2.4609, Accuracy: 3325/5000 (66%)\n",
      "[epoch 41] loss: 0.0000002\n",
      "Test set: Average loss: 2.4601, Accuracy: 3315/5000 (66%)\n",
      "[epoch 42] loss: 0.0000002\n",
      "Test set: Average loss: 2.4717, Accuracy: 3305/5000 (66%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Test set: Average loss: 2.4812, Accuracy: 3309/5000 (66%)\n",
      "[epoch 44] loss: 0.0000001\n",
      "Test set: Average loss: 2.4859, Accuracy: 3326/5000 (67%)\n",
      "[epoch 45] loss: 0.0000001\n",
      "Test set: Average loss: 2.5069, Accuracy: 3309/5000 (66%)\n",
      "[epoch 46] loss: 0.4887257\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7967, Accuracy: 2790/5000 (56%)\n",
      "[epoch 47] loss: 0.7763953\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.4139, Accuracy: 3002/5000 (60%)\n",
      "[epoch 48] loss: 0.5073469\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.4084, Accuracy: 3033/5000 (61%)\n",
      "[epoch 49] loss: 0.4850621\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.4082, Accuracy: 3034/5000 (61%)\n",
      "[epoch 50] loss: 0.4829563\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.4081, Accuracy: 3035/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7095, Accuracy: 3382/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.6743, Accuracy: 6802/10000 (68%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2995, Accuracy: 754/5000 (15%)\n",
      "[epoch 1] loss: 0.3658543\n",
      "Test set: Average loss: 1.1158, Accuracy: 3357/5000 (67%)\n",
      "[epoch 2] loss: 0.0489856\n",
      "Test set: Average loss: 1.3050, Accuracy: 3323/5000 (66%)\n",
      "[epoch 3] loss: 0.0137304\n",
      "Test set: Average loss: 1.3967, Accuracy: 3350/5000 (67%)\n",
      "[epoch 4] loss: 0.0031701\n",
      "Test set: Average loss: 1.4643, Accuracy: 3364/5000 (67%)\n",
      "[epoch 5] loss: 0.0015910\n",
      "Test set: Average loss: 1.5188, Accuracy: 3380/5000 (68%)\n",
      "[epoch 6] loss: 0.0010116\n",
      "Test set: Average loss: 1.5705, Accuracy: 3368/5000 (67%)\n",
      "[epoch 7] loss: 0.0006791\n",
      "Test set: Average loss: 1.6185, Accuracy: 3369/5000 (67%)\n",
      "[epoch 8] loss: 0.0004667\n",
      "Test set: Average loss: 1.6668, Accuracy: 3373/5000 (67%)\n",
      "[epoch 9] loss: 0.0003256\n",
      "Test set: Average loss: 1.7138, Accuracy: 3374/5000 (67%)\n",
      "[epoch 10] loss: 0.0002278\n",
      "Test set: Average loss: 1.7575, Accuracy: 3369/5000 (67%)\n",
      "[epoch 11] loss: 0.0001603\n",
      "Test set: Average loss: 1.8075, Accuracy: 3371/5000 (67%)\n",
      "[epoch 12] loss: 0.0001134\n",
      "Test set: Average loss: 1.8522, Accuracy: 3372/5000 (67%)\n",
      "[epoch 13] loss: 0.0000803\n",
      "Test set: Average loss: 1.8981, Accuracy: 3362/5000 (67%)\n",
      "[epoch 14] loss: 0.0000570\n",
      "Test set: Average loss: 1.9492, Accuracy: 3368/5000 (67%)\n",
      "[epoch 15] loss: 0.0000405\n",
      "Test set: Average loss: 1.9959, Accuracy: 3366/5000 (67%)\n",
      "[epoch 16] loss: 0.0000288\n",
      "Test set: Average loss: 2.0404, Accuracy: 3357/5000 (67%)\n",
      "[epoch 17] loss: 0.0000205\n",
      "Test set: Average loss: 2.0879, Accuracy: 3366/5000 (67%)\n",
      "[epoch 18] loss: 0.0000146\n",
      "Test set: Average loss: 2.1334, Accuracy: 3357/5000 (67%)\n",
      "[epoch 19] loss: 0.0000104\n",
      "Test set: Average loss: 2.1774, Accuracy: 3359/5000 (67%)\n",
      "[epoch 20] loss: 0.0000074\n",
      "Test set: Average loss: 2.2245, Accuracy: 3364/5000 (67%)\n",
      "[epoch 21] loss: 0.0000052\n",
      "Test set: Average loss: 2.2722, Accuracy: 3359/5000 (67%)\n",
      "[epoch 22] loss: 0.0000037\n",
      "Test set: Average loss: 2.3180, Accuracy: 3359/5000 (67%)\n",
      "[epoch 23] loss: 0.0000026\n",
      "Test set: Average loss: 2.3671, Accuracy: 3352/5000 (67%)\n",
      "[epoch 24] loss: 0.0000019\n",
      "Test set: Average loss: 2.4029, Accuracy: 3356/5000 (67%)\n",
      "[epoch 25] loss: 0.0000013\n",
      "Test set: Average loss: 2.4473, Accuracy: 3353/5000 (67%)\n",
      "[epoch 26] loss: 0.0000009\n",
      "Test set: Average loss: 2.4760, Accuracy: 3346/5000 (67%)\n",
      "[epoch 27] loss: 0.0000006\n",
      "Test set: Average loss: 2.5027, Accuracy: 3354/5000 (67%)\n",
      "[epoch 28] loss: 0.0000004\n",
      "Test set: Average loss: 2.5187, Accuracy: 3342/5000 (67%)\n",
      "[epoch 29] loss: 0.0000003\n",
      "Test set: Average loss: 2.5264, Accuracy: 3344/5000 (67%)\n",
      "[epoch 30] loss: 0.0000002\n",
      "Test set: Average loss: 2.5299, Accuracy: 3334/5000 (67%)\n",
      "[epoch 31] loss: 0.0000002\n",
      "Test set: Average loss: 2.5284, Accuracy: 3336/5000 (67%)\n",
      "[epoch 32] loss: 0.0000002\n",
      "Test set: Average loss: 2.5534, Accuracy: 3324/5000 (66%)\n",
      "[epoch 33] loss: 0.0000002\n",
      "Test set: Average loss: 2.5755, Accuracy: 3314/5000 (66%)\n",
      "[epoch 34] loss: 0.6378706\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.3759, Accuracy: 2857/5000 (57%)\n",
      "[epoch 35] loss: 0.7199461\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.1785, Accuracy: 3101/5000 (62%)\n",
      "[epoch 36] loss: 0.5600442\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.1805, Accuracy: 3105/5000 (62%)\n",
      "[epoch 37] loss: 0.5439153\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.1807, Accuracy: 3101/5000 (62%)\n",
      "[epoch 38] loss: 0.5423655\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 39] loss: 0.5422126\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 40] loss: 0.5422051\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 41] loss: 0.5422050\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 42] loss: 0.5422050\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 43] loss: 0.5422050\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 44] loss: 0.5422050\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 45] loss: 0.5422050\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 46] loss: 0.5422050\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 47] loss: 0.5422050\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 48] loss: 0.5422050\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 49] loss: 0.5422050\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "[epoch 50] loss: 0.5422050\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.1808, Accuracy: 3101/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5188, Accuracy: 3380/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.5133, Accuracy: 6792/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3483, Accuracy: 630/5000 (13%)\n",
      "[epoch 1] loss: 0.3789557\n",
      "Test set: Average loss: 1.1111, Accuracy: 3344/5000 (67%)\n",
      "[epoch 2] loss: 0.0643108\n",
      "Test set: Average loss: 1.3540, Accuracy: 3289/5000 (66%)\n",
      "[epoch 3] loss: 0.0678812\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5121, Accuracy: 3218/5000 (64%)\n",
      "[epoch 4] loss: 0.0395605\n",
      "Test set: Average loss: 1.4498, Accuracy: 3300/5000 (66%)\n",
      "[epoch 5] loss: 0.0111302\n",
      "Test set: Average loss: 1.4551, Accuracy: 3319/5000 (66%)\n",
      "[epoch 6] loss: 0.0075671\n",
      "Test set: Average loss: 1.4701, Accuracy: 3321/5000 (66%)\n",
      "[epoch 7] loss: 0.0056558\n",
      "Test set: Average loss: 1.4854, Accuracy: 3337/5000 (67%)\n",
      "[epoch 8] loss: 0.0043555\n",
      "Test set: Average loss: 1.5072, Accuracy: 3338/5000 (67%)\n",
      "[epoch 9] loss: 0.0033860\n",
      "Test set: Average loss: 1.5267, Accuracy: 3346/5000 (67%)\n",
      "[epoch 10] loss: 0.0026422\n",
      "Test set: Average loss: 1.5524, Accuracy: 3346/5000 (67%)\n",
      "[epoch 11] loss: 0.0020596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.5788, Accuracy: 3349/5000 (67%)\n",
      "[epoch 12] loss: 0.0015942\n",
      "Test set: Average loss: 1.6096, Accuracy: 3347/5000 (67%)\n",
      "[epoch 13] loss: 0.0012280\n",
      "Test set: Average loss: 1.6384, Accuracy: 3352/5000 (67%)\n",
      "[epoch 14] loss: 0.0009400\n",
      "Test set: Average loss: 1.6716, Accuracy: 3353/5000 (67%)\n",
      "[epoch 15] loss: 0.0007141\n",
      "Test set: Average loss: 1.7060, Accuracy: 3354/5000 (67%)\n",
      "[epoch 16] loss: 0.0005399\n",
      "Test set: Average loss: 1.7405, Accuracy: 3359/5000 (67%)\n",
      "[epoch 17] loss: 0.0004057\n",
      "Test set: Average loss: 1.7790, Accuracy: 3360/5000 (67%)\n",
      "[epoch 18] loss: 0.0003032\n",
      "Test set: Average loss: 1.8190, Accuracy: 3360/5000 (67%)\n",
      "[epoch 19] loss: 0.0002258\n",
      "Test set: Average loss: 1.8576, Accuracy: 3356/5000 (67%)\n",
      "[epoch 20] loss: 0.0001675\n",
      "Test set: Average loss: 1.8947, Accuracy: 3357/5000 (67%)\n",
      "[epoch 21] loss: 0.0001239\n",
      "Test set: Average loss: 1.9368, Accuracy: 3360/5000 (67%)\n",
      "[epoch 22] loss: 0.0000914\n",
      "Test set: Average loss: 1.9785, Accuracy: 3349/5000 (67%)\n",
      "[epoch 23] loss: 0.0000673\n",
      "Test set: Average loss: 2.0218, Accuracy: 3349/5000 (67%)\n",
      "[epoch 24] loss: 0.0000493\n",
      "Test set: Average loss: 2.0662, Accuracy: 3355/5000 (67%)\n",
      "[epoch 25] loss: 0.0000362\n",
      "Test set: Average loss: 2.1098, Accuracy: 3352/5000 (67%)\n",
      "[epoch 26] loss: 0.0000266\n",
      "Test set: Average loss: 2.1502, Accuracy: 3349/5000 (67%)\n",
      "[epoch 27] loss: 0.0000194\n",
      "Test set: Average loss: 2.1963, Accuracy: 3340/5000 (67%)\n",
      "[epoch 28] loss: 0.0000142\n",
      "Test set: Average loss: 2.2388, Accuracy: 3348/5000 (67%)\n",
      "[epoch 29] loss: 0.0000104\n",
      "Test set: Average loss: 2.2856, Accuracy: 3343/5000 (67%)\n",
      "[epoch 30] loss: 0.0000076\n",
      "Test set: Average loss: 2.3294, Accuracy: 3344/5000 (67%)\n",
      "[epoch 31] loss: 0.0000055\n",
      "Test set: Average loss: 2.3657, Accuracy: 3347/5000 (67%)\n",
      "[epoch 32] loss: 0.0000040\n",
      "Test set: Average loss: 2.4180, Accuracy: 3334/5000 (67%)\n",
      "[epoch 33] loss: 0.0000029\n",
      "Test set: Average loss: 2.4602, Accuracy: 3336/5000 (67%)\n",
      "[epoch 34] loss: 0.0000021\n",
      "Test set: Average loss: 2.4995, Accuracy: 3338/5000 (67%)\n",
      "[epoch 35] loss: 0.0000015\n",
      "Test set: Average loss: 2.5401, Accuracy: 3331/5000 (67%)\n",
      "[epoch 36] loss: 0.0000011\n",
      "Test set: Average loss: 2.5754, Accuracy: 3332/5000 (67%)\n",
      "[epoch 37] loss: 0.0000008\n",
      "Test set: Average loss: 2.6070, Accuracy: 3324/5000 (66%)\n",
      "[epoch 38] loss: 0.0000005\n",
      "Test set: Average loss: 2.6307, Accuracy: 3327/5000 (67%)\n",
      "[epoch 39] loss: 0.0000004\n",
      "Test set: Average loss: 2.6428, Accuracy: 3330/5000 (67%)\n",
      "[epoch 40] loss: 0.0000003\n",
      "Test set: Average loss: 2.6485, Accuracy: 3333/5000 (67%)\n",
      "[epoch 41] loss: 0.0000002\n",
      "Test set: Average loss: 2.6536, Accuracy: 3320/5000 (66%)\n",
      "[epoch 42] loss: 0.0000002\n",
      "Test set: Average loss: 2.6556, Accuracy: 3322/5000 (66%)\n",
      "[epoch 43] loss: 0.0000002\n",
      "Test set: Average loss: 2.6624, Accuracy: 3319/5000 (66%)\n",
      "[epoch 44] loss: 0.0000002\n",
      "Test set: Average loss: 2.6661, Accuracy: 3314/5000 (66%)\n",
      "[epoch 45] loss: 0.0000001\n",
      "Test set: Average loss: 2.6799, Accuracy: 3318/5000 (66%)\n",
      "[epoch 46] loss: 0.0000001\n",
      "Test set: Average loss: 2.6864, Accuracy: 3316/5000 (66%)\n",
      "[epoch 47] loss: 0.0000001\n",
      "Test set: Average loss: 2.6918, Accuracy: 3310/5000 (66%)\n",
      "[epoch 48] loss: 0.0000001\n",
      "Test set: Average loss: 2.7003, Accuracy: 3310/5000 (66%)\n",
      "[epoch 49] loss: 0.0000001\n",
      "Test set: Average loss: 2.7166, Accuracy: 3301/5000 (66%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 2.7272, Accuracy: 3311/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9368, Accuracy: 3360/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.9063, Accuracy: 6793/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4774, Accuracy: 469/5000 (9%)\n",
      "[epoch 1] loss: 0.3949728\n",
      "Test set: Average loss: 1.1253, Accuracy: 3327/5000 (67%)\n",
      "[epoch 2] loss: 0.0612418\n",
      "Test set: Average loss: 1.3707, Accuracy: 3268/5000 (65%)\n",
      "[epoch 3] loss: 0.0248468\n",
      "Test set: Average loss: 1.4212, Accuracy: 3347/5000 (67%)\n",
      "[epoch 4] loss: 0.0042509\n",
      "Test set: Average loss: 1.5043, Accuracy: 3345/5000 (67%)\n",
      "[epoch 5] loss: 0.0016752\n",
      "Test set: Average loss: 1.5551, Accuracy: 3340/5000 (67%)\n",
      "[epoch 6] loss: 0.0010471\n",
      "Test set: Average loss: 1.6059, Accuracy: 3345/5000 (67%)\n",
      "[epoch 7] loss: 0.0007114\n",
      "Test set: Average loss: 1.6533, Accuracy: 3349/5000 (67%)\n",
      "[epoch 8] loss: 0.0004953\n",
      "Test set: Average loss: 1.6999, Accuracy: 3343/5000 (67%)\n",
      "[epoch 9] loss: 0.0003486\n",
      "Test set: Average loss: 1.7446, Accuracy: 3342/5000 (67%)\n",
      "[epoch 10] loss: 0.0002460\n",
      "Test set: Average loss: 1.7953, Accuracy: 3350/5000 (67%)\n",
      "[epoch 11] loss: 0.0001749\n",
      "Test set: Average loss: 1.8410, Accuracy: 3350/5000 (67%)\n",
      "[epoch 12] loss: 0.0001244\n",
      "Test set: Average loss: 1.8858, Accuracy: 3352/5000 (67%)\n",
      "[epoch 13] loss: 0.0000884\n",
      "Test set: Average loss: 1.9337, Accuracy: 3351/5000 (67%)\n",
      "[epoch 14] loss: 0.0000631\n",
      "Test set: Average loss: 1.9797, Accuracy: 3339/5000 (67%)\n",
      "[epoch 15] loss: 0.0000450\n",
      "Test set: Average loss: 2.0223, Accuracy: 3342/5000 (67%)\n",
      "[epoch 16] loss: 0.0000321\n",
      "Test set: Average loss: 2.0730, Accuracy: 3347/5000 (67%)\n",
      "[epoch 17] loss: 0.0000229\n",
      "Test set: Average loss: 2.1212, Accuracy: 3337/5000 (67%)\n",
      "[epoch 18] loss: 0.0000163\n",
      "Test set: Average loss: 2.1662, Accuracy: 3355/5000 (67%)\n",
      "[epoch 19] loss: 0.0000116\n",
      "Test set: Average loss: 2.2114, Accuracy: 3351/5000 (67%)\n",
      "[epoch 20] loss: 0.0000083\n",
      "Test set: Average loss: 2.2570, Accuracy: 3345/5000 (67%)\n",
      "[epoch 21] loss: 0.0000059\n",
      "Test set: Average loss: 2.3076, Accuracy: 3343/5000 (67%)\n",
      "[epoch 22] loss: 0.0000042\n",
      "Test set: Average loss: 2.3523, Accuracy: 3339/5000 (67%)\n",
      "[epoch 23] loss: 0.0000030\n",
      "Test set: Average loss: 2.4032, Accuracy: 3335/5000 (67%)\n",
      "[epoch 24] loss: 0.0000021\n",
      "Test set: Average loss: 2.4382, Accuracy: 3345/5000 (67%)\n",
      "[epoch 25] loss: 0.0000015\n",
      "Test set: Average loss: 2.4817, Accuracy: 3342/5000 (67%)\n",
      "[epoch 26] loss: 0.0000010\n",
      "Test set: Average loss: 2.5172, Accuracy: 3338/5000 (67%)\n",
      "[epoch 27] loss: 0.0000007\n",
      "Test set: Average loss: 2.5426, Accuracy: 3334/5000 (67%)\n",
      "[epoch 28] loss: 0.0000005\n",
      "Test set: Average loss: 2.5624, Accuracy: 3337/5000 (67%)\n",
      "[epoch 29] loss: 0.0000003\n",
      "Test set: Average loss: 2.5682, Accuracy: 3342/5000 (67%)\n",
      "[epoch 30] loss: 0.0000002\n",
      "Test set: Average loss: 2.5727, Accuracy: 3347/5000 (67%)\n",
      "[epoch 31] loss: 0.0000002\n",
      "Test set: Average loss: 2.5744, Accuracy: 3334/5000 (67%)\n",
      "[epoch 32] loss: 0.0000002\n",
      "Test set: Average loss: 2.5863, Accuracy: 3325/5000 (66%)\n",
      "[epoch 33] loss: 0.0000002\n",
      "Test set: Average loss: 2.5978, Accuracy: 3343/5000 (67%)\n",
      "[epoch 34] loss: 0.2692085\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9593, Accuracy: 2614/5000 (52%)\n",
      "[epoch 35] loss: 0.9526362\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.3560, Accuracy: 3003/5000 (60%)\n",
      "[epoch 36] loss: 0.6545252\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.3466, Accuracy: 3015/5000 (60%)\n",
      "[epoch 37] loss: 0.6302413\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 38] loss: 0.6280562\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 39] loss: 0.6278442\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 40] loss: 0.6278336\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 41] loss: 0.6278334\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 42] loss: 0.6278334\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 43] loss: 0.6278334\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 44] loss: 0.6278334\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 45] loss: 0.6278334\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 46] loss: 0.6278334\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 47] loss: 0.6278334\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 48] loss: 0.6278334\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 49] loss: 0.6278334\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "[epoch 50] loss: 0.6278334\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.3461, Accuracy: 3018/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1662, Accuracy: 3355/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.1233, Accuracy: 6780/10000 (68%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3672, Accuracy: 602/5000 (12%)\n",
      "[epoch 1] loss: 0.3324539\n",
      "Test set: Average loss: 1.1919, Accuracy: 3302/5000 (66%)\n",
      "[epoch 2] loss: 0.0747347\n",
      "Test set: Average loss: 1.4500, Accuracy: 3239/5000 (65%)\n",
      "[epoch 3] loss: 0.1323198\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5117, Accuracy: 3287/5000 (66%)\n",
      "[epoch 4] loss: 0.0387508\n",
      "Test set: Average loss: 1.4789, Accuracy: 3334/5000 (67%)\n",
      "[epoch 5] loss: 0.0136013\n",
      "Test set: Average loss: 1.5038, Accuracy: 3339/5000 (67%)\n",
      "[epoch 6] loss: 0.0087495\n",
      "Test set: Average loss: 1.5256, Accuracy: 3338/5000 (67%)\n",
      "[epoch 7] loss: 0.0062851\n",
      "Test set: Average loss: 1.5503, Accuracy: 3335/5000 (67%)\n",
      "[epoch 8] loss: 0.0046299\n",
      "Test set: Average loss: 1.5786, Accuracy: 3339/5000 (67%)\n",
      "[epoch 9] loss: 0.0034252\n",
      "Test set: Average loss: 1.6111, Accuracy: 3342/5000 (67%)\n",
      "[epoch 10] loss: 0.0025217\n",
      "Test set: Average loss: 1.6436, Accuracy: 3351/5000 (67%)\n",
      "[epoch 11] loss: 0.0018441\n",
      "Test set: Average loss: 1.6787, Accuracy: 3353/5000 (67%)\n",
      "[epoch 12] loss: 0.0013352\n",
      "Test set: Average loss: 1.7209, Accuracy: 3356/5000 (67%)\n",
      "[epoch 13] loss: 0.0009597\n",
      "Test set: Average loss: 1.7611, Accuracy: 3351/5000 (67%)\n",
      "[epoch 14] loss: 0.0006820\n",
      "Test set: Average loss: 1.8049, Accuracy: 3344/5000 (67%)\n",
      "[epoch 15] loss: 0.0004806\n",
      "Test set: Average loss: 1.8531, Accuracy: 3352/5000 (67%)\n",
      "[epoch 16] loss: 0.0003357\n",
      "Test set: Average loss: 1.9032, Accuracy: 3349/5000 (67%)\n",
      "[epoch 17] loss: 0.0002343\n",
      "Test set: Average loss: 1.9525, Accuracy: 3350/5000 (67%)\n",
      "[epoch 18] loss: 0.0001620\n",
      "Test set: Average loss: 2.0039, Accuracy: 3348/5000 (67%)\n",
      "[epoch 19] loss: 0.0001115\n",
      "Test set: Average loss: 2.0573, Accuracy: 3347/5000 (67%)\n",
      "[epoch 20] loss: 0.0000767\n",
      "Test set: Average loss: 2.1083, Accuracy: 3348/5000 (67%)\n",
      "[epoch 21] loss: 0.0000526\n",
      "Test set: Average loss: 2.1632, Accuracy: 3356/5000 (67%)\n",
      "[epoch 22] loss: 0.0000359\n",
      "Test set: Average loss: 2.2185, Accuracy: 3351/5000 (67%)\n",
      "[epoch 23] loss: 0.0000245\n",
      "Test set: Average loss: 2.2725, Accuracy: 3350/5000 (67%)\n",
      "[epoch 24] loss: 0.0000167\n",
      "Test set: Average loss: 2.3259, Accuracy: 3353/5000 (67%)\n",
      "[epoch 25] loss: 0.0000114\n",
      "Test set: Average loss: 2.3839, Accuracy: 3346/5000 (67%)\n",
      "[epoch 26] loss: 0.0000077\n",
      "Test set: Average loss: 2.4395, Accuracy: 3349/5000 (67%)\n",
      "[epoch 27] loss: 0.0000053\n",
      "Test set: Average loss: 2.4922, Accuracy: 3352/5000 (67%)\n",
      "[epoch 28] loss: 0.0000036\n",
      "Test set: Average loss: 2.5468, Accuracy: 3347/5000 (67%)\n",
      "[epoch 29] loss: 0.0000024\n",
      "Test set: Average loss: 2.6010, Accuracy: 3342/5000 (67%)\n",
      "[epoch 30] loss: 0.0000016\n",
      "Test set: Average loss: 2.6540, Accuracy: 3342/5000 (67%)\n",
      "[epoch 31] loss: 0.0000011\n",
      "Test set: Average loss: 2.7016, Accuracy: 3352/5000 (67%)\n",
      "[epoch 32] loss: 0.0000007\n",
      "Test set: Average loss: 2.7389, Accuracy: 3334/5000 (67%)\n",
      "[epoch 33] loss: 0.0000005\n",
      "Test set: Average loss: 2.7601, Accuracy: 3346/5000 (67%)\n",
      "[epoch 34] loss: 0.0000003\n",
      "Test set: Average loss: 2.7773, Accuracy: 3350/5000 (67%)\n",
      "[epoch 35] loss: 0.0000002\n",
      "Test set: Average loss: 2.7805, Accuracy: 3350/5000 (67%)\n",
      "[epoch 36] loss: 0.0000002\n",
      "Test set: Average loss: 2.7841, Accuracy: 3324/5000 (66%)\n",
      "[epoch 37] loss: 0.0000002\n",
      "Test set: Average loss: 2.7905, Accuracy: 3336/5000 (67%)\n",
      "[epoch 38] loss: 0.0000001\n",
      "Test set: Average loss: 2.7963, Accuracy: 3346/5000 (67%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Test set: Average loss: 2.7964, Accuracy: 3341/5000 (67%)\n",
      "[epoch 40] loss: 0.0000001\n",
      "Test set: Average loss: 2.8029, Accuracy: 3349/5000 (67%)\n",
      "[epoch 41] loss: 0.0000001\n",
      "Test set: Average loss: 2.8243, Accuracy: 3336/5000 (67%)\n",
      "[epoch 42] loss: 0.0000001\n",
      "Test set: Average loss: 2.8302, Accuracy: 3343/5000 (67%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Test set: Average loss: 2.8444, Accuracy: 3336/5000 (67%)\n",
      "[epoch 44] loss: 0.0000001\n",
      "Test set: Average loss: 2.8643, Accuracy: 3334/5000 (67%)\n",
      "[epoch 45] loss: 0.0000001\n",
      "Test set: Average loss: 2.8945, Accuracy: 3331/5000 (67%)\n",
      "[epoch 46] loss: 0.0000001\n",
      "Test set: Average loss: 2.9080, Accuracy: 3343/5000 (67%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Test set: Average loss: 2.9196, Accuracy: 3339/5000 (67%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Test set: Average loss: 2.9463, Accuracy: 3340/5000 (67%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9396, Accuracy: 3331/5000 (67%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Test set: Average loss: 2.9265, Accuracy: 3331/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1632, Accuracy: 3356/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.1267, Accuracy: 6721/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5190, Accuracy: 469/5000 (9%)\n",
      "[epoch 1] loss: 0.3461776\n",
      "Test set: Average loss: 1.2139, Accuracy: 3281/5000 (66%)\n",
      "[epoch 2] loss: 0.0727214\n",
      "Test set: Average loss: 1.4344, Accuracy: 3209/5000 (64%)\n",
      "[epoch 3] loss: 0.1473804\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5636, Accuracy: 3229/5000 (65%)\n",
      "[epoch 4] loss: 0.0438203\n",
      "Test set: Average loss: 1.4846, Accuracy: 3307/5000 (66%)\n",
      "[epoch 5] loss: 0.0140955\n",
      "Test set: Average loss: 1.5013, Accuracy: 3315/5000 (66%)\n",
      "[epoch 6] loss: 0.0090062\n",
      "Test set: Average loss: 1.5178, Accuracy: 3321/5000 (66%)\n",
      "[epoch 7] loss: 0.0064846\n",
      "Test set: Average loss: 1.5376, Accuracy: 3330/5000 (67%)\n",
      "[epoch 8] loss: 0.0047926\n",
      "Test set: Average loss: 1.5614, Accuracy: 3333/5000 (67%)\n",
      "[epoch 9] loss: 0.0035649\n",
      "Test set: Average loss: 1.5908, Accuracy: 3338/5000 (67%)\n",
      "[epoch 10] loss: 0.0026431\n",
      "Test set: Average loss: 1.6198, Accuracy: 3334/5000 (67%)\n",
      "[epoch 11] loss: 0.0019362\n",
      "Test set: Average loss: 1.6546, Accuracy: 3337/5000 (67%)\n",
      "[epoch 12] loss: 0.0014103\n",
      "Test set: Average loss: 1.6924, Accuracy: 3335/5000 (67%)\n",
      "[epoch 13] loss: 0.0010118\n",
      "Test set: Average loss: 1.7390, Accuracy: 3333/5000 (67%)\n",
      "[epoch 14] loss: 0.0007201\n",
      "Test set: Average loss: 1.7769, Accuracy: 3353/5000 (67%)\n",
      "[epoch 15] loss: 0.0005080\n",
      "Test set: Average loss: 1.8271, Accuracy: 3335/5000 (67%)\n",
      "[epoch 16] loss: 0.0003557\n",
      "Test set: Average loss: 1.8738, Accuracy: 3349/5000 (67%)\n",
      "[epoch 17] loss: 0.0002472\n",
      "Test set: Average loss: 1.9234, Accuracy: 3344/5000 (67%)\n",
      "[epoch 18] loss: 0.0001710\n",
      "Test set: Average loss: 1.9730, Accuracy: 3354/5000 (67%)\n",
      "[epoch 19] loss: 0.0001179\n",
      "Test set: Average loss: 2.0269, Accuracy: 3353/5000 (67%)\n",
      "[epoch 20] loss: 0.0000812\n",
      "Test set: Average loss: 2.0806, Accuracy: 3357/5000 (67%)\n",
      "[epoch 21] loss: 0.0000557\n",
      "Test set: Average loss: 2.1306, Accuracy: 3364/5000 (67%)\n",
      "[epoch 22] loss: 0.0000382\n",
      "Test set: Average loss: 2.1860, Accuracy: 3362/5000 (67%)\n",
      "[epoch 23] loss: 0.0000261\n",
      "Test set: Average loss: 2.2420, Accuracy: 3351/5000 (67%)\n",
      "[epoch 24] loss: 0.0000177\n",
      "Test set: Average loss: 2.2939, Accuracy: 3365/5000 (67%)\n",
      "[epoch 25] loss: 0.0000121\n",
      "Test set: Average loss: 2.3511, Accuracy: 3350/5000 (67%)\n",
      "[epoch 26] loss: 0.0000082\n",
      "Test set: Average loss: 2.4060, Accuracy: 3358/5000 (67%)\n",
      "[epoch 27] loss: 0.0000056\n",
      "Test set: Average loss: 2.4610, Accuracy: 3350/5000 (67%)\n",
      "[epoch 28] loss: 0.0000038\n",
      "Test set: Average loss: 2.5150, Accuracy: 3356/5000 (67%)\n",
      "[epoch 29] loss: 0.0000026\n",
      "Test set: Average loss: 2.5717, Accuracy: 3359/5000 (67%)\n",
      "[epoch 30] loss: 0.0000017\n",
      "Test set: Average loss: 2.6232, Accuracy: 3348/5000 (67%)\n",
      "[epoch 31] loss: 0.0000012\n",
      "Test set: Average loss: 2.6740, Accuracy: 3360/5000 (67%)\n",
      "[epoch 32] loss: 0.0000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.7080, Accuracy: 3348/5000 (67%)\n",
      "[epoch 33] loss: 0.0000005\n",
      "Test set: Average loss: 2.7376, Accuracy: 3349/5000 (67%)\n",
      "[epoch 34] loss: 0.0000003\n",
      "Test set: Average loss: 2.7519, Accuracy: 3352/5000 (67%)\n",
      "[epoch 35] loss: 0.0000002\n",
      "Test set: Average loss: 2.7567, Accuracy: 3355/5000 (67%)\n",
      "[epoch 36] loss: 0.0000002\n",
      "Test set: Average loss: 2.7615, Accuracy: 3341/5000 (67%)\n",
      "[epoch 37] loss: 0.0000002\n",
      "Test set: Average loss: 2.7721, Accuracy: 3339/5000 (67%)\n",
      "[epoch 38] loss: 0.0000002\n",
      "Test set: Average loss: 2.7811, Accuracy: 3335/5000 (67%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Test set: Average loss: 2.7939, Accuracy: 3332/5000 (67%)\n",
      "[epoch 40] loss: 0.0000001\n",
      "Test set: Average loss: 2.7916, Accuracy: 3337/5000 (67%)\n",
      "[epoch 41] loss: 0.0000001\n",
      "Test set: Average loss: 2.8145, Accuracy: 3338/5000 (67%)\n",
      "[epoch 42] loss: 0.0000001\n",
      "Test set: Average loss: 2.8270, Accuracy: 3331/5000 (67%)\n",
      "[epoch 43] loss: 0.0398651\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.8445, Accuracy: 3322/5000 (66%)\n",
      "[epoch 44] loss: 0.0000010\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.8485, Accuracy: 3324/5000 (66%)\n",
      "[epoch 45] loss: 0.0000008\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.8484, Accuracy: 3325/5000 (66%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.8484, Accuracy: 3325/5000 (66%)\n",
      "[epoch 47] loss: 0.0000007\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.8484, Accuracy: 3325/5000 (66%)\n",
      "[epoch 48] loss: 0.0000007\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.8484, Accuracy: 3325/5000 (66%)\n",
      "[epoch 49] loss: 0.0000007\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.8484, Accuracy: 3325/5000 (66%)\n",
      "[epoch 50] loss: 0.0000007\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.8484, Accuracy: 3325/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2939, Accuracy: 3365/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.2747, Accuracy: 6764/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4874, Accuracy: 464/5000 (9%)\n",
      "[epoch 1] loss: 0.3426430\n",
      "Test set: Average loss: 1.1968, Accuracy: 3298/5000 (66%)\n",
      "[epoch 2] loss: 0.0602224\n",
      "Test set: Average loss: 1.4204, Accuracy: 3291/5000 (66%)\n",
      "[epoch 3] loss: 0.1559858\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5158, Accuracy: 3226/5000 (65%)\n",
      "[epoch 4] loss: 0.0762333\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.4489, Accuracy: 3325/5000 (66%)\n",
      "[epoch 5] loss: 0.0276919\n",
      "Test set: Average loss: 1.4505, Accuracy: 3333/5000 (67%)\n",
      "[epoch 6] loss: 0.0254175\n",
      "Test set: Average loss: 1.4530, Accuracy: 3343/5000 (67%)\n",
      "[epoch 7] loss: 0.0233172\n",
      "Test set: Average loss: 1.4562, Accuracy: 3349/5000 (67%)\n",
      "[epoch 8] loss: 0.0211257\n",
      "Test set: Average loss: 1.4596, Accuracy: 3352/5000 (67%)\n",
      "[epoch 9] loss: 0.0190146\n",
      "Test set: Average loss: 1.4647, Accuracy: 3349/5000 (67%)\n",
      "[epoch 10] loss: 0.0171053\n",
      "Test set: Average loss: 1.4718, Accuracy: 3344/5000 (67%)\n",
      "[epoch 11] loss: 0.0153136\n",
      "Test set: Average loss: 1.4771, Accuracy: 3346/5000 (67%)\n",
      "[epoch 12] loss: 0.0137323\n",
      "Test set: Average loss: 1.4832, Accuracy: 3330/5000 (67%)\n",
      "[epoch 13] loss: 0.0123447\n",
      "Test set: Average loss: 1.4920, Accuracy: 3335/5000 (67%)\n",
      "[epoch 14] loss: 0.0110928\n",
      "Test set: Average loss: 1.4994, Accuracy: 3337/5000 (67%)\n",
      "[epoch 15] loss: 0.0099897\n",
      "Test set: Average loss: 1.5074, Accuracy: 3339/5000 (67%)\n",
      "[epoch 16] loss: 0.0089918\n",
      "Test set: Average loss: 1.5167, Accuracy: 3336/5000 (67%)\n",
      "[epoch 17] loss: 0.0081155\n",
      "Test set: Average loss: 1.5259, Accuracy: 3337/5000 (67%)\n",
      "[epoch 18] loss: 0.0073328\n",
      "Test set: Average loss: 1.5344, Accuracy: 3336/5000 (67%)\n",
      "[epoch 19] loss: 0.0066147\n",
      "Test set: Average loss: 1.5437, Accuracy: 3338/5000 (67%)\n",
      "[epoch 20] loss: 0.0059807\n",
      "Test set: Average loss: 1.5538, Accuracy: 3337/5000 (67%)\n",
      "[epoch 21] loss: 0.0054019\n",
      "Test set: Average loss: 1.5637, Accuracy: 3337/5000 (67%)\n",
      "[epoch 22] loss: 0.0049015\n",
      "Test set: Average loss: 1.5741, Accuracy: 3341/5000 (67%)\n",
      "[epoch 23] loss: 0.0044197\n",
      "Test set: Average loss: 1.5844, Accuracy: 3348/5000 (67%)\n",
      "[epoch 24] loss: 0.0040000\n",
      "Test set: Average loss: 1.5947, Accuracy: 3347/5000 (67%)\n",
      "[epoch 25] loss: 0.0036181\n",
      "Test set: Average loss: 1.6070, Accuracy: 3343/5000 (67%)\n",
      "[epoch 26] loss: 0.0032671\n",
      "Test set: Average loss: 1.6176, Accuracy: 3349/5000 (67%)\n",
      "[epoch 27] loss: 0.0029538\n",
      "Test set: Average loss: 1.6280, Accuracy: 3346/5000 (67%)\n",
      "[epoch 28] loss: 0.0026731\n",
      "Test set: Average loss: 1.6399, Accuracy: 3353/5000 (67%)\n",
      "[epoch 29] loss: 0.0024169\n",
      "Test set: Average loss: 1.6521, Accuracy: 3353/5000 (67%)\n",
      "[epoch 30] loss: 0.0021827\n",
      "Test set: Average loss: 1.6647, Accuracy: 3349/5000 (67%)\n",
      "[epoch 31] loss: 0.0019709\n",
      "Test set: Average loss: 1.6755, Accuracy: 3351/5000 (67%)\n",
      "[epoch 32] loss: 0.0017785\n",
      "Test set: Average loss: 1.6886, Accuracy: 3352/5000 (67%)\n",
      "[epoch 33] loss: 0.0016078\n",
      "Test set: Average loss: 1.7028, Accuracy: 3356/5000 (67%)\n",
      "[epoch 34] loss: 0.0014502\n",
      "Test set: Average loss: 1.7148, Accuracy: 3353/5000 (67%)\n",
      "[epoch 35] loss: 0.0013091\n",
      "Test set: Average loss: 1.7281, Accuracy: 3352/5000 (67%)\n",
      "[epoch 36] loss: 0.0011794\n",
      "Test set: Average loss: 1.7416, Accuracy: 3345/5000 (67%)\n",
      "[epoch 37] loss: 0.0010637\n",
      "Test set: Average loss: 1.7543, Accuracy: 3351/5000 (67%)\n",
      "[epoch 38] loss: 0.0009589\n",
      "Test set: Average loss: 1.7683, Accuracy: 3355/5000 (67%)\n",
      "[epoch 39] loss: 0.0008637\n",
      "Test set: Average loss: 1.7818, Accuracy: 3356/5000 (67%)\n",
      "[epoch 40] loss: 0.0007782\n",
      "Test set: Average loss: 1.7961, Accuracy: 3357/5000 (67%)\n",
      "[epoch 41] loss: 0.0007007\n",
      "Test set: Average loss: 1.8085, Accuracy: 3356/5000 (67%)\n",
      "[epoch 42] loss: 0.0006307\n",
      "Test set: Average loss: 1.8234, Accuracy: 3360/5000 (67%)\n",
      "[epoch 43] loss: 0.0005675\n",
      "Test set: Average loss: 1.8367, Accuracy: 3364/5000 (67%)\n",
      "[epoch 44] loss: 0.0005098\n",
      "Test set: Average loss: 1.8535, Accuracy: 3362/5000 (67%)\n",
      "[epoch 45] loss: 0.0004579\n",
      "Test set: Average loss: 1.8655, Accuracy: 3361/5000 (67%)\n",
      "[epoch 46] loss: 0.0004118\n",
      "Test set: Average loss: 1.8816, Accuracy: 3370/5000 (67%)\n",
      "[epoch 47] loss: 0.0003695\n",
      "Test set: Average loss: 1.8961, Accuracy: 3365/5000 (67%)\n",
      "[epoch 48] loss: 0.0003319\n",
      "Test set: Average loss: 1.9120, Accuracy: 3361/5000 (67%)\n",
      "[epoch 49] loss: 0.0002978\n",
      "Test set: Average loss: 1.9265, Accuracy: 3361/5000 (67%)\n",
      "[epoch 50] loss: 0.0002669\n",
      "Test set: Average loss: 1.9429, Accuracy: 3365/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8816, Accuracy: 3370/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.8441, Accuracy: 6739/10000 (67%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4015, Accuracy: 530/5000 (11%)\n",
      "[epoch 1] loss: 0.3111525\n",
      "Test set: Average loss: 1.2375, Accuracy: 3295/5000 (66%)\n",
      "[epoch 2] loss: 0.1091884\n",
      "Test set: Average loss: 1.4968, Accuracy: 3218/5000 (64%)\n",
      "[epoch 3] loss: 0.1499176\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5939, Accuracy: 3249/5000 (65%)\n",
      "[epoch 4] loss: 0.0405557\n",
      "Test set: Average loss: 1.4915, Accuracy: 3342/5000 (67%)\n",
      "[epoch 5] loss: 0.0150166\n",
      "Test set: Average loss: 1.5146, Accuracy: 3347/5000 (67%)\n",
      "[epoch 6] loss: 0.0094434\n",
      "Test set: Average loss: 1.5437, Accuracy: 3354/5000 (67%)\n",
      "[epoch 7] loss: 0.0065488\n",
      "Test set: Average loss: 1.5697, Accuracy: 3363/5000 (67%)\n",
      "[epoch 8] loss: 0.0045948\n",
      "Test set: Average loss: 1.6065, Accuracy: 3371/5000 (67%)\n",
      "[epoch 9] loss: 0.0032229\n",
      "Test set: Average loss: 1.6481, Accuracy: 3371/5000 (67%)\n",
      "[epoch 10] loss: 0.0022324\n",
      "Test set: Average loss: 1.6866, Accuracy: 3380/5000 (68%)\n",
      "[epoch 11] loss: 0.0015277\n",
      "Test set: Average loss: 1.7390, Accuracy: 3376/5000 (68%)\n",
      "[epoch 12] loss: 0.0010276\n",
      "Test set: Average loss: 1.7887, Accuracy: 3379/5000 (68%)\n",
      "[epoch 13] loss: 0.0006829\n",
      "Test set: Average loss: 1.8440, Accuracy: 3363/5000 (67%)\n",
      "[epoch 14] loss: 0.0004509\n",
      "Test set: Average loss: 1.9040, Accuracy: 3379/5000 (68%)\n",
      "[epoch 15] loss: 0.0002951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.9629, Accuracy: 3367/5000 (67%)\n",
      "[epoch 16] loss: 0.0001913\n",
      "Test set: Average loss: 2.0311, Accuracy: 3375/5000 (68%)\n",
      "[epoch 17] loss: 0.0001240\n",
      "Test set: Average loss: 2.0877, Accuracy: 3373/5000 (67%)\n",
      "[epoch 18] loss: 0.0000796\n",
      "Test set: Average loss: 2.1506, Accuracy: 3372/5000 (67%)\n",
      "[epoch 19] loss: 0.0000512\n",
      "Test set: Average loss: 2.2200, Accuracy: 3367/5000 (67%)\n",
      "[epoch 20] loss: 0.0000327\n",
      "Test set: Average loss: 2.2902, Accuracy: 3360/5000 (67%)\n",
      "[epoch 21] loss: 0.0000209\n",
      "Test set: Average loss: 2.3481, Accuracy: 3368/5000 (67%)\n",
      "[epoch 22] loss: 0.0000133\n",
      "Test set: Average loss: 2.4163, Accuracy: 3371/5000 (67%)\n",
      "[epoch 23] loss: 0.0000085\n",
      "Test set: Average loss: 2.4865, Accuracy: 3374/5000 (67%)\n",
      "[epoch 24] loss: 0.0000054\n",
      "Test set: Average loss: 2.5522, Accuracy: 3369/5000 (67%)\n",
      "[epoch 25] loss: 0.0000034\n",
      "Test set: Average loss: 2.6205, Accuracy: 3368/5000 (67%)\n",
      "[epoch 26] loss: 0.0000022\n",
      "Test set: Average loss: 2.6832, Accuracy: 3369/5000 (67%)\n",
      "[epoch 27] loss: 0.0000014\n",
      "Test set: Average loss: 2.7474, Accuracy: 3370/5000 (67%)\n",
      "[epoch 28] loss: 0.0000008\n",
      "Test set: Average loss: 2.7949, Accuracy: 3362/5000 (67%)\n",
      "[epoch 29] loss: 0.0000005\n",
      "Test set: Average loss: 2.8343, Accuracy: 3359/5000 (67%)\n",
      "[epoch 30] loss: 0.0000003\n",
      "Test set: Average loss: 2.8539, Accuracy: 3367/5000 (67%)\n",
      "[epoch 31] loss: 0.0000002\n",
      "Test set: Average loss: 2.8669, Accuracy: 3360/5000 (67%)\n",
      "[epoch 32] loss: 0.0000002\n",
      "Test set: Average loss: 2.8678, Accuracy: 3356/5000 (67%)\n",
      "[epoch 33] loss: 0.0000002\n",
      "Test set: Average loss: 2.8803, Accuracy: 3343/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 2.8892, Accuracy: 3345/5000 (67%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 2.9010, Accuracy: 3357/5000 (67%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 2.9189, Accuracy: 3345/5000 (67%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 2.9292, Accuracy: 3342/5000 (67%)\n",
      "[epoch 38] loss: 0.0000001\n",
      "Test set: Average loss: 2.9469, Accuracy: 3339/5000 (67%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Test set: Average loss: 2.9670, Accuracy: 3339/5000 (67%)\n",
      "[epoch 40] loss: 0.0000001\n",
      "Test set: Average loss: 2.9959, Accuracy: 3331/5000 (67%)\n",
      "[epoch 41] loss: 0.0000001\n",
      "Test set: Average loss: 3.0103, Accuracy: 3338/5000 (67%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Test set: Average loss: 3.0289, Accuracy: 3347/5000 (67%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0777, Accuracy: 3336/5000 (67%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Test set: Average loss: 3.0365, Accuracy: 3338/5000 (67%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0267, Accuracy: 3343/5000 (67%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0245, Accuracy: 3343/5000 (67%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.0243, Accuracy: 3343/5000 (67%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.0243, Accuracy: 3343/5000 (67%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.0243, Accuracy: 3343/5000 (67%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.0243, Accuracy: 3343/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6866, Accuracy: 3380/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.6702, Accuracy: 6707/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4202, Accuracy: 517/5000 (10%)\n",
      "[epoch 1] loss: 0.3126517\n",
      "Test set: Average loss: 1.2082, Accuracy: 3302/5000 (66%)\n",
      "[epoch 2] loss: 0.1157357\n",
      "Test set: Average loss: 1.5121, Accuracy: 3190/5000 (64%)\n",
      "[epoch 3] loss: 0.1291283\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5668, Accuracy: 3267/5000 (65%)\n",
      "[epoch 4] loss: 0.0371165\n",
      "Test set: Average loss: 1.5144, Accuracy: 3330/5000 (67%)\n",
      "[epoch 5] loss: 0.0128366\n",
      "Test set: Average loss: 1.5380, Accuracy: 3332/5000 (67%)\n",
      "[epoch 6] loss: 0.0081977\n",
      "Test set: Average loss: 1.5629, Accuracy: 3331/5000 (67%)\n",
      "[epoch 7] loss: 0.0057309\n",
      "Test set: Average loss: 1.5944, Accuracy: 3325/5000 (66%)\n",
      "[epoch 8] loss: 0.0040799\n",
      "Test set: Average loss: 1.6280, Accuracy: 3329/5000 (67%)\n",
      "[epoch 9] loss: 0.0028717\n",
      "Test set: Average loss: 1.6665, Accuracy: 3342/5000 (67%)\n",
      "[epoch 10] loss: 0.0019999\n",
      "Test set: Average loss: 1.7113, Accuracy: 3337/5000 (67%)\n",
      "[epoch 11] loss: 0.0013689\n",
      "Test set: Average loss: 1.7623, Accuracy: 3345/5000 (67%)\n",
      "[epoch 12] loss: 0.0009240\n",
      "Test set: Average loss: 1.8152, Accuracy: 3344/5000 (67%)\n",
      "[epoch 13] loss: 0.0006173\n",
      "Test set: Average loss: 1.8730, Accuracy: 3337/5000 (67%)\n",
      "[epoch 14] loss: 0.0004077\n",
      "Test set: Average loss: 1.9304, Accuracy: 3334/5000 (67%)\n",
      "[epoch 15] loss: 0.0002673\n",
      "Test set: Average loss: 1.9897, Accuracy: 3343/5000 (67%)\n",
      "[epoch 16] loss: 0.0001743\n",
      "Test set: Average loss: 2.0483, Accuracy: 3344/5000 (67%)\n",
      "[epoch 17] loss: 0.0001125\n",
      "Test set: Average loss: 2.1154, Accuracy: 3346/5000 (67%)\n",
      "[epoch 18] loss: 0.0000727\n",
      "Test set: Average loss: 2.1794, Accuracy: 3351/5000 (67%)\n",
      "[epoch 19] loss: 0.0000466\n",
      "Test set: Average loss: 2.2473, Accuracy: 3335/5000 (67%)\n",
      "[epoch 20] loss: 0.0000299\n",
      "Test set: Average loss: 2.3147, Accuracy: 3348/5000 (67%)\n",
      "[epoch 21] loss: 0.0000191\n",
      "Test set: Average loss: 2.3825, Accuracy: 3346/5000 (67%)\n",
      "[epoch 22] loss: 0.0000122\n",
      "Test set: Average loss: 2.4514, Accuracy: 3347/5000 (67%)\n",
      "[epoch 23] loss: 0.0000078\n",
      "Test set: Average loss: 2.5197, Accuracy: 3345/5000 (67%)\n",
      "[epoch 24] loss: 0.0000049\n",
      "Test set: Average loss: 2.5873, Accuracy: 3347/5000 (67%)\n",
      "[epoch 25] loss: 0.0000031\n",
      "Test set: Average loss: 2.6586, Accuracy: 3353/5000 (67%)\n",
      "[epoch 26] loss: 0.0000020\n",
      "Test set: Average loss: 2.7210, Accuracy: 3345/5000 (67%)\n",
      "[epoch 27] loss: 0.0000012\n",
      "Test set: Average loss: 2.7885, Accuracy: 3341/5000 (67%)\n",
      "[epoch 28] loss: 0.0000008\n",
      "Test set: Average loss: 2.8395, Accuracy: 3343/5000 (67%)\n",
      "[epoch 29] loss: 0.0000005\n",
      "Test set: Average loss: 2.8747, Accuracy: 3330/5000 (67%)\n",
      "[epoch 30] loss: 0.0000003\n",
      "Test set: Average loss: 2.8861, Accuracy: 3343/5000 (67%)\n",
      "[epoch 31] loss: 0.0000002\n",
      "Test set: Average loss: 2.8970, Accuracy: 3323/5000 (66%)\n",
      "[epoch 32] loss: 0.0000002\n",
      "Test set: Average loss: 2.9114, Accuracy: 3314/5000 (66%)\n",
      "[epoch 33] loss: 0.0000002\n",
      "Test set: Average loss: 2.9297, Accuracy: 3320/5000 (66%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 2.9323, Accuracy: 3316/5000 (66%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 2.9488, Accuracy: 3312/5000 (66%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 2.9573, Accuracy: 3318/5000 (66%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 2.9865, Accuracy: 3307/5000 (66%)\n",
      "[epoch 38] loss: 0.0000001\n",
      "Test set: Average loss: 3.0108, Accuracy: 3317/5000 (66%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Test set: Average loss: 3.0264, Accuracy: 3311/5000 (66%)\n",
      "[epoch 40] loss: 0.0000001\n",
      "Test set: Average loss: 3.0565, Accuracy: 3311/5000 (66%)\n",
      "[epoch 41] loss: 0.0000001\n",
      "Test set: Average loss: 3.0840, Accuracy: 3309/5000 (66%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Test set: Average loss: 3.0948, Accuracy: 3304/5000 (66%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.1161, Accuracy: 3301/5000 (66%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Test set: Average loss: 3.0890, Accuracy: 3301/5000 (66%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0858, Accuracy: 3297/5000 (66%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0835, Accuracy: 3298/5000 (66%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.0834, Accuracy: 3298/5000 (66%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.0834, Accuracy: 3298/5000 (66%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.0834, Accuracy: 3298/5000 (66%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.0834, Accuracy: 3298/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6586, Accuracy: 3353/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.5655, Accuracy: 6781/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3851, Accuracy: 664/5000 (13%)\n",
      "[epoch 1] loss: 0.3126852\n",
      "Test set: Average loss: 1.2399, Accuracy: 3307/5000 (66%)\n",
      "[epoch 2] loss: 0.1025225\n",
      "Test set: Average loss: 1.5605, Accuracy: 3221/5000 (64%)\n",
      "[epoch 3] loss: 0.1461914\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5630, Accuracy: 3223/5000 (64%)\n",
      "[epoch 4] loss: 0.0440816\n",
      "Test set: Average loss: 1.4953, Accuracy: 3315/5000 (66%)\n",
      "[epoch 5] loss: 0.0147308\n",
      "Test set: Average loss: 1.5155, Accuracy: 3328/5000 (67%)\n",
      "[epoch 6] loss: 0.0091705\n",
      "Test set: Average loss: 1.5403, Accuracy: 3324/5000 (66%)\n",
      "[epoch 7] loss: 0.0063197\n",
      "Test set: Average loss: 1.5686, Accuracy: 3331/5000 (67%)\n",
      "[epoch 8] loss: 0.0044590\n",
      "Test set: Average loss: 1.5986, Accuracy: 3334/5000 (67%)\n",
      "[epoch 9] loss: 0.0031352\n",
      "Test set: Average loss: 1.6384, Accuracy: 3341/5000 (67%)\n",
      "[epoch 10] loss: 0.0021778\n",
      "Test set: Average loss: 1.6835, Accuracy: 3356/5000 (67%)\n",
      "[epoch 11] loss: 0.0014918\n",
      "Test set: Average loss: 1.7277, Accuracy: 3359/5000 (67%)\n",
      "[epoch 12] loss: 0.0010097\n",
      "Test set: Average loss: 1.7808, Accuracy: 3361/5000 (67%)\n",
      "[epoch 13] loss: 0.0006752\n",
      "Test set: Average loss: 1.8320, Accuracy: 3361/5000 (67%)\n",
      "[epoch 14] loss: 0.0004456\n",
      "Test set: Average loss: 1.8885, Accuracy: 3365/5000 (67%)\n",
      "[epoch 15] loss: 0.0002923\n",
      "Test set: Average loss: 1.9480, Accuracy: 3364/5000 (67%)\n",
      "[epoch 16] loss: 0.0001904\n",
      "Test set: Average loss: 2.0072, Accuracy: 3376/5000 (68%)\n",
      "[epoch 17] loss: 0.0001236\n",
      "Test set: Average loss: 2.0697, Accuracy: 3367/5000 (67%)\n",
      "[epoch 18] loss: 0.0000796\n",
      "Test set: Average loss: 2.1339, Accuracy: 3368/5000 (67%)\n",
      "[epoch 19] loss: 0.0000512\n",
      "Test set: Average loss: 2.1988, Accuracy: 3369/5000 (67%)\n",
      "[epoch 20] loss: 0.0000328\n",
      "Test set: Average loss: 2.2653, Accuracy: 3371/5000 (67%)\n",
      "[epoch 21] loss: 0.0000210\n",
      "Test set: Average loss: 2.3330, Accuracy: 3374/5000 (67%)\n",
      "[epoch 22] loss: 0.0000134\n",
      "Test set: Average loss: 2.3967, Accuracy: 3368/5000 (67%)\n",
      "[epoch 23] loss: 0.0000085\n",
      "Test set: Average loss: 2.4676, Accuracy: 3363/5000 (67%)\n",
      "[epoch 24] loss: 0.0000054\n",
      "Test set: Average loss: 2.5323, Accuracy: 3363/5000 (67%)\n",
      "[epoch 25] loss: 0.0000034\n",
      "Test set: Average loss: 2.6037, Accuracy: 3364/5000 (67%)\n",
      "[epoch 26] loss: 0.0000022\n",
      "Test set: Average loss: 2.6642, Accuracy: 3365/5000 (67%)\n",
      "[epoch 27] loss: 0.0000014\n",
      "Test set: Average loss: 2.7274, Accuracy: 3376/5000 (68%)\n",
      "[epoch 28] loss: 0.0000008\n",
      "Test set: Average loss: 2.7776, Accuracy: 3371/5000 (67%)\n",
      "[epoch 29] loss: 0.0000005\n",
      "Test set: Average loss: 2.8121, Accuracy: 3375/5000 (68%)\n",
      "[epoch 30] loss: 0.0000003\n",
      "Test set: Average loss: 2.8334, Accuracy: 3369/5000 (67%)\n",
      "[epoch 31] loss: 0.0000002\n",
      "Test set: Average loss: 2.8440, Accuracy: 3366/5000 (67%)\n",
      "[epoch 32] loss: 0.0000002\n",
      "Test set: Average loss: 2.8418, Accuracy: 3357/5000 (67%)\n",
      "[epoch 33] loss: 0.0000002\n",
      "Test set: Average loss: 2.8635, Accuracy: 3358/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 2.8642, Accuracy: 3351/5000 (67%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 2.8833, Accuracy: 3359/5000 (67%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 2.8952, Accuracy: 3346/5000 (67%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 2.9092, Accuracy: 3339/5000 (67%)\n",
      "[epoch 38] loss: 0.0000001\n",
      "Test set: Average loss: 2.9353, Accuracy: 3337/5000 (67%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Test set: Average loss: 2.9617, Accuracy: 3331/5000 (67%)\n",
      "[epoch 40] loss: 0.0000001\n",
      "Test set: Average loss: 2.9902, Accuracy: 3330/5000 (67%)\n",
      "[epoch 41] loss: 0.0000001\n",
      "Test set: Average loss: 3.0019, Accuracy: 3334/5000 (67%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Test set: Average loss: 3.0218, Accuracy: 3340/5000 (67%)\n",
      "[epoch 43] loss: 0.0000001\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0448, Accuracy: 3319/5000 (66%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Test set: Average loss: 3.0268, Accuracy: 3324/5000 (66%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0215, Accuracy: 3318/5000 (66%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0204, Accuracy: 3314/5000 (66%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.0203, Accuracy: 3315/5000 (66%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.0203, Accuracy: 3315/5000 (66%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.0203, Accuracy: 3315/5000 (66%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.0203, Accuracy: 3315/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7274, Accuracy: 3376/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6994, Accuracy: 6763/10000 (68%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3818, Accuracy: 602/5000 (12%)\n",
      "[epoch 1] loss: 0.3010972\n",
      "Test set: Average loss: 1.2154, Accuracy: 3335/5000 (67%)\n",
      "[epoch 2] loss: 0.1269058\n",
      "Test set: Average loss: 1.5598, Accuracy: 3213/5000 (64%)\n",
      "[epoch 3] loss: 0.1419794\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5978, Accuracy: 3253/5000 (65%)\n",
      "[epoch 4] loss: 0.0419684\n",
      "Test set: Average loss: 1.5362, Accuracy: 3328/5000 (67%)\n",
      "[epoch 5] loss: 0.0139294\n",
      "Test set: Average loss: 1.5555, Accuracy: 3344/5000 (67%)\n",
      "[epoch 6] loss: 0.0084672\n",
      "Test set: Average loss: 1.5881, Accuracy: 3350/5000 (67%)\n",
      "[epoch 7] loss: 0.0056735\n",
      "Test set: Average loss: 1.6228, Accuracy: 3353/5000 (67%)\n",
      "[epoch 8] loss: 0.0038351\n",
      "Test set: Average loss: 1.6690, Accuracy: 3362/5000 (67%)\n",
      "[epoch 9] loss: 0.0025494\n",
      "Test set: Average loss: 1.7162, Accuracy: 3373/5000 (67%)\n",
      "[epoch 10] loss: 0.0016610\n",
      "Test set: Average loss: 1.7618, Accuracy: 3367/5000 (67%)\n",
      "[epoch 11] loss: 0.0010660\n",
      "Test set: Average loss: 1.8296, Accuracy: 3381/5000 (68%)\n",
      "[epoch 12] loss: 0.0006751\n",
      "Test set: Average loss: 1.8921, Accuracy: 3385/5000 (68%)\n",
      "[epoch 13] loss: 0.0004218\n",
      "Test set: Average loss: 1.9627, Accuracy: 3394/5000 (68%)\n",
      "[epoch 14] loss: 0.0002594\n",
      "Test set: Average loss: 2.0295, Accuracy: 3388/5000 (68%)\n",
      "[epoch 15] loss: 0.0001591\n",
      "Test set: Average loss: 2.1092, Accuracy: 3380/5000 (68%)\n",
      "[epoch 16] loss: 0.0000968\n",
      "Test set: Average loss: 2.1829, Accuracy: 3386/5000 (68%)\n",
      "[epoch 17] loss: 0.0000587\n",
      "Test set: Average loss: 2.2570, Accuracy: 3396/5000 (68%)\n",
      "[epoch 18] loss: 0.0000353\n",
      "Test set: Average loss: 2.3420, Accuracy: 3387/5000 (68%)\n",
      "[epoch 19] loss: 0.0000212\n",
      "Test set: Average loss: 2.4171, Accuracy: 3387/5000 (68%)\n",
      "[epoch 20] loss: 0.0000126\n",
      "Test set: Average loss: 2.5034, Accuracy: 3385/5000 (68%)\n",
      "[epoch 21] loss: 0.0000076\n",
      "Test set: Average loss: 2.5847, Accuracy: 3381/5000 (68%)\n",
      "[epoch 22] loss: 0.0000045\n",
      "Test set: Average loss: 2.6602, Accuracy: 3380/5000 (68%)\n",
      "[epoch 23] loss: 0.0000027\n",
      "Test set: Average loss: 2.7416, Accuracy: 3381/5000 (68%)\n",
      "[epoch 24] loss: 0.0000016\n",
      "Test set: Average loss: 2.8129, Accuracy: 3382/5000 (68%)\n",
      "[epoch 25] loss: 0.0000009\n",
      "Test set: Average loss: 2.8815, Accuracy: 3378/5000 (68%)\n",
      "[epoch 26] loss: 0.0000005\n",
      "Test set: Average loss: 2.9284, Accuracy: 3371/5000 (67%)\n",
      "[epoch 27] loss: 0.0000003\n",
      "Test set: Average loss: 2.9676, Accuracy: 3358/5000 (67%)\n",
      "[epoch 28] loss: 0.0000002\n",
      "Test set: Average loss: 2.9716, Accuracy: 3363/5000 (67%)\n",
      "[epoch 29] loss: 0.0000002\n",
      "Test set: Average loss: 2.9861, Accuracy: 3352/5000 (67%)\n",
      "[epoch 30] loss: 0.0000001\n",
      "Test set: Average loss: 2.9898, Accuracy: 3365/5000 (67%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.0124, Accuracy: 3357/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.0191, Accuracy: 3346/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.0322, Accuracy: 3349/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 3.0599, Accuracy: 3350/5000 (67%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 3.0768, Accuracy: 3337/5000 (67%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 3.1060, Accuracy: 3343/5000 (67%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 3.1247, Accuracy: 3346/5000 (67%)\n",
      "[epoch 38] loss: 0.0000001\n",
      "Test set: Average loss: 3.1384, Accuracy: 3340/5000 (67%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.1875, Accuracy: 3341/5000 (67%)\n",
      "[epoch 40] loss: 0.0000000\n",
      "Test set: Average loss: 3.1427, Accuracy: 3336/5000 (67%)\n",
      "[epoch 41] loss: 0.0000000\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.1343, Accuracy: 3322/5000 (66%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.1313, Accuracy: 3326/5000 (67%)\n",
      "[epoch 43] loss: 0.0000000\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.1311, Accuracy: 3325/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2570, Accuracy: 3396/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.2274, Accuracy: 6742/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3726, Accuracy: 584/5000 (12%)\n",
      "[epoch 1] loss: 0.2984759\n",
      "Test set: Average loss: 1.2437, Accuracy: 3326/5000 (67%)\n",
      "[epoch 2] loss: 0.1297904\n",
      "Test set: Average loss: 1.6066, Accuracy: 3165/5000 (63%)\n",
      "[epoch 3] loss: 0.1452800\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5516, Accuracy: 3281/5000 (66%)\n",
      "[epoch 4] loss: 0.0436257\n",
      "Test set: Average loss: 1.5191, Accuracy: 3333/5000 (67%)\n",
      "[epoch 5] loss: 0.0149655\n",
      "Test set: Average loss: 1.5416, Accuracy: 3321/5000 (66%)\n",
      "[epoch 6] loss: 0.0090740\n",
      "Test set: Average loss: 1.5756, Accuracy: 3320/5000 (66%)\n",
      "[epoch 7] loss: 0.0060464\n",
      "Test set: Average loss: 1.6021, Accuracy: 3327/5000 (67%)\n",
      "[epoch 8] loss: 0.0040637\n",
      "Test set: Average loss: 1.6503, Accuracy: 3337/5000 (67%)\n",
      "[epoch 9] loss: 0.0026965\n",
      "Test set: Average loss: 1.7040, Accuracy: 3357/5000 (67%)\n",
      "[epoch 10] loss: 0.0017667\n",
      "Test set: Average loss: 1.7596, Accuracy: 3354/5000 (67%)\n",
      "[epoch 11] loss: 0.0011335\n",
      "Test set: Average loss: 1.8100, Accuracy: 3373/5000 (67%)\n",
      "[epoch 12] loss: 0.0007138\n",
      "Test set: Average loss: 1.8804, Accuracy: 3374/5000 (67%)\n",
      "[epoch 13] loss: 0.0004455\n",
      "Test set: Average loss: 1.9493, Accuracy: 3368/5000 (67%)\n",
      "[epoch 14] loss: 0.0002753\n",
      "Test set: Average loss: 2.0197, Accuracy: 3374/5000 (67%)\n",
      "[epoch 15] loss: 0.0001688\n",
      "Test set: Average loss: 2.0936, Accuracy: 3377/5000 (68%)\n",
      "[epoch 16] loss: 0.0001030\n",
      "Test set: Average loss: 2.1665, Accuracy: 3373/5000 (67%)\n",
      "[epoch 17] loss: 0.0000625\n",
      "Test set: Average loss: 2.2433, Accuracy: 3370/5000 (67%)\n",
      "[epoch 18] loss: 0.0000376\n",
      "Test set: Average loss: 2.3228, Accuracy: 3371/5000 (67%)\n",
      "[epoch 19] loss: 0.0000228\n",
      "Test set: Average loss: 2.4029, Accuracy: 3375/5000 (68%)\n",
      "[epoch 20] loss: 0.0000136\n",
      "Test set: Average loss: 2.4869, Accuracy: 3375/5000 (68%)\n",
      "[epoch 21] loss: 0.0000081\n",
      "Test set: Average loss: 2.5658, Accuracy: 3370/5000 (67%)\n",
      "[epoch 22] loss: 0.0000048\n",
      "Test set: Average loss: 2.6442, Accuracy: 3375/5000 (68%)\n",
      "[epoch 23] loss: 0.0000029\n",
      "Test set: Average loss: 2.7254, Accuracy: 3376/5000 (68%)\n",
      "[epoch 24] loss: 0.0000017\n",
      "Test set: Average loss: 2.8052, Accuracy: 3374/5000 (67%)\n",
      "[epoch 25] loss: 0.0000010\n",
      "Test set: Average loss: 2.8711, Accuracy: 3356/5000 (67%)\n",
      "[epoch 26] loss: 0.0000006\n",
      "Test set: Average loss: 2.9191, Accuracy: 3366/5000 (67%)\n",
      "[epoch 27] loss: 0.0000003\n",
      "Test set: Average loss: 2.9514, Accuracy: 3369/5000 (67%)\n",
      "[epoch 28] loss: 0.0000002\n",
      "Test set: Average loss: 2.9712, Accuracy: 3348/5000 (67%)\n",
      "[epoch 29] loss: 0.0000002\n",
      "Test set: Average loss: 2.9763, Accuracy: 3355/5000 (67%)\n",
      "[epoch 30] loss: 0.0000002\n",
      "Test set: Average loss: 3.0114, Accuracy: 3353/5000 (67%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.0085, Accuracy: 3340/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.0091, Accuracy: 3340/5000 (67%)\n",
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.0424, Accuracy: 3346/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 3.0486, Accuracy: 3336/5000 (67%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 3.0788, Accuracy: 3333/5000 (67%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 3.1108, Accuracy: 3339/5000 (67%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 3.1334, Accuracy: 3342/5000 (67%)\n",
      "[epoch 38] loss: 0.0000000\n",
      "Test set: Average loss: 3.1406, Accuracy: 3341/5000 (67%)\n",
      "[epoch 39] loss: 0.0000001\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.1645, Accuracy: 3326/5000 (67%)\n",
      "[epoch 40] loss: 0.0000000\n",
      "Test set: Average loss: 3.1449, Accuracy: 3329/5000 (67%)\n",
      "[epoch 41] loss: 0.0000000\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.1395, Accuracy: 3323/5000 (66%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.1379, Accuracy: 3321/5000 (66%)\n",
      "[epoch 43] loss: 0.0000000\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.1378, Accuracy: 3320/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0936, Accuracy: 3377/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.0574, Accuracy: 6769/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3203, Accuracy: 652/5000 (13%)\n",
      "[epoch 1] loss: 0.2880035\n",
      "Test set: Average loss: 1.2961, Accuracy: 3274/5000 (65%)\n",
      "[epoch 2] loss: 0.1304842\n",
      "Test set: Average loss: 1.4877, Accuracy: 3240/5000 (65%)\n",
      "[epoch 3] loss: 0.1421602\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5446, Accuracy: 3251/5000 (65%)\n",
      "[epoch 4] loss: 0.0424893\n",
      "Test set: Average loss: 1.5167, Accuracy: 3345/5000 (67%)\n",
      "[epoch 5] loss: 0.0148716\n",
      "Test set: Average loss: 1.5383, Accuracy: 3360/5000 (67%)\n",
      "[epoch 6] loss: 0.0088963\n",
      "Test set: Average loss: 1.5738, Accuracy: 3349/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 0.0059375\n",
      "Test set: Average loss: 1.6058, Accuracy: 3350/5000 (67%)\n",
      "[epoch 8] loss: 0.0039956\n",
      "Test set: Average loss: 1.6527, Accuracy: 3343/5000 (67%)\n",
      "[epoch 9] loss: 0.0026590\n",
      "Test set: Average loss: 1.7044, Accuracy: 3357/5000 (67%)\n",
      "[epoch 10] loss: 0.0017434\n",
      "Test set: Average loss: 1.7622, Accuracy: 3366/5000 (67%)\n",
      "[epoch 11] loss: 0.0011152\n",
      "Test set: Average loss: 1.8188, Accuracy: 3363/5000 (67%)\n",
      "[epoch 12] loss: 0.0007051\n",
      "Test set: Average loss: 1.8873, Accuracy: 3360/5000 (67%)\n",
      "[epoch 13] loss: 0.0004406\n",
      "Test set: Average loss: 1.9600, Accuracy: 3366/5000 (67%)\n",
      "[epoch 14] loss: 0.0002722\n",
      "Test set: Average loss: 2.0282, Accuracy: 3356/5000 (67%)\n",
      "[epoch 15] loss: 0.0001661\n",
      "Test set: Average loss: 2.1000, Accuracy: 3363/5000 (67%)\n",
      "[epoch 16] loss: 0.0001015\n",
      "Test set: Average loss: 2.1754, Accuracy: 3359/5000 (67%)\n",
      "[epoch 17] loss: 0.0000614\n",
      "Test set: Average loss: 2.2589, Accuracy: 3357/5000 (67%)\n",
      "[epoch 18] loss: 0.0000370\n",
      "Test set: Average loss: 2.3308, Accuracy: 3354/5000 (67%)\n",
      "[epoch 19] loss: 0.0000223\n",
      "Test set: Average loss: 2.4124, Accuracy: 3366/5000 (67%)\n",
      "[epoch 20] loss: 0.0000134\n",
      "Test set: Average loss: 2.4936, Accuracy: 3354/5000 (67%)\n",
      "[epoch 21] loss: 0.0000080\n",
      "Test set: Average loss: 2.5776, Accuracy: 3352/5000 (67%)\n",
      "[epoch 22] loss: 0.0000047\n",
      "Test set: Average loss: 2.6607, Accuracy: 3345/5000 (67%)\n",
      "[epoch 23] loss: 0.0000028\n",
      "Test set: Average loss: 2.7376, Accuracy: 3348/5000 (67%)\n",
      "[epoch 24] loss: 0.0000017\n",
      "Test set: Average loss: 2.8182, Accuracy: 3346/5000 (67%)\n",
      "[epoch 25] loss: 0.0000010\n",
      "Test set: Average loss: 2.8858, Accuracy: 3336/5000 (67%)\n",
      "[epoch 26] loss: 0.0000006\n",
      "Test set: Average loss: 2.9285, Accuracy: 3350/5000 (67%)\n",
      "[epoch 27] loss: 0.0000003\n",
      "Test set: Average loss: 2.9493, Accuracy: 3336/5000 (67%)\n",
      "[epoch 28] loss: 0.0000002\n",
      "Test set: Average loss: 2.9731, Accuracy: 3327/5000 (67%)\n",
      "[epoch 29] loss: 0.0000002\n",
      "Test set: Average loss: 2.9936, Accuracy: 3331/5000 (67%)\n",
      "[epoch 30] loss: 0.0000002\n",
      "Test set: Average loss: 2.9931, Accuracy: 3333/5000 (67%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.0026, Accuracy: 3333/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.0253, Accuracy: 3333/5000 (67%)\n",
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.0238, Accuracy: 3330/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 3.0593, Accuracy: 3329/5000 (67%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 3.0879, Accuracy: 3334/5000 (67%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 3.1038, Accuracy: 3321/5000 (66%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 3.1593, Accuracy: 3323/5000 (66%)\n",
      "[epoch 38] loss: 0.0003481\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2748, Accuracy: 3281/5000 (66%)\n",
      "[epoch 39] loss: 0.0001546\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2923, Accuracy: 3294/5000 (66%)\n",
      "[epoch 40] loss: 0.0000224\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 41] loss: 0.0000217\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 42] loss: 0.0000216\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 43] loss: 0.0000216\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 44] loss: 0.0000216\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 45] loss: 0.0000216\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 46] loss: 0.0000216\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 47] loss: 0.0000216\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 48] loss: 0.0000216\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 49] loss: 0.0000216\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "[epoch 50] loss: 0.0000216\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.2536, Accuracy: 3299/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4124, Accuracy: 3366/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.3803, Accuracy: 6771/10000 (68%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.5590, Accuracy: 313/5000 (6%)\n",
      "[epoch 1] loss: 0.2952811\n",
      "Test set: Average loss: 1.3297, Accuracy: 3234/5000 (65%)\n",
      "[epoch 2] loss: 0.1423927\n",
      "Test set: Average loss: 1.5626, Accuracy: 3212/5000 (64%)\n",
      "[epoch 3] loss: 0.1573544\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5749, Accuracy: 3254/5000 (65%)\n",
      "[epoch 4] loss: 0.0518632\n",
      "Test set: Average loss: 1.5097, Accuracy: 3344/5000 (67%)\n",
      "[epoch 5] loss: 0.0177577\n",
      "Test set: Average loss: 1.5423, Accuracy: 3335/5000 (67%)\n",
      "[epoch 6] loss: 0.0101349\n",
      "Test set: Average loss: 1.5771, Accuracy: 3360/5000 (67%)\n",
      "[epoch 7] loss: 0.0064780\n",
      "Test set: Average loss: 1.6213, Accuracy: 3359/5000 (67%)\n",
      "[epoch 8] loss: 0.0041349\n",
      "Test set: Average loss: 1.6701, Accuracy: 3361/5000 (67%)\n",
      "[epoch 9] loss: 0.0025934\n",
      "Test set: Average loss: 1.7317, Accuracy: 3365/5000 (67%)\n",
      "[epoch 10] loss: 0.0015899\n",
      "Test set: Average loss: 1.7990, Accuracy: 3358/5000 (67%)\n",
      "[epoch 11] loss: 0.0009572\n",
      "Test set: Average loss: 1.8698, Accuracy: 3382/5000 (68%)\n",
      "[epoch 12] loss: 0.0005679\n",
      "Test set: Average loss: 1.9481, Accuracy: 3370/5000 (67%)\n",
      "[epoch 13] loss: 0.0003344\n",
      "Test set: Average loss: 2.0247, Accuracy: 3362/5000 (67%)\n",
      "[epoch 14] loss: 0.0001944\n",
      "Test set: Average loss: 2.1011, Accuracy: 3370/5000 (67%)\n",
      "[epoch 15] loss: 0.0001122\n",
      "Test set: Average loss: 2.1915, Accuracy: 3368/5000 (67%)\n",
      "[epoch 16] loss: 0.0000646\n",
      "Test set: Average loss: 2.2726, Accuracy: 3361/5000 (67%)\n",
      "[epoch 17] loss: 0.0000367\n",
      "Test set: Average loss: 2.3673, Accuracy: 3374/5000 (67%)\n",
      "[epoch 18] loss: 0.0000208\n",
      "Test set: Average loss: 2.4485, Accuracy: 3368/5000 (67%)\n",
      "[epoch 19] loss: 0.0000119\n",
      "Test set: Average loss: 2.5456, Accuracy: 3367/5000 (67%)\n",
      "[epoch 20] loss: 0.0000067\n",
      "Test set: Average loss: 2.6348, Accuracy: 3369/5000 (67%)\n",
      "[epoch 21] loss: 0.0000037\n",
      "Test set: Average loss: 2.7222, Accuracy: 3364/5000 (67%)\n",
      "[epoch 22] loss: 0.0000021\n",
      "Test set: Average loss: 2.8078, Accuracy: 3367/5000 (67%)\n",
      "[epoch 23] loss: 0.0000012\n",
      "Test set: Average loss: 2.8924, Accuracy: 3360/5000 (67%)\n",
      "[epoch 24] loss: 0.0000006\n",
      "Test set: Average loss: 2.9507, Accuracy: 3358/5000 (67%)\n",
      "[epoch 25] loss: 0.0000004\n",
      "Test set: Average loss: 2.9971, Accuracy: 3356/5000 (67%)\n",
      "[epoch 26] loss: 0.0000002\n",
      "Test set: Average loss: 3.0233, Accuracy: 3356/5000 (67%)\n",
      "[epoch 27] loss: 0.0001660\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.1351, Accuracy: 3317/5000 (66%)\n",
      "[epoch 28] loss: 0.0002696\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0881, Accuracy: 3345/5000 (67%)\n",
      "[epoch 29] loss: 0.0000380\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 30] loss: 0.0000366\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 31] loss: 0.0000365\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 32] loss: 0.0000364\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 33] loss: 0.0000364\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 34] loss: 0.0000364\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0000364\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 36] loss: 0.0000364\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 37] loss: 0.0000364\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 38] loss: 0.0000364\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 39] loss: 0.0000364\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 40] loss: 0.0000364\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 41] loss: 0.0000364\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 42] loss: 0.0000364\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 43] loss: 0.0000364\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 44] loss: 0.0000364\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 45] loss: 0.0000364\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 46] loss: 0.0000364\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 47] loss: 0.0000364\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 48] loss: 0.0000364\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 49] loss: 0.0000364\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "[epoch 50] loss: 0.0000364\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 3.0877, Accuracy: 3346/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8698, Accuracy: 3382/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.8578, Accuracy: 6797/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3583, Accuracy: 595/5000 (12%)\n",
      "[epoch 1] loss: 0.2822559\n",
      "Test set: Average loss: 1.3013, Accuracy: 3278/5000 (66%)\n",
      "[epoch 2] loss: 0.1567135\n",
      "Test set: Average loss: 1.5220, Accuracy: 3241/5000 (65%)\n",
      "[epoch 3] loss: 0.1326394\n",
      "Test set: Average loss: 1.6343, Accuracy: 3234/5000 (65%)\n",
      "[epoch 4] loss: 0.1535991\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6850, Accuracy: 3247/5000 (65%)\n",
      "[epoch 5] loss: 0.0494578\n",
      "Test set: Average loss: 1.6137, Accuracy: 3330/5000 (67%)\n",
      "[epoch 6] loss: 0.0159415\n",
      "Test set: Average loss: 1.6374, Accuracy: 3337/5000 (67%)\n",
      "[epoch 7] loss: 0.0091148\n",
      "Test set: Average loss: 1.6613, Accuracy: 3339/5000 (67%)\n",
      "[epoch 8] loss: 0.0058304\n",
      "Test set: Average loss: 1.7022, Accuracy: 3341/5000 (67%)\n",
      "[epoch 9] loss: 0.0037669\n",
      "Test set: Average loss: 1.7500, Accuracy: 3361/5000 (67%)\n",
      "[epoch 10] loss: 0.0023947\n",
      "Test set: Average loss: 1.8086, Accuracy: 3362/5000 (67%)\n",
      "[epoch 11] loss: 0.0014901\n",
      "Test set: Average loss: 1.8706, Accuracy: 3365/5000 (67%)\n",
      "[epoch 12] loss: 0.0009078\n",
      "Test set: Average loss: 1.9461, Accuracy: 3355/5000 (67%)\n",
      "[epoch 13] loss: 0.0005477\n",
      "Test set: Average loss: 2.0088, Accuracy: 3363/5000 (67%)\n",
      "[epoch 14] loss: 0.0003239\n",
      "Test set: Average loss: 2.0869, Accuracy: 3364/5000 (67%)\n",
      "[epoch 15] loss: 0.0001908\n",
      "Test set: Average loss: 2.1717, Accuracy: 3368/5000 (67%)\n",
      "[epoch 16] loss: 0.0001107\n",
      "Test set: Average loss: 2.2585, Accuracy: 3383/5000 (68%)\n",
      "[epoch 17] loss: 0.0000641\n",
      "Test set: Average loss: 2.3433, Accuracy: 3377/5000 (68%)\n",
      "[epoch 18] loss: 0.0000366\n",
      "Test set: Average loss: 2.4238, Accuracy: 3378/5000 (68%)\n",
      "[epoch 19] loss: 0.0000209\n",
      "Test set: Average loss: 2.5184, Accuracy: 3379/5000 (68%)\n",
      "[epoch 20] loss: 0.0000119\n",
      "Test set: Average loss: 2.6065, Accuracy: 3368/5000 (67%)\n",
      "[epoch 21] loss: 0.0000067\n",
      "Test set: Average loss: 2.6995, Accuracy: 3375/5000 (68%)\n",
      "[epoch 22] loss: 0.0000038\n",
      "Test set: Average loss: 2.7895, Accuracy: 3368/5000 (67%)\n",
      "[epoch 23] loss: 0.0000021\n",
      "Test set: Average loss: 2.8765, Accuracy: 3361/5000 (67%)\n",
      "[epoch 24] loss: 0.0000012\n",
      "Test set: Average loss: 2.9524, Accuracy: 3360/5000 (67%)\n",
      "[epoch 25] loss: 0.0000007\n",
      "Test set: Average loss: 3.0221, Accuracy: 3357/5000 (67%)\n",
      "[epoch 26] loss: 0.0000004\n",
      "Test set: Average loss: 3.0571, Accuracy: 3356/5000 (67%)\n",
      "[epoch 27] loss: 0.0000002\n",
      "Test set: Average loss: 3.0817, Accuracy: 3355/5000 (67%)\n",
      "[epoch 28] loss: 0.0000002\n",
      "Test set: Average loss: 3.0828, Accuracy: 3344/5000 (67%)\n",
      "[epoch 29] loss: 0.0000002\n",
      "Test set: Average loss: 3.1087, Accuracy: 3354/5000 (67%)\n",
      "[epoch 30] loss: 0.0000001\n",
      "Test set: Average loss: 3.1297, Accuracy: 3340/5000 (67%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.1342, Accuracy: 3337/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.1548, Accuracy: 3331/5000 (67%)\n",
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.1783, Accuracy: 3340/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 3.1978, Accuracy: 3339/5000 (67%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 3.2277, Accuracy: 3343/5000 (67%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 3.2389, Accuracy: 3331/5000 (67%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2624, Accuracy: 3333/5000 (67%)\n",
      "[epoch 38] loss: 0.0000000\n",
      "Test set: Average loss: 3.2426, Accuracy: 3326/5000 (67%)\n",
      "[epoch 39] loss: 0.0000000\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2364, Accuracy: 3332/5000 (67%)\n",
      "[epoch 40] loss: 0.0000000\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2342, Accuracy: 3332/5000 (67%)\n",
      "[epoch 41] loss: 0.0000000\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 43] loss: 0.0000000\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.2340, Accuracy: 3332/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2585, Accuracy: 3383/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.2039, Accuracy: 6743/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4206, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 0.2839021\n",
      "Test set: Average loss: 1.3418, Accuracy: 3259/5000 (65%)\n",
      "[epoch 2] loss: 0.1503823\n",
      "Test set: Average loss: 1.4818, Accuracy: 3222/5000 (64%)\n",
      "[epoch 3] loss: 0.1418296\n",
      "Test set: Average loss: 1.5886, Accuracy: 3278/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 0.1352412\n",
      "Test set: Average loss: 1.7140, Accuracy: 3227/5000 (65%)\n",
      "[epoch 5] loss: 0.1418447\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7766, Accuracy: 3223/5000 (64%)\n",
      "[epoch 6] loss: 0.0532027\n",
      "Test set: Average loss: 1.6777, Accuracy: 3283/5000 (66%)\n",
      "[epoch 7] loss: 0.0161599\n",
      "Test set: Average loss: 1.7035, Accuracy: 3289/5000 (66%)\n",
      "[epoch 8] loss: 0.0087312\n",
      "Test set: Average loss: 1.7281, Accuracy: 3299/5000 (66%)\n",
      "[epoch 9] loss: 0.0055680\n",
      "Test set: Average loss: 1.7590, Accuracy: 3295/5000 (66%)\n",
      "[epoch 10] loss: 0.0036175\n",
      "Test set: Average loss: 1.8061, Accuracy: 3312/5000 (66%)\n",
      "[epoch 11] loss: 0.0023189\n",
      "Test set: Average loss: 1.8579, Accuracy: 3317/5000 (66%)\n",
      "[epoch 12] loss: 0.0014520\n",
      "Test set: Average loss: 1.9111, Accuracy: 3325/5000 (66%)\n",
      "[epoch 13] loss: 0.0008958\n",
      "Test set: Average loss: 1.9730, Accuracy: 3338/5000 (67%)\n",
      "[epoch 14] loss: 0.0005414\n",
      "Test set: Average loss: 2.0369, Accuracy: 3338/5000 (67%)\n",
      "[epoch 15] loss: 0.0003237\n",
      "Test set: Average loss: 2.1120, Accuracy: 3337/5000 (67%)\n",
      "[epoch 16] loss: 0.0001920\n",
      "Test set: Average loss: 2.1827, Accuracy: 3341/5000 (67%)\n",
      "[epoch 17] loss: 0.0001122\n",
      "Test set: Average loss: 2.2566, Accuracy: 3351/5000 (67%)\n",
      "[epoch 18] loss: 0.0000654\n",
      "Test set: Average loss: 2.3433, Accuracy: 3351/5000 (67%)\n",
      "[epoch 19] loss: 0.0000378\n",
      "Test set: Average loss: 2.4224, Accuracy: 3355/5000 (67%)\n",
      "[epoch 20] loss: 0.0000216\n",
      "Test set: Average loss: 2.5078, Accuracy: 3365/5000 (67%)\n",
      "[epoch 21] loss: 0.0000124\n",
      "Test set: Average loss: 2.5977, Accuracy: 3360/5000 (67%)\n",
      "[epoch 22] loss: 0.0000071\n",
      "Test set: Average loss: 2.6706, Accuracy: 3362/5000 (67%)\n",
      "[epoch 23] loss: 0.0000040\n",
      "Test set: Average loss: 2.7573, Accuracy: 3370/5000 (67%)\n",
      "[epoch 24] loss: 0.0000023\n",
      "Test set: Average loss: 2.8441, Accuracy: 3359/5000 (67%)\n",
      "[epoch 25] loss: 0.0000013\n",
      "Test set: Average loss: 2.9230, Accuracy: 3358/5000 (67%)\n",
      "[epoch 26] loss: 0.0000007\n",
      "Test set: Average loss: 2.9865, Accuracy: 3353/5000 (67%)\n",
      "[epoch 27] loss: 0.0000004\n",
      "Test set: Average loss: 3.0166, Accuracy: 3358/5000 (67%)\n",
      "[epoch 28] loss: 0.0000002\n",
      "Test set: Average loss: 3.0432, Accuracy: 3343/5000 (67%)\n",
      "[epoch 29] loss: 0.0000002\n",
      "Test set: Average loss: 3.0535, Accuracy: 3337/5000 (67%)\n",
      "[epoch 30] loss: 0.0000002\n",
      "Test set: Average loss: 3.0702, Accuracy: 3329/5000 (67%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.0817, Accuracy: 3345/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.0979, Accuracy: 3324/5000 (66%)\n",
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.1111, Accuracy: 3325/5000 (66%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 3.1248, Accuracy: 3321/5000 (66%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Test set: Average loss: 3.1613, Accuracy: 3314/5000 (66%)\n",
      "[epoch 36] loss: 0.0000001\n",
      "Test set: Average loss: 3.1805, Accuracy: 3314/5000 (66%)\n",
      "[epoch 37] loss: 0.0000001\n",
      "Test set: Average loss: 3.1923, Accuracy: 3324/5000 (66%)\n",
      "[epoch 38] loss: 0.0000001\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2178, Accuracy: 3320/5000 (66%)\n",
      "[epoch 39] loss: 0.0000000\n",
      "Test set: Average loss: 3.1965, Accuracy: 3313/5000 (66%)\n",
      "[epoch 40] loss: 0.0000000\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.1905, Accuracy: 3307/5000 (66%)\n",
      "[epoch 41] loss: 0.0000000\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.1878, Accuracy: 3311/5000 (66%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 43] loss: 0.0000000\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.1877, Accuracy: 3313/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7573, Accuracy: 3370/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.7347, Accuracy: 6720/10000 (67%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3858, Accuracy: 504/5000 (10%)\n",
      "[epoch 1] loss: 0.2773829\n",
      "Test set: Average loss: 1.3326, Accuracy: 3278/5000 (66%)\n",
      "[epoch 2] loss: 0.1631602\n",
      "Test set: Average loss: 1.5267, Accuracy: 3235/5000 (65%)\n",
      "[epoch 3] loss: 0.1427735\n",
      "Test set: Average loss: 1.7036, Accuracy: 3189/5000 (64%)\n",
      "[epoch 4] loss: 0.1442402\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7329, Accuracy: 3222/5000 (64%)\n",
      "[epoch 5] loss: 0.0538186\n",
      "Test set: Average loss: 1.6364, Accuracy: 3325/5000 (66%)\n",
      "[epoch 6] loss: 0.0162221\n",
      "Test set: Average loss: 1.6628, Accuracy: 3318/5000 (66%)\n",
      "[epoch 7] loss: 0.0088361\n",
      "Test set: Average loss: 1.6968, Accuracy: 3325/5000 (66%)\n",
      "[epoch 8] loss: 0.0054287\n",
      "Test set: Average loss: 1.7451, Accuracy: 3345/5000 (67%)\n",
      "[epoch 9] loss: 0.0033527\n",
      "Test set: Average loss: 1.7904, Accuracy: 3346/5000 (67%)\n",
      "[epoch 10] loss: 0.0020258\n",
      "Test set: Average loss: 1.8573, Accuracy: 3353/5000 (67%)\n",
      "[epoch 11] loss: 0.0011980\n",
      "Test set: Average loss: 1.9255, Accuracy: 3338/5000 (67%)\n",
      "[epoch 12] loss: 0.0006914\n",
      "Test set: Average loss: 2.0076, Accuracy: 3356/5000 (67%)\n",
      "[epoch 13] loss: 0.0003945\n",
      "Test set: Average loss: 2.0852, Accuracy: 3342/5000 (67%)\n",
      "[epoch 14] loss: 0.0002213\n",
      "Test set: Average loss: 2.1686, Accuracy: 3354/5000 (67%)\n",
      "[epoch 15] loss: 0.0001228\n",
      "Test set: Average loss: 2.2596, Accuracy: 3353/5000 (67%)\n",
      "[epoch 16] loss: 0.0000679\n",
      "Test set: Average loss: 2.3525, Accuracy: 3350/5000 (67%)\n",
      "[epoch 17] loss: 0.0000370\n",
      "Test set: Average loss: 2.4447, Accuracy: 3347/5000 (67%)\n",
      "[epoch 18] loss: 0.0000200\n",
      "Test set: Average loss: 2.5438, Accuracy: 3346/5000 (67%)\n",
      "[epoch 19] loss: 0.0000108\n",
      "Test set: Average loss: 2.6415, Accuracy: 3338/5000 (67%)\n",
      "[epoch 20] loss: 0.0000058\n",
      "Test set: Average loss: 2.7444, Accuracy: 3337/5000 (67%)\n",
      "[epoch 21] loss: 0.0000031\n",
      "Test set: Average loss: 2.8424, Accuracy: 3343/5000 (67%)\n",
      "[epoch 22] loss: 0.0000016\n",
      "Test set: Average loss: 2.9387, Accuracy: 3343/5000 (67%)\n",
      "[epoch 23] loss: 0.0000009\n",
      "Test set: Average loss: 3.0244, Accuracy: 3339/5000 (67%)\n",
      "[epoch 24] loss: 0.0000005\n",
      "Test set: Average loss: 3.0719, Accuracy: 3339/5000 (67%)\n",
      "[epoch 25] loss: 0.0000003\n",
      "Test set: Average loss: 3.1046, Accuracy: 3340/5000 (67%)\n",
      "[epoch 26] loss: 0.0000002\n",
      "Test set: Average loss: 3.1162, Accuracy: 3346/5000 (67%)\n",
      "[epoch 27] loss: 0.0000001\n",
      "Test set: Average loss: 3.1433, Accuracy: 3323/5000 (66%)\n",
      "[epoch 28] loss: 0.0000001\n",
      "Test set: Average loss: 3.1704, Accuracy: 3327/5000 (67%)\n",
      "[epoch 29] loss: 0.0000001\n",
      "Test set: Average loss: 3.1821, Accuracy: 3314/5000 (66%)\n",
      "[epoch 30] loss: 0.0000001\n",
      "Test set: Average loss: 3.2024, Accuracy: 3324/5000 (66%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.2222, Accuracy: 3337/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.2721, Accuracy: 3296/5000 (66%)\n",
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.2771, Accuracy: 3301/5000 (66%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Test set: Average loss: 3.2974, Accuracy: 3313/5000 (66%)\n",
      "[epoch 35] loss: 0.0000001\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.3219, Accuracy: 3304/5000 (66%)\n",
      "[epoch 36] loss: 0.0000000\n",
      "Test set: Average loss: 3.3036, Accuracy: 3308/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] loss: 0.0000000\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.3017, Accuracy: 3306/5000 (66%)\n",
      "[epoch 38] loss: 0.0000000\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2959, Accuracy: 3302/5000 (66%)\n",
      "[epoch 39] loss: 0.0000000\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 40] loss: 0.0000000\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 41] loss: 0.0000000\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 43] loss: 0.0000000\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.2956, Accuracy: 3303/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0076, Accuracy: 3356/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.9688, Accuracy: 6790/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.4449, Accuracy: 652/5000 (13%)\n",
      "[epoch 1] loss: 0.2821073\n",
      "Test set: Average loss: 1.3234, Accuracy: 3299/5000 (66%)\n",
      "[epoch 2] loss: 0.1568212\n",
      "Test set: Average loss: 1.5237, Accuracy: 3234/5000 (65%)\n",
      "[epoch 3] loss: 0.1587326\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6633, Accuracy: 3197/5000 (64%)\n",
      "[epoch 4] loss: 0.0598460\n",
      "Test set: Average loss: 1.5356, Accuracy: 3337/5000 (67%)\n",
      "[epoch 5] loss: 0.0197480\n",
      "Test set: Average loss: 1.5720, Accuracy: 3337/5000 (67%)\n",
      "[epoch 6] loss: 0.0109097\n",
      "Test set: Average loss: 1.6101, Accuracy: 3349/5000 (67%)\n",
      "[epoch 7] loss: 0.0066151\n",
      "Test set: Average loss: 1.6531, Accuracy: 3361/5000 (67%)\n",
      "[epoch 8] loss: 0.0040151\n",
      "Test set: Average loss: 1.7166, Accuracy: 3368/5000 (67%)\n",
      "[epoch 9] loss: 0.0023922\n",
      "Test set: Average loss: 1.7856, Accuracy: 3357/5000 (67%)\n",
      "[epoch 10] loss: 0.0014002\n",
      "Test set: Average loss: 1.8679, Accuracy: 3370/5000 (67%)\n",
      "[epoch 11] loss: 0.0007992\n",
      "Test set: Average loss: 1.9475, Accuracy: 3365/5000 (67%)\n",
      "[epoch 12] loss: 0.0004551\n",
      "Test set: Average loss: 2.0339, Accuracy: 3373/5000 (67%)\n",
      "[epoch 13] loss: 0.0002517\n",
      "Test set: Average loss: 2.1163, Accuracy: 3387/5000 (68%)\n",
      "[epoch 14] loss: 0.0001391\n",
      "Test set: Average loss: 2.2182, Accuracy: 3379/5000 (68%)\n",
      "[epoch 15] loss: 0.0000766\n",
      "Test set: Average loss: 2.3112, Accuracy: 3389/5000 (68%)\n",
      "[epoch 16] loss: 0.0000414\n",
      "Test set: Average loss: 2.4144, Accuracy: 3383/5000 (68%)\n",
      "[epoch 17] loss: 0.0000223\n",
      "Test set: Average loss: 2.5131, Accuracy: 3382/5000 (68%)\n",
      "[epoch 18] loss: 0.0000120\n",
      "Test set: Average loss: 2.6159, Accuracy: 3379/5000 (68%)\n",
      "[epoch 19] loss: 0.0000064\n",
      "Test set: Average loss: 2.7145, Accuracy: 3368/5000 (67%)\n",
      "[epoch 20] loss: 0.0000034\n",
      "Test set: Average loss: 2.8120, Accuracy: 3369/5000 (67%)\n",
      "[epoch 21] loss: 0.0000018\n",
      "Test set: Average loss: 2.9109, Accuracy: 3367/5000 (67%)\n",
      "[epoch 22] loss: 0.0000009\n",
      "Test set: Average loss: 3.0051, Accuracy: 3374/5000 (67%)\n",
      "[epoch 23] loss: 0.0000005\n",
      "Test set: Average loss: 3.0666, Accuracy: 3372/5000 (67%)\n",
      "[epoch 24] loss: 0.0000003\n",
      "Test set: Average loss: 3.0922, Accuracy: 3368/5000 (67%)\n",
      "[epoch 25] loss: 0.0000002\n",
      "Test set: Average loss: 3.1164, Accuracy: 3365/5000 (67%)\n",
      "[epoch 26] loss: 0.0000002\n",
      "Test set: Average loss: 3.1247, Accuracy: 3368/5000 (67%)\n",
      "[epoch 27] loss: 0.0000001\n",
      "Test set: Average loss: 3.1498, Accuracy: 3361/5000 (67%)\n",
      "[epoch 28] loss: 0.0000001\n",
      "Test set: Average loss: 3.1510, Accuracy: 3358/5000 (67%)\n",
      "[epoch 29] loss: 0.0000001\n",
      "Test set: Average loss: 3.1779, Accuracy: 3350/5000 (67%)\n",
      "[epoch 30] loss: 0.0000001\n",
      "Test set: Average loss: 3.1954, Accuracy: 3351/5000 (67%)\n",
      "[epoch 31] loss: 0.0000001\n",
      "Test set: Average loss: 3.2132, Accuracy: 3348/5000 (67%)\n",
      "[epoch 32] loss: 0.0000001\n",
      "Test set: Average loss: 3.2366, Accuracy: 3346/5000 (67%)\n",
      "[epoch 33] loss: 0.0000001\n",
      "Test set: Average loss: 3.2763, Accuracy: 3340/5000 (67%)\n",
      "[epoch 34] loss: 0.0000001\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2866, Accuracy: 3337/5000 (67%)\n",
      "[epoch 35] loss: 0.0000000\n",
      "Test set: Average loss: 3.2651, Accuracy: 3338/5000 (67%)\n",
      "[epoch 36] loss: 0.0000000\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2556, Accuracy: 3336/5000 (67%)\n",
      "[epoch 37] loss: 0.0000000\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2545, Accuracy: 3339/5000 (67%)\n",
      "[epoch 38] loss: 0.0000000\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 39] loss: 0.0000000\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 40] loss: 0.0000000\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 41] loss: 0.0000000\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 42] loss: 0.0000000\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 43] loss: 0.0000000\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 44] loss: 0.0000000\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 45] loss: 0.0000000\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 46] loss: 0.0000000\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 47] loss: 0.0000000\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 48] loss: 0.0000000\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 49] loss: 0.0000000\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "[epoch 50] loss: 0.0000000\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.2544, Accuracy: 3340/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3112, Accuracy: 3389/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.2705, Accuracy: 6804/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3874, Accuracy: 512/5000 (10%)\n",
      "[epoch 1] loss: 0.2874337\n",
      "Test set: Average loss: 1.3376, Accuracy: 3266/5000 (65%)\n",
      "[epoch 2] loss: 0.1527242\n",
      "Test set: Average loss: 1.5981, Accuracy: 3192/5000 (64%)\n",
      "[epoch 3] loss: 0.1556852\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6423, Accuracy: 3209/5000 (64%)\n",
      "[epoch 4] loss: 0.0572587\n",
      "Test set: Average loss: 1.5468, Accuracy: 3328/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 0.0188949\n",
      "Test set: Average loss: 1.5695, Accuracy: 3342/5000 (67%)\n",
      "[epoch 6] loss: 0.0104141\n",
      "Test set: Average loss: 1.6134, Accuracy: 3337/5000 (67%)\n",
      "[epoch 7] loss: 0.0063080\n",
      "Test set: Average loss: 1.6572, Accuracy: 3344/5000 (67%)\n",
      "[epoch 8] loss: 0.0038454\n",
      "Test set: Average loss: 1.7200, Accuracy: 3355/5000 (67%)\n",
      "[epoch 9] loss: 0.0022934\n",
      "Test set: Average loss: 1.7857, Accuracy: 3364/5000 (67%)\n",
      "[epoch 10] loss: 0.0013349\n",
      "Test set: Average loss: 1.8572, Accuracy: 3363/5000 (67%)\n",
      "[epoch 11] loss: 0.0007694\n",
      "Test set: Average loss: 1.9445, Accuracy: 3364/5000 (67%)\n",
      "[epoch 12] loss: 0.0004350\n",
      "Test set: Average loss: 2.0285, Accuracy: 3377/5000 (68%)\n",
      "[epoch 13] loss: 0.0002417\n",
      "Test set: Average loss: 2.1257, Accuracy: 3367/5000 (67%)\n",
      "[epoch 14] loss: 0.0001336\n",
      "Test set: Average loss: 2.2246, Accuracy: 3366/5000 (67%)\n",
      "[epoch 15] loss: 0.0000729\n",
      "Test set: Average loss: 2.3167, Accuracy: 3373/5000 (67%)\n",
      "[epoch 16] loss: 0.0000398\n",
      "Test set: Average loss: 2.4151, Accuracy: 3370/5000 (67%)\n",
      "[epoch 17] loss: 0.0000214\n",
      "Test set: Average loss: 2.5176, Accuracy: 3374/5000 (67%)\n",
      "[epoch 18] loss: 0.0000115\n",
      "Test set: Average loss: 2.6181, Accuracy: 3362/5000 (67%)\n",
      "[epoch 19] loss: 0.0000061\n",
      "Test set: Average loss: 2.7251, Accuracy: 3372/5000 (67%)\n",
      "[epoch 20] loss: 0.0000033\n",
      "Test set: Average loss: 2.8229, Accuracy: 3358/5000 (67%)\n",
      "[epoch 21] loss: 0.0000017\n",
      "Test set: Average loss: 2.9183, Accuracy: 3362/5000 (67%)\n",
      "[epoch 22] loss: 0.0000009\n",
      "Test set: Average loss: 3.0068, Accuracy: 3356/5000 (67%)\n",
      "[epoch 23] loss: 0.0000005\n",
      "Test set: Average loss: 3.0612, Accuracy: 3358/5000 (67%)\n",
      "[epoch 24] loss: 0.0000003\n",
      "Test set: Average loss: 3.0930, Accuracy: 3359/5000 (67%)\n",
      "[epoch 25] loss: 0.0000002\n",
      "Test set: Average loss: 3.1074, Accuracy: 3349/5000 (67%)\n",
      "[epoch 26] loss: 0.0000002\n",
      "Test set: Average loss: 3.1331, Accuracy: 3350/5000 (67%)\n",
      "[epoch 27] loss: 0.0000001\n",
      "Test set: Average loss: 3.1663, Accuracy: 3347/5000 (67%)\n",
      "[epoch 28] loss: 0.0010957\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2256, Accuracy: 3325/5000 (66%)\n",
      "[epoch 29] loss: 0.0003636\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2221, Accuracy: 3324/5000 (66%)\n",
      "[epoch 30] loss: 0.0000509\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2213, Accuracy: 3324/5000 (66%)\n",
      "[epoch 31] loss: 0.0000478\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 32] loss: 0.0000475\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 33] loss: 0.0000474\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 34] loss: 0.0000478\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 35] loss: 0.0000474\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 36] loss: 0.0000474\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 37] loss: 0.0000474\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 38] loss: 0.0000475\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 39] loss: 0.0000474\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 40] loss: 0.0000474\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 41] loss: 0.0000475\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 42] loss: 0.0000474\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 43] loss: 0.0000474\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 44] loss: 0.0215909\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 45] loss: 0.0000474\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 46] loss: 0.0000474\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 47] loss: 0.0000474\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 48] loss: 0.0000474\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 49] loss: 0.0000474\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "[epoch 50] loss: 0.0000474\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 3.2212, Accuracy: 3324/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0285, Accuracy: 3377/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.0026, Accuracy: 6769/10000 (68%)\n"
     ]
    }
   ],
   "source": [
    "# CLF pretraining on actual task\n",
    "cnn = CNN()\n",
    "model = CLF(cnn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=0, eps=0., verbose=True)\n",
    "for epoch in range(50):\n",
    "    train_clf(model, epoch, train_loader_all, optimizer, lr_scheduler)\n",
    "test_acc = test_clf(model, test_loader_all)\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.cnn.state_dict())\n",
    "test_accuracies_clf_pt = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_clf_pt.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining with an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T06:49:34.511749Z",
     "start_time": "2019-07-24T04:07:28.731907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.3634853\n",
      "[epoch 2] loss: 0.1982109\n",
      "[epoch 3] loss: 0.1617943\n",
      "[epoch 4] loss: 0.1370626\n",
      "[epoch 5] loss: 0.1230806\n",
      "[epoch 6] loss: 0.1145815\n",
      "[epoch 7] loss: 0.1076624\n",
      "[epoch 8] loss: 0.1029501\n",
      "[epoch 9] loss: 0.0981396\n",
      "[epoch 10] loss: 0.0949685\n",
      "[epoch 11] loss: 0.0930394\n",
      "[epoch 12] loss: 0.0907666\n",
      "[epoch 13] loss: 0.0898418\n",
      "[epoch 14] loss: 0.0904966\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[epoch 15] loss: 0.0793299\n",
      "[epoch 16] loss: 0.0781145\n",
      "[epoch 17] loss: 0.0775784\n",
      "[epoch 18] loss: 0.0780930\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[epoch 19] loss: 0.0770422\n",
      "[epoch 20] loss: 0.0768268\n",
      "[epoch 21] loss: 0.0766996\n",
      "[epoch 22] loss: 0.0766409\n",
      "[epoch 23] loss: 0.0765794\n",
      "[epoch 24] loss: 0.0766285\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-06.\n",
      "[epoch 25] loss: 0.0765190\n",
      "[epoch 26] loss: 0.0764977\n",
      "[epoch 27] loss: 0.0764860\n",
      "[epoch 28] loss: 0.0764847\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-07.\n",
      "[epoch 29] loss: 0.0764462\n",
      "[epoch 30] loss: 0.0764374\n",
      "[epoch 31] loss: 0.0764607\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-08.\n",
      "[epoch 32] loss: 0.0764444\n",
      "[epoch 33] loss: 0.0764448\n",
      "[epoch 34] loss: 0.0764479\n",
      "[epoch 35] loss: 0.0764372\n",
      "[epoch 36] loss: 0.0764344\n",
      "[epoch 37] loss: 0.0764572\n",
      "[epoch 38] loss: 0.0764594\n",
      "[epoch 39] loss: 0.0764538\n",
      "[epoch 40] loss: 0.0764366\n",
      "[epoch 41] loss: 0.0764363\n",
      "[epoch 42] loss: 0.0764410\n",
      "[epoch 43] loss: 0.0764493\n",
      "[epoch 44] loss: 0.0764399\n",
      "[epoch 45] loss: 0.0764398\n",
      "[epoch 46] loss: 0.0764379\n",
      "[epoch 47] loss: 0.0764400\n",
      "[epoch 48] loss: 0.0764411\n",
      "[epoch 49] loss: 0.0764412\n",
      "[epoch 50] loss: 0.0764461\n",
      "Took 459 sec to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3059, Accuracy: 496/5000 (10%)\n",
      "[epoch 1] loss: 2.2917123\n",
      "Test set: Average loss: 2.3051, Accuracy: 481/5000 (10%)\n",
      "[epoch 2] loss: 2.2075548\n",
      "Test set: Average loss: 2.3172, Accuracy: 479/5000 (10%)\n",
      "[epoch 3] loss: 2.0966527\n",
      "Test set: Average loss: 2.3695, Accuracy: 478/5000 (10%)\n",
      "[epoch 4] loss: 1.9452251\n",
      "Test set: Average loss: 2.5162, Accuracy: 482/5000 (10%)\n",
      "[epoch 5] loss: 1.7895703\n",
      "Test set: Average loss: 2.6490, Accuracy: 614/5000 (12%)\n",
      "[epoch 6] loss: 1.6138104\n",
      "Test set: Average loss: 2.6823, Accuracy: 722/5000 (14%)\n",
      "[epoch 7] loss: 1.3870378\n",
      "Test set: Average loss: 2.6961, Accuracy: 767/5000 (15%)\n",
      "[epoch 8] loss: 1.1505725\n",
      "Test set: Average loss: 2.7468, Accuracy: 774/5000 (15%)\n",
      "[epoch 9] loss: 0.9184383\n",
      "Test set: Average loss: 2.8699, Accuracy: 767/5000 (15%)\n",
      "[epoch 10] loss: 0.6989800\n",
      "Test set: Average loss: 3.0777, Accuracy: 742/5000 (15%)\n",
      "[epoch 11] loss: 0.5116541\n",
      "Test set: Average loss: 3.3306, Accuracy: 742/5000 (15%)\n",
      "[epoch 12] loss: 0.3590814\n",
      "Test set: Average loss: 3.5843, Accuracy: 743/5000 (15%)\n",
      "[epoch 13] loss: 0.2359776\n",
      "Test set: Average loss: 3.8477, Accuracy: 749/5000 (15%)\n",
      "[epoch 14] loss: 0.1500967\n",
      "Test set: Average loss: 4.1427, Accuracy: 759/5000 (15%)\n",
      "[epoch 15] loss: 0.1024984\n",
      "Test set: Average loss: 4.4330, Accuracy: 779/5000 (16%)\n",
      "[epoch 16] loss: 0.0691681\n",
      "Test set: Average loss: 4.6979, Accuracy: 797/5000 (16%)\n",
      "[epoch 17] loss: 0.0423969\n",
      "Test set: Average loss: 4.9465, Accuracy: 806/5000 (16%)\n",
      "[epoch 18] loss: 0.0268196\n",
      "Test set: Average loss: 5.1771, Accuracy: 810/5000 (16%)\n",
      "[epoch 19] loss: 0.0180735\n",
      "Test set: Average loss: 5.3840, Accuracy: 814/5000 (16%)\n",
      "[epoch 20] loss: 0.0121253\n",
      "Test set: Average loss: 5.5677, Accuracy: 818/5000 (16%)\n",
      "[epoch 21] loss: 0.0078721\n",
      "Test set: Average loss: 5.7331, Accuracy: 823/5000 (16%)\n",
      "[epoch 22] loss: 0.0051485\n",
      "Test set: Average loss: 5.8842, Accuracy: 821/5000 (16%)\n",
      "[epoch 23] loss: 0.0035653\n",
      "Test set: Average loss: 6.0233, Accuracy: 817/5000 (16%)\n",
      "[epoch 24] loss: 0.0026631\n",
      "Test set: Average loss: 6.1514, Accuracy: 814/5000 (16%)\n",
      "[epoch 25] loss: 0.0021256\n",
      "Test set: Average loss: 6.2691, Accuracy: 811/5000 (16%)\n",
      "[epoch 26] loss: 0.0017785\n",
      "Test set: Average loss: 6.3771, Accuracy: 810/5000 (16%)\n",
      "[epoch 27] loss: 0.0015336\n",
      "Test set: Average loss: 6.4759, Accuracy: 810/5000 (16%)\n",
      "[epoch 28] loss: 0.0013454\n",
      "Test set: Average loss: 6.5662, Accuracy: 809/5000 (16%)\n",
      "[epoch 29] loss: 0.0011902\n",
      "Test set: Average loss: 6.6485, Accuracy: 809/5000 (16%)\n",
      "[epoch 30] loss: 0.0010573\n",
      "Test set: Average loss: 6.7236, Accuracy: 806/5000 (16%)\n",
      "[epoch 31] loss: 0.0009400\n",
      "Test set: Average loss: 6.7920, Accuracy: 808/5000 (16%)\n",
      "[epoch 32] loss: 0.0008358\n",
      "Test set: Average loss: 6.8544, Accuracy: 806/5000 (16%)\n",
      "[epoch 33] loss: 0.0007431\n",
      "Test set: Average loss: 6.9113, Accuracy: 806/5000 (16%)\n",
      "[epoch 34] loss: 0.0006611\n",
      "Test set: Average loss: 6.9632, Accuracy: 807/5000 (16%)\n",
      "[epoch 35] loss: 0.0005892\n",
      "Test set: Average loss: 7.0107, Accuracy: 805/5000 (16%)\n",
      "[epoch 36] loss: 0.0005265\n",
      "Test set: Average loss: 7.0541, Accuracy: 805/5000 (16%)\n",
      "[epoch 37] loss: 0.0004721\n",
      "Test set: Average loss: 7.0939, Accuracy: 804/5000 (16%)\n",
      "[epoch 38] loss: 0.0004253\n",
      "Test set: Average loss: 7.1303, Accuracy: 802/5000 (16%)\n",
      "[epoch 39] loss: 0.0003851\n",
      "Test set: Average loss: 7.1636, Accuracy: 799/5000 (16%)\n",
      "[epoch 40] loss: 0.0003505\n",
      "Test set: Average loss: 7.1942, Accuracy: 798/5000 (16%)\n",
      "[epoch 41] loss: 0.0003207\n",
      "Test set: Average loss: 7.2223, Accuracy: 797/5000 (16%)\n",
      "[epoch 42] loss: 0.0002952\n",
      "Test set: Average loss: 7.2481, Accuracy: 797/5000 (16%)\n",
      "[epoch 43] loss: 0.0002732\n",
      "Test set: Average loss: 7.2718, Accuracy: 802/5000 (16%)\n",
      "[epoch 44] loss: 0.0002544\n",
      "Test set: Average loss: 7.2936, Accuracy: 801/5000 (16%)\n",
      "[epoch 45] loss: 0.0002378\n",
      "Test set: Average loss: 7.3136, Accuracy: 803/5000 (16%)\n",
      "[epoch 46] loss: 0.0002236\n",
      "Test set: Average loss: 7.3320, Accuracy: 805/5000 (16%)\n",
      "[epoch 47] loss: 0.0002111\n",
      "Test set: Average loss: 7.3489, Accuracy: 804/5000 (16%)\n",
      "[epoch 48] loss: 0.0002000\n",
      "Test set: Average loss: 7.3644, Accuracy: 805/5000 (16%)\n",
      "[epoch 49] loss: 0.0001904\n",
      "Test set: Average loss: 7.3787, Accuracy: 804/5000 (16%)\n",
      "[epoch 50] loss: 0.0001818\n",
      "Test set: Average loss: 7.3919, Accuracy: 806/5000 (16%)\n",
      "Validation:\n",
      "Test set: Average loss: 5.7331, Accuracy: 823/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 5.6191, Accuracy: 1673/10000 (17%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3020, Accuracy: 566/5000 (11%)\n",
      "[epoch 1] loss: 2.3018513\n",
      "Test set: Average loss: 2.2979, Accuracy: 606/5000 (12%)\n",
      "[epoch 2] loss: 2.2068119\n",
      "Test set: Average loss: 2.3025, Accuracy: 695/5000 (14%)\n",
      "[epoch 3] loss: 2.0707431\n",
      "Test set: Average loss: 2.3459, Accuracy: 622/5000 (12%)\n",
      "[epoch 4] loss: 1.8883303\n",
      "Test set: Average loss: 2.4819, Accuracy: 615/5000 (12%)\n",
      "[epoch 5] loss: 1.6997241\n",
      "Test set: Average loss: 2.6476, Accuracy: 677/5000 (14%)\n",
      "[epoch 6] loss: 1.5107275\n",
      "Test set: Average loss: 2.7452, Accuracy: 746/5000 (15%)\n",
      "[epoch 7] loss: 1.2862014\n",
      "Test set: Average loss: 2.8128, Accuracy: 753/5000 (15%)\n",
      "[epoch 8] loss: 1.0547554\n",
      "Test set: Average loss: 2.8752, Accuracy: 745/5000 (15%)\n",
      "[epoch 9] loss: 0.8287922\n",
      "Test set: Average loss: 2.9444, Accuracy: 773/5000 (15%)\n",
      "[epoch 10] loss: 0.6251652\n",
      "Test set: Average loss: 3.0501, Accuracy: 770/5000 (15%)\n",
      "[epoch 11] loss: 0.4642082\n",
      "Test set: Average loss: 3.2046, Accuracy: 786/5000 (16%)\n",
      "[epoch 12] loss: 0.3355689\n",
      "Test set: Average loss: 3.3905, Accuracy: 792/5000 (16%)\n",
      "[epoch 13] loss: 0.2282913\n",
      "Test set: Average loss: 3.5965, Accuracy: 780/5000 (16%)\n",
      "[epoch 14] loss: 0.1476193\n",
      "Test set: Average loss: 3.8157, Accuracy: 755/5000 (15%)\n",
      "[epoch 15] loss: 0.0946966\n",
      "Test set: Average loss: 4.0375, Accuracy: 756/5000 (15%)\n",
      "[epoch 16] loss: 0.0612891\n",
      "Test set: Average loss: 4.2526, Accuracy: 736/5000 (15%)\n",
      "[epoch 17] loss: 0.0402715\n",
      "Test set: Average loss: 4.4544, Accuracy: 729/5000 (15%)\n",
      "[epoch 18] loss: 0.0267524\n",
      "Test set: Average loss: 4.6393, Accuracy: 736/5000 (15%)\n",
      "[epoch 19] loss: 0.0177061\n",
      "Test set: Average loss: 4.8067, Accuracy: 730/5000 (15%)\n",
      "[epoch 20] loss: 0.0116560\n",
      "Test set: Average loss: 4.9578, Accuracy: 738/5000 (15%)\n",
      "[epoch 21] loss: 0.0077395\n",
      "Test set: Average loss: 5.0941, Accuracy: 745/5000 (15%)\n",
      "[epoch 22] loss: 0.0052725\n",
      "Test set: Average loss: 5.2172, Accuracy: 739/5000 (15%)\n",
      "[epoch 23] loss: 0.0037290\n",
      "Test set: Average loss: 5.3286, Accuracy: 738/5000 (15%)\n",
      "[epoch 24] loss: 0.0027502\n",
      "Test set: Average loss: 5.4292, Accuracy: 737/5000 (15%)\n",
      "[epoch 25] loss: 0.0021108\n",
      "Test set: Average loss: 5.5202, Accuracy: 733/5000 (15%)\n",
      "[epoch 26] loss: 0.0016768\n",
      "Test set: Average loss: 5.6024, Accuracy: 731/5000 (15%)\n",
      "[epoch 27] loss: 0.0013707\n",
      "Test set: Average loss: 5.6766, Accuracy: 731/5000 (15%)\n",
      "[epoch 28] loss: 0.0011470\n",
      "Test set: Average loss: 5.7438, Accuracy: 733/5000 (15%)\n",
      "[epoch 29] loss: 0.0009781\n",
      "Test set: Average loss: 5.8045, Accuracy: 732/5000 (15%)\n",
      "[epoch 30] loss: 0.0008479\n",
      "Test set: Average loss: 5.8594, Accuracy: 728/5000 (15%)\n",
      "[epoch 31] loss: 0.0007446\n",
      "Test set: Average loss: 5.9092, Accuracy: 728/5000 (15%)\n",
      "[epoch 32] loss: 0.0006614\n",
      "Test set: Average loss: 5.9544, Accuracy: 725/5000 (14%)\n",
      "[epoch 33] loss: 0.0005930\n",
      "Test set: Average loss: 5.9954, Accuracy: 720/5000 (14%)\n",
      "[epoch 34] loss: 0.0005362\n",
      "Test set: Average loss: 6.0328, Accuracy: 723/5000 (14%)\n",
      "[epoch 35] loss: 0.0004884\n",
      "Test set: Average loss: 6.0670, Accuracy: 724/5000 (14%)\n",
      "[epoch 36] loss: 0.0004478\n",
      "Test set: Average loss: 6.0982, Accuracy: 721/5000 (14%)\n",
      "[epoch 37] loss: 0.0004131\n",
      "Test set: Average loss: 6.1268, Accuracy: 722/5000 (14%)\n",
      "[epoch 38] loss: 0.0003830\n",
      "Test set: Average loss: 6.1530, Accuracy: 723/5000 (14%)\n",
      "[epoch 39] loss: 0.0003566\n",
      "Test set: Average loss: 6.1772, Accuracy: 724/5000 (14%)\n",
      "[epoch 40] loss: 0.0003336\n",
      "Test set: Average loss: 6.1994, Accuracy: 722/5000 (14%)\n",
      "[epoch 41] loss: 0.0003133\n",
      "Test set: Average loss: 6.2200, Accuracy: 721/5000 (14%)\n",
      "[epoch 42] loss: 0.0002952\n",
      "Test set: Average loss: 6.2390, Accuracy: 723/5000 (14%)\n",
      "[epoch 43] loss: 0.0002792\n",
      "Test set: Average loss: 6.2566, Accuracy: 726/5000 (15%)\n",
      "[epoch 44] loss: 0.0002648\n",
      "Test set: Average loss: 6.2730, Accuracy: 724/5000 (14%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] loss: 0.0002518\n",
      "Test set: Average loss: 6.2881, Accuracy: 723/5000 (14%)\n",
      "[epoch 46] loss: 0.0002400\n",
      "Test set: Average loss: 6.3023, Accuracy: 719/5000 (14%)\n",
      "[epoch 47] loss: 0.0002293\n",
      "Test set: Average loss: 6.3155, Accuracy: 719/5000 (14%)\n",
      "[epoch 48] loss: 0.0002195\n",
      "Test set: Average loss: 6.3278, Accuracy: 722/5000 (14%)\n",
      "[epoch 49] loss: 0.0002106\n",
      "Test set: Average loss: 6.3394, Accuracy: 721/5000 (14%)\n",
      "[epoch 50] loss: 0.0002024\n",
      "Test set: Average loss: 6.3503, Accuracy: 722/5000 (14%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.3905, Accuracy: 792/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 3.3748, Accuracy: 1595/10000 (16%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 497/5000 (10%)\n",
      "[epoch 1] loss: 2.3096452\n",
      "Test set: Average loss: 2.2994, Accuracy: 536/5000 (11%)\n",
      "[epoch 2] loss: 2.2074974\n",
      "Test set: Average loss: 2.3068, Accuracy: 524/5000 (10%)\n",
      "[epoch 3] loss: 2.0572615\n",
      "Test set: Average loss: 2.3844, Accuracy: 525/5000 (10%)\n",
      "[epoch 4] loss: 1.8647332\n",
      "Test set: Average loss: 2.6543, Accuracy: 525/5000 (10%)\n",
      "[epoch 5] loss: 1.7502998\n",
      "Test set: Average loss: 2.7909, Accuracy: 561/5000 (11%)\n",
      "[epoch 6] loss: 1.6143427\n",
      "Test set: Average loss: 2.7903, Accuracy: 712/5000 (14%)\n",
      "[epoch 7] loss: 1.4342078\n",
      "Test set: Average loss: 2.7477, Accuracy: 737/5000 (15%)\n",
      "[epoch 8] loss: 1.2336842\n",
      "Test set: Average loss: 2.7113, Accuracy: 747/5000 (15%)\n",
      "[epoch 9] loss: 1.0265092\n",
      "Test set: Average loss: 2.7295, Accuracy: 719/5000 (14%)\n",
      "[epoch 10] loss: 0.8487498\n",
      "Test set: Average loss: 2.8068, Accuracy: 687/5000 (14%)\n",
      "[epoch 11] loss: 0.7007335\n",
      "Test set: Average loss: 2.9213, Accuracy: 698/5000 (14%)\n",
      "[epoch 12] loss: 0.5686353\n",
      "Test set: Average loss: 3.0535, Accuracy: 744/5000 (15%)\n",
      "[epoch 13] loss: 0.4472851\n",
      "Test set: Average loss: 3.2035, Accuracy: 785/5000 (16%)\n",
      "[epoch 14] loss: 0.3437212\n",
      "Test set: Average loss: 3.3880, Accuracy: 769/5000 (15%)\n",
      "[epoch 15] loss: 0.2664288\n",
      "Test set: Average loss: 3.6072, Accuracy: 792/5000 (16%)\n",
      "[epoch 16] loss: 0.2059796\n",
      "Test set: Average loss: 3.8480, Accuracy: 775/5000 (16%)\n",
      "[epoch 17] loss: 0.1526237\n",
      "Test set: Average loss: 4.0938, Accuracy: 766/5000 (15%)\n",
      "[epoch 18] loss: 0.1074420\n",
      "Test set: Average loss: 4.3257, Accuracy: 743/5000 (15%)\n",
      "[epoch 19] loss: 0.0705682\n",
      "Test set: Average loss: 4.5418, Accuracy: 705/5000 (14%)\n",
      "[epoch 20] loss: 0.0469119\n",
      "Test set: Average loss: 4.7542, Accuracy: 651/5000 (13%)\n",
      "[epoch 21] loss: 0.0387319\n",
      "Test set: Average loss: 4.9426, Accuracy: 615/5000 (12%)\n",
      "[epoch 22] loss: 0.0353083\n",
      "Test set: Average loss: 5.0756, Accuracy: 626/5000 (13%)\n",
      "[epoch 23] loss: 0.0266809\n",
      "Test set: Average loss: 5.1652, Accuracy: 635/5000 (13%)\n",
      "[epoch 24] loss: 0.0166248\n",
      "Test set: Average loss: 5.2423, Accuracy: 645/5000 (13%)\n",
      "[epoch 25] loss: 0.0102312\n",
      "Test set: Average loss: 5.3210, Accuracy: 668/5000 (13%)\n",
      "[epoch 26] loss: 0.0070813\n",
      "Test set: Average loss: 5.3999, Accuracy: 684/5000 (14%)\n",
      "[epoch 27] loss: 0.0054543\n",
      "Test set: Average loss: 5.4747, Accuracy: 695/5000 (14%)\n",
      "[epoch 28] loss: 0.0044283\n",
      "Test set: Average loss: 5.5425, Accuracy: 702/5000 (14%)\n",
      "[epoch 29] loss: 0.0036525\n",
      "Test set: Average loss: 5.6024, Accuracy: 713/5000 (14%)\n",
      "[epoch 30] loss: 0.0030271\n",
      "Test set: Average loss: 5.6544, Accuracy: 712/5000 (14%)\n",
      "[epoch 31] loss: 0.0025200\n",
      "Test set: Average loss: 5.6996, Accuracy: 711/5000 (14%)\n",
      "[epoch 32] loss: 0.0021126\n",
      "Test set: Average loss: 5.7390, Accuracy: 724/5000 (14%)\n",
      "[epoch 33] loss: 0.0017915\n",
      "Test set: Average loss: 5.7736, Accuracy: 725/5000 (14%)\n",
      "[epoch 34] loss: 0.0015412\n",
      "Test set: Average loss: 5.8044, Accuracy: 720/5000 (14%)\n",
      "[epoch 35] loss: 0.0013454\n",
      "Test set: Average loss: 5.8323, Accuracy: 719/5000 (14%)\n",
      "[epoch 36] loss: 0.0011906\n",
      "Test set: Average loss: 5.8578, Accuracy: 720/5000 (14%)\n",
      "[epoch 37] loss: 0.0010662\n",
      "Test set: Average loss: 5.8814, Accuracy: 725/5000 (14%)\n",
      "[epoch 38] loss: 0.0009645\n",
      "Test set: Average loss: 5.9035, Accuracy: 729/5000 (15%)\n",
      "[epoch 39] loss: 0.0008803\n",
      "Test set: Average loss: 5.9245, Accuracy: 734/5000 (15%)\n",
      "[epoch 40] loss: 0.0008093\n",
      "Test set: Average loss: 5.9444, Accuracy: 736/5000 (15%)\n",
      "[epoch 41] loss: 0.0007486\n",
      "Test set: Average loss: 5.9636, Accuracy: 737/5000 (15%)\n",
      "[epoch 42] loss: 0.0006960\n",
      "Test set: Average loss: 5.9822, Accuracy: 740/5000 (15%)\n",
      "[epoch 43] loss: 0.0006503\n",
      "Test set: Average loss: 6.0001, Accuracy: 740/5000 (15%)\n",
      "[epoch 44] loss: 0.0006094\n",
      "Test set: Average loss: 6.0176, Accuracy: 743/5000 (15%)\n",
      "[epoch 45] loss: 0.0005731\n",
      "Test set: Average loss: 6.0346, Accuracy: 744/5000 (15%)\n",
      "[epoch 46] loss: 0.0005404\n",
      "Test set: Average loss: 6.0511, Accuracy: 745/5000 (15%)\n",
      "[epoch 47] loss: 0.0005106\n",
      "Test set: Average loss: 6.0673, Accuracy: 747/5000 (15%)\n",
      "[epoch 48] loss: 0.0004836\n",
      "Test set: Average loss: 6.0830, Accuracy: 749/5000 (15%)\n",
      "[epoch 49] loss: 0.0004589\n",
      "Test set: Average loss: 6.0983, Accuracy: 753/5000 (15%)\n",
      "[epoch 50] loss: 0.0004364\n",
      "Test set: Average loss: 6.1131, Accuracy: 753/5000 (15%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.6072, Accuracy: 792/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 3.6049, Accuracy: 1594/10000 (16%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3051, Accuracy: 447/5000 (9%)\n",
      "[epoch 1] loss: 2.2976737\n",
      "Test set: Average loss: 2.2985, Accuracy: 513/5000 (10%)\n",
      "[epoch 2] loss: 2.2025627\n",
      "Test set: Average loss: 2.3207, Accuracy: 479/5000 (10%)\n",
      "[epoch 3] loss: 2.0327979\n",
      "Test set: Average loss: 2.4582, Accuracy: 603/5000 (12%)\n",
      "[epoch 4] loss: 1.7749608\n",
      "Test set: Average loss: 2.6312, Accuracy: 791/5000 (16%)\n",
      "[epoch 5] loss: 1.5941350\n",
      "Test set: Average loss: 2.7578, Accuracy: 879/5000 (18%)\n",
      "[epoch 6] loss: 1.4139245\n",
      "Test set: Average loss: 2.8125, Accuracy: 912/5000 (18%)\n",
      "[epoch 7] loss: 1.1287366\n",
      "Test set: Average loss: 2.8738, Accuracy: 926/5000 (19%)\n",
      "[epoch 8] loss: 0.9495899\n",
      "Test set: Average loss: 2.9164, Accuracy: 975/5000 (20%)\n",
      "[epoch 9] loss: 0.6896209\n",
      "Test set: Average loss: 3.0784, Accuracy: 950/5000 (19%)\n",
      "[epoch 10] loss: 0.5477783\n",
      "Test set: Average loss: 3.3325, Accuracy: 888/5000 (18%)\n",
      "[epoch 11] loss: 0.4181229\n",
      "Test set: Average loss: 3.6418, Accuracy: 885/5000 (18%)\n",
      "[epoch 12] loss: 0.2579973\n",
      "Test set: Average loss: 3.8951, Accuracy: 874/5000 (17%)\n",
      "[epoch 13] loss: 0.2245919\n",
      "Test set: Average loss: 4.0215, Accuracy: 899/5000 (18%)\n",
      "[epoch 14] loss: 0.1246685\n",
      "Test set: Average loss: 4.1425, Accuracy: 937/5000 (19%)\n",
      "[epoch 15] loss: 0.1047838\n",
      "Test set: Average loss: 4.3191, Accuracy: 944/5000 (19%)\n",
      "[epoch 16] loss: 0.0600504\n",
      "Test set: Average loss: 4.4854, Accuracy: 922/5000 (18%)\n",
      "[epoch 17] loss: 0.0377337\n",
      "Test set: Average loss: 4.6455, Accuracy: 911/5000 (18%)\n",
      "[epoch 18] loss: 0.0258915\n",
      "Test set: Average loss: 4.7789, Accuracy: 903/5000 (18%)\n",
      "[epoch 19] loss: 0.0183222\n",
      "Test set: Average loss: 4.8546, Accuracy: 924/5000 (18%)\n",
      "[epoch 20] loss: 0.0146499\n",
      "Test set: Average loss: 4.9021, Accuracy: 924/5000 (18%)\n",
      "[epoch 21] loss: 0.0108220\n",
      "Test set: Average loss: 4.9407, Accuracy: 924/5000 (18%)\n",
      "[epoch 22] loss: 0.0080945\n",
      "Test set: Average loss: 4.9843, Accuracy: 921/5000 (18%)\n",
      "[epoch 23] loss: 0.0066199\n",
      "Test set: Average loss: 5.0332, Accuracy: 919/5000 (18%)\n",
      "[epoch 24] loss: 0.0057468\n",
      "Test set: Average loss: 5.0889, Accuracy: 922/5000 (18%)\n",
      "[epoch 25] loss: 0.0044439\n",
      "Test set: Average loss: 5.1473, Accuracy: 927/5000 (19%)\n",
      "[epoch 26] loss: 0.0038138\n",
      "Test set: Average loss: 5.2034, Accuracy: 930/5000 (19%)\n",
      "[epoch 27] loss: 0.0036822\n",
      "Test set: Average loss: 5.2556, Accuracy: 928/5000 (19%)\n",
      "[epoch 28] loss: 0.0030812\n",
      "Test set: Average loss: 5.3015, Accuracy: 924/5000 (18%)\n",
      "[epoch 29] loss: 0.0028762\n",
      "Test set: Average loss: 5.3409, Accuracy: 925/5000 (18%)\n",
      "[epoch 30] loss: 0.0026112\n",
      "Test set: Average loss: 5.3756, Accuracy: 926/5000 (19%)\n",
      "[epoch 31] loss: 0.0023570\n",
      "Test set: Average loss: 5.4044, Accuracy: 924/5000 (18%)\n",
      "[epoch 32] loss: 0.0022239\n",
      "Test set: Average loss: 5.4276, Accuracy: 923/5000 (18%)\n",
      "[epoch 33] loss: 0.0022488\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.4465, Accuracy: 923/5000 (18%)\n",
      "[epoch 34] loss: 0.0020560\n",
      "Test set: Average loss: 5.4479, Accuracy: 923/5000 (18%)\n",
      "[epoch 35] loss: 0.0019034\n",
      "Test set: Average loss: 5.4490, Accuracy: 923/5000 (18%)\n",
      "[epoch 36] loss: 0.0018539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 5.4498, Accuracy: 924/5000 (18%)\n",
      "[epoch 37] loss: 0.0019403\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.4504, Accuracy: 925/5000 (18%)\n",
      "[epoch 38] loss: 0.0019843\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 39] loss: 0.0019854\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 40] loss: 0.0019311\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 41] loss: 0.0020768\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 42] loss: 0.0019458\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 43] loss: 0.0018922\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 44] loss: 0.0019152\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 45] loss: 0.0018492\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 46] loss: 0.0020557\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 47] loss: 0.0018944\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 48] loss: 0.0019289\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 49] loss: 0.0019429\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "[epoch 50] loss: 0.0019080\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 5.4505, Accuracy: 925/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9164, Accuracy: 975/5000 (20%)\n",
      "Test\n",
      "Test set: Average loss: 2.8481, Accuracy: 2060/10000 (21%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3065, Accuracy: 430/5000 (9%)\n",
      "[epoch 1] loss: 2.2968539\n",
      "Test set: Average loss: 2.3010, Accuracy: 496/5000 (10%)\n",
      "[epoch 2] loss: 2.2188455\n",
      "Test set: Average loss: 2.3332, Accuracy: 501/5000 (10%)\n",
      "[epoch 3] loss: 2.1324339\n",
      "Test set: Average loss: 2.3771, Accuracy: 539/5000 (11%)\n",
      "[epoch 4] loss: 1.8990347\n",
      "Test set: Average loss: 2.3329, Accuracy: 812/5000 (16%)\n",
      "[epoch 5] loss: 1.6375302\n",
      "Test set: Average loss: 2.3155, Accuracy: 927/5000 (19%)\n",
      "[epoch 6] loss: 1.3739165\n",
      "Test set: Average loss: 2.3828, Accuracy: 939/5000 (19%)\n",
      "[epoch 7] loss: 1.0305135\n",
      "Test set: Average loss: 2.5008, Accuracy: 955/5000 (19%)\n",
      "[epoch 8] loss: 0.7382689\n",
      "Test set: Average loss: 2.6662, Accuracy: 923/5000 (18%)\n",
      "[epoch 9] loss: 0.5326689\n",
      "Test set: Average loss: 2.8429, Accuracy: 931/5000 (19%)\n",
      "[epoch 10] loss: 0.3542671\n",
      "Test set: Average loss: 3.0368, Accuracy: 929/5000 (19%)\n",
      "[epoch 11] loss: 0.2163957\n",
      "Test set: Average loss: 3.2812, Accuracy: 938/5000 (19%)\n",
      "[epoch 12] loss: 0.1413718\n",
      "Test set: Average loss: 3.5178, Accuracy: 906/5000 (18%)\n",
      "[epoch 13] loss: 0.0798939\n",
      "Test set: Average loss: 3.7254, Accuracy: 859/5000 (17%)\n",
      "[epoch 14] loss: 0.0478993\n",
      "Test set: Average loss: 3.9217, Accuracy: 830/5000 (17%)\n",
      "[epoch 15] loss: 0.0313927\n",
      "Test set: Average loss: 4.0719, Accuracy: 842/5000 (17%)\n",
      "[epoch 16] loss: 0.0198027\n",
      "Test set: Average loss: 4.2074, Accuracy: 849/5000 (17%)\n",
      "[epoch 17] loss: 0.0116759\n",
      "Test set: Average loss: 4.3352, Accuracy: 858/5000 (17%)\n",
      "[epoch 18] loss: 0.0083486\n",
      "Test set: Average loss: 4.4544, Accuracy: 869/5000 (17%)\n",
      "[epoch 19] loss: 0.0064320\n",
      "Test set: Average loss: 4.5583, Accuracy: 887/5000 (18%)\n",
      "[epoch 20] loss: 0.0058378\n",
      "Test set: Average loss: 4.6349, Accuracy: 893/5000 (18%)\n",
      "[epoch 21] loss: 0.0046987\n",
      "Test set: Average loss: 4.6853, Accuracy: 894/5000 (18%)\n",
      "[epoch 22] loss: 0.0033576\n",
      "Test set: Average loss: 4.7227, Accuracy: 900/5000 (18%)\n",
      "[epoch 23] loss: 0.0029036\n",
      "Test set: Average loss: 4.7590, Accuracy: 898/5000 (18%)\n",
      "[epoch 24] loss: 0.0023458\n",
      "Test set: Average loss: 4.7952, Accuracy: 892/5000 (18%)\n",
      "[epoch 25] loss: 0.0020731\n",
      "Test set: Average loss: 4.8312, Accuracy: 891/5000 (18%)\n",
      "[epoch 26] loss: 0.0019414\n",
      "Test set: Average loss: 4.8654, Accuracy: 900/5000 (18%)\n",
      "[epoch 27] loss: 0.0017807\n",
      "Test set: Average loss: 4.8990, Accuracy: 900/5000 (18%)\n",
      "[epoch 28] loss: 0.0016658\n",
      "Test set: Average loss: 4.9316, Accuracy: 899/5000 (18%)\n",
      "[epoch 29] loss: 0.0015725\n",
      "Test set: Average loss: 4.9634, Accuracy: 897/5000 (18%)\n",
      "[epoch 30] loss: 0.0013089\n",
      "Test set: Average loss: 4.9933, Accuracy: 893/5000 (18%)\n",
      "[epoch 31] loss: 0.0012158\n",
      "Test set: Average loss: 5.0214, Accuracy: 892/5000 (18%)\n",
      "[epoch 32] loss: 0.0011617\n",
      "Test set: Average loss: 5.0471, Accuracy: 891/5000 (18%)\n",
      "[epoch 33] loss: 0.0010985\n",
      "Test set: Average loss: 5.0707, Accuracy: 894/5000 (18%)\n",
      "[epoch 34] loss: 0.0010377\n",
      "Test set: Average loss: 5.0920, Accuracy: 889/5000 (18%)\n",
      "[epoch 35] loss: 0.0009945\n",
      "Test set: Average loss: 5.1108, Accuracy: 882/5000 (18%)\n",
      "[epoch 36] loss: 0.0009540\n",
      "Test set: Average loss: 5.1265, Accuracy: 881/5000 (18%)\n",
      "[epoch 37] loss: 0.0009013\n",
      "Test set: Average loss: 5.1385, Accuracy: 876/5000 (18%)\n",
      "[epoch 38] loss: 0.0008789\n",
      "Test set: Average loss: 5.1485, Accuracy: 878/5000 (18%)\n",
      "[epoch 39] loss: 0.0008243\n",
      "Test set: Average loss: 5.1567, Accuracy: 876/5000 (18%)\n",
      "[epoch 40] loss: 0.0008192\n",
      "Test set: Average loss: 5.1630, Accuracy: 879/5000 (18%)\n",
      "[epoch 41] loss: 0.0007896\n",
      "Test set: Average loss: 5.1672, Accuracy: 881/5000 (18%)\n",
      "[epoch 42] loss: 0.0007196\n",
      "Test set: Average loss: 5.1696, Accuracy: 883/5000 (18%)\n",
      "[epoch 43] loss: 0.0007087\n",
      "Test set: Average loss: 5.1712, Accuracy: 889/5000 (18%)\n",
      "[epoch 44] loss: 0.0007208\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.1729, Accuracy: 893/5000 (18%)\n",
      "[epoch 45] loss: 0.0006818\n",
      "Test set: Average loss: 5.1732, Accuracy: 894/5000 (18%)\n",
      "[epoch 46] loss: 0.0006609\n",
      "Test set: Average loss: 5.1734, Accuracy: 892/5000 (18%)\n",
      "[epoch 47] loss: 0.0006693\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.1737, Accuracy: 891/5000 (18%)\n",
      "[epoch 48] loss: 0.0006463\n",
      "Test set: Average loss: 5.1738, Accuracy: 891/5000 (18%)\n",
      "[epoch 49] loss: 0.0006848\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.1738, Accuracy: 891/5000 (18%)\n",
      "[epoch 50] loss: 0.0006560\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.1738, Accuracy: 891/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5008, Accuracy: 955/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 2.4866, Accuracy: 1946/10000 (19%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 472/5000 (9%)\n",
      "[epoch 1] loss: 2.2885801\n",
      "Test set: Average loss: 2.2956, Accuracy: 548/5000 (11%)\n",
      "[epoch 2] loss: 2.1097543\n",
      "Test set: Average loss: 2.3648, Accuracy: 526/5000 (11%)\n",
      "[epoch 3] loss: 1.9230257\n",
      "Test set: Average loss: 2.5480, Accuracy: 581/5000 (12%)\n",
      "[epoch 4] loss: 1.6849024\n",
      "Test set: Average loss: 2.5026, Accuracy: 909/5000 (18%)\n",
      "[epoch 5] loss: 1.4163649\n",
      "Test set: Average loss: 2.4822, Accuracy: 875/5000 (18%)\n",
      "[epoch 6] loss: 1.1035441\n",
      "Test set: Average loss: 2.5695, Accuracy: 852/5000 (17%)\n",
      "[epoch 7] loss: 0.8949556\n",
      "Test set: Average loss: 2.7896, Accuracy: 869/5000 (17%)\n",
      "[epoch 8] loss: 0.6280424\n",
      "Test set: Average loss: 3.1098, Accuracy: 882/5000 (18%)\n",
      "[epoch 9] loss: 0.4105810\n",
      "Test set: Average loss: 3.2550, Accuracy: 913/5000 (18%)\n",
      "[epoch 10] loss: 0.3028079\n",
      "Test set: Average loss: 3.4089, Accuracy: 883/5000 (18%)\n",
      "[epoch 11] loss: 0.2699362\n",
      "Test set: Average loss: 3.5578, Accuracy: 900/5000 (18%)\n",
      "[epoch 12] loss: 0.2156860\n",
      "Test set: Average loss: 3.7374, Accuracy: 912/5000 (18%)\n",
      "[epoch 13] loss: 0.1261650\n",
      "Test set: Average loss: 3.9290, Accuracy: 902/5000 (18%)\n",
      "[epoch 14] loss: 0.1108598\n",
      "Test set: Average loss: 4.0587, Accuracy: 861/5000 (17%)\n",
      "[epoch 15] loss: 0.0863066\n",
      "Test set: Average loss: 4.1344, Accuracy: 862/5000 (17%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 0.0509269\n",
      "Test set: Average loss: 4.2404, Accuracy: 829/5000 (17%)\n",
      "[epoch 17] loss: 0.0406451\n",
      "Test set: Average loss: 4.3279, Accuracy: 828/5000 (17%)\n",
      "[epoch 18] loss: 0.0315960\n",
      "Test set: Average loss: 4.3906, Accuracy: 852/5000 (17%)\n",
      "[epoch 19] loss: 0.0205197\n",
      "Test set: Average loss: 4.4613, Accuracy: 870/5000 (17%)\n",
      "[epoch 20] loss: 0.0165192\n",
      "Test set: Average loss: 4.5516, Accuracy: 874/5000 (17%)\n",
      "[epoch 21] loss: 0.0125650\n",
      "Test set: Average loss: 4.6480, Accuracy: 860/5000 (17%)\n",
      "[epoch 22] loss: 0.0087711\n",
      "Test set: Average loss: 4.7427, Accuracy: 849/5000 (17%)\n",
      "[epoch 23] loss: 0.0069239\n",
      "Test set: Average loss: 4.8265, Accuracy: 833/5000 (17%)\n",
      "[epoch 24] loss: 0.0059612\n",
      "Test set: Average loss: 4.8940, Accuracy: 828/5000 (17%)\n",
      "[epoch 25] loss: 0.0055322\n",
      "Test set: Average loss: 4.9479, Accuracy: 834/5000 (17%)\n",
      "[epoch 26] loss: 0.0043496\n",
      "Test set: Average loss: 4.9864, Accuracy: 846/5000 (17%)\n",
      "[epoch 27] loss: 0.0035770\n",
      "Test set: Average loss: 5.0135, Accuracy: 861/5000 (17%)\n",
      "[epoch 28] loss: 0.0033256\n",
      "Test set: Average loss: 5.0367, Accuracy: 857/5000 (17%)\n",
      "[epoch 29] loss: 0.0027909\n",
      "Test set: Average loss: 5.0560, Accuracy: 864/5000 (17%)\n",
      "[epoch 30] loss: 0.0025650\n",
      "Test set: Average loss: 5.0706, Accuracy: 866/5000 (17%)\n",
      "[epoch 31] loss: 0.0023235\n",
      "Test set: Average loss: 5.0820, Accuracy: 867/5000 (17%)\n",
      "[epoch 32] loss: 0.0021483\n",
      "Test set: Average loss: 5.0927, Accuracy: 868/5000 (17%)\n",
      "[epoch 33] loss: 0.0020926\n",
      "Test set: Average loss: 5.1030, Accuracy: 862/5000 (17%)\n",
      "[epoch 34] loss: 0.0017539\n",
      "Test set: Average loss: 5.1143, Accuracy: 860/5000 (17%)\n",
      "[epoch 35] loss: 0.0016771\n",
      "Test set: Average loss: 5.1257, Accuracy: 859/5000 (17%)\n",
      "[epoch 36] loss: 0.0016394\n",
      "Test set: Average loss: 5.1368, Accuracy: 853/5000 (17%)\n",
      "[epoch 37] loss: 0.0014611\n",
      "Test set: Average loss: 5.1473, Accuracy: 852/5000 (17%)\n",
      "[epoch 38] loss: 0.0014311\n",
      "Test set: Average loss: 5.1578, Accuracy: 848/5000 (17%)\n",
      "[epoch 39] loss: 0.0013481\n",
      "Test set: Average loss: 5.1675, Accuracy: 847/5000 (17%)\n",
      "[epoch 40] loss: 0.0014000\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.1769, Accuracy: 844/5000 (17%)\n",
      "[epoch 41] loss: 0.0013572\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.1778, Accuracy: 843/5000 (17%)\n",
      "[epoch 42] loss: 0.0013463\n",
      "Test set: Average loss: 5.1779, Accuracy: 843/5000 (17%)\n",
      "[epoch 43] loss: 0.0013090\n",
      "Test set: Average loss: 5.1780, Accuracy: 843/5000 (17%)\n",
      "[epoch 44] loss: 0.0013862\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "[epoch 45] loss: 0.0013201\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "[epoch 46] loss: 0.0012828\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "[epoch 47] loss: 0.0013190\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "[epoch 48] loss: 0.0013777\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "[epoch 49] loss: 0.0013459\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "[epoch 50] loss: 0.0013816\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 5.1781, Accuracy: 843/5000 (17%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.2550, Accuracy: 913/5000 (18%)\n",
      "Test\n",
      "Test set: Average loss: 3.1918, Accuracy: 1798/10000 (18%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3018, Accuracy: 576/5000 (12%)\n",
      "[epoch 1] loss: 2.2939357\n",
      "Test set: Average loss: 2.3034, Accuracy: 584/5000 (12%)\n",
      "[epoch 2] loss: 2.0229272\n",
      "Test set: Average loss: 2.3782, Accuracy: 897/5000 (18%)\n",
      "[epoch 3] loss: 1.9120286\n",
      "Test set: Average loss: 2.4784, Accuracy: 957/5000 (19%)\n",
      "[epoch 4] loss: 1.7016234\n",
      "Test set: Average loss: 2.4479, Accuracy: 946/5000 (19%)\n",
      "[epoch 5] loss: 1.4698771\n",
      "Test set: Average loss: 2.4510, Accuracy: 1024/5000 (20%)\n",
      "[epoch 6] loss: 1.1980047\n",
      "Test set: Average loss: 2.4797, Accuracy: 987/5000 (20%)\n",
      "[epoch 7] loss: 1.1246993\n",
      "Test set: Average loss: 2.5959, Accuracy: 1060/5000 (21%)\n",
      "[epoch 8] loss: 1.0105374\n",
      "Test set: Average loss: 2.8349, Accuracy: 1067/5000 (21%)\n",
      "[epoch 9] loss: 1.8850487\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.8577, Accuracy: 1005/5000 (20%)\n",
      "[epoch 10] loss: 0.7938810\n",
      "Test set: Average loss: 2.8482, Accuracy: 1005/5000 (20%)\n",
      "[epoch 11] loss: 0.6842283\n",
      "Test set: Average loss: 2.8417, Accuracy: 1009/5000 (20%)\n",
      "[epoch 12] loss: 0.7996016\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.8420, Accuracy: 1005/5000 (20%)\n",
      "[epoch 13] loss: 0.7079322\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 14] loss: 0.7625672\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 15] loss: 0.9230143\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 16] loss: 0.6984033\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 17] loss: 0.8142737\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 18] loss: 0.6524110\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 19] loss: 0.6587912\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 20] loss: 0.6029422\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 21] loss: 0.7560874\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 22] loss: 0.6634167\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 23] loss: 0.6724133\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 24] loss: 0.7001794\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 25] loss: 0.8033165\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 26] loss: 0.6395369\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 27] loss: 0.7754431\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 28] loss: 0.6882149\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 29] loss: 0.8407446\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 30] loss: 0.6579734\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 31] loss: 0.7168396\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 32] loss: 0.6604729\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 33] loss: 1.7072555\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 34] loss: 0.7905062\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 35] loss: 0.6152257\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 36] loss: 0.7056691\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] loss: 0.8056628\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 38] loss: 0.6218529\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 39] loss: 0.6609363\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 40] loss: 0.8553853\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 41] loss: 0.6020503\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 42] loss: 1.2928261\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 43] loss: 0.6264711\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 44] loss: 0.7235898\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 45] loss: 0.6784318\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 46] loss: 0.8541062\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 47] loss: 0.7511048\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 48] loss: 0.7393812\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 49] loss: 0.7270033\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "[epoch 50] loss: 0.6413719\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.8417, Accuracy: 1004/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8349, Accuracy: 1067/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 2.7369, Accuracy: 2224/10000 (22%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3029, Accuracy: 548/5000 (11%)\n",
      "[epoch 1] loss: 2.3166162\n",
      "Test set: Average loss: 2.2863, Accuracy: 783/5000 (16%)\n",
      "[epoch 2] loss: 2.2005278\n",
      "Test set: Average loss: 2.2577, Accuracy: 781/5000 (16%)\n",
      "[epoch 3] loss: 2.1252967\n",
      "Test set: Average loss: 2.2363, Accuracy: 1019/5000 (20%)\n",
      "[epoch 4] loss: 1.7643057\n",
      "Test set: Average loss: 2.2156, Accuracy: 1005/5000 (20%)\n",
      "[epoch 5] loss: 1.5601121\n",
      "Test set: Average loss: 2.2507, Accuracy: 1141/5000 (23%)\n",
      "[epoch 6] loss: 1.3337660\n",
      "Test set: Average loss: 2.3598, Accuracy: 1139/5000 (23%)\n",
      "[epoch 7] loss: 1.2226600\n",
      "Test set: Average loss: 2.4193, Accuracy: 1118/5000 (22%)\n",
      "[epoch 8] loss: 0.9478682\n",
      "Test set: Average loss: 2.5753, Accuracy: 1060/5000 (21%)\n",
      "[epoch 9] loss: 1.0382247\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5993, Accuracy: 1022/5000 (20%)\n",
      "[epoch 10] loss: 0.5918906\n",
      "Test set: Average loss: 2.5920, Accuracy: 1023/5000 (20%)\n",
      "[epoch 11] loss: 0.6723095\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5810, Accuracy: 1042/5000 (21%)\n",
      "[epoch 12] loss: 0.6863064\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5798, Accuracy: 1046/5000 (21%)\n",
      "[epoch 13] loss: 0.6332636\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5797, Accuracy: 1046/5000 (21%)\n",
      "[epoch 14] loss: 0.6702935\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 15] loss: 0.6542064\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 16] loss: 0.7652318\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 17] loss: 0.6401026\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 18] loss: 0.6073136\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 19] loss: 0.6036375\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 20] loss: 1.4462468\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 21] loss: 0.6100824\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 22] loss: 0.7517438\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 23] loss: 0.5661651\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 24] loss: 0.6689891\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 25] loss: 0.6707546\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 26] loss: 0.7753588\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 27] loss: 0.5825812\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 28] loss: 0.6369762\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 29] loss: 0.6997400\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 30] loss: 0.5131131\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 31] loss: 0.5479455\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 32] loss: 1.5137231\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 33] loss: 0.5899315\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 34] loss: 0.6437838\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 35] loss: 0.5873809\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 36] loss: 0.5995728\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 37] loss: 0.6071413\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 38] loss: 0.6673260\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 39] loss: 0.5940721\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 40] loss: 0.6357503\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 41] loss: 0.6061987\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 42] loss: 0.5518029\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 43] loss: 0.6651911\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 44] loss: 0.5785101\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 45] loss: 0.5727768\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 46] loss: 0.5317833\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-38.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 47] loss: 0.6219604\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 48] loss: 0.5438552\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 49] loss: 1.5948865\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "[epoch 50] loss: 0.5549078\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.5796, Accuracy: 1047/5000 (21%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2507, Accuracy: 1141/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.2266, Accuracy: 2302/10000 (23%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2973, Accuracy: 652/5000 (13%)\n",
      "[epoch 1] loss: 2.2593339\n",
      "Test set: Average loss: 2.3247, Accuracy: 532/5000 (11%)\n",
      "[epoch 2] loss: 1.9945492\n",
      "Test set: Average loss: 2.4063, Accuracy: 662/5000 (13%)\n",
      "[epoch 3] loss: 2.0480006\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3253, Accuracy: 882/5000 (18%)\n",
      "[epoch 4] loss: 1.6606743\n",
      "Test set: Average loss: 2.3077, Accuracy: 898/5000 (18%)\n",
      "[epoch 5] loss: 1.5482450\n",
      "Test set: Average loss: 2.2952, Accuracy: 930/5000 (19%)\n",
      "[epoch 6] loss: 1.5387183\n",
      "Test set: Average loss: 2.2946, Accuracy: 953/5000 (19%)\n",
      "[epoch 7] loss: 1.4804408\n",
      "Test set: Average loss: 2.2965, Accuracy: 959/5000 (19%)\n",
      "[epoch 8] loss: 1.3244652\n",
      "Test set: Average loss: 2.3076, Accuracy: 961/5000 (19%)\n",
      "[epoch 9] loss: 1.4313008\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3339, Accuracy: 953/5000 (19%)\n",
      "[epoch 10] loss: 1.3071620\n",
      "Test set: Average loss: 2.3366, Accuracy: 948/5000 (19%)\n",
      "[epoch 11] loss: 1.3147858\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3391, Accuracy: 947/5000 (19%)\n",
      "[epoch 12] loss: 1.4902738\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 13] loss: 1.3736812\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 14] loss: 1.3659558\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 15] loss: 1.3815524\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 16] loss: 1.4826099\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 17] loss: 1.4428434\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 18] loss: 1.2833394\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 19] loss: 1.3995965\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 20] loss: 1.4377337\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 21] loss: 1.2897150\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 22] loss: 1.3362036\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 23] loss: 1.3164411\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 24] loss: 1.3791908\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 25] loss: 1.4455207\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 26] loss: 1.3337643\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 27] loss: 1.4219533\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 28] loss: 1.3982570\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 29] loss: 1.2876551\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 30] loss: 1.3024724\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 31] loss: 1.3416515\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 32] loss: 1.4519432\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 33] loss: 1.3750581\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 34] loss: 1.3889855\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 35] loss: 1.3977110\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 36] loss: 1.3493164\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 37] loss: 1.2760441\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 38] loss: 1.4098944\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 39] loss: 1.3173591\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 40] loss: 1.4442199\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 41] loss: 1.4179926\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 42] loss: 1.2905562\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 43] loss: 1.5131955\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 44] loss: 1.3493191\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 45] loss: 1.4164101\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 46] loss: 1.2983849\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 47] loss: 1.3201437\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 48] loss: 1.4172337\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 49] loss: 1.3814961\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "[epoch 50] loss: 1.4135414\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.3393, Accuracy: 948/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3076, Accuracy: 961/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 2.3124, Accuracy: 1872/10000 (19%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3049, Accuracy: 602/5000 (12%)\n",
      "[epoch 1] loss: 2.2918626\n",
      "Test set: Average loss: 2.2595, Accuracy: 690/5000 (14%)\n",
      "[epoch 2] loss: 2.0817863\n",
      "Test set: Average loss: 2.1587, Accuracy: 1144/5000 (23%)\n",
      "[epoch 3] loss: 1.7650423\n",
      "Test set: Average loss: 2.0995, Accuracy: 1279/5000 (26%)\n",
      "[epoch 4] loss: 1.5021121\n",
      "Test set: Average loss: 2.1524, Accuracy: 1335/5000 (27%)\n",
      "[epoch 5] loss: 1.2820671\n",
      "Test set: Average loss: 2.2390, Accuracy: 1390/5000 (28%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 1.0352123\n",
      "Test set: Average loss: 2.3364, Accuracy: 1386/5000 (28%)\n",
      "[epoch 7] loss: 0.8438072\n",
      "Test set: Average loss: 2.4880, Accuracy: 1319/5000 (26%)\n",
      "[epoch 8] loss: 0.5898284\n",
      "Test set: Average loss: 2.5820, Accuracy: 1359/5000 (27%)\n",
      "[epoch 9] loss: 0.4003368\n",
      "Test set: Average loss: 2.7635, Accuracy: 1350/5000 (27%)\n",
      "[epoch 10] loss: 0.2576897\n",
      "Test set: Average loss: 3.0475, Accuracy: 1328/5000 (27%)\n",
      "[epoch 11] loss: 0.1687444\n",
      "Test set: Average loss: 3.1379, Accuracy: 1361/5000 (27%)\n",
      "[epoch 12] loss: 0.0935444\n",
      "Test set: Average loss: 3.4567, Accuracy: 1251/5000 (25%)\n",
      "[epoch 13] loss: 0.0748737\n",
      "Test set: Average loss: 3.4007, Accuracy: 1403/5000 (28%)\n",
      "[epoch 14] loss: 0.0467472\n",
      "Test set: Average loss: 3.5611, Accuracy: 1345/5000 (27%)\n",
      "[epoch 15] loss: 0.0263284\n",
      "Test set: Average loss: 3.6209, Accuracy: 1343/5000 (27%)\n",
      "[epoch 16] loss: 0.0162935\n",
      "Test set: Average loss: 3.6275, Accuracy: 1364/5000 (27%)\n",
      "[epoch 17] loss: 0.0138683\n",
      "Test set: Average loss: 3.7077, Accuracy: 1371/5000 (27%)\n",
      "[epoch 18] loss: 0.0103236\n",
      "Test set: Average loss: 3.7727, Accuracy: 1350/5000 (27%)\n",
      "[epoch 19] loss: 0.0084786\n",
      "Test set: Average loss: 3.7831, Accuracy: 1351/5000 (27%)\n",
      "[epoch 20] loss: 0.0072333\n",
      "Test set: Average loss: 3.8060, Accuracy: 1337/5000 (27%)\n",
      "[epoch 21] loss: 0.0062707\n",
      "Test set: Average loss: 3.8268, Accuracy: 1353/5000 (27%)\n",
      "[epoch 22] loss: 0.0056046\n",
      "Test set: Average loss: 3.8570, Accuracy: 1351/5000 (27%)\n",
      "[epoch 23] loss: 0.0050313\n",
      "Test set: Average loss: 3.8850, Accuracy: 1356/5000 (27%)\n",
      "[epoch 24] loss: 0.0045856\n",
      "Test set: Average loss: 3.9088, Accuracy: 1355/5000 (27%)\n",
      "[epoch 25] loss: 0.0041629\n",
      "Test set: Average loss: 3.9233, Accuracy: 1354/5000 (27%)\n",
      "[epoch 26] loss: 0.0038336\n",
      "Test set: Average loss: 3.9453, Accuracy: 1359/5000 (27%)\n",
      "[epoch 27] loss: 0.0035265\n",
      "Test set: Average loss: 3.9636, Accuracy: 1355/5000 (27%)\n",
      "[epoch 28] loss: 0.0032502\n",
      "Test set: Average loss: 3.9830, Accuracy: 1354/5000 (27%)\n",
      "[epoch 29] loss: 0.0030162\n",
      "Test set: Average loss: 3.9977, Accuracy: 1355/5000 (27%)\n",
      "[epoch 30] loss: 0.0027995\n",
      "Test set: Average loss: 4.0095, Accuracy: 1361/5000 (27%)\n",
      "[epoch 31] loss: 0.0026067\n",
      "Test set: Average loss: 4.0309, Accuracy: 1355/5000 (27%)\n",
      "[epoch 32] loss: 0.0024521\n",
      "Test set: Average loss: 4.0454, Accuracy: 1356/5000 (27%)\n",
      "[epoch 33] loss: 0.0022889\n",
      "Test set: Average loss: 4.0580, Accuracy: 1358/5000 (27%)\n",
      "[epoch 34] loss: 0.0021604\n",
      "Test set: Average loss: 4.0739, Accuracy: 1359/5000 (27%)\n",
      "[epoch 35] loss: 0.0020251\n",
      "Test set: Average loss: 4.0870, Accuracy: 1355/5000 (27%)\n",
      "[epoch 36] loss: 0.0019055\n",
      "Test set: Average loss: 4.0989, Accuracy: 1358/5000 (27%)\n",
      "[epoch 37] loss: 0.0018034\n",
      "Test set: Average loss: 4.1116, Accuracy: 1361/5000 (27%)\n",
      "[epoch 38] loss: 0.0017103\n",
      "Test set: Average loss: 4.1265, Accuracy: 1364/5000 (27%)\n",
      "[epoch 39] loss: 0.0016135\n",
      "Test set: Average loss: 4.1366, Accuracy: 1353/5000 (27%)\n",
      "[epoch 40] loss: 0.0015373\n",
      "Test set: Average loss: 4.1519, Accuracy: 1357/5000 (27%)\n",
      "[epoch 41] loss: 0.0014612\n",
      "Test set: Average loss: 4.1648, Accuracy: 1354/5000 (27%)\n",
      "[epoch 42] loss: 0.0013907\n",
      "Test set: Average loss: 4.1725, Accuracy: 1355/5000 (27%)\n",
      "[epoch 43] loss: 0.0013235\n",
      "Test set: Average loss: 4.1838, Accuracy: 1357/5000 (27%)\n",
      "[epoch 44] loss: 0.0012672\n",
      "Test set: Average loss: 4.1957, Accuracy: 1361/5000 (27%)\n",
      "[epoch 45] loss: 0.0011997\n",
      "Test set: Average loss: 4.2060, Accuracy: 1363/5000 (27%)\n",
      "[epoch 46] loss: 0.0011559\n",
      "Test set: Average loss: 4.2166, Accuracy: 1361/5000 (27%)\n",
      "[epoch 47] loss: 0.0011047\n",
      "Test set: Average loss: 4.2225, Accuracy: 1362/5000 (27%)\n",
      "[epoch 48] loss: 0.0010573\n",
      "Test set: Average loss: 4.2356, Accuracy: 1357/5000 (27%)\n",
      "[epoch 49] loss: 0.0010118\n",
      "Test set: Average loss: 4.2461, Accuracy: 1355/5000 (27%)\n",
      "[epoch 50] loss: 0.0009713\n",
      "Test set: Average loss: 4.2564, Accuracy: 1357/5000 (27%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.4007, Accuracy: 1403/5000 (28%)\n",
      "Test\n",
      "Test set: Average loss: 3.3879, Accuracy: 2815/10000 (28%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3021, Accuracy: 520/5000 (10%)\n",
      "[epoch 1] loss: 2.2762654\n",
      "Test set: Average loss: 2.2043, Accuracy: 1086/5000 (22%)\n",
      "[epoch 2] loss: 1.9858348\n",
      "Test set: Average loss: 2.0518, Accuracy: 1257/5000 (25%)\n",
      "[epoch 3] loss: 1.6468373\n",
      "Test set: Average loss: 2.1458, Accuracy: 1262/5000 (25%)\n",
      "[epoch 4] loss: 1.4497620\n",
      "Test set: Average loss: 2.1148, Accuracy: 1463/5000 (29%)\n",
      "[epoch 5] loss: 1.2323841\n",
      "Test set: Average loss: 2.2531, Accuracy: 1412/5000 (28%)\n",
      "[epoch 6] loss: 1.0585737\n",
      "Test set: Average loss: 2.1646, Accuracy: 1548/5000 (31%)\n",
      "[epoch 7] loss: 0.7692461\n",
      "Test set: Average loss: 2.2313, Accuracy: 1562/5000 (31%)\n",
      "[epoch 8] loss: 0.5950858\n",
      "Test set: Average loss: 2.3405, Accuracy: 1558/5000 (31%)\n",
      "[epoch 9] loss: 0.4203700\n",
      "Test set: Average loss: 2.5793, Accuracy: 1560/5000 (31%)\n",
      "[epoch 10] loss: 0.2899841\n",
      "Test set: Average loss: 2.6880, Accuracy: 1569/5000 (31%)\n",
      "[epoch 11] loss: 0.1972593\n",
      "Test set: Average loss: 2.8030, Accuracy: 1570/5000 (31%)\n",
      "[epoch 12] loss: 0.1189456\n",
      "Test set: Average loss: 2.8636, Accuracy: 1580/5000 (32%)\n",
      "[epoch 13] loss: 0.0802551\n",
      "Test set: Average loss: 3.0845, Accuracy: 1554/5000 (31%)\n",
      "[epoch 14] loss: 0.0691529\n",
      "Test set: Average loss: 3.2171, Accuracy: 1519/5000 (30%)\n",
      "[epoch 15] loss: 0.0541078\n",
      "Test set: Average loss: 3.2998, Accuracy: 1501/5000 (30%)\n",
      "[epoch 16] loss: 0.0318661\n",
      "Test set: Average loss: 3.2818, Accuracy: 1573/5000 (31%)\n",
      "[epoch 17] loss: 0.0227615\n",
      "Test set: Average loss: 3.3823, Accuracy: 1555/5000 (31%)\n",
      "[epoch 18] loss: 0.0166639\n",
      "Test set: Average loss: 3.4159, Accuracy: 1545/5000 (31%)\n",
      "[epoch 19] loss: 0.0130765\n",
      "Test set: Average loss: 3.4339, Accuracy: 1558/5000 (31%)\n",
      "[epoch 20] loss: 0.0110438\n",
      "Test set: Average loss: 3.4749, Accuracy: 1563/5000 (31%)\n",
      "[epoch 21] loss: 0.0090872\n",
      "Test set: Average loss: 3.5080, Accuracy: 1559/5000 (31%)\n",
      "[epoch 22] loss: 0.0078838\n",
      "Test set: Average loss: 3.5318, Accuracy: 1555/5000 (31%)\n",
      "[epoch 23] loss: 0.0069798\n",
      "Test set: Average loss: 3.5546, Accuracy: 1566/5000 (31%)\n",
      "[epoch 24] loss: 0.0062354\n",
      "Test set: Average loss: 3.5852, Accuracy: 1573/5000 (31%)\n",
      "[epoch 25] loss: 0.0055277\n",
      "Test set: Average loss: 3.6033, Accuracy: 1573/5000 (31%)\n",
      "[epoch 26] loss: 0.0050551\n",
      "Test set: Average loss: 3.6259, Accuracy: 1573/5000 (31%)\n",
      "[epoch 27] loss: 0.0044682\n",
      "Test set: Average loss: 3.6477, Accuracy: 1566/5000 (31%)\n",
      "[epoch 28] loss: 0.0040448\n",
      "Test set: Average loss: 3.6675, Accuracy: 1568/5000 (31%)\n",
      "[epoch 29] loss: 0.0036943\n",
      "Test set: Average loss: 3.6846, Accuracy: 1565/5000 (31%)\n",
      "[epoch 30] loss: 0.0033653\n",
      "Test set: Average loss: 3.7073, Accuracy: 1566/5000 (31%)\n",
      "[epoch 31] loss: 0.0030779\n",
      "Test set: Average loss: 3.7255, Accuracy: 1567/5000 (31%)\n",
      "[epoch 32] loss: 0.0028227\n",
      "Test set: Average loss: 3.7377, Accuracy: 1571/5000 (31%)\n",
      "[epoch 33] loss: 0.0026140\n",
      "Test set: Average loss: 3.7566, Accuracy: 1557/5000 (31%)\n",
      "[epoch 34] loss: 0.0024396\n",
      "Test set: Average loss: 3.7724, Accuracy: 1573/5000 (31%)\n",
      "[epoch 35] loss: 0.0022352\n",
      "Test set: Average loss: 3.7885, Accuracy: 1568/5000 (31%)\n",
      "[epoch 36] loss: 0.0020791\n",
      "Test set: Average loss: 3.8013, Accuracy: 1570/5000 (31%)\n",
      "[epoch 37] loss: 0.0019391\n",
      "Test set: Average loss: 3.8177, Accuracy: 1566/5000 (31%)\n",
      "[epoch 38] loss: 0.0018007\n",
      "Test set: Average loss: 3.8348, Accuracy: 1570/5000 (31%)\n",
      "[epoch 39] loss: 0.0017113\n",
      "Test set: Average loss: 3.8526, Accuracy: 1572/5000 (31%)\n",
      "[epoch 40] loss: 0.0015965\n",
      "Test set: Average loss: 3.8695, Accuracy: 1570/5000 (31%)\n",
      "[epoch 41] loss: 0.0014999\n",
      "Test set: Average loss: 3.8805, Accuracy: 1567/5000 (31%)\n",
      "[epoch 42] loss: 0.0014170\n",
      "Test set: Average loss: 3.8908, Accuracy: 1572/5000 (31%)\n",
      "[epoch 43] loss: 0.0013407\n",
      "Test set: Average loss: 3.9043, Accuracy: 1563/5000 (31%)\n",
      "[epoch 44] loss: 0.0012741\n",
      "Test set: Average loss: 3.9194, Accuracy: 1566/5000 (31%)\n",
      "[epoch 45] loss: 0.0012183\n",
      "Test set: Average loss: 3.9320, Accuracy: 1576/5000 (32%)\n",
      "[epoch 46] loss: 0.0011509\n",
      "Test set: Average loss: 3.9418, Accuracy: 1570/5000 (31%)\n",
      "[epoch 47] loss: 0.0011075\n",
      "Test set: Average loss: 3.9546, Accuracy: 1569/5000 (31%)\n",
      "[epoch 48] loss: 0.0010439\n",
      "Test set: Average loss: 3.9677, Accuracy: 1568/5000 (31%)\n",
      "[epoch 49] loss: 0.0009973\n",
      "Test set: Average loss: 3.9782, Accuracy: 1563/5000 (31%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.0009675\n",
      "Test set: Average loss: 3.9868, Accuracy: 1558/5000 (31%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8636, Accuracy: 1580/5000 (32%)\n",
      "Test\n",
      "Test set: Average loss: 2.8154, Accuracy: 3238/10000 (32%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 434/5000 (9%)\n",
      "[epoch 1] loss: 2.2758804\n",
      "Test set: Average loss: 2.2120, Accuracy: 891/5000 (18%)\n",
      "[epoch 2] loss: 2.0534900\n",
      "Test set: Average loss: 2.1147, Accuracy: 1152/5000 (23%)\n",
      "[epoch 3] loss: 1.8345903\n",
      "Test set: Average loss: 2.0970, Accuracy: 1237/5000 (25%)\n",
      "[epoch 4] loss: 1.6826785\n",
      "Test set: Average loss: 1.9981, Accuracy: 1498/5000 (30%)\n",
      "[epoch 5] loss: 1.4193366\n",
      "Test set: Average loss: 2.0270, Accuracy: 1451/5000 (29%)\n",
      "[epoch 6] loss: 1.1554305\n",
      "Test set: Average loss: 2.0855, Accuracy: 1553/5000 (31%)\n",
      "[epoch 7] loss: 0.9444771\n",
      "Test set: Average loss: 2.2880, Accuracy: 1570/5000 (31%)\n",
      "[epoch 8] loss: 0.7351140\n",
      "Test set: Average loss: 2.4356, Accuracy: 1444/5000 (29%)\n",
      "[epoch 9] loss: 0.4746980\n",
      "Test set: Average loss: 2.6833, Accuracy: 1516/5000 (30%)\n",
      "[epoch 10] loss: 0.3455048\n",
      "Test set: Average loss: 2.7294, Accuracy: 1525/5000 (30%)\n",
      "[epoch 11] loss: 0.2067427\n",
      "Test set: Average loss: 2.9135, Accuracy: 1524/5000 (30%)\n",
      "[epoch 12] loss: 0.1603625\n",
      "Test set: Average loss: 3.1724, Accuracy: 1482/5000 (30%)\n",
      "[epoch 13] loss: 0.1066370\n",
      "Test set: Average loss: 3.3073, Accuracy: 1446/5000 (29%)\n",
      "[epoch 14] loss: 0.0814750\n",
      "Test set: Average loss: 3.3838, Accuracy: 1477/5000 (30%)\n",
      "[epoch 15] loss: 0.0533826\n",
      "Test set: Average loss: 3.4297, Accuracy: 1497/5000 (30%)\n",
      "[epoch 16] loss: 0.0368918\n",
      "Test set: Average loss: 3.5257, Accuracy: 1493/5000 (30%)\n",
      "[epoch 17] loss: 0.0270250\n",
      "Test set: Average loss: 3.5914, Accuracy: 1505/5000 (30%)\n",
      "[epoch 18] loss: 0.0167792\n",
      "Test set: Average loss: 3.6436, Accuracy: 1482/5000 (30%)\n",
      "[epoch 19] loss: 0.0122762\n",
      "Test set: Average loss: 3.7065, Accuracy: 1475/5000 (30%)\n",
      "[epoch 20] loss: 0.0101707\n",
      "Test set: Average loss: 3.7233, Accuracy: 1509/5000 (30%)\n",
      "[epoch 21] loss: 0.0084721\n",
      "Test set: Average loss: 3.7533, Accuracy: 1505/5000 (30%)\n",
      "[epoch 22] loss: 0.0075919\n",
      "Test set: Average loss: 3.7842, Accuracy: 1509/5000 (30%)\n",
      "[epoch 23] loss: 0.0067040\n",
      "Test set: Average loss: 3.8093, Accuracy: 1505/5000 (30%)\n",
      "[epoch 24] loss: 0.0060525\n",
      "Test set: Average loss: 3.8387, Accuracy: 1507/5000 (30%)\n",
      "[epoch 25] loss: 0.0055582\n",
      "Test set: Average loss: 3.8625, Accuracy: 1508/5000 (30%)\n",
      "[epoch 26] loss: 0.0051258\n",
      "Test set: Average loss: 3.8878, Accuracy: 1507/5000 (30%)\n",
      "[epoch 27] loss: 0.0047576\n",
      "Test set: Average loss: 3.9013, Accuracy: 1512/5000 (30%)\n",
      "[epoch 28] loss: 0.0043846\n",
      "Test set: Average loss: 3.9194, Accuracy: 1502/5000 (30%)\n",
      "[epoch 29] loss: 0.0041209\n",
      "Test set: Average loss: 3.9429, Accuracy: 1506/5000 (30%)\n",
      "[epoch 30] loss: 0.0038224\n",
      "Test set: Average loss: 3.9564, Accuracy: 1502/5000 (30%)\n",
      "[epoch 31] loss: 0.0035975\n",
      "Test set: Average loss: 3.9747, Accuracy: 1499/5000 (30%)\n",
      "[epoch 32] loss: 0.0033772\n",
      "Test set: Average loss: 3.9950, Accuracy: 1494/5000 (30%)\n",
      "[epoch 33] loss: 0.0031928\n",
      "Test set: Average loss: 4.0140, Accuracy: 1495/5000 (30%)\n",
      "[epoch 34] loss: 0.0030316\n",
      "Test set: Average loss: 4.0265, Accuracy: 1500/5000 (30%)\n",
      "[epoch 35] loss: 0.0028493\n",
      "Test set: Average loss: 4.0381, Accuracy: 1503/5000 (30%)\n",
      "[epoch 36] loss: 0.0027064\n",
      "Test set: Average loss: 4.0535, Accuracy: 1497/5000 (30%)\n",
      "[epoch 37] loss: 0.0025685\n",
      "Test set: Average loss: 4.0700, Accuracy: 1501/5000 (30%)\n",
      "[epoch 38] loss: 0.0024577\n",
      "Test set: Average loss: 4.0814, Accuracy: 1497/5000 (30%)\n",
      "[epoch 39] loss: 0.0023245\n",
      "Test set: Average loss: 4.0954, Accuracy: 1498/5000 (30%)\n",
      "[epoch 40] loss: 0.0022281\n",
      "Test set: Average loss: 4.1101, Accuracy: 1498/5000 (30%)\n",
      "[epoch 41] loss: 0.0021337\n",
      "Test set: Average loss: 4.1226, Accuracy: 1499/5000 (30%)\n",
      "[epoch 42] loss: 0.0020396\n",
      "Test set: Average loss: 4.1350, Accuracy: 1502/5000 (30%)\n",
      "[epoch 43] loss: 0.0019483\n",
      "Test set: Average loss: 4.1458, Accuracy: 1496/5000 (30%)\n",
      "[epoch 44] loss: 0.0018832\n",
      "Test set: Average loss: 4.1578, Accuracy: 1496/5000 (30%)\n",
      "[epoch 45] loss: 0.0017983\n",
      "Test set: Average loss: 4.1700, Accuracy: 1495/5000 (30%)\n",
      "[epoch 46] loss: 0.0017263\n",
      "Test set: Average loss: 4.1804, Accuracy: 1500/5000 (30%)\n",
      "[epoch 47] loss: 0.0016582\n",
      "Test set: Average loss: 4.1939, Accuracy: 1496/5000 (30%)\n",
      "[epoch 48] loss: 0.0015852\n",
      "Test set: Average loss: 4.2038, Accuracy: 1494/5000 (30%)\n",
      "[epoch 49] loss: 0.0015382\n",
      "Test set: Average loss: 4.2150, Accuracy: 1493/5000 (30%)\n",
      "[epoch 50] loss: 0.0014746\n",
      "Test set: Average loss: 4.2250, Accuracy: 1491/5000 (30%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2880, Accuracy: 1570/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.3096, Accuracy: 3094/10000 (31%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3052, Accuracy: 435/5000 (9%)\n",
      "[epoch 1] loss: 2.2498801\n",
      "Test set: Average loss: 2.1076, Accuracy: 1073/5000 (21%)\n",
      "[epoch 2] loss: 1.9389759\n",
      "Test set: Average loss: 2.0650, Accuracy: 1181/5000 (24%)\n",
      "[epoch 3] loss: 1.7859919\n",
      "Test set: Average loss: 1.9416, Accuracy: 1500/5000 (30%)\n",
      "[epoch 4] loss: 1.5976221\n",
      "Test set: Average loss: 1.8802, Accuracy: 1685/5000 (34%)\n",
      "[epoch 5] loss: 1.4199128\n",
      "Test set: Average loss: 1.8946, Accuracy: 1757/5000 (35%)\n",
      "[epoch 6] loss: 1.2309135\n",
      "Test set: Average loss: 1.9326, Accuracy: 1749/5000 (35%)\n",
      "[epoch 7] loss: 1.0425673\n",
      "Test set: Average loss: 2.0641, Accuracy: 1770/5000 (35%)\n",
      "[epoch 8] loss: 0.9010230\n",
      "Test set: Average loss: 2.2346, Accuracy: 1610/5000 (32%)\n",
      "[epoch 9] loss: 0.7576213\n",
      "Test set: Average loss: 2.4123, Accuracy: 1711/5000 (34%)\n",
      "[epoch 10] loss: 0.6183000\n",
      "Test set: Average loss: 2.4879, Accuracy: 1803/5000 (36%)\n",
      "[epoch 11] loss: 0.4914421\n",
      "Test set: Average loss: 2.6081, Accuracy: 1748/5000 (35%)\n",
      "[epoch 12] loss: 0.3355256\n",
      "Test set: Average loss: 2.7214, Accuracy: 1714/5000 (34%)\n",
      "[epoch 13] loss: 0.2172743\n",
      "Test set: Average loss: 2.9510, Accuracy: 1705/5000 (34%)\n",
      "[epoch 14] loss: 0.1610996\n",
      "Test set: Average loss: 3.1361, Accuracy: 1708/5000 (34%)\n",
      "[epoch 15] loss: 0.1012520\n",
      "Test set: Average loss: 3.2389, Accuracy: 1712/5000 (34%)\n",
      "[epoch 16] loss: 0.0560356\n",
      "Test set: Average loss: 3.2942, Accuracy: 1724/5000 (34%)\n",
      "[epoch 17] loss: 0.0317879\n",
      "Test set: Average loss: 3.3960, Accuracy: 1742/5000 (35%)\n",
      "[epoch 18] loss: 0.0220028\n",
      "Test set: Average loss: 3.4512, Accuracy: 1762/5000 (35%)\n",
      "[epoch 19] loss: 0.0161296\n",
      "Test set: Average loss: 3.5262, Accuracy: 1746/5000 (35%)\n",
      "[epoch 20] loss: 0.0134697\n",
      "Test set: Average loss: 3.5712, Accuracy: 1753/5000 (35%)\n",
      "[epoch 21] loss: 0.0108252\n",
      "Test set: Average loss: 3.6150, Accuracy: 1737/5000 (35%)\n",
      "[epoch 22] loss: 0.0094985\n",
      "Test set: Average loss: 3.6529, Accuracy: 1743/5000 (35%)\n",
      "[epoch 23] loss: 0.0082897\n",
      "Test set: Average loss: 3.6992, Accuracy: 1736/5000 (35%)\n",
      "[epoch 24] loss: 0.0073405\n",
      "Test set: Average loss: 3.7327, Accuracy: 1738/5000 (35%)\n",
      "[epoch 25] loss: 0.0068146\n",
      "Test set: Average loss: 3.7681, Accuracy: 1737/5000 (35%)\n",
      "[epoch 26] loss: 0.0061227\n",
      "Test set: Average loss: 3.7998, Accuracy: 1734/5000 (35%)\n",
      "[epoch 27] loss: 0.0055282\n",
      "Test set: Average loss: 3.8279, Accuracy: 1732/5000 (35%)\n",
      "[epoch 28] loss: 0.0049877\n",
      "Test set: Average loss: 3.8575, Accuracy: 1734/5000 (35%)\n",
      "[epoch 29] loss: 0.0046285\n",
      "Test set: Average loss: 3.8849, Accuracy: 1738/5000 (35%)\n",
      "[epoch 30] loss: 0.0042015\n",
      "Test set: Average loss: 3.9137, Accuracy: 1735/5000 (35%)\n",
      "[epoch 31] loss: 0.0039343\n",
      "Test set: Average loss: 3.9342, Accuracy: 1740/5000 (35%)\n",
      "[epoch 32] loss: 0.0036420\n",
      "Test set: Average loss: 3.9630, Accuracy: 1735/5000 (35%)\n",
      "[epoch 33] loss: 0.0034310\n",
      "Test set: Average loss: 3.9813, Accuracy: 1734/5000 (35%)\n",
      "[epoch 34] loss: 0.0031857\n",
      "Test set: Average loss: 4.0094, Accuracy: 1743/5000 (35%)\n",
      "[epoch 35] loss: 0.0029807\n",
      "Test set: Average loss: 4.0253, Accuracy: 1734/5000 (35%)\n",
      "[epoch 36] loss: 0.0028128\n",
      "Test set: Average loss: 4.0464, Accuracy: 1743/5000 (35%)\n",
      "[epoch 37] loss: 0.0026507\n",
      "Test set: Average loss: 4.0721, Accuracy: 1727/5000 (35%)\n",
      "[epoch 38] loss: 0.0024764\n",
      "Test set: Average loss: 4.0845, Accuracy: 1735/5000 (35%)\n",
      "[epoch 39] loss: 0.0023548\n",
      "Test set: Average loss: 4.1014, Accuracy: 1743/5000 (35%)\n",
      "[epoch 40] loss: 0.0022218\n",
      "Test set: Average loss: 4.1193, Accuracy: 1734/5000 (35%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.0021242\n",
      "Test set: Average loss: 4.1370, Accuracy: 1737/5000 (35%)\n",
      "[epoch 42] loss: 0.0020078\n",
      "Test set: Average loss: 4.1582, Accuracy: 1732/5000 (35%)\n",
      "[epoch 43] loss: 0.0018996\n",
      "Test set: Average loss: 4.1730, Accuracy: 1734/5000 (35%)\n",
      "[epoch 44] loss: 0.0018188\n",
      "Test set: Average loss: 4.1859, Accuracy: 1736/5000 (35%)\n",
      "[epoch 45] loss: 0.0017202\n",
      "Test set: Average loss: 4.2017, Accuracy: 1730/5000 (35%)\n",
      "[epoch 46] loss: 0.0016514\n",
      "Test set: Average loss: 4.2166, Accuracy: 1732/5000 (35%)\n",
      "[epoch 47] loss: 0.0015923\n",
      "Test set: Average loss: 4.2344, Accuracy: 1731/5000 (35%)\n",
      "[epoch 48] loss: 0.0015275\n",
      "Test set: Average loss: 4.2486, Accuracy: 1732/5000 (35%)\n",
      "[epoch 49] loss: 0.0014510\n",
      "Test set: Average loss: 4.2615, Accuracy: 1724/5000 (34%)\n",
      "[epoch 50] loss: 0.0013935\n",
      "Test set: Average loss: 4.2766, Accuracy: 1726/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4879, Accuracy: 1803/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 2.4735, Accuracy: 3551/10000 (36%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 566/5000 (11%)\n",
      "[epoch 1] loss: 2.1807931\n",
      "Test set: Average loss: 2.0960, Accuracy: 1068/5000 (21%)\n",
      "[epoch 2] loss: 1.9246713\n",
      "Test set: Average loss: 2.0102, Accuracy: 1464/5000 (29%)\n",
      "[epoch 3] loss: 1.7364852\n",
      "Test set: Average loss: 1.9075, Accuracy: 1464/5000 (29%)\n",
      "[epoch 4] loss: 1.4977794\n",
      "Test set: Average loss: 1.8964, Accuracy: 1622/5000 (32%)\n",
      "[epoch 5] loss: 1.2517494\n",
      "Test set: Average loss: 1.9718, Accuracy: 1697/5000 (34%)\n",
      "[epoch 6] loss: 1.1160988\n",
      "Test set: Average loss: 2.0589, Accuracy: 1645/5000 (33%)\n",
      "[epoch 7] loss: 0.9610459\n",
      "Test set: Average loss: 2.1594, Accuracy: 1720/5000 (34%)\n",
      "[epoch 8] loss: 0.8410135\n",
      "Test set: Average loss: 2.1074, Accuracy: 1783/5000 (36%)\n",
      "[epoch 9] loss: 0.6156464\n",
      "Test set: Average loss: 2.3022, Accuracy: 1663/5000 (33%)\n",
      "[epoch 10] loss: 0.4636169\n",
      "Test set: Average loss: 2.4414, Accuracy: 1686/5000 (34%)\n",
      "[epoch 11] loss: 0.3375869\n",
      "Test set: Average loss: 2.5978, Accuracy: 1704/5000 (34%)\n",
      "[epoch 12] loss: 0.2304452\n",
      "Test set: Average loss: 2.7955, Accuracy: 1688/5000 (34%)\n",
      "[epoch 13] loss: 0.1686312\n",
      "Test set: Average loss: 2.9750, Accuracy: 1631/5000 (33%)\n",
      "[epoch 14] loss: 0.0966499\n",
      "Test set: Average loss: 3.0190, Accuracy: 1692/5000 (34%)\n",
      "[epoch 15] loss: 0.0698447\n",
      "Test set: Average loss: 3.0659, Accuracy: 1690/5000 (34%)\n",
      "[epoch 16] loss: 0.0429194\n",
      "Test set: Average loss: 3.1368, Accuracy: 1716/5000 (34%)\n",
      "[epoch 17] loss: 0.0277687\n",
      "Test set: Average loss: 3.2203, Accuracy: 1708/5000 (34%)\n",
      "[epoch 18] loss: 0.0207360\n",
      "Test set: Average loss: 3.2713, Accuracy: 1688/5000 (34%)\n",
      "[epoch 19] loss: 0.0148564\n",
      "Test set: Average loss: 3.3297, Accuracy: 1691/5000 (34%)\n",
      "[epoch 20] loss: 0.0123549\n",
      "Test set: Average loss: 3.3742, Accuracy: 1670/5000 (33%)\n",
      "[epoch 21] loss: 0.0117739\n",
      "Test set: Average loss: 3.3985, Accuracy: 1696/5000 (34%)\n",
      "[epoch 22] loss: 0.0143310\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.4983, Accuracy: 1688/5000 (34%)\n",
      "[epoch 23] loss: 0.0220040\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.4420, Accuracy: 1699/5000 (34%)\n",
      "[epoch 24] loss: 0.0091656\n",
      "Test set: Average loss: 3.4408, Accuracy: 1699/5000 (34%)\n",
      "[epoch 25] loss: 0.0087844\n",
      "Test set: Average loss: 3.4403, Accuracy: 1701/5000 (34%)\n",
      "[epoch 26] loss: 0.0086152\n",
      "Test set: Average loss: 3.4399, Accuracy: 1702/5000 (34%)\n",
      "[epoch 27] loss: 0.0084844\n",
      "Test set: Average loss: 3.4398, Accuracy: 1703/5000 (34%)\n",
      "[epoch 28] loss: 0.0084623\n",
      "Test set: Average loss: 3.4396, Accuracy: 1700/5000 (34%)\n",
      "[epoch 29] loss: 0.0083903\n",
      "Test set: Average loss: 3.4395, Accuracy: 1698/5000 (34%)\n",
      "[epoch 30] loss: 0.0082949\n",
      "Test set: Average loss: 3.4396, Accuracy: 1699/5000 (34%)\n",
      "[epoch 31] loss: 0.0082166\n",
      "Test set: Average loss: 3.4396, Accuracy: 1699/5000 (34%)\n",
      "[epoch 32] loss: 0.0081541\n",
      "Test set: Average loss: 3.4397, Accuracy: 1698/5000 (34%)\n",
      "[epoch 33] loss: 0.0080394\n",
      "Test set: Average loss: 3.4399, Accuracy: 1697/5000 (34%)\n",
      "[epoch 34] loss: 0.0080861\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 35] loss: 0.0080078\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 36] loss: 0.0081466\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 37] loss: 0.0080625\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 38] loss: 0.0079939\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 39] loss: 0.0080173\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 40] loss: 0.0080143\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 41] loss: 0.0079748\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 42] loss: 0.0079997\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 43] loss: 0.0079793\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 44] loss: 0.0079300\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 45] loss: 0.0079610\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 46] loss: 0.0080891\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 47] loss: 0.0079740\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 48] loss: 0.0080169\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 49] loss: 0.0079910\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "[epoch 50] loss: 0.0081735\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.4401, Accuracy: 1694/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1074, Accuracy: 1783/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 2.0736, Accuracy: 3625/10000 (36%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 567/5000 (11%)\n",
      "[epoch 1] loss: 2.2286833\n",
      "Test set: Average loss: 2.0711, Accuracy: 1190/5000 (24%)\n",
      "[epoch 2] loss: 1.9682670\n",
      "Test set: Average loss: 2.0257, Accuracy: 1417/5000 (28%)\n",
      "[epoch 3] loss: 1.7248962\n",
      "Test set: Average loss: 1.9569, Accuracy: 1486/5000 (30%)\n",
      "[epoch 4] loss: 1.5334836\n",
      "Test set: Average loss: 1.8901, Accuracy: 1715/5000 (34%)\n",
      "[epoch 5] loss: 1.2870964\n",
      "Test set: Average loss: 1.9684, Accuracy: 1753/5000 (35%)\n",
      "[epoch 6] loss: 1.0865724\n",
      "Test set: Average loss: 2.1086, Accuracy: 1676/5000 (34%)\n",
      "[epoch 7] loss: 0.8753324\n",
      "Test set: Average loss: 2.1384, Accuracy: 1786/5000 (36%)\n",
      "[epoch 8] loss: 0.7051710\n",
      "Test set: Average loss: 2.3573, Accuracy: 1722/5000 (34%)\n",
      "[epoch 9] loss: 0.6207374\n",
      "Test set: Average loss: 2.5825, Accuracy: 1597/5000 (32%)\n",
      "[epoch 10] loss: 0.4348938\n",
      "Test set: Average loss: 2.7068, Accuracy: 1624/5000 (32%)\n",
      "[epoch 11] loss: 0.3374967\n",
      "Test set: Average loss: 2.9013, Accuracy: 1700/5000 (34%)\n",
      "[epoch 12] loss: 0.2259685\n",
      "Test set: Average loss: 2.9949, Accuracy: 1708/5000 (34%)\n",
      "[epoch 13] loss: 0.1340954\n",
      "Test set: Average loss: 3.1303, Accuracy: 1657/5000 (33%)\n",
      "[epoch 14] loss: 0.0955753\n",
      "Test set: Average loss: 3.2858, Accuracy: 1681/5000 (34%)\n",
      "[epoch 15] loss: 0.0719592\n",
      "Test set: Average loss: 3.4060, Accuracy: 1707/5000 (34%)\n",
      "[epoch 16] loss: 0.0612713\n",
      "Test set: Average loss: 3.4749, Accuracy: 1695/5000 (34%)\n",
      "[epoch 17] loss: 0.0354699\n",
      "Test set: Average loss: 3.5739, Accuracy: 1674/5000 (33%)\n",
      "[epoch 18] loss: 0.0190549\n",
      "Test set: Average loss: 3.5960, Accuracy: 1693/5000 (34%)\n",
      "[epoch 19] loss: 0.0128095\n",
      "Test set: Average loss: 3.6268, Accuracy: 1702/5000 (34%)\n",
      "[epoch 20] loss: 0.0097791\n",
      "Test set: Average loss: 3.6716, Accuracy: 1735/5000 (35%)\n",
      "[epoch 21] loss: 0.0082118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.7084, Accuracy: 1717/5000 (34%)\n",
      "[epoch 22] loss: 0.0072081\n",
      "Test set: Average loss: 3.7358, Accuracy: 1721/5000 (34%)\n",
      "[epoch 23] loss: 0.0062972\n",
      "Test set: Average loss: 3.7681, Accuracy: 1721/5000 (34%)\n",
      "[epoch 24] loss: 0.0056025\n",
      "Test set: Average loss: 3.8056, Accuracy: 1723/5000 (34%)\n",
      "[epoch 25] loss: 0.0049683\n",
      "Test set: Average loss: 3.8293, Accuracy: 1720/5000 (34%)\n",
      "[epoch 26] loss: 0.0045755\n",
      "Test set: Average loss: 3.8540, Accuracy: 1721/5000 (34%)\n",
      "[epoch 27] loss: 0.0041375\n",
      "Test set: Average loss: 3.8809, Accuracy: 1718/5000 (34%)\n",
      "[epoch 28] loss: 0.0037901\n",
      "Test set: Average loss: 3.9089, Accuracy: 1709/5000 (34%)\n",
      "[epoch 29] loss: 0.0035525\n",
      "Test set: Average loss: 3.9302, Accuracy: 1712/5000 (34%)\n",
      "[epoch 30] loss: 0.0032490\n",
      "Test set: Average loss: 3.9477, Accuracy: 1709/5000 (34%)\n",
      "[epoch 31] loss: 0.0029875\n",
      "Test set: Average loss: 3.9776, Accuracy: 1701/5000 (34%)\n",
      "[epoch 32] loss: 0.0028154\n",
      "Test set: Average loss: 3.9885, Accuracy: 1697/5000 (34%)\n",
      "[epoch 33] loss: 0.0026105\n",
      "Test set: Average loss: 4.0169, Accuracy: 1711/5000 (34%)\n",
      "[epoch 34] loss: 0.0024289\n",
      "Test set: Average loss: 4.0369, Accuracy: 1699/5000 (34%)\n",
      "[epoch 35] loss: 0.0022612\n",
      "Test set: Average loss: 4.0479, Accuracy: 1695/5000 (34%)\n",
      "[epoch 36] loss: 0.0021305\n",
      "Test set: Average loss: 4.0704, Accuracy: 1701/5000 (34%)\n",
      "[epoch 37] loss: 0.0020199\n",
      "Test set: Average loss: 4.0851, Accuracy: 1693/5000 (34%)\n",
      "[epoch 38] loss: 0.0019038\n",
      "Test set: Average loss: 4.1075, Accuracy: 1700/5000 (34%)\n",
      "[epoch 39] loss: 0.0017941\n",
      "Test set: Average loss: 4.1164, Accuracy: 1693/5000 (34%)\n",
      "[epoch 40] loss: 0.0016890\n",
      "Test set: Average loss: 4.1377, Accuracy: 1697/5000 (34%)\n",
      "[epoch 41] loss: 0.0016140\n",
      "Test set: Average loss: 4.1482, Accuracy: 1696/5000 (34%)\n",
      "[epoch 42] loss: 0.0015324\n",
      "Test set: Average loss: 4.1670, Accuracy: 1693/5000 (34%)\n",
      "[epoch 43] loss: 0.0014378\n",
      "Test set: Average loss: 4.1836, Accuracy: 1693/5000 (34%)\n",
      "[epoch 44] loss: 0.0013678\n",
      "Test set: Average loss: 4.1927, Accuracy: 1698/5000 (34%)\n",
      "[epoch 45] loss: 0.0013198\n",
      "Test set: Average loss: 4.2115, Accuracy: 1698/5000 (34%)\n",
      "[epoch 46] loss: 0.0012601\n",
      "Test set: Average loss: 4.2260, Accuracy: 1695/5000 (34%)\n",
      "[epoch 47] loss: 0.0012044\n",
      "Test set: Average loss: 4.2366, Accuracy: 1697/5000 (34%)\n",
      "[epoch 48] loss: 0.0011437\n",
      "Test set: Average loss: 4.2445, Accuracy: 1699/5000 (34%)\n",
      "[epoch 49] loss: 0.0010924\n",
      "Test set: Average loss: 4.2646, Accuracy: 1699/5000 (34%)\n",
      "[epoch 50] loss: 0.0010383\n",
      "Test set: Average loss: 4.2746, Accuracy: 1700/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1384, Accuracy: 1786/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 2.1155, Accuracy: 3615/10000 (36%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 470/5000 (9%)\n",
      "[epoch 1] loss: 2.1651618\n",
      "Test set: Average loss: 1.9924, Accuracy: 1381/5000 (28%)\n",
      "[epoch 2] loss: 1.8428927\n",
      "Test set: Average loss: 1.8655, Accuracy: 1696/5000 (34%)\n",
      "[epoch 3] loss: 1.6039142\n",
      "Test set: Average loss: 1.8695, Accuracy: 1610/5000 (32%)\n",
      "[epoch 4] loss: 1.4532183\n",
      "Test set: Average loss: 1.8858, Accuracy: 1749/5000 (35%)\n",
      "[epoch 5] loss: 1.2655682\n",
      "Test set: Average loss: 2.0023, Accuracy: 1689/5000 (34%)\n",
      "[epoch 6] loss: 1.1694541\n",
      "Test set: Average loss: 1.9314, Accuracy: 1790/5000 (36%)\n",
      "[epoch 7] loss: 0.9893229\n",
      "Test set: Average loss: 2.1189, Accuracy: 1732/5000 (35%)\n",
      "[epoch 8] loss: 0.8407358\n",
      "Test set: Average loss: 2.1962, Accuracy: 1804/5000 (36%)\n",
      "[epoch 9] loss: 0.6896595\n",
      "Test set: Average loss: 2.5848, Accuracy: 1758/5000 (35%)\n",
      "[epoch 10] loss: 0.6314542\n",
      "Test set: Average loss: 2.4429, Accuracy: 1831/5000 (37%)\n",
      "[epoch 11] loss: 0.4286368\n",
      "Test set: Average loss: 2.6031, Accuracy: 1732/5000 (35%)\n",
      "[epoch 12] loss: 0.3052096\n",
      "Test set: Average loss: 2.7268, Accuracy: 1773/5000 (35%)\n",
      "[epoch 13] loss: 0.1920542\n",
      "Test set: Average loss: 2.8768, Accuracy: 1775/5000 (36%)\n",
      "[epoch 14] loss: 0.1366035\n",
      "Test set: Average loss: 2.9998, Accuracy: 1790/5000 (36%)\n",
      "[epoch 15] loss: 0.0880637\n",
      "Test set: Average loss: 3.1587, Accuracy: 1798/5000 (36%)\n",
      "[epoch 16] loss: 0.0524257\n",
      "Test set: Average loss: 3.2236, Accuracy: 1793/5000 (36%)\n",
      "[epoch 17] loss: 0.0333304\n",
      "Test set: Average loss: 3.2948, Accuracy: 1805/5000 (36%)\n",
      "[epoch 18] loss: 0.0240793\n",
      "Test set: Average loss: 3.3859, Accuracy: 1801/5000 (36%)\n",
      "[epoch 19] loss: 0.0182413\n",
      "Test set: Average loss: 3.4217, Accuracy: 1815/5000 (36%)\n",
      "[epoch 20] loss: 0.0134077\n",
      "Test set: Average loss: 3.4856, Accuracy: 1833/5000 (37%)\n",
      "[epoch 21] loss: 0.0107311\n",
      "Test set: Average loss: 3.5208, Accuracy: 1822/5000 (36%)\n",
      "[epoch 22] loss: 0.0089538\n",
      "Test set: Average loss: 3.5569, Accuracy: 1810/5000 (36%)\n",
      "[epoch 23] loss: 0.0078587\n",
      "Test set: Average loss: 3.5906, Accuracy: 1821/5000 (36%)\n",
      "[epoch 24] loss: 0.0070581\n",
      "Test set: Average loss: 3.6237, Accuracy: 1823/5000 (36%)\n",
      "[epoch 25] loss: 0.0063037\n",
      "Test set: Average loss: 3.6591, Accuracy: 1814/5000 (36%)\n",
      "[epoch 26] loss: 0.0056322\n",
      "Test set: Average loss: 3.6804, Accuracy: 1827/5000 (37%)\n",
      "[epoch 27] loss: 0.0050643\n",
      "Test set: Average loss: 3.7078, Accuracy: 1830/5000 (37%)\n",
      "[epoch 28] loss: 0.0046752\n",
      "Test set: Average loss: 3.7420, Accuracy: 1823/5000 (36%)\n",
      "[epoch 29] loss: 0.0042128\n",
      "Test set: Average loss: 3.7682, Accuracy: 1817/5000 (36%)\n",
      "[epoch 30] loss: 0.0038528\n",
      "Test set: Average loss: 3.7873, Accuracy: 1822/5000 (36%)\n",
      "[epoch 31] loss: 0.0035613\n",
      "Test set: Average loss: 3.8102, Accuracy: 1825/5000 (36%)\n",
      "[epoch 32] loss: 0.0032733\n",
      "Test set: Average loss: 3.8298, Accuracy: 1821/5000 (36%)\n",
      "[epoch 33] loss: 0.0030955\n",
      "Test set: Average loss: 3.8536, Accuracy: 1821/5000 (36%)\n",
      "[epoch 34] loss: 0.0028647\n",
      "Test set: Average loss: 3.8742, Accuracy: 1819/5000 (36%)\n",
      "[epoch 35] loss: 0.0026374\n",
      "Test set: Average loss: 3.8931, Accuracy: 1822/5000 (36%)\n",
      "[epoch 36] loss: 0.0024761\n",
      "Test set: Average loss: 3.9151, Accuracy: 1820/5000 (36%)\n",
      "[epoch 37] loss: 0.0023367\n",
      "Test set: Average loss: 3.9304, Accuracy: 1815/5000 (36%)\n",
      "[epoch 38] loss: 0.0021689\n",
      "Test set: Average loss: 3.9474, Accuracy: 1814/5000 (36%)\n",
      "[epoch 39] loss: 0.0020559\n",
      "Test set: Average loss: 3.9648, Accuracy: 1811/5000 (36%)\n",
      "[epoch 40] loss: 0.0019344\n",
      "Test set: Average loss: 3.9815, Accuracy: 1816/5000 (36%)\n",
      "[epoch 41] loss: 0.0018440\n",
      "Test set: Average loss: 3.9959, Accuracy: 1809/5000 (36%)\n",
      "[epoch 42] loss: 0.0017322\n",
      "Test set: Average loss: 4.0144, Accuracy: 1813/5000 (36%)\n",
      "[epoch 43] loss: 0.0016641\n",
      "Test set: Average loss: 4.0274, Accuracy: 1810/5000 (36%)\n",
      "[epoch 44] loss: 0.0015633\n",
      "Test set: Average loss: 4.0421, Accuracy: 1817/5000 (36%)\n",
      "[epoch 45] loss: 0.0014702\n",
      "Test set: Average loss: 4.0580, Accuracy: 1809/5000 (36%)\n",
      "[epoch 46] loss: 0.0014084\n",
      "Test set: Average loss: 4.0701, Accuracy: 1812/5000 (36%)\n",
      "[epoch 47] loss: 0.0013521\n",
      "Test set: Average loss: 4.0844, Accuracy: 1807/5000 (36%)\n",
      "[epoch 48] loss: 0.0012778\n",
      "Test set: Average loss: 4.0978, Accuracy: 1801/5000 (36%)\n",
      "[epoch 49] loss: 0.0012263\n",
      "Test set: Average loss: 4.1108, Accuracy: 1806/5000 (36%)\n",
      "[epoch 50] loss: 0.0011720\n",
      "Test set: Average loss: 4.1232, Accuracy: 1806/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.4856, Accuracy: 1833/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 3.4518, Accuracy: 3657/10000 (37%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3020, Accuracy: 466/5000 (9%)\n",
      "[epoch 1] loss: 2.1389405\n",
      "Test set: Average loss: 2.0935, Accuracy: 1241/5000 (25%)\n",
      "[epoch 2] loss: 1.8632607\n",
      "Test set: Average loss: 1.9340, Accuracy: 1528/5000 (31%)\n",
      "[epoch 3] loss: 1.6319023\n",
      "Test set: Average loss: 1.8758, Accuracy: 1639/5000 (33%)\n",
      "[epoch 4] loss: 1.3728299\n",
      "Test set: Average loss: 1.9080, Accuracy: 1732/5000 (35%)\n",
      "[epoch 5] loss: 1.1654830\n",
      "Test set: Average loss: 1.8415, Accuracy: 1841/5000 (37%)\n",
      "[epoch 6] loss: 1.0350719\n",
      "Test set: Average loss: 1.9666, Accuracy: 1797/5000 (36%)\n",
      "[epoch 7] loss: 0.8976471\n",
      "Test set: Average loss: 2.1334, Accuracy: 1836/5000 (37%)\n",
      "[epoch 8] loss: 0.8196547\n",
      "Test set: Average loss: 2.1660, Accuracy: 1867/5000 (37%)\n",
      "[epoch 9] loss: 0.6468777\n",
      "Test set: Average loss: 2.3963, Accuracy: 1861/5000 (37%)\n",
      "[epoch 10] loss: 0.4802984\n",
      "Test set: Average loss: 2.4340, Accuracy: 1907/5000 (38%)\n",
      "[epoch 11] loss: 0.3670943\n",
      "Test set: Average loss: 2.6596, Accuracy: 1881/5000 (38%)\n",
      "[epoch 12] loss: 0.3328312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.6785, Accuracy: 1931/5000 (39%)\n",
      "[epoch 13] loss: 0.2210308\n",
      "Test set: Average loss: 2.8561, Accuracy: 1881/5000 (38%)\n",
      "[epoch 14] loss: 0.1504212\n",
      "Test set: Average loss: 2.9638, Accuracy: 1880/5000 (38%)\n",
      "[epoch 15] loss: 0.1149496\n",
      "Test set: Average loss: 3.1178, Accuracy: 1845/5000 (37%)\n",
      "[epoch 16] loss: 0.0734043\n",
      "Test set: Average loss: 3.1870, Accuracy: 1863/5000 (37%)\n",
      "[epoch 17] loss: 0.0447170\n",
      "Test set: Average loss: 3.2544, Accuracy: 1869/5000 (37%)\n",
      "[epoch 18] loss: 0.0314960\n",
      "Test set: Average loss: 3.3300, Accuracy: 1868/5000 (37%)\n",
      "[epoch 19] loss: 0.0240471\n",
      "Test set: Average loss: 3.3753, Accuracy: 1874/5000 (37%)\n",
      "[epoch 20] loss: 0.0160165\n",
      "Test set: Average loss: 3.4353, Accuracy: 1875/5000 (38%)\n",
      "[epoch 21] loss: 0.0136311\n",
      "Test set: Average loss: 3.5066, Accuracy: 1863/5000 (37%)\n",
      "[epoch 22] loss: 0.0112717\n",
      "Test set: Average loss: 3.5438, Accuracy: 1884/5000 (38%)\n",
      "[epoch 23] loss: 0.0101731\n",
      "Test set: Average loss: 3.5755, Accuracy: 1864/5000 (37%)\n",
      "[epoch 24] loss: 0.0087538\n",
      "Test set: Average loss: 3.6165, Accuracy: 1878/5000 (38%)\n",
      "[epoch 25] loss: 0.0077502\n",
      "Test set: Average loss: 3.6454, Accuracy: 1863/5000 (37%)\n",
      "[epoch 26] loss: 0.0069193\n",
      "Test set: Average loss: 3.6864, Accuracy: 1862/5000 (37%)\n",
      "[epoch 27] loss: 0.0060970\n",
      "Test set: Average loss: 3.7151, Accuracy: 1862/5000 (37%)\n",
      "[epoch 28] loss: 0.0055803\n",
      "Test set: Average loss: 3.7459, Accuracy: 1863/5000 (37%)\n",
      "[epoch 29] loss: 0.0050925\n",
      "Test set: Average loss: 3.7737, Accuracy: 1873/5000 (37%)\n",
      "[epoch 30] loss: 0.0046989\n",
      "Test set: Average loss: 3.7969, Accuracy: 1868/5000 (37%)\n",
      "[epoch 31] loss: 0.0043112\n",
      "Test set: Average loss: 3.8238, Accuracy: 1865/5000 (37%)\n",
      "[epoch 32] loss: 0.0040169\n",
      "Test set: Average loss: 3.8460, Accuracy: 1868/5000 (37%)\n",
      "[epoch 33] loss: 0.0037427\n",
      "Test set: Average loss: 3.8688, Accuracy: 1869/5000 (37%)\n",
      "[epoch 34] loss: 0.0035063\n",
      "Test set: Average loss: 3.8898, Accuracy: 1874/5000 (37%)\n",
      "[epoch 35] loss: 0.0033087\n",
      "Test set: Average loss: 3.9158, Accuracy: 1874/5000 (37%)\n",
      "[epoch 36] loss: 0.0030573\n",
      "Test set: Average loss: 3.9326, Accuracy: 1861/5000 (37%)\n",
      "[epoch 37] loss: 0.0028486\n",
      "Test set: Average loss: 3.9555, Accuracy: 1875/5000 (38%)\n",
      "[epoch 38] loss: 0.0027023\n",
      "Test set: Average loss: 3.9704, Accuracy: 1868/5000 (37%)\n",
      "[epoch 39] loss: 0.0025382\n",
      "Test set: Average loss: 3.9904, Accuracy: 1868/5000 (37%)\n",
      "[epoch 40] loss: 0.0024169\n",
      "Test set: Average loss: 4.0099, Accuracy: 1872/5000 (37%)\n",
      "[epoch 41] loss: 0.0023031\n",
      "Test set: Average loss: 4.0268, Accuracy: 1870/5000 (37%)\n",
      "[epoch 42] loss: 0.0021717\n",
      "Test set: Average loss: 4.0405, Accuracy: 1865/5000 (37%)\n",
      "[epoch 43] loss: 0.0020479\n",
      "Test set: Average loss: 4.0609, Accuracy: 1871/5000 (37%)\n",
      "[epoch 44] loss: 0.0019330\n",
      "Test set: Average loss: 4.0782, Accuracy: 1872/5000 (37%)\n",
      "[epoch 45] loss: 0.0018466\n",
      "Test set: Average loss: 4.0935, Accuracy: 1874/5000 (37%)\n",
      "[epoch 46] loss: 0.0017693\n",
      "Test set: Average loss: 4.1063, Accuracy: 1870/5000 (37%)\n",
      "[epoch 47] loss: 0.0016893\n",
      "Test set: Average loss: 4.1211, Accuracy: 1873/5000 (37%)\n",
      "[epoch 48] loss: 0.0016175\n",
      "Test set: Average loss: 4.1383, Accuracy: 1867/5000 (37%)\n",
      "[epoch 49] loss: 0.0015465\n",
      "Test set: Average loss: 4.1501, Accuracy: 1872/5000 (37%)\n",
      "[epoch 50] loss: 0.0014623\n",
      "Test set: Average loss: 4.1782, Accuracy: 1868/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6785, Accuracy: 1931/5000 (39%)\n",
      "Test\n",
      "Test set: Average loss: 2.6779, Accuracy: 3894/10000 (39%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3038, Accuracy: 524/5000 (10%)\n",
      "[epoch 1] loss: 2.1972003\n",
      "Test set: Average loss: 2.1059, Accuracy: 985/5000 (20%)\n",
      "[epoch 2] loss: 1.9582219\n",
      "Test set: Average loss: 1.9459, Accuracy: 1564/5000 (31%)\n",
      "[epoch 3] loss: 1.8125439\n",
      "Test set: Average loss: 1.8531, Accuracy: 1735/5000 (35%)\n",
      "[epoch 4] loss: 1.6504513\n",
      "Test set: Average loss: 1.7849, Accuracy: 1817/5000 (36%)\n",
      "[epoch 5] loss: 1.4832012\n",
      "Test set: Average loss: 1.8790, Accuracy: 1794/5000 (36%)\n",
      "[epoch 6] loss: 1.3213240\n",
      "Test set: Average loss: 1.8765, Accuracy: 1809/5000 (36%)\n",
      "[epoch 7] loss: 1.2172877\n",
      "Test set: Average loss: 1.9061, Accuracy: 1822/5000 (36%)\n",
      "[epoch 8] loss: 1.0629940\n",
      "Test set: Average loss: 2.0245, Accuracy: 1824/5000 (36%)\n",
      "[epoch 9] loss: 0.8718325\n",
      "Test set: Average loss: 2.2349, Accuracy: 1734/5000 (35%)\n",
      "[epoch 10] loss: 0.8405482\n",
      "Test set: Average loss: 2.3642, Accuracy: 1749/5000 (35%)\n",
      "[epoch 11] loss: 0.7305296\n",
      "Test set: Average loss: 2.5612, Accuracy: 1697/5000 (34%)\n",
      "[epoch 12] loss: 0.5213774\n",
      "Test set: Average loss: 2.6316, Accuracy: 1759/5000 (35%)\n",
      "[epoch 13] loss: 0.3705871\n",
      "Test set: Average loss: 2.8134, Accuracy: 1732/5000 (35%)\n",
      "[epoch 14] loss: 0.2511131\n",
      "Test set: Average loss: 2.9871, Accuracy: 1768/5000 (35%)\n",
      "[epoch 15] loss: 0.1794471\n",
      "Test set: Average loss: 3.2563, Accuracy: 1704/5000 (34%)\n",
      "[epoch 16] loss: 0.1458379\n",
      "Test set: Average loss: 3.3416, Accuracy: 1759/5000 (35%)\n",
      "[epoch 17] loss: 0.0948828\n",
      "Test set: Average loss: 3.5243, Accuracy: 1654/5000 (33%)\n",
      "[epoch 18] loss: 0.0837802\n",
      "Test set: Average loss: 3.6114, Accuracy: 1695/5000 (34%)\n",
      "[epoch 19] loss: 0.0479556\n",
      "Test set: Average loss: 3.7164, Accuracy: 1718/5000 (34%)\n",
      "[epoch 20] loss: 0.0231143\n",
      "Test set: Average loss: 3.8480, Accuracy: 1716/5000 (34%)\n",
      "[epoch 21] loss: 0.0158352\n",
      "Test set: Average loss: 3.8772, Accuracy: 1740/5000 (35%)\n",
      "[epoch 22] loss: 0.0118154\n",
      "Test set: Average loss: 3.9576, Accuracy: 1744/5000 (35%)\n",
      "[epoch 23] loss: 0.0097458\n",
      "Test set: Average loss: 4.0214, Accuracy: 1741/5000 (35%)\n",
      "[epoch 24] loss: 0.0084108\n",
      "Test set: Average loss: 4.0597, Accuracy: 1731/5000 (35%)\n",
      "[epoch 25] loss: 0.0073341\n",
      "Test set: Average loss: 4.0962, Accuracy: 1734/5000 (35%)\n",
      "[epoch 26] loss: 0.0065077\n",
      "Test set: Average loss: 4.1393, Accuracy: 1735/5000 (35%)\n",
      "[epoch 27] loss: 0.0056443\n",
      "Test set: Average loss: 4.1957, Accuracy: 1737/5000 (35%)\n",
      "[epoch 28] loss: 0.0052285\n",
      "Test set: Average loss: 4.2128, Accuracy: 1741/5000 (35%)\n",
      "[epoch 29] loss: 0.0047584\n",
      "Test set: Average loss: 4.2468, Accuracy: 1733/5000 (35%)\n",
      "[epoch 30] loss: 0.0043064\n",
      "Test set: Average loss: 4.2810, Accuracy: 1737/5000 (35%)\n",
      "[epoch 31] loss: 0.0039846\n",
      "Test set: Average loss: 4.3111, Accuracy: 1737/5000 (35%)\n",
      "[epoch 32] loss: 0.0037534\n",
      "Test set: Average loss: 4.3406, Accuracy: 1732/5000 (35%)\n",
      "[epoch 33] loss: 0.0034646\n",
      "Test set: Average loss: 4.3684, Accuracy: 1734/5000 (35%)\n",
      "[epoch 34] loss: 0.0032155\n",
      "Test set: Average loss: 4.3941, Accuracy: 1732/5000 (35%)\n",
      "[epoch 35] loss: 0.0030305\n",
      "Test set: Average loss: 4.4248, Accuracy: 1726/5000 (35%)\n",
      "[epoch 36] loss: 0.0028172\n",
      "Test set: Average loss: 4.4490, Accuracy: 1735/5000 (35%)\n",
      "[epoch 37] loss: 0.0026390\n",
      "Test set: Average loss: 4.4717, Accuracy: 1729/5000 (35%)\n",
      "[epoch 38] loss: 0.0024880\n",
      "Test set: Average loss: 4.4926, Accuracy: 1730/5000 (35%)\n",
      "[epoch 39] loss: 0.0023489\n",
      "Test set: Average loss: 4.5188, Accuracy: 1725/5000 (34%)\n",
      "[epoch 40] loss: 0.0022317\n",
      "Test set: Average loss: 4.5428, Accuracy: 1724/5000 (34%)\n",
      "[epoch 41] loss: 0.0020956\n",
      "Test set: Average loss: 4.5590, Accuracy: 1733/5000 (35%)\n",
      "[epoch 42] loss: 0.0020003\n",
      "Test set: Average loss: 4.5803, Accuracy: 1728/5000 (35%)\n",
      "[epoch 43] loss: 0.0018817\n",
      "Test set: Average loss: 4.6030, Accuracy: 1723/5000 (34%)\n",
      "[epoch 44] loss: 0.0018072\n",
      "Test set: Average loss: 4.6211, Accuracy: 1729/5000 (35%)\n",
      "[epoch 45] loss: 0.0017201\n",
      "Test set: Average loss: 4.6413, Accuracy: 1725/5000 (34%)\n",
      "[epoch 46] loss: 0.0016424\n",
      "Test set: Average loss: 4.6601, Accuracy: 1727/5000 (35%)\n",
      "[epoch 47] loss: 0.0015847\n",
      "Test set: Average loss: 4.6789, Accuracy: 1728/5000 (35%)\n",
      "[epoch 48] loss: 0.0014858\n",
      "Test set: Average loss: 4.6959, Accuracy: 1729/5000 (35%)\n",
      "[epoch 49] loss: 0.0014288\n",
      "Test set: Average loss: 4.7147, Accuracy: 1728/5000 (35%)\n",
      "[epoch 50] loss: 0.0013785\n",
      "Test set: Average loss: 4.7309, Accuracy: 1729/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0245, Accuracy: 1824/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.9941, Accuracy: 3730/10000 (37%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 465/5000 (9%)\n",
      "[epoch 1] loss: 2.1469257\n",
      "Test set: Average loss: 1.9963, Accuracy: 1386/5000 (28%)\n",
      "[epoch 2] loss: 1.8398171\n",
      "Test set: Average loss: 1.8494, Accuracy: 1649/5000 (33%)\n",
      "[epoch 3] loss: 1.6326692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.8356, Accuracy: 1729/5000 (35%)\n",
      "[epoch 4] loss: 1.4609020\n",
      "Test set: Average loss: 1.7733, Accuracy: 1834/5000 (37%)\n",
      "[epoch 5] loss: 1.3164370\n",
      "Test set: Average loss: 1.8130, Accuracy: 1877/5000 (38%)\n",
      "[epoch 6] loss: 1.1618007\n",
      "Test set: Average loss: 2.0391, Accuracy: 1850/5000 (37%)\n",
      "[epoch 7] loss: 1.0644188\n",
      "Test set: Average loss: 1.9771, Accuracy: 1774/5000 (35%)\n",
      "[epoch 8] loss: 0.8522450\n",
      "Test set: Average loss: 2.1521, Accuracy: 1860/5000 (37%)\n",
      "[epoch 9] loss: 0.7372243\n",
      "Test set: Average loss: 2.3438, Accuracy: 1746/5000 (35%)\n",
      "[epoch 10] loss: 0.6067937\n",
      "Test set: Average loss: 2.4257, Accuracy: 1846/5000 (37%)\n",
      "[epoch 11] loss: 0.4949984\n",
      "Test set: Average loss: 2.6669, Accuracy: 1813/5000 (36%)\n",
      "[epoch 12] loss: 0.4055929\n",
      "Test set: Average loss: 2.8164, Accuracy: 1806/5000 (36%)\n",
      "[epoch 13] loss: 0.2800089\n",
      "Test set: Average loss: 2.9869, Accuracy: 1830/5000 (37%)\n",
      "[epoch 14] loss: 0.1675204\n",
      "Test set: Average loss: 3.1352, Accuracy: 1856/5000 (37%)\n",
      "[epoch 15] loss: 0.1482176\n",
      "Test set: Average loss: 3.2905, Accuracy: 1856/5000 (37%)\n",
      "[epoch 16] loss: 0.0943460\n",
      "Test set: Average loss: 3.3305, Accuracy: 1891/5000 (38%)\n",
      "[epoch 17] loss: 0.0493863\n",
      "Test set: Average loss: 3.4455, Accuracy: 1857/5000 (37%)\n",
      "[epoch 18] loss: 0.0288242\n",
      "Test set: Average loss: 3.5324, Accuracy: 1895/5000 (38%)\n",
      "[epoch 19] loss: 0.0175353\n",
      "Test set: Average loss: 3.6087, Accuracy: 1885/5000 (38%)\n",
      "[epoch 20] loss: 0.0134217\n",
      "Test set: Average loss: 3.6857, Accuracy: 1894/5000 (38%)\n",
      "[epoch 21] loss: 0.0123370\n",
      "Test set: Average loss: 3.7327, Accuracy: 1911/5000 (38%)\n",
      "[epoch 22] loss: 0.0110868\n",
      "Test set: Average loss: 3.8100, Accuracy: 1887/5000 (38%)\n",
      "[epoch 23] loss: 0.0079335\n",
      "Test set: Average loss: 3.8450, Accuracy: 1889/5000 (38%)\n",
      "[epoch 24] loss: 0.0070040\n",
      "Test set: Average loss: 3.8858, Accuracy: 1892/5000 (38%)\n",
      "[epoch 25] loss: 0.0060835\n",
      "Test set: Average loss: 3.9285, Accuracy: 1897/5000 (38%)\n",
      "[epoch 26] loss: 0.0054829\n",
      "Test set: Average loss: 3.9690, Accuracy: 1886/5000 (38%)\n",
      "[epoch 27] loss: 0.0049526\n",
      "Test set: Average loss: 4.0001, Accuracy: 1886/5000 (38%)\n",
      "[epoch 28] loss: 0.0045499\n",
      "Test set: Average loss: 4.0376, Accuracy: 1889/5000 (38%)\n",
      "[epoch 29] loss: 0.0042265\n",
      "Test set: Average loss: 4.0644, Accuracy: 1890/5000 (38%)\n",
      "[epoch 30] loss: 0.0038629\n",
      "Test set: Average loss: 4.1010, Accuracy: 1888/5000 (38%)\n",
      "[epoch 31] loss: 0.0035592\n",
      "Test set: Average loss: 4.1260, Accuracy: 1886/5000 (38%)\n",
      "[epoch 32] loss: 0.0033699\n",
      "Test set: Average loss: 4.1531, Accuracy: 1881/5000 (38%)\n",
      "[epoch 33] loss: 0.0031035\n",
      "Test set: Average loss: 4.1861, Accuracy: 1882/5000 (38%)\n",
      "[epoch 34] loss: 0.0028676\n",
      "Test set: Average loss: 4.2109, Accuracy: 1876/5000 (38%)\n",
      "[epoch 35] loss: 0.0026625\n",
      "Test set: Average loss: 4.2354, Accuracy: 1886/5000 (38%)\n",
      "[epoch 36] loss: 0.0025207\n",
      "Test set: Average loss: 4.2578, Accuracy: 1884/5000 (38%)\n",
      "[epoch 37] loss: 0.0023504\n",
      "Test set: Average loss: 4.2958, Accuracy: 1882/5000 (38%)\n",
      "[epoch 38] loss: 0.0021677\n",
      "Test set: Average loss: 4.3069, Accuracy: 1879/5000 (38%)\n",
      "[epoch 39] loss: 0.0020665\n",
      "Test set: Average loss: 4.3293, Accuracy: 1881/5000 (38%)\n",
      "[epoch 40] loss: 0.0019621\n",
      "Test set: Average loss: 4.3493, Accuracy: 1875/5000 (38%)\n",
      "[epoch 41] loss: 0.0018184\n",
      "Test set: Average loss: 4.3708, Accuracy: 1875/5000 (38%)\n",
      "[epoch 42] loss: 0.0017412\n",
      "Test set: Average loss: 4.3901, Accuracy: 1878/5000 (38%)\n",
      "[epoch 43] loss: 0.0016573\n",
      "Test set: Average loss: 4.4104, Accuracy: 1879/5000 (38%)\n",
      "[epoch 44] loss: 0.0015806\n",
      "Test set: Average loss: 4.4313, Accuracy: 1878/5000 (38%)\n",
      "[epoch 45] loss: 0.0014966\n",
      "Test set: Average loss: 4.4499, Accuracy: 1874/5000 (37%)\n",
      "[epoch 46] loss: 0.0014200\n",
      "Test set: Average loss: 4.4674, Accuracy: 1872/5000 (37%)\n",
      "[epoch 47] loss: 0.0013622\n",
      "Test set: Average loss: 4.4853, Accuracy: 1870/5000 (37%)\n",
      "[epoch 48] loss: 0.0012874\n",
      "Test set: Average loss: 4.5047, Accuracy: 1875/5000 (38%)\n",
      "[epoch 49] loss: 0.0012379\n",
      "Test set: Average loss: 4.5216, Accuracy: 1873/5000 (37%)\n",
      "[epoch 50] loss: 0.0011807\n",
      "Test set: Average loss: 4.5394, Accuracy: 1869/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.7327, Accuracy: 1911/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 3.7282, Accuracy: 3695/10000 (37%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3008, Accuracy: 501/5000 (10%)\n",
      "[epoch 1] loss: 2.1034678\n",
      "Test set: Average loss: 2.0076, Accuracy: 1310/5000 (26%)\n",
      "[epoch 2] loss: 1.7874695\n",
      "Test set: Average loss: 1.9230, Accuracy: 1581/5000 (32%)\n",
      "[epoch 3] loss: 1.5836647\n",
      "Test set: Average loss: 1.8174, Accuracy: 1790/5000 (36%)\n",
      "[epoch 4] loss: 1.4055177\n",
      "Test set: Average loss: 1.9370, Accuracy: 1821/5000 (36%)\n",
      "[epoch 5] loss: 1.2812866\n",
      "Test set: Average loss: 1.9839, Accuracy: 1770/5000 (35%)\n",
      "[epoch 6] loss: 1.1268273\n",
      "Test set: Average loss: 1.9891, Accuracy: 1917/5000 (38%)\n",
      "[epoch 7] loss: 1.0369942\n",
      "Test set: Average loss: 2.0723, Accuracy: 1882/5000 (38%)\n",
      "[epoch 8] loss: 0.8636386\n",
      "Test set: Average loss: 2.0382, Accuracy: 2008/5000 (40%)\n",
      "[epoch 9] loss: 0.8042050\n",
      "Test set: Average loss: 2.2157, Accuracy: 1906/5000 (38%)\n",
      "[epoch 10] loss: 0.6840407\n",
      "Test set: Average loss: 2.2624, Accuracy: 1910/5000 (38%)\n",
      "[epoch 11] loss: 0.5796873\n",
      "Test set: Average loss: 2.3662, Accuracy: 1901/5000 (38%)\n",
      "[epoch 12] loss: 0.4387652\n",
      "Test set: Average loss: 2.4552, Accuracy: 1988/5000 (40%)\n",
      "[epoch 13] loss: 0.2984505\n",
      "Test set: Average loss: 2.6786, Accuracy: 1945/5000 (39%)\n",
      "[epoch 14] loss: 0.2018173\n",
      "Test set: Average loss: 2.7940, Accuracy: 1900/5000 (38%)\n",
      "[epoch 15] loss: 0.1352042\n",
      "Test set: Average loss: 2.9419, Accuracy: 1934/5000 (39%)\n",
      "[epoch 16] loss: 0.1178654\n",
      "Test set: Average loss: 3.0539, Accuracy: 1935/5000 (39%)\n",
      "[epoch 17] loss: 0.0677485\n",
      "Test set: Average loss: 3.1051, Accuracy: 1928/5000 (39%)\n",
      "[epoch 18] loss: 0.0331999\n",
      "Test set: Average loss: 3.1943, Accuracy: 1930/5000 (39%)\n",
      "[epoch 19] loss: 0.0228336\n",
      "Test set: Average loss: 3.2724, Accuracy: 1960/5000 (39%)\n",
      "[epoch 20] loss: 0.0156016\n",
      "Test set: Average loss: 3.3112, Accuracy: 1967/5000 (39%)\n",
      "[epoch 21] loss: 0.0124563\n",
      "Test set: Average loss: 3.3636, Accuracy: 1964/5000 (39%)\n",
      "[epoch 22] loss: 0.0106427\n",
      "Test set: Average loss: 3.4139, Accuracy: 1956/5000 (39%)\n",
      "[epoch 23] loss: 0.0089469\n",
      "Test set: Average loss: 3.4519, Accuracy: 1968/5000 (39%)\n",
      "[epoch 24] loss: 0.0079169\n",
      "Test set: Average loss: 3.4961, Accuracy: 1950/5000 (39%)\n",
      "[epoch 25] loss: 0.0068935\n",
      "Test set: Average loss: 3.5276, Accuracy: 1958/5000 (39%)\n",
      "[epoch 26] loss: 0.0061705\n",
      "Test set: Average loss: 3.5612, Accuracy: 1962/5000 (39%)\n",
      "[epoch 27] loss: 0.0055360\n",
      "Test set: Average loss: 3.5989, Accuracy: 1944/5000 (39%)\n",
      "[epoch 28] loss: 0.0050964\n",
      "Test set: Average loss: 3.6241, Accuracy: 1959/5000 (39%)\n",
      "[epoch 29] loss: 0.0046031\n",
      "Test set: Average loss: 3.6654, Accuracy: 1953/5000 (39%)\n",
      "[epoch 30] loss: 0.0042709\n",
      "Test set: Average loss: 3.6832, Accuracy: 1949/5000 (39%)\n",
      "[epoch 31] loss: 0.0039665\n",
      "Test set: Average loss: 3.7141, Accuracy: 1953/5000 (39%)\n",
      "[epoch 32] loss: 0.0037034\n",
      "Test set: Average loss: 3.7367, Accuracy: 1952/5000 (39%)\n",
      "[epoch 33] loss: 0.0034475\n",
      "Test set: Average loss: 3.7625, Accuracy: 1942/5000 (39%)\n",
      "[epoch 34] loss: 0.0032051\n",
      "Test set: Average loss: 3.7881, Accuracy: 1951/5000 (39%)\n",
      "[epoch 35] loss: 0.0029477\n",
      "Test set: Average loss: 3.8086, Accuracy: 1946/5000 (39%)\n",
      "[epoch 36] loss: 0.0028185\n",
      "Test set: Average loss: 3.8314, Accuracy: 1959/5000 (39%)\n",
      "[epoch 37] loss: 0.0025867\n",
      "Test set: Average loss: 3.8524, Accuracy: 1958/5000 (39%)\n",
      "[epoch 38] loss: 0.0024393\n",
      "Test set: Average loss: 3.8753, Accuracy: 1946/5000 (39%)\n",
      "[epoch 39] loss: 0.0022797\n",
      "Test set: Average loss: 3.8937, Accuracy: 1948/5000 (39%)\n",
      "[epoch 40] loss: 0.0021530\n",
      "Test set: Average loss: 3.9143, Accuracy: 1941/5000 (39%)\n",
      "[epoch 41] loss: 0.0020104\n",
      "Test set: Average loss: 3.9335, Accuracy: 1953/5000 (39%)\n",
      "[epoch 42] loss: 0.0018922\n",
      "Test set: Average loss: 3.9523, Accuracy: 1946/5000 (39%)\n",
      "[epoch 43] loss: 0.0018299\n",
      "Test set: Average loss: 3.9686, Accuracy: 1944/5000 (39%)\n",
      "[epoch 44] loss: 0.0017307\n",
      "Test set: Average loss: 3.9896, Accuracy: 1948/5000 (39%)\n",
      "[epoch 45] loss: 0.0016358\n",
      "Test set: Average loss: 4.0041, Accuracy: 1942/5000 (39%)\n",
      "[epoch 46] loss: 0.0015511\n",
      "Test set: Average loss: 4.0211, Accuracy: 1937/5000 (39%)\n",
      "[epoch 47] loss: 0.0014798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.0387, Accuracy: 1947/5000 (39%)\n",
      "[epoch 48] loss: 0.0014074\n",
      "Test set: Average loss: 4.0540, Accuracy: 1946/5000 (39%)\n",
      "[epoch 49] loss: 0.0013363\n",
      "Test set: Average loss: 4.0690, Accuracy: 1950/5000 (39%)\n",
      "[epoch 50] loss: 0.0012730\n",
      "Test set: Average loss: 4.0837, Accuracy: 1950/5000 (39%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0382, Accuracy: 2008/5000 (40%)\n",
      "Test\n",
      "Test set: Average loss: 2.0145, Accuracy: 4006/10000 (40%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3052, Accuracy: 450/5000 (9%)\n",
      "[epoch 1] loss: 2.1794646\n",
      "Test set: Average loss: 1.9386, Accuracy: 1504/5000 (30%)\n",
      "[epoch 2] loss: 1.8288536\n",
      "Test set: Average loss: 1.8261, Accuracy: 1737/5000 (35%)\n",
      "[epoch 3] loss: 1.7021227\n",
      "Test set: Average loss: 1.7861, Accuracy: 1813/5000 (36%)\n",
      "[epoch 4] loss: 1.5925632\n",
      "Test set: Average loss: 1.7787, Accuracy: 1823/5000 (36%)\n",
      "[epoch 5] loss: 1.4524863\n",
      "Test set: Average loss: 1.8363, Accuracy: 1817/5000 (36%)\n",
      "[epoch 6] loss: 1.3873933\n",
      "Test set: Average loss: 1.8392, Accuracy: 1749/5000 (35%)\n",
      "[epoch 7] loss: 1.2330601\n",
      "Test set: Average loss: 1.8687, Accuracy: 1882/5000 (38%)\n",
      "[epoch 8] loss: 1.1439062\n",
      "Test set: Average loss: 1.9958, Accuracy: 1864/5000 (37%)\n",
      "[epoch 9] loss: 1.0228070\n",
      "Test set: Average loss: 2.1010, Accuracy: 1794/5000 (36%)\n",
      "[epoch 10] loss: 0.8943709\n",
      "Test set: Average loss: 2.1474, Accuracy: 1893/5000 (38%)\n",
      "[epoch 11] loss: 0.7593840\n",
      "Test set: Average loss: 2.2458, Accuracy: 1829/5000 (37%)\n",
      "[epoch 12] loss: 0.5614817\n",
      "Test set: Average loss: 2.4860, Accuracy: 1796/5000 (36%)\n",
      "[epoch 13] loss: 0.4825986\n",
      "Test set: Average loss: 2.7298, Accuracy: 1766/5000 (35%)\n",
      "[epoch 14] loss: 0.3961190\n",
      "Test set: Average loss: 2.8171, Accuracy: 1854/5000 (37%)\n",
      "[epoch 15] loss: 0.2937846\n",
      "Test set: Average loss: 2.9546, Accuracy: 1768/5000 (35%)\n",
      "[epoch 16] loss: 0.2244407\n",
      "Test set: Average loss: 3.1222, Accuracy: 1782/5000 (36%)\n",
      "[epoch 17] loss: 0.1929972\n",
      "Test set: Average loss: 3.3393, Accuracy: 1769/5000 (35%)\n",
      "[epoch 18] loss: 0.1534125\n",
      "Test set: Average loss: 3.4481, Accuracy: 1768/5000 (35%)\n",
      "[epoch 19] loss: 0.1054610\n",
      "Test set: Average loss: 3.4675, Accuracy: 1803/5000 (36%)\n",
      "[epoch 20] loss: 0.0602858\n",
      "Test set: Average loss: 3.6079, Accuracy: 1797/5000 (36%)\n",
      "[epoch 21] loss: 0.0370852\n",
      "Test set: Average loss: 3.6500, Accuracy: 1798/5000 (36%)\n",
      "[epoch 22] loss: 0.0250193\n",
      "Test set: Average loss: 3.7527, Accuracy: 1846/5000 (37%)\n",
      "[epoch 23] loss: 0.0150574\n",
      "Test set: Average loss: 3.8275, Accuracy: 1841/5000 (37%)\n",
      "[epoch 24] loss: 0.0117039\n",
      "Test set: Average loss: 3.8738, Accuracy: 1829/5000 (37%)\n",
      "[epoch 25] loss: 0.0099524\n",
      "Test set: Average loss: 3.9153, Accuracy: 1811/5000 (36%)\n",
      "[epoch 26] loss: 0.0089370\n",
      "Test set: Average loss: 3.9682, Accuracy: 1824/5000 (36%)\n",
      "[epoch 27] loss: 0.0076712\n",
      "Test set: Average loss: 4.0192, Accuracy: 1820/5000 (36%)\n",
      "[epoch 28] loss: 0.0069085\n",
      "Test set: Average loss: 4.0611, Accuracy: 1833/5000 (37%)\n",
      "[epoch 29] loss: 0.0062385\n",
      "Test set: Average loss: 4.0952, Accuracy: 1815/5000 (36%)\n",
      "[epoch 30] loss: 0.0055901\n",
      "Test set: Average loss: 4.1416, Accuracy: 1825/5000 (36%)\n",
      "[epoch 31] loss: 0.0049767\n",
      "Test set: Average loss: 4.1738, Accuracy: 1821/5000 (36%)\n",
      "[epoch 32] loss: 0.0045940\n",
      "Test set: Average loss: 4.2009, Accuracy: 1819/5000 (36%)\n",
      "[epoch 33] loss: 0.0041780\n",
      "Test set: Average loss: 4.2345, Accuracy: 1814/5000 (36%)\n",
      "[epoch 34] loss: 0.0039095\n",
      "Test set: Average loss: 4.2657, Accuracy: 1820/5000 (36%)\n",
      "[epoch 35] loss: 0.0036193\n",
      "Test set: Average loss: 4.2987, Accuracy: 1830/5000 (37%)\n",
      "[epoch 36] loss: 0.0033856\n",
      "Test set: Average loss: 4.3265, Accuracy: 1824/5000 (36%)\n",
      "[epoch 37] loss: 0.0031498\n",
      "Test set: Average loss: 4.3505, Accuracy: 1815/5000 (36%)\n",
      "[epoch 38] loss: 0.0029976\n",
      "Test set: Average loss: 4.3795, Accuracy: 1824/5000 (36%)\n",
      "[epoch 39] loss: 0.0027752\n",
      "Test set: Average loss: 4.4052, Accuracy: 1829/5000 (37%)\n",
      "[epoch 40] loss: 0.0026174\n",
      "Test set: Average loss: 4.4246, Accuracy: 1831/5000 (37%)\n",
      "[epoch 41] loss: 0.0024200\n",
      "Test set: Average loss: 4.4521, Accuracy: 1831/5000 (37%)\n",
      "[epoch 42] loss: 0.0022975\n",
      "Test set: Average loss: 4.4710, Accuracy: 1828/5000 (37%)\n",
      "[epoch 43] loss: 0.0021983\n",
      "Test set: Average loss: 4.4967, Accuracy: 1827/5000 (37%)\n",
      "[epoch 44] loss: 0.0020451\n",
      "Test set: Average loss: 4.5164, Accuracy: 1832/5000 (37%)\n",
      "[epoch 45] loss: 0.0019620\n",
      "Test set: Average loss: 4.5345, Accuracy: 1833/5000 (37%)\n",
      "[epoch 46] loss: 0.0018742\n",
      "Test set: Average loss: 4.5570, Accuracy: 1831/5000 (37%)\n",
      "[epoch 47] loss: 0.0017709\n",
      "Test set: Average loss: 4.5789, Accuracy: 1822/5000 (36%)\n",
      "[epoch 48] loss: 0.0016831\n",
      "Test set: Average loss: 4.6011, Accuracy: 1826/5000 (37%)\n",
      "[epoch 49] loss: 0.0016204\n",
      "Test set: Average loss: 4.6180, Accuracy: 1840/5000 (37%)\n",
      "[epoch 50] loss: 0.0015343\n",
      "Test set: Average loss: 4.6363, Accuracy: 1826/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1474, Accuracy: 1893/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 2.1474, Accuracy: 3762/10000 (38%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 496/5000 (10%)\n",
      "[epoch 1] loss: 2.0088176\n",
      "Test set: Average loss: 1.7260, Accuracy: 1775/5000 (36%)\n",
      "[epoch 2] loss: 1.6237877\n",
      "Test set: Average loss: 1.5825, Accuracy: 2200/5000 (44%)\n",
      "[epoch 3] loss: 1.4956183\n",
      "Test set: Average loss: 1.6691, Accuracy: 1972/5000 (39%)\n",
      "[epoch 4] loss: 1.3770234\n",
      "Test set: Average loss: 1.5689, Accuracy: 2228/5000 (45%)\n",
      "[epoch 5] loss: 1.2741815\n",
      "Test set: Average loss: 1.5559, Accuracy: 2284/5000 (46%)\n",
      "[epoch 6] loss: 1.1463592\n",
      "Test set: Average loss: 1.6281, Accuracy: 2225/5000 (44%)\n",
      "[epoch 7] loss: 1.1689638\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6688, Accuracy: 2168/5000 (43%)\n",
      "[epoch 8] loss: 0.8598801\n",
      "Test set: Average loss: 1.5744, Accuracy: 2329/5000 (47%)\n",
      "[epoch 9] loss: 0.7751724\n",
      "Test set: Average loss: 1.5948, Accuracy: 2363/5000 (47%)\n",
      "[epoch 10] loss: 0.7447367\n",
      "Test set: Average loss: 1.6124, Accuracy: 2376/5000 (48%)\n",
      "[epoch 11] loss: 0.7205813\n",
      "Test set: Average loss: 1.6371, Accuracy: 2364/5000 (47%)\n",
      "[epoch 12] loss: 0.7040645\n",
      "Test set: Average loss: 1.6584, Accuracy: 2339/5000 (47%)\n",
      "[epoch 13] loss: 0.6785909\n",
      "Test set: Average loss: 1.6755, Accuracy: 2350/5000 (47%)\n",
      "[epoch 14] loss: 0.6647658\n",
      "Test set: Average loss: 1.7024, Accuracy: 2325/5000 (46%)\n",
      "[epoch 15] loss: 0.6430844\n",
      "Test set: Average loss: 1.7213, Accuracy: 2355/5000 (47%)\n",
      "[epoch 16] loss: 0.6279643\n",
      "Test set: Average loss: 1.7384, Accuracy: 2338/5000 (47%)\n",
      "[epoch 17] loss: 0.6093292\n",
      "Test set: Average loss: 1.7554, Accuracy: 2362/5000 (47%)\n",
      "[epoch 18] loss: 0.5965514\n",
      "Test set: Average loss: 1.7878, Accuracy: 2318/5000 (46%)\n",
      "[epoch 19] loss: 0.5896787\n",
      "Test set: Average loss: 1.7944, Accuracy: 2324/5000 (46%)\n",
      "[epoch 20] loss: 0.5615958\n",
      "Test set: Average loss: 1.8160, Accuracy: 2344/5000 (47%)\n",
      "[epoch 21] loss: 0.5455267\n",
      "Test set: Average loss: 1.8358, Accuracy: 2318/5000 (46%)\n",
      "[epoch 22] loss: 0.5354276\n",
      "Test set: Average loss: 1.8671, Accuracy: 2312/5000 (46%)\n",
      "[epoch 23] loss: 0.5148308\n",
      "Test set: Average loss: 1.8912, Accuracy: 2318/5000 (46%)\n",
      "[epoch 24] loss: 0.5029393\n",
      "Test set: Average loss: 1.9136, Accuracy: 2303/5000 (46%)\n",
      "[epoch 25] loss: 0.5051069\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9324, Accuracy: 2309/5000 (46%)\n",
      "[epoch 26] loss: 0.4531751\n",
      "Test set: Average loss: 1.9272, Accuracy: 2316/5000 (46%)\n",
      "[epoch 27] loss: 0.4464202\n",
      "Test set: Average loss: 1.9310, Accuracy: 2312/5000 (46%)\n",
      "[epoch 28] loss: 0.4476631\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.9343, Accuracy: 2313/5000 (46%)\n",
      "[epoch 29] loss: 0.4481258\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.9346, Accuracy: 2313/5000 (46%)\n",
      "[epoch 30] loss: 0.4420593\n",
      "Test set: Average loss: 1.9346, Accuracy: 2313/5000 (46%)\n",
      "[epoch 31] loss: 0.4426959\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 32] loss: 0.4527244\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 33] loss: 0.4462295\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 34] loss: 0.4540794\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 35] loss: 0.4569353\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 36] loss: 0.5554179\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 37] loss: 0.4446374\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 38] loss: 0.4391829\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 39] loss: 0.4430277\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 40] loss: 0.4435831\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 41] loss: 0.4424423\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 42] loss: 0.4513532\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 43] loss: 0.4567004\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 44] loss: 0.4400249\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 45] loss: 0.4410645\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 46] loss: 0.5746889\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 47] loss: 0.4448923\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 48] loss: 0.4400713\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 49] loss: 0.4668845\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "[epoch 50] loss: 0.4438502\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.9347, Accuracy: 2313/5000 (46%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6124, Accuracy: 2376/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 1.6073, Accuracy: 4801/10000 (48%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3051, Accuracy: 521/5000 (10%)\n",
      "[epoch 1] loss: 1.9364625\n",
      "Test set: Average loss: 1.6827, Accuracy: 1959/5000 (39%)\n",
      "[epoch 2] loss: 1.5746911\n",
      "Test set: Average loss: 1.5992, Accuracy: 2080/5000 (42%)\n",
      "[epoch 3] loss: 1.4192163\n",
      "Test set: Average loss: 1.5232, Accuracy: 2287/5000 (46%)\n",
      "[epoch 4] loss: 1.3026622\n",
      "Test set: Average loss: 1.6650, Accuracy: 2148/5000 (43%)\n",
      "[epoch 5] loss: 1.2161594\n",
      "Test set: Average loss: 1.5989, Accuracy: 2270/5000 (45%)\n",
      "[epoch 6] loss: 1.1387453\n",
      "Test set: Average loss: 1.6690, Accuracy: 2222/5000 (44%)\n",
      "[epoch 7] loss: 1.0618200\n",
      "Test set: Average loss: 1.6321, Accuracy: 2330/5000 (47%)\n",
      "[epoch 8] loss: 0.9843062\n",
      "Test set: Average loss: 1.7392, Accuracy: 2241/5000 (45%)\n",
      "[epoch 9] loss: 0.9021222\n",
      "Test set: Average loss: 1.8093, Accuracy: 2168/5000 (43%)\n",
      "[epoch 10] loss: 0.7990885\n",
      "Test set: Average loss: 1.9631, Accuracy: 2074/5000 (41%)\n",
      "[epoch 11] loss: 0.7078953\n",
      "Test set: Average loss: 1.8961, Accuracy: 2234/5000 (45%)\n",
      "[epoch 12] loss: 0.5808850\n",
      "Test set: Average loss: 1.9954, Accuracy: 2252/5000 (45%)\n",
      "[epoch 13] loss: 0.5078897\n",
      "Test set: Average loss: 2.1537, Accuracy: 2167/5000 (43%)\n",
      "[epoch 14] loss: 0.3491729\n",
      "Test set: Average loss: 2.1787, Accuracy: 2258/5000 (45%)\n",
      "[epoch 15] loss: 0.2265716\n",
      "Test set: Average loss: 2.2862, Accuracy: 2237/5000 (45%)\n",
      "[epoch 16] loss: 0.1401731\n",
      "Test set: Average loss: 2.5288, Accuracy: 2196/5000 (44%)\n",
      "[epoch 17] loss: 0.0937178\n",
      "Test set: Average loss: 2.6011, Accuracy: 2250/5000 (45%)\n",
      "[epoch 18] loss: 0.2190909\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.9131, Accuracy: 2052/5000 (41%)\n",
      "[epoch 19] loss: 0.0626719\n",
      "Test set: Average loss: 2.7070, Accuracy: 2176/5000 (44%)\n",
      "[epoch 20] loss: 0.0335182\n",
      "Test set: Average loss: 2.7026, Accuracy: 2192/5000 (44%)\n",
      "[epoch 21] loss: 0.0292010\n",
      "Test set: Average loss: 2.7055, Accuracy: 2194/5000 (44%)\n",
      "[epoch 22] loss: 0.0266661\n",
      "Test set: Average loss: 2.7157, Accuracy: 2204/5000 (44%)\n",
      "[epoch 23] loss: 0.0251603\n",
      "Test set: Average loss: 2.7242, Accuracy: 2207/5000 (44%)\n",
      "[epoch 24] loss: 0.0235053\n",
      "Test set: Average loss: 2.7353, Accuracy: 2211/5000 (44%)\n",
      "[epoch 25] loss: 0.0222402\n",
      "Test set: Average loss: 2.7453, Accuracy: 2210/5000 (44%)\n",
      "[epoch 26] loss: 0.0212756\n",
      "Test set: Average loss: 2.7561, Accuracy: 2212/5000 (44%)\n",
      "[epoch 27] loss: 0.0203322\n",
      "Test set: Average loss: 2.7724, Accuracy: 2212/5000 (44%)\n",
      "[epoch 28] loss: 0.0195402\n",
      "Test set: Average loss: 2.7845, Accuracy: 2215/5000 (44%)\n",
      "[epoch 29] loss: 0.0187966\n",
      "Test set: Average loss: 2.7962, Accuracy: 2216/5000 (44%)\n",
      "[epoch 30] loss: 0.1571992\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.8057, Accuracy: 2223/5000 (44%)\n",
      "[epoch 31] loss: 0.0189239\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.8083, Accuracy: 2225/5000 (44%)\n",
      "[epoch 32] loss: 0.0185969\n",
      "Test set: Average loss: 2.8081, Accuracy: 2223/5000 (44%)\n",
      "[epoch 33] loss: 0.0186424\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 34] loss: 0.0183961\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 35] loss: 0.0186593\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 36] loss: 0.1812955\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 37] loss: 0.0184982\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 38] loss: 0.0184420\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 39] loss: 0.0186480\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 40] loss: 0.0184583\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 41] loss: 0.0186332\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 42] loss: 0.0185904\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 43] loss: 0.0183972\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 44] loss: 0.0185375\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 45] loss: 0.0187219\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 46] loss: 0.0185580\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 47] loss: 0.0184374\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 48] loss: 0.0184285\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 49] loss: 0.0186997\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "[epoch 50] loss: 0.0185491\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.8079, Accuracy: 2222/5000 (44%)\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6321, Accuracy: 2330/5000 (47%)\n",
      "Test\n",
      "Test set: Average loss: 1.6146, Accuracy: 4634/10000 (46%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3006, Accuracy: 575/5000 (12%)\n",
      "[epoch 1] loss: 2.0500319\n",
      "Test set: Average loss: 1.7931, Accuracy: 1761/5000 (35%)\n",
      "[epoch 2] loss: 1.7204392\n",
      "Test set: Average loss: 1.6073, Accuracy: 2151/5000 (43%)\n",
      "[epoch 3] loss: 1.5920902\n",
      "Test set: Average loss: 1.6183, Accuracy: 2098/5000 (42%)\n",
      "[epoch 4] loss: 1.4725471\n",
      "Test set: Average loss: 1.7279, Accuracy: 1849/5000 (37%)\n",
      "[epoch 5] loss: 1.3669465\n",
      "Test set: Average loss: 1.5924, Accuracy: 2196/5000 (44%)\n",
      "[epoch 6] loss: 1.2721339\n",
      "Test set: Average loss: 1.5874, Accuracy: 2207/5000 (44%)\n",
      "[epoch 7] loss: 1.1818690\n",
      "Test set: Average loss: 1.5942, Accuracy: 2262/5000 (45%)\n",
      "[epoch 8] loss: 1.0862190\n",
      "Test set: Average loss: 1.8114, Accuracy: 2127/5000 (43%)\n",
      "[epoch 9] loss: 1.0505467\n",
      "Test set: Average loss: 1.7630, Accuracy: 2174/5000 (43%)\n",
      "[epoch 10] loss: 0.9399023\n",
      "Test set: Average loss: 1.7790, Accuracy: 2241/5000 (45%)\n",
      "[epoch 11] loss: 0.8041871\n",
      "Test set: Average loss: 1.8387, Accuracy: 2254/5000 (45%)\n",
      "[epoch 12] loss: 0.7555698\n",
      "Test set: Average loss: 2.0172, Accuracy: 2179/5000 (44%)\n",
      "[epoch 13] loss: 0.6306752\n",
      "Test set: Average loss: 2.0134, Accuracy: 2231/5000 (45%)\n",
      "[epoch 14] loss: 0.5282840\n",
      "Test set: Average loss: 2.1258, Accuracy: 2172/5000 (43%)\n",
      "[epoch 15] loss: 0.3838661\n",
      "Test set: Average loss: 2.1847, Accuracy: 2274/5000 (45%)\n",
      "[epoch 16] loss: 0.2960252\n",
      "Test set: Average loss: 2.3530, Accuracy: 2217/5000 (44%)\n",
      "[epoch 17] loss: 0.2020351\n",
      "Test set: Average loss: 2.4293, Accuracy: 2232/5000 (45%)\n",
      "[epoch 18] loss: 0.1255471\n",
      "Test set: Average loss: 2.5697, Accuracy: 2235/5000 (45%)\n",
      "[epoch 19] loss: 0.0789278\n",
      "Test set: Average loss: 2.7307, Accuracy: 2239/5000 (45%)\n",
      "[epoch 20] loss: 0.0509656\n",
      "Test set: Average loss: 2.7497, Accuracy: 2265/5000 (45%)\n",
      "[epoch 21] loss: 0.0285791\n",
      "Test set: Average loss: 2.8631, Accuracy: 2274/5000 (45%)\n",
      "[epoch 22] loss: 0.1398825\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.2744, Accuracy: 2105/5000 (42%)\n",
      "[epoch 23] loss: 0.0655852\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9483, Accuracy: 2241/5000 (45%)\n",
      "[epoch 24] loss: 0.0240375\n",
      "Test set: Average loss: 2.9466, Accuracy: 2248/5000 (45%)\n",
      "[epoch 25] loss: 0.0234128\n",
      "Test set: Average loss: 2.9457, Accuracy: 2250/5000 (45%)\n",
      "[epoch 26] loss: 0.0229877\n",
      "Test set: Average loss: 2.9449, Accuracy: 2254/5000 (45%)\n",
      "[epoch 27] loss: 0.0225224\n",
      "Test set: Average loss: 2.9441, Accuracy: 2253/5000 (45%)\n",
      "[epoch 28] loss: 0.0219161\n",
      "Test set: Average loss: 2.9435, Accuracy: 2252/5000 (45%)\n",
      "[epoch 29] loss: 0.0213987\n",
      "Test set: Average loss: 2.9431, Accuracy: 2253/5000 (45%)\n",
      "[epoch 30] loss: 0.0211042\n",
      "Test set: Average loss: 2.9428, Accuracy: 2256/5000 (45%)\n",
      "[epoch 31] loss: 0.0206228\n",
      "Test set: Average loss: 2.9427, Accuracy: 2255/5000 (45%)\n",
      "[epoch 32] loss: 0.0200345\n",
      "Test set: Average loss: 2.9425, Accuracy: 2253/5000 (45%)\n",
      "[epoch 33] loss: 0.0197218\n",
      "Test set: Average loss: 2.9425, Accuracy: 2255/5000 (45%)\n",
      "[epoch 34] loss: 0.0193220\n",
      "Test set: Average loss: 2.9424, Accuracy: 2259/5000 (45%)\n",
      "[epoch 35] loss: 0.0189943\n",
      "Test set: Average loss: 2.9426, Accuracy: 2261/5000 (45%)\n",
      "[epoch 36] loss: 0.0188949\n",
      "Test set: Average loss: 2.9426, Accuracy: 2262/5000 (45%)\n",
      "[epoch 37] loss: 0.0181691\n",
      "Test set: Average loss: 2.9433, Accuracy: 2260/5000 (45%)\n",
      "[epoch 38] loss: 0.0178184\n",
      "Test set: Average loss: 2.9435, Accuracy: 2260/5000 (45%)\n",
      "[epoch 39] loss: 0.0174497\n",
      "Test set: Average loss: 2.9442, Accuracy: 2263/5000 (45%)\n",
      "[epoch 40] loss: 0.0171904\n",
      "Test set: Average loss: 2.9445, Accuracy: 2261/5000 (45%)\n",
      "[epoch 41] loss: 0.0170929\n",
      "Test set: Average loss: 2.9451, Accuracy: 2264/5000 (45%)\n",
      "[epoch 42] loss: 0.0165559\n",
      "Test set: Average loss: 2.9456, Accuracy: 2263/5000 (45%)\n",
      "[epoch 43] loss: 0.0162843\n",
      "Test set: Average loss: 2.9466, Accuracy: 2264/5000 (45%)\n",
      "[epoch 44] loss: 0.0160680\n",
      "Test set: Average loss: 2.9475, Accuracy: 2265/5000 (45%)\n",
      "[epoch 45] loss: 0.0157018\n",
      "Test set: Average loss: 2.9484, Accuracy: 2262/5000 (45%)\n",
      "[epoch 46] loss: 0.0154352\n",
      "Test set: Average loss: 2.9494, Accuracy: 2261/5000 (45%)\n",
      "[epoch 47] loss: 0.0152352\n",
      "Test set: Average loss: 2.9508, Accuracy: 2260/5000 (45%)\n",
      "[epoch 48] loss: 0.0148802\n",
      "Test set: Average loss: 2.9516, Accuracy: 2260/5000 (45%)\n",
      "[epoch 49] loss: 0.0147404\n",
      "Test set: Average loss: 2.9533, Accuracy: 2260/5000 (45%)\n",
      "[epoch 50] loss: 0.0144405\n",
      "Test set: Average loss: 2.9546, Accuracy: 2260/5000 (45%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8631, Accuracy: 2274/5000 (45%)\n",
      "Test\n",
      "Test set: Average loss: 2.9124, Accuracy: 4409/10000 (44%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 569/5000 (11%)\n",
      "[epoch 1] loss: 1.8654122\n",
      "Test set: Average loss: 1.6415, Accuracy: 2031/5000 (41%)\n",
      "[epoch 2] loss: 1.5352897\n",
      "Test set: Average loss: 1.4982, Accuracy: 2271/5000 (45%)\n",
      "[epoch 3] loss: 1.3871720\n",
      "Test set: Average loss: 1.4784, Accuracy: 2363/5000 (47%)\n",
      "[epoch 4] loss: 1.3051577\n",
      "Test set: Average loss: 1.4434, Accuracy: 2386/5000 (48%)\n",
      "[epoch 5] loss: 1.2200009\n",
      "Test set: Average loss: 1.4670, Accuracy: 2399/5000 (48%)\n",
      "[epoch 6] loss: 1.1571204\n",
      "Test set: Average loss: 1.5573, Accuracy: 2349/5000 (47%)\n",
      "[epoch 7] loss: 1.1263870\n",
      "Test set: Average loss: 1.5241, Accuracy: 2371/5000 (47%)\n",
      "[epoch 8] loss: 1.0446807\n",
      "Test set: Average loss: 1.4891, Accuracy: 2440/5000 (49%)\n",
      "[epoch 9] loss: 0.9795823\n",
      "Test set: Average loss: 1.5115, Accuracy: 2504/5000 (50%)\n",
      "[epoch 10] loss: 0.9154240\n",
      "Test set: Average loss: 1.5816, Accuracy: 2431/5000 (49%)\n",
      "[epoch 11] loss: 0.8426826\n",
      "Test set: Average loss: 1.6011, Accuracy: 2470/5000 (49%)\n",
      "[epoch 12] loss: 0.7839798\n",
      "Test set: Average loss: 1.6773, Accuracy: 2425/5000 (48%)\n",
      "[epoch 13] loss: 0.6792933\n",
      "Test set: Average loss: 1.6293, Accuracy: 2526/5000 (51%)\n",
      "[epoch 14] loss: 0.5853705\n",
      "Test set: Average loss: 1.7279, Accuracy: 2447/5000 (49%)\n",
      "[epoch 15] loss: 0.4658427\n",
      "Test set: Average loss: 1.7422, Accuracy: 2522/5000 (50%)\n",
      "[epoch 16] loss: 0.3489010\n",
      "Test set: Average loss: 1.9035, Accuracy: 2479/5000 (50%)\n",
      "[epoch 17] loss: 0.2545695\n",
      "Test set: Average loss: 1.9509, Accuracy: 2500/5000 (50%)\n",
      "[epoch 18] loss: 0.1563929\n",
      "Test set: Average loss: 2.0538, Accuracy: 2499/5000 (50%)\n",
      "[epoch 19] loss: 0.0881594\n",
      "Test set: Average loss: 2.1573, Accuracy: 2480/5000 (50%)\n",
      "[epoch 20] loss: 0.0516832\n",
      "Test set: Average loss: 2.2271, Accuracy: 2509/5000 (50%)\n",
      "[epoch 21] loss: 0.0287385\n",
      "Test set: Average loss: 2.3354, Accuracy: 2518/5000 (50%)\n",
      "[epoch 22] loss: 0.0208672\n",
      "Test set: Average loss: 2.4083, Accuracy: 2523/5000 (50%)\n",
      "[epoch 23] loss: 0.0140002\n",
      "Test set: Average loss: 2.4731, Accuracy: 2547/5000 (51%)\n",
      "[epoch 24] loss: 0.0101455\n",
      "Test set: Average loss: 2.5340, Accuracy: 2528/5000 (51%)\n",
      "[epoch 25] loss: 0.0081072\n",
      "Test set: Average loss: 2.5904, Accuracy: 2534/5000 (51%)\n",
      "[epoch 26] loss: 0.0067308\n",
      "Test set: Average loss: 2.6456, Accuracy: 2529/5000 (51%)\n",
      "[epoch 27] loss: 0.0090396\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.7134, Accuracy: 2536/5000 (51%)\n",
      "[epoch 28] loss: 0.0059348\n",
      "Test set: Average loss: 2.7048, Accuracy: 2528/5000 (51%)\n",
      "[epoch 29] loss: 0.0051533\n",
      "Test set: Average loss: 2.7098, Accuracy: 2526/5000 (51%)\n",
      "[epoch 30] loss: 0.0048775\n",
      "Test set: Average loss: 2.7137, Accuracy: 2524/5000 (50%)\n",
      "[epoch 31] loss: 0.0046693\n",
      "Test set: Average loss: 2.7187, Accuracy: 2521/5000 (50%)\n",
      "[epoch 32] loss: 0.0045084\n",
      "Test set: Average loss: 2.7245, Accuracy: 2521/5000 (50%)\n",
      "[epoch 33] loss: 0.0043693\n",
      "Test set: Average loss: 2.7308, Accuracy: 2526/5000 (51%)\n",
      "[epoch 34] loss: 0.0042165\n",
      "Test set: Average loss: 2.7375, Accuracy: 2524/5000 (50%)\n",
      "[epoch 35] loss: 0.0040804\n",
      "Test set: Average loss: 2.7456, Accuracy: 2525/5000 (50%)\n",
      "[epoch 36] loss: 0.0039670\n",
      "Test set: Average loss: 2.7517, Accuracy: 2526/5000 (51%)\n",
      "[epoch 37] loss: 0.0038509\n",
      "Test set: Average loss: 2.7600, Accuracy: 2527/5000 (51%)\n",
      "[epoch 38] loss: 0.0037136\n",
      "Test set: Average loss: 2.7685, Accuracy: 2524/5000 (50%)\n",
      "[epoch 39] loss: 0.0036016\n",
      "Test set: Average loss: 2.7766, Accuracy: 2527/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40] loss: 0.0034837\n",
      "Test set: Average loss: 2.7881, Accuracy: 2523/5000 (50%)\n",
      "[epoch 41] loss: 0.0033626\n",
      "Test set: Average loss: 2.7963, Accuracy: 2526/5000 (51%)\n",
      "[epoch 42] loss: 0.0032372\n",
      "Test set: Average loss: 2.8048, Accuracy: 2526/5000 (51%)\n",
      "[epoch 43] loss: 0.0031280\n",
      "Test set: Average loss: 2.8168, Accuracy: 2527/5000 (51%)\n",
      "[epoch 44] loss: 0.0030050\n",
      "Test set: Average loss: 2.8279, Accuracy: 2529/5000 (51%)\n",
      "[epoch 45] loss: 0.0028798\n",
      "Test set: Average loss: 2.8402, Accuracy: 2531/5000 (51%)\n",
      "[epoch 46] loss: 0.0027702\n",
      "Test set: Average loss: 2.8509, Accuracy: 2528/5000 (51%)\n",
      "[epoch 47] loss: 0.0026628\n",
      "Test set: Average loss: 2.8623, Accuracy: 2528/5000 (51%)\n",
      "[epoch 48] loss: 0.0025447\n",
      "Test set: Average loss: 2.8770, Accuracy: 2536/5000 (51%)\n",
      "[epoch 49] loss: 0.0024238\n",
      "Test set: Average loss: 2.8891, Accuracy: 2533/5000 (51%)\n",
      "[epoch 50] loss: 0.0023129\n",
      "Test set: Average loss: 2.9034, Accuracy: 2528/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4731, Accuracy: 2547/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 2.3783, Accuracy: 5156/10000 (52%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 516/5000 (10%)\n",
      "[epoch 1] loss: 1.8268263\n",
      "Test set: Average loss: 1.6520, Accuracy: 2069/5000 (41%)\n",
      "[epoch 2] loss: 1.5021824\n",
      "Test set: Average loss: 1.5497, Accuracy: 2182/5000 (44%)\n",
      "[epoch 3] loss: 1.3803386\n",
      "Test set: Average loss: 1.4926, Accuracy: 2324/5000 (46%)\n",
      "[epoch 4] loss: 1.2603949\n",
      "Test set: Average loss: 1.4904, Accuracy: 2379/5000 (48%)\n",
      "[epoch 5] loss: 1.1905956\n",
      "Test set: Average loss: 1.5091, Accuracy: 2294/5000 (46%)\n",
      "[epoch 6] loss: 1.1214643\n",
      "Test set: Average loss: 1.5279, Accuracy: 2370/5000 (47%)\n",
      "[epoch 7] loss: 1.0259674\n",
      "Test set: Average loss: 1.4944, Accuracy: 2438/5000 (49%)\n",
      "[epoch 8] loss: 0.9712684\n",
      "Test set: Average loss: 1.5596, Accuracy: 2415/5000 (48%)\n",
      "[epoch 9] loss: 0.8678725\n",
      "Test set: Average loss: 1.5814, Accuracy: 2482/5000 (50%)\n",
      "[epoch 10] loss: 0.7709902\n",
      "Test set: Average loss: 1.6409, Accuracy: 2415/5000 (48%)\n",
      "[epoch 11] loss: 0.6536109\n",
      "Test set: Average loss: 1.6689, Accuracy: 2450/5000 (49%)\n",
      "[epoch 12] loss: 0.5212463\n",
      "Test set: Average loss: 1.7943, Accuracy: 2411/5000 (48%)\n",
      "[epoch 13] loss: 0.3992609\n",
      "Test set: Average loss: 1.8645, Accuracy: 2469/5000 (49%)\n",
      "[epoch 14] loss: 0.2742210\n",
      "Test set: Average loss: 2.0309, Accuracy: 2407/5000 (48%)\n",
      "[epoch 15] loss: 0.2386684\n",
      "Test set: Average loss: 2.0155, Accuracy: 2473/5000 (49%)\n",
      "[epoch 16] loss: 0.1023958\n",
      "Test set: Average loss: 2.1171, Accuracy: 2498/5000 (50%)\n",
      "[epoch 17] loss: 0.0543545\n",
      "Test set: Average loss: 2.2229, Accuracy: 2525/5000 (50%)\n",
      "[epoch 18] loss: 0.0304861\n",
      "Test set: Average loss: 2.3223, Accuracy: 2537/5000 (51%)\n",
      "[epoch 19] loss: 0.0189373\n",
      "Test set: Average loss: 2.3813, Accuracy: 2530/5000 (51%)\n",
      "[epoch 20] loss: 0.0117320\n",
      "Test set: Average loss: 2.4618, Accuracy: 2549/5000 (51%)\n",
      "[epoch 21] loss: 0.0086979\n",
      "Test set: Average loss: 2.5252, Accuracy: 2546/5000 (51%)\n",
      "[epoch 22] loss: 0.0068483\n",
      "Test set: Average loss: 2.5746, Accuracy: 2533/5000 (51%)\n",
      "[epoch 23] loss: 0.0056369\n",
      "Test set: Average loss: 2.6335, Accuracy: 2551/5000 (51%)\n",
      "[epoch 24] loss: 0.0047176\n",
      "Test set: Average loss: 2.6750, Accuracy: 2530/5000 (51%)\n",
      "[epoch 25] loss: 0.0040595\n",
      "Test set: Average loss: 2.7189, Accuracy: 2529/5000 (51%)\n",
      "[epoch 26] loss: 0.0034194\n",
      "Test set: Average loss: 2.7660, Accuracy: 2538/5000 (51%)\n",
      "[epoch 27] loss: 0.0029393\n",
      "Test set: Average loss: 2.8072, Accuracy: 2529/5000 (51%)\n",
      "[epoch 28] loss: 0.0025227\n",
      "Test set: Average loss: 2.8533, Accuracy: 2534/5000 (51%)\n",
      "[epoch 29] loss: 0.0022154\n",
      "Test set: Average loss: 2.8809, Accuracy: 2533/5000 (51%)\n",
      "[epoch 30] loss: 0.0019355\n",
      "Test set: Average loss: 2.9140, Accuracy: 2533/5000 (51%)\n",
      "[epoch 31] loss: 0.0016945\n",
      "Test set: Average loss: 2.9560, Accuracy: 2517/5000 (50%)\n",
      "[epoch 32] loss: 0.0014964\n",
      "Test set: Average loss: 2.9898, Accuracy: 2526/5000 (51%)\n",
      "[epoch 33] loss: 0.0013224\n",
      "Test set: Average loss: 3.0176, Accuracy: 2518/5000 (50%)\n",
      "[epoch 34] loss: 0.0011751\n",
      "Test set: Average loss: 3.0515, Accuracy: 2538/5000 (51%)\n",
      "[epoch 35] loss: 0.0010575\n",
      "Test set: Average loss: 3.0856, Accuracy: 2529/5000 (51%)\n",
      "[epoch 36] loss: 0.0009358\n",
      "Test set: Average loss: 3.1206, Accuracy: 2532/5000 (51%)\n",
      "[epoch 37] loss: 0.0008341\n",
      "Test set: Average loss: 3.1487, Accuracy: 2531/5000 (51%)\n",
      "[epoch 38] loss: 0.0007480\n",
      "Test set: Average loss: 3.1790, Accuracy: 2522/5000 (50%)\n",
      "[epoch 39] loss: 0.0006671\n",
      "Test set: Average loss: 3.2141, Accuracy: 2528/5000 (51%)\n",
      "[epoch 40] loss: 0.0005987\n",
      "Test set: Average loss: 3.2384, Accuracy: 2524/5000 (50%)\n",
      "[epoch 41] loss: 0.0005396\n",
      "Test set: Average loss: 3.2675, Accuracy: 2535/5000 (51%)\n",
      "[epoch 42] loss: 0.0004835\n",
      "Test set: Average loss: 3.2981, Accuracy: 2528/5000 (51%)\n",
      "[epoch 43] loss: 0.0004361\n",
      "Test set: Average loss: 3.3247, Accuracy: 2524/5000 (50%)\n",
      "[epoch 44] loss: 0.0003915\n",
      "Test set: Average loss: 3.3513, Accuracy: 2522/5000 (50%)\n",
      "[epoch 45] loss: 0.0003531\n",
      "Test set: Average loss: 3.3814, Accuracy: 2526/5000 (51%)\n",
      "[epoch 46] loss: 0.0003197\n",
      "Test set: Average loss: 3.4096, Accuracy: 2528/5000 (51%)\n",
      "[epoch 47] loss: 0.0002873\n",
      "Test set: Average loss: 3.4376, Accuracy: 2532/5000 (51%)\n",
      "[epoch 48] loss: 0.0002594\n",
      "Test set: Average loss: 3.4644, Accuracy: 2524/5000 (50%)\n",
      "[epoch 49] loss: 0.0002352\n",
      "Test set: Average loss: 3.4941, Accuracy: 2528/5000 (51%)\n",
      "[epoch 50] loss: 0.0002134\n",
      "Test set: Average loss: 3.5224, Accuracy: 2529/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6335, Accuracy: 2551/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 2.5969, Accuracy: 5192/10000 (52%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2999, Accuracy: 583/5000 (12%)\n",
      "[epoch 1] loss: 1.8281327\n",
      "Test set: Average loss: 1.6141, Accuracy: 1978/5000 (40%)\n",
      "[epoch 2] loss: 1.5526020\n",
      "Test set: Average loss: 1.5493, Accuracy: 2145/5000 (43%)\n",
      "[epoch 3] loss: 1.4294736\n",
      "Test set: Average loss: 1.4562, Accuracy: 2396/5000 (48%)\n",
      "[epoch 4] loss: 1.3319027\n",
      "Test set: Average loss: 1.4702, Accuracy: 2358/5000 (47%)\n",
      "[epoch 5] loss: 1.2564766\n",
      "Test set: Average loss: 1.4244, Accuracy: 2457/5000 (49%)\n",
      "[epoch 6] loss: 1.1839505\n",
      "Test set: Average loss: 1.5462, Accuracy: 2313/5000 (46%)\n",
      "[epoch 7] loss: 1.1175975\n",
      "Test set: Average loss: 1.4981, Accuracy: 2431/5000 (49%)\n",
      "[epoch 8] loss: 1.0556022\n",
      "Test set: Average loss: 1.4934, Accuracy: 2397/5000 (48%)\n",
      "[epoch 9] loss: 0.9845903\n",
      "Test set: Average loss: 1.5372, Accuracy: 2417/5000 (48%)\n",
      "[epoch 10] loss: 0.8864654\n",
      "Test set: Average loss: 1.5203, Accuracy: 2478/5000 (50%)\n",
      "[epoch 11] loss: 0.7953676\n",
      "Test set: Average loss: 1.5363, Accuracy: 2522/5000 (50%)\n",
      "[epoch 12] loss: 0.6904040\n",
      "Test set: Average loss: 1.6193, Accuracy: 2441/5000 (49%)\n",
      "[epoch 13] loss: 0.5508512\n",
      "Test set: Average loss: 1.7052, Accuracy: 2426/5000 (49%)\n",
      "[epoch 14] loss: 0.4366087\n",
      "Test set: Average loss: 1.7655, Accuracy: 2454/5000 (49%)\n",
      "[epoch 15] loss: 0.3060938\n",
      "Test set: Average loss: 1.8589, Accuracy: 2485/5000 (50%)\n",
      "[epoch 16] loss: 0.2073728\n",
      "Test set: Average loss: 1.9895, Accuracy: 2465/5000 (49%)\n",
      "[epoch 17] loss: 0.1256328\n",
      "Test set: Average loss: 2.0377, Accuracy: 2455/5000 (49%)\n",
      "[epoch 18] loss: 0.0736125\n",
      "Test set: Average loss: 2.1379, Accuracy: 2464/5000 (49%)\n",
      "[epoch 19] loss: 0.0430555\n",
      "Test set: Average loss: 2.2608, Accuracy: 2502/5000 (50%)\n",
      "[epoch 20] loss: 0.0225178\n",
      "Test set: Average loss: 2.3010, Accuracy: 2488/5000 (50%)\n",
      "[epoch 21] loss: 0.0142149\n",
      "Test set: Average loss: 2.3844, Accuracy: 2493/5000 (50%)\n",
      "[epoch 22] loss: 0.0105295\n",
      "Test set: Average loss: 2.4335, Accuracy: 2468/5000 (49%)\n",
      "[epoch 23] loss: 0.0082586\n",
      "Test set: Average loss: 2.4813, Accuracy: 2487/5000 (50%)\n",
      "[epoch 24] loss: 0.0067106\n",
      "Test set: Average loss: 2.5354, Accuracy: 2473/5000 (49%)\n",
      "[epoch 25] loss: 0.0056068\n",
      "Test set: Average loss: 2.5915, Accuracy: 2483/5000 (50%)\n",
      "[epoch 26] loss: 0.0047014\n",
      "Test set: Average loss: 2.6265, Accuracy: 2473/5000 (49%)\n",
      "[epoch 27] loss: 0.0040126\n",
      "Test set: Average loss: 2.6653, Accuracy: 2468/5000 (49%)\n",
      "[epoch 28] loss: 0.0034284\n",
      "Test set: Average loss: 2.7086, Accuracy: 2478/5000 (50%)\n",
      "[epoch 29] loss: 0.0029619\n",
      "Test set: Average loss: 2.7465, Accuracy: 2480/5000 (50%)\n",
      "[epoch 30] loss: 0.0025667\n",
      "Test set: Average loss: 2.7909, Accuracy: 2482/5000 (50%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0022442\n",
      "Test set: Average loss: 2.8225, Accuracy: 2478/5000 (50%)\n",
      "[epoch 32] loss: 0.0019649\n",
      "Test set: Average loss: 2.8592, Accuracy: 2480/5000 (50%)\n",
      "[epoch 33] loss: 0.0017378\n",
      "Test set: Average loss: 2.8912, Accuracy: 2486/5000 (50%)\n",
      "[epoch 34] loss: 0.0015312\n",
      "Test set: Average loss: 2.9257, Accuracy: 2479/5000 (50%)\n",
      "[epoch 35] loss: 0.0013546\n",
      "Test set: Average loss: 2.9610, Accuracy: 2484/5000 (50%)\n",
      "[epoch 36] loss: 0.0011984\n",
      "Test set: Average loss: 2.9900, Accuracy: 2484/5000 (50%)\n",
      "[epoch 37] loss: 0.0010675\n",
      "Test set: Average loss: 3.0193, Accuracy: 2484/5000 (50%)\n",
      "[epoch 38] loss: 0.0009536\n",
      "Test set: Average loss: 3.0568, Accuracy: 2481/5000 (50%)\n",
      "[epoch 39] loss: 0.0008532\n",
      "Test set: Average loss: 3.0880, Accuracy: 2476/5000 (50%)\n",
      "[epoch 40] loss: 0.0007646\n",
      "Test set: Average loss: 3.1173, Accuracy: 2483/5000 (50%)\n",
      "[epoch 41] loss: 0.0006813\n",
      "Test set: Average loss: 3.1435, Accuracy: 2483/5000 (50%)\n",
      "[epoch 42] loss: 0.0006084\n",
      "Test set: Average loss: 3.1850, Accuracy: 2473/5000 (49%)\n",
      "[epoch 43] loss: 0.0005478\n",
      "Test set: Average loss: 3.2104, Accuracy: 2468/5000 (49%)\n",
      "[epoch 44] loss: 0.0004921\n",
      "Test set: Average loss: 3.2357, Accuracy: 2475/5000 (50%)\n",
      "[epoch 45] loss: 0.0004422\n",
      "Test set: Average loss: 3.2639, Accuracy: 2468/5000 (49%)\n",
      "[epoch 46] loss: 0.0003984\n",
      "Test set: Average loss: 3.2885, Accuracy: 2477/5000 (50%)\n",
      "[epoch 47] loss: 0.0003609\n",
      "Test set: Average loss: 3.3198, Accuracy: 2475/5000 (50%)\n",
      "[epoch 48] loss: 0.0003254\n",
      "Test set: Average loss: 3.3508, Accuracy: 2474/5000 (49%)\n",
      "[epoch 49] loss: 0.0002919\n",
      "Test set: Average loss: 3.3763, Accuracy: 2474/5000 (49%)\n",
      "[epoch 50] loss: 0.0002636\n",
      "Test set: Average loss: 3.3990, Accuracy: 2479/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5363, Accuracy: 2522/5000 (50%)\n",
      "Test\n",
      "Test set: Average loss: 1.5037, Accuracy: 5070/10000 (51%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3050, Accuracy: 444/5000 (9%)\n",
      "[epoch 1] loss: 1.7078844\n",
      "Test set: Average loss: 1.4962, Accuracy: 2329/5000 (47%)\n",
      "[epoch 2] loss: 1.4476017\n",
      "Test set: Average loss: 1.4937, Accuracy: 2295/5000 (46%)\n",
      "[epoch 3] loss: 1.3568121\n",
      "Test set: Average loss: 1.4120, Accuracy: 2515/5000 (50%)\n",
      "[epoch 4] loss: 1.2857782\n",
      "Test set: Average loss: 1.4506, Accuracy: 2448/5000 (49%)\n",
      "[epoch 5] loss: 1.2296265\n",
      "Test set: Average loss: 1.3904, Accuracy: 2542/5000 (51%)\n",
      "[epoch 6] loss: 1.1743362\n",
      "Test set: Average loss: 1.3598, Accuracy: 2627/5000 (53%)\n",
      "[epoch 7] loss: 1.0950804\n",
      "Test set: Average loss: 1.3414, Accuracy: 2636/5000 (53%)\n",
      "[epoch 8] loss: 1.0249866\n",
      "Test set: Average loss: 1.4360, Accuracy: 2539/5000 (51%)\n",
      "[epoch 9] loss: 0.9449701\n",
      "Test set: Average loss: 1.3234, Accuracy: 2720/5000 (54%)\n",
      "[epoch 10] loss: 0.8601845\n",
      "Test set: Average loss: 1.3688, Accuracy: 2685/5000 (54%)\n",
      "[epoch 11] loss: 0.7562533\n",
      "Test set: Average loss: 1.3931, Accuracy: 2715/5000 (54%)\n",
      "[epoch 12] loss: 0.6319662\n",
      "Test set: Average loss: 1.4032, Accuracy: 2789/5000 (56%)\n",
      "[epoch 13] loss: 0.5077288\n",
      "Test set: Average loss: 1.5598, Accuracy: 2634/5000 (53%)\n",
      "[epoch 14] loss: 0.3705273\n",
      "Test set: Average loss: 1.5504, Accuracy: 2723/5000 (54%)\n",
      "[epoch 15] loss: 0.2495503\n",
      "Test set: Average loss: 1.6329, Accuracy: 2747/5000 (55%)\n",
      "[epoch 16] loss: 0.1411878\n",
      "Test set: Average loss: 1.7164, Accuracy: 2728/5000 (55%)\n",
      "[epoch 17] loss: 0.0878272\n",
      "Test set: Average loss: 1.7679, Accuracy: 2746/5000 (55%)\n",
      "[epoch 18] loss: 0.0426677\n",
      "Test set: Average loss: 1.8214, Accuracy: 2833/5000 (57%)\n",
      "[epoch 19] loss: 0.0191188\n",
      "Test set: Average loss: 1.8974, Accuracy: 2820/5000 (56%)\n",
      "[epoch 20] loss: 0.0101505\n",
      "Test set: Average loss: 1.9598, Accuracy: 2839/5000 (57%)\n",
      "[epoch 21] loss: 0.0065806\n",
      "Test set: Average loss: 2.0170, Accuracy: 2836/5000 (57%)\n",
      "[epoch 22] loss: 0.0048995\n",
      "Test set: Average loss: 2.0620, Accuracy: 2844/5000 (57%)\n",
      "[epoch 23] loss: 0.0037788\n",
      "Test set: Average loss: 2.1047, Accuracy: 2846/5000 (57%)\n",
      "[epoch 24] loss: 0.0030165\n",
      "Test set: Average loss: 2.1551, Accuracy: 2842/5000 (57%)\n",
      "[epoch 25] loss: 0.0023988\n",
      "Test set: Average loss: 2.2011, Accuracy: 2846/5000 (57%)\n",
      "[epoch 26] loss: 0.0019425\n",
      "Test set: Average loss: 2.2483, Accuracy: 2842/5000 (57%)\n",
      "[epoch 27] loss: 0.0015637\n",
      "Test set: Average loss: 2.2896, Accuracy: 2860/5000 (57%)\n",
      "[epoch 28] loss: 0.0012782\n",
      "Test set: Average loss: 2.3307, Accuracy: 2852/5000 (57%)\n",
      "[epoch 29] loss: 0.0010406\n",
      "Test set: Average loss: 2.3745, Accuracy: 2856/5000 (57%)\n",
      "[epoch 30] loss: 0.0008495\n",
      "Test set: Average loss: 2.4179, Accuracy: 2851/5000 (57%)\n",
      "[epoch 31] loss: 0.0006900\n",
      "Test set: Average loss: 2.4651, Accuracy: 2841/5000 (57%)\n",
      "[epoch 32] loss: 0.0005684\n",
      "Test set: Average loss: 2.5025, Accuracy: 2850/5000 (57%)\n",
      "[epoch 33] loss: 0.0004657\n",
      "Test set: Average loss: 2.5355, Accuracy: 2853/5000 (57%)\n",
      "[epoch 34] loss: 0.0003803\n",
      "Test set: Average loss: 2.5781, Accuracy: 2857/5000 (57%)\n",
      "[epoch 35] loss: 0.0003132\n",
      "Test set: Average loss: 2.6225, Accuracy: 2848/5000 (57%)\n",
      "[epoch 36] loss: 0.0002576\n",
      "Test set: Average loss: 2.6662, Accuracy: 2847/5000 (57%)\n",
      "[epoch 37] loss: 0.0002116\n",
      "Test set: Average loss: 2.7069, Accuracy: 2839/5000 (57%)\n",
      "[epoch 38] loss: 0.0001745\n",
      "Test set: Average loss: 2.7481, Accuracy: 2847/5000 (57%)\n",
      "[epoch 39] loss: 0.0001437\n",
      "Test set: Average loss: 2.7912, Accuracy: 2830/5000 (57%)\n",
      "[epoch 40] loss: 0.0001183\n",
      "Test set: Average loss: 2.8286, Accuracy: 2848/5000 (57%)\n",
      "[epoch 41] loss: 0.0000973\n",
      "Test set: Average loss: 2.8726, Accuracy: 2842/5000 (57%)\n",
      "[epoch 42] loss: 0.0000799\n",
      "Test set: Average loss: 2.9085, Accuracy: 2847/5000 (57%)\n",
      "[epoch 43] loss: 0.0000662\n",
      "Test set: Average loss: 2.9504, Accuracy: 2835/5000 (57%)\n",
      "[epoch 44] loss: 0.0000548\n",
      "Test set: Average loss: 2.9994, Accuracy: 2840/5000 (57%)\n",
      "[epoch 45] loss: 0.0000450\n",
      "Test set: Average loss: 3.0383, Accuracy: 2842/5000 (57%)\n",
      "[epoch 46] loss: 0.0000373\n",
      "Test set: Average loss: 3.0797, Accuracy: 2834/5000 (57%)\n",
      "[epoch 47] loss: 0.0000308\n",
      "Test set: Average loss: 3.1156, Accuracy: 2839/5000 (57%)\n",
      "[epoch 48] loss: 0.0000254\n",
      "Test set: Average loss: 3.1653, Accuracy: 2830/5000 (57%)\n",
      "[epoch 49] loss: 0.0000211\n",
      "Test set: Average loss: 3.2018, Accuracy: 2836/5000 (57%)\n",
      "[epoch 50] loss: 0.0000175\n",
      "Test set: Average loss: 3.2353, Accuracy: 2837/5000 (57%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2896, Accuracy: 2860/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 2.2784, Accuracy: 5711/10000 (57%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3015, Accuracy: 592/5000 (12%)\n",
      "[epoch 1] loss: 1.6625075\n",
      "Test set: Average loss: 1.5922, Accuracy: 2159/5000 (43%)\n",
      "[epoch 2] loss: 1.4079617\n",
      "Test set: Average loss: 1.3613, Accuracy: 2554/5000 (51%)\n",
      "[epoch 3] loss: 1.3327643\n",
      "Test set: Average loss: 1.3298, Accuracy: 2625/5000 (52%)\n",
      "[epoch 4] loss: 1.2543978\n",
      "Test set: Average loss: 1.3611, Accuracy: 2597/5000 (52%)\n",
      "[epoch 5] loss: 1.1873449\n",
      "Test set: Average loss: 1.3244, Accuracy: 2640/5000 (53%)\n",
      "[epoch 6] loss: 1.1246806\n",
      "Test set: Average loss: 1.3552, Accuracy: 2590/5000 (52%)\n",
      "[epoch 7] loss: 1.0625288\n",
      "Test set: Average loss: 1.3156, Accuracy: 2712/5000 (54%)\n",
      "[epoch 8] loss: 0.9746927\n",
      "Test set: Average loss: 1.3287, Accuracy: 2747/5000 (55%)\n",
      "[epoch 9] loss: 0.8809562\n",
      "Test set: Average loss: 1.3115, Accuracy: 2776/5000 (56%)\n",
      "[epoch 10] loss: 0.7791881\n",
      "Test set: Average loss: 1.3218, Accuracy: 2821/5000 (56%)\n",
      "[epoch 11] loss: 0.6738869\n",
      "Test set: Average loss: 1.3571, Accuracy: 2834/5000 (57%)\n",
      "[epoch 12] loss: 0.5331985\n",
      "Test set: Average loss: 1.4476, Accuracy: 2746/5000 (55%)\n",
      "[epoch 13] loss: 0.3949204\n",
      "Test set: Average loss: 1.5206, Accuracy: 2777/5000 (56%)\n",
      "[epoch 14] loss: 0.2717895\n",
      "Test set: Average loss: 1.5173, Accuracy: 2818/5000 (56%)\n",
      "[epoch 15] loss: 0.1595242\n",
      "Test set: Average loss: 1.6100, Accuracy: 2794/5000 (56%)\n",
      "[epoch 16] loss: 0.0918562\n",
      "Test set: Average loss: 1.6752, Accuracy: 2865/5000 (57%)\n",
      "[epoch 17] loss: 0.0501470\n",
      "Test set: Average loss: 1.7796, Accuracy: 2842/5000 (57%)\n",
      "[epoch 18] loss: 0.0283151\n",
      "Test set: Average loss: 1.8252, Accuracy: 2844/5000 (57%)\n",
      "[epoch 19] loss: 0.0206433\n",
      "Test set: Average loss: 2.0110, Accuracy: 2765/5000 (55%)\n",
      "[epoch 20] loss: 0.1659645\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0661, Accuracy: 2694/5000 (54%)\n",
      "[epoch 21] loss: 0.1067094\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.8506, Accuracy: 2824/5000 (56%)\n",
      "[epoch 22] loss: 0.0398978\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 23] loss: 0.0378418\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 24] loss: 0.0377432\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 25] loss: 0.0376730\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 26] loss: 0.0376190\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 27] loss: 0.0376641\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 28] loss: 0.0376282\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 29] loss: 0.0376191\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 30] loss: 0.0376529\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 31] loss: 0.0376214\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 32] loss: 0.0376132\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 33] loss: 0.0376225\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 34] loss: 0.0376495\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 35] loss: 0.0376605\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 36] loss: 0.0376405\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 37] loss: 0.0376348\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 38] loss: 0.0376836\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 39] loss: 0.0378080\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 40] loss: 0.0376756\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 41] loss: 0.0376406\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 42] loss: 0.0376151\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 43] loss: 0.0376601\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 44] loss: 0.0376225\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 45] loss: 0.0376375\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 46] loss: 0.0376705\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 47] loss: 0.0376586\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 48] loss: 0.0376681\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 49] loss: 0.0376329\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "[epoch 50] loss: 0.0376364\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.8471, Accuracy: 2824/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6752, Accuracy: 2865/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.6621, Accuracy: 5688/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3091, Accuracy: 367/5000 (7%)\n",
      "[epoch 1] loss: 1.7129224\n",
      "Test set: Average loss: 1.5730, Accuracy: 2161/5000 (43%)\n",
      "[epoch 2] loss: 1.4495672\n",
      "Test set: Average loss: 1.4059, Accuracy: 2428/5000 (49%)\n",
      "[epoch 3] loss: 1.3513488\n",
      "Test set: Average loss: 1.4415, Accuracy: 2403/5000 (48%)\n",
      "[epoch 4] loss: 1.2734779\n",
      "Test set: Average loss: 1.3526, Accuracy: 2617/5000 (52%)\n",
      "[epoch 5] loss: 1.2049924\n",
      "Test set: Average loss: 1.3084, Accuracy: 2675/5000 (54%)\n",
      "[epoch 6] loss: 1.1299382\n",
      "Test set: Average loss: 1.3678, Accuracy: 2600/5000 (52%)\n",
      "[epoch 7] loss: 1.0822291\n",
      "Test set: Average loss: 1.3413, Accuracy: 2687/5000 (54%)\n",
      "[epoch 8] loss: 1.0186571\n",
      "Test set: Average loss: 1.3556, Accuracy: 2607/5000 (52%)\n",
      "[epoch 9] loss: 0.9464987\n",
      "Test set: Average loss: 1.3679, Accuracy: 2666/5000 (53%)\n",
      "[epoch 10] loss: 0.8779687\n",
      "Test set: Average loss: 1.3762, Accuracy: 2719/5000 (54%)\n",
      "[epoch 11] loss: 0.7756898\n",
      "Test set: Average loss: 1.4123, Accuracy: 2730/5000 (55%)\n",
      "[epoch 12] loss: 0.6916922\n",
      "Test set: Average loss: 1.3868, Accuracy: 2778/5000 (56%)\n",
      "[epoch 13] loss: 0.5748506\n",
      "Test set: Average loss: 1.4691, Accuracy: 2722/5000 (54%)\n",
      "[epoch 14] loss: 0.4607676\n",
      "Test set: Average loss: 1.5020, Accuracy: 2717/5000 (54%)\n",
      "[epoch 15] loss: 0.3352872\n",
      "Test set: Average loss: 1.6008, Accuracy: 2793/5000 (56%)\n",
      "[epoch 16] loss: 0.2328837\n",
      "Test set: Average loss: 1.6710, Accuracy: 2740/5000 (55%)\n",
      "[epoch 17] loss: 0.1360698\n",
      "Test set: Average loss: 1.7407, Accuracy: 2737/5000 (55%)\n",
      "[epoch 18] loss: 0.0740889\n",
      "Test set: Average loss: 1.8240, Accuracy: 2765/5000 (55%)\n",
      "[epoch 19] loss: 0.0393247\n",
      "Test set: Average loss: 1.9254, Accuracy: 2775/5000 (56%)\n",
      "[epoch 20] loss: 0.0202152\n",
      "Test set: Average loss: 1.9468, Accuracy: 2805/5000 (56%)\n",
      "[epoch 21] loss: 0.0100581\n",
      "Test set: Average loss: 2.0237, Accuracy: 2791/5000 (56%)\n",
      "[epoch 22] loss: 0.0068195\n",
      "Test set: Average loss: 2.0838, Accuracy: 2785/5000 (56%)\n",
      "[epoch 23] loss: 0.0050141\n",
      "Test set: Average loss: 2.1308, Accuracy: 2805/5000 (56%)\n",
      "[epoch 24] loss: 0.0039279\n",
      "Test set: Average loss: 2.1791, Accuracy: 2804/5000 (56%)\n",
      "[epoch 25] loss: 0.0031189\n",
      "Test set: Average loss: 2.2327, Accuracy: 2800/5000 (56%)\n",
      "[epoch 26] loss: 0.0024760\n",
      "Test set: Average loss: 2.2793, Accuracy: 2790/5000 (56%)\n",
      "[epoch 27] loss: 0.0020222\n",
      "Test set: Average loss: 2.3256, Accuracy: 2806/5000 (56%)\n",
      "[epoch 28] loss: 0.0016310\n",
      "Test set: Average loss: 2.3632, Accuracy: 2809/5000 (56%)\n",
      "[epoch 29] loss: 0.0013322\n",
      "Test set: Average loss: 2.4099, Accuracy: 2803/5000 (56%)\n",
      "[epoch 30] loss: 0.0010812\n",
      "Test set: Average loss: 2.4489, Accuracy: 2816/5000 (56%)\n",
      "[epoch 31] loss: 0.0008847\n",
      "Test set: Average loss: 2.5047, Accuracy: 2796/5000 (56%)\n",
      "[epoch 32] loss: 0.0007251\n",
      "Test set: Average loss: 2.5411, Accuracy: 2794/5000 (56%)\n",
      "[epoch 33] loss: 0.0005923\n",
      "Test set: Average loss: 2.5836, Accuracy: 2809/5000 (56%)\n",
      "[epoch 34] loss: 0.0004897\n",
      "Test set: Average loss: 2.6229, Accuracy: 2811/5000 (56%)\n",
      "[epoch 35] loss: 0.0004002\n",
      "Test set: Average loss: 2.6711, Accuracy: 2801/5000 (56%)\n",
      "[epoch 36] loss: 0.0003279\n",
      "Test set: Average loss: 2.7129, Accuracy: 2798/5000 (56%)\n",
      "[epoch 37] loss: 0.0002706\n",
      "Test set: Average loss: 2.7594, Accuracy: 2792/5000 (56%)\n",
      "[epoch 38] loss: 0.0002227\n",
      "Test set: Average loss: 2.7918, Accuracy: 2797/5000 (56%)\n",
      "[epoch 39] loss: 0.0001833\n",
      "Test set: Average loss: 2.8463, Accuracy: 2794/5000 (56%)\n",
      "[epoch 40] loss: 0.0001512\n",
      "Test set: Average loss: 2.8825, Accuracy: 2801/5000 (56%)\n",
      "[epoch 41] loss: 0.0001250\n",
      "Test set: Average loss: 2.9318, Accuracy: 2790/5000 (56%)\n",
      "[epoch 42] loss: 0.0001029\n",
      "Test set: Average loss: 2.9651, Accuracy: 2797/5000 (56%)\n",
      "[epoch 43] loss: 0.0000851\n",
      "Test set: Average loss: 3.0082, Accuracy: 2803/5000 (56%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 44] loss: 0.0000701\n",
      "Test set: Average loss: 3.0515, Accuracy: 2800/5000 (56%)\n",
      "[epoch 45] loss: 0.0000578\n",
      "Test set: Average loss: 3.0977, Accuracy: 2789/5000 (56%)\n",
      "[epoch 46] loss: 0.0000480\n",
      "Test set: Average loss: 3.1370, Accuracy: 2791/5000 (56%)\n",
      "[epoch 47] loss: 0.0000397\n",
      "Test set: Average loss: 3.1855, Accuracy: 2789/5000 (56%)\n",
      "[epoch 48] loss: 0.0000329\n",
      "Test set: Average loss: 3.2165, Accuracy: 2790/5000 (56%)\n",
      "[epoch 49] loss: 0.0000270\n",
      "Test set: Average loss: 3.2584, Accuracy: 2797/5000 (56%)\n",
      "[epoch 50] loss: 0.0000226\n",
      "Test set: Average loss: 3.3023, Accuracy: 2802/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4489, Accuracy: 2816/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 2.4201, Accuracy: 5690/10000 (57%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3051, Accuracy: 439/5000 (9%)\n",
      "[epoch 1] loss: 1.6358257\n",
      "Test set: Average loss: 1.4430, Accuracy: 2382/5000 (48%)\n",
      "[epoch 2] loss: 1.3779657\n",
      "Test set: Average loss: 1.3749, Accuracy: 2535/5000 (51%)\n",
      "[epoch 3] loss: 1.2888956\n",
      "Test set: Average loss: 1.3874, Accuracy: 2541/5000 (51%)\n",
      "[epoch 4] loss: 1.2188134\n",
      "Test set: Average loss: 1.3222, Accuracy: 2624/5000 (52%)\n",
      "[epoch 5] loss: 1.1438200\n",
      "Test set: Average loss: 1.3076, Accuracy: 2676/5000 (54%)\n",
      "[epoch 6] loss: 1.0738898\n",
      "Test set: Average loss: 1.2978, Accuracy: 2770/5000 (55%)\n",
      "[epoch 7] loss: 1.0101504\n",
      "Test set: Average loss: 1.2325, Accuracy: 2847/5000 (57%)\n",
      "[epoch 8] loss: 0.9383884\n",
      "Test set: Average loss: 1.2463, Accuracy: 2924/5000 (58%)\n",
      "[epoch 9] loss: 0.8518815\n",
      "Test set: Average loss: 1.3882, Accuracy: 2733/5000 (55%)\n",
      "[epoch 10] loss: 0.7545342\n",
      "Test set: Average loss: 1.2890, Accuracy: 2900/5000 (58%)\n",
      "[epoch 11] loss: 0.6444052\n",
      "Test set: Average loss: 1.3357, Accuracy: 2914/5000 (58%)\n",
      "[epoch 12] loss: 0.5213494\n",
      "Test set: Average loss: 1.4154, Accuracy: 2871/5000 (57%)\n",
      "[epoch 13] loss: 0.4065140\n",
      "Test set: Average loss: 1.4629, Accuracy: 2839/5000 (57%)\n",
      "[epoch 14] loss: 0.2872315\n",
      "Test set: Average loss: 1.5038, Accuracy: 2883/5000 (58%)\n",
      "[epoch 15] loss: 0.1854606\n",
      "Test set: Average loss: 1.6758, Accuracy: 2843/5000 (57%)\n",
      "[epoch 16] loss: 0.1086708\n",
      "Test set: Average loss: 1.7429, Accuracy: 2884/5000 (58%)\n",
      "[epoch 17] loss: 0.0590405\n",
      "Test set: Average loss: 1.8502, Accuracy: 2847/5000 (57%)\n",
      "[epoch 18] loss: 0.0281376\n",
      "Test set: Average loss: 1.8396, Accuracy: 2909/5000 (58%)\n",
      "[epoch 19] loss: 0.0086517\n",
      "Test set: Average loss: 1.8817, Accuracy: 2937/5000 (59%)\n",
      "[epoch 20] loss: 0.0043493\n",
      "Test set: Average loss: 1.9548, Accuracy: 2937/5000 (59%)\n",
      "[epoch 21] loss: 0.0030307\n",
      "Test set: Average loss: 1.9986, Accuracy: 2931/5000 (59%)\n",
      "[epoch 22] loss: 0.0022500\n",
      "Test set: Average loss: 2.0549, Accuracy: 2939/5000 (59%)\n",
      "[epoch 23] loss: 0.0017101\n",
      "Test set: Average loss: 2.1055, Accuracy: 2938/5000 (59%)\n",
      "[epoch 24] loss: 0.0013128\n",
      "Test set: Average loss: 2.1490, Accuracy: 2925/5000 (58%)\n",
      "[epoch 25] loss: 0.0010094\n",
      "Test set: Average loss: 2.1950, Accuracy: 2940/5000 (59%)\n",
      "[epoch 26] loss: 0.0007722\n",
      "Test set: Average loss: 2.2464, Accuracy: 2936/5000 (59%)\n",
      "[epoch 27] loss: 0.0005916\n",
      "Test set: Average loss: 2.3050, Accuracy: 2930/5000 (59%)\n",
      "[epoch 28] loss: 0.0004524\n",
      "Test set: Average loss: 2.3604, Accuracy: 2940/5000 (59%)\n",
      "[epoch 29] loss: 0.0003485\n",
      "Test set: Average loss: 2.4022, Accuracy: 2944/5000 (59%)\n",
      "[epoch 30] loss: 0.0002645\n",
      "Test set: Average loss: 2.4601, Accuracy: 2942/5000 (59%)\n",
      "[epoch 31] loss: 0.0002021\n",
      "Test set: Average loss: 2.5111, Accuracy: 2937/5000 (59%)\n",
      "[epoch 32] loss: 0.0001543\n",
      "Test set: Average loss: 2.5622, Accuracy: 2940/5000 (59%)\n",
      "[epoch 33] loss: 0.0001177\n",
      "Test set: Average loss: 2.6177, Accuracy: 2949/5000 (59%)\n",
      "[epoch 34] loss: 0.0000902\n",
      "Test set: Average loss: 2.6707, Accuracy: 2938/5000 (59%)\n",
      "[epoch 35] loss: 0.0000686\n",
      "Test set: Average loss: 2.7203, Accuracy: 2934/5000 (59%)\n",
      "[epoch 36] loss: 0.0000522\n",
      "Test set: Average loss: 2.7809, Accuracy: 2945/5000 (59%)\n",
      "[epoch 37] loss: 0.0000396\n",
      "Test set: Average loss: 2.8362, Accuracy: 2941/5000 (59%)\n",
      "[epoch 38] loss: 0.0000302\n",
      "Test set: Average loss: 2.8900, Accuracy: 2936/5000 (59%)\n",
      "[epoch 39] loss: 0.0000230\n",
      "Test set: Average loss: 2.9412, Accuracy: 2937/5000 (59%)\n",
      "[epoch 40] loss: 0.0000175\n",
      "Test set: Average loss: 2.9943, Accuracy: 2936/5000 (59%)\n",
      "[epoch 41] loss: 0.0000133\n",
      "Test set: Average loss: 3.0534, Accuracy: 2939/5000 (59%)\n",
      "[epoch 42] loss: 0.0000101\n",
      "Test set: Average loss: 3.0990, Accuracy: 2933/5000 (59%)\n",
      "[epoch 43] loss: 0.0000077\n",
      "Test set: Average loss: 3.1606, Accuracy: 2921/5000 (58%)\n",
      "[epoch 44] loss: 0.0000059\n",
      "Test set: Average loss: 3.2113, Accuracy: 2931/5000 (59%)\n",
      "[epoch 45] loss: 0.0000045\n",
      "Test set: Average loss: 3.2695, Accuracy: 2933/5000 (59%)\n",
      "[epoch 46] loss: 0.0000034\n",
      "Test set: Average loss: 3.3171, Accuracy: 2941/5000 (59%)\n",
      "[epoch 47] loss: 0.0000026\n",
      "Test set: Average loss: 3.3723, Accuracy: 2930/5000 (59%)\n",
      "[epoch 48] loss: 0.0000020\n",
      "Test set: Average loss: 3.4121, Accuracy: 2920/5000 (58%)\n",
      "[epoch 49] loss: 0.0000015\n",
      "Test set: Average loss: 3.4571, Accuracy: 2928/5000 (59%)\n",
      "[epoch 50] loss: 0.0000011\n",
      "Test set: Average loss: 3.5001, Accuracy: 2926/5000 (59%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6177, Accuracy: 2949/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 2.5824, Accuracy: 6001/10000 (60%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 704/5000 (14%)\n",
      "[epoch 1] loss: 1.6186397\n",
      "Test set: Average loss: 1.4437, Accuracy: 2327/5000 (47%)\n",
      "[epoch 2] loss: 1.3811001\n",
      "Test set: Average loss: 1.3695, Accuracy: 2470/5000 (49%)\n",
      "[epoch 3] loss: 1.2709267\n",
      "Test set: Average loss: 1.3112, Accuracy: 2643/5000 (53%)\n",
      "[epoch 4] loss: 1.2100919\n",
      "Test set: Average loss: 1.2966, Accuracy: 2676/5000 (54%)\n",
      "[epoch 5] loss: 1.1174774\n",
      "Test set: Average loss: 1.2716, Accuracy: 2732/5000 (55%)\n",
      "[epoch 6] loss: 1.0520433\n",
      "Test set: Average loss: 1.2726, Accuracy: 2732/5000 (55%)\n",
      "[epoch 7] loss: 0.9816490\n",
      "Test set: Average loss: 1.2563, Accuracy: 2828/5000 (57%)\n",
      "[epoch 8] loss: 0.8987073\n",
      "Test set: Average loss: 1.2898, Accuracy: 2811/5000 (56%)\n",
      "[epoch 9] loss: 0.8010366\n",
      "Test set: Average loss: 1.2726, Accuracy: 2832/5000 (57%)\n",
      "[epoch 10] loss: 0.7002395\n",
      "Test set: Average loss: 1.2820, Accuracy: 2852/5000 (57%)\n",
      "[epoch 11] loss: 0.5833465\n",
      "Test set: Average loss: 1.3235, Accuracy: 2904/5000 (58%)\n",
      "[epoch 12] loss: 0.4588844\n",
      "Test set: Average loss: 1.4229, Accuracy: 2854/5000 (57%)\n",
      "[epoch 13] loss: 0.3319815\n",
      "Test set: Average loss: 1.4452, Accuracy: 2904/5000 (58%)\n",
      "[epoch 14] loss: 0.2087715\n",
      "Test set: Average loss: 1.5579, Accuracy: 2876/5000 (58%)\n",
      "[epoch 15] loss: 0.1270880\n",
      "Test set: Average loss: 1.6267, Accuracy: 2913/5000 (58%)\n",
      "[epoch 16] loss: 0.0641739\n",
      "Test set: Average loss: 1.7462, Accuracy: 2878/5000 (58%)\n",
      "[epoch 17] loss: 0.0404249\n",
      "Test set: Average loss: 1.8666, Accuracy: 2870/5000 (57%)\n",
      "[epoch 18] loss: 0.1706619\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9912, Accuracy: 2731/5000 (55%)\n",
      "[epoch 19] loss: 0.1397579\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7715, Accuracy: 2856/5000 (57%)\n",
      "[epoch 20] loss: 0.0494015\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7736, Accuracy: 2870/5000 (57%)\n",
      "[epoch 21] loss: 0.0463018\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 22] loss: 0.0460043\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 23] loss: 0.0459903\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 24] loss: 0.0459812\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 25] loss: 0.0459764\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 26] loss: 0.0459768\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 27] loss: 0.0459762\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] loss: 0.0459699\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 29] loss: 0.0459656\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 30] loss: 0.0459832\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 31] loss: 0.0459640\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 32] loss: 0.0459878\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 33] loss: 0.0459673\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 34] loss: 0.0459620\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 35] loss: 0.0459823\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 36] loss: 0.0459772\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 37] loss: 0.0459689\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 38] loss: 0.0459822\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 39] loss: 0.0459700\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 40] loss: 0.0459763\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 41] loss: 0.0459815\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 42] loss: 0.0459607\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 43] loss: 0.0459747\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 44] loss: 0.0459736\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 45] loss: 0.0459803\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 46] loss: 0.0459663\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 47] loss: 0.0459875\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 48] loss: 0.0459658\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 49] loss: 0.0459706\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "[epoch 50] loss: 0.0459645\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.7737, Accuracy: 2872/5000 (57%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6267, Accuracy: 2913/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.5587, Accuracy: 5918/10000 (59%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3027, Accuracy: 494/5000 (10%)\n",
      "[epoch 1] loss: 1.6239532\n",
      "Test set: Average loss: 1.3994, Accuracy: 2379/5000 (48%)\n",
      "[epoch 2] loss: 1.3724159\n",
      "Test set: Average loss: 1.3835, Accuracy: 2478/5000 (50%)\n",
      "[epoch 3] loss: 1.2858246\n",
      "Test set: Average loss: 1.3419, Accuracy: 2600/5000 (52%)\n",
      "[epoch 4] loss: 1.2101071\n",
      "Test set: Average loss: 1.3003, Accuracy: 2697/5000 (54%)\n",
      "[epoch 5] loss: 1.1484267\n",
      "Test set: Average loss: 1.2950, Accuracy: 2730/5000 (55%)\n",
      "[epoch 6] loss: 1.0864932\n",
      "Test set: Average loss: 1.2330, Accuracy: 2831/5000 (57%)\n",
      "[epoch 7] loss: 1.0225364\n",
      "Test set: Average loss: 1.2421, Accuracy: 2830/5000 (57%)\n",
      "[epoch 8] loss: 0.9378305\n",
      "Test set: Average loss: 1.2587, Accuracy: 2807/5000 (56%)\n",
      "[epoch 9] loss: 0.8439382\n",
      "Test set: Average loss: 1.2539, Accuracy: 2898/5000 (58%)\n",
      "[epoch 10] loss: 0.7465671\n",
      "Test set: Average loss: 1.2734, Accuracy: 2912/5000 (58%)\n",
      "[epoch 11] loss: 0.6408519\n",
      "Test set: Average loss: 1.3063, Accuracy: 2903/5000 (58%)\n",
      "[epoch 12] loss: 0.5272587\n",
      "Test set: Average loss: 1.4173, Accuracy: 2824/5000 (56%)\n",
      "[epoch 13] loss: 0.3944142\n",
      "Test set: Average loss: 1.4451, Accuracy: 2862/5000 (57%)\n",
      "[epoch 14] loss: 0.2927797\n",
      "Test set: Average loss: 1.4891, Accuracy: 2855/5000 (57%)\n",
      "[epoch 15] loss: 0.1956288\n",
      "Test set: Average loss: 1.5464, Accuracy: 2901/5000 (58%)\n",
      "[epoch 16] loss: 0.1149280\n",
      "Test set: Average loss: 1.6621, Accuracy: 2878/5000 (58%)\n",
      "[epoch 17] loss: 0.0687492\n",
      "Test set: Average loss: 1.7672, Accuracy: 2896/5000 (58%)\n",
      "[epoch 18] loss: 0.0336796\n",
      "Test set: Average loss: 1.8035, Accuracy: 2929/5000 (59%)\n",
      "[epoch 19] loss: 0.0119023\n",
      "Test set: Average loss: 1.8614, Accuracy: 2956/5000 (59%)\n",
      "[epoch 20] loss: 0.0050065\n",
      "Test set: Average loss: 1.9321, Accuracy: 2968/5000 (59%)\n",
      "[epoch 21] loss: 0.0032456\n",
      "Test set: Average loss: 1.9705, Accuracy: 2970/5000 (59%)\n",
      "[epoch 22] loss: 0.0024139\n",
      "Test set: Average loss: 2.0183, Accuracy: 2958/5000 (59%)\n",
      "[epoch 23] loss: 0.0018402\n",
      "Test set: Average loss: 2.0663, Accuracy: 2954/5000 (59%)\n",
      "[epoch 24] loss: 0.0014164\n",
      "Test set: Average loss: 2.1112, Accuracy: 2972/5000 (59%)\n",
      "[epoch 25] loss: 0.0010901\n",
      "Test set: Average loss: 2.1635, Accuracy: 2960/5000 (59%)\n",
      "[epoch 26] loss: 0.0008411\n",
      "Test set: Average loss: 2.2110, Accuracy: 2980/5000 (60%)\n",
      "[epoch 27] loss: 0.0006466\n",
      "Test set: Average loss: 2.2539, Accuracy: 2983/5000 (60%)\n",
      "[epoch 28] loss: 0.0004991\n",
      "Test set: Average loss: 2.3054, Accuracy: 2962/5000 (59%)\n",
      "[epoch 29] loss: 0.0003804\n",
      "Test set: Average loss: 2.3576, Accuracy: 2970/5000 (59%)\n",
      "[epoch 30] loss: 0.0002922\n",
      "Test set: Average loss: 2.4050, Accuracy: 2967/5000 (59%)\n",
      "[epoch 31] loss: 0.0002232\n",
      "Test set: Average loss: 2.4605, Accuracy: 2980/5000 (60%)\n",
      "[epoch 32] loss: 0.0001709\n",
      "Test set: Average loss: 2.5112, Accuracy: 2972/5000 (59%)\n",
      "[epoch 33] loss: 0.0001310\n",
      "Test set: Average loss: 2.5546, Accuracy: 2967/5000 (59%)\n",
      "[epoch 34] loss: 0.0000997\n",
      "Test set: Average loss: 2.6037, Accuracy: 2969/5000 (59%)\n",
      "[epoch 35] loss: 0.0000760\n",
      "Test set: Average loss: 2.6609, Accuracy: 2979/5000 (60%)\n",
      "[epoch 36] loss: 0.0000583\n",
      "Test set: Average loss: 2.7192, Accuracy: 2981/5000 (60%)\n",
      "[epoch 37] loss: 0.0000446\n",
      "Test set: Average loss: 2.7629, Accuracy: 2986/5000 (60%)\n",
      "[epoch 38] loss: 0.0000336\n",
      "Test set: Average loss: 2.8255, Accuracy: 2973/5000 (59%)\n",
      "[epoch 39] loss: 0.0000256\n",
      "Test set: Average loss: 2.8628, Accuracy: 2983/5000 (60%)\n",
      "[epoch 40] loss: 0.0000195\n",
      "Test set: Average loss: 2.9145, Accuracy: 2984/5000 (60%)\n",
      "[epoch 41] loss: 0.0000148\n",
      "Test set: Average loss: 2.9743, Accuracy: 2984/5000 (60%)\n",
      "[epoch 42] loss: 0.0000114\n",
      "Test set: Average loss: 3.0266, Accuracy: 2978/5000 (60%)\n",
      "[epoch 43] loss: 0.0000086\n",
      "Test set: Average loss: 3.0664, Accuracy: 2974/5000 (59%)\n",
      "[epoch 44] loss: 0.0000066\n",
      "Test set: Average loss: 3.1188, Accuracy: 2986/5000 (60%)\n",
      "[epoch 45] loss: 0.0000050\n",
      "Test set: Average loss: 3.1675, Accuracy: 2981/5000 (60%)\n",
      "[epoch 46] loss: 0.0000038\n",
      "Test set: Average loss: 3.2204, Accuracy: 2978/5000 (60%)\n",
      "[epoch 47] loss: 0.0000029\n",
      "Test set: Average loss: 3.2657, Accuracy: 2977/5000 (60%)\n",
      "[epoch 48] loss: 0.0000022\n",
      "Test set: Average loss: 3.3218, Accuracy: 2981/5000 (60%)\n",
      "[epoch 49] loss: 0.0000017\n",
      "Test set: Average loss: 3.3589, Accuracy: 2978/5000 (60%)\n",
      "[epoch 50] loss: 0.0000012\n",
      "Test set: Average loss: 3.4001, Accuracy: 2977/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1188, Accuracy: 2986/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 3.1441, Accuracy: 5966/10000 (60%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3047, Accuracy: 526/5000 (11%)\n",
      "[epoch 1] loss: 1.5957906\n",
      "Test set: Average loss: 1.3975, Accuracy: 2475/5000 (50%)\n",
      "[epoch 2] loss: 1.3742959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3119, Accuracy: 2601/5000 (52%)\n",
      "[epoch 3] loss: 1.2684720\n",
      "Test set: Average loss: 1.2863, Accuracy: 2708/5000 (54%)\n",
      "[epoch 4] loss: 1.1902083\n",
      "Test set: Average loss: 1.2704, Accuracy: 2759/5000 (55%)\n",
      "[epoch 5] loss: 1.1264745\n",
      "Test set: Average loss: 1.2100, Accuracy: 2849/5000 (57%)\n",
      "[epoch 6] loss: 1.0566559\n",
      "Test set: Average loss: 1.2718, Accuracy: 2806/5000 (56%)\n",
      "[epoch 7] loss: 0.9887176\n",
      "Test set: Average loss: 1.2259, Accuracy: 2867/5000 (57%)\n",
      "[epoch 8] loss: 0.9220954\n",
      "Test set: Average loss: 1.2044, Accuracy: 2906/5000 (58%)\n",
      "[epoch 9] loss: 0.8287748\n",
      "Test set: Average loss: 1.2061, Accuracy: 2967/5000 (59%)\n",
      "[epoch 10] loss: 0.7577380\n",
      "Test set: Average loss: 1.1891, Accuracy: 3020/5000 (60%)\n",
      "[epoch 11] loss: 0.6620300\n",
      "Test set: Average loss: 1.2777, Accuracy: 2938/5000 (59%)\n",
      "[epoch 12] loss: 0.5676238\n",
      "Test set: Average loss: 1.2785, Accuracy: 2996/5000 (60%)\n",
      "[epoch 13] loss: 0.4513412\n",
      "Test set: Average loss: 1.3611, Accuracy: 3009/5000 (60%)\n",
      "[epoch 14] loss: 0.3394680\n",
      "Test set: Average loss: 1.3635, Accuracy: 2944/5000 (59%)\n",
      "[epoch 15] loss: 0.2511924\n",
      "Test set: Average loss: 1.4813, Accuracy: 2923/5000 (58%)\n",
      "[epoch 16] loss: 0.1792935\n",
      "Test set: Average loss: 1.5889, Accuracy: 2903/5000 (58%)\n",
      "[epoch 17] loss: 0.1562236\n",
      "Test set: Average loss: 1.7315, Accuracy: 2899/5000 (58%)\n",
      "[epoch 18] loss: 0.1265878\n",
      "Test set: Average loss: 1.7538, Accuracy: 2898/5000 (58%)\n",
      "[epoch 19] loss: 0.0634403\n",
      "Test set: Average loss: 1.7919, Accuracy: 2957/5000 (59%)\n",
      "[epoch 20] loss: 0.0734602\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0726, Accuracy: 2819/5000 (56%)\n",
      "[epoch 21] loss: 0.0544004\n",
      "Test set: Average loss: 1.8268, Accuracy: 2995/5000 (60%)\n",
      "[epoch 22] loss: 0.0158030\n",
      "Test set: Average loss: 1.8257, Accuracy: 3035/5000 (61%)\n",
      "[epoch 23] loss: 0.0106511\n",
      "Test set: Average loss: 1.8389, Accuracy: 3034/5000 (61%)\n",
      "[epoch 24] loss: 0.0080986\n",
      "Test set: Average loss: 1.8489, Accuracy: 3046/5000 (61%)\n",
      "[epoch 25] loss: 0.0064041\n",
      "Test set: Average loss: 1.8650, Accuracy: 3044/5000 (61%)\n",
      "[epoch 26] loss: 0.0051604\n",
      "Test set: Average loss: 1.8831, Accuracy: 3049/5000 (61%)\n",
      "[epoch 27] loss: 0.0041876\n",
      "Test set: Average loss: 1.9019, Accuracy: 3052/5000 (61%)\n",
      "[epoch 28] loss: 0.0034083\n",
      "Test set: Average loss: 1.9189, Accuracy: 3053/5000 (61%)\n",
      "[epoch 29] loss: 0.0027648\n",
      "Test set: Average loss: 1.9410, Accuracy: 3055/5000 (61%)\n",
      "[epoch 30] loss: 0.0022503\n",
      "Test set: Average loss: 1.9665, Accuracy: 3050/5000 (61%)\n",
      "[epoch 31] loss: 0.0018157\n",
      "Test set: Average loss: 1.9944, Accuracy: 3047/5000 (61%)\n",
      "[epoch 32] loss: 0.0014558\n",
      "Test set: Average loss: 2.0241, Accuracy: 3032/5000 (61%)\n",
      "[epoch 33] loss: 0.0011640\n",
      "Test set: Average loss: 2.0593, Accuracy: 3045/5000 (61%)\n",
      "[epoch 34] loss: 0.0009220\n",
      "Test set: Average loss: 2.0862, Accuracy: 3042/5000 (61%)\n",
      "[epoch 35] loss: 0.0007273\n",
      "Test set: Average loss: 2.1250, Accuracy: 3059/5000 (61%)\n",
      "[epoch 36] loss: 0.0005696\n",
      "Test set: Average loss: 2.1598, Accuracy: 3055/5000 (61%)\n",
      "[epoch 37] loss: 0.0004457\n",
      "Test set: Average loss: 2.1974, Accuracy: 3056/5000 (61%)\n",
      "[epoch 38] loss: 0.0003461\n",
      "Test set: Average loss: 2.2379, Accuracy: 3049/5000 (61%)\n",
      "[epoch 39] loss: 0.0002673\n",
      "Test set: Average loss: 2.2774, Accuracy: 3055/5000 (61%)\n",
      "[epoch 40] loss: 0.0002054\n",
      "Test set: Average loss: 2.3233, Accuracy: 3057/5000 (61%)\n",
      "[epoch 41] loss: 0.0001581\n",
      "Test set: Average loss: 2.3628, Accuracy: 3061/5000 (61%)\n",
      "[epoch 42] loss: 0.0001214\n",
      "Test set: Average loss: 2.4063, Accuracy: 3064/5000 (61%)\n",
      "[epoch 43] loss: 0.0000926\n",
      "Test set: Average loss: 2.4504, Accuracy: 3061/5000 (61%)\n",
      "[epoch 44] loss: 0.0000704\n",
      "Test set: Average loss: 2.4944, Accuracy: 3077/5000 (62%)\n",
      "[epoch 45] loss: 0.0000536\n",
      "Test set: Average loss: 2.5354, Accuracy: 3052/5000 (61%)\n",
      "[epoch 46] loss: 0.0000406\n",
      "Test set: Average loss: 2.5851, Accuracy: 3066/5000 (61%)\n",
      "[epoch 47] loss: 0.0000308\n",
      "Test set: Average loss: 2.6284, Accuracy: 3070/5000 (61%)\n",
      "[epoch 48] loss: 0.0000232\n",
      "Test set: Average loss: 2.6733, Accuracy: 3073/5000 (61%)\n",
      "[epoch 49] loss: 0.0000176\n",
      "Test set: Average loss: 2.7235, Accuracy: 3081/5000 (62%)\n",
      "[epoch 50] loss: 0.0000133\n",
      "Test set: Average loss: 2.7685, Accuracy: 3077/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7235, Accuracy: 3081/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.7606, Accuracy: 6124/10000 (61%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3049, Accuracy: 509/5000 (10%)\n",
      "[epoch 1] loss: 1.5631658\n",
      "Test set: Average loss: 1.4159, Accuracy: 2430/5000 (49%)\n",
      "[epoch 2] loss: 1.3532538\n",
      "Test set: Average loss: 1.4278, Accuracy: 2484/5000 (50%)\n",
      "[epoch 3] loss: 1.2475030\n",
      "Test set: Average loss: 1.3176, Accuracy: 2677/5000 (54%)\n",
      "[epoch 4] loss: 1.1757895\n",
      "Test set: Average loss: 1.2721, Accuracy: 2742/5000 (55%)\n",
      "[epoch 5] loss: 1.1126093\n",
      "Test set: Average loss: 1.2763, Accuracy: 2708/5000 (54%)\n",
      "[epoch 6] loss: 1.0446391\n",
      "Test set: Average loss: 1.2788, Accuracy: 2763/5000 (55%)\n",
      "[epoch 7] loss: 0.9571290\n",
      "Test set: Average loss: 1.2620, Accuracy: 2835/5000 (57%)\n",
      "[epoch 8] loss: 0.8800007\n",
      "Test set: Average loss: 1.2384, Accuracy: 2910/5000 (58%)\n",
      "[epoch 9] loss: 0.7798103\n",
      "Test set: Average loss: 1.3055, Accuracy: 2861/5000 (57%)\n",
      "[epoch 10] loss: 0.6704192\n",
      "Test set: Average loss: 1.2646, Accuracy: 2920/5000 (58%)\n",
      "[epoch 11] loss: 0.5591422\n",
      "Test set: Average loss: 1.3461, Accuracy: 2875/5000 (58%)\n",
      "[epoch 12] loss: 0.4319756\n",
      "Test set: Average loss: 1.4211, Accuracy: 2912/5000 (58%)\n",
      "[epoch 13] loss: 0.3177229\n",
      "Test set: Average loss: 1.4566, Accuracy: 2929/5000 (59%)\n",
      "[epoch 14] loss: 0.2141646\n",
      "Test set: Average loss: 1.5753, Accuracy: 2911/5000 (58%)\n",
      "[epoch 15] loss: 0.1484555\n",
      "Test set: Average loss: 1.6897, Accuracy: 2920/5000 (58%)\n",
      "[epoch 16] loss: 0.1007052\n",
      "Test set: Average loss: 1.8109, Accuracy: 2824/5000 (56%)\n",
      "[epoch 17] loss: 0.1196513\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9896, Accuracy: 2826/5000 (57%)\n",
      "[epoch 18] loss: 0.0548383\n",
      "Test set: Average loss: 1.8177, Accuracy: 2945/5000 (59%)\n",
      "[epoch 19] loss: 0.0194797\n",
      "Test set: Average loss: 1.8103, Accuracy: 2953/5000 (59%)\n",
      "[epoch 20] loss: 0.0135304\n",
      "Test set: Average loss: 1.8238, Accuracy: 2961/5000 (59%)\n",
      "[epoch 21] loss: 0.0104580\n",
      "Test set: Average loss: 1.8386, Accuracy: 2970/5000 (59%)\n",
      "[epoch 22] loss: 0.0083355\n",
      "Test set: Average loss: 1.8535, Accuracy: 2962/5000 (59%)\n",
      "[epoch 23] loss: 0.0067374\n",
      "Test set: Average loss: 1.8772, Accuracy: 2955/5000 (59%)\n",
      "[epoch 24] loss: 0.0054463\n",
      "Test set: Average loss: 1.9044, Accuracy: 2987/5000 (60%)\n",
      "[epoch 25] loss: 0.0044183\n",
      "Test set: Average loss: 1.9229, Accuracy: 2990/5000 (60%)\n",
      "[epoch 26] loss: 0.0035590\n",
      "Test set: Average loss: 1.9498, Accuracy: 2990/5000 (60%)\n",
      "[epoch 27] loss: 0.0028524\n",
      "Test set: Average loss: 1.9828, Accuracy: 2985/5000 (60%)\n",
      "[epoch 28] loss: 0.0022792\n",
      "Test set: Average loss: 2.0157, Accuracy: 2999/5000 (60%)\n",
      "[epoch 29] loss: 0.0017973\n",
      "Test set: Average loss: 2.0503, Accuracy: 2994/5000 (60%)\n",
      "[epoch 30] loss: 0.0014184\n",
      "Test set: Average loss: 2.0880, Accuracy: 3008/5000 (60%)\n",
      "[epoch 31] loss: 0.0011088\n",
      "Test set: Average loss: 2.1268, Accuracy: 3013/5000 (60%)\n",
      "[epoch 32] loss: 0.0008631\n",
      "Test set: Average loss: 2.1763, Accuracy: 3004/5000 (60%)\n",
      "[epoch 33] loss: 0.0006665\n",
      "Test set: Average loss: 2.2107, Accuracy: 3009/5000 (60%)\n",
      "[epoch 34] loss: 0.0005127\n",
      "Test set: Average loss: 2.2576, Accuracy: 3008/5000 (60%)\n",
      "[epoch 35] loss: 0.0003926\n",
      "Test set: Average loss: 2.2982, Accuracy: 3009/5000 (60%)\n",
      "[epoch 36] loss: 0.0003000\n",
      "Test set: Average loss: 2.3519, Accuracy: 3007/5000 (60%)\n",
      "[epoch 37] loss: 0.0002286\n",
      "Test set: Average loss: 2.3984, Accuracy: 3018/5000 (60%)\n",
      "[epoch 38] loss: 0.0001730\n",
      "Test set: Average loss: 2.4365, Accuracy: 3014/5000 (60%)\n",
      "[epoch 39] loss: 0.0001309\n",
      "Test set: Average loss: 2.4931, Accuracy: 3014/5000 (60%)\n",
      "[epoch 40] loss: 0.0000986\n",
      "Test set: Average loss: 2.5423, Accuracy: 3032/5000 (61%)\n",
      "[epoch 41] loss: 0.0000743\n",
      "Test set: Average loss: 2.5938, Accuracy: 3029/5000 (61%)\n",
      "[epoch 42] loss: 0.0000557\n",
      "Test set: Average loss: 2.6512, Accuracy: 3033/5000 (61%)\n",
      "[epoch 43] loss: 0.0000419\n",
      "Test set: Average loss: 2.7002, Accuracy: 3025/5000 (60%)\n",
      "[epoch 44] loss: 0.0000313\n",
      "Test set: Average loss: 2.7501, Accuracy: 3027/5000 (61%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] loss: 0.0000234\n",
      "Test set: Average loss: 2.8157, Accuracy: 3022/5000 (60%)\n",
      "[epoch 46] loss: 0.0000174\n",
      "Test set: Average loss: 2.8593, Accuracy: 3026/5000 (61%)\n",
      "[epoch 47] loss: 0.0000130\n",
      "Test set: Average loss: 2.9201, Accuracy: 3022/5000 (60%)\n",
      "[epoch 48] loss: 0.0000097\n",
      "Test set: Average loss: 2.9619, Accuracy: 3021/5000 (60%)\n",
      "[epoch 49] loss: 0.0000072\n",
      "Test set: Average loss: 3.0160, Accuracy: 3023/5000 (60%)\n",
      "[epoch 50] loss: 0.0000053\n",
      "Test set: Average loss: 3.0718, Accuracy: 3030/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6512, Accuracy: 3033/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.6212, Accuracy: 6125/10000 (61%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3043, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 1.5704210\n",
      "Test set: Average loss: 1.4326, Accuracy: 2382/5000 (48%)\n",
      "[epoch 2] loss: 1.3357375\n",
      "Test set: Average loss: 1.3258, Accuracy: 2624/5000 (52%)\n",
      "[epoch 3] loss: 1.2357960\n",
      "Test set: Average loss: 1.2653, Accuracy: 2719/5000 (54%)\n",
      "[epoch 4] loss: 1.1594270\n",
      "Test set: Average loss: 1.2378, Accuracy: 2784/5000 (56%)\n",
      "[epoch 5] loss: 1.0885739\n",
      "Test set: Average loss: 1.2337, Accuracy: 2851/5000 (57%)\n",
      "[epoch 6] loss: 1.0213137\n",
      "Test set: Average loss: 1.2727, Accuracy: 2777/5000 (56%)\n",
      "[epoch 7] loss: 0.9382917\n",
      "Test set: Average loss: 1.1950, Accuracy: 2915/5000 (58%)\n",
      "[epoch 8] loss: 0.8733762\n",
      "Test set: Average loss: 1.2869, Accuracy: 2879/5000 (58%)\n",
      "[epoch 9] loss: 0.7800315\n",
      "Test set: Average loss: 1.2029, Accuracy: 2971/5000 (59%)\n",
      "[epoch 10] loss: 0.6826543\n",
      "Test set: Average loss: 1.2275, Accuracy: 2974/5000 (59%)\n",
      "[epoch 11] loss: 0.5729022\n",
      "Test set: Average loss: 1.3641, Accuracy: 2899/5000 (58%)\n",
      "[epoch 12] loss: 0.4753116\n",
      "Test set: Average loss: 1.3606, Accuracy: 2901/5000 (58%)\n",
      "[epoch 13] loss: 0.3488714\n",
      "Test set: Average loss: 1.3884, Accuracy: 2978/5000 (60%)\n",
      "[epoch 14] loss: 0.2530186\n",
      "Test set: Average loss: 1.5225, Accuracy: 2940/5000 (59%)\n",
      "[epoch 15] loss: 0.1576920\n",
      "Test set: Average loss: 1.5432, Accuracy: 2955/5000 (59%)\n",
      "[epoch 16] loss: 0.1129890\n",
      "Test set: Average loss: 1.6688, Accuracy: 2913/5000 (58%)\n",
      "[epoch 17] loss: 0.0943754\n",
      "Test set: Average loss: 1.8336, Accuracy: 2898/5000 (58%)\n",
      "[epoch 18] loss: 0.1462782\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8486, Accuracy: 2878/5000 (58%)\n",
      "[epoch 19] loss: 0.0554528\n",
      "Test set: Average loss: 1.7427, Accuracy: 2950/5000 (59%)\n",
      "[epoch 20] loss: 0.0220755\n",
      "Test set: Average loss: 1.7434, Accuracy: 2953/5000 (59%)\n",
      "[epoch 21] loss: 0.0152991\n",
      "Test set: Average loss: 1.7571, Accuracy: 2983/5000 (60%)\n",
      "[epoch 22] loss: 0.0116340\n",
      "Test set: Average loss: 1.7721, Accuracy: 2975/5000 (60%)\n",
      "[epoch 23] loss: 0.0091910\n",
      "Test set: Average loss: 1.7894, Accuracy: 2996/5000 (60%)\n",
      "[epoch 24] loss: 0.0073578\n",
      "Test set: Average loss: 1.8123, Accuracy: 2995/5000 (60%)\n",
      "[epoch 25] loss: 0.0059055\n",
      "Test set: Average loss: 1.8348, Accuracy: 3005/5000 (60%)\n",
      "[epoch 26] loss: 0.0047623\n",
      "Test set: Average loss: 1.8563, Accuracy: 3016/5000 (60%)\n",
      "[epoch 27] loss: 0.0038277\n",
      "Test set: Average loss: 1.8834, Accuracy: 3024/5000 (60%)\n",
      "[epoch 28] loss: 0.0030634\n",
      "Test set: Average loss: 1.9076, Accuracy: 3019/5000 (60%)\n",
      "[epoch 29] loss: 0.0024396\n",
      "Test set: Average loss: 1.9402, Accuracy: 3042/5000 (61%)\n",
      "[epoch 30] loss: 0.0019384\n",
      "Test set: Average loss: 1.9699, Accuracy: 3040/5000 (61%)\n",
      "[epoch 31] loss: 0.0015310\n",
      "Test set: Average loss: 2.0058, Accuracy: 3059/5000 (61%)\n",
      "[epoch 32] loss: 0.0012008\n",
      "Test set: Average loss: 2.0417, Accuracy: 3053/5000 (61%)\n",
      "[epoch 33] loss: 0.0009380\n",
      "Test set: Average loss: 2.0802, Accuracy: 3055/5000 (61%)\n",
      "[epoch 34] loss: 0.0007301\n",
      "Test set: Average loss: 2.1175, Accuracy: 3054/5000 (61%)\n",
      "[epoch 35] loss: 0.0005633\n",
      "Test set: Average loss: 2.1526, Accuracy: 3068/5000 (61%)\n",
      "[epoch 36] loss: 0.0004344\n",
      "Test set: Average loss: 2.1960, Accuracy: 3073/5000 (61%)\n",
      "[epoch 37] loss: 0.0003337\n",
      "Test set: Average loss: 2.2402, Accuracy: 3069/5000 (61%)\n",
      "[epoch 38] loss: 0.0002563\n",
      "Test set: Average loss: 2.2834, Accuracy: 3080/5000 (62%)\n",
      "[epoch 39] loss: 0.0001960\n",
      "Test set: Average loss: 2.3240, Accuracy: 3062/5000 (61%)\n",
      "[epoch 40] loss: 0.0001488\n",
      "Test set: Average loss: 2.3685, Accuracy: 3064/5000 (61%)\n",
      "[epoch 41] loss: 0.0001129\n",
      "Test set: Average loss: 2.4052, Accuracy: 3076/5000 (62%)\n",
      "[epoch 42] loss: 0.0000858\n",
      "Test set: Average loss: 2.4578, Accuracy: 3060/5000 (61%)\n",
      "[epoch 43] loss: 0.0000650\n",
      "Test set: Average loss: 2.5013, Accuracy: 3058/5000 (61%)\n",
      "[epoch 44] loss: 0.0000491\n",
      "Test set: Average loss: 2.5565, Accuracy: 3063/5000 (61%)\n",
      "[epoch 45] loss: 0.0000369\n",
      "Test set: Average loss: 2.5959, Accuracy: 3070/5000 (61%)\n",
      "[epoch 46] loss: 0.0000277\n",
      "Test set: Average loss: 2.6469, Accuracy: 3070/5000 (61%)\n",
      "[epoch 47] loss: 0.0000209\n",
      "Test set: Average loss: 2.6976, Accuracy: 3070/5000 (61%)\n",
      "[epoch 48] loss: 0.0000156\n",
      "Test set: Average loss: 2.7430, Accuracy: 3061/5000 (61%)\n",
      "[epoch 49] loss: 0.0000118\n",
      "Test set: Average loss: 2.7896, Accuracy: 3063/5000 (61%)\n",
      "[epoch 50] loss: 0.0000088\n",
      "Test set: Average loss: 2.8431, Accuracy: 3049/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2834, Accuracy: 3080/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.3735, Accuracy: 6122/10000 (61%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 412/5000 (8%)\n",
      "[epoch 1] loss: 1.5453313\n",
      "Test set: Average loss: 1.4711, Accuracy: 2359/5000 (47%)\n",
      "[epoch 2] loss: 1.3273699\n",
      "Test set: Average loss: 1.2992, Accuracy: 2640/5000 (53%)\n",
      "[epoch 3] loss: 1.2306537\n",
      "Test set: Average loss: 1.2692, Accuracy: 2763/5000 (55%)\n",
      "[epoch 4] loss: 1.1513327\n",
      "Test set: Average loss: 1.3001, Accuracy: 2698/5000 (54%)\n",
      "[epoch 5] loss: 1.0797375\n",
      "Test set: Average loss: 1.2243, Accuracy: 2829/5000 (57%)\n",
      "[epoch 6] loss: 1.0113247\n",
      "Test set: Average loss: 1.1669, Accuracy: 2988/5000 (60%)\n",
      "[epoch 7] loss: 0.9373114\n",
      "Test set: Average loss: 1.2087, Accuracy: 2967/5000 (59%)\n",
      "[epoch 8] loss: 0.8641795\n",
      "Test set: Average loss: 1.1974, Accuracy: 3007/5000 (60%)\n",
      "[epoch 9] loss: 0.7761641\n",
      "Test set: Average loss: 1.2306, Accuracy: 2989/5000 (60%)\n",
      "[epoch 10] loss: 0.6847516\n",
      "Test set: Average loss: 1.2003, Accuracy: 3023/5000 (60%)\n",
      "[epoch 11] loss: 0.5807163\n",
      "Test set: Average loss: 1.2894, Accuracy: 2990/5000 (60%)\n",
      "[epoch 12] loss: 0.4695424\n",
      "Test set: Average loss: 1.3146, Accuracy: 3002/5000 (60%)\n",
      "[epoch 13] loss: 0.3574169\n",
      "Test set: Average loss: 1.4053, Accuracy: 3033/5000 (61%)\n",
      "[epoch 14] loss: 0.2703980\n",
      "Test set: Average loss: 1.4912, Accuracy: 3025/5000 (60%)\n",
      "[epoch 15] loss: 0.1896608\n",
      "Test set: Average loss: 1.5982, Accuracy: 3005/5000 (60%)\n",
      "[epoch 16] loss: 0.1605694\n",
      "Test set: Average loss: 1.7089, Accuracy: 2999/5000 (60%)\n",
      "[epoch 17] loss: 0.1396077\n",
      "Test set: Average loss: 1.7705, Accuracy: 2958/5000 (59%)\n",
      "[epoch 18] loss: 0.1327299\n",
      "Test set: Average loss: 1.8839, Accuracy: 2940/5000 (59%)\n",
      "[epoch 19] loss: 0.1409581\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9765, Accuracy: 2890/5000 (58%)\n",
      "[epoch 20] loss: 0.0494909\n",
      "Test set: Average loss: 1.8299, Accuracy: 3042/5000 (61%)\n",
      "[epoch 21] loss: 0.0174799\n",
      "Test set: Average loss: 1.8314, Accuracy: 3060/5000 (61%)\n",
      "[epoch 22] loss: 0.0116734\n",
      "Test set: Average loss: 1.8377, Accuracy: 3055/5000 (61%)\n",
      "[epoch 23] loss: 0.0087437\n",
      "Test set: Average loss: 1.8534, Accuracy: 3073/5000 (61%)\n",
      "[epoch 24] loss: 0.0067361\n",
      "Test set: Average loss: 1.8737, Accuracy: 3083/5000 (62%)\n",
      "[epoch 25] loss: 0.0052347\n",
      "Test set: Average loss: 1.8898, Accuracy: 3094/5000 (62%)\n",
      "[epoch 26] loss: 0.0040503\n",
      "Test set: Average loss: 1.9135, Accuracy: 3084/5000 (62%)\n",
      "[epoch 27] loss: 0.0031381\n",
      "Test set: Average loss: 1.9408, Accuracy: 3091/5000 (62%)\n",
      "[epoch 28] loss: 0.0024074\n",
      "Test set: Average loss: 1.9773, Accuracy: 3094/5000 (62%)\n",
      "[epoch 29] loss: 0.0018405\n",
      "Test set: Average loss: 2.0111, Accuracy: 3090/5000 (62%)\n",
      "[epoch 30] loss: 0.0013930\n",
      "Test set: Average loss: 2.0514, Accuracy: 3101/5000 (62%)\n",
      "[epoch 31] loss: 0.0010491\n",
      "Test set: Average loss: 2.0879, Accuracy: 3090/5000 (62%)\n",
      "[epoch 32] loss: 0.0007800\n",
      "Test set: Average loss: 2.1305, Accuracy: 3089/5000 (62%)\n",
      "[epoch 33] loss: 0.0005769\n",
      "Test set: Average loss: 2.1778, Accuracy: 3092/5000 (62%)\n",
      "[epoch 34] loss: 0.0004265\n",
      "Test set: Average loss: 2.2258, Accuracy: 3093/5000 (62%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0003130\n",
      "Test set: Average loss: 2.2741, Accuracy: 3100/5000 (62%)\n",
      "[epoch 36] loss: 0.0002307\n",
      "Test set: Average loss: 2.3267, Accuracy: 3089/5000 (62%)\n",
      "[epoch 37] loss: 0.0001666\n",
      "Test set: Average loss: 2.3713, Accuracy: 3098/5000 (62%)\n",
      "[epoch 38] loss: 0.0001199\n",
      "Test set: Average loss: 2.4298, Accuracy: 3108/5000 (62%)\n",
      "[epoch 39] loss: 0.0000870\n",
      "Test set: Average loss: 2.4788, Accuracy: 3088/5000 (62%)\n",
      "[epoch 40] loss: 0.0000626\n",
      "Test set: Average loss: 2.5332, Accuracy: 3104/5000 (62%)\n",
      "[epoch 41] loss: 0.0000449\n",
      "Test set: Average loss: 2.5959, Accuracy: 3101/5000 (62%)\n",
      "[epoch 42] loss: 0.0000324\n",
      "Test set: Average loss: 2.6473, Accuracy: 3103/5000 (62%)\n",
      "[epoch 43] loss: 0.0000230\n",
      "Test set: Average loss: 2.7015, Accuracy: 3105/5000 (62%)\n",
      "[epoch 44] loss: 0.0000164\n",
      "Test set: Average loss: 2.7632, Accuracy: 3108/5000 (62%)\n",
      "[epoch 45] loss: 0.0000117\n",
      "Test set: Average loss: 2.8261, Accuracy: 3106/5000 (62%)\n",
      "[epoch 46] loss: 0.0000083\n",
      "Test set: Average loss: 2.8775, Accuracy: 3111/5000 (62%)\n",
      "[epoch 47] loss: 0.0000059\n",
      "Test set: Average loss: 2.9351, Accuracy: 3102/5000 (62%)\n",
      "[epoch 48] loss: 0.0000808\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.0614, Accuracy: 3023/5000 (60%)\n",
      "[epoch 49] loss: 0.0004530\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.0021, Accuracy: 3074/5000 (61%)\n",
      "[epoch 50] loss: 0.0000560\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.0010, Accuracy: 3077/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8775, Accuracy: 3111/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.8499, Accuracy: 6281/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 459/5000 (9%)\n",
      "[epoch 1] loss: 1.5353126\n",
      "Test set: Average loss: 1.3500, Accuracy: 2553/5000 (51%)\n",
      "[epoch 2] loss: 1.3066899\n",
      "Test set: Average loss: 1.2762, Accuracy: 2715/5000 (54%)\n",
      "[epoch 3] loss: 1.1960558\n",
      "Test set: Average loss: 1.2602, Accuracy: 2756/5000 (55%)\n",
      "[epoch 4] loss: 1.1043306\n",
      "Test set: Average loss: 1.2586, Accuracy: 2771/5000 (55%)\n",
      "[epoch 5] loss: 1.0283861\n",
      "Test set: Average loss: 1.1629, Accuracy: 2996/5000 (60%)\n",
      "[epoch 6] loss: 0.9522905\n",
      "Test set: Average loss: 1.1015, Accuracy: 3037/5000 (61%)\n",
      "[epoch 7] loss: 0.8696255\n",
      "Test set: Average loss: 1.1502, Accuracy: 3075/5000 (62%)\n",
      "[epoch 8] loss: 0.7793963\n",
      "Test set: Average loss: 1.1471, Accuracy: 3047/5000 (61%)\n",
      "[epoch 9] loss: 0.6820823\n",
      "Test set: Average loss: 1.1707, Accuracy: 3059/5000 (61%)\n",
      "[epoch 10] loss: 0.5840369\n",
      "Test set: Average loss: 1.2020, Accuracy: 3055/5000 (61%)\n",
      "[epoch 11] loss: 0.4674490\n",
      "Test set: Average loss: 1.2216, Accuracy: 3152/5000 (63%)\n",
      "[epoch 12] loss: 0.3578127\n",
      "Test set: Average loss: 1.2862, Accuracy: 3127/5000 (63%)\n",
      "[epoch 13] loss: 0.2719081\n",
      "Test set: Average loss: 1.4010, Accuracy: 3095/5000 (62%)\n",
      "[epoch 14] loss: 0.1794298\n",
      "Test set: Average loss: 1.4863, Accuracy: 3112/5000 (62%)\n",
      "[epoch 15] loss: 0.1375514\n",
      "Test set: Average loss: 1.5505, Accuracy: 3089/5000 (62%)\n",
      "[epoch 16] loss: 0.1700532\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6675, Accuracy: 3084/5000 (62%)\n",
      "[epoch 17] loss: 0.0643112\n",
      "Test set: Average loss: 1.5606, Accuracy: 3156/5000 (63%)\n",
      "[epoch 18] loss: 0.0251866\n",
      "Test set: Average loss: 1.5644, Accuracy: 3179/5000 (64%)\n",
      "[epoch 19] loss: 0.0168966\n",
      "Test set: Average loss: 1.5794, Accuracy: 3172/5000 (63%)\n",
      "[epoch 20] loss: 0.0125211\n",
      "Test set: Average loss: 1.5999, Accuracy: 3181/5000 (64%)\n",
      "[epoch 21] loss: 0.0095315\n",
      "Test set: Average loss: 1.6262, Accuracy: 3192/5000 (64%)\n",
      "[epoch 22] loss: 0.0073108\n",
      "Test set: Average loss: 1.6435, Accuracy: 3197/5000 (64%)\n",
      "[epoch 23] loss: 0.0055834\n",
      "Test set: Average loss: 1.6789, Accuracy: 3192/5000 (64%)\n",
      "[epoch 24] loss: 0.0042610\n",
      "Test set: Average loss: 1.7060, Accuracy: 3191/5000 (64%)\n",
      "[epoch 25] loss: 0.0032213\n",
      "Test set: Average loss: 1.7422, Accuracy: 3199/5000 (64%)\n",
      "[epoch 26] loss: 0.0024197\n",
      "Test set: Average loss: 1.7773, Accuracy: 3204/5000 (64%)\n",
      "[epoch 27] loss: 0.0018093\n",
      "Test set: Average loss: 1.8147, Accuracy: 3195/5000 (64%)\n",
      "[epoch 28] loss: 0.0013349\n",
      "Test set: Average loss: 1.8576, Accuracy: 3198/5000 (64%)\n",
      "[epoch 29] loss: 0.0009786\n",
      "Test set: Average loss: 1.8992, Accuracy: 3195/5000 (64%)\n",
      "[epoch 30] loss: 0.0007184\n",
      "Test set: Average loss: 1.9478, Accuracy: 3199/5000 (64%)\n",
      "[epoch 31] loss: 0.0005210\n",
      "Test set: Average loss: 1.9858, Accuracy: 3206/5000 (64%)\n",
      "[epoch 32] loss: 0.0003763\n",
      "Test set: Average loss: 2.0383, Accuracy: 3201/5000 (64%)\n",
      "[epoch 33] loss: 0.0002712\n",
      "Test set: Average loss: 2.0857, Accuracy: 3200/5000 (64%)\n",
      "[epoch 34] loss: 0.0001955\n",
      "Test set: Average loss: 2.1432, Accuracy: 3197/5000 (64%)\n",
      "[epoch 35] loss: 0.0001398\n",
      "Test set: Average loss: 2.1864, Accuracy: 3189/5000 (64%)\n",
      "[epoch 36] loss: 0.0000993\n",
      "Test set: Average loss: 2.2398, Accuracy: 3190/5000 (64%)\n",
      "[epoch 37] loss: 0.0000709\n",
      "Test set: Average loss: 2.2977, Accuracy: 3199/5000 (64%)\n",
      "[epoch 38] loss: 0.0000502\n",
      "Test set: Average loss: 2.3466, Accuracy: 3202/5000 (64%)\n",
      "[epoch 39] loss: 0.0000354\n",
      "Test set: Average loss: 2.3977, Accuracy: 3199/5000 (64%)\n",
      "[epoch 40] loss: 0.0000250\n",
      "Test set: Average loss: 2.4620, Accuracy: 3201/5000 (64%)\n",
      "[epoch 41] loss: 0.0000176\n",
      "Test set: Average loss: 2.5137, Accuracy: 3192/5000 (64%)\n",
      "[epoch 42] loss: 0.0000123\n",
      "Test set: Average loss: 2.5721, Accuracy: 3204/5000 (64%)\n",
      "[epoch 43] loss: 0.0000087\n",
      "Test set: Average loss: 2.6276, Accuracy: 3196/5000 (64%)\n",
      "[epoch 44] loss: 0.0000061\n",
      "Test set: Average loss: 2.6839, Accuracy: 3192/5000 (64%)\n",
      "[epoch 45] loss: 0.0000042\n",
      "Test set: Average loss: 2.7398, Accuracy: 3189/5000 (64%)\n",
      "[epoch 46] loss: 0.0000030\n",
      "Test set: Average loss: 2.7977, Accuracy: 3184/5000 (64%)\n",
      "[epoch 47] loss: 0.0000020\n",
      "Test set: Average loss: 2.8511, Accuracy: 3192/5000 (64%)\n",
      "[epoch 48] loss: 0.0000014\n",
      "Test set: Average loss: 2.8997, Accuracy: 3191/5000 (64%)\n",
      "[epoch 49] loss: 0.0000010\n",
      "Test set: Average loss: 2.9386, Accuracy: 3194/5000 (64%)\n",
      "[epoch 50] loss: 0.0000007\n",
      "Test set: Average loss: 2.9638, Accuracy: 3186/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9858, Accuracy: 3206/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.0500, Accuracy: 6460/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 455/5000 (9%)\n",
      "[epoch 1] loss: 1.5747263\n",
      "Test set: Average loss: 1.3674, Accuracy: 2507/5000 (50%)\n",
      "[epoch 2] loss: 1.3234697\n",
      "Test set: Average loss: 1.3468, Accuracy: 2603/5000 (52%)\n",
      "[epoch 3] loss: 1.2194311\n",
      "Test set: Average loss: 1.2443, Accuracy: 2772/5000 (55%)\n",
      "[epoch 4] loss: 1.1394580\n",
      "Test set: Average loss: 1.3243, Accuracy: 2618/5000 (52%)\n",
      "[epoch 5] loss: 1.0694034\n",
      "Test set: Average loss: 1.2259, Accuracy: 2789/5000 (56%)\n",
      "[epoch 6] loss: 1.0008340\n",
      "Test set: Average loss: 1.1562, Accuracy: 2993/5000 (60%)\n",
      "[epoch 7] loss: 0.9218272\n",
      "Test set: Average loss: 1.1709, Accuracy: 2968/5000 (59%)\n",
      "[epoch 8] loss: 0.8559453\n",
      "Test set: Average loss: 1.1778, Accuracy: 3008/5000 (60%)\n",
      "[epoch 9] loss: 0.7798943\n",
      "Test set: Average loss: 1.1650, Accuracy: 3016/5000 (60%)\n",
      "[epoch 10] loss: 0.6852792\n",
      "Test set: Average loss: 1.1882, Accuracy: 3069/5000 (61%)\n",
      "[epoch 11] loss: 0.5906766\n",
      "Test set: Average loss: 1.2116, Accuracy: 3067/5000 (61%)\n",
      "[epoch 12] loss: 0.4849725\n",
      "Test set: Average loss: 1.2909, Accuracy: 3038/5000 (61%)\n",
      "[epoch 13] loss: 0.3812265\n",
      "Test set: Average loss: 1.3640, Accuracy: 3060/5000 (61%)\n",
      "[epoch 14] loss: 0.2860085\n",
      "Test set: Average loss: 1.4533, Accuracy: 2968/5000 (59%)\n",
      "[epoch 15] loss: 0.2115708\n",
      "Test set: Average loss: 1.5483, Accuracy: 3025/5000 (60%)\n",
      "[epoch 16] loss: 0.1746933\n",
      "Test set: Average loss: 1.6166, Accuracy: 3015/5000 (60%)\n",
      "[epoch 17] loss: 0.1233289\n",
      "Test set: Average loss: 1.7136, Accuracy: 2995/5000 (60%)\n",
      "[epoch 18] loss: 0.1454416\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8537, Accuracy: 2946/5000 (59%)\n",
      "[epoch 19] loss: 0.0502157\n",
      "Test set: Average loss: 1.7026, Accuracy: 3064/5000 (61%)\n",
      "[epoch 20] loss: 0.0201809\n",
      "Test set: Average loss: 1.7049, Accuracy: 3083/5000 (62%)\n",
      "[epoch 21] loss: 0.0137555\n",
      "Test set: Average loss: 1.7265, Accuracy: 3093/5000 (62%)\n",
      "[epoch 22] loss: 0.0103028\n",
      "Test set: Average loss: 1.7463, Accuracy: 3107/5000 (62%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] loss: 0.0079250\n",
      "Test set: Average loss: 1.7653, Accuracy: 3110/5000 (62%)\n",
      "[epoch 24] loss: 0.0061521\n",
      "Test set: Average loss: 1.7915, Accuracy: 3106/5000 (62%)\n",
      "[epoch 25] loss: 0.0047566\n",
      "Test set: Average loss: 1.8211, Accuracy: 3119/5000 (62%)\n",
      "[epoch 26] loss: 0.0036780\n",
      "Test set: Average loss: 1.8517, Accuracy: 3117/5000 (62%)\n",
      "[epoch 27] loss: 0.0028145\n",
      "Test set: Average loss: 1.8930, Accuracy: 3119/5000 (62%)\n",
      "[epoch 28] loss: 0.0021319\n",
      "Test set: Average loss: 1.9245, Accuracy: 3104/5000 (62%)\n",
      "[epoch 29] loss: 0.0016168\n",
      "Test set: Average loss: 1.9692, Accuracy: 3117/5000 (62%)\n",
      "[epoch 30] loss: 0.0012101\n",
      "Test set: Average loss: 2.0050, Accuracy: 3142/5000 (63%)\n",
      "[epoch 31] loss: 0.0009015\n",
      "Test set: Average loss: 2.0608, Accuracy: 3128/5000 (63%)\n",
      "[epoch 32] loss: 0.0006657\n",
      "Test set: Average loss: 2.0961, Accuracy: 3128/5000 (63%)\n",
      "[epoch 33] loss: 0.0004922\n",
      "Test set: Average loss: 2.1499, Accuracy: 3126/5000 (63%)\n",
      "[epoch 34] loss: 0.0003588\n",
      "Test set: Average loss: 2.2013, Accuracy: 3137/5000 (63%)\n",
      "[epoch 35] loss: 0.0002625\n",
      "Test set: Average loss: 2.2593, Accuracy: 3125/5000 (62%)\n",
      "[epoch 36] loss: 0.0001914\n",
      "Test set: Average loss: 2.3108, Accuracy: 3132/5000 (63%)\n",
      "[epoch 37] loss: 0.0001387\n",
      "Test set: Average loss: 2.3585, Accuracy: 3130/5000 (63%)\n",
      "[epoch 38] loss: 0.0001003\n",
      "Test set: Average loss: 2.4186, Accuracy: 3121/5000 (62%)\n",
      "[epoch 39] loss: 0.0000722\n",
      "Test set: Average loss: 2.4767, Accuracy: 3119/5000 (62%)\n",
      "[epoch 40] loss: 0.0000518\n",
      "Test set: Average loss: 2.5277, Accuracy: 3131/5000 (63%)\n",
      "[epoch 41] loss: 0.0000371\n",
      "Test set: Average loss: 2.5808, Accuracy: 3134/5000 (63%)\n",
      "[epoch 42] loss: 0.0000265\n",
      "Test set: Average loss: 2.6346, Accuracy: 3122/5000 (62%)\n",
      "[epoch 43] loss: 0.0000189\n",
      "Test set: Average loss: 2.7040, Accuracy: 3124/5000 (62%)\n",
      "[epoch 44] loss: 0.0000134\n",
      "Test set: Average loss: 2.7658, Accuracy: 3121/5000 (62%)\n",
      "[epoch 45] loss: 0.0000095\n",
      "Test set: Average loss: 2.8136, Accuracy: 3125/5000 (62%)\n",
      "[epoch 46] loss: 0.0000068\n",
      "Test set: Average loss: 2.8808, Accuracy: 3128/5000 (63%)\n",
      "[epoch 47] loss: 0.0000048\n",
      "Test set: Average loss: 2.9398, Accuracy: 3121/5000 (62%)\n",
      "[epoch 48] loss: 0.0000034\n",
      "Test set: Average loss: 2.9885, Accuracy: 3128/5000 (63%)\n",
      "[epoch 49] loss: 0.0000024\n",
      "Test set: Average loss: 3.0481, Accuracy: 3122/5000 (62%)\n",
      "[epoch 50] loss: 0.0000016\n",
      "Test set: Average loss: 3.1004, Accuracy: 3113/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0050, Accuracy: 3142/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 1.9344, Accuracy: 6355/10000 (64%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3051, Accuracy: 578/5000 (12%)\n",
      "[epoch 1] loss: 1.5510121\n",
      "Test set: Average loss: 1.4407, Accuracy: 2385/5000 (48%)\n",
      "[epoch 2] loss: 1.3220795\n",
      "Test set: Average loss: 1.2863, Accuracy: 2694/5000 (54%)\n",
      "[epoch 3] loss: 1.2172789\n",
      "Test set: Average loss: 1.2357, Accuracy: 2772/5000 (55%)\n",
      "[epoch 4] loss: 1.1313222\n",
      "Test set: Average loss: 1.2194, Accuracy: 2882/5000 (58%)\n",
      "[epoch 5] loss: 1.0618076\n",
      "Test set: Average loss: 1.1794, Accuracy: 2956/5000 (59%)\n",
      "[epoch 6] loss: 0.9966878\n",
      "Test set: Average loss: 1.1810, Accuracy: 2928/5000 (59%)\n",
      "[epoch 7] loss: 0.9263173\n",
      "Test set: Average loss: 1.1324, Accuracy: 3009/5000 (60%)\n",
      "[epoch 8] loss: 0.8591998\n",
      "Test set: Average loss: 1.1059, Accuracy: 3111/5000 (62%)\n",
      "[epoch 9] loss: 0.7969250\n",
      "Test set: Average loss: 1.1035, Accuracy: 3086/5000 (62%)\n",
      "[epoch 10] loss: 0.7154749\n",
      "Test set: Average loss: 1.1927, Accuracy: 3038/5000 (61%)\n",
      "[epoch 11] loss: 0.6299327\n",
      "Test set: Average loss: 1.1992, Accuracy: 3061/5000 (61%)\n",
      "[epoch 12] loss: 0.5435776\n",
      "Test set: Average loss: 1.1872, Accuracy: 3128/5000 (63%)\n",
      "[epoch 13] loss: 0.4422247\n",
      "Test set: Average loss: 1.3014, Accuracy: 3061/5000 (61%)\n",
      "[epoch 14] loss: 0.3582634\n",
      "Test set: Average loss: 1.2993, Accuracy: 3109/5000 (62%)\n",
      "[epoch 15] loss: 0.2727810\n",
      "Test set: Average loss: 1.4044, Accuracy: 3087/5000 (62%)\n",
      "[epoch 16] loss: 0.2043205\n",
      "Test set: Average loss: 1.5164, Accuracy: 3050/5000 (61%)\n",
      "[epoch 17] loss: 0.1906748\n",
      "Test set: Average loss: 1.6344, Accuracy: 3051/5000 (61%)\n",
      "[epoch 18] loss: 0.1779421\n",
      "Test set: Average loss: 1.6837, Accuracy: 3011/5000 (60%)\n",
      "[epoch 19] loss: 0.1497564\n",
      "Test set: Average loss: 1.7821, Accuracy: 2982/5000 (60%)\n",
      "[epoch 20] loss: 0.1369799\n",
      "Test set: Average loss: 1.8237, Accuracy: 3015/5000 (60%)\n",
      "[epoch 21] loss: 0.1451119\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8635, Accuracy: 2978/5000 (60%)\n",
      "[epoch 22] loss: 0.0548209\n",
      "Test set: Average loss: 1.7706, Accuracy: 3073/5000 (61%)\n",
      "[epoch 23] loss: 0.0178947\n",
      "Test set: Average loss: 1.7686, Accuracy: 3090/5000 (62%)\n",
      "[epoch 24] loss: 0.0112069\n",
      "Test set: Average loss: 1.7819, Accuracy: 3104/5000 (62%)\n",
      "[epoch 25] loss: 0.0080262\n",
      "Test set: Average loss: 1.7995, Accuracy: 3120/5000 (62%)\n",
      "[epoch 26] loss: 0.0059055\n",
      "Test set: Average loss: 1.8162, Accuracy: 3124/5000 (62%)\n",
      "[epoch 27] loss: 0.0044303\n",
      "Test set: Average loss: 1.8409, Accuracy: 3130/5000 (63%)\n",
      "[epoch 28] loss: 0.0032744\n",
      "Test set: Average loss: 1.8624, Accuracy: 3141/5000 (63%)\n",
      "[epoch 29] loss: 0.0024209\n",
      "Test set: Average loss: 1.8977, Accuracy: 3140/5000 (63%)\n",
      "[epoch 30] loss: 0.0017695\n",
      "Test set: Average loss: 1.9320, Accuracy: 3134/5000 (63%)\n",
      "[epoch 31] loss: 0.0012856\n",
      "Test set: Average loss: 1.9705, Accuracy: 3143/5000 (63%)\n",
      "[epoch 32] loss: 0.0009266\n",
      "Test set: Average loss: 2.0092, Accuracy: 3149/5000 (63%)\n",
      "[epoch 33] loss: 0.0006601\n",
      "Test set: Average loss: 2.0524, Accuracy: 3147/5000 (63%)\n",
      "[epoch 34] loss: 0.0004681\n",
      "Test set: Average loss: 2.1025, Accuracy: 3137/5000 (63%)\n",
      "[epoch 35] loss: 0.0003307\n",
      "Test set: Average loss: 2.1473, Accuracy: 3143/5000 (63%)\n",
      "[epoch 36] loss: 0.0002330\n",
      "Test set: Average loss: 2.1989, Accuracy: 3150/5000 (63%)\n",
      "[epoch 37] loss: 0.0001627\n",
      "Test set: Average loss: 2.2430, Accuracy: 3155/5000 (63%)\n",
      "[epoch 38] loss: 0.0001137\n",
      "Test set: Average loss: 2.2972, Accuracy: 3160/5000 (63%)\n",
      "[epoch 39] loss: 0.0000784\n",
      "Test set: Average loss: 2.3482, Accuracy: 3153/5000 (63%)\n",
      "[epoch 40] loss: 0.0000543\n",
      "Test set: Average loss: 2.4031, Accuracy: 3160/5000 (63%)\n",
      "[epoch 41] loss: 0.0000373\n",
      "Test set: Average loss: 2.4582, Accuracy: 3164/5000 (63%)\n",
      "[epoch 42] loss: 0.0000256\n",
      "Test set: Average loss: 2.5108, Accuracy: 3164/5000 (63%)\n",
      "[epoch 43] loss: 0.0000176\n",
      "Test set: Average loss: 2.5687, Accuracy: 3171/5000 (63%)\n",
      "[epoch 44] loss: 0.0000120\n",
      "Test set: Average loss: 2.6367, Accuracy: 3165/5000 (63%)\n",
      "[epoch 45] loss: 0.0000082\n",
      "Test set: Average loss: 2.6879, Accuracy: 3171/5000 (63%)\n",
      "[epoch 46] loss: 0.0000055\n",
      "Test set: Average loss: 2.7481, Accuracy: 3167/5000 (63%)\n",
      "[epoch 47] loss: 0.0000038\n",
      "Test set: Average loss: 2.8015, Accuracy: 3174/5000 (63%)\n",
      "[epoch 48] loss: 0.0000025\n",
      "Test set: Average loss: 2.8573, Accuracy: 3168/5000 (63%)\n",
      "[epoch 49] loss: 0.0000017\n",
      "Test set: Average loss: 2.9182, Accuracy: 3172/5000 (63%)\n",
      "[epoch 50] loss: 0.0000011\n",
      "Test set: Average loss: 2.9594, Accuracy: 3174/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9594, Accuracy: 3174/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 3.0072, Accuracy: 6408/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3008, Accuracy: 489/5000 (10%)\n",
      "[epoch 1] loss: 1.4922813\n",
      "Test set: Average loss: 1.3166, Accuracy: 2603/5000 (52%)\n",
      "[epoch 2] loss: 1.2475816\n",
      "Test set: Average loss: 1.3031, Accuracy: 2622/5000 (52%)\n",
      "[epoch 3] loss: 1.1511419\n",
      "Test set: Average loss: 1.2077, Accuracy: 2884/5000 (58%)\n",
      "[epoch 4] loss: 1.0802267\n",
      "Test set: Average loss: 1.1728, Accuracy: 2917/5000 (58%)\n",
      "[epoch 5] loss: 1.0140430\n",
      "Test set: Average loss: 1.1189, Accuracy: 3032/5000 (61%)\n",
      "[epoch 6] loss: 0.9500499\n",
      "Test set: Average loss: 1.1023, Accuracy: 3062/5000 (61%)\n",
      "[epoch 7] loss: 0.8899362\n",
      "Test set: Average loss: 1.1618, Accuracy: 3011/5000 (60%)\n",
      "[epoch 8] loss: 0.8130999\n",
      "Test set: Average loss: 1.1526, Accuracy: 3006/5000 (60%)\n",
      "[epoch 9] loss: 0.7438918\n",
      "Test set: Average loss: 1.1274, Accuracy: 3093/5000 (62%)\n",
      "[epoch 10] loss: 0.6534385\n",
      "Test set: Average loss: 1.1284, Accuracy: 3139/5000 (63%)\n",
      "[epoch 11] loss: 0.5537764\n",
      "Test set: Average loss: 1.2255, Accuracy: 3069/5000 (61%)\n",
      "[epoch 12] loss: 0.4540604\n",
      "Test set: Average loss: 1.2273, Accuracy: 3135/5000 (63%)\n",
      "[epoch 13] loss: 0.3638031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.2970, Accuracy: 3165/5000 (63%)\n",
      "[epoch 14] loss: 0.2696255\n",
      "Test set: Average loss: 1.4005, Accuracy: 3068/5000 (61%)\n",
      "[epoch 15] loss: 0.2134510\n",
      "Test set: Average loss: 1.5216, Accuracy: 3035/5000 (61%)\n",
      "[epoch 16] loss: 0.1761828\n",
      "Test set: Average loss: 1.6340, Accuracy: 3053/5000 (61%)\n",
      "[epoch 17] loss: 0.1470411\n",
      "Test set: Average loss: 1.7256, Accuracy: 3006/5000 (60%)\n",
      "[epoch 18] loss: 0.1593638\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7265, Accuracy: 3103/5000 (62%)\n",
      "[epoch 19] loss: 0.0590825\n",
      "Test set: Average loss: 1.6210, Accuracy: 3157/5000 (63%)\n",
      "[epoch 20] loss: 0.0215334\n",
      "Test set: Average loss: 1.6373, Accuracy: 3187/5000 (64%)\n",
      "[epoch 21] loss: 0.0140092\n",
      "Test set: Average loss: 1.6555, Accuracy: 3181/5000 (64%)\n",
      "[epoch 22] loss: 0.0100722\n",
      "Test set: Average loss: 1.6764, Accuracy: 3197/5000 (64%)\n",
      "[epoch 23] loss: 0.0074578\n",
      "Test set: Average loss: 1.6994, Accuracy: 3191/5000 (64%)\n",
      "[epoch 24] loss: 0.0055179\n",
      "Test set: Average loss: 1.7309, Accuracy: 3199/5000 (64%)\n",
      "[epoch 25] loss: 0.0040810\n",
      "Test set: Average loss: 1.7604, Accuracy: 3214/5000 (64%)\n",
      "[epoch 26] loss: 0.0030044\n",
      "Test set: Average loss: 1.8025, Accuracy: 3202/5000 (64%)\n",
      "[epoch 27] loss: 0.0021878\n",
      "Test set: Average loss: 1.8490, Accuracy: 3214/5000 (64%)\n",
      "[epoch 28] loss: 0.0015794\n",
      "Test set: Average loss: 1.8859, Accuracy: 3197/5000 (64%)\n",
      "[epoch 29] loss: 0.0011793\n",
      "Test set: Average loss: 1.9378, Accuracy: 3205/5000 (64%)\n",
      "[epoch 30] loss: 0.0008090\n",
      "Test set: Average loss: 1.9865, Accuracy: 3197/5000 (64%)\n",
      "[epoch 31] loss: 0.0005764\n",
      "Test set: Average loss: 2.0407, Accuracy: 3209/5000 (64%)\n",
      "[epoch 32] loss: 0.0004070\n",
      "Test set: Average loss: 2.0926, Accuracy: 3212/5000 (64%)\n",
      "[epoch 33] loss: 0.0002876\n",
      "Test set: Average loss: 2.1456, Accuracy: 3217/5000 (64%)\n",
      "[epoch 34] loss: 0.0001994\n",
      "Test set: Average loss: 2.2030, Accuracy: 3216/5000 (64%)\n",
      "[epoch 35] loss: 0.0001381\n",
      "Test set: Average loss: 2.2629, Accuracy: 3216/5000 (64%)\n",
      "[epoch 36] loss: 0.0000955\n",
      "Test set: Average loss: 2.3163, Accuracy: 3204/5000 (64%)\n",
      "[epoch 37] loss: 0.0000655\n",
      "Test set: Average loss: 2.3767, Accuracy: 3221/5000 (64%)\n",
      "[epoch 38] loss: 0.0000447\n",
      "Test set: Average loss: 2.4409, Accuracy: 3212/5000 (64%)\n",
      "[epoch 39] loss: 0.0000308\n",
      "Test set: Average loss: 2.4958, Accuracy: 3206/5000 (64%)\n",
      "[epoch 40] loss: 0.0000209\n",
      "Test set: Average loss: 2.5651, Accuracy: 3210/5000 (64%)\n",
      "[epoch 41] loss: 0.0000142\n",
      "Test set: Average loss: 2.6234, Accuracy: 3210/5000 (64%)\n",
      "[epoch 42] loss: 0.0000095\n",
      "Test set: Average loss: 2.6862, Accuracy: 3212/5000 (64%)\n",
      "[epoch 43] loss: 0.0000064\n",
      "Test set: Average loss: 2.7485, Accuracy: 3221/5000 (64%)\n",
      "[epoch 44] loss: 0.0000043\n",
      "Test set: Average loss: 2.8148, Accuracy: 3210/5000 (64%)\n",
      "[epoch 45] loss: 0.0000029\n",
      "Test set: Average loss: 2.8697, Accuracy: 3211/5000 (64%)\n",
      "[epoch 46] loss: 0.0000019\n",
      "Test set: Average loss: 2.9308, Accuracy: 3213/5000 (64%)\n",
      "[epoch 47] loss: 0.0000013\n",
      "Test set: Average loss: 2.9905, Accuracy: 3209/5000 (64%)\n",
      "[epoch 48] loss: 0.0000008\n",
      "Test set: Average loss: 3.0236, Accuracy: 3203/5000 (64%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 3.0496, Accuracy: 3204/5000 (64%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.0596, Accuracy: 3201/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7485, Accuracy: 3221/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.7211, Accuracy: 6463/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3006, Accuracy: 581/5000 (12%)\n",
      "[epoch 1] loss: 1.5393015\n",
      "Test set: Average loss: 1.3937, Accuracy: 2479/5000 (50%)\n",
      "[epoch 2] loss: 1.3213319\n",
      "Test set: Average loss: 1.3481, Accuracy: 2600/5000 (52%)\n",
      "[epoch 3] loss: 1.2198523\n",
      "Test set: Average loss: 1.2517, Accuracy: 2756/5000 (55%)\n",
      "[epoch 4] loss: 1.1271115\n",
      "Test set: Average loss: 1.1964, Accuracy: 2865/5000 (57%)\n",
      "[epoch 5] loss: 1.0442819\n",
      "Test set: Average loss: 1.1467, Accuracy: 2957/5000 (59%)\n",
      "[epoch 6] loss: 0.9680258\n",
      "Test set: Average loss: 1.0932, Accuracy: 3072/5000 (61%)\n",
      "[epoch 7] loss: 0.8970869\n",
      "Test set: Average loss: 1.1214, Accuracy: 3026/5000 (61%)\n",
      "[epoch 8] loss: 0.8273528\n",
      "Test set: Average loss: 1.1013, Accuracy: 3076/5000 (62%)\n",
      "[epoch 9] loss: 0.7357814\n",
      "Test set: Average loss: 1.1019, Accuracy: 3116/5000 (62%)\n",
      "[epoch 10] loss: 0.6491072\n",
      "Test set: Average loss: 1.1705, Accuracy: 3109/5000 (62%)\n",
      "[epoch 11] loss: 0.5419254\n",
      "Test set: Average loss: 1.2023, Accuracy: 3114/5000 (62%)\n",
      "[epoch 12] loss: 0.4512124\n",
      "Test set: Average loss: 1.3081, Accuracy: 3046/5000 (61%)\n",
      "[epoch 13] loss: 0.3597412\n",
      "Test set: Average loss: 1.3734, Accuracy: 3082/5000 (62%)\n",
      "[epoch 14] loss: 0.2827556\n",
      "Test set: Average loss: 1.4318, Accuracy: 3043/5000 (61%)\n",
      "[epoch 15] loss: 0.2300851\n",
      "Test set: Average loss: 1.5237, Accuracy: 3049/5000 (61%)\n",
      "[epoch 16] loss: 0.2003014\n",
      "Test set: Average loss: 1.5672, Accuracy: 3032/5000 (61%)\n",
      "[epoch 17] loss: 0.1706988\n",
      "Test set: Average loss: 1.7151, Accuracy: 3002/5000 (60%)\n",
      "[epoch 18] loss: 0.1661287\n",
      "Test set: Average loss: 1.7949, Accuracy: 2975/5000 (60%)\n",
      "[epoch 19] loss: 0.1557247\n",
      "Test set: Average loss: 1.8222, Accuracy: 3010/5000 (60%)\n",
      "[epoch 20] loss: 0.1488686\n",
      "Test set: Average loss: 1.8479, Accuracy: 2999/5000 (60%)\n",
      "[epoch 21] loss: 0.1366028\n",
      "Test set: Average loss: 1.9809, Accuracy: 2976/5000 (60%)\n",
      "[epoch 22] loss: 0.1415649\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9702, Accuracy: 3013/5000 (60%)\n",
      "[epoch 23] loss: 0.0536629\n",
      "Test set: Average loss: 1.8539, Accuracy: 3086/5000 (62%)\n",
      "[epoch 24] loss: 0.0159168\n",
      "Test set: Average loss: 1.8569, Accuracy: 3102/5000 (62%)\n",
      "[epoch 25] loss: 0.0097088\n",
      "Test set: Average loss: 1.8675, Accuracy: 3108/5000 (62%)\n",
      "[epoch 26] loss: 0.0069135\n",
      "Test set: Average loss: 1.8860, Accuracy: 3097/5000 (62%)\n",
      "[epoch 27] loss: 0.0050617\n",
      "Test set: Average loss: 1.9037, Accuracy: 3090/5000 (62%)\n",
      "[epoch 28] loss: 0.0037327\n",
      "Test set: Average loss: 1.9255, Accuracy: 3105/5000 (62%)\n",
      "[epoch 29] loss: 0.0027477\n",
      "Test set: Average loss: 1.9530, Accuracy: 3105/5000 (62%)\n",
      "[epoch 30] loss: 0.0020060\n",
      "Test set: Average loss: 1.9797, Accuracy: 3106/5000 (62%)\n",
      "[epoch 31] loss: 0.0014566\n",
      "Test set: Average loss: 2.0198, Accuracy: 3100/5000 (62%)\n",
      "[epoch 32] loss: 0.0010425\n",
      "Test set: Average loss: 2.0544, Accuracy: 3124/5000 (62%)\n",
      "[epoch 33] loss: 0.0007444\n",
      "Test set: Average loss: 2.0907, Accuracy: 3131/5000 (63%)\n",
      "[epoch 34] loss: 0.0005266\n",
      "Test set: Average loss: 2.1340, Accuracy: 3125/5000 (62%)\n",
      "[epoch 35] loss: 0.0003697\n",
      "Test set: Average loss: 2.1809, Accuracy: 3124/5000 (62%)\n",
      "[epoch 36] loss: 0.0002574\n",
      "Test set: Average loss: 2.2265, Accuracy: 3123/5000 (62%)\n",
      "[epoch 37] loss: 0.0001788\n",
      "Test set: Average loss: 2.2737, Accuracy: 3135/5000 (63%)\n",
      "[epoch 38] loss: 0.0001239\n",
      "Test set: Average loss: 2.3268, Accuracy: 3131/5000 (63%)\n",
      "[epoch 39] loss: 0.0000851\n",
      "Test set: Average loss: 2.3735, Accuracy: 3141/5000 (63%)\n",
      "[epoch 40] loss: 0.0000580\n",
      "Test set: Average loss: 2.4269, Accuracy: 3134/5000 (63%)\n",
      "[epoch 41] loss: 0.0000396\n",
      "Test set: Average loss: 2.4816, Accuracy: 3144/5000 (63%)\n",
      "[epoch 42] loss: 0.0000271\n",
      "Test set: Average loss: 2.5419, Accuracy: 3147/5000 (63%)\n",
      "[epoch 43] loss: 0.0000183\n",
      "Test set: Average loss: 2.5886, Accuracy: 3140/5000 (63%)\n",
      "[epoch 44] loss: 0.0000124\n",
      "Test set: Average loss: 2.6514, Accuracy: 3152/5000 (63%)\n",
      "[epoch 45] loss: 0.0000084\n",
      "Test set: Average loss: 2.7079, Accuracy: 3154/5000 (63%)\n",
      "[epoch 46] loss: 0.0000056\n",
      "Test set: Average loss: 2.7535, Accuracy: 3156/5000 (63%)\n",
      "[epoch 47] loss: 0.0000038\n",
      "Test set: Average loss: 2.8183, Accuracy: 3153/5000 (63%)\n",
      "[epoch 48] loss: 0.0000025\n",
      "Test set: Average loss: 2.8744, Accuracy: 3150/5000 (63%)\n",
      "[epoch 49] loss: 0.0000017\n",
      "Test set: Average loss: 2.9241, Accuracy: 3154/5000 (63%)\n",
      "[epoch 50] loss: 0.0000011\n",
      "Test set: Average loss: 2.9717, Accuracy: 3150/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7535, Accuracy: 3156/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.8139, Accuracy: 6353/10000 (64%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3054, Accuracy: 493/5000 (10%)\n",
      "[epoch 1] loss: 1.4711583\n",
      "Test set: Average loss: 1.3212, Accuracy: 2600/5000 (52%)\n",
      "[epoch 2] loss: 1.2328754\n",
      "Test set: Average loss: 1.2270, Accuracy: 2819/5000 (56%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] loss: 1.1267918\n",
      "Test set: Average loss: 1.2024, Accuracy: 2890/5000 (58%)\n",
      "[epoch 4] loss: 1.0441139\n",
      "Test set: Average loss: 1.1159, Accuracy: 3005/5000 (60%)\n",
      "[epoch 5] loss: 0.9740017\n",
      "Test set: Average loss: 1.1083, Accuracy: 3096/5000 (62%)\n",
      "[epoch 6] loss: 0.8977538\n",
      "Test set: Average loss: 1.0979, Accuracy: 3121/5000 (62%)\n",
      "[epoch 7] loss: 0.8311636\n",
      "Test set: Average loss: 1.1018, Accuracy: 3103/5000 (62%)\n",
      "[epoch 8] loss: 0.7497202\n",
      "Test set: Average loss: 1.0996, Accuracy: 3185/5000 (64%)\n",
      "[epoch 9] loss: 0.6714181\n",
      "Test set: Average loss: 1.0927, Accuracy: 3203/5000 (64%)\n",
      "[epoch 10] loss: 0.5804151\n",
      "Test set: Average loss: 1.1701, Accuracy: 3148/5000 (63%)\n",
      "[epoch 11] loss: 0.4859639\n",
      "Test set: Average loss: 1.1960, Accuracy: 3199/5000 (64%)\n",
      "[epoch 12] loss: 0.3985808\n",
      "Test set: Average loss: 1.2451, Accuracy: 3180/5000 (64%)\n",
      "[epoch 13] loss: 0.3200574\n",
      "Test set: Average loss: 1.3526, Accuracy: 3121/5000 (62%)\n",
      "[epoch 14] loss: 0.2697418\n",
      "Test set: Average loss: 1.4813, Accuracy: 3106/5000 (62%)\n",
      "[epoch 15] loss: 0.2168202\n",
      "Test set: Average loss: 1.5093, Accuracy: 3137/5000 (63%)\n",
      "[epoch 16] loss: 0.2003898\n",
      "Test set: Average loss: 1.6089, Accuracy: 3126/5000 (63%)\n",
      "[epoch 17] loss: 0.1681598\n",
      "Test set: Average loss: 1.6296, Accuracy: 3168/5000 (63%)\n",
      "[epoch 18] loss: 0.1715438\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7006, Accuracy: 3117/5000 (62%)\n",
      "[epoch 19] loss: 0.0680933\n",
      "Test set: Average loss: 1.6434, Accuracy: 3193/5000 (64%)\n",
      "[epoch 20] loss: 0.0245752\n",
      "Test set: Average loss: 1.6548, Accuracy: 3226/5000 (65%)\n",
      "[epoch 21] loss: 0.0152049\n",
      "Test set: Average loss: 1.6720, Accuracy: 3219/5000 (64%)\n",
      "[epoch 22] loss: 0.0104914\n",
      "Test set: Average loss: 1.6950, Accuracy: 3235/5000 (65%)\n",
      "[epoch 23] loss: 0.0074288\n",
      "Test set: Average loss: 1.7237, Accuracy: 3244/5000 (65%)\n",
      "[epoch 24] loss: 0.0052721\n",
      "Test set: Average loss: 1.7561, Accuracy: 3246/5000 (65%)\n",
      "[epoch 25] loss: 0.0037066\n",
      "Test set: Average loss: 1.7966, Accuracy: 3254/5000 (65%)\n",
      "[epoch 26] loss: 0.0025833\n",
      "Test set: Average loss: 1.8322, Accuracy: 3258/5000 (65%)\n",
      "[epoch 27] loss: 0.0017816\n",
      "Test set: Average loss: 1.8812, Accuracy: 3257/5000 (65%)\n",
      "[epoch 28] loss: 0.0012241\n",
      "Test set: Average loss: 1.9345, Accuracy: 3260/5000 (65%)\n",
      "[epoch 29] loss: 0.0008317\n",
      "Test set: Average loss: 1.9868, Accuracy: 3253/5000 (65%)\n",
      "[epoch 30] loss: 0.0005662\n",
      "Test set: Average loss: 2.0397, Accuracy: 3261/5000 (65%)\n",
      "[epoch 31] loss: 0.0003788\n",
      "Test set: Average loss: 2.1002, Accuracy: 3253/5000 (65%)\n",
      "[epoch 32] loss: 0.0002532\n",
      "Test set: Average loss: 2.1542, Accuracy: 3257/5000 (65%)\n",
      "[epoch 33] loss: 0.0001701\n",
      "Test set: Average loss: 2.2213, Accuracy: 3254/5000 (65%)\n",
      "[epoch 34] loss: 0.0001124\n",
      "Test set: Average loss: 2.2804, Accuracy: 3251/5000 (65%)\n",
      "[epoch 35] loss: 0.0000739\n",
      "Test set: Average loss: 2.3467, Accuracy: 3259/5000 (65%)\n",
      "[epoch 36] loss: 0.0000482\n",
      "Test set: Average loss: 2.4073, Accuracy: 3254/5000 (65%)\n",
      "[epoch 37] loss: 0.0000318\n",
      "Test set: Average loss: 2.4767, Accuracy: 3264/5000 (65%)\n",
      "[epoch 38] loss: 0.0000211\n",
      "Test set: Average loss: 2.5494, Accuracy: 3255/5000 (65%)\n",
      "[epoch 39] loss: 0.0000133\n",
      "Test set: Average loss: 2.6143, Accuracy: 3259/5000 (65%)\n",
      "[epoch 40] loss: 0.0000087\n",
      "Test set: Average loss: 2.6871, Accuracy: 3259/5000 (65%)\n",
      "[epoch 41] loss: 0.0001739\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.7618, Accuracy: 3241/5000 (65%)\n",
      "[epoch 42] loss: 0.0005503\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.7394, Accuracy: 3253/5000 (65%)\n",
      "[epoch 43] loss: 0.0000999\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 44] loss: 0.0000963\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 45] loss: 0.0000958\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 46] loss: 0.0000958\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 47] loss: 0.0000958\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 48] loss: 0.0000958\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 49] loss: 0.0000958\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "[epoch 50] loss: 0.0000958\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.7391, Accuracy: 3254/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4767, Accuracy: 3264/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.4572, Accuracy: 6602/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 594/5000 (12%)\n",
      "[epoch 1] loss: 1.4937999\n",
      "Test set: Average loss: 1.4148, Accuracy: 2467/5000 (49%)\n",
      "[epoch 2] loss: 1.2710428\n",
      "Test set: Average loss: 1.2472, Accuracy: 2768/5000 (55%)\n",
      "[epoch 3] loss: 1.1649021\n",
      "Test set: Average loss: 1.1951, Accuracy: 2795/5000 (56%)\n",
      "[epoch 4] loss: 1.0814724\n",
      "Test set: Average loss: 1.1741, Accuracy: 2943/5000 (59%)\n",
      "[epoch 5] loss: 1.0127803\n",
      "Test set: Average loss: 1.1437, Accuracy: 3017/5000 (60%)\n",
      "[epoch 6] loss: 0.9490884\n",
      "Test set: Average loss: 1.1756, Accuracy: 2987/5000 (60%)\n",
      "[epoch 7] loss: 0.8865606\n",
      "Test set: Average loss: 1.0734, Accuracy: 3115/5000 (62%)\n",
      "[epoch 8] loss: 0.8063354\n",
      "Test set: Average loss: 1.1616, Accuracy: 3117/5000 (62%)\n",
      "[epoch 9] loss: 0.7307737\n",
      "Test set: Average loss: 1.1758, Accuracy: 3104/5000 (62%)\n",
      "[epoch 10] loss: 0.6504128\n",
      "Test set: Average loss: 1.1344, Accuracy: 3176/5000 (64%)\n",
      "[epoch 11] loss: 0.5573181\n",
      "Test set: Average loss: 1.1881, Accuracy: 3133/5000 (63%)\n",
      "[epoch 12] loss: 0.4666282\n",
      "Test set: Average loss: 1.3290, Accuracy: 3055/5000 (61%)\n",
      "[epoch 13] loss: 0.3932080\n",
      "Test set: Average loss: 1.3376, Accuracy: 3088/5000 (62%)\n",
      "[epoch 14] loss: 0.3111575\n",
      "Test set: Average loss: 1.4174, Accuracy: 3105/5000 (62%)\n",
      "[epoch 15] loss: 0.2540542\n",
      "Test set: Average loss: 1.5661, Accuracy: 3012/5000 (60%)\n",
      "[epoch 16] loss: 0.2213526\n",
      "Test set: Average loss: 1.5927, Accuracy: 3061/5000 (61%)\n",
      "[epoch 17] loss: 0.2004898\n",
      "Test set: Average loss: 1.7376, Accuracy: 3035/5000 (61%)\n",
      "[epoch 18] loss: 0.1793508\n",
      "Test set: Average loss: 1.7268, Accuracy: 3040/5000 (61%)\n",
      "[epoch 19] loss: 0.1772109\n",
      "Test set: Average loss: 1.8430, Accuracy: 2995/5000 (60%)\n",
      "[epoch 20] loss: 0.1580768\n",
      "Test set: Average loss: 1.8626, Accuracy: 3053/5000 (61%)\n",
      "[epoch 21] loss: 0.1750784\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8728, Accuracy: 3076/5000 (62%)\n",
      "[epoch 22] loss: 0.0720594\n",
      "Test set: Average loss: 1.7723, Accuracy: 3128/5000 (63%)\n",
      "[epoch 23] loss: 0.0230360\n",
      "Test set: Average loss: 1.7790, Accuracy: 3149/5000 (63%)\n",
      "[epoch 24] loss: 0.0135225\n",
      "Test set: Average loss: 1.7898, Accuracy: 3156/5000 (63%)\n",
      "[epoch 25] loss: 0.0092513\n",
      "Test set: Average loss: 1.8082, Accuracy: 3172/5000 (63%)\n",
      "[epoch 26] loss: 0.0065276\n",
      "Test set: Average loss: 1.8393, Accuracy: 3182/5000 (64%)\n",
      "[epoch 27] loss: 0.0046326\n",
      "Test set: Average loss: 1.8640, Accuracy: 3192/5000 (64%)\n",
      "[epoch 28] loss: 0.0032758\n",
      "Test set: Average loss: 1.8948, Accuracy: 3184/5000 (64%)\n",
      "[epoch 29] loss: 0.0023020\n",
      "Test set: Average loss: 1.9344, Accuracy: 3203/5000 (64%)\n",
      "[epoch 30] loss: 0.0016077\n",
      "Test set: Average loss: 1.9743, Accuracy: 3212/5000 (64%)\n",
      "[epoch 31] loss: 0.0011015\n",
      "Test set: Average loss: 2.0118, Accuracy: 3209/5000 (64%)\n",
      "[epoch 32] loss: 0.0007612\n",
      "Test set: Average loss: 2.0641, Accuracy: 3206/5000 (64%)\n",
      "[epoch 33] loss: 0.0005172\n",
      "Test set: Average loss: 2.1170, Accuracy: 3222/5000 (64%)\n",
      "[epoch 34] loss: 0.0004466\n",
      "Test set: Average loss: 2.1876, Accuracy: 3198/5000 (64%)\n",
      "[epoch 35] loss: 0.0007173\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.2013, Accuracy: 3204/5000 (64%)\n",
      "[epoch 36] loss: 0.0002482\n",
      "Test set: Average loss: 2.2042, Accuracy: 3206/5000 (64%)\n",
      "[epoch 37] loss: 0.0002335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.2087, Accuracy: 3202/5000 (64%)\n",
      "[epoch 38] loss: 0.0002198\n",
      "Test set: Average loss: 2.2133, Accuracy: 3203/5000 (64%)\n",
      "[epoch 39] loss: 0.0002056\n",
      "Test set: Average loss: 2.2198, Accuracy: 3204/5000 (64%)\n",
      "[epoch 40] loss: 0.0001908\n",
      "Test set: Average loss: 2.2265, Accuracy: 3204/5000 (64%)\n",
      "[epoch 41] loss: 0.0001759\n",
      "Test set: Average loss: 2.2368, Accuracy: 3205/5000 (64%)\n",
      "[epoch 42] loss: 0.0001616\n",
      "Test set: Average loss: 2.2446, Accuracy: 3209/5000 (64%)\n",
      "[epoch 43] loss: 0.0001482\n",
      "Test set: Average loss: 2.2565, Accuracy: 3208/5000 (64%)\n",
      "[epoch 44] loss: 0.0001358\n",
      "Test set: Average loss: 2.2680, Accuracy: 3206/5000 (64%)\n",
      "[epoch 45] loss: 0.0001245\n",
      "Test set: Average loss: 2.2774, Accuracy: 3211/5000 (64%)\n",
      "[epoch 46] loss: 0.0001141\n",
      "Test set: Average loss: 2.2912, Accuracy: 3212/5000 (64%)\n",
      "[epoch 47] loss: 0.0001049\n",
      "Test set: Average loss: 2.3016, Accuracy: 3211/5000 (64%)\n",
      "[epoch 48] loss: 0.0000963\n",
      "Test set: Average loss: 2.3128, Accuracy: 3210/5000 (64%)\n",
      "[epoch 49] loss: 0.0000885\n",
      "Test set: Average loss: 2.3262, Accuracy: 3203/5000 (64%)\n",
      "[epoch 50] loss: 0.0000813\n",
      "Test set: Average loss: 2.3372, Accuracy: 3209/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1170, Accuracy: 3222/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.0657, Accuracy: 6577/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 487/5000 (10%)\n",
      "[epoch 1] loss: 1.5124229\n",
      "Test set: Average loss: 1.3430, Accuracy: 2615/5000 (52%)\n",
      "[epoch 2] loss: 1.2737464\n",
      "Test set: Average loss: 1.2103, Accuracy: 2876/5000 (58%)\n",
      "[epoch 3] loss: 1.1556384\n",
      "Test set: Average loss: 1.1339, Accuracy: 2965/5000 (59%)\n",
      "[epoch 4] loss: 1.0615389\n",
      "Test set: Average loss: 1.1771, Accuracy: 2943/5000 (59%)\n",
      "[epoch 5] loss: 0.9811354\n",
      "Test set: Average loss: 1.1159, Accuracy: 3072/5000 (61%)\n",
      "[epoch 6] loss: 0.9118323\n",
      "Test set: Average loss: 1.1200, Accuracy: 3058/5000 (61%)\n",
      "[epoch 7] loss: 0.8360535\n",
      "Test set: Average loss: 1.0556, Accuracy: 3173/5000 (63%)\n",
      "[epoch 8] loss: 0.7646514\n",
      "Test set: Average loss: 1.0801, Accuracy: 3121/5000 (62%)\n",
      "[epoch 9] loss: 0.6791125\n",
      "Test set: Average loss: 1.1175, Accuracy: 3161/5000 (63%)\n",
      "[epoch 10] loss: 0.5930234\n",
      "Test set: Average loss: 1.1399, Accuracy: 3186/5000 (64%)\n",
      "[epoch 11] loss: 0.4978662\n",
      "Test set: Average loss: 1.2107, Accuracy: 3188/5000 (64%)\n",
      "[epoch 12] loss: 0.4109013\n",
      "Test set: Average loss: 1.2284, Accuracy: 3182/5000 (64%)\n",
      "[epoch 13] loss: 0.3406940\n",
      "Test set: Average loss: 1.3566, Accuracy: 3129/5000 (63%)\n",
      "[epoch 14] loss: 0.2686698\n",
      "Test set: Average loss: 1.4587, Accuracy: 3057/5000 (61%)\n",
      "[epoch 15] loss: 0.2398746\n",
      "Test set: Average loss: 1.5457, Accuracy: 3058/5000 (61%)\n",
      "[epoch 16] loss: 0.1991666\n",
      "Test set: Average loss: 1.5553, Accuracy: 3141/5000 (63%)\n",
      "[epoch 17] loss: 0.1652376\n",
      "Test set: Average loss: 1.6509, Accuracy: 3116/5000 (62%)\n",
      "[epoch 18] loss: 0.1768526\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6954, Accuracy: 3142/5000 (63%)\n",
      "[epoch 19] loss: 0.0641302\n",
      "Test set: Average loss: 1.5867, Accuracy: 3196/5000 (64%)\n",
      "[epoch 20] loss: 0.0241141\n",
      "Test set: Average loss: 1.5997, Accuracy: 3217/5000 (64%)\n",
      "[epoch 21] loss: 0.0149083\n",
      "Test set: Average loss: 1.6181, Accuracy: 3234/5000 (65%)\n",
      "[epoch 22] loss: 0.0103141\n",
      "Test set: Average loss: 1.6425, Accuracy: 3243/5000 (65%)\n",
      "[epoch 23] loss: 0.0073518\n",
      "Test set: Average loss: 1.6712, Accuracy: 3262/5000 (65%)\n",
      "[epoch 24] loss: 0.0052089\n",
      "Test set: Average loss: 1.7041, Accuracy: 3261/5000 (65%)\n",
      "[epoch 25] loss: 0.0036734\n",
      "Test set: Average loss: 1.7390, Accuracy: 3257/5000 (65%)\n",
      "[epoch 26] loss: 0.0025685\n",
      "Test set: Average loss: 1.7867, Accuracy: 3259/5000 (65%)\n",
      "[epoch 27] loss: 0.0017863\n",
      "Test set: Average loss: 1.8305, Accuracy: 3270/5000 (65%)\n",
      "[epoch 28] loss: 0.0012351\n",
      "Test set: Average loss: 1.8807, Accuracy: 3282/5000 (66%)\n",
      "[epoch 29] loss: 0.0008383\n",
      "Test set: Average loss: 1.9327, Accuracy: 3274/5000 (65%)\n",
      "[epoch 30] loss: 0.0005656\n",
      "Test set: Average loss: 1.9968, Accuracy: 3283/5000 (66%)\n",
      "[epoch 31] loss: 0.0003818\n",
      "Test set: Average loss: 2.0465, Accuracy: 3266/5000 (65%)\n",
      "[epoch 32] loss: 0.0002555\n",
      "Test set: Average loss: 2.1091, Accuracy: 3268/5000 (65%)\n",
      "[epoch 33] loss: 0.0001703\n",
      "Test set: Average loss: 2.1685, Accuracy: 3283/5000 (66%)\n",
      "[epoch 34] loss: 0.0001115\n",
      "Test set: Average loss: 2.2321, Accuracy: 3285/5000 (66%)\n",
      "[epoch 35] loss: 0.0000740\n",
      "Test set: Average loss: 2.2926, Accuracy: 3279/5000 (66%)\n",
      "[epoch 36] loss: 0.0000483\n",
      "Test set: Average loss: 2.3545, Accuracy: 3269/5000 (65%)\n",
      "[epoch 37] loss: 0.0000314\n",
      "Test set: Average loss: 2.4297, Accuracy: 3288/5000 (66%)\n",
      "[epoch 38] loss: 0.0000204\n",
      "Test set: Average loss: 2.4872, Accuracy: 3291/5000 (66%)\n",
      "[epoch 39] loss: 0.0000132\n",
      "Test set: Average loss: 2.5607, Accuracy: 3289/5000 (66%)\n",
      "[epoch 40] loss: 0.0000085\n",
      "Test set: Average loss: 2.6206, Accuracy: 3292/5000 (66%)\n",
      "[epoch 41] loss: 0.0000055\n",
      "Test set: Average loss: 2.6988, Accuracy: 3280/5000 (66%)\n",
      "[epoch 42] loss: 0.0000035\n",
      "Test set: Average loss: 2.7564, Accuracy: 3286/5000 (66%)\n",
      "[epoch 43] loss: 0.0000022\n",
      "Test set: Average loss: 2.8191, Accuracy: 3294/5000 (66%)\n",
      "[epoch 44] loss: 0.0000014\n",
      "Test set: Average loss: 2.8849, Accuracy: 3276/5000 (66%)\n",
      "[epoch 45] loss: 0.0000009\n",
      "Test set: Average loss: 2.9232, Accuracy: 3282/5000 (66%)\n",
      "[epoch 46] loss: 0.0000006\n",
      "Test set: Average loss: 2.9653, Accuracy: 3283/5000 (66%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 2.9699, Accuracy: 3267/5000 (65%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 2.9857, Accuracy: 3263/5000 (65%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.9897, Accuracy: 3259/5000 (65%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.9943, Accuracy: 3249/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8191, Accuracy: 3294/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.7749, Accuracy: 6627/10000 (66%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3043, Accuracy: 456/5000 (9%)\n",
      "[epoch 1] loss: 1.4903237\n",
      "Test set: Average loss: 1.3626, Accuracy: 2517/5000 (50%)\n",
      "[epoch 2] loss: 1.2487466\n",
      "Test set: Average loss: 1.2689, Accuracy: 2703/5000 (54%)\n",
      "[epoch 3] loss: 1.1358796\n",
      "Test set: Average loss: 1.1813, Accuracy: 2878/5000 (58%)\n",
      "[epoch 4] loss: 1.0472956\n",
      "Test set: Average loss: 1.0849, Accuracy: 3082/5000 (62%)\n",
      "[epoch 5] loss: 0.9582908\n",
      "Test set: Average loss: 1.1232, Accuracy: 3027/5000 (61%)\n",
      "[epoch 6] loss: 0.8895902\n",
      "Test set: Average loss: 1.0544, Accuracy: 3157/5000 (63%)\n",
      "[epoch 7] loss: 0.8070668\n",
      "Test set: Average loss: 1.0326, Accuracy: 3246/5000 (65%)\n",
      "[epoch 8] loss: 0.7267686\n",
      "Test set: Average loss: 1.0918, Accuracy: 3174/5000 (63%)\n",
      "[epoch 9] loss: 0.6511249\n",
      "Test set: Average loss: 1.1129, Accuracy: 3137/5000 (63%)\n",
      "[epoch 10] loss: 0.5653789\n",
      "Test set: Average loss: 1.1390, Accuracy: 3145/5000 (63%)\n",
      "[epoch 11] loss: 0.4774336\n",
      "Test set: Average loss: 1.2122, Accuracy: 3171/5000 (63%)\n",
      "[epoch 12] loss: 0.3985208\n",
      "Test set: Average loss: 1.2509, Accuracy: 3177/5000 (64%)\n",
      "[epoch 13] loss: 0.3255240\n",
      "Test set: Average loss: 1.3436, Accuracy: 3155/5000 (63%)\n",
      "[epoch 14] loss: 0.2704164\n",
      "Test set: Average loss: 1.4138, Accuracy: 3186/5000 (64%)\n",
      "[epoch 15] loss: 0.2297661\n",
      "Test set: Average loss: 1.4473, Accuracy: 3225/5000 (64%)\n",
      "[epoch 16] loss: 0.2022077\n",
      "Test set: Average loss: 1.5960, Accuracy: 3193/5000 (64%)\n",
      "[epoch 17] loss: 0.2013670\n",
      "Test set: Average loss: 1.6641, Accuracy: 3109/5000 (62%)\n",
      "[epoch 18] loss: 0.1947396\n",
      "Test set: Average loss: 1.6834, Accuracy: 3167/5000 (63%)\n",
      "[epoch 19] loss: 0.1723999\n",
      "Test set: Average loss: 1.7087, Accuracy: 3201/5000 (64%)\n",
      "[epoch 20] loss: 0.1665324\n",
      "Test set: Average loss: 1.8142, Accuracy: 3141/5000 (63%)\n",
      "[epoch 21] loss: 0.1756763\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8830, Accuracy: 3117/5000 (62%)\n",
      "[epoch 22] loss: 0.0712121\n",
      "Test set: Average loss: 1.7251, Accuracy: 3241/5000 (65%)\n",
      "[epoch 23] loss: 0.0219718\n",
      "Test set: Average loss: 1.7372, Accuracy: 3263/5000 (65%)\n",
      "[epoch 24] loss: 0.0121637\n",
      "Test set: Average loss: 1.7460, Accuracy: 3272/5000 (65%)\n",
      "[epoch 25] loss: 0.0078931\n",
      "Test set: Average loss: 1.7718, Accuracy: 3291/5000 (66%)\n",
      "[epoch 26] loss: 0.0053525\n",
      "Test set: Average loss: 1.8068, Accuracy: 3277/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27] loss: 0.0036225\n",
      "Test set: Average loss: 1.8380, Accuracy: 3285/5000 (66%)\n",
      "[epoch 28] loss: 0.0024095\n",
      "Test set: Average loss: 1.8765, Accuracy: 3297/5000 (66%)\n",
      "[epoch 29] loss: 0.0016630\n",
      "Test set: Average loss: 1.9215, Accuracy: 3297/5000 (66%)\n",
      "[epoch 30] loss: 0.0011028\n",
      "Test set: Average loss: 1.9733, Accuracy: 3292/5000 (66%)\n",
      "[epoch 31] loss: 0.0007001\n",
      "Test set: Average loss: 2.0147, Accuracy: 3309/5000 (66%)\n",
      "[epoch 32] loss: 0.0004612\n",
      "Test set: Average loss: 2.0717, Accuracy: 3295/5000 (66%)\n",
      "[epoch 33] loss: 0.0002989\n",
      "Test set: Average loss: 2.1418, Accuracy: 3311/5000 (66%)\n",
      "[epoch 34] loss: 0.0001919\n",
      "Test set: Average loss: 2.2031, Accuracy: 3302/5000 (66%)\n",
      "[epoch 35] loss: 0.0001224\n",
      "Test set: Average loss: 2.2681, Accuracy: 3294/5000 (66%)\n",
      "[epoch 36] loss: 0.0000772\n",
      "Test set: Average loss: 2.3381, Accuracy: 3291/5000 (66%)\n",
      "[epoch 37] loss: 0.0000490\n",
      "Test set: Average loss: 2.4083, Accuracy: 3289/5000 (66%)\n",
      "[epoch 38] loss: 0.0000308\n",
      "Test set: Average loss: 2.4754, Accuracy: 3300/5000 (66%)\n",
      "[epoch 39] loss: 0.0000188\n",
      "Test set: Average loss: 2.5451, Accuracy: 3291/5000 (66%)\n",
      "[epoch 40] loss: 0.0000117\n",
      "Test set: Average loss: 2.6230, Accuracy: 3290/5000 (66%)\n",
      "[epoch 41] loss: 0.0000073\n",
      "Test set: Average loss: 2.7198, Accuracy: 3288/5000 (66%)\n",
      "[epoch 42] loss: 0.0000045\n",
      "Test set: Average loss: 2.7729, Accuracy: 3284/5000 (66%)\n",
      "[epoch 43] loss: 0.0000027\n",
      "Test set: Average loss: 2.8416, Accuracy: 3294/5000 (66%)\n",
      "[epoch 44] loss: 0.0000016\n",
      "Test set: Average loss: 2.9155, Accuracy: 3296/5000 (66%)\n",
      "[epoch 45] loss: 0.0000010\n",
      "Test set: Average loss: 2.9759, Accuracy: 3293/5000 (66%)\n",
      "[epoch 46] loss: 0.0000006\n",
      "Test set: Average loss: 3.0180, Accuracy: 3300/5000 (66%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 3.0297, Accuracy: 3283/5000 (66%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.0479, Accuracy: 3286/5000 (66%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0628, Accuracy: 3281/5000 (66%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0872, Accuracy: 3281/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1418, Accuracy: 3311/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.0890, Accuracy: 6664/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3003, Accuracy: 516/5000 (10%)\n",
      "[epoch 1] loss: 1.4769973\n",
      "Test set: Average loss: 1.3119, Accuracy: 2638/5000 (53%)\n",
      "[epoch 2] loss: 1.2397899\n",
      "Test set: Average loss: 1.2176, Accuracy: 2825/5000 (56%)\n",
      "[epoch 3] loss: 1.1438582\n",
      "Test set: Average loss: 1.1142, Accuracy: 3069/5000 (61%)\n",
      "[epoch 4] loss: 1.0699478\n",
      "Test set: Average loss: 1.1061, Accuracy: 3038/5000 (61%)\n",
      "[epoch 5] loss: 1.0040603\n",
      "Test set: Average loss: 1.0788, Accuracy: 3092/5000 (62%)\n",
      "[epoch 6] loss: 0.9487835\n",
      "Test set: Average loss: 1.1219, Accuracy: 3032/5000 (61%)\n",
      "[epoch 7] loss: 0.8920977\n",
      "Test set: Average loss: 1.0462, Accuracy: 3141/5000 (63%)\n",
      "[epoch 8] loss: 0.8251144\n",
      "Test set: Average loss: 1.0471, Accuracy: 3215/5000 (64%)\n",
      "[epoch 9] loss: 0.7611947\n",
      "Test set: Average loss: 1.1418, Accuracy: 3087/5000 (62%)\n",
      "[epoch 10] loss: 0.6907907\n",
      "Test set: Average loss: 1.1621, Accuracy: 3096/5000 (62%)\n",
      "[epoch 11] loss: 0.6137375\n",
      "Test set: Average loss: 1.1057, Accuracy: 3226/5000 (65%)\n",
      "[epoch 12] loss: 0.5431384\n",
      "Test set: Average loss: 1.1828, Accuracy: 3180/5000 (64%)\n",
      "[epoch 13] loss: 0.4641148\n",
      "Test set: Average loss: 1.2434, Accuracy: 3136/5000 (63%)\n",
      "[epoch 14] loss: 0.3972087\n",
      "Test set: Average loss: 1.3351, Accuracy: 3118/5000 (62%)\n",
      "[epoch 15] loss: 0.3317217\n",
      "Test set: Average loss: 1.3765, Accuracy: 3129/5000 (63%)\n",
      "[epoch 16] loss: 0.2837307\n",
      "Test set: Average loss: 1.4767, Accuracy: 3155/5000 (63%)\n",
      "[epoch 17] loss: 0.2568598\n",
      "Test set: Average loss: 1.4720, Accuracy: 3153/5000 (63%)\n",
      "[epoch 18] loss: 0.2248997\n",
      "Test set: Average loss: 1.5844, Accuracy: 3143/5000 (63%)\n",
      "[epoch 19] loss: 0.2033161\n",
      "Test set: Average loss: 1.6194, Accuracy: 3119/5000 (62%)\n",
      "[epoch 20] loss: 0.2050156\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6800, Accuracy: 3081/5000 (62%)\n",
      "[epoch 21] loss: 0.0768459\n",
      "Test set: Average loss: 1.5875, Accuracy: 3173/5000 (63%)\n",
      "[epoch 22] loss: 0.0313405\n",
      "Test set: Average loss: 1.5971, Accuracy: 3204/5000 (64%)\n",
      "[epoch 23] loss: 0.0193095\n",
      "Test set: Average loss: 1.6218, Accuracy: 3207/5000 (64%)\n",
      "[epoch 24] loss: 0.0130342\n",
      "Test set: Average loss: 1.6428, Accuracy: 3211/5000 (64%)\n",
      "[epoch 25] loss: 0.0090304\n",
      "Test set: Average loss: 1.6785, Accuracy: 3222/5000 (64%)\n",
      "[epoch 26] loss: 0.0062866\n",
      "Test set: Average loss: 1.7134, Accuracy: 3246/5000 (65%)\n",
      "[epoch 27] loss: 0.0043460\n",
      "Test set: Average loss: 1.7556, Accuracy: 3241/5000 (65%)\n",
      "[epoch 28] loss: 0.0029855\n",
      "Test set: Average loss: 1.7934, Accuracy: 3245/5000 (65%)\n",
      "[epoch 29] loss: 0.0020478\n",
      "Test set: Average loss: 1.8463, Accuracy: 3259/5000 (65%)\n",
      "[epoch 30] loss: 0.0013702\n",
      "Test set: Average loss: 1.9226, Accuracy: 3257/5000 (65%)\n",
      "[epoch 31] loss: 0.0009360\n",
      "Test set: Average loss: 1.9530, Accuracy: 3254/5000 (65%)\n",
      "[epoch 32] loss: 0.0006263\n",
      "Test set: Average loss: 2.0147, Accuracy: 3266/5000 (65%)\n",
      "[epoch 33] loss: 0.0004172\n",
      "Test set: Average loss: 2.0668, Accuracy: 3271/5000 (65%)\n",
      "[epoch 34] loss: 0.0002749\n",
      "Test set: Average loss: 2.1314, Accuracy: 3294/5000 (66%)\n",
      "[epoch 35] loss: 0.0001822\n",
      "Test set: Average loss: 2.1951, Accuracy: 3294/5000 (66%)\n",
      "[epoch 36] loss: 0.0001184\n",
      "Test set: Average loss: 2.2619, Accuracy: 3296/5000 (66%)\n",
      "[epoch 37] loss: 0.0000778\n",
      "Test set: Average loss: 2.3244, Accuracy: 3300/5000 (66%)\n",
      "[epoch 38] loss: 0.0000503\n",
      "Test set: Average loss: 2.3983, Accuracy: 3292/5000 (66%)\n",
      "[epoch 39] loss: 0.0000324\n",
      "Test set: Average loss: 2.4663, Accuracy: 3295/5000 (66%)\n",
      "[epoch 40] loss: 0.0000206\n",
      "Test set: Average loss: 2.5334, Accuracy: 3301/5000 (66%)\n",
      "[epoch 41] loss: 0.0000132\n",
      "Test set: Average loss: 2.6101, Accuracy: 3308/5000 (66%)\n",
      "[epoch 42] loss: 0.0000084\n",
      "Test set: Average loss: 2.6846, Accuracy: 3305/5000 (66%)\n",
      "[epoch 43] loss: 0.0000053\n",
      "Test set: Average loss: 2.7485, Accuracy: 3300/5000 (66%)\n",
      "[epoch 44] loss: 0.0000033\n",
      "Test set: Average loss: 2.8266, Accuracy: 3306/5000 (66%)\n",
      "[epoch 45] loss: 0.0000021\n",
      "Test set: Average loss: 2.8922, Accuracy: 3310/5000 (66%)\n",
      "[epoch 46] loss: 0.0000013\n",
      "Test set: Average loss: 2.9484, Accuracy: 3311/5000 (66%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 3.0061, Accuracy: 3304/5000 (66%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 3.0368, Accuracy: 3289/5000 (66%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.0602, Accuracy: 3296/5000 (66%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 3.0849, Accuracy: 3300/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9484, Accuracy: 3311/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.9417, Accuracy: 6604/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3060, Accuracy: 454/5000 (9%)\n",
      "[epoch 1] loss: 1.4744043\n",
      "Test set: Average loss: 1.3691, Accuracy: 2512/5000 (50%)\n",
      "[epoch 2] loss: 1.2369769\n",
      "Test set: Average loss: 1.3157, Accuracy: 2682/5000 (54%)\n",
      "[epoch 3] loss: 1.1247572\n",
      "Test set: Average loss: 1.1483, Accuracy: 2939/5000 (59%)\n",
      "[epoch 4] loss: 1.0336660\n",
      "Test set: Average loss: 1.1203, Accuracy: 3007/5000 (60%)\n",
      "[epoch 5] loss: 0.9520529\n",
      "Test set: Average loss: 1.0767, Accuracy: 3096/5000 (62%)\n",
      "[epoch 6] loss: 0.8858814\n",
      "Test set: Average loss: 1.1244, Accuracy: 3003/5000 (60%)\n",
      "[epoch 7] loss: 0.8151822\n",
      "Test set: Average loss: 1.0350, Accuracy: 3193/5000 (64%)\n",
      "[epoch 8] loss: 0.7351925\n",
      "Test set: Average loss: 1.0712, Accuracy: 3223/5000 (64%)\n",
      "[epoch 9] loss: 0.6567158\n",
      "Test set: Average loss: 1.0953, Accuracy: 3226/5000 (65%)\n",
      "[epoch 10] loss: 0.5693681\n",
      "Test set: Average loss: 1.1143, Accuracy: 3207/5000 (64%)\n",
      "[epoch 11] loss: 0.4752640\n",
      "Test set: Average loss: 1.1805, Accuracy: 3241/5000 (65%)\n",
      "[epoch 12] loss: 0.4087999\n",
      "Test set: Average loss: 1.2671, Accuracy: 3179/5000 (64%)\n",
      "[epoch 13] loss: 0.3344747\n",
      "Test set: Average loss: 1.2946, Accuracy: 3197/5000 (64%)\n",
      "[epoch 14] loss: 0.2838551\n",
      "Test set: Average loss: 1.4390, Accuracy: 3200/5000 (64%)\n",
      "[epoch 15] loss: 0.2466357\n",
      "Test set: Average loss: 1.5057, Accuracy: 3105/5000 (62%)\n",
      "[epoch 16] loss: 0.2260526\n",
      "Test set: Average loss: 1.5788, Accuracy: 3178/5000 (64%)\n",
      "[epoch 17] loss: 0.2105355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6379, Accuracy: 3144/5000 (63%)\n",
      "[epoch 18] loss: 0.1996577\n",
      "Test set: Average loss: 1.6582, Accuracy: 3156/5000 (63%)\n",
      "[epoch 19] loss: 0.1919950\n",
      "Test set: Average loss: 1.7567, Accuracy: 3149/5000 (63%)\n",
      "[epoch 20] loss: 0.1804294\n",
      "Test set: Average loss: 1.7370, Accuracy: 3174/5000 (63%)\n",
      "[epoch 21] loss: 0.1791644\n",
      "Test set: Average loss: 1.8261, Accuracy: 3182/5000 (64%)\n",
      "[epoch 22] loss: 0.1838061\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8449, Accuracy: 3113/5000 (62%)\n",
      "[epoch 23] loss: 0.0709760\n",
      "Test set: Average loss: 1.7354, Accuracy: 3226/5000 (65%)\n",
      "[epoch 24] loss: 0.0227441\n",
      "Test set: Average loss: 1.7377, Accuracy: 3244/5000 (65%)\n",
      "[epoch 25] loss: 0.0127803\n",
      "Test set: Average loss: 1.7627, Accuracy: 3245/5000 (65%)\n",
      "[epoch 26] loss: 0.0083495\n",
      "Test set: Average loss: 1.7788, Accuracy: 3254/5000 (65%)\n",
      "[epoch 27] loss: 0.0056330\n",
      "Test set: Average loss: 1.8166, Accuracy: 3278/5000 (66%)\n",
      "[epoch 28] loss: 0.0038244\n",
      "Test set: Average loss: 1.8567, Accuracy: 3287/5000 (66%)\n",
      "[epoch 29] loss: 0.0025535\n",
      "Test set: Average loss: 1.8915, Accuracy: 3284/5000 (66%)\n",
      "[epoch 30] loss: 0.0016919\n",
      "Test set: Average loss: 1.9354, Accuracy: 3289/5000 (66%)\n",
      "[epoch 31] loss: 0.0011109\n",
      "Test set: Average loss: 1.9939, Accuracy: 3293/5000 (66%)\n",
      "[epoch 32] loss: 0.0007266\n",
      "Test set: Average loss: 2.0472, Accuracy: 3302/5000 (66%)\n",
      "[epoch 33] loss: 0.0004696\n",
      "Test set: Average loss: 2.1007, Accuracy: 3312/5000 (66%)\n",
      "[epoch 34] loss: 0.0003024\n",
      "Test set: Average loss: 2.1638, Accuracy: 3316/5000 (66%)\n",
      "[epoch 35] loss: 0.0001927\n",
      "Test set: Average loss: 2.2237, Accuracy: 3316/5000 (66%)\n",
      "[epoch 36] loss: 0.0001215\n",
      "Test set: Average loss: 2.2855, Accuracy: 3307/5000 (66%)\n",
      "[epoch 37] loss: 0.0000771\n",
      "Test set: Average loss: 2.3533, Accuracy: 3295/5000 (66%)\n",
      "[epoch 38] loss: 0.0000485\n",
      "Test set: Average loss: 2.4239, Accuracy: 3303/5000 (66%)\n",
      "[epoch 39] loss: 0.0000302\n",
      "Test set: Average loss: 2.4951, Accuracy: 3296/5000 (66%)\n",
      "[epoch 40] loss: 0.0000188\n",
      "Test set: Average loss: 2.5723, Accuracy: 3299/5000 (66%)\n",
      "[epoch 41] loss: 0.0000117\n",
      "Test set: Average loss: 2.6397, Accuracy: 3293/5000 (66%)\n",
      "[epoch 42] loss: 0.0000072\n",
      "Test set: Average loss: 2.7175, Accuracy: 3298/5000 (66%)\n",
      "[epoch 43] loss: 0.0000044\n",
      "Test set: Average loss: 2.7835, Accuracy: 3296/5000 (66%)\n",
      "[epoch 44] loss: 0.0000027\n",
      "Test set: Average loss: 2.8625, Accuracy: 3302/5000 (66%)\n",
      "[epoch 45] loss: 0.0000016\n",
      "Test set: Average loss: 2.9235, Accuracy: 3295/5000 (66%)\n",
      "[epoch 46] loss: 0.0000010\n",
      "Test set: Average loss: 2.9818, Accuracy: 3295/5000 (66%)\n",
      "[epoch 47] loss: 0.0000006\n",
      "Test set: Average loss: 3.0262, Accuracy: 3292/5000 (66%)\n",
      "[epoch 48] loss: 0.0000004\n",
      "Test set: Average loss: 3.0366, Accuracy: 3297/5000 (66%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.0543, Accuracy: 3286/5000 (66%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0776, Accuracy: 3278/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2237, Accuracy: 3316/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.2033, Accuracy: 6638/10000 (66%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3010, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 1.4594361\n",
      "Test set: Average loss: 1.3453, Accuracy: 2591/5000 (52%)\n",
      "[epoch 2] loss: 1.2343568\n",
      "Test set: Average loss: 1.1755, Accuracy: 2895/5000 (58%)\n",
      "[epoch 3] loss: 1.1173620\n",
      "Test set: Average loss: 1.1011, Accuracy: 3067/5000 (61%)\n",
      "[epoch 4] loss: 1.0367569\n",
      "Test set: Average loss: 1.1438, Accuracy: 3033/5000 (61%)\n",
      "[epoch 5] loss: 0.9680198\n",
      "Test set: Average loss: 1.0954, Accuracy: 3067/5000 (61%)\n",
      "[epoch 6] loss: 0.9026397\n",
      "Test set: Average loss: 1.0691, Accuracy: 3120/5000 (62%)\n",
      "[epoch 7] loss: 0.8329827\n",
      "Test set: Average loss: 1.0246, Accuracy: 3247/5000 (65%)\n",
      "[epoch 8] loss: 0.7671616\n",
      "Test set: Average loss: 1.0571, Accuracy: 3256/5000 (65%)\n",
      "[epoch 9] loss: 0.6975056\n",
      "Test set: Average loss: 1.0414, Accuracy: 3271/5000 (65%)\n",
      "[epoch 10] loss: 0.6273340\n",
      "Test set: Average loss: 1.1196, Accuracy: 3184/5000 (64%)\n",
      "[epoch 11] loss: 0.5632949\n",
      "Test set: Average loss: 1.1229, Accuracy: 3270/5000 (65%)\n",
      "[epoch 12] loss: 0.4916037\n",
      "Test set: Average loss: 1.1885, Accuracy: 3182/5000 (64%)\n",
      "[epoch 13] loss: 0.4300588\n",
      "Test set: Average loss: 1.2042, Accuracy: 3251/5000 (65%)\n",
      "[epoch 14] loss: 0.3713449\n",
      "Test set: Average loss: 1.3746, Accuracy: 3178/5000 (64%)\n",
      "[epoch 15] loss: 0.3295422\n",
      "Test set: Average loss: 1.3711, Accuracy: 3184/5000 (64%)\n",
      "[epoch 16] loss: 0.2910339\n",
      "Test set: Average loss: 1.4547, Accuracy: 3204/5000 (64%)\n",
      "[epoch 17] loss: 0.2802570\n",
      "Test set: Average loss: 1.5043, Accuracy: 3175/5000 (64%)\n",
      "[epoch 18] loss: 0.2374752\n",
      "Test set: Average loss: 1.5626, Accuracy: 3178/5000 (64%)\n",
      "[epoch 19] loss: 0.2469937\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5439, Accuracy: 3177/5000 (64%)\n",
      "[epoch 20] loss: 0.1003471\n",
      "Test set: Average loss: 1.4565, Accuracy: 3312/5000 (66%)\n",
      "[epoch 21] loss: 0.0421366\n",
      "Test set: Average loss: 1.4638, Accuracy: 3321/5000 (66%)\n",
      "[epoch 22] loss: 0.0254692\n",
      "Test set: Average loss: 1.4951, Accuracy: 3324/5000 (66%)\n",
      "[epoch 23] loss: 0.0165556\n",
      "Test set: Average loss: 1.5267, Accuracy: 3337/5000 (67%)\n",
      "[epoch 24] loss: 0.0111891\n",
      "Test set: Average loss: 1.5662, Accuracy: 3339/5000 (67%)\n",
      "[epoch 25] loss: 0.0074514\n",
      "Test set: Average loss: 1.6225, Accuracy: 3341/5000 (67%)\n",
      "[epoch 26] loss: 0.0051130\n",
      "Test set: Average loss: 1.6666, Accuracy: 3337/5000 (67%)\n",
      "[epoch 27] loss: 0.0033951\n",
      "Test set: Average loss: 1.7212, Accuracy: 3340/5000 (67%)\n",
      "[epoch 28] loss: 0.0023040\n",
      "Test set: Average loss: 1.7740, Accuracy: 3330/5000 (67%)\n",
      "[epoch 29] loss: 0.0016305\n",
      "Test set: Average loss: 1.8365, Accuracy: 3348/5000 (67%)\n",
      "[epoch 30] loss: 0.0010120\n",
      "Test set: Average loss: 1.8890, Accuracy: 3356/5000 (67%)\n",
      "[epoch 31] loss: 0.0006818\n",
      "Test set: Average loss: 1.9598, Accuracy: 3346/5000 (67%)\n",
      "[epoch 32] loss: 0.0004396\n",
      "Test set: Average loss: 2.0174, Accuracy: 3355/5000 (67%)\n",
      "[epoch 33] loss: 0.0002872\n",
      "Test set: Average loss: 2.0861, Accuracy: 3348/5000 (67%)\n",
      "[epoch 34] loss: 0.0001818\n",
      "Test set: Average loss: 2.1495, Accuracy: 3347/5000 (67%)\n",
      "[epoch 35] loss: 0.0001154\n",
      "Test set: Average loss: 2.2310, Accuracy: 3348/5000 (67%)\n",
      "[epoch 36] loss: 0.0000763\n",
      "Test set: Average loss: 2.3067, Accuracy: 3345/5000 (67%)\n",
      "[epoch 37] loss: 0.0000458\n",
      "Test set: Average loss: 2.3835, Accuracy: 3339/5000 (67%)\n",
      "[epoch 38] loss: 0.0000284\n",
      "Test set: Average loss: 2.4386, Accuracy: 3346/5000 (67%)\n",
      "[epoch 39] loss: 0.0000177\n",
      "Test set: Average loss: 2.5317, Accuracy: 3355/5000 (67%)\n",
      "[epoch 40] loss: 0.0000110\n",
      "Test set: Average loss: 2.6002, Accuracy: 3345/5000 (67%)\n",
      "[epoch 41] loss: 0.0000066\n",
      "Test set: Average loss: 2.6896, Accuracy: 3335/5000 (67%)\n",
      "[epoch 42] loss: 0.0000041\n",
      "Test set: Average loss: 2.7661, Accuracy: 3333/5000 (67%)\n",
      "[epoch 43] loss: 0.0006727\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.7851, Accuracy: 3301/5000 (66%)\n",
      "[epoch 44] loss: 0.0000423\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.7842, Accuracy: 3298/5000 (66%)\n",
      "[epoch 45] loss: 0.0000298\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.7841, Accuracy: 3299/5000 (66%)\n",
      "[epoch 46] loss: 0.0000293\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.7840, Accuracy: 3299/5000 (66%)\n",
      "[epoch 47] loss: 0.0000293\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.7840, Accuracy: 3299/5000 (66%)\n",
      "[epoch 48] loss: 0.0000292\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.7840, Accuracy: 3299/5000 (66%)\n",
      "[epoch 49] loss: 0.0000292\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.7840, Accuracy: 3299/5000 (66%)\n",
      "[epoch 50] loss: 0.0000292\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.7840, Accuracy: 3299/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8890, Accuracy: 3356/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 1.9500, Accuracy: 6690/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3007, Accuracy: 586/5000 (12%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4772524\n",
      "Test set: Average loss: 1.3116, Accuracy: 2622/5000 (52%)\n",
      "[epoch 2] loss: 1.2363826\n",
      "Test set: Average loss: 1.1922, Accuracy: 2884/5000 (58%)\n",
      "[epoch 3] loss: 1.1272796\n",
      "Test set: Average loss: 1.1548, Accuracy: 2927/5000 (59%)\n",
      "[epoch 4] loss: 1.0437555\n",
      "Test set: Average loss: 1.1280, Accuracy: 2991/5000 (60%)\n",
      "[epoch 5] loss: 0.9733307\n",
      "Test set: Average loss: 1.1407, Accuracy: 2988/5000 (60%)\n",
      "[epoch 6] loss: 0.9173340\n",
      "Test set: Average loss: 1.0437, Accuracy: 3202/5000 (64%)\n",
      "[epoch 7] loss: 0.8578837\n",
      "Test set: Average loss: 1.0357, Accuracy: 3195/5000 (64%)\n",
      "[epoch 8] loss: 0.7984637\n",
      "Test set: Average loss: 1.0787, Accuracy: 3151/5000 (63%)\n",
      "[epoch 9] loss: 0.7275570\n",
      "Test set: Average loss: 1.0653, Accuracy: 3173/5000 (63%)\n",
      "[epoch 10] loss: 0.6568033\n",
      "Test set: Average loss: 1.0789, Accuracy: 3225/5000 (64%)\n",
      "[epoch 11] loss: 0.5897492\n",
      "Test set: Average loss: 1.1161, Accuracy: 3176/5000 (64%)\n",
      "[epoch 12] loss: 0.5156526\n",
      "Test set: Average loss: 1.1702, Accuracy: 3212/5000 (64%)\n",
      "[epoch 13] loss: 0.4354033\n",
      "Test set: Average loss: 1.2512, Accuracy: 3180/5000 (64%)\n",
      "[epoch 14] loss: 0.3734590\n",
      "Test set: Average loss: 1.3248, Accuracy: 3160/5000 (63%)\n",
      "[epoch 15] loss: 0.3182592\n",
      "Test set: Average loss: 1.3873, Accuracy: 3151/5000 (63%)\n",
      "[epoch 16] loss: 0.2797143\n",
      "Test set: Average loss: 1.4285, Accuracy: 3189/5000 (64%)\n",
      "[epoch 17] loss: 0.2476016\n",
      "Test set: Average loss: 1.4749, Accuracy: 3119/5000 (62%)\n",
      "[epoch 18] loss: 0.2254330\n",
      "Test set: Average loss: 1.6194, Accuracy: 3112/5000 (62%)\n",
      "[epoch 19] loss: 0.2132139\n",
      "Test set: Average loss: 1.6352, Accuracy: 3152/5000 (63%)\n",
      "[epoch 20] loss: 0.2123380\n",
      "Test set: Average loss: 1.7393, Accuracy: 3099/5000 (62%)\n",
      "[epoch 21] loss: 0.1872481\n",
      "Test set: Average loss: 1.7667, Accuracy: 3079/5000 (62%)\n",
      "[epoch 22] loss: 0.2007201\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7395, Accuracy: 3151/5000 (63%)\n",
      "[epoch 23] loss: 0.0792328\n",
      "Test set: Average loss: 1.6640, Accuracy: 3225/5000 (64%)\n",
      "[epoch 24] loss: 0.0282873\n",
      "Test set: Average loss: 1.6816, Accuracy: 3227/5000 (65%)\n",
      "[epoch 25] loss: 0.0159367\n",
      "Test set: Average loss: 1.7026, Accuracy: 3246/5000 (65%)\n",
      "[epoch 26] loss: 0.0101680\n",
      "Test set: Average loss: 1.7396, Accuracy: 3270/5000 (65%)\n",
      "[epoch 27] loss: 0.0067801\n",
      "Test set: Average loss: 1.7724, Accuracy: 3252/5000 (65%)\n",
      "[epoch 28] loss: 0.0045325\n",
      "Test set: Average loss: 1.8135, Accuracy: 3266/5000 (65%)\n",
      "[epoch 29] loss: 0.0029959\n",
      "Test set: Average loss: 1.8573, Accuracy: 3272/5000 (65%)\n",
      "[epoch 30] loss: 0.0019563\n",
      "Test set: Average loss: 1.9105, Accuracy: 3256/5000 (65%)\n",
      "[epoch 31] loss: 0.0012867\n",
      "Test set: Average loss: 1.9545, Accuracy: 3267/5000 (65%)\n",
      "[epoch 32] loss: 0.0008307\n",
      "Test set: Average loss: 2.0115, Accuracy: 3275/5000 (66%)\n",
      "[epoch 33] loss: 0.0005327\n",
      "Test set: Average loss: 2.0701, Accuracy: 3267/5000 (65%)\n",
      "[epoch 34] loss: 0.0003446\n",
      "Test set: Average loss: 2.1454, Accuracy: 3263/5000 (65%)\n",
      "[epoch 35] loss: 0.0002179\n",
      "Test set: Average loss: 2.2031, Accuracy: 3279/5000 (66%)\n",
      "[epoch 36] loss: 0.0001385\n",
      "Test set: Average loss: 2.2772, Accuracy: 3276/5000 (66%)\n",
      "[epoch 37] loss: 0.0000868\n",
      "Test set: Average loss: 2.3397, Accuracy: 3279/5000 (66%)\n",
      "[epoch 38] loss: 0.0000543\n",
      "Test set: Average loss: 2.4090, Accuracy: 3268/5000 (65%)\n",
      "[epoch 39] loss: 0.0000337\n",
      "Test set: Average loss: 2.4878, Accuracy: 3261/5000 (65%)\n",
      "[epoch 40] loss: 0.0000208\n",
      "Test set: Average loss: 2.5587, Accuracy: 3261/5000 (65%)\n",
      "[epoch 41] loss: 0.0000128\n",
      "Test set: Average loss: 2.6465, Accuracy: 3260/5000 (65%)\n",
      "[epoch 42] loss: 0.0000079\n",
      "Test set: Average loss: 2.7091, Accuracy: 3257/5000 (65%)\n",
      "[epoch 43] loss: 0.0000048\n",
      "Test set: Average loss: 2.8035, Accuracy: 3250/5000 (65%)\n",
      "[epoch 44] loss: 0.0000029\n",
      "Test set: Average loss: 2.8725, Accuracy: 3252/5000 (65%)\n",
      "[epoch 45] loss: 0.0000018\n",
      "Test set: Average loss: 2.9506, Accuracy: 3264/5000 (65%)\n",
      "[epoch 46] loss: 0.0000015\n",
      "Test set: Average loss: 3.0097, Accuracy: 3255/5000 (65%)\n",
      "[epoch 47] loss: 0.0000007\n",
      "Test set: Average loss: 3.0345, Accuracy: 3266/5000 (65%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 3.0617, Accuracy: 3254/5000 (65%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.0831, Accuracy: 3257/5000 (65%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 3.0978, Accuracy: 3255/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3397, Accuracy: 3279/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.3470, Accuracy: 6597/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 437/5000 (9%)\n",
      "[epoch 1] loss: 1.4515893\n",
      "Test set: Average loss: 1.3733, Accuracy: 2476/5000 (50%)\n",
      "[epoch 2] loss: 1.2256670\n",
      "Test set: Average loss: 1.2027, Accuracy: 2849/5000 (57%)\n",
      "[epoch 3] loss: 1.1139104\n",
      "Test set: Average loss: 1.1439, Accuracy: 3004/5000 (60%)\n",
      "[epoch 4] loss: 1.0312342\n",
      "Test set: Average loss: 1.0977, Accuracy: 3109/5000 (62%)\n",
      "[epoch 5] loss: 0.9530664\n",
      "Test set: Average loss: 1.0578, Accuracy: 3161/5000 (63%)\n",
      "[epoch 6] loss: 0.8853937\n",
      "Test set: Average loss: 1.1180, Accuracy: 3112/5000 (62%)\n",
      "[epoch 7] loss: 0.8127857\n",
      "Test set: Average loss: 1.0053, Accuracy: 3241/5000 (65%)\n",
      "[epoch 8] loss: 0.7379101\n",
      "Test set: Average loss: 1.0221, Accuracy: 3273/5000 (65%)\n",
      "[epoch 9] loss: 0.6599395\n",
      "Test set: Average loss: 1.0593, Accuracy: 3270/5000 (65%)\n",
      "[epoch 10] loss: 0.5816132\n",
      "Test set: Average loss: 1.1395, Accuracy: 3217/5000 (64%)\n",
      "[epoch 11] loss: 0.5063128\n",
      "Test set: Average loss: 1.1771, Accuracy: 3206/5000 (64%)\n",
      "[epoch 12] loss: 0.4340828\n",
      "Test set: Average loss: 1.1645, Accuracy: 3308/5000 (66%)\n",
      "[epoch 13] loss: 0.3518606\n",
      "Test set: Average loss: 1.2584, Accuracy: 3279/5000 (66%)\n",
      "[epoch 14] loss: 0.3022426\n",
      "Test set: Average loss: 1.3578, Accuracy: 3230/5000 (65%)\n",
      "[epoch 15] loss: 0.2572731\n",
      "Test set: Average loss: 1.4274, Accuracy: 3229/5000 (65%)\n",
      "[epoch 16] loss: 0.2218999\n",
      "Test set: Average loss: 1.5011, Accuracy: 3217/5000 (64%)\n",
      "[epoch 17] loss: 0.2128564\n",
      "Test set: Average loss: 1.5999, Accuracy: 3227/5000 (65%)\n",
      "[epoch 18] loss: 0.2093595\n",
      "Test set: Average loss: 1.6332, Accuracy: 3198/5000 (64%)\n",
      "[epoch 19] loss: 0.1825805\n",
      "Test set: Average loss: 1.6268, Accuracy: 3212/5000 (64%)\n",
      "[epoch 20] loss: 0.1796904\n",
      "Test set: Average loss: 1.7880, Accuracy: 3184/5000 (64%)\n",
      "[epoch 21] loss: 0.1921328\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7818, Accuracy: 3170/5000 (63%)\n",
      "[epoch 22] loss: 0.0720285\n",
      "Test set: Average loss: 1.6734, Accuracy: 3309/5000 (66%)\n",
      "[epoch 23] loss: 0.0244676\n",
      "Test set: Average loss: 1.6806, Accuracy: 3305/5000 (66%)\n",
      "[epoch 24] loss: 0.0135033\n",
      "Test set: Average loss: 1.7012, Accuracy: 3323/5000 (66%)\n",
      "[epoch 25] loss: 0.0085567\n",
      "Test set: Average loss: 1.7357, Accuracy: 3322/5000 (66%)\n",
      "[epoch 26] loss: 0.0055609\n",
      "Test set: Average loss: 1.7662, Accuracy: 3320/5000 (66%)\n",
      "[epoch 27] loss: 0.0036380\n",
      "Test set: Average loss: 1.8081, Accuracy: 3315/5000 (66%)\n",
      "[epoch 28] loss: 0.0023510\n",
      "Test set: Average loss: 1.8505, Accuracy: 3330/5000 (67%)\n",
      "[epoch 29] loss: 0.0014894\n",
      "Test set: Average loss: 1.9074, Accuracy: 3331/5000 (67%)\n",
      "[epoch 30] loss: 0.0009420\n",
      "Test set: Average loss: 1.9584, Accuracy: 3335/5000 (67%)\n",
      "[epoch 31] loss: 0.0005949\n",
      "Test set: Average loss: 2.0293, Accuracy: 3332/5000 (67%)\n",
      "[epoch 32] loss: 0.0003708\n",
      "Test set: Average loss: 2.0874, Accuracy: 3349/5000 (67%)\n",
      "[epoch 33] loss: 0.0002281\n",
      "Test set: Average loss: 2.1574, Accuracy: 3340/5000 (67%)\n",
      "[epoch 34] loss: 0.0001410\n",
      "Test set: Average loss: 2.2259, Accuracy: 3348/5000 (67%)\n",
      "[epoch 35] loss: 0.0000863\n",
      "Test set: Average loss: 2.3041, Accuracy: 3338/5000 (67%)\n",
      "[epoch 36] loss: 0.0000519\n",
      "Test set: Average loss: 2.3751, Accuracy: 3345/5000 (67%)\n",
      "[epoch 37] loss: 0.0000313\n",
      "Test set: Average loss: 2.4481, Accuracy: 3351/5000 (67%)\n",
      "[epoch 38] loss: 0.0000187\n",
      "Test set: Average loss: 2.5158, Accuracy: 3345/5000 (67%)\n",
      "[epoch 39] loss: 0.0000111\n",
      "Test set: Average loss: 2.6039, Accuracy: 3350/5000 (67%)\n",
      "[epoch 40] loss: 0.0000067\n",
      "Test set: Average loss: 2.6851, Accuracy: 3348/5000 (67%)\n",
      "[epoch 41] loss: 0.0000039\n",
      "Test set: Average loss: 2.7557, Accuracy: 3342/5000 (67%)\n",
      "[epoch 42] loss: 0.0000023\n",
      "Test set: Average loss: 2.8477, Accuracy: 3326/5000 (67%)\n",
      "[epoch 43] loss: 0.0000013\n",
      "Test set: Average loss: 2.9085, Accuracy: 3350/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 44] loss: 0.0000008\n",
      "Test set: Average loss: 2.9613, Accuracy: 3345/5000 (67%)\n",
      "[epoch 45] loss: 0.0000005\n",
      "Test set: Average loss: 2.9953, Accuracy: 3338/5000 (67%)\n",
      "[epoch 46] loss: 0.0000003\n",
      "Test set: Average loss: 3.0101, Accuracy: 3344/5000 (67%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 3.0243, Accuracy: 3339/5000 (67%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.0307, Accuracy: 3339/5000 (67%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0431, Accuracy: 3337/5000 (67%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.0690, Accuracy: 3336/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4481, Accuracy: 3351/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.4256, Accuracy: 6772/10000 (68%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train AE (on full train dataset)\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = AE(cnn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=0, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader_all):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('[epoch %d] loss: %.7f' % (epoch + 1, running_loss / (batch_idx + 1)))\n",
    "    lr_scheduler.step(running_loss)\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.encoder.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# check how well some test images match\n",
    "model.eval()\n",
    "dataiter = iter(test_loader_all)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images[:5]))\n",
    "images = images.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructed_images = model(images).cpu()\n",
    "    imshow(torchvision.utils.make_grid(reconstructed_images[:5]))\n",
    "plt.title(' '.join('%13s' % classes[labels[j]] for j in range(5)))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_ae = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_ae.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:30:22.258978Z",
     "start_time": "2019-07-24T06:49:34.514029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.3140151\n",
      "[epoch 2] loss: 0.1904510\n",
      "[epoch 3] loss: 0.1650867\n",
      "[epoch 4] loss: 0.1515929\n",
      "[epoch 5] loss: 0.1440110\n",
      "[epoch 6] loss: 0.1379243\n",
      "[epoch 7] loss: 0.1343180\n",
      "[epoch 8] loss: 0.1309230\n",
      "[epoch 9] loss: 0.1283125\n",
      "[epoch 10] loss: 0.1257787\n",
      "[epoch 11] loss: 0.1235788\n",
      "[epoch 12] loss: 0.1218627\n",
      "[epoch 13] loss: 0.1199178\n",
      "[epoch 14] loss: 0.1183935\n",
      "[epoch 15] loss: 0.1170878\n",
      "[epoch 16] loss: 0.1154505\n",
      "[epoch 17] loss: 0.1139176\n",
      "[epoch 18] loss: 0.1133424\n",
      "[epoch 19] loss: 0.1120388\n",
      "[epoch 20] loss: 0.1113448\n",
      "[epoch 21] loss: 0.1101913\n",
      "[epoch 22] loss: 0.1091934\n",
      "[epoch 23] loss: 0.1087638\n",
      "[epoch 24] loss: 0.1078929\n",
      "[epoch 25] loss: 0.1073619\n",
      "[epoch 26] loss: 0.1068852\n",
      "[epoch 27] loss: 0.1060686\n",
      "[epoch 28] loss: 0.1060049\n",
      "[epoch 29] loss: 0.1050254\n",
      "[epoch 30] loss: 0.1044404\n",
      "[epoch 31] loss: 0.1042162\n",
      "[epoch 32] loss: 0.1033754\n",
      "[epoch 33] loss: 0.1023266\n",
      "[epoch 34] loss: 0.1022135\n",
      "[epoch 35] loss: 0.1020204\n",
      "[epoch 36] loss: 0.1015543\n",
      "[epoch 37] loss: 0.1012570\n",
      "[epoch 38] loss: 0.1009188\n",
      "[epoch 39] loss: 0.1010246\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[epoch 40] loss: 0.0899939\n",
      "[epoch 41] loss: 0.0890622\n",
      "[epoch 42] loss: 0.0887526\n",
      "[epoch 43] loss: 0.0885362\n",
      "[epoch 44] loss: 0.0883126\n",
      "[epoch 45] loss: 0.0881650\n",
      "[epoch 46] loss: 0.0880143\n",
      "[epoch 47] loss: 0.0879076\n",
      "[epoch 48] loss: 0.0877895\n",
      "[epoch 49] loss: 0.0876634\n",
      "[epoch 50] loss: 0.0875875\n",
      "Took 442 sec to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3124, Accuracy: 369/5000 (7%)\n",
      "[epoch 1] loss: 2.3194385\n",
      "Test set: Average loss: 2.3712, Accuracy: 482/5000 (10%)\n",
      "[epoch 2] loss: 2.0320985\n",
      "Test set: Average loss: 2.5460, Accuracy: 481/5000 (10%)\n",
      "[epoch 3] loss: 1.8644969\n",
      "Test set: Average loss: 2.6358, Accuracy: 523/5000 (10%)\n",
      "[epoch 4] loss: 1.6967750\n",
      "Test set: Average loss: 2.6303, Accuracy: 665/5000 (13%)\n",
      "[epoch 5] loss: 1.4961116\n",
      "Test set: Average loss: 2.6269, Accuracy: 665/5000 (13%)\n",
      "[epoch 6] loss: 1.2814310\n",
      "Test set: Average loss: 2.6580, Accuracy: 668/5000 (13%)\n",
      "[epoch 7] loss: 1.0566111\n",
      "Test set: Average loss: 2.7179, Accuracy: 678/5000 (14%)\n",
      "[epoch 8] loss: 0.8253591\n",
      "Test set: Average loss: 2.7996, Accuracy: 725/5000 (14%)\n",
      "[epoch 9] loss: 0.6121258\n",
      "Test set: Average loss: 2.9055, Accuracy: 752/5000 (15%)\n",
      "[epoch 10] loss: 0.4349628\n",
      "Test set: Average loss: 3.0385, Accuracy: 770/5000 (15%)\n",
      "[epoch 11] loss: 0.2968901\n",
      "Test set: Average loss: 3.1974, Accuracy: 782/5000 (16%)\n",
      "[epoch 12] loss: 0.1967876\n",
      "Test set: Average loss: 3.3743, Accuracy: 784/5000 (16%)\n",
      "[epoch 13] loss: 0.1294801\n",
      "Test set: Average loss: 3.5578, Accuracy: 782/5000 (16%)\n",
      "[epoch 14] loss: 0.0851735\n",
      "Test set: Average loss: 3.7409, Accuracy: 781/5000 (16%)\n",
      "[epoch 15] loss: 0.0562719\n",
      "Test set: Average loss: 3.9207, Accuracy: 777/5000 (16%)\n",
      "[epoch 16] loss: 0.0374555\n",
      "Test set: Average loss: 4.0927, Accuracy: 777/5000 (16%)\n",
      "[epoch 17] loss: 0.0252087\n",
      "Test set: Average loss: 4.2526, Accuracy: 776/5000 (16%)\n",
      "[epoch 18] loss: 0.0173522\n",
      "Test set: Average loss: 4.3972, Accuracy: 776/5000 (16%)\n",
      "[epoch 19] loss: 0.0123559\n",
      "Test set: Average loss: 4.5248, Accuracy: 775/5000 (16%)\n",
      "[epoch 20] loss: 0.0091225\n",
      "Test set: Average loss: 4.6360, Accuracy: 773/5000 (15%)\n",
      "[epoch 21] loss: 0.0069590\n",
      "Test set: Average loss: 4.7326, Accuracy: 780/5000 (16%)\n",
      "[epoch 22] loss: 0.0054608\n",
      "Test set: Average loss: 4.8172, Accuracy: 775/5000 (16%)\n",
      "[epoch 23] loss: 0.0043889\n",
      "Test set: Average loss: 4.8920, Accuracy: 767/5000 (15%)\n",
      "[epoch 24] loss: 0.0035984\n",
      "Test set: Average loss: 4.9590, Accuracy: 767/5000 (15%)\n",
      "[epoch 25] loss: 0.0030017\n",
      "Test set: Average loss: 5.0200, Accuracy: 772/5000 (15%)\n",
      "[epoch 26] loss: 0.0025418\n",
      "Test set: Average loss: 5.0761, Accuracy: 774/5000 (15%)\n",
      "[epoch 27] loss: 0.0021803\n",
      "Test set: Average loss: 5.1282, Accuracy: 777/5000 (16%)\n",
      "[epoch 28] loss: 0.0018911\n",
      "Test set: Average loss: 5.1770, Accuracy: 777/5000 (16%)\n",
      "[epoch 29] loss: 0.0016562\n",
      "Test set: Average loss: 5.2229, Accuracy: 781/5000 (16%)\n",
      "[epoch 30] loss: 0.0014629\n",
      "Test set: Average loss: 5.2663, Accuracy: 781/5000 (16%)\n",
      "[epoch 31] loss: 0.0013020\n",
      "Test set: Average loss: 5.3074, Accuracy: 783/5000 (16%)\n",
      "[epoch 32] loss: 0.0011669\n",
      "Test set: Average loss: 5.3463, Accuracy: 783/5000 (16%)\n",
      "[epoch 33] loss: 0.0010526\n",
      "Test set: Average loss: 5.3833, Accuracy: 786/5000 (16%)\n",
      "[epoch 34] loss: 0.0009554\n",
      "Test set: Average loss: 5.4183, Accuracy: 786/5000 (16%)\n",
      "[epoch 35] loss: 0.0008719\n",
      "Test set: Average loss: 5.4515, Accuracy: 787/5000 (16%)\n",
      "[epoch 36] loss: 0.0008000\n",
      "Test set: Average loss: 5.4829, Accuracy: 783/5000 (16%)\n",
      "[epoch 37] loss: 0.0007378\n",
      "Test set: Average loss: 5.5127, Accuracy: 783/5000 (16%)\n",
      "[epoch 38] loss: 0.0006838\n",
      "Test set: Average loss: 5.5408, Accuracy: 779/5000 (16%)\n",
      "[epoch 39] loss: 0.0006367\n",
      "Test set: Average loss: 5.5674, Accuracy: 781/5000 (16%)\n",
      "[epoch 40] loss: 0.0005952\n",
      "Test set: Average loss: 5.5925, Accuracy: 780/5000 (16%)\n",
      "[epoch 41] loss: 0.0005590\n",
      "Test set: Average loss: 5.6161, Accuracy: 783/5000 (16%)\n",
      "[epoch 42] loss: 0.0005268\n",
      "Test set: Average loss: 5.6384, Accuracy: 784/5000 (16%)\n",
      "[epoch 43] loss: 0.0004984\n",
      "Test set: Average loss: 5.6593, Accuracy: 786/5000 (16%)\n",
      "[epoch 44] loss: 0.0004729\n",
      "Test set: Average loss: 5.6789, Accuracy: 785/5000 (16%)\n",
      "[epoch 45] loss: 0.0004504\n",
      "Test set: Average loss: 5.6974, Accuracy: 783/5000 (16%)\n",
      "[epoch 46] loss: 0.0004300\n",
      "Test set: Average loss: 5.7147, Accuracy: 783/5000 (16%)\n",
      "[epoch 47] loss: 0.0004117\n",
      "Test set: Average loss: 5.7309, Accuracy: 782/5000 (16%)\n",
      "[epoch 48] loss: 0.0003952\n",
      "Test set: Average loss: 5.7461, Accuracy: 782/5000 (16%)\n",
      "[epoch 49] loss: 0.0003803\n",
      "Test set: Average loss: 5.7603, Accuracy: 782/5000 (16%)\n",
      "[epoch 50] loss: 0.0003667\n",
      "Test set: Average loss: 5.7736, Accuracy: 785/5000 (16%)\n",
      "Validation:\n",
      "Test set: Average loss: 5.4515, Accuracy: 787/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 5.3480, Accuracy: 1668/10000 (17%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3107, Accuracy: 463/5000 (9%)\n",
      "[epoch 1] loss: 2.3321960\n",
      "Test set: Average loss: 2.3691, Accuracy: 496/5000 (10%)\n",
      "[epoch 2] loss: 2.0766001\n",
      "Test set: Average loss: 2.4892, Accuracy: 530/5000 (11%)\n",
      "[epoch 3] loss: 1.8962982\n",
      "Test set: Average loss: 2.5516, Accuracy: 673/5000 (13%)\n",
      "[epoch 4] loss: 1.7024286\n",
      "Test set: Average loss: 2.6049, Accuracy: 710/5000 (14%)\n",
      "[epoch 5] loss: 1.4945751\n",
      "Test set: Average loss: 2.6617, Accuracy: 741/5000 (15%)\n",
      "[epoch 6] loss: 1.2617276\n",
      "Test set: Average loss: 2.7337, Accuracy: 769/5000 (15%)\n",
      "[epoch 7] loss: 1.0319053\n",
      "Test set: Average loss: 2.8264, Accuracy: 781/5000 (16%)\n",
      "[epoch 8] loss: 0.8269212\n",
      "Test set: Average loss: 2.9359, Accuracy: 800/5000 (16%)\n",
      "[epoch 9] loss: 0.6424339\n",
      "Test set: Average loss: 3.0590, Accuracy: 784/5000 (16%)\n",
      "[epoch 10] loss: 0.4749361\n",
      "Test set: Average loss: 3.1928, Accuracy: 762/5000 (15%)\n",
      "[epoch 11] loss: 0.3322488\n",
      "Test set: Average loss: 3.3360, Accuracy: 752/5000 (15%)\n",
      "[epoch 12] loss: 0.2245648\n",
      "Test set: Average loss: 3.4833, Accuracy: 751/5000 (15%)\n",
      "[epoch 13] loss: 0.1496264\n",
      "Test set: Average loss: 3.6284, Accuracy: 762/5000 (15%)\n",
      "[epoch 14] loss: 0.0985698\n",
      "Test set: Average loss: 3.7674, Accuracy: 759/5000 (15%)\n",
      "[epoch 15] loss: 0.0646968\n",
      "Test set: Average loss: 3.8992, Accuracy: 755/5000 (15%)\n",
      "[epoch 16] loss: 0.0431582\n",
      "Test set: Average loss: 4.0230, Accuracy: 749/5000 (15%)\n",
      "[epoch 17] loss: 0.0297801\n",
      "Test set: Average loss: 4.1392, Accuracy: 760/5000 (15%)\n",
      "[epoch 18] loss: 0.0213701\n",
      "Test set: Average loss: 4.2482, Accuracy: 754/5000 (15%)\n",
      "[epoch 19] loss: 0.0158306\n",
      "Test set: Average loss: 4.3506, Accuracy: 753/5000 (15%)\n",
      "[epoch 20] loss: 0.0119832\n",
      "Test set: Average loss: 4.4469, Accuracy: 751/5000 (15%)\n",
      "[epoch 21] loss: 0.0092194\n",
      "Test set: Average loss: 4.5373, Accuracy: 749/5000 (15%)\n",
      "[epoch 22] loss: 0.0072019\n",
      "Test set: Average loss: 4.6219, Accuracy: 755/5000 (15%)\n",
      "[epoch 23] loss: 0.0057160\n",
      "Test set: Average loss: 4.7007, Accuracy: 755/5000 (15%)\n",
      "[epoch 24] loss: 0.0046151\n",
      "Test set: Average loss: 4.7739, Accuracy: 760/5000 (15%)\n",
      "[epoch 25] loss: 0.0037903\n",
      "Test set: Average loss: 4.8414, Accuracy: 759/5000 (15%)\n",
      "[epoch 26] loss: 0.0031655\n",
      "Test set: Average loss: 4.9037, Accuracy: 758/5000 (15%)\n",
      "[epoch 27] loss: 0.0026867\n",
      "Test set: Average loss: 4.9609, Accuracy: 762/5000 (15%)\n",
      "[epoch 28] loss: 0.0023145\n",
      "Test set: Average loss: 5.0134, Accuracy: 763/5000 (15%)\n",
      "[epoch 29] loss: 0.0020205\n",
      "Test set: Average loss: 5.0616, Accuracy: 762/5000 (15%)\n",
      "[epoch 30] loss: 0.0017852\n",
      "Test set: Average loss: 5.1059, Accuracy: 768/5000 (15%)\n",
      "[epoch 31] loss: 0.0015938\n",
      "Test set: Average loss: 5.1465, Accuracy: 770/5000 (15%)\n",
      "[epoch 32] loss: 0.0014362\n",
      "Test set: Average loss: 5.1838, Accuracy: 770/5000 (15%)\n",
      "[epoch 33] loss: 0.0013048\n",
      "Test set: Average loss: 5.2181, Accuracy: 770/5000 (15%)\n",
      "[epoch 34] loss: 0.0011938\n",
      "Test set: Average loss: 5.2496, Accuracy: 768/5000 (15%)\n",
      "[epoch 35] loss: 0.0010991\n",
      "Test set: Average loss: 5.2788, Accuracy: 765/5000 (15%)\n",
      "[epoch 36] loss: 0.0010173\n",
      "Test set: Average loss: 5.3056, Accuracy: 761/5000 (15%)\n",
      "[epoch 37] loss: 0.0009462\n",
      "Test set: Average loss: 5.3304, Accuracy: 763/5000 (15%)\n",
      "[epoch 38] loss: 0.0008838\n",
      "Test set: Average loss: 5.3534, Accuracy: 764/5000 (15%)\n",
      "[epoch 39] loss: 0.0008290\n",
      "Test set: Average loss: 5.3747, Accuracy: 765/5000 (15%)\n",
      "[epoch 40] loss: 0.0007803\n",
      "Test set: Average loss: 5.3944, Accuracy: 763/5000 (15%)\n",
      "[epoch 41] loss: 0.0007370\n",
      "Test set: Average loss: 5.4128, Accuracy: 762/5000 (15%)\n",
      "[epoch 42] loss: 0.0006983\n",
      "Test set: Average loss: 5.4299, Accuracy: 763/5000 (15%)\n",
      "[epoch 43] loss: 0.0006637\n",
      "Test set: Average loss: 5.4458, Accuracy: 764/5000 (15%)\n",
      "[epoch 44] loss: 0.0006326\n",
      "Test set: Average loss: 5.4606, Accuracy: 763/5000 (15%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] loss: 0.0006046\n",
      "Test set: Average loss: 5.4744, Accuracy: 764/5000 (15%)\n",
      "[epoch 46] loss: 0.0005793\n",
      "Test set: Average loss: 5.4874, Accuracy: 765/5000 (15%)\n",
      "[epoch 47] loss: 0.0005564\n",
      "Test set: Average loss: 5.4995, Accuracy: 766/5000 (15%)\n",
      "[epoch 48] loss: 0.0005356\n",
      "Test set: Average loss: 5.5109, Accuracy: 766/5000 (15%)\n",
      "[epoch 49] loss: 0.0005167\n",
      "Test set: Average loss: 5.5215, Accuracy: 765/5000 (15%)\n",
      "[epoch 50] loss: 0.0004994\n",
      "Test set: Average loss: 5.5316, Accuracy: 766/5000 (15%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9359, Accuracy: 800/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 2.9390, Accuracy: 1645/10000 (16%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2975, Accuracy: 583/5000 (12%)\n",
      "[epoch 1] loss: 2.3010540\n",
      "Test set: Average loss: 2.3784, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 1.9819212\n",
      "Test set: Average loss: 2.5992, Accuracy: 525/5000 (10%)\n",
      "[epoch 3] loss: 1.8244373\n",
      "Test set: Average loss: 2.6642, Accuracy: 554/5000 (11%)\n",
      "[epoch 4] loss: 1.6528946\n",
      "Test set: Average loss: 2.6418, Accuracy: 764/5000 (15%)\n",
      "[epoch 5] loss: 1.4408622\n",
      "Test set: Average loss: 2.6061, Accuracy: 766/5000 (15%)\n",
      "[epoch 6] loss: 1.2163458\n",
      "Test set: Average loss: 2.6073, Accuracy: 748/5000 (15%)\n",
      "[epoch 7] loss: 1.0056757\n",
      "Test set: Average loss: 2.6569, Accuracy: 744/5000 (15%)\n",
      "[epoch 8] loss: 0.8244656\n",
      "Test set: Average loss: 2.7386, Accuracy: 768/5000 (15%)\n",
      "[epoch 9] loss: 0.6635312\n",
      "Test set: Average loss: 2.8498, Accuracy: 766/5000 (15%)\n",
      "[epoch 10] loss: 0.5216902\n",
      "Test set: Average loss: 2.9988, Accuracy: 750/5000 (15%)\n",
      "[epoch 11] loss: 0.4021780\n",
      "Test set: Average loss: 3.1748, Accuracy: 737/5000 (15%)\n",
      "[epoch 12] loss: 0.2994626\n",
      "Test set: Average loss: 3.3446, Accuracy: 729/5000 (15%)\n",
      "[epoch 13] loss: 0.2121032\n",
      "Test set: Average loss: 3.4969, Accuracy: 728/5000 (15%)\n",
      "[epoch 14] loss: 0.1455359\n",
      "Test set: Average loss: 3.6340, Accuracy: 730/5000 (15%)\n",
      "[epoch 15] loss: 0.1018104\n",
      "Test set: Average loss: 3.7502, Accuracy: 737/5000 (15%)\n",
      "[epoch 16] loss: 0.0719195\n",
      "Test set: Average loss: 3.8462, Accuracy: 761/5000 (15%)\n",
      "[epoch 17] loss: 0.0503413\n",
      "Test set: Average loss: 3.9304, Accuracy: 756/5000 (15%)\n",
      "[epoch 18] loss: 0.0360787\n",
      "Test set: Average loss: 4.0095, Accuracy: 747/5000 (15%)\n",
      "[epoch 19] loss: 0.0268691\n",
      "Test set: Average loss: 4.0869, Accuracy: 740/5000 (15%)\n",
      "[epoch 20] loss: 0.0206055\n",
      "Test set: Average loss: 4.1640, Accuracy: 736/5000 (15%)\n",
      "[epoch 21] loss: 0.0160423\n",
      "Test set: Average loss: 4.2405, Accuracy: 731/5000 (15%)\n",
      "[epoch 22] loss: 0.0125727\n",
      "Test set: Average loss: 4.3153, Accuracy: 734/5000 (15%)\n",
      "[epoch 23] loss: 0.0099011\n",
      "Test set: Average loss: 4.3877, Accuracy: 730/5000 (15%)\n",
      "[epoch 24] loss: 0.0078587\n",
      "Test set: Average loss: 4.4574, Accuracy: 728/5000 (15%)\n",
      "[epoch 25] loss: 0.0063134\n",
      "Test set: Average loss: 4.5240, Accuracy: 729/5000 (15%)\n",
      "[epoch 26] loss: 0.0051481\n",
      "Test set: Average loss: 4.5876, Accuracy: 734/5000 (15%)\n",
      "[epoch 27] loss: 0.0042663\n",
      "Test set: Average loss: 4.6480, Accuracy: 732/5000 (15%)\n",
      "[epoch 28] loss: 0.0035930\n",
      "Test set: Average loss: 4.7051, Accuracy: 733/5000 (15%)\n",
      "[epoch 29] loss: 0.0030711\n",
      "Test set: Average loss: 4.7589, Accuracy: 734/5000 (15%)\n",
      "[epoch 30] loss: 0.0026603\n",
      "Test set: Average loss: 4.8094, Accuracy: 732/5000 (15%)\n",
      "[epoch 31] loss: 0.0023311\n",
      "Test set: Average loss: 4.8565, Accuracy: 731/5000 (15%)\n",
      "[epoch 32] loss: 0.0020634\n",
      "Test set: Average loss: 4.9002, Accuracy: 729/5000 (15%)\n",
      "[epoch 33] loss: 0.0018429\n",
      "Test set: Average loss: 4.9408, Accuracy: 729/5000 (15%)\n",
      "[epoch 34] loss: 0.0016588\n",
      "Test set: Average loss: 4.9782, Accuracy: 727/5000 (15%)\n",
      "[epoch 35] loss: 0.0015040\n",
      "Test set: Average loss: 5.0127, Accuracy: 723/5000 (14%)\n",
      "[epoch 36] loss: 0.0013726\n",
      "Test set: Average loss: 5.0445, Accuracy: 720/5000 (14%)\n",
      "[epoch 37] loss: 0.0012603\n",
      "Test set: Average loss: 5.0737, Accuracy: 721/5000 (14%)\n",
      "[epoch 38] loss: 0.0011638\n",
      "Test set: Average loss: 5.1006, Accuracy: 720/5000 (14%)\n",
      "[epoch 39] loss: 0.0010806\n",
      "Test set: Average loss: 5.1253, Accuracy: 717/5000 (14%)\n",
      "[epoch 40] loss: 0.0010081\n",
      "Test set: Average loss: 5.1481, Accuracy: 717/5000 (14%)\n",
      "[epoch 41] loss: 0.0009449\n",
      "Test set: Average loss: 5.1690, Accuracy: 717/5000 (14%)\n",
      "[epoch 42] loss: 0.0008897\n",
      "Test set: Average loss: 5.1883, Accuracy: 717/5000 (14%)\n",
      "[epoch 43] loss: 0.0008409\n",
      "Test set: Average loss: 5.2060, Accuracy: 716/5000 (14%)\n",
      "[epoch 44] loss: 0.0007979\n",
      "Test set: Average loss: 5.2225, Accuracy: 715/5000 (14%)\n",
      "[epoch 45] loss: 0.0007595\n",
      "Test set: Average loss: 5.2377, Accuracy: 715/5000 (14%)\n",
      "[epoch 46] loss: 0.0007255\n",
      "Test set: Average loss: 5.2518, Accuracy: 716/5000 (14%)\n",
      "[epoch 47] loss: 0.0006948\n",
      "Test set: Average loss: 5.2649, Accuracy: 716/5000 (14%)\n",
      "[epoch 48] loss: 0.0006674\n",
      "Test set: Average loss: 5.2770, Accuracy: 716/5000 (14%)\n",
      "[epoch 49] loss: 0.0006428\n",
      "Test set: Average loss: 5.2884, Accuracy: 717/5000 (14%)\n",
      "[epoch 50] loss: 0.0006203\n",
      "Test set: Average loss: 5.2989, Accuracy: 716/5000 (14%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7386, Accuracy: 768/5000 (15%)\n",
      "Test\n",
      "Test set: Average loss: 2.7476, Accuracy: 1490/10000 (15%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3115, Accuracy: 560/5000 (11%)\n",
      "[epoch 1] loss: 2.3362708\n",
      "Test set: Average loss: 2.3884, Accuracy: 494/5000 (10%)\n",
      "[epoch 2] loss: 2.0651234\n",
      "Test set: Average loss: 2.4643, Accuracy: 774/5000 (15%)\n",
      "[epoch 3] loss: 1.8155985\n",
      "Test set: Average loss: 2.4664, Accuracy: 790/5000 (16%)\n",
      "[epoch 4] loss: 1.6896034\n",
      "Test set: Average loss: 2.5536, Accuracy: 740/5000 (15%)\n",
      "[epoch 5] loss: 1.4305405\n",
      "Test set: Average loss: 2.6114, Accuracy: 819/5000 (16%)\n",
      "[epoch 6] loss: 1.1641602\n",
      "Test set: Average loss: 2.6319, Accuracy: 931/5000 (19%)\n",
      "[epoch 7] loss: 0.8942410\n",
      "Test set: Average loss: 2.7037, Accuracy: 986/5000 (20%)\n",
      "[epoch 8] loss: 0.7341743\n",
      "Test set: Average loss: 2.8249, Accuracy: 976/5000 (20%)\n",
      "[epoch 9] loss: 0.5940175\n",
      "Test set: Average loss: 2.8994, Accuracy: 967/5000 (19%)\n",
      "[epoch 10] loss: 0.3974367\n",
      "Test set: Average loss: 2.9561, Accuracy: 1001/5000 (20%)\n",
      "[epoch 11] loss: 0.2783254\n",
      "Test set: Average loss: 3.0688, Accuracy: 1012/5000 (20%)\n",
      "[epoch 12] loss: 0.2046861\n",
      "Test set: Average loss: 3.2253, Accuracy: 986/5000 (20%)\n",
      "[epoch 13] loss: 0.1358393\n",
      "Test set: Average loss: 3.3656, Accuracy: 1003/5000 (20%)\n",
      "[epoch 14] loss: 0.0887500\n",
      "Test set: Average loss: 3.4718, Accuracy: 1029/5000 (21%)\n",
      "[epoch 15] loss: 0.0573744\n",
      "Test set: Average loss: 3.5684, Accuracy: 1045/5000 (21%)\n",
      "[epoch 16] loss: 0.0460168\n",
      "Test set: Average loss: 3.6712, Accuracy: 1033/5000 (21%)\n",
      "[epoch 17] loss: 0.0332544\n",
      "Test set: Average loss: 3.7858, Accuracy: 1018/5000 (20%)\n",
      "[epoch 18] loss: 0.0242220\n",
      "Test set: Average loss: 3.8952, Accuracy: 998/5000 (20%)\n",
      "[epoch 19] loss: 0.0189012\n",
      "Test set: Average loss: 4.0007, Accuracy: 978/5000 (20%)\n",
      "[epoch 20] loss: 0.0149307\n",
      "Test set: Average loss: 4.0891, Accuracy: 966/5000 (19%)\n",
      "[epoch 21] loss: 0.0129284\n",
      "Test set: Average loss: 4.1629, Accuracy: 959/5000 (19%)\n",
      "[epoch 22] loss: 0.0104758\n",
      "Test set: Average loss: 4.2185, Accuracy: 967/5000 (19%)\n",
      "[epoch 23] loss: 0.0088989\n",
      "Test set: Average loss: 4.2607, Accuracy: 974/5000 (19%)\n",
      "[epoch 24] loss: 0.0076968\n",
      "Test set: Average loss: 4.2977, Accuracy: 976/5000 (20%)\n",
      "[epoch 25] loss: 0.0067119\n",
      "Test set: Average loss: 4.3300, Accuracy: 985/5000 (20%)\n",
      "[epoch 26] loss: 0.0059148\n",
      "Test set: Average loss: 4.3612, Accuracy: 989/5000 (20%)\n",
      "[epoch 27] loss: 0.0055029\n",
      "Test set: Average loss: 4.3923, Accuracy: 999/5000 (20%)\n",
      "[epoch 28] loss: 0.0048459\n",
      "Test set: Average loss: 4.4232, Accuracy: 999/5000 (20%)\n",
      "[epoch 29] loss: 0.0045322\n",
      "Test set: Average loss: 4.4540, Accuracy: 1001/5000 (20%)\n",
      "[epoch 30] loss: 0.0039870\n",
      "Test set: Average loss: 4.4828, Accuracy: 998/5000 (20%)\n",
      "[epoch 31] loss: 0.0037299\n",
      "Test set: Average loss: 4.5084, Accuracy: 997/5000 (20%)\n",
      "[epoch 32] loss: 0.0035456\n",
      "Test set: Average loss: 4.5306, Accuracy: 1000/5000 (20%)\n",
      "[epoch 33] loss: 0.0033022\n",
      "Test set: Average loss: 4.5495, Accuracy: 1000/5000 (20%)\n",
      "[epoch 34] loss: 0.0031114\n",
      "Test set: Average loss: 4.5654, Accuracy: 996/5000 (20%)\n",
      "[epoch 35] loss: 0.0030227\n",
      "Test set: Average loss: 4.5783, Accuracy: 995/5000 (20%)\n",
      "[epoch 36] loss: 0.0029055\n",
      "Test set: Average loss: 4.5882, Accuracy: 997/5000 (20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] loss: 0.0027701\n",
      "Test set: Average loss: 4.5967, Accuracy: 999/5000 (20%)\n",
      "[epoch 38] loss: 0.0026401\n",
      "Test set: Average loss: 4.6030, Accuracy: 1000/5000 (20%)\n",
      "[epoch 39] loss: 0.0025995\n",
      "Test set: Average loss: 4.6084, Accuracy: 1001/5000 (20%)\n",
      "[epoch 40] loss: 0.0025320\n",
      "Test set: Average loss: 4.6124, Accuracy: 996/5000 (20%)\n",
      "[epoch 41] loss: 0.0025060\n",
      "Test set: Average loss: 4.6151, Accuracy: 1000/5000 (20%)\n",
      "[epoch 42] loss: 0.0023358\n",
      "Test set: Average loss: 4.6178, Accuracy: 999/5000 (20%)\n",
      "[epoch 43] loss: 0.0022761\n",
      "Test set: Average loss: 4.6208, Accuracy: 1004/5000 (20%)\n",
      "[epoch 44] loss: 0.0022390\n",
      "Test set: Average loss: 4.6243, Accuracy: 1004/5000 (20%)\n",
      "[epoch 45] loss: 0.0021354\n",
      "Test set: Average loss: 4.6277, Accuracy: 1004/5000 (20%)\n",
      "[epoch 46] loss: 0.0021531\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.6313, Accuracy: 1003/5000 (20%)\n",
      "[epoch 47] loss: 0.0020434\n",
      "Test set: Average loss: 4.6317, Accuracy: 1003/5000 (20%)\n",
      "[epoch 48] loss: 0.0020993\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.6322, Accuracy: 1003/5000 (20%)\n",
      "[epoch 49] loss: 0.0020800\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.6322, Accuracy: 1003/5000 (20%)\n",
      "[epoch 50] loss: 0.0020888\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.6322, Accuracy: 1003/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.5684, Accuracy: 1045/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 3.5153, Accuracy: 2063/10000 (21%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3049, Accuracy: 468/5000 (9%)\n",
      "[epoch 1] loss: 2.4154693\n",
      "Test set: Average loss: 2.3663, Accuracy: 499/5000 (10%)\n",
      "[epoch 2] loss: 2.1019487\n",
      "Test set: Average loss: 2.3605, Accuracy: 720/5000 (14%)\n",
      "[epoch 3] loss: 1.8583821\n",
      "Test set: Average loss: 2.3498, Accuracy: 902/5000 (18%)\n",
      "[epoch 4] loss: 1.6517888\n",
      "Test set: Average loss: 2.3707, Accuracy: 958/5000 (19%)\n",
      "[epoch 5] loss: 1.4367401\n",
      "Test set: Average loss: 2.4038, Accuracy: 923/5000 (18%)\n",
      "[epoch 6] loss: 1.1733036\n",
      "Test set: Average loss: 2.4633, Accuracy: 928/5000 (19%)\n",
      "[epoch 7] loss: 0.9821300\n",
      "Test set: Average loss: 2.5503, Accuracy: 958/5000 (19%)\n",
      "[epoch 8] loss: 0.7284276\n",
      "Test set: Average loss: 2.6561, Accuracy: 948/5000 (19%)\n",
      "[epoch 9] loss: 0.5421276\n",
      "Test set: Average loss: 2.7529, Accuracy: 942/5000 (19%)\n",
      "[epoch 10] loss: 0.3995346\n",
      "Test set: Average loss: 2.8198, Accuracy: 950/5000 (19%)\n",
      "[epoch 11] loss: 0.2646208\n",
      "Test set: Average loss: 2.8869, Accuracy: 921/5000 (18%)\n",
      "[epoch 12] loss: 0.2060038\n",
      "Test set: Average loss: 2.9673, Accuracy: 952/5000 (19%)\n",
      "[epoch 13] loss: 0.1291290\n",
      "Test set: Average loss: 3.0708, Accuracy: 958/5000 (19%)\n",
      "[epoch 14] loss: 0.0761187\n",
      "Test set: Average loss: 3.2258, Accuracy: 956/5000 (19%)\n",
      "[epoch 15] loss: 0.0579104\n",
      "Test set: Average loss: 3.3536, Accuracy: 929/5000 (19%)\n",
      "[epoch 16] loss: 0.0440584\n",
      "Test set: Average loss: 3.4395, Accuracy: 926/5000 (19%)\n",
      "[epoch 17] loss: 0.0289829\n",
      "Test set: Average loss: 3.4915, Accuracy: 923/5000 (18%)\n",
      "[epoch 18] loss: 0.0188184\n",
      "Test set: Average loss: 3.5380, Accuracy: 935/5000 (19%)\n",
      "[epoch 19] loss: 0.0149853\n",
      "Test set: Average loss: 3.5856, Accuracy: 933/5000 (19%)\n",
      "[epoch 20] loss: 0.0127029\n",
      "Test set: Average loss: 3.6277, Accuracy: 926/5000 (19%)\n",
      "[epoch 21] loss: 0.0114886\n",
      "Test set: Average loss: 3.6686, Accuracy: 931/5000 (19%)\n",
      "[epoch 22] loss: 0.0100638\n",
      "Test set: Average loss: 3.7076, Accuracy: 930/5000 (19%)\n",
      "[epoch 23] loss: 0.0080801\n",
      "Test set: Average loss: 3.7444, Accuracy: 926/5000 (19%)\n",
      "[epoch 24] loss: 0.0067601\n",
      "Test set: Average loss: 3.7792, Accuracy: 934/5000 (19%)\n",
      "[epoch 25] loss: 0.0057130\n",
      "Test set: Average loss: 3.8139, Accuracy: 933/5000 (19%)\n",
      "[epoch 26] loss: 0.0051653\n",
      "Test set: Average loss: 3.8478, Accuracy: 936/5000 (19%)\n",
      "[epoch 27] loss: 0.0046485\n",
      "Test set: Average loss: 3.8778, Accuracy: 939/5000 (19%)\n",
      "[epoch 28] loss: 0.0042358\n",
      "Test set: Average loss: 3.9051, Accuracy: 936/5000 (19%)\n",
      "[epoch 29] loss: 0.0038197\n",
      "Test set: Average loss: 3.9293, Accuracy: 933/5000 (19%)\n",
      "[epoch 30] loss: 0.0036721\n",
      "Test set: Average loss: 3.9501, Accuracy: 937/5000 (19%)\n",
      "[epoch 31] loss: 0.0035504\n",
      "Test set: Average loss: 3.9674, Accuracy: 941/5000 (19%)\n",
      "[epoch 32] loss: 0.0033507\n",
      "Test set: Average loss: 3.9811, Accuracy: 941/5000 (19%)\n",
      "[epoch 33] loss: 0.0029992\n",
      "Test set: Average loss: 3.9930, Accuracy: 941/5000 (19%)\n",
      "[epoch 34] loss: 0.0029586\n",
      "Test set: Average loss: 4.0030, Accuracy: 938/5000 (19%)\n",
      "[epoch 35] loss: 0.0028389\n",
      "Test set: Average loss: 4.0115, Accuracy: 941/5000 (19%)\n",
      "[epoch 36] loss: 0.0027274\n",
      "Test set: Average loss: 4.0189, Accuracy: 938/5000 (19%)\n",
      "[epoch 37] loss: 0.0025517\n",
      "Test set: Average loss: 4.0253, Accuracy: 935/5000 (19%)\n",
      "[epoch 38] loss: 0.0024865\n",
      "Test set: Average loss: 4.0308, Accuracy: 936/5000 (19%)\n",
      "[epoch 39] loss: 0.0023674\n",
      "Test set: Average loss: 4.0363, Accuracy: 935/5000 (19%)\n",
      "[epoch 40] loss: 0.0023002\n",
      "Test set: Average loss: 4.0412, Accuracy: 937/5000 (19%)\n",
      "[epoch 41] loss: 0.0021890\n",
      "Test set: Average loss: 4.0452, Accuracy: 940/5000 (19%)\n",
      "[epoch 42] loss: 0.0022299\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.0488, Accuracy: 941/5000 (19%)\n",
      "[epoch 43] loss: 0.0022237\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 44] loss: 0.0022115\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 45] loss: 0.0021722\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 46] loss: 0.0021698\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 47] loss: 0.0020766\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 48] loss: 0.0021456\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 49] loss: 0.0021327\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "[epoch 50] loss: 0.0020753\n",
      "Test set: Average loss: 4.0492, Accuracy: 941/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0708, Accuracy: 958/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 3.0775, Accuracy: 2004/10000 (20%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3125, Accuracy: 444/5000 (9%)\n",
      "[epoch 1] loss: 2.3397015\n",
      "Test set: Average loss: 2.3957, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 1.9767986\n",
      "Test set: Average loss: 2.4351, Accuracy: 643/5000 (13%)\n",
      "[epoch 3] loss: 1.7478571\n",
      "Test set: Average loss: 2.4088, Accuracy: 865/5000 (17%)\n",
      "[epoch 4] loss: 1.4859805\n",
      "Test set: Average loss: 2.4225, Accuracy: 902/5000 (18%)\n",
      "[epoch 5] loss: 1.2115918\n",
      "Test set: Average loss: 2.4825, Accuracy: 905/5000 (18%)\n",
      "[epoch 6] loss: 1.1023419\n",
      "Test set: Average loss: 2.5642, Accuracy: 927/5000 (19%)\n",
      "[epoch 7] loss: 0.8316854\n",
      "Test set: Average loss: 2.6351, Accuracy: 986/5000 (20%)\n",
      "[epoch 8] loss: 0.6298255\n",
      "Test set: Average loss: 2.6799, Accuracy: 950/5000 (19%)\n",
      "[epoch 9] loss: 0.5393787\n",
      "Test set: Average loss: 2.7338, Accuracy: 943/5000 (19%)\n",
      "[epoch 10] loss: 0.3689113\n",
      "Test set: Average loss: 2.8367, Accuracy: 929/5000 (19%)\n",
      "[epoch 11] loss: 0.3234594\n",
      "Test set: Average loss: 2.9839, Accuracy: 932/5000 (19%)\n",
      "[epoch 12] loss: 0.2585668\n",
      "Test set: Average loss: 3.1461, Accuracy: 931/5000 (19%)\n",
      "[epoch 13] loss: 0.1730442\n",
      "Test set: Average loss: 3.2661, Accuracy: 945/5000 (19%)\n",
      "[epoch 14] loss: 0.1534358\n",
      "Test set: Average loss: 3.3189, Accuracy: 939/5000 (19%)\n",
      "[epoch 15] loss: 0.1065672\n",
      "Test set: Average loss: 3.3549, Accuracy: 941/5000 (19%)\n",
      "[epoch 16] loss: 0.0815102\n",
      "Test set: Average loss: 3.3912, Accuracy: 922/5000 (18%)\n",
      "[epoch 17] loss: 0.0574156\n",
      "Test set: Average loss: 3.4298, Accuracy: 928/5000 (19%)\n",
      "[epoch 18] loss: 0.0562169\n",
      "Test set: Average loss: 3.4765, Accuracy: 916/5000 (18%)\n",
      "[epoch 19] loss: 0.0366764\n",
      "Test set: Average loss: 3.5445, Accuracy: 907/5000 (18%)\n",
      "[epoch 20] loss: 0.0322547\n",
      "Test set: Average loss: 3.6168, Accuracy: 902/5000 (18%)\n",
      "[epoch 21] loss: 0.0220675\n",
      "Test set: Average loss: 3.6929, Accuracy: 894/5000 (18%)\n",
      "[epoch 22] loss: 0.0200897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.7602, Accuracy: 891/5000 (18%)\n",
      "[epoch 23] loss: 0.0170633\n",
      "Test set: Average loss: 3.8026, Accuracy: 890/5000 (18%)\n",
      "[epoch 24] loss: 0.0130288\n",
      "Test set: Average loss: 3.8276, Accuracy: 892/5000 (18%)\n",
      "[epoch 25] loss: 0.0111180\n",
      "Test set: Average loss: 3.8443, Accuracy: 900/5000 (18%)\n",
      "[epoch 26] loss: 0.0090588\n",
      "Test set: Average loss: 3.8590, Accuracy: 910/5000 (18%)\n",
      "[epoch 27] loss: 0.0084035\n",
      "Test set: Average loss: 3.8726, Accuracy: 911/5000 (18%)\n",
      "[epoch 28] loss: 0.0074584\n",
      "Test set: Average loss: 3.8889, Accuracy: 909/5000 (18%)\n",
      "[epoch 29] loss: 0.0069630\n",
      "Test set: Average loss: 3.9058, Accuracy: 913/5000 (18%)\n",
      "[epoch 30] loss: 0.0063606\n",
      "Test set: Average loss: 3.9256, Accuracy: 912/5000 (18%)\n",
      "[epoch 31] loss: 0.0057706\n",
      "Test set: Average loss: 3.9478, Accuracy: 913/5000 (18%)\n",
      "[epoch 32] loss: 0.0053437\n",
      "Test set: Average loss: 3.9714, Accuracy: 912/5000 (18%)\n",
      "[epoch 33] loss: 0.0049119\n",
      "Test set: Average loss: 3.9957, Accuracy: 911/5000 (18%)\n",
      "[epoch 34] loss: 0.0046402\n",
      "Test set: Average loss: 4.0196, Accuracy: 913/5000 (18%)\n",
      "[epoch 35] loss: 0.0041001\n",
      "Test set: Average loss: 4.0417, Accuracy: 912/5000 (18%)\n",
      "[epoch 36] loss: 0.0037932\n",
      "Test set: Average loss: 4.0621, Accuracy: 911/5000 (18%)\n",
      "[epoch 37] loss: 0.0037179\n",
      "Test set: Average loss: 4.0796, Accuracy: 909/5000 (18%)\n",
      "[epoch 38] loss: 0.0034329\n",
      "Test set: Average loss: 4.0941, Accuracy: 908/5000 (18%)\n",
      "[epoch 39] loss: 0.0034182\n",
      "Test set: Average loss: 4.1059, Accuracy: 905/5000 (18%)\n",
      "[epoch 40] loss: 0.0032594\n",
      "Test set: Average loss: 4.1152, Accuracy: 906/5000 (18%)\n",
      "[epoch 41] loss: 0.0033043\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.1230, Accuracy: 903/5000 (18%)\n",
      "[epoch 42] loss: 0.0029748\n",
      "Test set: Average loss: 4.1237, Accuracy: 904/5000 (18%)\n",
      "[epoch 43] loss: 0.0029868\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 44] loss: 0.0031523\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 45] loss: 0.0030490\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 46] loss: 0.0030299\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 47] loss: 0.0032174\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 48] loss: 0.0030556\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 49] loss: 0.0031623\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "[epoch 50] loss: 0.0032589\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.1242, Accuracy: 906/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6351, Accuracy: 986/5000 (20%)\n",
      "Test\n",
      "Test set: Average loss: 2.6209, Accuracy: 1883/10000 (19%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3093, Accuracy: 462/5000 (9%)\n",
      "[epoch 1] loss: 2.1791156\n",
      "Test set: Average loss: 2.5943, Accuracy: 549/5000 (11%)\n",
      "[epoch 2] loss: 2.1122072\n",
      "Test set: Average loss: 2.3547, Accuracy: 892/5000 (18%)\n",
      "[epoch 3] loss: 1.8927045\n",
      "Test set: Average loss: 2.2498, Accuracy: 972/5000 (19%)\n",
      "[epoch 4] loss: 1.6547180\n",
      "Test set: Average loss: 2.3863, Accuracy: 910/5000 (18%)\n",
      "[epoch 5] loss: 1.4477365\n",
      "Test set: Average loss: 2.6297, Accuracy: 912/5000 (18%)\n",
      "[epoch 6] loss: 1.7153275\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.6193, Accuracy: 985/5000 (20%)\n",
      "[epoch 7] loss: 1.5165195\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.6077, Accuracy: 994/5000 (20%)\n",
      "[epoch 8] loss: 1.2952740\n",
      "Test set: Average loss: 2.6050, Accuracy: 1000/5000 (20%)\n",
      "[epoch 9] loss: 1.3282361\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.6015, Accuracy: 1002/5000 (20%)\n",
      "[epoch 10] loss: 1.2197403\n",
      "Test set: Average loss: 2.6011, Accuracy: 1001/5000 (20%)\n",
      "[epoch 11] loss: 1.2466578\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 12] loss: 1.2729812\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 13] loss: 1.1194318\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 14] loss: 1.2129253\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 15] loss: 1.2057084\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 16] loss: 1.1726480\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 17] loss: 1.2444779\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 18] loss: 1.2193916\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 19] loss: 1.2478581\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 20] loss: 1.2013969\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 21] loss: 1.1021902\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 22] loss: 1.2324789\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 23] loss: 1.1009990\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 24] loss: 1.2447959\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 25] loss: 1.0327204\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 26] loss: 1.1629160\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 27] loss: 1.1900260\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 28] loss: 1.2224242\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 29] loss: 1.2647472\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 30] loss: 1.2379020\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 31] loss: 1.2114398\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 32] loss: 1.3071217\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 33] loss: 1.1307701\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 34] loss: 1.3122358\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 35] loss: 1.1587250\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 36] loss: 1.3054559\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 37] loss: 1.1844602\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 38] loss: 1.3121772\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 39] loss: 1.1743025\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40] loss: 1.1873720\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 41] loss: 1.2065900\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 42] loss: 1.1425628\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 43] loss: 1.3096693\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 44] loss: 1.1794149\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 45] loss: 1.1820776\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 46] loss: 1.1988766\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 47] loss: 1.1477284\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 48] loss: 1.0799219\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 49] loss: 1.0669384\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "[epoch 50] loss: 1.2538128\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.6008, Accuracy: 1001/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6015, Accuracy: 1002/5000 (20%)\n",
      "Test\n",
      "Test set: Average loss: 2.5418, Accuracy: 2133/10000 (21%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3069, Accuracy: 447/5000 (9%)\n",
      "[epoch 1] loss: 2.4297485\n",
      "Test set: Average loss: 2.2810, Accuracy: 702/5000 (14%)\n",
      "[epoch 2] loss: 2.1739916\n",
      "Test set: Average loss: 2.2456, Accuracy: 734/5000 (15%)\n",
      "[epoch 3] loss: 2.0216800\n",
      "Test set: Average loss: 2.2633, Accuracy: 825/5000 (16%)\n",
      "[epoch 4] loss: 1.8178807\n",
      "Test set: Average loss: 2.3262, Accuracy: 943/5000 (19%)\n",
      "[epoch 5] loss: 1.6186527\n",
      "Test set: Average loss: 2.3611, Accuracy: 979/5000 (20%)\n",
      "[epoch 6] loss: 1.5569077\n",
      "Test set: Average loss: 2.3175, Accuracy: 1083/5000 (22%)\n",
      "[epoch 7] loss: 1.4523508\n",
      "Test set: Average loss: 2.4349, Accuracy: 996/5000 (20%)\n",
      "[epoch 8] loss: 1.3243903\n",
      "Test set: Average loss: 2.4345, Accuracy: 993/5000 (20%)\n",
      "[epoch 9] loss: 1.7432323\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3675, Accuracy: 1085/5000 (22%)\n",
      "[epoch 10] loss: 1.0368664\n",
      "Test set: Average loss: 2.3595, Accuracy: 1090/5000 (22%)\n",
      "[epoch 11] loss: 0.8733655\n",
      "Test set: Average loss: 2.3449, Accuracy: 1062/5000 (21%)\n",
      "[epoch 12] loss: 0.7791488\n",
      "Test set: Average loss: 2.3339, Accuracy: 1083/5000 (22%)\n",
      "[epoch 13] loss: 0.6983016\n",
      "Test set: Average loss: 2.3310, Accuracy: 1089/5000 (22%)\n",
      "[epoch 14] loss: 0.8285345\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3340, Accuracy: 1095/5000 (22%)\n",
      "[epoch 15] loss: 0.8184924\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1103/5000 (22%)\n",
      "[epoch 16] loss: 0.7504109\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 17] loss: 0.7743270\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 18] loss: 1.5326396\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 19] loss: 0.6566573\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 20] loss: 0.6944182\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 21] loss: 0.7645224\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 22] loss: 0.7324890\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 23] loss: 0.8126930\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 24] loss: 0.7230741\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 25] loss: 0.7185232\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 26] loss: 1.5237142\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 27] loss: 0.6880705\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 28] loss: 0.7291115\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 29] loss: 0.7955858\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 30] loss: 0.7178675\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 31] loss: 0.7398299\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 32] loss: 0.6698506\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 33] loss: 0.8754708\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 34] loss: 0.7732896\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 35] loss: 0.8607573\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 36] loss: 0.7301152\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 37] loss: 0.8182320\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 38] loss: 0.8270961\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 39] loss: 0.6803288\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 40] loss: 0.6653744\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 41] loss: 0.7614504\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 42] loss: 0.7567857\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 43] loss: 0.8128019\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 44] loss: 0.7789013\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 45] loss: 0.7023603\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 46] loss: 0.6722210\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 47] loss: 0.7356653\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 48] loss: 0.7744545\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "[epoch 49] loss: 0.7439016\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.7061369\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3344, Accuracy: 1105/5000 (22%)\n",
      "Test\n",
      "Test set: Average loss: 2.3150, Accuracy: 2341/10000 (23%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3000, Accuracy: 530/5000 (11%)\n",
      "[epoch 1] loss: 2.2807517\n",
      "Test set: Average loss: 2.4343, Accuracy: 593/5000 (12%)\n",
      "[epoch 2] loss: 2.1632782\n",
      "Test set: Average loss: 2.3402, Accuracy: 816/5000 (16%)\n",
      "[epoch 3] loss: 1.9547610\n",
      "Test set: Average loss: 2.3812, Accuracy: 854/5000 (17%)\n",
      "[epoch 4] loss: 1.4582514\n",
      "Test set: Average loss: 2.5453, Accuracy: 881/5000 (18%)\n",
      "[epoch 5] loss: 1.6308229\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.6507, Accuracy: 872/5000 (17%)\n",
      "[epoch 6] loss: 1.3445028\n",
      "Test set: Average loss: 2.6368, Accuracy: 876/5000 (18%)\n",
      "[epoch 7] loss: 1.3363495\n",
      "Test set: Average loss: 2.6061, Accuracy: 883/5000 (18%)\n",
      "[epoch 8] loss: 1.5827832\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5689, Accuracy: 893/5000 (18%)\n",
      "[epoch 9] loss: 1.2834299\n",
      "Test set: Average loss: 2.5648, Accuracy: 893/5000 (18%)\n",
      "[epoch 10] loss: 1.2991647\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5616, Accuracy: 893/5000 (18%)\n",
      "[epoch 11] loss: 1.4320698\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 12] loss: 1.3510697\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 13] loss: 1.2654414\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 14] loss: 1.2661996\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 15] loss: 1.2392174\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 16] loss: 1.1946879\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 17] loss: 1.2656792\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 18] loss: 1.2263602\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 19] loss: 1.3747367\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 20] loss: 1.5449990\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 21] loss: 1.2178800\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 22] loss: 1.3241138\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 23] loss: 1.3691989\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 24] loss: 1.4130670\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 25] loss: 1.4177573\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 26] loss: 1.3101626\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 27] loss: 1.4023874\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 28] loss: 1.3983240\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 29] loss: 1.4299460\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 30] loss: 1.3830864\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 31] loss: 1.4105114\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 32] loss: 1.3813915\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 33] loss: 1.3712325\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 34] loss: 1.3549272\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 35] loss: 1.3235595\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 36] loss: 1.1805452\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 37] loss: 1.2730463\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 38] loss: 1.3278531\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 39] loss: 1.3484415\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 40] loss: 1.3165554\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 41] loss: 1.9338249\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 42] loss: 1.2991123\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 43] loss: 1.4332496\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 44] loss: 1.2842114\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 45] loss: 1.3268442\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 46] loss: 1.3249260\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 47] loss: 1.4575311\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 48] loss: 1.2696469\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 49] loss: 1.1646309\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "[epoch 50] loss: 1.2997504\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.5613, Accuracy: 891/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5616, Accuracy: 893/5000 (18%)\n",
      "Test\n",
      "Test set: Average loss: 2.5647, Accuracy: 1817/10000 (18%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2989, Accuracy: 584/5000 (12%)\n",
      "[epoch 1] loss: 2.3190244\n",
      "Test set: Average loss: 2.2286, Accuracy: 889/5000 (18%)\n",
      "[epoch 2] loss: 2.0904336\n",
      "Test set: Average loss: 2.1795, Accuracy: 1028/5000 (21%)\n",
      "[epoch 3] loss: 1.8568822\n",
      "Test set: Average loss: 2.1402, Accuracy: 1152/5000 (23%)\n",
      "[epoch 4] loss: 1.6617724\n",
      "Test set: Average loss: 2.1463, Accuracy: 1259/5000 (25%)\n",
      "[epoch 5] loss: 1.4169193\n",
      "Test set: Average loss: 2.1714, Accuracy: 1271/5000 (25%)\n",
      "[epoch 6] loss: 1.2024404\n",
      "Test set: Average loss: 2.1815, Accuracy: 1330/5000 (27%)\n",
      "[epoch 7] loss: 0.9416044\n",
      "Test set: Average loss: 2.2218, Accuracy: 1318/5000 (26%)\n",
      "[epoch 8] loss: 0.7116846\n",
      "Test set: Average loss: 2.3312, Accuracy: 1361/5000 (27%)\n",
      "[epoch 9] loss: 0.5207960\n",
      "Test set: Average loss: 2.3617, Accuracy: 1348/5000 (27%)\n",
      "[epoch 10] loss: 0.3797396\n",
      "Test set: Average loss: 2.5134, Accuracy: 1333/5000 (27%)\n",
      "[epoch 11] loss: 0.2376003\n",
      "Test set: Average loss: 2.5462, Accuracy: 1363/5000 (27%)\n",
      "[epoch 12] loss: 0.1535500\n",
      "Test set: Average loss: 2.6124, Accuracy: 1330/5000 (27%)\n",
      "[epoch 13] loss: 0.1027213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.7239, Accuracy: 1326/5000 (27%)\n",
      "[epoch 14] loss: 0.0715899\n",
      "Test set: Average loss: 2.7362, Accuracy: 1343/5000 (27%)\n",
      "[epoch 15] loss: 0.0524533\n",
      "Test set: Average loss: 2.8403, Accuracy: 1313/5000 (26%)\n",
      "[epoch 16] loss: 0.0396060\n",
      "Test set: Average loss: 2.8797, Accuracy: 1326/5000 (27%)\n",
      "[epoch 17] loss: 0.0310588\n",
      "Test set: Average loss: 2.8934, Accuracy: 1331/5000 (27%)\n",
      "[epoch 18] loss: 0.0254651\n",
      "Test set: Average loss: 2.9557, Accuracy: 1310/5000 (26%)\n",
      "[epoch 19] loss: 0.0214350\n",
      "Test set: Average loss: 2.9656, Accuracy: 1327/5000 (27%)\n",
      "[epoch 20] loss: 0.0188835\n",
      "Test set: Average loss: 2.9856, Accuracy: 1331/5000 (27%)\n",
      "[epoch 21] loss: 0.0166719\n",
      "Test set: Average loss: 3.0151, Accuracy: 1324/5000 (26%)\n",
      "[epoch 22] loss: 0.0150948\n",
      "Test set: Average loss: 3.0384, Accuracy: 1323/5000 (26%)\n",
      "[epoch 23] loss: 0.0135792\n",
      "Test set: Average loss: 3.0575, Accuracy: 1319/5000 (26%)\n",
      "[epoch 24] loss: 0.0125080\n",
      "Test set: Average loss: 3.0719, Accuracy: 1329/5000 (27%)\n",
      "[epoch 25] loss: 0.0114355\n",
      "Test set: Average loss: 3.0951, Accuracy: 1323/5000 (26%)\n",
      "[epoch 26] loss: 0.0105846\n",
      "Test set: Average loss: 3.1048, Accuracy: 1335/5000 (27%)\n",
      "[epoch 27] loss: 0.0097444\n",
      "Test set: Average loss: 3.1284, Accuracy: 1322/5000 (26%)\n",
      "[epoch 28] loss: 0.0090412\n",
      "Test set: Average loss: 3.1386, Accuracy: 1328/5000 (27%)\n",
      "[epoch 29] loss: 0.0083920\n",
      "Test set: Average loss: 3.1528, Accuracy: 1325/5000 (26%)\n",
      "[epoch 30] loss: 0.0078622\n",
      "Test set: Average loss: 3.1769, Accuracy: 1318/5000 (26%)\n",
      "[epoch 31] loss: 0.0073410\n",
      "Test set: Average loss: 3.1827, Accuracy: 1324/5000 (26%)\n",
      "[epoch 32] loss: 0.0068951\n",
      "Test set: Average loss: 3.1929, Accuracy: 1329/5000 (27%)\n",
      "[epoch 33] loss: 0.0065298\n",
      "Test set: Average loss: 3.2127, Accuracy: 1330/5000 (27%)\n",
      "[epoch 34] loss: 0.0061479\n",
      "Test set: Average loss: 3.2282, Accuracy: 1325/5000 (26%)\n",
      "[epoch 35] loss: 0.0058100\n",
      "Test set: Average loss: 3.2418, Accuracy: 1320/5000 (26%)\n",
      "[epoch 36] loss: 0.0054992\n",
      "Test set: Average loss: 3.2508, Accuracy: 1327/5000 (27%)\n",
      "[epoch 37] loss: 0.0052340\n",
      "Test set: Average loss: 3.2565, Accuracy: 1331/5000 (27%)\n",
      "[epoch 38] loss: 0.0049606\n",
      "Test set: Average loss: 3.2707, Accuracy: 1332/5000 (27%)\n",
      "[epoch 39] loss: 0.0047092\n",
      "Test set: Average loss: 3.2812, Accuracy: 1333/5000 (27%)\n",
      "[epoch 40] loss: 0.0044981\n",
      "Test set: Average loss: 3.2908, Accuracy: 1334/5000 (27%)\n",
      "[epoch 41] loss: 0.0042953\n",
      "Test set: Average loss: 3.2987, Accuracy: 1331/5000 (27%)\n",
      "[epoch 42] loss: 0.0041089\n",
      "Test set: Average loss: 3.3124, Accuracy: 1334/5000 (27%)\n",
      "[epoch 43] loss: 0.0039181\n",
      "Test set: Average loss: 3.3230, Accuracy: 1332/5000 (27%)\n",
      "[epoch 44] loss: 0.0037981\n",
      "Test set: Average loss: 3.3313, Accuracy: 1335/5000 (27%)\n",
      "[epoch 45] loss: 0.0036086\n",
      "Test set: Average loss: 3.3431, Accuracy: 1326/5000 (27%)\n",
      "[epoch 46] loss: 0.0034711\n",
      "Test set: Average loss: 3.3505, Accuracy: 1329/5000 (27%)\n",
      "[epoch 47] loss: 0.0033430\n",
      "Test set: Average loss: 3.3577, Accuracy: 1334/5000 (27%)\n",
      "[epoch 48] loss: 0.0031960\n",
      "Test set: Average loss: 3.3693, Accuracy: 1334/5000 (27%)\n",
      "[epoch 49] loss: 0.0030802\n",
      "Test set: Average loss: 3.3769, Accuracy: 1332/5000 (27%)\n",
      "[epoch 50] loss: 0.0029608\n",
      "Test set: Average loss: 3.3847, Accuracy: 1331/5000 (27%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5462, Accuracy: 1363/5000 (27%)\n",
      "Test\n",
      "Test set: Average loss: 2.5169, Accuracy: 2863/10000 (29%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 531/5000 (11%)\n",
      "[epoch 1] loss: 2.3732901\n",
      "Test set: Average loss: 2.2370, Accuracy: 863/5000 (17%)\n",
      "[epoch 2] loss: 2.1448377\n",
      "Test set: Average loss: 2.1633, Accuracy: 983/5000 (20%)\n",
      "[epoch 3] loss: 1.9035765\n",
      "Test set: Average loss: 2.0570, Accuracy: 1306/5000 (26%)\n",
      "[epoch 4] loss: 1.6155566\n",
      "Test set: Average loss: 2.0418, Accuracy: 1413/5000 (28%)\n",
      "[epoch 5] loss: 1.3699157\n",
      "Test set: Average loss: 2.0703, Accuracy: 1396/5000 (28%)\n",
      "[epoch 6] loss: 1.1300129\n",
      "Test set: Average loss: 2.0699, Accuracy: 1471/5000 (29%)\n",
      "[epoch 7] loss: 0.8890635\n",
      "Test set: Average loss: 2.1657, Accuracy: 1438/5000 (29%)\n",
      "[epoch 8] loss: 0.6942320\n",
      "Test set: Average loss: 2.2168, Accuracy: 1471/5000 (29%)\n",
      "[epoch 9] loss: 0.4860470\n",
      "Test set: Average loss: 2.2801, Accuracy: 1448/5000 (29%)\n",
      "[epoch 10] loss: 0.3233265\n",
      "Test set: Average loss: 2.3676, Accuracy: 1482/5000 (30%)\n",
      "[epoch 11] loss: 0.2296152\n",
      "Test set: Average loss: 2.4811, Accuracy: 1462/5000 (29%)\n",
      "[epoch 12] loss: 0.1375383\n",
      "Test set: Average loss: 2.5456, Accuracy: 1441/5000 (29%)\n",
      "[epoch 13] loss: 0.0920566\n",
      "Test set: Average loss: 2.5882, Accuracy: 1448/5000 (29%)\n",
      "[epoch 14] loss: 0.0628598\n",
      "Test set: Average loss: 2.6454, Accuracy: 1463/5000 (29%)\n",
      "[epoch 15] loss: 0.0473122\n",
      "Test set: Average loss: 2.7179, Accuracy: 1486/5000 (30%)\n",
      "[epoch 16] loss: 0.0344518\n",
      "Test set: Average loss: 2.7600, Accuracy: 1479/5000 (30%)\n",
      "[epoch 17] loss: 0.0285355\n",
      "Test set: Average loss: 2.7912, Accuracy: 1474/5000 (29%)\n",
      "[epoch 18] loss: 0.0236036\n",
      "Test set: Average loss: 2.8277, Accuracy: 1477/5000 (30%)\n",
      "[epoch 19] loss: 0.0197979\n",
      "Test set: Average loss: 2.8680, Accuracy: 1456/5000 (29%)\n",
      "[epoch 20] loss: 0.0175620\n",
      "Test set: Average loss: 2.8831, Accuracy: 1466/5000 (29%)\n",
      "[epoch 21] loss: 0.0152009\n",
      "Test set: Average loss: 2.9112, Accuracy: 1472/5000 (29%)\n",
      "[epoch 22] loss: 0.0138268\n",
      "Test set: Average loss: 2.9310, Accuracy: 1469/5000 (29%)\n",
      "[epoch 23] loss: 0.0123267\n",
      "Test set: Average loss: 2.9522, Accuracy: 1473/5000 (29%)\n",
      "[epoch 24] loss: 0.0112115\n",
      "Test set: Average loss: 2.9705, Accuracy: 1471/5000 (29%)\n",
      "[epoch 25] loss: 0.0103395\n",
      "Test set: Average loss: 2.9902, Accuracy: 1461/5000 (29%)\n",
      "[epoch 26] loss: 0.0094987\n",
      "Test set: Average loss: 3.0094, Accuracy: 1475/5000 (30%)\n",
      "[epoch 27] loss: 0.0088634\n",
      "Test set: Average loss: 3.0312, Accuracy: 1474/5000 (29%)\n",
      "[epoch 28] loss: 0.0081806\n",
      "Test set: Average loss: 3.0383, Accuracy: 1468/5000 (29%)\n",
      "[epoch 29] loss: 0.0075872\n",
      "Test set: Average loss: 3.0546, Accuracy: 1473/5000 (29%)\n",
      "[epoch 30] loss: 0.0070764\n",
      "Test set: Average loss: 3.0710, Accuracy: 1476/5000 (30%)\n",
      "[epoch 31] loss: 0.0066140\n",
      "Test set: Average loss: 3.0880, Accuracy: 1471/5000 (29%)\n",
      "[epoch 32] loss: 0.0062483\n",
      "Test set: Average loss: 3.1007, Accuracy: 1477/5000 (30%)\n",
      "[epoch 33] loss: 0.0059061\n",
      "Test set: Average loss: 3.1129, Accuracy: 1481/5000 (30%)\n",
      "[epoch 34] loss: 0.0055854\n",
      "Test set: Average loss: 3.1261, Accuracy: 1474/5000 (29%)\n",
      "[epoch 35] loss: 0.0052484\n",
      "Test set: Average loss: 3.1435, Accuracy: 1472/5000 (29%)\n",
      "[epoch 36] loss: 0.0049690\n",
      "Test set: Average loss: 3.1499, Accuracy: 1478/5000 (30%)\n",
      "[epoch 37] loss: 0.0047327\n",
      "Test set: Average loss: 3.1623, Accuracy: 1477/5000 (30%)\n",
      "[epoch 38] loss: 0.0044610\n",
      "Test set: Average loss: 3.1748, Accuracy: 1475/5000 (30%)\n",
      "[epoch 39] loss: 0.0042653\n",
      "Test set: Average loss: 3.1863, Accuracy: 1471/5000 (29%)\n",
      "[epoch 40] loss: 0.0040973\n",
      "Test set: Average loss: 3.1960, Accuracy: 1477/5000 (30%)\n",
      "[epoch 41] loss: 0.0038663\n",
      "Test set: Average loss: 3.2049, Accuracy: 1478/5000 (30%)\n",
      "[epoch 42] loss: 0.0037067\n",
      "Test set: Average loss: 3.2169, Accuracy: 1473/5000 (29%)\n",
      "[epoch 43] loss: 0.0035735\n",
      "Test set: Average loss: 3.2285, Accuracy: 1472/5000 (29%)\n",
      "[epoch 44] loss: 0.0034042\n",
      "Test set: Average loss: 3.2372, Accuracy: 1475/5000 (30%)\n",
      "[epoch 45] loss: 0.0032598\n",
      "Test set: Average loss: 3.2461, Accuracy: 1475/5000 (30%)\n",
      "[epoch 46] loss: 0.0031186\n",
      "Test set: Average loss: 3.2550, Accuracy: 1472/5000 (29%)\n",
      "[epoch 47] loss: 0.0029964\n",
      "Test set: Average loss: 3.2654, Accuracy: 1475/5000 (30%)\n",
      "[epoch 48] loss: 0.0028874\n",
      "Test set: Average loss: 3.2735, Accuracy: 1475/5000 (30%)\n",
      "[epoch 49] loss: 0.0027754\n",
      "Test set: Average loss: 3.2829, Accuracy: 1473/5000 (29%)\n",
      "[epoch 50] loss: 0.0026762\n",
      "Test set: Average loss: 3.2886, Accuracy: 1464/5000 (29%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7179, Accuracy: 1486/5000 (30%)\n",
      "Test\n",
      "Test set: Average loss: 2.6472, Accuracy: 3074/10000 (31%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3094, Accuracy: 460/5000 (9%)\n",
      "[epoch 1] loss: 2.3064561\n",
      "Test set: Average loss: 2.2103, Accuracy: 869/5000 (17%)\n",
      "[epoch 2] loss: 2.0470494\n",
      "Test set: Average loss: 2.0699, Accuracy: 1249/5000 (25%)\n",
      "[epoch 3] loss: 1.8536179\n",
      "Test set: Average loss: 2.0349, Accuracy: 1263/5000 (25%)\n",
      "[epoch 4] loss: 1.6136729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.0137, Accuracy: 1437/5000 (29%)\n",
      "[epoch 5] loss: 1.3590308\n",
      "Test set: Average loss: 2.0393, Accuracy: 1438/5000 (29%)\n",
      "[epoch 6] loss: 1.0912985\n",
      "Test set: Average loss: 2.0902, Accuracy: 1437/5000 (29%)\n",
      "[epoch 7] loss: 0.8826796\n",
      "Test set: Average loss: 2.1701, Accuracy: 1529/5000 (31%)\n",
      "[epoch 8] loss: 0.6415827\n",
      "Test set: Average loss: 2.2635, Accuracy: 1520/5000 (30%)\n",
      "[epoch 9] loss: 0.4755402\n",
      "Test set: Average loss: 2.3519, Accuracy: 1493/5000 (30%)\n",
      "[epoch 10] loss: 0.3202942\n",
      "Test set: Average loss: 2.4578, Accuracy: 1518/5000 (30%)\n",
      "[epoch 11] loss: 0.2146583\n",
      "Test set: Average loss: 2.5491, Accuracy: 1479/5000 (30%)\n",
      "[epoch 12] loss: 0.1522341\n",
      "Test set: Average loss: 2.6394, Accuracy: 1542/5000 (31%)\n",
      "[epoch 13] loss: 0.1000213\n",
      "Test set: Average loss: 2.7203, Accuracy: 1476/5000 (30%)\n",
      "[epoch 14] loss: 0.0698521\n",
      "Test set: Average loss: 2.7928, Accuracy: 1508/5000 (30%)\n",
      "[epoch 15] loss: 0.0521352\n",
      "Test set: Average loss: 2.8196, Accuracy: 1498/5000 (30%)\n",
      "[epoch 16] loss: 0.0396361\n",
      "Test set: Average loss: 2.9038, Accuracy: 1487/5000 (30%)\n",
      "[epoch 17] loss: 0.0293699\n",
      "Test set: Average loss: 2.9398, Accuracy: 1517/5000 (30%)\n",
      "[epoch 18] loss: 0.0231219\n",
      "Test set: Average loss: 2.9703, Accuracy: 1490/5000 (30%)\n",
      "[epoch 19] loss: 0.0200452\n",
      "Test set: Average loss: 3.0059, Accuracy: 1500/5000 (30%)\n",
      "[epoch 20] loss: 0.0174614\n",
      "Test set: Average loss: 3.0375, Accuracy: 1492/5000 (30%)\n",
      "[epoch 21] loss: 0.0153950\n",
      "Test set: Average loss: 3.0556, Accuracy: 1486/5000 (30%)\n",
      "[epoch 22] loss: 0.0134430\n",
      "Test set: Average loss: 3.0822, Accuracy: 1492/5000 (30%)\n",
      "[epoch 23] loss: 0.0123677\n",
      "Test set: Average loss: 3.1056, Accuracy: 1509/5000 (30%)\n",
      "[epoch 24] loss: 0.0110864\n",
      "Test set: Average loss: 3.1284, Accuracy: 1499/5000 (30%)\n",
      "[epoch 25] loss: 0.0102005\n",
      "Test set: Average loss: 3.1458, Accuracy: 1492/5000 (30%)\n",
      "[epoch 26] loss: 0.0092913\n",
      "Test set: Average loss: 3.1767, Accuracy: 1507/5000 (30%)\n",
      "[epoch 27] loss: 0.0085898\n",
      "Test set: Average loss: 3.1889, Accuracy: 1496/5000 (30%)\n",
      "[epoch 28] loss: 0.0080034\n",
      "Test set: Average loss: 3.1969, Accuracy: 1509/5000 (30%)\n",
      "[epoch 29] loss: 0.0073910\n",
      "Test set: Average loss: 3.2205, Accuracy: 1490/5000 (30%)\n",
      "[epoch 30] loss: 0.0069709\n",
      "Test set: Average loss: 3.2360, Accuracy: 1490/5000 (30%)\n",
      "[epoch 31] loss: 0.0064704\n",
      "Test set: Average loss: 3.2556, Accuracy: 1494/5000 (30%)\n",
      "[epoch 32] loss: 0.0060958\n",
      "Test set: Average loss: 3.2631, Accuracy: 1488/5000 (30%)\n",
      "[epoch 33] loss: 0.0057302\n",
      "Test set: Average loss: 3.2712, Accuracy: 1490/5000 (30%)\n",
      "[epoch 34] loss: 0.0053654\n",
      "Test set: Average loss: 3.2893, Accuracy: 1500/5000 (30%)\n",
      "[epoch 35] loss: 0.0050727\n",
      "Test set: Average loss: 3.3058, Accuracy: 1496/5000 (30%)\n",
      "[epoch 36] loss: 0.0048065\n",
      "Test set: Average loss: 3.3220, Accuracy: 1491/5000 (30%)\n",
      "[epoch 37] loss: 0.0045767\n",
      "Test set: Average loss: 3.3330, Accuracy: 1491/5000 (30%)\n",
      "[epoch 38] loss: 0.0043776\n",
      "Test set: Average loss: 3.3423, Accuracy: 1493/5000 (30%)\n",
      "[epoch 39] loss: 0.0041497\n",
      "Test set: Average loss: 3.3557, Accuracy: 1487/5000 (30%)\n",
      "[epoch 40] loss: 0.0039352\n",
      "Test set: Average loss: 3.3651, Accuracy: 1498/5000 (30%)\n",
      "[epoch 41] loss: 0.0037711\n",
      "Test set: Average loss: 3.3724, Accuracy: 1493/5000 (30%)\n",
      "[epoch 42] loss: 0.0036019\n",
      "Test set: Average loss: 3.3903, Accuracy: 1494/5000 (30%)\n",
      "[epoch 43] loss: 0.0034599\n",
      "Test set: Average loss: 3.4014, Accuracy: 1490/5000 (30%)\n",
      "[epoch 44] loss: 0.0032999\n",
      "Test set: Average loss: 3.4096, Accuracy: 1491/5000 (30%)\n",
      "[epoch 45] loss: 0.0031803\n",
      "Test set: Average loss: 3.4160, Accuracy: 1482/5000 (30%)\n",
      "[epoch 46] loss: 0.0030593\n",
      "Test set: Average loss: 3.4247, Accuracy: 1491/5000 (30%)\n",
      "[epoch 47] loss: 0.0029368\n",
      "Test set: Average loss: 3.4374, Accuracy: 1486/5000 (30%)\n",
      "[epoch 48] loss: 0.0028243\n",
      "Test set: Average loss: 3.4494, Accuracy: 1480/5000 (30%)\n",
      "[epoch 49] loss: 0.0027095\n",
      "Test set: Average loss: 3.4606, Accuracy: 1486/5000 (30%)\n",
      "[epoch 50] loss: 0.0026000\n",
      "Test set: Average loss: 3.4671, Accuracy: 1488/5000 (30%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6394, Accuracy: 1542/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.6297, Accuracy: 3000/10000 (30%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3090, Accuracy: 492/5000 (10%)\n",
      "[epoch 1] loss: 2.2531929\n",
      "Test set: Average loss: 2.1130, Accuracy: 1202/5000 (24%)\n",
      "[epoch 2] loss: 1.9197516\n",
      "Test set: Average loss: 2.0251, Accuracy: 1365/5000 (27%)\n",
      "[epoch 3] loss: 1.6649748\n",
      "Test set: Average loss: 1.9204, Accuracy: 1535/5000 (31%)\n",
      "[epoch 4] loss: 1.4008002\n",
      "Test set: Average loss: 1.9602, Accuracy: 1572/5000 (31%)\n",
      "[epoch 5] loss: 1.1493350\n",
      "Test set: Average loss: 1.9206, Accuracy: 1724/5000 (34%)\n",
      "[epoch 6] loss: 0.8919356\n",
      "Test set: Average loss: 1.9720, Accuracy: 1704/5000 (34%)\n",
      "[epoch 7] loss: 0.7040983\n",
      "Test set: Average loss: 2.1095, Accuracy: 1696/5000 (34%)\n",
      "[epoch 8] loss: 0.5437732\n",
      "Test set: Average loss: 2.2305, Accuracy: 1654/5000 (33%)\n",
      "[epoch 9] loss: 0.3671018\n",
      "Test set: Average loss: 2.3438, Accuracy: 1620/5000 (32%)\n",
      "[epoch 10] loss: 0.2225039\n",
      "Test set: Average loss: 2.4472, Accuracy: 1670/5000 (33%)\n",
      "[epoch 11] loss: 0.1427793\n",
      "Test set: Average loss: 2.4778, Accuracy: 1683/5000 (34%)\n",
      "[epoch 12] loss: 0.0841386\n",
      "Test set: Average loss: 2.5565, Accuracy: 1646/5000 (33%)\n",
      "[epoch 13] loss: 0.0562325\n",
      "Test set: Average loss: 2.6521, Accuracy: 1672/5000 (33%)\n",
      "[epoch 14] loss: 0.0419898\n",
      "Test set: Average loss: 2.7139, Accuracy: 1643/5000 (33%)\n",
      "[epoch 15] loss: 0.0306788\n",
      "Test set: Average loss: 2.7492, Accuracy: 1656/5000 (33%)\n",
      "[epoch 16] loss: 0.0242440\n",
      "Test set: Average loss: 2.7986, Accuracy: 1652/5000 (33%)\n",
      "[epoch 17] loss: 0.0204330\n",
      "Test set: Average loss: 2.8275, Accuracy: 1652/5000 (33%)\n",
      "[epoch 18] loss: 0.0173512\n",
      "Test set: Average loss: 2.8656, Accuracy: 1648/5000 (33%)\n",
      "[epoch 19] loss: 0.0153002\n",
      "Test set: Average loss: 2.8869, Accuracy: 1644/5000 (33%)\n",
      "[epoch 20] loss: 0.0131077\n",
      "Test set: Average loss: 2.9242, Accuracy: 1641/5000 (33%)\n",
      "[epoch 21] loss: 0.0117581\n",
      "Test set: Average loss: 2.9506, Accuracy: 1643/5000 (33%)\n",
      "[epoch 22] loss: 0.0105385\n",
      "Test set: Average loss: 2.9762, Accuracy: 1640/5000 (33%)\n",
      "[epoch 23] loss: 0.0095358\n",
      "Test set: Average loss: 2.9961, Accuracy: 1639/5000 (33%)\n",
      "[epoch 24] loss: 0.0087512\n",
      "Test set: Average loss: 3.0197, Accuracy: 1643/5000 (33%)\n",
      "[epoch 25] loss: 0.0079737\n",
      "Test set: Average loss: 3.0455, Accuracy: 1640/5000 (33%)\n",
      "[epoch 26] loss: 0.0072421\n",
      "Test set: Average loss: 3.0617, Accuracy: 1643/5000 (33%)\n",
      "[epoch 27] loss: 0.0067720\n",
      "Test set: Average loss: 3.0836, Accuracy: 1640/5000 (33%)\n",
      "[epoch 28] loss: 0.0062050\n",
      "Test set: Average loss: 3.0995, Accuracy: 1636/5000 (33%)\n",
      "[epoch 29] loss: 0.0058000\n",
      "Test set: Average loss: 3.1191, Accuracy: 1645/5000 (33%)\n",
      "[epoch 30] loss: 0.0053170\n",
      "Test set: Average loss: 3.1335, Accuracy: 1644/5000 (33%)\n",
      "[epoch 31] loss: 0.0049914\n",
      "Test set: Average loss: 3.1539, Accuracy: 1643/5000 (33%)\n",
      "[epoch 32] loss: 0.0047071\n",
      "Test set: Average loss: 3.1676, Accuracy: 1645/5000 (33%)\n",
      "[epoch 33] loss: 0.0043941\n",
      "Test set: Average loss: 3.1848, Accuracy: 1636/5000 (33%)\n",
      "[epoch 34] loss: 0.0041456\n",
      "Test set: Average loss: 3.1986, Accuracy: 1643/5000 (33%)\n",
      "[epoch 35] loss: 0.0038872\n",
      "Test set: Average loss: 3.2120, Accuracy: 1644/5000 (33%)\n",
      "[epoch 36] loss: 0.0037040\n",
      "Test set: Average loss: 3.2268, Accuracy: 1645/5000 (33%)\n",
      "[epoch 37] loss: 0.0034782\n",
      "Test set: Average loss: 3.2395, Accuracy: 1646/5000 (33%)\n",
      "[epoch 38] loss: 0.0032898\n",
      "Test set: Average loss: 3.2514, Accuracy: 1645/5000 (33%)\n",
      "[epoch 39] loss: 0.0031264\n",
      "Test set: Average loss: 3.2692, Accuracy: 1644/5000 (33%)\n",
      "[epoch 40] loss: 0.0029770\n",
      "Test set: Average loss: 3.2788, Accuracy: 1649/5000 (33%)\n",
      "[epoch 41] loss: 0.0028230\n",
      "Test set: Average loss: 3.2907, Accuracy: 1643/5000 (33%)\n",
      "[epoch 42] loss: 0.0026950\n",
      "Test set: Average loss: 3.2986, Accuracy: 1650/5000 (33%)\n",
      "[epoch 43] loss: 0.0025799\n",
      "Test set: Average loss: 3.3139, Accuracy: 1648/5000 (33%)\n",
      "[epoch 44] loss: 0.0024573\n",
      "Test set: Average loss: 3.3238, Accuracy: 1650/5000 (33%)\n",
      "[epoch 45] loss: 0.0023357\n",
      "Test set: Average loss: 3.3345, Accuracy: 1651/5000 (33%)\n",
      "[epoch 46] loss: 0.0022410\n",
      "Test set: Average loss: 3.3459, Accuracy: 1654/5000 (33%)\n",
      "[epoch 47] loss: 0.0021424\n",
      "Test set: Average loss: 3.3568, Accuracy: 1655/5000 (33%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 48] loss: 0.0020749\n",
      "Test set: Average loss: 3.3665, Accuracy: 1654/5000 (33%)\n",
      "[epoch 49] loss: 0.0019643\n",
      "Test set: Average loss: 3.3768, Accuracy: 1651/5000 (33%)\n",
      "[epoch 50] loss: 0.0018900\n",
      "Test set: Average loss: 3.3865, Accuracy: 1649/5000 (33%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9206, Accuracy: 1724/5000 (34%)\n",
      "Test\n",
      "Test set: Average loss: 1.8934, Accuracy: 3571/10000 (36%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3102, Accuracy: 490/5000 (10%)\n",
      "[epoch 1] loss: 2.2061688\n",
      "Test set: Average loss: 2.1435, Accuracy: 1078/5000 (22%)\n",
      "[epoch 2] loss: 1.9358703\n",
      "Test set: Average loss: 2.0567, Accuracy: 1275/5000 (26%)\n",
      "[epoch 3] loss: 1.6936746\n",
      "Test set: Average loss: 1.9576, Accuracy: 1500/5000 (30%)\n",
      "[epoch 4] loss: 1.4037769\n",
      "Test set: Average loss: 1.9915, Accuracy: 1594/5000 (32%)\n",
      "[epoch 5] loss: 1.2264269\n",
      "Test set: Average loss: 1.9687, Accuracy: 1508/5000 (30%)\n",
      "[epoch 6] loss: 0.9746718\n",
      "Test set: Average loss: 2.0098, Accuracy: 1678/5000 (34%)\n",
      "[epoch 7] loss: 0.8024757\n",
      "Test set: Average loss: 2.0773, Accuracy: 1611/5000 (32%)\n",
      "[epoch 8] loss: 0.5932786\n",
      "Test set: Average loss: 2.1065, Accuracy: 1701/5000 (34%)\n",
      "[epoch 9] loss: 0.3834019\n",
      "Test set: Average loss: 2.2234, Accuracy: 1713/5000 (34%)\n",
      "[epoch 10] loss: 0.2619623\n",
      "Test set: Average loss: 2.3592, Accuracy: 1638/5000 (33%)\n",
      "[epoch 11] loss: 0.2076353\n",
      "Test set: Average loss: 2.4183, Accuracy: 1667/5000 (33%)\n",
      "[epoch 12] loss: 0.1156605\n",
      "Test set: Average loss: 2.4330, Accuracy: 1684/5000 (34%)\n",
      "[epoch 13] loss: 0.0806262\n",
      "Test set: Average loss: 2.5510, Accuracy: 1714/5000 (34%)\n",
      "[epoch 14] loss: 0.0532553\n",
      "Test set: Average loss: 2.5814, Accuracy: 1733/5000 (35%)\n",
      "[epoch 15] loss: 0.0361946\n",
      "Test set: Average loss: 2.6149, Accuracy: 1716/5000 (34%)\n",
      "[epoch 16] loss: 0.0272533\n",
      "Test set: Average loss: 2.6652, Accuracy: 1717/5000 (34%)\n",
      "[epoch 17] loss: 0.0222851\n",
      "Test set: Average loss: 2.7134, Accuracy: 1733/5000 (35%)\n",
      "[epoch 18] loss: 0.0195057\n",
      "Test set: Average loss: 2.7422, Accuracy: 1723/5000 (34%)\n",
      "[epoch 19] loss: 0.0166200\n",
      "Test set: Average loss: 2.7657, Accuracy: 1728/5000 (35%)\n",
      "[epoch 20] loss: 0.0145555\n",
      "Test set: Average loss: 2.7921, Accuracy: 1730/5000 (35%)\n",
      "[epoch 21] loss: 0.0127757\n",
      "Test set: Average loss: 2.8315, Accuracy: 1736/5000 (35%)\n",
      "[epoch 22] loss: 0.0116130\n",
      "Test set: Average loss: 2.8453, Accuracy: 1716/5000 (34%)\n",
      "[epoch 23] loss: 0.0105523\n",
      "Test set: Average loss: 2.8728, Accuracy: 1730/5000 (35%)\n",
      "[epoch 24] loss: 0.0096920\n",
      "Test set: Average loss: 2.9011, Accuracy: 1732/5000 (35%)\n",
      "[epoch 25] loss: 0.0085933\n",
      "Test set: Average loss: 2.9219, Accuracy: 1728/5000 (35%)\n",
      "[epoch 26] loss: 0.0078617\n",
      "Test set: Average loss: 2.9389, Accuracy: 1723/5000 (34%)\n",
      "[epoch 27] loss: 0.0072631\n",
      "Test set: Average loss: 2.9588, Accuracy: 1732/5000 (35%)\n",
      "[epoch 28] loss: 0.0066991\n",
      "Test set: Average loss: 2.9824, Accuracy: 1728/5000 (35%)\n",
      "[epoch 29] loss: 0.0062589\n",
      "Test set: Average loss: 2.9958, Accuracy: 1728/5000 (35%)\n",
      "[epoch 30] loss: 0.0058056\n",
      "Test set: Average loss: 3.0117, Accuracy: 1727/5000 (35%)\n",
      "[epoch 31] loss: 0.0054079\n",
      "Test set: Average loss: 3.0280, Accuracy: 1731/5000 (35%)\n",
      "[epoch 32] loss: 0.0050453\n",
      "Test set: Average loss: 3.0494, Accuracy: 1725/5000 (34%)\n",
      "[epoch 33] loss: 0.0047303\n",
      "Test set: Average loss: 3.0599, Accuracy: 1726/5000 (35%)\n",
      "[epoch 34] loss: 0.0044330\n",
      "Test set: Average loss: 3.0751, Accuracy: 1731/5000 (35%)\n",
      "[epoch 35] loss: 0.0041639\n",
      "Test set: Average loss: 3.0904, Accuracy: 1728/5000 (35%)\n",
      "[epoch 36] loss: 0.0039571\n",
      "Test set: Average loss: 3.1026, Accuracy: 1724/5000 (34%)\n",
      "[epoch 37] loss: 0.0037336\n",
      "Test set: Average loss: 3.1174, Accuracy: 1733/5000 (35%)\n",
      "[epoch 38] loss: 0.0035563\n",
      "Test set: Average loss: 3.1327, Accuracy: 1729/5000 (35%)\n",
      "[epoch 39] loss: 0.0033995\n",
      "Test set: Average loss: 3.1434, Accuracy: 1727/5000 (35%)\n",
      "[epoch 40] loss: 0.0031900\n",
      "Test set: Average loss: 3.1562, Accuracy: 1737/5000 (35%)\n",
      "[epoch 41] loss: 0.0030415\n",
      "Test set: Average loss: 3.1701, Accuracy: 1730/5000 (35%)\n",
      "[epoch 42] loss: 0.0028775\n",
      "Test set: Average loss: 3.1785, Accuracy: 1732/5000 (35%)\n",
      "[epoch 43] loss: 0.0027755\n",
      "Test set: Average loss: 3.1935, Accuracy: 1737/5000 (35%)\n",
      "[epoch 44] loss: 0.0026322\n",
      "Test set: Average loss: 3.2022, Accuracy: 1731/5000 (35%)\n",
      "[epoch 45] loss: 0.0025249\n",
      "Test set: Average loss: 3.2132, Accuracy: 1729/5000 (35%)\n",
      "[epoch 46] loss: 0.0024089\n",
      "Test set: Average loss: 3.2258, Accuracy: 1727/5000 (35%)\n",
      "[epoch 47] loss: 0.0023101\n",
      "Test set: Average loss: 3.2349, Accuracy: 1727/5000 (35%)\n",
      "[epoch 48] loss: 0.0022072\n",
      "Test set: Average loss: 3.2467, Accuracy: 1736/5000 (35%)\n",
      "[epoch 49] loss: 0.0021118\n",
      "Test set: Average loss: 3.2563, Accuracy: 1732/5000 (35%)\n",
      "[epoch 50] loss: 0.0020437\n",
      "Test set: Average loss: 3.2656, Accuracy: 1733/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1935, Accuracy: 1737/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 3.1633, Accuracy: 3510/10000 (35%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3072, Accuracy: 503/5000 (10%)\n",
      "[epoch 1] loss: 2.2878179\n",
      "Test set: Average loss: 2.1673, Accuracy: 953/5000 (19%)\n",
      "[epoch 2] loss: 2.0576820\n",
      "Test set: Average loss: 2.0850, Accuracy: 1247/5000 (25%)\n",
      "[epoch 3] loss: 1.8644838\n",
      "Test set: Average loss: 1.9986, Accuracy: 1406/5000 (28%)\n",
      "[epoch 4] loss: 1.7066236\n",
      "Test set: Average loss: 1.9512, Accuracy: 1501/5000 (30%)\n",
      "[epoch 5] loss: 1.4505978\n",
      "Test set: Average loss: 1.9865, Accuracy: 1553/5000 (31%)\n",
      "[epoch 6] loss: 1.2389412\n",
      "Test set: Average loss: 1.9844, Accuracy: 1669/5000 (33%)\n",
      "[epoch 7] loss: 1.0462073\n",
      "Test set: Average loss: 2.0109, Accuracy: 1733/5000 (35%)\n",
      "[epoch 8] loss: 0.8893659\n",
      "Test set: Average loss: 2.0868, Accuracy: 1725/5000 (34%)\n",
      "[epoch 9] loss: 0.6641784\n",
      "Test set: Average loss: 2.1092, Accuracy: 1725/5000 (34%)\n",
      "[epoch 10] loss: 0.4544611\n",
      "Test set: Average loss: 2.2032, Accuracy: 1701/5000 (34%)\n",
      "[epoch 11] loss: 0.3152869\n",
      "Test set: Average loss: 2.3072, Accuracy: 1652/5000 (33%)\n",
      "[epoch 12] loss: 0.2033007\n",
      "Test set: Average loss: 2.3757, Accuracy: 1661/5000 (33%)\n",
      "[epoch 13] loss: 0.1361578\n",
      "Test set: Average loss: 2.4419, Accuracy: 1701/5000 (34%)\n",
      "[epoch 14] loss: 0.0861241\n",
      "Test set: Average loss: 2.5407, Accuracy: 1666/5000 (33%)\n",
      "[epoch 15] loss: 0.0631864\n",
      "Test set: Average loss: 2.5565, Accuracy: 1675/5000 (34%)\n",
      "[epoch 16] loss: 0.0470744\n",
      "Test set: Average loss: 2.6162, Accuracy: 1721/5000 (34%)\n",
      "[epoch 17] loss: 0.0358302\n",
      "Test set: Average loss: 2.6493, Accuracy: 1687/5000 (34%)\n",
      "[epoch 18] loss: 0.0280553\n",
      "Test set: Average loss: 2.6875, Accuracy: 1695/5000 (34%)\n",
      "[epoch 19] loss: 0.0234509\n",
      "Test set: Average loss: 2.7320, Accuracy: 1709/5000 (34%)\n",
      "[epoch 20] loss: 0.0201407\n",
      "Test set: Average loss: 2.7441, Accuracy: 1703/5000 (34%)\n",
      "[epoch 21] loss: 0.0174391\n",
      "Test set: Average loss: 2.7914, Accuracy: 1691/5000 (34%)\n",
      "[epoch 22] loss: 0.0155397\n",
      "Test set: Average loss: 2.8075, Accuracy: 1708/5000 (34%)\n",
      "[epoch 23] loss: 0.0136883\n",
      "Test set: Average loss: 2.8360, Accuracy: 1707/5000 (34%)\n",
      "[epoch 24] loss: 0.0121129\n",
      "Test set: Average loss: 2.8540, Accuracy: 1700/5000 (34%)\n",
      "[epoch 25] loss: 0.0111405\n",
      "Test set: Average loss: 2.8804, Accuracy: 1713/5000 (34%)\n",
      "[epoch 26] loss: 0.0099855\n",
      "Test set: Average loss: 2.9020, Accuracy: 1710/5000 (34%)\n",
      "[epoch 27] loss: 0.0091047\n",
      "Test set: Average loss: 2.9192, Accuracy: 1702/5000 (34%)\n",
      "[epoch 28] loss: 0.0084255\n",
      "Test set: Average loss: 2.9400, Accuracy: 1706/5000 (34%)\n",
      "[epoch 29] loss: 0.0077294\n",
      "Test set: Average loss: 2.9560, Accuracy: 1711/5000 (34%)\n",
      "[epoch 30] loss: 0.0071308\n",
      "Test set: Average loss: 2.9749, Accuracy: 1712/5000 (34%)\n",
      "[epoch 31] loss: 0.0066763\n",
      "Test set: Average loss: 2.9920, Accuracy: 1709/5000 (34%)\n",
      "[epoch 32] loss: 0.0061931\n",
      "Test set: Average loss: 3.0077, Accuracy: 1705/5000 (34%)\n",
      "[epoch 33] loss: 0.0057897\n",
      "Test set: Average loss: 3.0220, Accuracy: 1712/5000 (34%)\n",
      "[epoch 34] loss: 0.0054472\n",
      "Test set: Average loss: 3.0381, Accuracy: 1701/5000 (34%)\n",
      "[epoch 35] loss: 0.0050925\n",
      "Test set: Average loss: 3.0522, Accuracy: 1707/5000 (34%)\n",
      "[epoch 36] loss: 0.0047428\n",
      "Test set: Average loss: 3.0648, Accuracy: 1708/5000 (34%)\n",
      "[epoch 37] loss: 0.0045042\n",
      "Test set: Average loss: 3.0803, Accuracy: 1712/5000 (34%)\n",
      "[epoch 38] loss: 0.0042807\n",
      "Test set: Average loss: 3.0902, Accuracy: 1704/5000 (34%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39] loss: 0.0040370\n",
      "Test set: Average loss: 3.1056, Accuracy: 1696/5000 (34%)\n",
      "[epoch 40] loss: 0.0038028\n",
      "Test set: Average loss: 3.1186, Accuracy: 1708/5000 (34%)\n",
      "[epoch 41] loss: 0.0036291\n",
      "Test set: Average loss: 3.1288, Accuracy: 1710/5000 (34%)\n",
      "[epoch 42] loss: 0.0034621\n",
      "Test set: Average loss: 3.1427, Accuracy: 1706/5000 (34%)\n",
      "[epoch 43] loss: 0.0032759\n",
      "Test set: Average loss: 3.1505, Accuracy: 1707/5000 (34%)\n",
      "[epoch 44] loss: 0.0031434\n",
      "Test set: Average loss: 3.1615, Accuracy: 1707/5000 (34%)\n",
      "[epoch 45] loss: 0.0029757\n",
      "Test set: Average loss: 3.1775, Accuracy: 1702/5000 (34%)\n",
      "[epoch 46] loss: 0.0028349\n",
      "Test set: Average loss: 3.1822, Accuracy: 1712/5000 (34%)\n",
      "[epoch 47] loss: 0.0027152\n",
      "Test set: Average loss: 3.1973, Accuracy: 1700/5000 (34%)\n",
      "[epoch 48] loss: 0.0026078\n",
      "Test set: Average loss: 3.2034, Accuracy: 1703/5000 (34%)\n",
      "[epoch 49] loss: 0.0024890\n",
      "Test set: Average loss: 3.2132, Accuracy: 1709/5000 (34%)\n",
      "[epoch 50] loss: 0.0023960\n",
      "Test set: Average loss: 3.2207, Accuracy: 1710/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0109, Accuracy: 1733/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 2.0103, Accuracy: 3411/10000 (34%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3139, Accuracy: 422/5000 (8%)\n",
      "[epoch 1] loss: 2.2002409\n",
      "Test set: Average loss: 2.0730, Accuracy: 1309/5000 (26%)\n",
      "[epoch 2] loss: 1.8663397\n",
      "Test set: Average loss: 1.9272, Accuracy: 1543/5000 (31%)\n",
      "[epoch 3] loss: 1.6649380\n",
      "Test set: Average loss: 1.9321, Accuracy: 1621/5000 (32%)\n",
      "[epoch 4] loss: 1.4309351\n",
      "Test set: Average loss: 1.8510, Accuracy: 1826/5000 (37%)\n",
      "[epoch 5] loss: 1.2070318\n",
      "Test set: Average loss: 1.9491, Accuracy: 1649/5000 (33%)\n",
      "[epoch 6] loss: 1.0256360\n",
      "Test set: Average loss: 1.9381, Accuracy: 1838/5000 (37%)\n",
      "[epoch 7] loss: 0.7778278\n",
      "Test set: Average loss: 1.9763, Accuracy: 1790/5000 (36%)\n",
      "[epoch 8] loss: 0.5820094\n",
      "Test set: Average loss: 2.0745, Accuracy: 1761/5000 (35%)\n",
      "[epoch 9] loss: 0.4096093\n",
      "Test set: Average loss: 2.1805, Accuracy: 1791/5000 (36%)\n",
      "[epoch 10] loss: 0.2494932\n",
      "Test set: Average loss: 2.2301, Accuracy: 1796/5000 (36%)\n",
      "[epoch 11] loss: 0.1562346\n",
      "Test set: Average loss: 2.2904, Accuracy: 1820/5000 (36%)\n",
      "[epoch 12] loss: 0.1000296\n",
      "Test set: Average loss: 2.3566, Accuracy: 1788/5000 (36%)\n",
      "[epoch 13] loss: 0.0630884\n",
      "Test set: Average loss: 2.4316, Accuracy: 1817/5000 (36%)\n",
      "[epoch 14] loss: 0.0453497\n",
      "Test set: Average loss: 2.4712, Accuracy: 1828/5000 (37%)\n",
      "[epoch 15] loss: 0.0345148\n",
      "Test set: Average loss: 2.5077, Accuracy: 1825/5000 (36%)\n",
      "[epoch 16] loss: 0.0268314\n",
      "Test set: Average loss: 2.5528, Accuracy: 1810/5000 (36%)\n",
      "[epoch 17] loss: 0.0227442\n",
      "Test set: Average loss: 2.5834, Accuracy: 1828/5000 (37%)\n",
      "[epoch 18] loss: 0.0191058\n",
      "Test set: Average loss: 2.6188, Accuracy: 1803/5000 (36%)\n",
      "[epoch 19] loss: 0.0164772\n",
      "Test set: Average loss: 2.6406, Accuracy: 1824/5000 (36%)\n",
      "[epoch 20] loss: 0.0142638\n",
      "Test set: Average loss: 2.6656, Accuracy: 1817/5000 (36%)\n",
      "[epoch 21] loss: 0.0127192\n",
      "Test set: Average loss: 2.6955, Accuracy: 1822/5000 (36%)\n",
      "[epoch 22] loss: 0.0112706\n",
      "Test set: Average loss: 2.7153, Accuracy: 1828/5000 (37%)\n",
      "[epoch 23] loss: 0.0100613\n",
      "Test set: Average loss: 2.7485, Accuracy: 1808/5000 (36%)\n",
      "[epoch 24] loss: 0.0092496\n",
      "Test set: Average loss: 2.7611, Accuracy: 1820/5000 (36%)\n",
      "[epoch 25] loss: 0.0082739\n",
      "Test set: Average loss: 2.7837, Accuracy: 1817/5000 (36%)\n",
      "[epoch 26] loss: 0.0076172\n",
      "Test set: Average loss: 2.8024, Accuracy: 1820/5000 (36%)\n",
      "[epoch 27] loss: 0.0069097\n",
      "Test set: Average loss: 2.8213, Accuracy: 1825/5000 (36%)\n",
      "[epoch 28] loss: 0.0063652\n",
      "Test set: Average loss: 2.8385, Accuracy: 1826/5000 (37%)\n",
      "[epoch 29] loss: 0.0058585\n",
      "Test set: Average loss: 2.8529, Accuracy: 1816/5000 (36%)\n",
      "[epoch 30] loss: 0.0054520\n",
      "Test set: Average loss: 2.8705, Accuracy: 1823/5000 (36%)\n",
      "[epoch 31] loss: 0.0050801\n",
      "Test set: Average loss: 2.8865, Accuracy: 1826/5000 (37%)\n",
      "[epoch 32] loss: 0.0047584\n",
      "Test set: Average loss: 2.9020, Accuracy: 1821/5000 (36%)\n",
      "[epoch 33] loss: 0.0044232\n",
      "Test set: Average loss: 2.9186, Accuracy: 1829/5000 (37%)\n",
      "[epoch 34] loss: 0.0041308\n",
      "Test set: Average loss: 2.9281, Accuracy: 1821/5000 (36%)\n",
      "[epoch 35] loss: 0.0039006\n",
      "Test set: Average loss: 2.9457, Accuracy: 1822/5000 (36%)\n",
      "[epoch 36] loss: 0.0036524\n",
      "Test set: Average loss: 2.9560, Accuracy: 1824/5000 (36%)\n",
      "[epoch 37] loss: 0.0034457\n",
      "Test set: Average loss: 2.9726, Accuracy: 1825/5000 (36%)\n",
      "[epoch 38] loss: 0.0032578\n",
      "Test set: Average loss: 2.9823, Accuracy: 1818/5000 (36%)\n",
      "[epoch 39] loss: 0.0030819\n",
      "Test set: Average loss: 2.9953, Accuracy: 1823/5000 (36%)\n",
      "[epoch 40] loss: 0.0029343\n",
      "Test set: Average loss: 3.0050, Accuracy: 1820/5000 (36%)\n",
      "[epoch 41] loss: 0.0027610\n",
      "Test set: Average loss: 3.0182, Accuracy: 1825/5000 (36%)\n",
      "[epoch 42] loss: 0.0026198\n",
      "Test set: Average loss: 3.0279, Accuracy: 1820/5000 (36%)\n",
      "[epoch 43] loss: 0.0025049\n",
      "Test set: Average loss: 3.0385, Accuracy: 1827/5000 (37%)\n",
      "[epoch 44] loss: 0.0023939\n",
      "Test set: Average loss: 3.0511, Accuracy: 1819/5000 (36%)\n",
      "[epoch 45] loss: 0.0022811\n",
      "Test set: Average loss: 3.0630, Accuracy: 1822/5000 (36%)\n",
      "[epoch 46] loss: 0.0021705\n",
      "Test set: Average loss: 3.0706, Accuracy: 1824/5000 (36%)\n",
      "[epoch 47] loss: 0.0020779\n",
      "Test set: Average loss: 3.0812, Accuracy: 1827/5000 (37%)\n",
      "[epoch 48] loss: 0.0019916\n",
      "Test set: Average loss: 3.0910, Accuracy: 1827/5000 (37%)\n",
      "[epoch 49] loss: 0.0019070\n",
      "Test set: Average loss: 3.1001, Accuracy: 1823/5000 (36%)\n",
      "[epoch 50] loss: 0.0018169\n",
      "Test set: Average loss: 3.1102, Accuracy: 1825/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9381, Accuracy: 1838/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 1.9184, Accuracy: 3603/10000 (36%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3131, Accuracy: 461/5000 (9%)\n",
      "[epoch 1] loss: 2.1699050\n",
      "Test set: Average loss: 2.0235, Accuracy: 1370/5000 (27%)\n",
      "[epoch 2] loss: 1.7921716\n",
      "Test set: Average loss: 1.8724, Accuracy: 1578/5000 (32%)\n",
      "[epoch 3] loss: 1.5647593\n",
      "Test set: Average loss: 1.9421, Accuracy: 1566/5000 (31%)\n",
      "[epoch 4] loss: 1.3405362\n",
      "Test set: Average loss: 1.8793, Accuracy: 1785/5000 (36%)\n",
      "[epoch 5] loss: 1.1793332\n",
      "Test set: Average loss: 1.8794, Accuracy: 1795/5000 (36%)\n",
      "[epoch 6] loss: 0.9809470\n",
      "Test set: Average loss: 1.9453, Accuracy: 1859/5000 (37%)\n",
      "[epoch 7] loss: 0.8074461\n",
      "Test set: Average loss: 2.0883, Accuracy: 1791/5000 (36%)\n",
      "[epoch 8] loss: 0.6075853\n",
      "Test set: Average loss: 2.0972, Accuracy: 1808/5000 (36%)\n",
      "[epoch 9] loss: 0.3896701\n",
      "Test set: Average loss: 2.2135, Accuracy: 1886/5000 (38%)\n",
      "[epoch 10] loss: 0.3057758\n",
      "Test set: Average loss: 2.2699, Accuracy: 1841/5000 (37%)\n",
      "[epoch 11] loss: 0.2018396\n",
      "Test set: Average loss: 2.4019, Accuracy: 1854/5000 (37%)\n",
      "[epoch 12] loss: 0.1113088\n",
      "Test set: Average loss: 2.4524, Accuracy: 1838/5000 (37%)\n",
      "[epoch 13] loss: 0.0697003\n",
      "Test set: Average loss: 2.5408, Accuracy: 1838/5000 (37%)\n",
      "[epoch 14] loss: 0.0484656\n",
      "Test set: Average loss: 2.5773, Accuracy: 1855/5000 (37%)\n",
      "[epoch 15] loss: 0.0352041\n",
      "Test set: Average loss: 2.6254, Accuracy: 1841/5000 (37%)\n",
      "[epoch 16] loss: 0.0285957\n",
      "Test set: Average loss: 2.6885, Accuracy: 1837/5000 (37%)\n",
      "[epoch 17] loss: 0.0230833\n",
      "Test set: Average loss: 2.7191, Accuracy: 1842/5000 (37%)\n",
      "[epoch 18] loss: 0.0191717\n",
      "Test set: Average loss: 2.7709, Accuracy: 1854/5000 (37%)\n",
      "[epoch 19] loss: 0.0164350\n",
      "Test set: Average loss: 2.7983, Accuracy: 1851/5000 (37%)\n",
      "[epoch 20] loss: 0.0146807\n",
      "Test set: Average loss: 2.8278, Accuracy: 1846/5000 (37%)\n",
      "[epoch 21] loss: 0.0126978\n",
      "Test set: Average loss: 2.8657, Accuracy: 1853/5000 (37%)\n",
      "[epoch 22] loss: 0.0110775\n",
      "Test set: Average loss: 2.8921, Accuracy: 1856/5000 (37%)\n",
      "[epoch 23] loss: 0.0099839\n",
      "Test set: Average loss: 2.9192, Accuracy: 1852/5000 (37%)\n",
      "[epoch 24] loss: 0.0090627\n",
      "Test set: Average loss: 2.9449, Accuracy: 1836/5000 (37%)\n",
      "[epoch 25] loss: 0.0082080\n",
      "Test set: Average loss: 2.9657, Accuracy: 1855/5000 (37%)\n",
      "[epoch 26] loss: 0.0073638\n",
      "Test set: Average loss: 2.9916, Accuracy: 1856/5000 (37%)\n",
      "[epoch 27] loss: 0.0067860\n",
      "Test set: Average loss: 3.0094, Accuracy: 1854/5000 (37%)\n",
      "[epoch 28] loss: 0.0062319\n",
      "Test set: Average loss: 3.0281, Accuracy: 1855/5000 (37%)\n",
      "[epoch 29] loss: 0.0058154\n",
      "Test set: Average loss: 3.0560, Accuracy: 1856/5000 (37%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 30] loss: 0.0053688\n",
      "Test set: Average loss: 3.0691, Accuracy: 1859/5000 (37%)\n",
      "[epoch 31] loss: 0.0049442\n",
      "Test set: Average loss: 3.0845, Accuracy: 1855/5000 (37%)\n",
      "[epoch 32] loss: 0.0046496\n",
      "Test set: Average loss: 3.1028, Accuracy: 1859/5000 (37%)\n",
      "[epoch 33] loss: 0.0043066\n",
      "Test set: Average loss: 3.1223, Accuracy: 1854/5000 (37%)\n",
      "[epoch 34] loss: 0.0040383\n",
      "Test set: Average loss: 3.1364, Accuracy: 1854/5000 (37%)\n",
      "[epoch 35] loss: 0.0038391\n",
      "Test set: Average loss: 3.1550, Accuracy: 1851/5000 (37%)\n",
      "[epoch 36] loss: 0.0036107\n",
      "Test set: Average loss: 3.1694, Accuracy: 1859/5000 (37%)\n",
      "[epoch 37] loss: 0.0033972\n",
      "Test set: Average loss: 3.1824, Accuracy: 1858/5000 (37%)\n",
      "[epoch 38] loss: 0.0032042\n",
      "Test set: Average loss: 3.1982, Accuracy: 1853/5000 (37%)\n",
      "[epoch 39] loss: 0.0030075\n",
      "Test set: Average loss: 3.2101, Accuracy: 1851/5000 (37%)\n",
      "[epoch 40] loss: 0.0028690\n",
      "Test set: Average loss: 3.2261, Accuracy: 1852/5000 (37%)\n",
      "[epoch 41] loss: 0.0027324\n",
      "Test set: Average loss: 3.2391, Accuracy: 1856/5000 (37%)\n",
      "[epoch 42] loss: 0.0025862\n",
      "Test set: Average loss: 3.2514, Accuracy: 1852/5000 (37%)\n",
      "[epoch 43] loss: 0.0024667\n",
      "Test set: Average loss: 3.2617, Accuracy: 1855/5000 (37%)\n",
      "[epoch 44] loss: 0.0023338\n",
      "Test set: Average loss: 3.2754, Accuracy: 1853/5000 (37%)\n",
      "[epoch 45] loss: 0.0022445\n",
      "Test set: Average loss: 3.2882, Accuracy: 1852/5000 (37%)\n",
      "[epoch 46] loss: 0.0021461\n",
      "Test set: Average loss: 3.2998, Accuracy: 1859/5000 (37%)\n",
      "[epoch 47] loss: 0.0020370\n",
      "Test set: Average loss: 3.3091, Accuracy: 1851/5000 (37%)\n",
      "[epoch 48] loss: 0.0019488\n",
      "Test set: Average loss: 3.3242, Accuracy: 1852/5000 (37%)\n",
      "[epoch 49] loss: 0.0018626\n",
      "Test set: Average loss: 3.3340, Accuracy: 1860/5000 (37%)\n",
      "[epoch 50] loss: 0.0017860\n",
      "Test set: Average loss: 3.3433, Accuracy: 1847/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2135, Accuracy: 1886/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 2.1956, Accuracy: 3763/10000 (38%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2988, Accuracy: 535/5000 (11%)\n",
      "[epoch 1] loss: 2.2272406\n",
      "Test set: Average loss: 2.0827, Accuracy: 1152/5000 (23%)\n",
      "[epoch 2] loss: 2.0007611\n",
      "Test set: Average loss: 1.9614, Accuracy: 1449/5000 (29%)\n",
      "[epoch 3] loss: 1.8116552\n",
      "Test set: Average loss: 1.8766, Accuracy: 1610/5000 (32%)\n",
      "[epoch 4] loss: 1.6633960\n",
      "Test set: Average loss: 1.8394, Accuracy: 1727/5000 (35%)\n",
      "[epoch 5] loss: 1.4485673\n",
      "Test set: Average loss: 1.8750, Accuracy: 1743/5000 (35%)\n",
      "[epoch 6] loss: 1.2682775\n",
      "Test set: Average loss: 1.8856, Accuracy: 1730/5000 (35%)\n",
      "[epoch 7] loss: 1.0867702\n",
      "Test set: Average loss: 2.0328, Accuracy: 1695/5000 (34%)\n",
      "[epoch 8] loss: 0.8989667\n",
      "Test set: Average loss: 2.1126, Accuracy: 1703/5000 (34%)\n",
      "[epoch 9] loss: 0.7568482\n",
      "Test set: Average loss: 2.2768, Accuracy: 1684/5000 (34%)\n",
      "[epoch 10] loss: 0.5832625\n",
      "Test set: Average loss: 2.3705, Accuracy: 1706/5000 (34%)\n",
      "[epoch 11] loss: 0.4342696\n",
      "Test set: Average loss: 2.5359, Accuracy: 1630/5000 (33%)\n",
      "[epoch 12] loss: 0.3283437\n",
      "Test set: Average loss: 2.5375, Accuracy: 1703/5000 (34%)\n",
      "[epoch 13] loss: 0.1874432\n",
      "Test set: Average loss: 2.6448, Accuracy: 1697/5000 (34%)\n",
      "[epoch 14] loss: 0.1303274\n",
      "Test set: Average loss: 2.7491, Accuracy: 1699/5000 (34%)\n",
      "[epoch 15] loss: 0.0891743\n",
      "Test set: Average loss: 2.8487, Accuracy: 1712/5000 (34%)\n",
      "[epoch 16] loss: 0.0591622\n",
      "Test set: Average loss: 2.8942, Accuracy: 1712/5000 (34%)\n",
      "[epoch 17] loss: 0.0407375\n",
      "Test set: Average loss: 2.9813, Accuracy: 1696/5000 (34%)\n",
      "[epoch 18] loss: 0.0294674\n",
      "Test set: Average loss: 3.0343, Accuracy: 1709/5000 (34%)\n",
      "[epoch 19] loss: 0.0233745\n",
      "Test set: Average loss: 3.0907, Accuracy: 1685/5000 (34%)\n",
      "[epoch 20] loss: 0.0200980\n",
      "Test set: Average loss: 3.1416, Accuracy: 1699/5000 (34%)\n",
      "[epoch 21] loss: 0.0168932\n",
      "Test set: Average loss: 3.1866, Accuracy: 1715/5000 (34%)\n",
      "[epoch 22] loss: 0.0144777\n",
      "Test set: Average loss: 3.2314, Accuracy: 1701/5000 (34%)\n",
      "[epoch 23] loss: 0.0126527\n",
      "Test set: Average loss: 3.2769, Accuracy: 1686/5000 (34%)\n",
      "[epoch 24] loss: 0.0113197\n",
      "Test set: Average loss: 3.3002, Accuracy: 1698/5000 (34%)\n",
      "[epoch 25] loss: 0.0102015\n",
      "Test set: Average loss: 3.3384, Accuracy: 1687/5000 (34%)\n",
      "[epoch 26] loss: 0.0091218\n",
      "Test set: Average loss: 3.3689, Accuracy: 1701/5000 (34%)\n",
      "[epoch 27] loss: 0.0082813\n",
      "Test set: Average loss: 3.4009, Accuracy: 1696/5000 (34%)\n",
      "[epoch 28] loss: 0.0075989\n",
      "Test set: Average loss: 3.4274, Accuracy: 1698/5000 (34%)\n",
      "[epoch 29] loss: 0.0069601\n",
      "Test set: Average loss: 3.4537, Accuracy: 1704/5000 (34%)\n",
      "[epoch 30] loss: 0.0063029\n",
      "Test set: Average loss: 3.4804, Accuracy: 1692/5000 (34%)\n",
      "[epoch 31] loss: 0.0058783\n",
      "Test set: Average loss: 3.5062, Accuracy: 1699/5000 (34%)\n",
      "[epoch 32] loss: 0.0055619\n",
      "Test set: Average loss: 3.5270, Accuracy: 1697/5000 (34%)\n",
      "[epoch 33] loss: 0.0051023\n",
      "Test set: Average loss: 3.5496, Accuracy: 1693/5000 (34%)\n",
      "[epoch 34] loss: 0.0048025\n",
      "Test set: Average loss: 3.5727, Accuracy: 1694/5000 (34%)\n",
      "[epoch 35] loss: 0.0044715\n",
      "Test set: Average loss: 3.5928, Accuracy: 1696/5000 (34%)\n",
      "[epoch 36] loss: 0.0041927\n",
      "Test set: Average loss: 3.6160, Accuracy: 1703/5000 (34%)\n",
      "[epoch 37] loss: 0.0038874\n",
      "Test set: Average loss: 3.6361, Accuracy: 1693/5000 (34%)\n",
      "[epoch 38] loss: 0.0036756\n",
      "Test set: Average loss: 3.6514, Accuracy: 1694/5000 (34%)\n",
      "[epoch 39] loss: 0.0034332\n",
      "Test set: Average loss: 3.6716, Accuracy: 1701/5000 (34%)\n",
      "[epoch 40] loss: 0.0032708\n",
      "Test set: Average loss: 3.6883, Accuracy: 1696/5000 (34%)\n",
      "[epoch 41] loss: 0.0030983\n",
      "Test set: Average loss: 3.7074, Accuracy: 1702/5000 (34%)\n",
      "[epoch 42] loss: 0.0029556\n",
      "Test set: Average loss: 3.7214, Accuracy: 1698/5000 (34%)\n",
      "[epoch 43] loss: 0.0028207\n",
      "Test set: Average loss: 3.7390, Accuracy: 1695/5000 (34%)\n",
      "[epoch 44] loss: 0.0026846\n",
      "Test set: Average loss: 3.7561, Accuracy: 1694/5000 (34%)\n",
      "[epoch 45] loss: 0.0025348\n",
      "Test set: Average loss: 3.7728, Accuracy: 1693/5000 (34%)\n",
      "[epoch 46] loss: 0.0024037\n",
      "Test set: Average loss: 3.7869, Accuracy: 1694/5000 (34%)\n",
      "[epoch 47] loss: 0.0022884\n",
      "Test set: Average loss: 3.8034, Accuracy: 1691/5000 (34%)\n",
      "[epoch 48] loss: 0.0021874\n",
      "Test set: Average loss: 3.8148, Accuracy: 1698/5000 (34%)\n",
      "[epoch 49] loss: 0.0020946\n",
      "Test set: Average loss: 3.8295, Accuracy: 1694/5000 (34%)\n",
      "[epoch 50] loss: 0.0019920\n",
      "Test set: Average loss: 3.8436, Accuracy: 1699/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8750, Accuracy: 1743/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 1.8645, Accuracy: 3415/10000 (34%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3077, Accuracy: 410/5000 (8%)\n",
      "[epoch 1] loss: 2.2037454\n",
      "Test set: Average loss: 2.1513, Accuracy: 1117/5000 (22%)\n",
      "[epoch 2] loss: 1.9113686\n",
      "Test set: Average loss: 1.9031, Accuracy: 1617/5000 (32%)\n",
      "[epoch 3] loss: 1.6672251\n",
      "Test set: Average loss: 1.8282, Accuracy: 1770/5000 (35%)\n",
      "[epoch 4] loss: 1.4848623\n",
      "Test set: Average loss: 1.7465, Accuracy: 1929/5000 (39%)\n",
      "[epoch 5] loss: 1.2773531\n",
      "Test set: Average loss: 1.8894, Accuracy: 1806/5000 (36%)\n",
      "[epoch 6] loss: 1.1635966\n",
      "Test set: Average loss: 1.8772, Accuracy: 1851/5000 (37%)\n",
      "[epoch 7] loss: 0.9745781\n",
      "Test set: Average loss: 1.9393, Accuracy: 1870/5000 (37%)\n",
      "[epoch 8] loss: 0.7763847\n",
      "Test set: Average loss: 2.0219, Accuracy: 1818/5000 (36%)\n",
      "[epoch 9] loss: 0.6127029\n",
      "Test set: Average loss: 2.1040, Accuracy: 1846/5000 (37%)\n",
      "[epoch 10] loss: 0.4720427\n",
      "Test set: Average loss: 2.1892, Accuracy: 1848/5000 (37%)\n",
      "[epoch 11] loss: 0.3403707\n",
      "Test set: Average loss: 2.2804, Accuracy: 1835/5000 (37%)\n",
      "[epoch 12] loss: 0.2038817\n",
      "Test set: Average loss: 2.3709, Accuracy: 1859/5000 (37%)\n",
      "[epoch 13] loss: 0.1437804\n",
      "Test set: Average loss: 2.4420, Accuracy: 1858/5000 (37%)\n",
      "[epoch 14] loss: 0.0855544\n",
      "Test set: Average loss: 2.4807, Accuracy: 1869/5000 (37%)\n",
      "[epoch 15] loss: 0.0499054\n",
      "Test set: Average loss: 2.5514, Accuracy: 1880/5000 (38%)\n",
      "[epoch 16] loss: 0.0358562\n",
      "Test set: Average loss: 2.6049, Accuracy: 1900/5000 (38%)\n",
      "[epoch 17] loss: 0.0280109\n",
      "Test set: Average loss: 2.6545, Accuracy: 1888/5000 (38%)\n",
      "[epoch 18] loss: 0.0227671\n",
      "Test set: Average loss: 2.6973, Accuracy: 1876/5000 (38%)\n",
      "[epoch 19] loss: 0.0191353\n",
      "Test set: Average loss: 2.7434, Accuracy: 1885/5000 (38%)\n",
      "[epoch 20] loss: 0.0162206\n",
      "Test set: Average loss: 2.7758, Accuracy: 1880/5000 (38%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21] loss: 0.0139637\n",
      "Test set: Average loss: 2.8172, Accuracy: 1883/5000 (38%)\n",
      "[epoch 22] loss: 0.0122667\n",
      "Test set: Average loss: 2.8405, Accuracy: 1876/5000 (38%)\n",
      "[epoch 23] loss: 0.0110488\n",
      "Test set: Average loss: 2.8725, Accuracy: 1878/5000 (38%)\n",
      "[epoch 24] loss: 0.0097418\n",
      "Test set: Average loss: 2.8969, Accuracy: 1883/5000 (38%)\n",
      "[epoch 25] loss: 0.0088431\n",
      "Test set: Average loss: 2.9242, Accuracy: 1892/5000 (38%)\n",
      "[epoch 26] loss: 0.0078495\n",
      "Test set: Average loss: 2.9491, Accuracy: 1895/5000 (38%)\n",
      "[epoch 27] loss: 0.0071876\n",
      "Test set: Average loss: 2.9740, Accuracy: 1907/5000 (38%)\n",
      "[epoch 28] loss: 0.0066264\n",
      "Test set: Average loss: 2.9948, Accuracy: 1884/5000 (38%)\n",
      "[epoch 29] loss: 0.0060298\n",
      "Test set: Average loss: 3.0153, Accuracy: 1890/5000 (38%)\n",
      "[epoch 30] loss: 0.0055976\n",
      "Test set: Average loss: 3.0338, Accuracy: 1894/5000 (38%)\n",
      "[epoch 31] loss: 0.0051892\n",
      "Test set: Average loss: 3.0582, Accuracy: 1893/5000 (38%)\n",
      "[epoch 32] loss: 0.0047537\n",
      "Test set: Average loss: 3.0723, Accuracy: 1897/5000 (38%)\n",
      "[epoch 33] loss: 0.0044180\n",
      "Test set: Average loss: 3.0936, Accuracy: 1896/5000 (38%)\n",
      "[epoch 34] loss: 0.0041579\n",
      "Test set: Average loss: 3.1128, Accuracy: 1896/5000 (38%)\n",
      "[epoch 35] loss: 0.0038624\n",
      "Test set: Average loss: 3.1296, Accuracy: 1893/5000 (38%)\n",
      "[epoch 36] loss: 0.0036378\n",
      "Test set: Average loss: 3.1417, Accuracy: 1891/5000 (38%)\n",
      "[epoch 37] loss: 0.0034132\n",
      "Test set: Average loss: 3.1625, Accuracy: 1899/5000 (38%)\n",
      "[epoch 38] loss: 0.0032053\n",
      "Test set: Average loss: 3.1765, Accuracy: 1905/5000 (38%)\n",
      "[epoch 39] loss: 0.0029858\n",
      "Test set: Average loss: 3.1919, Accuracy: 1903/5000 (38%)\n",
      "[epoch 40] loss: 0.0028730\n",
      "Test set: Average loss: 3.2049, Accuracy: 1902/5000 (38%)\n",
      "[epoch 41] loss: 0.0027093\n",
      "Test set: Average loss: 3.2206, Accuracy: 1897/5000 (38%)\n",
      "[epoch 42] loss: 0.0025765\n",
      "Test set: Average loss: 3.2339, Accuracy: 1904/5000 (38%)\n",
      "[epoch 43] loss: 0.0024239\n",
      "Test set: Average loss: 3.2457, Accuracy: 1896/5000 (38%)\n",
      "[epoch 44] loss: 0.0023016\n",
      "Test set: Average loss: 3.2599, Accuracy: 1904/5000 (38%)\n",
      "[epoch 45] loss: 0.0021710\n",
      "Test set: Average loss: 3.2738, Accuracy: 1904/5000 (38%)\n",
      "[epoch 46] loss: 0.0021004\n",
      "Test set: Average loss: 3.2865, Accuracy: 1903/5000 (38%)\n",
      "[epoch 47] loss: 0.0019795\n",
      "Test set: Average loss: 3.2983, Accuracy: 1907/5000 (38%)\n",
      "[epoch 48] loss: 0.0018832\n",
      "Test set: Average loss: 3.3124, Accuracy: 1908/5000 (38%)\n",
      "[epoch 49] loss: 0.0018073\n",
      "Test set: Average loss: 3.3210, Accuracy: 1903/5000 (38%)\n",
      "[epoch 50] loss: 0.0017000\n",
      "Test set: Average loss: 3.3363, Accuracy: 1901/5000 (38%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7465, Accuracy: 1929/5000 (39%)\n",
      "Test\n",
      "Test set: Average loss: 1.7432, Accuracy: 3836/10000 (38%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3056, Accuracy: 446/5000 (9%)\n",
      "[epoch 1] loss: 2.1355246\n",
      "Test set: Average loss: 2.0030, Accuracy: 1277/5000 (26%)\n",
      "[epoch 2] loss: 1.7868453\n",
      "Test set: Average loss: 1.8898, Accuracy: 1594/5000 (32%)\n",
      "[epoch 3] loss: 1.5395829\n",
      "Test set: Average loss: 1.7056, Accuracy: 1875/5000 (38%)\n",
      "[epoch 4] loss: 1.3085926\n",
      "Test set: Average loss: 1.7287, Accuracy: 1895/5000 (38%)\n",
      "[epoch 5] loss: 1.1119690\n",
      "Test set: Average loss: 1.8806, Accuracy: 1841/5000 (37%)\n",
      "[epoch 6] loss: 0.9601155\n",
      "Test set: Average loss: 1.8561, Accuracy: 1944/5000 (39%)\n",
      "[epoch 7] loss: 0.7822012\n",
      "Test set: Average loss: 1.9137, Accuracy: 1961/5000 (39%)\n",
      "[epoch 8] loss: 0.5817373\n",
      "Test set: Average loss: 1.9861, Accuracy: 1999/5000 (40%)\n",
      "[epoch 9] loss: 0.4064459\n",
      "Test set: Average loss: 2.1020, Accuracy: 1982/5000 (40%)\n",
      "[epoch 10] loss: 0.2761968\n",
      "Test set: Average loss: 2.1702, Accuracy: 1970/5000 (39%)\n",
      "[epoch 11] loss: 0.1690031\n",
      "Test set: Average loss: 2.2614, Accuracy: 1968/5000 (39%)\n",
      "[epoch 12] loss: 0.1143764\n",
      "Test set: Average loss: 2.3689, Accuracy: 1954/5000 (39%)\n",
      "[epoch 13] loss: 0.0673850\n",
      "Test set: Average loss: 2.4366, Accuracy: 1980/5000 (40%)\n",
      "[epoch 14] loss: 0.0442744\n",
      "Test set: Average loss: 2.5270, Accuracy: 1935/5000 (39%)\n",
      "[epoch 15] loss: 0.0316427\n",
      "Test set: Average loss: 2.5697, Accuracy: 1961/5000 (39%)\n",
      "[epoch 16] loss: 0.0242549\n",
      "Test set: Average loss: 2.6076, Accuracy: 1976/5000 (40%)\n",
      "[epoch 17] loss: 0.0199565\n",
      "Test set: Average loss: 2.6708, Accuracy: 1957/5000 (39%)\n",
      "[epoch 18] loss: 0.0167375\n",
      "Test set: Average loss: 2.6997, Accuracy: 1972/5000 (39%)\n",
      "[epoch 19] loss: 0.0143097\n",
      "Test set: Average loss: 2.7498, Accuracy: 1957/5000 (39%)\n",
      "[epoch 20] loss: 0.0119934\n",
      "Test set: Average loss: 2.7815, Accuracy: 1963/5000 (39%)\n",
      "[epoch 21] loss: 0.0110068\n",
      "Test set: Average loss: 2.8041, Accuracy: 1965/5000 (39%)\n",
      "[epoch 22] loss: 0.0095455\n",
      "Test set: Average loss: 2.8422, Accuracy: 1961/5000 (39%)\n",
      "[epoch 23] loss: 0.0083753\n",
      "Test set: Average loss: 2.8717, Accuracy: 1964/5000 (39%)\n",
      "[epoch 24] loss: 0.0074842\n",
      "Test set: Average loss: 2.8977, Accuracy: 1974/5000 (39%)\n",
      "[epoch 25] loss: 0.0068255\n",
      "Test set: Average loss: 2.9215, Accuracy: 1967/5000 (39%)\n",
      "[epoch 26] loss: 0.0063449\n",
      "Test set: Average loss: 2.9438, Accuracy: 1960/5000 (39%)\n",
      "[epoch 27] loss: 0.0057635\n",
      "Test set: Average loss: 2.9731, Accuracy: 1966/5000 (39%)\n",
      "[epoch 28] loss: 0.0052645\n",
      "Test set: Average loss: 2.9981, Accuracy: 1960/5000 (39%)\n",
      "[epoch 29] loss: 0.0048324\n",
      "Test set: Average loss: 3.0183, Accuracy: 1955/5000 (39%)\n",
      "[epoch 30] loss: 0.0044712\n",
      "Test set: Average loss: 3.0334, Accuracy: 1952/5000 (39%)\n",
      "[epoch 31] loss: 0.0041031\n",
      "Test set: Average loss: 3.0525, Accuracy: 1956/5000 (39%)\n",
      "[epoch 32] loss: 0.0037827\n",
      "Test set: Average loss: 3.0690, Accuracy: 1958/5000 (39%)\n",
      "[epoch 33] loss: 0.0035817\n",
      "Test set: Average loss: 3.0925, Accuracy: 1951/5000 (39%)\n",
      "[epoch 34] loss: 0.0033519\n",
      "Test set: Average loss: 3.1036, Accuracy: 1960/5000 (39%)\n",
      "[epoch 35] loss: 0.0031278\n",
      "Test set: Average loss: 3.1292, Accuracy: 1965/5000 (39%)\n",
      "[epoch 36] loss: 0.0029270\n",
      "Test set: Average loss: 3.1437, Accuracy: 1956/5000 (39%)\n",
      "[epoch 37] loss: 0.0027421\n",
      "Test set: Average loss: 3.1563, Accuracy: 1961/5000 (39%)\n",
      "[epoch 38] loss: 0.0025950\n",
      "Test set: Average loss: 3.1700, Accuracy: 1961/5000 (39%)\n",
      "[epoch 39] loss: 0.0024465\n",
      "Test set: Average loss: 3.1904, Accuracy: 1955/5000 (39%)\n",
      "[epoch 40] loss: 0.0023071\n",
      "Test set: Average loss: 3.2033, Accuracy: 1955/5000 (39%)\n",
      "[epoch 41] loss: 0.0022031\n",
      "Test set: Average loss: 3.2180, Accuracy: 1953/5000 (39%)\n",
      "[epoch 42] loss: 0.0020862\n",
      "Test set: Average loss: 3.2330, Accuracy: 1956/5000 (39%)\n",
      "[epoch 43] loss: 0.0019799\n",
      "Test set: Average loss: 3.2462, Accuracy: 1963/5000 (39%)\n",
      "[epoch 44] loss: 0.0018763\n",
      "Test set: Average loss: 3.2597, Accuracy: 1960/5000 (39%)\n",
      "[epoch 45] loss: 0.0017792\n",
      "Test set: Average loss: 3.2774, Accuracy: 1949/5000 (39%)\n",
      "[epoch 46] loss: 0.0016917\n",
      "Test set: Average loss: 3.2856, Accuracy: 1947/5000 (39%)\n",
      "[epoch 47] loss: 0.0016143\n",
      "Test set: Average loss: 3.2971, Accuracy: 1949/5000 (39%)\n",
      "[epoch 48] loss: 0.0015588\n",
      "Test set: Average loss: 3.3091, Accuracy: 1955/5000 (39%)\n",
      "[epoch 49] loss: 0.0014658\n",
      "Test set: Average loss: 3.3220, Accuracy: 1949/5000 (39%)\n",
      "[epoch 50] loss: 0.0014072\n",
      "Test set: Average loss: 3.3360, Accuracy: 1954/5000 (39%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9861, Accuracy: 1999/5000 (40%)\n",
      "Test\n",
      "Test set: Average loss: 1.9697, Accuracy: 4010/10000 (40%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3052, Accuracy: 519/5000 (10%)\n",
      "[epoch 1] loss: 2.1826684\n",
      "Test set: Average loss: 2.0890, Accuracy: 1113/5000 (22%)\n",
      "[epoch 2] loss: 1.8828627\n",
      "Test set: Average loss: 1.8530, Accuracy: 1685/5000 (34%)\n",
      "[epoch 3] loss: 1.6755801\n",
      "Test set: Average loss: 1.8006, Accuracy: 1781/5000 (36%)\n",
      "[epoch 4] loss: 1.5258787\n",
      "Test set: Average loss: 1.8592, Accuracy: 1752/5000 (35%)\n",
      "[epoch 5] loss: 1.4259938\n",
      "Test set: Average loss: 1.8305, Accuracy: 1779/5000 (36%)\n",
      "[epoch 6] loss: 1.2015422\n",
      "Test set: Average loss: 1.8457, Accuracy: 1834/5000 (37%)\n",
      "[epoch 7] loss: 1.0365487\n",
      "Test set: Average loss: 1.9394, Accuracy: 1745/5000 (35%)\n",
      "[epoch 8] loss: 0.8525085\n",
      "Test set: Average loss: 1.9613, Accuracy: 1855/5000 (37%)\n",
      "[epoch 9] loss: 0.6630614\n",
      "Test set: Average loss: 2.0048, Accuracy: 1823/5000 (36%)\n",
      "[epoch 10] loss: 0.4680895\n",
      "Test set: Average loss: 2.0666, Accuracy: 1841/5000 (37%)\n",
      "[epoch 11] loss: 0.3291901\n",
      "Test set: Average loss: 2.1285, Accuracy: 1856/5000 (37%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] loss: 0.2208507\n",
      "Test set: Average loss: 2.2223, Accuracy: 1877/5000 (38%)\n",
      "[epoch 13] loss: 0.1472036\n",
      "Test set: Average loss: 2.2610, Accuracy: 1882/5000 (38%)\n",
      "[epoch 14] loss: 0.0989269\n",
      "Test set: Average loss: 2.3180, Accuracy: 1869/5000 (37%)\n",
      "[epoch 15] loss: 0.0669840\n",
      "Test set: Average loss: 2.3647, Accuracy: 1884/5000 (38%)\n",
      "[epoch 16] loss: 0.0484193\n",
      "Test set: Average loss: 2.3905, Accuracy: 1906/5000 (38%)\n",
      "[epoch 17] loss: 0.0360009\n",
      "Test set: Average loss: 2.4334, Accuracy: 1903/5000 (38%)\n",
      "[epoch 18] loss: 0.0275110\n",
      "Test set: Average loss: 2.4786, Accuracy: 1898/5000 (38%)\n",
      "[epoch 19] loss: 0.0220406\n",
      "Test set: Average loss: 2.5062, Accuracy: 1906/5000 (38%)\n",
      "[epoch 20] loss: 0.0179743\n",
      "Test set: Average loss: 2.5403, Accuracy: 1903/5000 (38%)\n",
      "[epoch 21] loss: 0.0156443\n",
      "Test set: Average loss: 2.5660, Accuracy: 1900/5000 (38%)\n",
      "[epoch 22] loss: 0.0136377\n",
      "Test set: Average loss: 2.5894, Accuracy: 1910/5000 (38%)\n",
      "[epoch 23] loss: 0.0118186\n",
      "Test set: Average loss: 2.6200, Accuracy: 1892/5000 (38%)\n",
      "[epoch 24] loss: 0.0103703\n",
      "Test set: Average loss: 2.6432, Accuracy: 1902/5000 (38%)\n",
      "[epoch 25] loss: 0.0093517\n",
      "Test set: Average loss: 2.6659, Accuracy: 1903/5000 (38%)\n",
      "[epoch 26] loss: 0.0083773\n",
      "Test set: Average loss: 2.6851, Accuracy: 1891/5000 (38%)\n",
      "[epoch 27] loss: 0.0075699\n",
      "Test set: Average loss: 2.7035, Accuracy: 1901/5000 (38%)\n",
      "[epoch 28] loss: 0.0068126\n",
      "Test set: Average loss: 2.7235, Accuracy: 1891/5000 (38%)\n",
      "[epoch 29] loss: 0.0062803\n",
      "Test set: Average loss: 2.7422, Accuracy: 1889/5000 (38%)\n",
      "[epoch 30] loss: 0.0057326\n",
      "Test set: Average loss: 2.7556, Accuracy: 1898/5000 (38%)\n",
      "[epoch 31] loss: 0.0052964\n",
      "Test set: Average loss: 2.7776, Accuracy: 1885/5000 (38%)\n",
      "[epoch 32] loss: 0.3274108\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.1149, Accuracy: 1735/5000 (35%)\n",
      "[epoch 33] loss: 0.0548085\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.8414, Accuracy: 1820/5000 (36%)\n",
      "[epoch 34] loss: 0.0180128\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.8347, Accuracy: 1831/5000 (37%)\n",
      "[epoch 35] loss: 0.0171333\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 36] loss: 0.0171225\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 37] loss: 0.0171933\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 38] loss: 0.0169737\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 39] loss: 0.0169918\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 40] loss: 0.0190039\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 41] loss: 0.0258760\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 42] loss: 0.0170443\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 43] loss: 0.0170774\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 44] loss: 0.0170841\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 45] loss: 0.0169629\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 46] loss: 0.0170826\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 47] loss: 0.0173296\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 48] loss: 0.0171763\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 49] loss: 0.0174267\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "[epoch 50] loss: 0.0171397\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.8343, Accuracy: 1832/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5894, Accuracy: 1910/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 2.5928, Accuracy: 3808/10000 (38%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3005, Accuracy: 600/5000 (12%)\n",
      "[epoch 1] loss: 2.0215752\n",
      "Test set: Average loss: 1.8244, Accuracy: 1727/5000 (35%)\n",
      "[epoch 2] loss: 1.6904166\n",
      "Test set: Average loss: 1.7451, Accuracy: 1870/5000 (37%)\n",
      "[epoch 3] loss: 1.4786528\n",
      "Test set: Average loss: 1.5650, Accuracy: 2207/5000 (44%)\n",
      "[epoch 4] loss: 1.3056901\n",
      "Test set: Average loss: 1.6281, Accuracy: 2142/5000 (43%)\n",
      "[epoch 5] loss: 1.1623243\n",
      "Test set: Average loss: 1.7501, Accuracy: 2030/5000 (41%)\n",
      "[epoch 6] loss: 1.0306917\n",
      "Test set: Average loss: 1.7359, Accuracy: 2085/5000 (42%)\n",
      "[epoch 7] loss: 0.8705457\n",
      "Test set: Average loss: 1.7524, Accuracy: 2161/5000 (43%)\n",
      "[epoch 8] loss: 0.6707589\n",
      "Test set: Average loss: 1.8254, Accuracy: 2116/5000 (42%)\n",
      "[epoch 9] loss: 0.4787989\n",
      "Test set: Average loss: 1.9043, Accuracy: 2158/5000 (43%)\n",
      "[epoch 10] loss: 0.3011536\n",
      "Test set: Average loss: 1.9579, Accuracy: 2167/5000 (43%)\n",
      "[epoch 11] loss: 0.1875246\n",
      "Test set: Average loss: 2.0811, Accuracy: 2159/5000 (43%)\n",
      "[epoch 12] loss: 0.1165037\n",
      "Test set: Average loss: 2.1605, Accuracy: 2170/5000 (43%)\n",
      "[epoch 13] loss: 0.0583057\n",
      "Test set: Average loss: 2.2231, Accuracy: 2193/5000 (44%)\n",
      "[epoch 14] loss: 0.0364853\n",
      "Test set: Average loss: 2.2671, Accuracy: 2178/5000 (44%)\n",
      "[epoch 15] loss: 0.0247185\n",
      "Test set: Average loss: 2.3145, Accuracy: 2183/5000 (44%)\n",
      "[epoch 16] loss: 0.0184279\n",
      "Test set: Average loss: 2.3585, Accuracy: 2182/5000 (44%)\n",
      "[epoch 17] loss: 0.0148036\n",
      "Test set: Average loss: 2.4067, Accuracy: 2187/5000 (44%)\n",
      "[epoch 18] loss: 0.0120530\n",
      "Test set: Average loss: 2.4475, Accuracy: 2163/5000 (43%)\n",
      "[epoch 19] loss: 0.0101574\n",
      "Test set: Average loss: 2.4834, Accuracy: 2178/5000 (44%)\n",
      "[epoch 20] loss: 0.0087364\n",
      "Test set: Average loss: 2.5184, Accuracy: 2197/5000 (44%)\n",
      "[epoch 21] loss: 0.0075922\n",
      "Test set: Average loss: 2.5484, Accuracy: 2174/5000 (43%)\n",
      "[epoch 22] loss: 0.0065686\n",
      "Test set: Average loss: 2.5798, Accuracy: 2170/5000 (43%)\n",
      "[epoch 23] loss: 0.0058338\n",
      "Test set: Average loss: 2.6076, Accuracy: 2171/5000 (43%)\n",
      "[epoch 24] loss: 0.0051643\n",
      "Test set: Average loss: 2.6338, Accuracy: 2182/5000 (44%)\n",
      "[epoch 25] loss: 0.0045707\n",
      "Test set: Average loss: 2.6586, Accuracy: 2174/5000 (43%)\n",
      "[epoch 26] loss: 0.0041180\n",
      "Test set: Average loss: 2.6854, Accuracy: 2190/5000 (44%)\n",
      "[epoch 27] loss: 0.0037199\n",
      "Test set: Average loss: 2.7071, Accuracy: 2177/5000 (44%)\n",
      "[epoch 28] loss: 0.0033662\n",
      "Test set: Average loss: 2.7278, Accuracy: 2176/5000 (44%)\n",
      "[epoch 29] loss: 0.0030819\n",
      "Test set: Average loss: 2.7494, Accuracy: 2176/5000 (44%)\n",
      "[epoch 30] loss: 0.0028244\n",
      "Test set: Average loss: 2.7686, Accuracy: 2179/5000 (44%)\n",
      "[epoch 31] loss: 0.0025599\n",
      "Test set: Average loss: 2.7908, Accuracy: 2175/5000 (44%)\n",
      "[epoch 32] loss: 0.0023689\n",
      "Test set: Average loss: 2.8104, Accuracy: 2179/5000 (44%)\n",
      "[epoch 33] loss: 0.0021542\n",
      "Test set: Average loss: 2.8298, Accuracy: 2178/5000 (44%)\n",
      "[epoch 34] loss: 0.0020047\n",
      "Test set: Average loss: 2.8485, Accuracy: 2175/5000 (44%)\n",
      "[epoch 35] loss: 0.0018669\n",
      "Test set: Average loss: 2.8651, Accuracy: 2186/5000 (44%)\n",
      "[epoch 36] loss: 0.0017236\n",
      "Test set: Average loss: 2.8863, Accuracy: 2185/5000 (44%)\n",
      "[epoch 37] loss: 0.0015936\n",
      "Test set: Average loss: 2.9038, Accuracy: 2179/5000 (44%)\n",
      "[epoch 38] loss: 0.0014671\n",
      "Test set: Average loss: 2.9204, Accuracy: 2178/5000 (44%)\n",
      "[epoch 39] loss: 0.0013650\n",
      "Test set: Average loss: 2.9364, Accuracy: 2181/5000 (44%)\n",
      "[epoch 40] loss: 0.0012725\n",
      "Test set: Average loss: 2.9523, Accuracy: 2183/5000 (44%)\n",
      "[epoch 41] loss: 0.0011842\n",
      "Test set: Average loss: 2.9663, Accuracy: 2188/5000 (44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 42] loss: 0.0011023\n",
      "Test set: Average loss: 2.9825, Accuracy: 2182/5000 (44%)\n",
      "[epoch 43] loss: 0.0010280\n",
      "Test set: Average loss: 2.9990, Accuracy: 2192/5000 (44%)\n",
      "[epoch 44] loss: 0.0009694\n",
      "Test set: Average loss: 3.0120, Accuracy: 2182/5000 (44%)\n",
      "[epoch 45] loss: 0.0009094\n",
      "Test set: Average loss: 3.0300, Accuracy: 2184/5000 (44%)\n",
      "[epoch 46] loss: 0.0008562\n",
      "Test set: Average loss: 3.0439, Accuracy: 2185/5000 (44%)\n",
      "[epoch 47] loss: 0.0008010\n",
      "Test set: Average loss: 3.0553, Accuracy: 2181/5000 (44%)\n",
      "[epoch 48] loss: 0.0007557\n",
      "Test set: Average loss: 3.0695, Accuracy: 2181/5000 (44%)\n",
      "[epoch 49] loss: 0.0007105\n",
      "Test set: Average loss: 3.0824, Accuracy: 2182/5000 (44%)\n",
      "[epoch 50] loss: 0.0006678\n",
      "Test set: Average loss: 3.0963, Accuracy: 2180/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5650, Accuracy: 2207/5000 (44%)\n",
      "Test\n",
      "Test set: Average loss: 1.5477, Accuracy: 4482/10000 (45%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3012, Accuracy: 559/5000 (11%)\n",
      "[epoch 1] loss: 1.9971741\n",
      "Test set: Average loss: 1.8148, Accuracy: 1708/5000 (34%)\n",
      "[epoch 2] loss: 1.6506220\n",
      "Test set: Average loss: 1.6420, Accuracy: 1995/5000 (40%)\n",
      "[epoch 3] loss: 1.4805134\n",
      "Test set: Average loss: 1.6035, Accuracy: 2089/5000 (42%)\n",
      "[epoch 4] loss: 1.3310775\n",
      "Test set: Average loss: 1.6517, Accuracy: 2076/5000 (42%)\n",
      "[epoch 5] loss: 1.1889729\n",
      "Test set: Average loss: 1.8573, Accuracy: 1969/5000 (39%)\n",
      "[epoch 6] loss: 1.0799987\n",
      "Test set: Average loss: 1.7068, Accuracy: 2128/5000 (43%)\n",
      "[epoch 7] loss: 0.8635366\n",
      "Test set: Average loss: 1.7914, Accuracy: 2048/5000 (41%)\n",
      "[epoch 8] loss: 0.7083026\n",
      "Test set: Average loss: 1.8302, Accuracy: 2105/5000 (42%)\n",
      "[epoch 9] loss: 0.4981369\n",
      "Test set: Average loss: 1.8628, Accuracy: 2160/5000 (43%)\n",
      "[epoch 10] loss: 0.3372516\n",
      "Test set: Average loss: 1.9510, Accuracy: 2111/5000 (42%)\n",
      "[epoch 11] loss: 0.1996765\n",
      "Test set: Average loss: 2.0317, Accuracy: 2159/5000 (43%)\n",
      "[epoch 12] loss: 0.1207660\n",
      "Test set: Average loss: 2.1602, Accuracy: 2101/5000 (42%)\n",
      "[epoch 13] loss: 0.1856601\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2829, Accuracy: 2038/5000 (41%)\n",
      "[epoch 14] loss: 0.0583792\n",
      "Test set: Average loss: 2.2229, Accuracy: 2112/5000 (42%)\n",
      "[epoch 15] loss: 0.0380365\n",
      "Test set: Average loss: 2.2191, Accuracy: 2136/5000 (43%)\n",
      "[epoch 16] loss: 0.0340205\n",
      "Test set: Average loss: 2.2232, Accuracy: 2130/5000 (43%)\n",
      "[epoch 17] loss: 0.0316891\n",
      "Test set: Average loss: 2.2287, Accuracy: 2134/5000 (43%)\n",
      "[epoch 18] loss: 0.0306094\n",
      "Test set: Average loss: 2.2356, Accuracy: 2140/5000 (43%)\n",
      "[epoch 19] loss: 0.0283853\n",
      "Test set: Average loss: 2.2426, Accuracy: 2148/5000 (43%)\n",
      "[epoch 20] loss: 0.0271056\n",
      "Test set: Average loss: 2.2508, Accuracy: 2151/5000 (43%)\n",
      "[epoch 21] loss: 0.0261396\n",
      "Test set: Average loss: 2.2584, Accuracy: 2151/5000 (43%)\n",
      "[epoch 22] loss: 0.0253059\n",
      "Test set: Average loss: 2.2671, Accuracy: 2154/5000 (43%)\n",
      "[epoch 23] loss: 0.0238482\n",
      "Test set: Average loss: 2.2759, Accuracy: 2155/5000 (43%)\n",
      "[epoch 24] loss: 0.0233323\n",
      "Test set: Average loss: 2.2856, Accuracy: 2154/5000 (43%)\n",
      "[epoch 25] loss: 0.0224223\n",
      "Test set: Average loss: 2.2932, Accuracy: 2160/5000 (43%)\n",
      "[epoch 26] loss: 0.0214444\n",
      "Test set: Average loss: 2.3021, Accuracy: 2154/5000 (43%)\n",
      "[epoch 27] loss: 0.0206064\n",
      "Test set: Average loss: 2.3127, Accuracy: 2162/5000 (43%)\n",
      "[epoch 28] loss: 0.0199368\n",
      "Test set: Average loss: 2.3224, Accuracy: 2161/5000 (43%)\n",
      "[epoch 29] loss: 0.0192224\n",
      "Test set: Average loss: 2.3342, Accuracy: 2159/5000 (43%)\n",
      "[epoch 30] loss: 0.0184708\n",
      "Test set: Average loss: 2.3431, Accuracy: 2156/5000 (43%)\n",
      "[epoch 31] loss: 0.0179064\n",
      "Test set: Average loss: 2.3524, Accuracy: 2160/5000 (43%)\n",
      "[epoch 32] loss: 0.0170470\n",
      "Test set: Average loss: 2.3620, Accuracy: 2154/5000 (43%)\n",
      "[epoch 33] loss: 0.0164252\n",
      "Test set: Average loss: 2.3725, Accuracy: 2155/5000 (43%)\n",
      "[epoch 34] loss: 0.0157702\n",
      "Test set: Average loss: 2.3836, Accuracy: 2164/5000 (43%)\n",
      "[epoch 35] loss: 0.0151360\n",
      "Test set: Average loss: 2.3918, Accuracy: 2164/5000 (43%)\n",
      "[epoch 36] loss: 0.0146878\n",
      "Test set: Average loss: 2.4037, Accuracy: 2166/5000 (43%)\n",
      "[epoch 37] loss: 0.0138958\n",
      "Test set: Average loss: 2.4126, Accuracy: 2159/5000 (43%)\n",
      "[epoch 38] loss: 0.0133679\n",
      "Test set: Average loss: 2.4238, Accuracy: 2169/5000 (43%)\n",
      "[epoch 39] loss: 0.0128564\n",
      "Test set: Average loss: 2.4324, Accuracy: 2157/5000 (43%)\n",
      "[epoch 40] loss: 0.0124234\n",
      "Test set: Average loss: 2.4431, Accuracy: 2159/5000 (43%)\n",
      "[epoch 41] loss: 0.1622288\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4618, Accuracy: 2144/5000 (43%)\n",
      "[epoch 42] loss: 0.0130803\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.4719, Accuracy: 2126/5000 (43%)\n",
      "[epoch 43] loss: 0.0126721\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.4713, Accuracy: 2128/5000 (43%)\n",
      "[epoch 44] loss: 0.0126838\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "[epoch 45] loss: 0.0126934\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "[epoch 46] loss: 0.0126632\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "[epoch 47] loss: 0.0126303\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "[epoch 48] loss: 0.0126806\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "[epoch 49] loss: 0.0127066\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "[epoch 50] loss: 0.0127140\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.4712, Accuracy: 2131/5000 (43%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4238, Accuracy: 2169/5000 (43%)\n",
      "Test\n",
      "Test set: Average loss: 2.3721, Accuracy: 4399/10000 (44%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3082, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 2.0160899\n",
      "Test set: Average loss: 1.7856, Accuracy: 1775/5000 (36%)\n",
      "[epoch 2] loss: 1.7362578\n",
      "Test set: Average loss: 1.6898, Accuracy: 1946/5000 (39%)\n",
      "[epoch 3] loss: 1.5415127\n",
      "Test set: Average loss: 1.5986, Accuracy: 2125/5000 (42%)\n",
      "[epoch 4] loss: 1.4095985\n",
      "Test set: Average loss: 1.5832, Accuracy: 2141/5000 (43%)\n",
      "[epoch 5] loss: 1.2891806\n",
      "Test set: Average loss: 1.6476, Accuracy: 2141/5000 (43%)\n",
      "[epoch 6] loss: 1.1260834\n",
      "Test set: Average loss: 1.6924, Accuracy: 2170/5000 (43%)\n",
      "[epoch 7] loss: 0.9610168\n",
      "Test set: Average loss: 1.7157, Accuracy: 2165/5000 (43%)\n",
      "[epoch 8] loss: 0.7860840\n",
      "Test set: Average loss: 1.7119, Accuracy: 2254/5000 (45%)\n",
      "[epoch 9] loss: 0.5945979\n",
      "Test set: Average loss: 1.8229, Accuracy: 2157/5000 (43%)\n",
      "[epoch 10] loss: 0.4295759\n",
      "Test set: Average loss: 1.9195, Accuracy: 2186/5000 (44%)\n",
      "[epoch 11] loss: 0.2954001\n",
      "Test set: Average loss: 1.9861, Accuracy: 2218/5000 (44%)\n",
      "[epoch 12] loss: 0.1744017\n",
      "Test set: Average loss: 2.0661, Accuracy: 2181/5000 (44%)\n",
      "[epoch 13] loss: 0.1001377\n",
      "Test set: Average loss: 2.0986, Accuracy: 2219/5000 (44%)\n",
      "[epoch 14] loss: 0.0640839\n",
      "Test set: Average loss: 2.1743, Accuracy: 2225/5000 (44%)\n",
      "[epoch 15] loss: 0.0392625\n",
      "Test set: Average loss: 2.2307, Accuracy: 2245/5000 (45%)\n",
      "[epoch 16] loss: 0.0304209\n",
      "Test set: Average loss: 2.2865, Accuracy: 2227/5000 (45%)\n",
      "[epoch 17] loss: 0.1203654\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5084, Accuracy: 2141/5000 (43%)\n",
      "[epoch 18] loss: 0.0547774\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3359, Accuracy: 2225/5000 (44%)\n",
      "[epoch 19] loss: 0.1517941\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3343, Accuracy: 2221/5000 (44%)\n",
      "[epoch 20] loss: 0.0258996\n",
      "Test set: Average loss: 2.3343, Accuracy: 2219/5000 (44%)\n",
      "[epoch 21] loss: 0.0257806\n",
      "Test set: Average loss: 2.3341, Accuracy: 2219/5000 (44%)\n",
      "[epoch 22] loss: 0.0257559\n",
      "Test set: Average loss: 2.3340, Accuracy: 2218/5000 (44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] loss: 0.0256681\n",
      "Test set: Average loss: 2.3338, Accuracy: 2218/5000 (44%)\n",
      "[epoch 24] loss: 0.0256813\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 25] loss: 0.1433697\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 26] loss: 0.0254800\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 27] loss: 0.0255306\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 28] loss: 0.0257903\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 29] loss: 0.0255992\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 30] loss: 0.0256033\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 31] loss: 0.0256396\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 32] loss: 0.0255699\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 33] loss: 0.1767488\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 34] loss: 0.0256045\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 35] loss: 0.1522711\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 36] loss: 0.0255126\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 37] loss: 0.0257723\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 38] loss: 0.0255525\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 39] loss: 0.0254869\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 40] loss: 0.0258124\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 41] loss: 0.0258067\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 42] loss: 0.0255314\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 43] loss: 0.0255966\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 44] loss: 0.0255057\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 45] loss: 0.0255462\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 46] loss: 0.0257003\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 47] loss: 0.0255232\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 48] loss: 0.0255186\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 49] loss: 0.0255140\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "[epoch 50] loss: 0.0255410\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.3337, Accuracy: 2218/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7119, Accuracy: 2254/5000 (45%)\n",
      "Test\n",
      "Test set: Average loss: 1.7120, Accuracy: 4478/10000 (45%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3069, Accuracy: 456/5000 (9%)\n",
      "[epoch 1] loss: 1.8615298\n",
      "Test set: Average loss: 1.6271, Accuracy: 2044/5000 (41%)\n",
      "[epoch 2] loss: 1.5239231\n",
      "Test set: Average loss: 1.6094, Accuracy: 2060/5000 (41%)\n",
      "[epoch 3] loss: 1.3767824\n",
      "Test set: Average loss: 1.5413, Accuracy: 2245/5000 (45%)\n",
      "[epoch 4] loss: 1.2697669\n",
      "Test set: Average loss: 1.5264, Accuracy: 2287/5000 (46%)\n",
      "[epoch 5] loss: 1.1290742\n",
      "Test set: Average loss: 1.5265, Accuracy: 2319/5000 (46%)\n",
      "[epoch 6] loss: 0.9942487\n",
      "Test set: Average loss: 1.5397, Accuracy: 2325/5000 (46%)\n",
      "[epoch 7] loss: 0.7992294\n",
      "Test set: Average loss: 1.6439, Accuracy: 2267/5000 (45%)\n",
      "[epoch 8] loss: 0.6218996\n",
      "Test set: Average loss: 1.6238, Accuracy: 2386/5000 (48%)\n",
      "[epoch 9] loss: 0.4208292\n",
      "Test set: Average loss: 1.6587, Accuracy: 2388/5000 (48%)\n",
      "[epoch 10] loss: 0.2428770\n",
      "Test set: Average loss: 1.7864, Accuracy: 2379/5000 (48%)\n",
      "[epoch 11] loss: 0.1182804\n",
      "Test set: Average loss: 1.8274, Accuracy: 2398/5000 (48%)\n",
      "[epoch 12] loss: 0.0608018\n",
      "Test set: Average loss: 1.8860, Accuracy: 2433/5000 (49%)\n",
      "[epoch 13] loss: 0.0314146\n",
      "Test set: Average loss: 1.9326, Accuracy: 2441/5000 (49%)\n",
      "[epoch 14] loss: 0.0199734\n",
      "Test set: Average loss: 1.9950, Accuracy: 2452/5000 (49%)\n",
      "[epoch 15] loss: 0.0145909\n",
      "Test set: Average loss: 2.0488, Accuracy: 2450/5000 (49%)\n",
      "[epoch 16] loss: 0.0113080\n",
      "Test set: Average loss: 2.0952, Accuracy: 2446/5000 (49%)\n",
      "[epoch 17] loss: 0.0091086\n",
      "Test set: Average loss: 2.1315, Accuracy: 2454/5000 (49%)\n",
      "[epoch 18] loss: 0.0074409\n",
      "Test set: Average loss: 2.1616, Accuracy: 2466/5000 (49%)\n",
      "[epoch 19] loss: 0.0061709\n",
      "Test set: Average loss: 2.1979, Accuracy: 2459/5000 (49%)\n",
      "[epoch 20] loss: 0.0052127\n",
      "Test set: Average loss: 2.2376, Accuracy: 2442/5000 (49%)\n",
      "[epoch 21] loss: 0.0044460\n",
      "Test set: Average loss: 2.2645, Accuracy: 2440/5000 (49%)\n",
      "[epoch 22] loss: 0.0038224\n",
      "Test set: Average loss: 2.2938, Accuracy: 2463/5000 (49%)\n",
      "[epoch 23] loss: 0.0033483\n",
      "Test set: Average loss: 2.3214, Accuracy: 2457/5000 (49%)\n",
      "[epoch 24] loss: 0.0028973\n",
      "Test set: Average loss: 2.3505, Accuracy: 2451/5000 (49%)\n",
      "[epoch 25] loss: 0.0025334\n",
      "Test set: Average loss: 2.3708, Accuracy: 2451/5000 (49%)\n",
      "[epoch 26] loss: 0.0022280\n",
      "Test set: Average loss: 2.3956, Accuracy: 2447/5000 (49%)\n",
      "[epoch 27] loss: 0.0019670\n",
      "Test set: Average loss: 2.4260, Accuracy: 2457/5000 (49%)\n",
      "[epoch 28] loss: 0.0017404\n",
      "Test set: Average loss: 2.4468, Accuracy: 2456/5000 (49%)\n",
      "[epoch 29] loss: 0.0015524\n",
      "Test set: Average loss: 2.4702, Accuracy: 2453/5000 (49%)\n",
      "[epoch 30] loss: 0.0013748\n",
      "Test set: Average loss: 2.4933, Accuracy: 2445/5000 (49%)\n",
      "[epoch 31] loss: 0.0012246\n",
      "Test set: Average loss: 2.5160, Accuracy: 2442/5000 (49%)\n",
      "[epoch 32] loss: 0.0010972\n",
      "Test set: Average loss: 2.5385, Accuracy: 2439/5000 (49%)\n",
      "[epoch 33] loss: 0.0009822\n",
      "Test set: Average loss: 2.5620, Accuracy: 2447/5000 (49%)\n",
      "[epoch 34] loss: 0.0008827\n",
      "Test set: Average loss: 2.5830, Accuracy: 2442/5000 (49%)\n",
      "[epoch 35] loss: 0.0007932\n",
      "Test set: Average loss: 2.6022, Accuracy: 2444/5000 (49%)\n",
      "[epoch 36] loss: 0.0007179\n",
      "Test set: Average loss: 2.6224, Accuracy: 2445/5000 (49%)\n",
      "[epoch 37] loss: 0.0006490\n",
      "Test set: Average loss: 2.6468, Accuracy: 2442/5000 (49%)\n",
      "[epoch 38] loss: 0.0005814\n",
      "Test set: Average loss: 2.6629, Accuracy: 2440/5000 (49%)\n",
      "[epoch 39] loss: 0.0005252\n",
      "Test set: Average loss: 2.6833, Accuracy: 2438/5000 (49%)\n",
      "[epoch 40] loss: 0.0004759\n",
      "Test set: Average loss: 2.7047, Accuracy: 2434/5000 (49%)\n",
      "[epoch 41] loss: 0.0004307\n",
      "Test set: Average loss: 2.7241, Accuracy: 2435/5000 (49%)\n",
      "[epoch 42] loss: 0.0003898\n",
      "Test set: Average loss: 2.7401, Accuracy: 2442/5000 (49%)\n",
      "[epoch 43] loss: 0.0003535\n",
      "Test set: Average loss: 2.7620, Accuracy: 2432/5000 (49%)\n",
      "[epoch 44] loss: 0.0003202\n",
      "Test set: Average loss: 2.7855, Accuracy: 2433/5000 (49%)\n",
      "[epoch 45] loss: 0.0002918\n",
      "Test set: Average loss: 2.8008, Accuracy: 2427/5000 (49%)\n",
      "[epoch 46] loss: 0.0002636\n",
      "Test set: Average loss: 2.8262, Accuracy: 2435/5000 (49%)\n",
      "[epoch 47] loss: 0.0002403\n",
      "Test set: Average loss: 2.8403, Accuracy: 2433/5000 (49%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 48] loss: 0.0002182\n",
      "Test set: Average loss: 2.8635, Accuracy: 2427/5000 (49%)\n",
      "[epoch 49] loss: 0.0002000\n",
      "Test set: Average loss: 2.8791, Accuracy: 2427/5000 (49%)\n",
      "[epoch 50] loss: 0.0001815\n",
      "Test set: Average loss: 2.8972, Accuracy: 2429/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1616, Accuracy: 2466/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 2.1392, Accuracy: 4951/10000 (50%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3100, Accuracy: 439/5000 (9%)\n",
      "[epoch 1] loss: 1.8466471\n",
      "Test set: Average loss: 1.6599, Accuracy: 1939/5000 (39%)\n",
      "[epoch 2] loss: 1.5546721\n",
      "Test set: Average loss: 1.5453, Accuracy: 2149/5000 (43%)\n",
      "[epoch 3] loss: 1.4174728\n",
      "Test set: Average loss: 1.4960, Accuracy: 2338/5000 (47%)\n",
      "[epoch 4] loss: 1.2983458\n",
      "Test set: Average loss: 1.5427, Accuracy: 2287/5000 (46%)\n",
      "[epoch 5] loss: 1.1601628\n",
      "Test set: Average loss: 1.5444, Accuracy: 2348/5000 (47%)\n",
      "[epoch 6] loss: 1.0190125\n",
      "Test set: Average loss: 1.5328, Accuracy: 2353/5000 (47%)\n",
      "[epoch 7] loss: 0.8345923\n",
      "Test set: Average loss: 1.6210, Accuracy: 2313/5000 (46%)\n",
      "[epoch 8] loss: 0.6272898\n",
      "Test set: Average loss: 1.6340, Accuracy: 2352/5000 (47%)\n",
      "[epoch 9] loss: 0.4196317\n",
      "Test set: Average loss: 1.7187, Accuracy: 2334/5000 (47%)\n",
      "[epoch 10] loss: 0.2426347\n",
      "Test set: Average loss: 1.7600, Accuracy: 2400/5000 (48%)\n",
      "[epoch 11] loss: 0.1262689\n",
      "Test set: Average loss: 1.8435, Accuracy: 2378/5000 (48%)\n",
      "[epoch 12] loss: 0.0657432\n",
      "Test set: Average loss: 1.9279, Accuracy: 2359/5000 (47%)\n",
      "[epoch 13] loss: 0.0367232\n",
      "Test set: Average loss: 1.9854, Accuracy: 2366/5000 (47%)\n",
      "[epoch 14] loss: 0.0228642\n",
      "Test set: Average loss: 2.0269, Accuracy: 2359/5000 (47%)\n",
      "[epoch 15] loss: 0.0160620\n",
      "Test set: Average loss: 2.0943, Accuracy: 2369/5000 (47%)\n",
      "[epoch 16] loss: 0.0124737\n",
      "Test set: Average loss: 2.1378, Accuracy: 2370/5000 (47%)\n",
      "[epoch 17] loss: 0.0097044\n",
      "Test set: Average loss: 2.1765, Accuracy: 2364/5000 (47%)\n",
      "[epoch 18] loss: 0.0078349\n",
      "Test set: Average loss: 2.2182, Accuracy: 2366/5000 (47%)\n",
      "[epoch 19] loss: 0.0065128\n",
      "Test set: Average loss: 2.2586, Accuracy: 2369/5000 (47%)\n",
      "[epoch 20] loss: 0.0054606\n",
      "Test set: Average loss: 2.2878, Accuracy: 2362/5000 (47%)\n",
      "[epoch 21] loss: 0.0046356\n",
      "Test set: Average loss: 2.3224, Accuracy: 2364/5000 (47%)\n",
      "[epoch 22] loss: 0.0039623\n",
      "Test set: Average loss: 2.3518, Accuracy: 2369/5000 (47%)\n",
      "[epoch 23] loss: 0.0034094\n",
      "Test set: Average loss: 2.3818, Accuracy: 2357/5000 (47%)\n",
      "[epoch 24] loss: 0.0029604\n",
      "Test set: Average loss: 2.4068, Accuracy: 2377/5000 (48%)\n",
      "[epoch 25] loss: 0.0025904\n",
      "Test set: Average loss: 2.4370, Accuracy: 2369/5000 (47%)\n",
      "[epoch 26] loss: 0.0022707\n",
      "Test set: Average loss: 2.4636, Accuracy: 2376/5000 (48%)\n",
      "[epoch 27] loss: 0.0019916\n",
      "Test set: Average loss: 2.4851, Accuracy: 2366/5000 (47%)\n",
      "[epoch 28] loss: 0.0017688\n",
      "Test set: Average loss: 2.5137, Accuracy: 2374/5000 (47%)\n",
      "[epoch 29] loss: 0.0015633\n",
      "Test set: Average loss: 2.5385, Accuracy: 2363/5000 (47%)\n",
      "[epoch 30] loss: 0.0013998\n",
      "Test set: Average loss: 2.5637, Accuracy: 2370/5000 (47%)\n",
      "[epoch 31] loss: 0.0012478\n",
      "Test set: Average loss: 2.5840, Accuracy: 2376/5000 (48%)\n",
      "[epoch 32] loss: 0.0011105\n",
      "Test set: Average loss: 2.6121, Accuracy: 2371/5000 (47%)\n",
      "[epoch 33] loss: 0.0009892\n",
      "Test set: Average loss: 2.6356, Accuracy: 2373/5000 (47%)\n",
      "[epoch 34] loss: 0.0008897\n",
      "Test set: Average loss: 2.6550, Accuracy: 2366/5000 (47%)\n",
      "[epoch 35] loss: 0.0007992\n",
      "Test set: Average loss: 2.6769, Accuracy: 2376/5000 (48%)\n",
      "[epoch 36] loss: 0.0007219\n",
      "Test set: Average loss: 2.7030, Accuracy: 2364/5000 (47%)\n",
      "[epoch 37] loss: 0.0006475\n",
      "Test set: Average loss: 2.7193, Accuracy: 2363/5000 (47%)\n",
      "[epoch 38] loss: 0.0005839\n",
      "Test set: Average loss: 2.7442, Accuracy: 2364/5000 (47%)\n",
      "[epoch 39] loss: 0.0005278\n",
      "Test set: Average loss: 2.7635, Accuracy: 2367/5000 (47%)\n",
      "[epoch 40] loss: 0.0004758\n",
      "Test set: Average loss: 2.7900, Accuracy: 2363/5000 (47%)\n",
      "[epoch 41] loss: 0.0004316\n",
      "Test set: Average loss: 2.8101, Accuracy: 2370/5000 (47%)\n",
      "[epoch 42] loss: 0.0003903\n",
      "Test set: Average loss: 2.8281, Accuracy: 2374/5000 (47%)\n",
      "[epoch 43] loss: 0.0003537\n",
      "Test set: Average loss: 2.8438, Accuracy: 2367/5000 (47%)\n",
      "[epoch 44] loss: 0.0003205\n",
      "Test set: Average loss: 2.8690, Accuracy: 2357/5000 (47%)\n",
      "[epoch 45] loss: 0.0002921\n",
      "Test set: Average loss: 2.8891, Accuracy: 2360/5000 (47%)\n",
      "[epoch 46] loss: 0.0002649\n",
      "Test set: Average loss: 2.9128, Accuracy: 2363/5000 (47%)\n",
      "[epoch 47] loss: 0.0002403\n",
      "Test set: Average loss: 2.9320, Accuracy: 2366/5000 (47%)\n",
      "[epoch 48] loss: 0.0002182\n",
      "Test set: Average loss: 2.9543, Accuracy: 2360/5000 (47%)\n",
      "[epoch 49] loss: 0.0001986\n",
      "Test set: Average loss: 2.9713, Accuracy: 2370/5000 (47%)\n",
      "[epoch 50] loss: 0.0001804\n",
      "Test set: Average loss: 2.9920, Accuracy: 2359/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7600, Accuracy: 2400/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 1.7154, Accuracy: 4908/10000 (49%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3017, Accuracy: 545/5000 (11%)\n",
      "[epoch 1] loss: 1.8926413\n",
      "Test set: Average loss: 1.7214, Accuracy: 1890/5000 (38%)\n",
      "[epoch 2] loss: 1.6065548\n",
      "Test set: Average loss: 1.6531, Accuracy: 2027/5000 (41%)\n",
      "[epoch 3] loss: 1.4599297\n",
      "Test set: Average loss: 1.5241, Accuracy: 2247/5000 (45%)\n",
      "[epoch 4] loss: 1.3314980\n",
      "Test set: Average loss: 1.5441, Accuracy: 2221/5000 (44%)\n",
      "[epoch 5] loss: 1.2262565\n",
      "Test set: Average loss: 1.5825, Accuracy: 2246/5000 (45%)\n",
      "[epoch 6] loss: 1.0785446\n",
      "Test set: Average loss: 1.6323, Accuracy: 2238/5000 (45%)\n",
      "[epoch 7] loss: 0.9186893\n",
      "Test set: Average loss: 1.6197, Accuracy: 2233/5000 (45%)\n",
      "[epoch 8] loss: 0.7176930\n",
      "Test set: Average loss: 1.6549, Accuracy: 2317/5000 (46%)\n",
      "[epoch 9] loss: 0.5337124\n",
      "Test set: Average loss: 1.7302, Accuracy: 2313/5000 (46%)\n",
      "[epoch 10] loss: 0.3465713\n",
      "Test set: Average loss: 1.7563, Accuracy: 2363/5000 (47%)\n",
      "[epoch 11] loss: 0.1836214\n",
      "Test set: Average loss: 1.8308, Accuracy: 2327/5000 (47%)\n",
      "[epoch 12] loss: 0.0946733\n",
      "Test set: Average loss: 1.9065, Accuracy: 2350/5000 (47%)\n",
      "[epoch 13] loss: 0.0486893\n",
      "Test set: Average loss: 1.9759, Accuracy: 2371/5000 (47%)\n",
      "[epoch 14] loss: 0.0279916\n",
      "Test set: Average loss: 2.0327, Accuracy: 2369/5000 (47%)\n",
      "[epoch 15] loss: 0.0184578\n",
      "Test set: Average loss: 2.0933, Accuracy: 2385/5000 (48%)\n",
      "[epoch 16] loss: 0.0141408\n",
      "Test set: Average loss: 2.1296, Accuracy: 2368/5000 (47%)\n",
      "[epoch 17] loss: 0.0111424\n",
      "Test set: Average loss: 2.1764, Accuracy: 2372/5000 (47%)\n",
      "[epoch 18] loss: 0.0089495\n",
      "Test set: Average loss: 2.2146, Accuracy: 2383/5000 (48%)\n",
      "[epoch 19] loss: 0.0073924\n",
      "Test set: Average loss: 2.2499, Accuracy: 2368/5000 (47%)\n",
      "[epoch 20] loss: 0.0062130\n",
      "Test set: Average loss: 2.2886, Accuracy: 2373/5000 (47%)\n",
      "[epoch 21] loss: 0.0052555\n",
      "Test set: Average loss: 2.3309, Accuracy: 2364/5000 (47%)\n",
      "[epoch 22] loss: 0.0045062\n",
      "Test set: Average loss: 2.3444, Accuracy: 2375/5000 (48%)\n",
      "[epoch 23] loss: 0.0038813\n",
      "Test set: Average loss: 2.3773, Accuracy: 2367/5000 (47%)\n",
      "[epoch 24] loss: 0.0033593\n",
      "Test set: Average loss: 2.4028, Accuracy: 2375/5000 (48%)\n",
      "[epoch 25] loss: 0.0029230\n",
      "Test set: Average loss: 2.4277, Accuracy: 2370/5000 (47%)\n",
      "[epoch 26] loss: 0.0025734\n",
      "Test set: Average loss: 2.4571, Accuracy: 2367/5000 (47%)\n",
      "[epoch 27] loss: 0.0022757\n",
      "Test set: Average loss: 2.4828, Accuracy: 2373/5000 (47%)\n",
      "[epoch 28] loss: 0.0020072\n",
      "Test set: Average loss: 2.5101, Accuracy: 2366/5000 (47%)\n",
      "[epoch 29] loss: 0.0017752\n",
      "Test set: Average loss: 2.5361, Accuracy: 2373/5000 (47%)\n",
      "[epoch 30] loss: 0.0015800\n",
      "Test set: Average loss: 2.5520, Accuracy: 2366/5000 (47%)\n",
      "[epoch 31] loss: 0.0014067\n",
      "Test set: Average loss: 2.5823, Accuracy: 2365/5000 (47%)\n",
      "[epoch 32] loss: 0.0012607\n",
      "Test set: Average loss: 2.6041, Accuracy: 2365/5000 (47%)\n",
      "[epoch 33] loss: 0.0011256\n",
      "Test set: Average loss: 2.6238, Accuracy: 2357/5000 (47%)\n",
      "[epoch 34] loss: 0.0010115\n",
      "Test set: Average loss: 2.6467, Accuracy: 2364/5000 (47%)\n",
      "[epoch 35] loss: 0.0009061\n",
      "Test set: Average loss: 2.6667, Accuracy: 2373/5000 (47%)\n",
      "[epoch 36] loss: 0.0008157\n",
      "Test set: Average loss: 2.6910, Accuracy: 2371/5000 (47%)\n",
      "[epoch 37] loss: 0.0007340\n",
      "Test set: Average loss: 2.7126, Accuracy: 2361/5000 (47%)\n",
      "[epoch 38] loss: 0.0006645\n",
      "Test set: Average loss: 2.7331, Accuracy: 2374/5000 (47%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39] loss: 0.0005987\n",
      "Test set: Average loss: 2.7533, Accuracy: 2369/5000 (47%)\n",
      "[epoch 40] loss: 0.0005396\n",
      "Test set: Average loss: 2.7744, Accuracy: 2357/5000 (47%)\n",
      "[epoch 41] loss: 0.0004886\n",
      "Test set: Average loss: 2.7933, Accuracy: 2376/5000 (48%)\n",
      "[epoch 42] loss: 0.0004455\n",
      "Test set: Average loss: 2.8131, Accuracy: 2366/5000 (47%)\n",
      "[epoch 43] loss: 0.0004023\n",
      "Test set: Average loss: 2.8396, Accuracy: 2356/5000 (47%)\n",
      "[epoch 44] loss: 0.0003623\n",
      "Test set: Average loss: 2.8560, Accuracy: 2370/5000 (47%)\n",
      "[epoch 45] loss: 0.0003285\n",
      "Test set: Average loss: 2.8716, Accuracy: 2368/5000 (47%)\n",
      "[epoch 46] loss: 0.0002992\n",
      "Test set: Average loss: 2.8946, Accuracy: 2358/5000 (47%)\n",
      "[epoch 47] loss: 0.0002721\n",
      "Test set: Average loss: 2.9138, Accuracy: 2362/5000 (47%)\n",
      "[epoch 48] loss: 0.0002473\n",
      "Test set: Average loss: 2.9312, Accuracy: 2362/5000 (47%)\n",
      "[epoch 49] loss: 0.0002251\n",
      "Test set: Average loss: 2.9508, Accuracy: 2357/5000 (47%)\n",
      "[epoch 50] loss: 0.0002049\n",
      "Test set: Average loss: 2.9782, Accuracy: 2363/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0933, Accuracy: 2385/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 2.0466, Accuracy: 4867/10000 (49%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3074, Accuracy: 521/5000 (10%)\n",
      "[epoch 1] loss: 1.7498990\n",
      "Test set: Average loss: 1.5787, Accuracy: 2205/5000 (44%)\n",
      "[epoch 2] loss: 1.4799706\n",
      "Test set: Average loss: 1.4675, Accuracy: 2371/5000 (47%)\n",
      "[epoch 3] loss: 1.3436745\n",
      "Test set: Average loss: 1.3772, Accuracy: 2519/5000 (50%)\n",
      "[epoch 4] loss: 1.2176276\n",
      "Test set: Average loss: 1.4113, Accuracy: 2538/5000 (51%)\n",
      "[epoch 5] loss: 1.0962258\n",
      "Test set: Average loss: 1.4063, Accuracy: 2584/5000 (52%)\n",
      "[epoch 6] loss: 0.9634849\n",
      "Test set: Average loss: 1.4143, Accuracy: 2573/5000 (51%)\n",
      "[epoch 7] loss: 0.8204201\n",
      "Test set: Average loss: 1.3511, Accuracy: 2721/5000 (54%)\n",
      "[epoch 8] loss: 0.6561985\n",
      "Test set: Average loss: 1.4701, Accuracy: 2657/5000 (53%)\n",
      "[epoch 9] loss: 0.4742033\n",
      "Test set: Average loss: 1.4534, Accuracy: 2705/5000 (54%)\n",
      "[epoch 10] loss: 0.2970973\n",
      "Test set: Average loss: 1.4850, Accuracy: 2782/5000 (56%)\n",
      "[epoch 11] loss: 0.1635029\n",
      "Test set: Average loss: 1.5445, Accuracy: 2792/5000 (56%)\n",
      "[epoch 12] loss: 0.0713004\n",
      "Test set: Average loss: 1.6136, Accuracy: 2785/5000 (56%)\n",
      "[epoch 13] loss: 0.0326414\n",
      "Test set: Average loss: 1.6680, Accuracy: 2841/5000 (57%)\n",
      "[epoch 14] loss: 0.0162202\n",
      "Test set: Average loss: 1.7221, Accuracy: 2871/5000 (57%)\n",
      "[epoch 15] loss: 0.0104521\n",
      "Test set: Average loss: 1.7651, Accuracy: 2883/5000 (58%)\n",
      "[epoch 16] loss: 0.0075262\n",
      "Test set: Average loss: 1.8066, Accuracy: 2869/5000 (57%)\n",
      "[epoch 17] loss: 0.0057659\n",
      "Test set: Average loss: 1.8474, Accuracy: 2858/5000 (57%)\n",
      "[epoch 18] loss: 0.0045362\n",
      "Test set: Average loss: 1.8951, Accuracy: 2848/5000 (57%)\n",
      "[epoch 19] loss: 0.0036145\n",
      "Test set: Average loss: 1.9255, Accuracy: 2838/5000 (57%)\n",
      "[epoch 20] loss: 0.0028887\n",
      "Test set: Average loss: 1.9604, Accuracy: 2849/5000 (57%)\n",
      "[epoch 21] loss: 0.0023478\n",
      "Test set: Average loss: 1.9947, Accuracy: 2850/5000 (57%)\n",
      "[epoch 22] loss: 0.0019114\n",
      "Test set: Average loss: 2.0515, Accuracy: 2837/5000 (57%)\n",
      "[epoch 23] loss: 0.0015616\n",
      "Test set: Average loss: 2.0625, Accuracy: 2847/5000 (57%)\n",
      "[epoch 24] loss: 0.0012790\n",
      "Test set: Average loss: 2.1007, Accuracy: 2859/5000 (57%)\n",
      "[epoch 25] loss: 0.0010597\n",
      "Test set: Average loss: 2.1346, Accuracy: 2860/5000 (57%)\n",
      "[epoch 26] loss: 0.0008766\n",
      "Test set: Average loss: 2.1602, Accuracy: 2858/5000 (57%)\n",
      "[epoch 27] loss: 0.0007250\n",
      "Test set: Average loss: 2.2007, Accuracy: 2837/5000 (57%)\n",
      "[epoch 28] loss: 0.0005995\n",
      "Test set: Average loss: 2.2300, Accuracy: 2844/5000 (57%)\n",
      "[epoch 29] loss: 0.0004967\n",
      "Test set: Average loss: 2.2649, Accuracy: 2846/5000 (57%)\n",
      "[epoch 30] loss: 0.0004154\n",
      "Test set: Average loss: 2.2985, Accuracy: 2841/5000 (57%)\n",
      "[epoch 31] loss: 0.0003448\n",
      "Test set: Average loss: 2.3262, Accuracy: 2853/5000 (57%)\n",
      "[epoch 32] loss: 0.0002872\n",
      "Test set: Average loss: 2.3589, Accuracy: 2832/5000 (57%)\n",
      "[epoch 33] loss: 0.0002397\n",
      "Test set: Average loss: 2.3875, Accuracy: 2834/5000 (57%)\n",
      "[epoch 34] loss: 0.0002005\n",
      "Test set: Average loss: 2.4172, Accuracy: 2837/5000 (57%)\n",
      "[epoch 35] loss: 0.0001674\n",
      "Test set: Average loss: 2.4545, Accuracy: 2828/5000 (57%)\n",
      "[epoch 36] loss: 0.0001397\n",
      "Test set: Average loss: 2.4844, Accuracy: 2845/5000 (57%)\n",
      "[epoch 37] loss: 0.0001167\n",
      "Test set: Average loss: 2.5113, Accuracy: 2834/5000 (57%)\n",
      "[epoch 38] loss: 0.0000979\n",
      "Test set: Average loss: 2.5404, Accuracy: 2837/5000 (57%)\n",
      "[epoch 39] loss: 0.0000820\n",
      "Test set: Average loss: 2.5718, Accuracy: 2835/5000 (57%)\n",
      "[epoch 40] loss: 0.0000686\n",
      "Test set: Average loss: 2.6067, Accuracy: 2834/5000 (57%)\n",
      "[epoch 41] loss: 0.0000574\n",
      "Test set: Average loss: 2.6317, Accuracy: 2824/5000 (56%)\n",
      "[epoch 42] loss: 0.0000481\n",
      "Test set: Average loss: 2.6629, Accuracy: 2833/5000 (57%)\n",
      "[epoch 43] loss: 0.0000404\n",
      "Test set: Average loss: 2.6919, Accuracy: 2843/5000 (57%)\n",
      "[epoch 44] loss: 0.0000339\n",
      "Test set: Average loss: 2.7224, Accuracy: 2840/5000 (57%)\n",
      "[epoch 45] loss: 0.0000285\n",
      "Test set: Average loss: 2.7512, Accuracy: 2832/5000 (57%)\n",
      "[epoch 46] loss: 0.0000239\n",
      "Test set: Average loss: 2.7801, Accuracy: 2840/5000 (57%)\n",
      "[epoch 47] loss: 0.0000200\n",
      "Test set: Average loss: 2.8117, Accuracy: 2838/5000 (57%)\n",
      "[epoch 48] loss: 0.0000168\n",
      "Test set: Average loss: 2.8387, Accuracy: 2832/5000 (57%)\n",
      "[epoch 49] loss: 0.0000141\n",
      "Test set: Average loss: 2.8713, Accuracy: 2834/5000 (57%)\n",
      "[epoch 50] loss: 0.0000119\n",
      "Test set: Average loss: 2.9010, Accuracy: 2835/5000 (57%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7651, Accuracy: 2883/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.8130, Accuracy: 5643/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3151, Accuracy: 402/5000 (8%)\n",
      "[epoch 1] loss: 1.7279868\n",
      "Test set: Average loss: 1.5958, Accuracy: 2101/5000 (42%)\n",
      "[epoch 2] loss: 1.4537970\n",
      "Test set: Average loss: 1.5018, Accuracy: 2321/5000 (46%)\n",
      "[epoch 3] loss: 1.3311427\n",
      "Test set: Average loss: 1.3976, Accuracy: 2456/5000 (49%)\n",
      "[epoch 4] loss: 1.1986404\n",
      "Test set: Average loss: 1.4309, Accuracy: 2511/5000 (50%)\n",
      "[epoch 5] loss: 1.0690019\n",
      "Test set: Average loss: 1.3432, Accuracy: 2629/5000 (53%)\n",
      "[epoch 6] loss: 0.9115851\n",
      "Test set: Average loss: 1.4388, Accuracy: 2546/5000 (51%)\n",
      "[epoch 7] loss: 0.7346841\n",
      "Test set: Average loss: 1.4459, Accuracy: 2571/5000 (51%)\n",
      "[epoch 8] loss: 0.5410428\n",
      "Test set: Average loss: 1.5229, Accuracy: 2570/5000 (51%)\n",
      "[epoch 9] loss: 0.3522134\n",
      "Test set: Average loss: 1.6037, Accuracy: 2609/5000 (52%)\n",
      "[epoch 10] loss: 0.2103426\n",
      "Test set: Average loss: 1.6475, Accuracy: 2602/5000 (52%)\n",
      "[epoch 11] loss: 0.0999809\n",
      "Test set: Average loss: 1.6694, Accuracy: 2650/5000 (53%)\n",
      "[epoch 12] loss: 0.0423824\n",
      "Test set: Average loss: 1.7428, Accuracy: 2678/5000 (54%)\n",
      "[epoch 13] loss: 0.0209689\n",
      "Test set: Average loss: 1.8048, Accuracy: 2662/5000 (53%)\n",
      "[epoch 14] loss: 0.0127675\n",
      "Test set: Average loss: 1.8528, Accuracy: 2675/5000 (54%)\n",
      "[epoch 15] loss: 0.0081972\n",
      "Test set: Average loss: 1.8962, Accuracy: 2694/5000 (54%)\n",
      "[epoch 16] loss: 0.0059774\n",
      "Test set: Average loss: 1.9424, Accuracy: 2681/5000 (54%)\n",
      "[epoch 17] loss: 0.0046375\n",
      "Test set: Average loss: 1.9870, Accuracy: 2680/5000 (54%)\n",
      "[epoch 18] loss: 0.0036995\n",
      "Test set: Average loss: 2.0230, Accuracy: 2676/5000 (54%)\n",
      "[epoch 19] loss: 0.0029662\n",
      "Test set: Average loss: 2.0553, Accuracy: 2691/5000 (54%)\n",
      "[epoch 20] loss: 0.0024106\n",
      "Test set: Average loss: 2.0908, Accuracy: 2673/5000 (53%)\n",
      "[epoch 21] loss: 0.0019622\n",
      "Test set: Average loss: 2.1251, Accuracy: 2677/5000 (54%)\n",
      "[epoch 22] loss: 0.0016104\n",
      "Test set: Average loss: 2.1622, Accuracy: 2681/5000 (54%)\n",
      "[epoch 23] loss: 0.0013166\n",
      "Test set: Average loss: 2.1921, Accuracy: 2683/5000 (54%)\n",
      "[epoch 24] loss: 0.0010905\n",
      "Test set: Average loss: 2.2347, Accuracy: 2685/5000 (54%)\n",
      "[epoch 25] loss: 0.0009015\n",
      "Test set: Average loss: 2.2661, Accuracy: 2678/5000 (54%)\n",
      "[epoch 26] loss: 0.0007468\n",
      "Test set: Average loss: 2.3034, Accuracy: 2684/5000 (54%)\n",
      "[epoch 27] loss: 0.0006162\n",
      "Test set: Average loss: 2.3341, Accuracy: 2681/5000 (54%)\n",
      "[epoch 28] loss: 0.0005152\n",
      "Test set: Average loss: 2.3660, Accuracy: 2666/5000 (53%)\n",
      "[epoch 29] loss: 0.0004268\n",
      "Test set: Average loss: 2.3988, Accuracy: 2674/5000 (53%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 30] loss: 0.0003565\n",
      "Test set: Average loss: 2.4266, Accuracy: 2677/5000 (54%)\n",
      "[epoch 31] loss: 0.0002973\n",
      "Test set: Average loss: 2.4601, Accuracy: 2669/5000 (53%)\n",
      "[epoch 32] loss: 0.0002475\n",
      "Test set: Average loss: 2.5025, Accuracy: 2684/5000 (54%)\n",
      "[epoch 33] loss: 0.0002062\n",
      "Test set: Average loss: 2.5333, Accuracy: 2689/5000 (54%)\n",
      "[epoch 34] loss: 0.0001726\n",
      "Test set: Average loss: 2.5595, Accuracy: 2676/5000 (54%)\n",
      "[epoch 35] loss: 0.0001444\n",
      "Test set: Average loss: 2.5943, Accuracy: 2679/5000 (54%)\n",
      "[epoch 36] loss: 0.0001206\n",
      "Test set: Average loss: 2.6208, Accuracy: 2683/5000 (54%)\n",
      "[epoch 37] loss: 0.0001010\n",
      "Test set: Average loss: 2.6599, Accuracy: 2678/5000 (54%)\n",
      "[epoch 38] loss: 0.0000848\n",
      "Test set: Average loss: 2.6936, Accuracy: 2674/5000 (53%)\n",
      "[epoch 39] loss: 0.0000707\n",
      "Test set: Average loss: 2.7233, Accuracy: 2669/5000 (53%)\n",
      "[epoch 40] loss: 0.0000592\n",
      "Test set: Average loss: 2.7535, Accuracy: 2663/5000 (53%)\n",
      "[epoch 41] loss: 0.0000496\n",
      "Test set: Average loss: 2.7858, Accuracy: 2670/5000 (53%)\n",
      "[epoch 42] loss: 0.0000416\n",
      "Test set: Average loss: 2.8193, Accuracy: 2678/5000 (54%)\n",
      "[epoch 43] loss: 0.0000349\n",
      "Test set: Average loss: 2.8516, Accuracy: 2670/5000 (53%)\n",
      "[epoch 44] loss: 0.0000293\n",
      "Test set: Average loss: 2.8870, Accuracy: 2664/5000 (53%)\n",
      "[epoch 45] loss: 0.0000246\n",
      "Test set: Average loss: 2.9177, Accuracy: 2670/5000 (53%)\n",
      "[epoch 46] loss: 0.0000206\n",
      "Test set: Average loss: 2.9435, Accuracy: 2670/5000 (53%)\n",
      "[epoch 47] loss: 0.0000173\n",
      "Test set: Average loss: 2.9783, Accuracy: 2651/5000 (53%)\n",
      "[epoch 48] loss: 0.0000146\n",
      "Test set: Average loss: 3.0049, Accuracy: 2664/5000 (53%)\n",
      "[epoch 49] loss: 0.0000122\n",
      "Test set: Average loss: 3.0468, Accuracy: 2662/5000 (53%)\n",
      "[epoch 50] loss: 0.0000103\n",
      "Test set: Average loss: 3.0724, Accuracy: 2659/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8962, Accuracy: 2694/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.8874, Accuracy: 5403/10000 (54%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 490/5000 (10%)\n",
      "[epoch 1] loss: 1.7604923\n",
      "Test set: Average loss: 1.5914, Accuracy: 2142/5000 (43%)\n",
      "[epoch 2] loss: 1.5045504\n",
      "Test set: Average loss: 1.5062, Accuracy: 2311/5000 (46%)\n",
      "[epoch 3] loss: 1.3837977\n",
      "Test set: Average loss: 1.4701, Accuracy: 2380/5000 (48%)\n",
      "[epoch 4] loss: 1.2588152\n",
      "Test set: Average loss: 1.3800, Accuracy: 2591/5000 (52%)\n",
      "[epoch 5] loss: 1.1355771\n",
      "Test set: Average loss: 1.4169, Accuracy: 2528/5000 (51%)\n",
      "[epoch 6] loss: 0.9846593\n",
      "Test set: Average loss: 1.3761, Accuracy: 2623/5000 (52%)\n",
      "[epoch 7] loss: 0.8118807\n",
      "Test set: Average loss: 1.4436, Accuracy: 2613/5000 (52%)\n",
      "[epoch 8] loss: 0.6190199\n",
      "Test set: Average loss: 1.4766, Accuracy: 2582/5000 (52%)\n",
      "[epoch 9] loss: 0.4174319\n",
      "Test set: Average loss: 1.5549, Accuracy: 2592/5000 (52%)\n",
      "[epoch 10] loss: 0.2500638\n",
      "Test set: Average loss: 1.6043, Accuracy: 2613/5000 (52%)\n",
      "[epoch 11] loss: 0.1257919\n",
      "Test set: Average loss: 1.6794, Accuracy: 2631/5000 (53%)\n",
      "[epoch 12] loss: 0.0526656\n",
      "Test set: Average loss: 1.7166, Accuracy: 2673/5000 (53%)\n",
      "[epoch 13] loss: 0.0231725\n",
      "Test set: Average loss: 1.7886, Accuracy: 2676/5000 (54%)\n",
      "[epoch 14] loss: 0.0151744\n",
      "Test set: Average loss: 1.8421, Accuracy: 2684/5000 (54%)\n",
      "[epoch 15] loss: 0.0097773\n",
      "Test set: Average loss: 1.8974, Accuracy: 2687/5000 (54%)\n",
      "[epoch 16] loss: 0.0068487\n",
      "Test set: Average loss: 1.9360, Accuracy: 2694/5000 (54%)\n",
      "[epoch 17] loss: 0.0052921\n",
      "Test set: Average loss: 1.9711, Accuracy: 2689/5000 (54%)\n",
      "[epoch 18] loss: 0.0041701\n",
      "Test set: Average loss: 2.0106, Accuracy: 2679/5000 (54%)\n",
      "[epoch 19] loss: 0.0033422\n",
      "Test set: Average loss: 2.0520, Accuracy: 2705/5000 (54%)\n",
      "[epoch 20] loss: 0.0026991\n",
      "Test set: Average loss: 2.0857, Accuracy: 2688/5000 (54%)\n",
      "[epoch 21] loss: 0.0021910\n",
      "Test set: Average loss: 2.1204, Accuracy: 2690/5000 (54%)\n",
      "[epoch 22] loss: 0.0017999\n",
      "Test set: Average loss: 2.1513, Accuracy: 2698/5000 (54%)\n",
      "[epoch 23] loss: 0.0014707\n",
      "Test set: Average loss: 2.1842, Accuracy: 2686/5000 (54%)\n",
      "[epoch 24] loss: 0.0012101\n",
      "Test set: Average loss: 2.2108, Accuracy: 2705/5000 (54%)\n",
      "[epoch 25] loss: 0.0010007\n",
      "Test set: Average loss: 2.2504, Accuracy: 2712/5000 (54%)\n",
      "[epoch 26] loss: 0.0008293\n",
      "Test set: Average loss: 2.2803, Accuracy: 2690/5000 (54%)\n",
      "[epoch 27] loss: 0.0006851\n",
      "Test set: Average loss: 2.3188, Accuracy: 2699/5000 (54%)\n",
      "[epoch 28] loss: 0.0005676\n",
      "Test set: Average loss: 2.3442, Accuracy: 2684/5000 (54%)\n",
      "[epoch 29] loss: 0.0004735\n",
      "Test set: Average loss: 2.3773, Accuracy: 2686/5000 (54%)\n",
      "[epoch 30] loss: 0.0003941\n",
      "Test set: Average loss: 2.4140, Accuracy: 2679/5000 (54%)\n",
      "[epoch 31] loss: 0.0003276\n",
      "Test set: Average loss: 2.4443, Accuracy: 2689/5000 (54%)\n",
      "[epoch 32] loss: 0.0002735\n",
      "Test set: Average loss: 2.4765, Accuracy: 2687/5000 (54%)\n",
      "[epoch 33] loss: 0.0002284\n",
      "Test set: Average loss: 2.5089, Accuracy: 2697/5000 (54%)\n",
      "[epoch 34] loss: 0.0001911\n",
      "Test set: Average loss: 2.5371, Accuracy: 2681/5000 (54%)\n",
      "[epoch 35] loss: 0.0001593\n",
      "Test set: Average loss: 2.5701, Accuracy: 2681/5000 (54%)\n",
      "[epoch 36] loss: 0.0001331\n",
      "Test set: Average loss: 2.6002, Accuracy: 2687/5000 (54%)\n",
      "[epoch 37] loss: 0.0001114\n",
      "Test set: Average loss: 2.6300, Accuracy: 2687/5000 (54%)\n",
      "[epoch 38] loss: 0.0000929\n",
      "Test set: Average loss: 2.6613, Accuracy: 2690/5000 (54%)\n",
      "[epoch 39] loss: 0.0000784\n",
      "Test set: Average loss: 2.6905, Accuracy: 2684/5000 (54%)\n",
      "[epoch 40] loss: 0.0000654\n",
      "Test set: Average loss: 2.7210, Accuracy: 2688/5000 (54%)\n",
      "[epoch 41] loss: 0.0000550\n",
      "Test set: Average loss: 2.7471, Accuracy: 2680/5000 (54%)\n",
      "[epoch 42] loss: 0.0000461\n",
      "Test set: Average loss: 2.7850, Accuracy: 2677/5000 (54%)\n",
      "[epoch 43] loss: 0.0000387\n",
      "Test set: Average loss: 2.8078, Accuracy: 2686/5000 (54%)\n",
      "[epoch 44] loss: 0.0000324\n",
      "Test set: Average loss: 2.8405, Accuracy: 2692/5000 (54%)\n",
      "[epoch 45] loss: 0.0000273\n",
      "Test set: Average loss: 2.8809, Accuracy: 2681/5000 (54%)\n",
      "[epoch 46] loss: 0.0000228\n",
      "Test set: Average loss: 2.9049, Accuracy: 2674/5000 (53%)\n",
      "[epoch 47] loss: 0.0000192\n",
      "Test set: Average loss: 2.9381, Accuracy: 2677/5000 (54%)\n",
      "[epoch 48] loss: 0.0000161\n",
      "Test set: Average loss: 2.9651, Accuracy: 2681/5000 (54%)\n",
      "[epoch 49] loss: 0.0000136\n",
      "Test set: Average loss: 2.9935, Accuracy: 2676/5000 (54%)\n",
      "[epoch 50] loss: 0.0000114\n",
      "Test set: Average loss: 3.0228, Accuracy: 2690/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2504, Accuracy: 2712/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 2.1630, Accuracy: 5482/10000 (55%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3095, Accuracy: 446/5000 (9%)\n",
      "[epoch 1] loss: 1.6856795\n",
      "Test set: Average loss: 1.5231, Accuracy: 2223/5000 (44%)\n",
      "[epoch 2] loss: 1.4235358\n",
      "Test set: Average loss: 1.4378, Accuracy: 2420/5000 (48%)\n",
      "[epoch 3] loss: 1.2977523\n",
      "Test set: Average loss: 1.3685, Accuracy: 2588/5000 (52%)\n",
      "[epoch 4] loss: 1.1734946\n",
      "Test set: Average loss: 1.3757, Accuracy: 2602/5000 (52%)\n",
      "[epoch 5] loss: 1.0540898\n",
      "Test set: Average loss: 1.3400, Accuracy: 2622/5000 (52%)\n",
      "[epoch 6] loss: 0.8959738\n",
      "Test set: Average loss: 1.3542, Accuracy: 2704/5000 (54%)\n",
      "[epoch 7] loss: 0.7311836\n",
      "Test set: Average loss: 1.3844, Accuracy: 2694/5000 (54%)\n",
      "[epoch 8] loss: 0.5495724\n",
      "Test set: Average loss: 1.4236, Accuracy: 2724/5000 (54%)\n",
      "[epoch 9] loss: 0.3677737\n",
      "Test set: Average loss: 1.5350, Accuracy: 2728/5000 (55%)\n",
      "[epoch 10] loss: 0.2250538\n",
      "Test set: Average loss: 1.5782, Accuracy: 2706/5000 (54%)\n",
      "[epoch 11] loss: 0.1236744\n",
      "Test set: Average loss: 1.6417, Accuracy: 2793/5000 (56%)\n",
      "[epoch 12] loss: 0.0601749\n",
      "Test set: Average loss: 1.7421, Accuracy: 2753/5000 (55%)\n",
      "[epoch 13] loss: 0.0271864\n",
      "Test set: Average loss: 1.8402, Accuracy: 2744/5000 (55%)\n",
      "[epoch 14] loss: 0.0467586\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9537, Accuracy: 2687/5000 (54%)\n",
      "[epoch 15] loss: 0.0301929\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8634, Accuracy: 2756/5000 (55%)\n",
      "[epoch 16] loss: 0.0127862\n",
      "Test set: Average loss: 1.8639, Accuracy: 2759/5000 (55%)\n",
      "[epoch 17] loss: 0.0121888\n",
      "Test set: Average loss: 1.8641, Accuracy: 2758/5000 (55%)\n",
      "[epoch 18] loss: 0.0116237\n",
      "Test set: Average loss: 1.8654, Accuracy: 2758/5000 (55%)\n",
      "[epoch 19] loss: 0.0110404\n",
      "Test set: Average loss: 1.8665, Accuracy: 2762/5000 (55%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] loss: 0.0104345\n",
      "Test set: Average loss: 1.8671, Accuracy: 2768/5000 (55%)\n",
      "[epoch 21] loss: 0.0098386\n",
      "Test set: Average loss: 1.8690, Accuracy: 2770/5000 (55%)\n",
      "[epoch 22] loss: 0.0092280\n",
      "Test set: Average loss: 1.8714, Accuracy: 2776/5000 (56%)\n",
      "[epoch 23] loss: 0.0086478\n",
      "Test set: Average loss: 1.8749, Accuracy: 2778/5000 (56%)\n",
      "[epoch 24] loss: 0.0080897\n",
      "Test set: Average loss: 1.8777, Accuracy: 2774/5000 (55%)\n",
      "[epoch 25] loss: 0.0075610\n",
      "Test set: Average loss: 1.8830, Accuracy: 2786/5000 (56%)\n",
      "[epoch 26] loss: 0.0070656\n",
      "Test set: Average loss: 1.8872, Accuracy: 2782/5000 (56%)\n",
      "[epoch 27] loss: 0.0066019\n",
      "Test set: Average loss: 1.8920, Accuracy: 2784/5000 (56%)\n",
      "[epoch 28] loss: 0.0061719\n",
      "Test set: Average loss: 1.8970, Accuracy: 2782/5000 (56%)\n",
      "[epoch 29] loss: 0.0057735\n",
      "Test set: Average loss: 1.9030, Accuracy: 2782/5000 (56%)\n",
      "[epoch 30] loss: 0.0054075\n",
      "Test set: Average loss: 1.9103, Accuracy: 2782/5000 (56%)\n",
      "[epoch 31] loss: 0.0050648\n",
      "Test set: Average loss: 1.9166, Accuracy: 2782/5000 (56%)\n",
      "[epoch 32] loss: 0.0047506\n",
      "Test set: Average loss: 1.9245, Accuracy: 2784/5000 (56%)\n",
      "[epoch 33] loss: 0.0044638\n",
      "Test set: Average loss: 1.9311, Accuracy: 2789/5000 (56%)\n",
      "[epoch 34] loss: 0.0041934\n",
      "Test set: Average loss: 1.9385, Accuracy: 2787/5000 (56%)\n",
      "[epoch 35] loss: 0.0039414\n",
      "Test set: Average loss: 1.9457, Accuracy: 2786/5000 (56%)\n",
      "[epoch 36] loss: 0.0037101\n",
      "Test set: Average loss: 1.9534, Accuracy: 2785/5000 (56%)\n",
      "[epoch 37] loss: 0.0034947\n",
      "Test set: Average loss: 1.9606, Accuracy: 2788/5000 (56%)\n",
      "[epoch 38] loss: 0.0032947\n",
      "Test set: Average loss: 1.9693, Accuracy: 2790/5000 (56%)\n",
      "[epoch 39] loss: 0.0031076\n",
      "Test set: Average loss: 1.9764, Accuracy: 2785/5000 (56%)\n",
      "[epoch 40] loss: 0.0029338\n",
      "Test set: Average loss: 1.9852, Accuracy: 2789/5000 (56%)\n",
      "[epoch 41] loss: 0.0027685\n",
      "Test set: Average loss: 1.9938, Accuracy: 2796/5000 (56%)\n",
      "[epoch 42] loss: 0.0026157\n",
      "Test set: Average loss: 2.0015, Accuracy: 2795/5000 (56%)\n",
      "[epoch 43] loss: 0.0024722\n",
      "Test set: Average loss: 2.0093, Accuracy: 2799/5000 (56%)\n",
      "[epoch 44] loss: 0.0023359\n",
      "Test set: Average loss: 2.0191, Accuracy: 2794/5000 (56%)\n",
      "[epoch 45] loss: 0.0022121\n",
      "Test set: Average loss: 2.0279, Accuracy: 2793/5000 (56%)\n",
      "[epoch 46] loss: 0.0020921\n",
      "Test set: Average loss: 2.0367, Accuracy: 2794/5000 (56%)\n",
      "[epoch 47] loss: 0.0019799\n",
      "Test set: Average loss: 2.0448, Accuracy: 2796/5000 (56%)\n",
      "[epoch 48] loss: 0.0018771\n",
      "Test set: Average loss: 2.0533, Accuracy: 2795/5000 (56%)\n",
      "[epoch 49] loss: 0.0017765\n",
      "Test set: Average loss: 2.0617, Accuracy: 2798/5000 (56%)\n",
      "[epoch 50] loss: 0.0016829\n",
      "Test set: Average loss: 2.0709, Accuracy: 2792/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0093, Accuracy: 2799/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.9894, Accuracy: 5691/10000 (57%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3050, Accuracy: 467/5000 (9%)\n",
      "[epoch 1] loss: 1.6396819\n",
      "Test set: Average loss: 1.5282, Accuracy: 2201/5000 (44%)\n",
      "[epoch 2] loss: 1.3778187\n",
      "Test set: Average loss: 1.4218, Accuracy: 2443/5000 (49%)\n",
      "[epoch 3] loss: 1.2573096\n",
      "Test set: Average loss: 1.3427, Accuracy: 2579/5000 (52%)\n",
      "[epoch 4] loss: 1.1436968\n",
      "Test set: Average loss: 1.2968, Accuracy: 2684/5000 (54%)\n",
      "[epoch 5] loss: 1.0118176\n",
      "Test set: Average loss: 1.2827, Accuracy: 2687/5000 (54%)\n",
      "[epoch 6] loss: 0.8759992\n",
      "Test set: Average loss: 1.3090, Accuracy: 2745/5000 (55%)\n",
      "[epoch 7] loss: 0.7157217\n",
      "Test set: Average loss: 1.3284, Accuracy: 2779/5000 (56%)\n",
      "[epoch 8] loss: 0.5313062\n",
      "Test set: Average loss: 1.4271, Accuracy: 2722/5000 (54%)\n",
      "[epoch 9] loss: 0.3698631\n",
      "Test set: Average loss: 1.4214, Accuracy: 2770/5000 (55%)\n",
      "[epoch 10] loss: 0.2282385\n",
      "Test set: Average loss: 1.5449, Accuracy: 2752/5000 (55%)\n",
      "[epoch 11] loss: 0.1228564\n",
      "Test set: Average loss: 1.6086, Accuracy: 2764/5000 (55%)\n",
      "[epoch 12] loss: 0.0556226\n",
      "Test set: Average loss: 1.6531, Accuracy: 2844/5000 (57%)\n",
      "[epoch 13] loss: 0.0242631\n",
      "Test set: Average loss: 1.7315, Accuracy: 2819/5000 (56%)\n",
      "[epoch 14] loss: 0.0178854\n",
      "Test set: Average loss: 1.7793, Accuracy: 2844/5000 (57%)\n",
      "[epoch 15] loss: 0.1725500\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1795, Accuracy: 2393/5000 (48%)\n",
      "[epoch 16] loss: 0.3067360\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7455, Accuracy: 2715/5000 (54%)\n",
      "[epoch 17] loss: 0.1049974\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7374, Accuracy: 2717/5000 (54%)\n",
      "[epoch 18] loss: 0.0975536\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 19] loss: 0.0968599\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 20] loss: 0.0967633\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 21] loss: 0.0967361\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 22] loss: 0.0967723\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 23] loss: 0.0967617\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 24] loss: 0.0967639\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 25] loss: 0.0967452\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 26] loss: 0.0967811\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 27] loss: 0.0967851\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 28] loss: 0.0967464\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 29] loss: 0.0967682\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 30] loss: 0.0967644\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 31] loss: 0.0967561\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 32] loss: 0.0967350\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 33] loss: 0.0967674\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 34] loss: 0.0968034\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 35] loss: 0.0967752\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 36] loss: 0.0967450\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 37] loss: 0.0967321\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 38] loss: 0.0967390\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 39] loss: 0.0968439\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 40] loss: 0.0967305\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 41] loss: 0.0967460\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 42] loss: 0.0967524\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 43] loss: 0.0967632\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 44] loss: 0.0967610\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 45] loss: 0.0967424\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 46] loss: 0.0967494\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 47] loss: 0.0967614\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 48] loss: 0.0967752\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 49] loss: 0.0967468\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "[epoch 50] loss: 0.0967564\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.7373, Accuracy: 2716/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7793, Accuracy: 2844/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.7568, Accuracy: 5719/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2986, Accuracy: 535/5000 (11%)\n",
      "[epoch 1] loss: 1.6720727\n",
      "Test set: Average loss: 1.5366, Accuracy: 2279/5000 (46%)\n",
      "[epoch 2] loss: 1.4309398\n",
      "Test set: Average loss: 1.4033, Accuracy: 2500/5000 (50%)\n",
      "[epoch 3] loss: 1.2965687\n",
      "Test set: Average loss: 1.4356, Accuracy: 2434/5000 (49%)\n",
      "[epoch 4] loss: 1.1904925\n",
      "Test set: Average loss: 1.3480, Accuracy: 2643/5000 (53%)\n",
      "[epoch 5] loss: 1.0796824\n",
      "Test set: Average loss: 1.3361, Accuracy: 2648/5000 (53%)\n",
      "[epoch 6] loss: 0.9400552\n",
      "Test set: Average loss: 1.3469, Accuracy: 2660/5000 (53%)\n",
      "[epoch 7] loss: 0.7906245\n",
      "Test set: Average loss: 1.3549, Accuracy: 2734/5000 (55%)\n",
      "[epoch 8] loss: 0.6128149\n",
      "Test set: Average loss: 1.4092, Accuracy: 2682/5000 (54%)\n",
      "[epoch 9] loss: 0.4425511\n",
      "Test set: Average loss: 1.4279, Accuracy: 2718/5000 (54%)\n",
      "[epoch 10] loss: 0.2745504\n",
      "Test set: Average loss: 1.5178, Accuracy: 2755/5000 (55%)\n",
      "[epoch 11] loss: 0.1486758\n",
      "Test set: Average loss: 1.6126, Accuracy: 2736/5000 (55%)\n",
      "[epoch 12] loss: 0.0826386\n",
      "Test set: Average loss: 1.6953, Accuracy: 2768/5000 (55%)\n",
      "[epoch 13] loss: 0.0342624\n",
      "Test set: Average loss: 1.7584, Accuracy: 2807/5000 (56%)\n",
      "[epoch 14] loss: 0.0131963\n",
      "Test set: Average loss: 1.7834, Accuracy: 2839/5000 (57%)\n",
      "[epoch 15] loss: 0.0068606\n",
      "Test set: Average loss: 1.8374, Accuracy: 2849/5000 (57%)\n",
      "[epoch 16] loss: 0.0042965\n",
      "Test set: Average loss: 1.8921, Accuracy: 2860/5000 (57%)\n",
      "[epoch 17] loss: 0.0031882\n",
      "Test set: Average loss: 1.9319, Accuracy: 2861/5000 (57%)\n",
      "[epoch 18] loss: 0.0024177\n",
      "Test set: Average loss: 1.9749, Accuracy: 2868/5000 (57%)\n",
      "[epoch 19] loss: 0.0018548\n",
      "Test set: Average loss: 2.0120, Accuracy: 2868/5000 (57%)\n",
      "[epoch 20] loss: 0.0014401\n",
      "Test set: Average loss: 2.0614, Accuracy: 2865/5000 (57%)\n",
      "[epoch 21] loss: 0.0011081\n",
      "Test set: Average loss: 2.1077, Accuracy: 2858/5000 (57%)\n",
      "[epoch 22] loss: 0.0008588\n",
      "Test set: Average loss: 2.1561, Accuracy: 2855/5000 (57%)\n",
      "[epoch 23] loss: 0.0006643\n",
      "Test set: Average loss: 2.1922, Accuracy: 2857/5000 (57%)\n",
      "[epoch 24] loss: 0.0005129\n",
      "Test set: Average loss: 2.2417, Accuracy: 2853/5000 (57%)\n",
      "[epoch 25] loss: 0.0003931\n",
      "Test set: Average loss: 2.2815, Accuracy: 2836/5000 (57%)\n",
      "[epoch 26] loss: 0.0003043\n",
      "Test set: Average loss: 2.3325, Accuracy: 2831/5000 (57%)\n",
      "[epoch 27] loss: 0.0002348\n",
      "Test set: Average loss: 2.3711, Accuracy: 2847/5000 (57%)\n",
      "[epoch 28] loss: 0.0001804\n",
      "Test set: Average loss: 2.4238, Accuracy: 2842/5000 (57%)\n",
      "[epoch 29] loss: 0.0001396\n",
      "Test set: Average loss: 2.4665, Accuracy: 2834/5000 (57%)\n",
      "[epoch 30] loss: 0.0001078\n",
      "Test set: Average loss: 2.5068, Accuracy: 2839/5000 (57%)\n",
      "[epoch 31] loss: 0.0000829\n",
      "Test set: Average loss: 2.5591, Accuracy: 2829/5000 (57%)\n",
      "[epoch 32] loss: 0.0000643\n",
      "Test set: Average loss: 2.6046, Accuracy: 2829/5000 (57%)\n",
      "[epoch 33] loss: 0.0000494\n",
      "Test set: Average loss: 2.6425, Accuracy: 2828/5000 (57%)\n",
      "[epoch 34] loss: 0.0000381\n",
      "Test set: Average loss: 2.6815, Accuracy: 2820/5000 (56%)\n",
      "[epoch 35] loss: 0.0000295\n",
      "Test set: Average loss: 2.7313, Accuracy: 2821/5000 (56%)\n",
      "[epoch 36] loss: 0.0000227\n",
      "Test set: Average loss: 2.7759, Accuracy: 2820/5000 (56%)\n",
      "[epoch 37] loss: 0.0000175\n",
      "Test set: Average loss: 2.8261, Accuracy: 2819/5000 (56%)\n",
      "[epoch 38] loss: 0.0000135\n",
      "Test set: Average loss: 2.8687, Accuracy: 2812/5000 (56%)\n",
      "[epoch 39] loss: 0.0000104\n",
      "Test set: Average loss: 2.9097, Accuracy: 2805/5000 (56%)\n",
      "[epoch 40] loss: 0.0000081\n",
      "Test set: Average loss: 2.9538, Accuracy: 2815/5000 (56%)\n",
      "[epoch 41] loss: 0.0000062\n",
      "Test set: Average loss: 2.9939, Accuracy: 2812/5000 (56%)\n",
      "[epoch 42] loss: 0.0000048\n",
      "Test set: Average loss: 3.0402, Accuracy: 2804/5000 (56%)\n",
      "[epoch 43] loss: 0.0000037\n",
      "Test set: Average loss: 3.0883, Accuracy: 2809/5000 (56%)\n",
      "[epoch 44] loss: 0.0000029\n",
      "Test set: Average loss: 3.1330, Accuracy: 2804/5000 (56%)\n",
      "[epoch 45] loss: 0.0000022\n",
      "Test set: Average loss: 3.1614, Accuracy: 2804/5000 (56%)\n",
      "[epoch 46] loss: 0.0000017\n",
      "Test set: Average loss: 3.2050, Accuracy: 2798/5000 (56%)\n",
      "[epoch 47] loss: 0.0000013\n",
      "Test set: Average loss: 3.2363, Accuracy: 2803/5000 (56%)\n",
      "[epoch 48] loss: 0.0000010\n",
      "Test set: Average loss: 3.2691, Accuracy: 2794/5000 (56%)\n",
      "[epoch 49] loss: 0.0000007\n",
      "Test set: Average loss: 3.2721, Accuracy: 2786/5000 (56%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 3.2761, Accuracy: 2791/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0120, Accuracy: 2868/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.9849, Accuracy: 5743/10000 (57%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3061, Accuracy: 479/5000 (10%)\n",
      "[epoch 1] loss: 1.6193496\n",
      "Test set: Average loss: 1.4262, Accuracy: 2417/5000 (48%)\n",
      "[epoch 2] loss: 1.3592610\n",
      "Test set: Average loss: 1.3122, Accuracy: 2633/5000 (53%)\n",
      "[epoch 3] loss: 1.2336990\n",
      "Test set: Average loss: 1.2951, Accuracy: 2700/5000 (54%)\n",
      "[epoch 4] loss: 1.1126120\n",
      "Test set: Average loss: 1.3016, Accuracy: 2666/5000 (53%)\n",
      "[epoch 5] loss: 0.9937911\n",
      "Test set: Average loss: 1.2380, Accuracy: 2830/5000 (57%)\n",
      "[epoch 6] loss: 0.8679759\n",
      "Test set: Average loss: 1.2585, Accuracy: 2823/5000 (56%)\n",
      "[epoch 7] loss: 0.7332814\n",
      "Test set: Average loss: 1.3114, Accuracy: 2826/5000 (57%)\n",
      "[epoch 8] loss: 0.5838439\n",
      "Test set: Average loss: 1.4115, Accuracy: 2786/5000 (56%)\n",
      "[epoch 9] loss: 0.4290724\n",
      "Test set: Average loss: 1.3921, Accuracy: 2841/5000 (57%)\n",
      "[epoch 10] loss: 0.2826620\n",
      "Test set: Average loss: 1.5080, Accuracy: 2824/5000 (56%)\n",
      "[epoch 11] loss: 0.1908961\n",
      "Test set: Average loss: 1.6095, Accuracy: 2777/5000 (56%)\n",
      "[epoch 12] loss: 0.1385624\n",
      "Test set: Average loss: 1.6522, Accuracy: 2809/5000 (56%)\n",
      "[epoch 13] loss: 0.1222594\n",
      "Test set: Average loss: 1.8886, Accuracy: 2709/5000 (54%)\n",
      "[epoch 14] loss: 0.1342182\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2783/5000 (56%)\n",
      "[epoch 15] loss: 0.0531020\n",
      "Test set: Average loss: 1.8062, Accuracy: 2874/5000 (57%)\n",
      "[epoch 16] loss: 0.0218447\n",
      "Test set: Average loss: 1.8114, Accuracy: 2899/5000 (58%)\n",
      "[epoch 17] loss: 0.0152465\n",
      "Test set: Average loss: 1.8222, Accuracy: 2908/5000 (58%)\n",
      "[epoch 18] loss: 0.0116354\n",
      "Test set: Average loss: 1.8348, Accuracy: 2912/5000 (58%)\n",
      "[epoch 19] loss: 0.0092377\n",
      "Test set: Average loss: 1.8493, Accuracy: 2909/5000 (58%)\n",
      "[epoch 20] loss: 0.0074176\n",
      "Test set: Average loss: 1.8753, Accuracy: 2916/5000 (58%)\n",
      "[epoch 21] loss: 0.0060306\n",
      "Test set: Average loss: 1.8906, Accuracy: 2935/5000 (59%)\n",
      "[epoch 22] loss: 0.0048828\n",
      "Test set: Average loss: 1.9147, Accuracy: 2927/5000 (59%)\n",
      "[epoch 23] loss: 0.0039435\n",
      "Test set: Average loss: 1.9424, Accuracy: 2933/5000 (59%)\n",
      "[epoch 24] loss: 0.0031888\n",
      "Test set: Average loss: 1.9709, Accuracy: 2960/5000 (59%)\n",
      "[epoch 25] loss: 0.0025557\n",
      "Test set: Average loss: 2.0088, Accuracy: 2939/5000 (59%)\n",
      "[epoch 26] loss: 0.0020362\n",
      "Test set: Average loss: 2.0356, Accuracy: 2946/5000 (59%)\n",
      "[epoch 27] loss: 0.0016178\n",
      "Test set: Average loss: 2.0697, Accuracy: 2937/5000 (59%)\n",
      "[epoch 28] loss: 0.0012804\n",
      "Test set: Average loss: 2.1118, Accuracy: 2931/5000 (59%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] loss: 0.0010043\n",
      "Test set: Average loss: 2.1470, Accuracy: 2938/5000 (59%)\n",
      "[epoch 30] loss: 0.0007824\n",
      "Test set: Average loss: 2.1825, Accuracy: 2939/5000 (59%)\n",
      "[epoch 31] loss: 0.0006123\n",
      "Test set: Average loss: 2.2227, Accuracy: 2936/5000 (59%)\n",
      "[epoch 32] loss: 0.0004751\n",
      "Test set: Average loss: 2.2723, Accuracy: 2946/5000 (59%)\n",
      "[epoch 33] loss: 0.0003660\n",
      "Test set: Average loss: 2.3129, Accuracy: 2943/5000 (59%)\n",
      "[epoch 34] loss: 0.0002831\n",
      "Test set: Average loss: 2.3494, Accuracy: 2946/5000 (59%)\n",
      "[epoch 35] loss: 0.0002177\n",
      "Test set: Average loss: 2.3952, Accuracy: 2945/5000 (59%)\n",
      "[epoch 36] loss: 0.0001671\n",
      "Test set: Average loss: 2.4482, Accuracy: 2941/5000 (59%)\n",
      "[epoch 37] loss: 0.0001281\n",
      "Test set: Average loss: 2.4880, Accuracy: 2935/5000 (59%)\n",
      "[epoch 38] loss: 0.0000976\n",
      "Test set: Average loss: 2.5327, Accuracy: 2940/5000 (59%)\n",
      "[epoch 39] loss: 0.0000746\n",
      "Test set: Average loss: 2.5743, Accuracy: 2944/5000 (59%)\n",
      "[epoch 40] loss: 0.0000569\n",
      "Test set: Average loss: 2.6293, Accuracy: 2947/5000 (59%)\n",
      "[epoch 41] loss: 0.0000432\n",
      "Test set: Average loss: 2.6761, Accuracy: 2933/5000 (59%)\n",
      "[epoch 42] loss: 0.0000328\n",
      "Test set: Average loss: 2.7222, Accuracy: 2933/5000 (59%)\n",
      "[epoch 43] loss: 0.0000248\n",
      "Test set: Average loss: 2.7688, Accuracy: 2944/5000 (59%)\n",
      "[epoch 44] loss: 0.0000188\n",
      "Test set: Average loss: 2.8237, Accuracy: 2927/5000 (59%)\n",
      "[epoch 45] loss: 0.0000143\n",
      "Test set: Average loss: 2.8702, Accuracy: 2936/5000 (59%)\n",
      "[epoch 46] loss: 0.0000107\n",
      "Test set: Average loss: 2.9228, Accuracy: 2930/5000 (59%)\n",
      "[epoch 47] loss: 0.0000081\n",
      "Test set: Average loss: 2.9727, Accuracy: 2932/5000 (59%)\n",
      "[epoch 48] loss: 0.0000061\n",
      "Test set: Average loss: 3.0165, Accuracy: 2923/5000 (58%)\n",
      "[epoch 49] loss: 0.0000046\n",
      "Test set: Average loss: 3.0627, Accuracy: 2918/5000 (58%)\n",
      "[epoch 50] loss: 0.0000035\n",
      "Test set: Average loss: 3.1153, Accuracy: 2917/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9709, Accuracy: 2960/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 1.9412, Accuracy: 5895/10000 (59%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3079, Accuracy: 375/5000 (8%)\n",
      "[epoch 1] loss: 1.6170053\n",
      "Test set: Average loss: 1.4900, Accuracy: 2318/5000 (46%)\n",
      "[epoch 2] loss: 1.3529889\n",
      "Test set: Average loss: 1.3757, Accuracy: 2504/5000 (50%)\n",
      "[epoch 3] loss: 1.2033250\n",
      "Test set: Average loss: 1.3258, Accuracy: 2604/5000 (52%)\n",
      "[epoch 4] loss: 1.0730851\n",
      "Test set: Average loss: 1.2678, Accuracy: 2783/5000 (56%)\n",
      "[epoch 5] loss: 0.9247091\n",
      "Test set: Average loss: 1.3163, Accuracy: 2741/5000 (55%)\n",
      "[epoch 6] loss: 0.7742565\n",
      "Test set: Average loss: 1.3736, Accuracy: 2755/5000 (55%)\n",
      "[epoch 7] loss: 0.6063085\n",
      "Test set: Average loss: 1.4200, Accuracy: 2770/5000 (55%)\n",
      "[epoch 8] loss: 0.4311581\n",
      "Test set: Average loss: 1.4788, Accuracy: 2811/5000 (56%)\n",
      "[epoch 9] loss: 0.2786355\n",
      "Test set: Average loss: 1.5433, Accuracy: 2782/5000 (56%)\n",
      "[epoch 10] loss: 0.1782803\n",
      "Test set: Average loss: 1.7198, Accuracy: 2715/5000 (54%)\n",
      "[epoch 11] loss: 0.1117220\n",
      "Test set: Average loss: 1.7342, Accuracy: 2798/5000 (56%)\n",
      "[epoch 12] loss: 0.0768939\n",
      "Test set: Average loss: 1.8421, Accuracy: 2705/5000 (54%)\n",
      "[epoch 13] loss: 0.1274778\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0785, Accuracy: 2633/5000 (53%)\n",
      "[epoch 14] loss: 0.0803591\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8778, Accuracy: 2846/5000 (57%)\n",
      "[epoch 15] loss: 0.0260557\n",
      "Test set: Average loss: 1.8775, Accuracy: 2854/5000 (57%)\n",
      "[epoch 16] loss: 0.0243343\n",
      "Test set: Average loss: 1.8782, Accuracy: 2856/5000 (57%)\n",
      "[epoch 17] loss: 0.0227548\n",
      "Test set: Average loss: 1.8798, Accuracy: 2858/5000 (57%)\n",
      "[epoch 18] loss: 0.0211291\n",
      "Test set: Average loss: 1.8832, Accuracy: 2860/5000 (57%)\n",
      "[epoch 19] loss: 0.0194867\n",
      "Test set: Average loss: 1.8838, Accuracy: 2855/5000 (57%)\n",
      "[epoch 20] loss: 0.0179074\n",
      "Test set: Average loss: 1.8872, Accuracy: 2855/5000 (57%)\n",
      "[epoch 21] loss: 0.0163932\n",
      "Test set: Average loss: 1.8908, Accuracy: 2862/5000 (57%)\n",
      "[epoch 22] loss: 0.0149975\n",
      "Test set: Average loss: 1.8951, Accuracy: 2862/5000 (57%)\n",
      "[epoch 23] loss: 0.0137343\n",
      "Test set: Average loss: 1.8995, Accuracy: 2854/5000 (57%)\n",
      "[epoch 24] loss: 0.0125936\n",
      "Test set: Average loss: 1.9032, Accuracy: 2862/5000 (57%)\n",
      "[epoch 25] loss: 0.0115501\n",
      "Test set: Average loss: 1.9083, Accuracy: 2870/5000 (57%)\n",
      "[epoch 26] loss: 0.0106241\n",
      "Test set: Average loss: 1.9150, Accuracy: 2871/5000 (57%)\n",
      "[epoch 27] loss: 0.0097861\n",
      "Test set: Average loss: 1.9194, Accuracy: 2867/5000 (57%)\n",
      "[epoch 28] loss: 0.0090282\n",
      "Test set: Average loss: 1.9241, Accuracy: 2871/5000 (57%)\n",
      "[epoch 29] loss: 0.0083417\n",
      "Test set: Average loss: 1.9309, Accuracy: 2868/5000 (57%)\n",
      "[epoch 30] loss: 0.0077184\n",
      "Test set: Average loss: 1.9361, Accuracy: 2875/5000 (58%)\n",
      "[epoch 31] loss: 0.0071491\n",
      "Test set: Average loss: 1.9432, Accuracy: 2877/5000 (58%)\n",
      "[epoch 32] loss: 0.0066342\n",
      "Test set: Average loss: 1.9494, Accuracy: 2876/5000 (58%)\n",
      "[epoch 33] loss: 0.0061606\n",
      "Test set: Average loss: 1.9569, Accuracy: 2883/5000 (58%)\n",
      "[epoch 34] loss: 0.0057331\n",
      "Test set: Average loss: 1.9635, Accuracy: 2882/5000 (58%)\n",
      "[epoch 35] loss: 0.0053377\n",
      "Test set: Average loss: 1.9700, Accuracy: 2881/5000 (58%)\n",
      "[epoch 36] loss: 0.0049712\n",
      "Test set: Average loss: 1.9773, Accuracy: 2878/5000 (58%)\n",
      "[epoch 37] loss: 0.0046331\n",
      "Test set: Average loss: 1.9844, Accuracy: 2882/5000 (58%)\n",
      "[epoch 38] loss: 0.0043231\n",
      "Test set: Average loss: 1.9932, Accuracy: 2874/5000 (57%)\n",
      "[epoch 39] loss: 0.0040380\n",
      "Test set: Average loss: 1.9999, Accuracy: 2879/5000 (58%)\n",
      "[epoch 40] loss: 0.0037696\n",
      "Test set: Average loss: 2.0077, Accuracy: 2879/5000 (58%)\n",
      "[epoch 41] loss: 0.0035244\n",
      "Test set: Average loss: 2.0168, Accuracy: 2877/5000 (58%)\n",
      "[epoch 42] loss: 0.0032967\n",
      "Test set: Average loss: 2.0231, Accuracy: 2878/5000 (58%)\n",
      "[epoch 43] loss: 0.0030848\n",
      "Test set: Average loss: 2.0302, Accuracy: 2883/5000 (58%)\n",
      "[epoch 44] loss: 0.0028884\n",
      "Test set: Average loss: 2.0394, Accuracy: 2888/5000 (58%)\n",
      "[epoch 45] loss: 0.0027041\n",
      "Test set: Average loss: 2.0478, Accuracy: 2882/5000 (58%)\n",
      "[epoch 46] loss: 0.0025318\n",
      "Test set: Average loss: 2.0565, Accuracy: 2883/5000 (58%)\n",
      "[epoch 47] loss: 0.0023746\n",
      "Test set: Average loss: 2.0652, Accuracy: 2880/5000 (58%)\n",
      "[epoch 48] loss: 0.0022245\n",
      "Test set: Average loss: 2.0748, Accuracy: 2878/5000 (58%)\n",
      "[epoch 49] loss: 0.0020864\n",
      "Test set: Average loss: 2.0831, Accuracy: 2885/5000 (58%)\n",
      "[epoch 50] loss: 0.0019577\n",
      "Test set: Average loss: 2.0915, Accuracy: 2882/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0394, Accuracy: 2888/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 2.0185, Accuracy: 5778/10000 (58%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3118, Accuracy: 397/5000 (8%)\n",
      "[epoch 1] loss: 1.6252894\n",
      "Test set: Average loss: 1.4703, Accuracy: 2321/5000 (46%)\n",
      "[epoch 2] loss: 1.3602956\n",
      "Test set: Average loss: 1.3694, Accuracy: 2557/5000 (51%)\n",
      "[epoch 3] loss: 1.2324297\n",
      "Test set: Average loss: 1.3034, Accuracy: 2662/5000 (53%)\n",
      "[epoch 4] loss: 1.1144570\n",
      "Test set: Average loss: 1.2608, Accuracy: 2760/5000 (55%)\n",
      "[epoch 5] loss: 0.9967215\n",
      "Test set: Average loss: 1.2224, Accuracy: 2873/5000 (57%)\n",
      "[epoch 6] loss: 0.8679906\n",
      "Test set: Average loss: 1.3239, Accuracy: 2774/5000 (55%)\n",
      "[epoch 7] loss: 0.7410775\n",
      "Test set: Average loss: 1.3261, Accuracy: 2781/5000 (56%)\n",
      "[epoch 8] loss: 0.5882634\n",
      "Test set: Average loss: 1.3572, Accuracy: 2828/5000 (57%)\n",
      "[epoch 9] loss: 0.4355845\n",
      "Test set: Average loss: 1.3681, Accuracy: 2836/5000 (57%)\n",
      "[epoch 10] loss: 0.3035454\n",
      "Test set: Average loss: 1.4939, Accuracy: 2798/5000 (56%)\n",
      "[epoch 11] loss: 0.2208358\n",
      "Test set: Average loss: 1.6038, Accuracy: 2825/5000 (56%)\n",
      "[epoch 12] loss: 0.1400082\n",
      "Test set: Average loss: 1.7148, Accuracy: 2791/5000 (56%)\n",
      "[epoch 13] loss: 0.1269173\n",
      "Test set: Average loss: 1.7920, Accuracy: 2848/5000 (57%)\n",
      "[epoch 14] loss: 0.1736969\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9082, Accuracy: 2745/5000 (55%)\n",
      "[epoch 15] loss: 0.0734425\n",
      "Test set: Average loss: 1.7502, Accuracy: 2874/5000 (57%)\n",
      "[epoch 16] loss: 0.0275871\n",
      "Test set: Average loss: 1.7521, Accuracy: 2901/5000 (58%)\n",
      "[epoch 17] loss: 0.0189525\n",
      "Test set: Average loss: 1.7614, Accuracy: 2910/5000 (58%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0143881\n",
      "Test set: Average loss: 1.7798, Accuracy: 2916/5000 (58%)\n",
      "[epoch 19] loss: 0.0113193\n",
      "Test set: Average loss: 1.7969, Accuracy: 2928/5000 (59%)\n",
      "[epoch 20] loss: 0.0090202\n",
      "Test set: Average loss: 1.8166, Accuracy: 2919/5000 (58%)\n",
      "[epoch 21] loss: 0.0072656\n",
      "Test set: Average loss: 1.8352, Accuracy: 2938/5000 (59%)\n",
      "[epoch 22] loss: 0.0058601\n",
      "Test set: Average loss: 1.8605, Accuracy: 2943/5000 (59%)\n",
      "[epoch 23] loss: 0.0047042\n",
      "Test set: Average loss: 1.8911, Accuracy: 2942/5000 (59%)\n",
      "[epoch 24] loss: 0.0037842\n",
      "Test set: Average loss: 1.9116, Accuracy: 2949/5000 (59%)\n",
      "[epoch 25] loss: 0.0030274\n",
      "Test set: Average loss: 1.9389, Accuracy: 2941/5000 (59%)\n",
      "[epoch 26] loss: 0.0024033\n",
      "Test set: Average loss: 1.9761, Accuracy: 2945/5000 (59%)\n",
      "[epoch 27] loss: 0.0019043\n",
      "Test set: Average loss: 2.0079, Accuracy: 2943/5000 (59%)\n",
      "[epoch 28] loss: 0.0015017\n",
      "Test set: Average loss: 2.0399, Accuracy: 2942/5000 (59%)\n",
      "[epoch 29] loss: 0.0011773\n",
      "Test set: Average loss: 2.0840, Accuracy: 2948/5000 (59%)\n",
      "[epoch 30] loss: 0.0009202\n",
      "Test set: Average loss: 2.1185, Accuracy: 2939/5000 (59%)\n",
      "[epoch 31] loss: 0.0007153\n",
      "Test set: Average loss: 2.1579, Accuracy: 2944/5000 (59%)\n",
      "[epoch 32] loss: 0.0005541\n",
      "Test set: Average loss: 2.2009, Accuracy: 2951/5000 (59%)\n",
      "[epoch 33] loss: 0.0004280\n",
      "Test set: Average loss: 2.2418, Accuracy: 2953/5000 (59%)\n",
      "[epoch 34] loss: 0.0003295\n",
      "Test set: Average loss: 2.2831, Accuracy: 2948/5000 (59%)\n",
      "[epoch 35] loss: 0.0002532\n",
      "Test set: Average loss: 2.3244, Accuracy: 2940/5000 (59%)\n",
      "[epoch 36] loss: 0.0001948\n",
      "Test set: Average loss: 2.3726, Accuracy: 2954/5000 (59%)\n",
      "[epoch 37] loss: 0.0001486\n",
      "Test set: Average loss: 2.4158, Accuracy: 2941/5000 (59%)\n",
      "[epoch 38] loss: 0.0001135\n",
      "Test set: Average loss: 2.4567, Accuracy: 2951/5000 (59%)\n",
      "[epoch 39] loss: 0.0000863\n",
      "Test set: Average loss: 2.5059, Accuracy: 2946/5000 (59%)\n",
      "[epoch 40] loss: 0.0000657\n",
      "Test set: Average loss: 2.5536, Accuracy: 2942/5000 (59%)\n",
      "[epoch 41] loss: 0.0000499\n",
      "Test set: Average loss: 2.6044, Accuracy: 2942/5000 (59%)\n",
      "[epoch 42] loss: 0.0000379\n",
      "Test set: Average loss: 2.6526, Accuracy: 2943/5000 (59%)\n",
      "[epoch 43] loss: 0.0000286\n",
      "Test set: Average loss: 2.7020, Accuracy: 2936/5000 (59%)\n",
      "[epoch 44] loss: 0.0000217\n",
      "Test set: Average loss: 2.7492, Accuracy: 2932/5000 (59%)\n",
      "[epoch 45] loss: 0.0000164\n",
      "Test set: Average loss: 2.7957, Accuracy: 2933/5000 (59%)\n",
      "[epoch 46] loss: 0.0000124\n",
      "Test set: Average loss: 2.8423, Accuracy: 2940/5000 (59%)\n",
      "[epoch 47] loss: 0.0000093\n",
      "Test set: Average loss: 2.8993, Accuracy: 2942/5000 (59%)\n",
      "[epoch 48] loss: 0.0000070\n",
      "Test set: Average loss: 2.9393, Accuracy: 2929/5000 (59%)\n",
      "[epoch 49] loss: 0.0000053\n",
      "Test set: Average loss: 2.9927, Accuracy: 2942/5000 (59%)\n",
      "[epoch 50] loss: 0.0000040\n",
      "Test set: Average loss: 3.0338, Accuracy: 2925/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3726, Accuracy: 2954/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 2.3603, Accuracy: 5931/10000 (59%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3029, Accuracy: 563/5000 (11%)\n",
      "[epoch 1] loss: 1.5758955\n",
      "Test set: Average loss: 1.4203, Accuracy: 2413/5000 (48%)\n",
      "[epoch 2] loss: 1.3337631\n",
      "Test set: Average loss: 1.3944, Accuracy: 2522/5000 (50%)\n",
      "[epoch 3] loss: 1.2179844\n",
      "Test set: Average loss: 1.2560, Accuracy: 2773/5000 (55%)\n",
      "[epoch 4] loss: 1.1031812\n",
      "Test set: Average loss: 1.2956, Accuracy: 2751/5000 (55%)\n",
      "[epoch 5] loss: 1.0058206\n",
      "Test set: Average loss: 1.2661, Accuracy: 2820/5000 (56%)\n",
      "[epoch 6] loss: 0.8865784\n",
      "Test set: Average loss: 1.2837, Accuracy: 2772/5000 (55%)\n",
      "[epoch 7] loss: 0.7671147\n",
      "Test set: Average loss: 1.2632, Accuracy: 2845/5000 (57%)\n",
      "[epoch 8] loss: 0.6330510\n",
      "Test set: Average loss: 1.3094, Accuracy: 2867/5000 (57%)\n",
      "[epoch 9] loss: 0.4984774\n",
      "Test set: Average loss: 1.4160, Accuracy: 2845/5000 (57%)\n",
      "[epoch 10] loss: 0.3768933\n",
      "Test set: Average loss: 1.4875, Accuracy: 2786/5000 (56%)\n",
      "[epoch 11] loss: 0.2764189\n",
      "Test set: Average loss: 1.5779, Accuracy: 2793/5000 (56%)\n",
      "[epoch 12] loss: 0.1966938\n",
      "Test set: Average loss: 1.6628, Accuracy: 2792/5000 (56%)\n",
      "[epoch 13] loss: 0.1780396\n",
      "Test set: Average loss: 1.7588, Accuracy: 2775/5000 (56%)\n",
      "[epoch 14] loss: 0.1599775\n",
      "Test set: Average loss: 1.9055, Accuracy: 2739/5000 (55%)\n",
      "[epoch 15] loss: 0.1499268\n",
      "Test set: Average loss: 2.0074, Accuracy: 2727/5000 (55%)\n",
      "[epoch 16] loss: 0.1453514\n",
      "Test set: Average loss: 1.9994, Accuracy: 2800/5000 (56%)\n",
      "[epoch 17] loss: 0.1281167\n",
      "Test set: Average loss: 2.1072, Accuracy: 2735/5000 (55%)\n",
      "[epoch 18] loss: 0.1559944\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1957, Accuracy: 2691/5000 (54%)\n",
      "[epoch 19] loss: 0.0731650\n",
      "Test set: Average loss: 2.0537, Accuracy: 2826/5000 (57%)\n",
      "[epoch 20] loss: 0.0216369\n",
      "Test set: Average loss: 2.0587, Accuracy: 2858/5000 (57%)\n",
      "[epoch 21] loss: 0.0133731\n",
      "Test set: Average loss: 2.0652, Accuracy: 2858/5000 (57%)\n",
      "[epoch 22] loss: 0.0096231\n",
      "Test set: Average loss: 2.0756, Accuracy: 2865/5000 (57%)\n",
      "[epoch 23] loss: 0.0072376\n",
      "Test set: Average loss: 2.0912, Accuracy: 2878/5000 (58%)\n",
      "[epoch 24] loss: 0.0055569\n",
      "Test set: Average loss: 2.1048, Accuracy: 2889/5000 (58%)\n",
      "[epoch 25] loss: 0.0042774\n",
      "Test set: Average loss: 2.1266, Accuracy: 2895/5000 (58%)\n",
      "[epoch 26] loss: 0.0033344\n",
      "Test set: Average loss: 2.1403, Accuracy: 2916/5000 (58%)\n",
      "[epoch 27] loss: 0.0025435\n",
      "Test set: Average loss: 2.1643, Accuracy: 2914/5000 (58%)\n",
      "[epoch 28] loss: 0.0019454\n",
      "Test set: Average loss: 2.1949, Accuracy: 2911/5000 (58%)\n",
      "[epoch 29] loss: 0.0014856\n",
      "Test set: Average loss: 2.2301, Accuracy: 2903/5000 (58%)\n",
      "[epoch 30] loss: 0.0011283\n",
      "Test set: Average loss: 2.2532, Accuracy: 2910/5000 (58%)\n",
      "[epoch 31] loss: 0.0008527\n",
      "Test set: Average loss: 2.2975, Accuracy: 2899/5000 (58%)\n",
      "[epoch 32] loss: 0.0006404\n",
      "Test set: Average loss: 2.3272, Accuracy: 2900/5000 (58%)\n",
      "[epoch 33] loss: 0.0004801\n",
      "Test set: Average loss: 2.3656, Accuracy: 2902/5000 (58%)\n",
      "[epoch 34] loss: 0.0003565\n",
      "Test set: Average loss: 2.4130, Accuracy: 2908/5000 (58%)\n",
      "[epoch 35] loss: 0.0002635\n",
      "Test set: Average loss: 2.4502, Accuracy: 2908/5000 (58%)\n",
      "[epoch 36] loss: 0.0001950\n",
      "Test set: Average loss: 2.4958, Accuracy: 2926/5000 (59%)\n",
      "[epoch 37] loss: 0.0001440\n",
      "Test set: Average loss: 2.5463, Accuracy: 2903/5000 (58%)\n",
      "[epoch 38] loss: 0.0001058\n",
      "Test set: Average loss: 2.5860, Accuracy: 2926/5000 (59%)\n",
      "[epoch 39] loss: 0.0000776\n",
      "Test set: Average loss: 2.6445, Accuracy: 2904/5000 (58%)\n",
      "[epoch 40] loss: 0.0000566\n",
      "Test set: Average loss: 2.6929, Accuracy: 2921/5000 (58%)\n",
      "[epoch 41] loss: 0.0000413\n",
      "Test set: Average loss: 2.7674, Accuracy: 2906/5000 (58%)\n",
      "[epoch 42] loss: 0.0000301\n",
      "Test set: Average loss: 2.7954, Accuracy: 2907/5000 (58%)\n",
      "[epoch 43] loss: 0.0000219\n",
      "Test set: Average loss: 2.8489, Accuracy: 2925/5000 (58%)\n",
      "[epoch 44] loss: 0.0000158\n",
      "Test set: Average loss: 2.9060, Accuracy: 2935/5000 (59%)\n",
      "[epoch 45] loss: 0.0000115\n",
      "Test set: Average loss: 2.9519, Accuracy: 2913/5000 (58%)\n",
      "[epoch 46] loss: 0.0000083\n",
      "Test set: Average loss: 3.0053, Accuracy: 2918/5000 (58%)\n",
      "[epoch 47] loss: 0.0000060\n",
      "Test set: Average loss: 3.0536, Accuracy: 2924/5000 (58%)\n",
      "[epoch 48] loss: 0.0000043\n",
      "Test set: Average loss: 3.1073, Accuracy: 2918/5000 (58%)\n",
      "[epoch 49] loss: 0.0000031\n",
      "Test set: Average loss: 3.1628, Accuracy: 2933/5000 (59%)\n",
      "[epoch 50] loss: 0.0000022\n",
      "Test set: Average loss: 3.2201, Accuracy: 2918/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9060, Accuracy: 2935/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 2.8594, Accuracy: 5918/10000 (59%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2987, Accuracy: 577/5000 (12%)\n",
      "[epoch 1] loss: 1.5479410\n",
      "Test set: Average loss: 1.4417, Accuracy: 2394/5000 (48%)\n",
      "[epoch 2] loss: 1.2956597\n",
      "Test set: Average loss: 1.3134, Accuracy: 2654/5000 (53%)\n",
      "[epoch 3] loss: 1.1592665\n",
      "Test set: Average loss: 1.2018, Accuracy: 2890/5000 (58%)\n",
      "[epoch 4] loss: 1.0339982\n",
      "Test set: Average loss: 1.1818, Accuracy: 2896/5000 (58%)\n",
      "[epoch 5] loss: 0.9204936\n",
      "Test set: Average loss: 1.1869, Accuracy: 2931/5000 (59%)\n",
      "[epoch 6] loss: 0.7978271\n",
      "Test set: Average loss: 1.2372, Accuracy: 2952/5000 (59%)\n",
      "[epoch 7] loss: 0.6661070\n",
      "Test set: Average loss: 1.2250, Accuracy: 2978/5000 (60%)\n",
      "[epoch 8] loss: 0.5386847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3230, Accuracy: 2914/5000 (58%)\n",
      "[epoch 9] loss: 0.4154308\n",
      "Test set: Average loss: 1.4611, Accuracy: 2839/5000 (57%)\n",
      "[epoch 10] loss: 0.3076306\n",
      "Test set: Average loss: 1.4585, Accuracy: 2968/5000 (59%)\n",
      "[epoch 11] loss: 0.2191394\n",
      "Test set: Average loss: 1.6026, Accuracy: 2909/5000 (58%)\n",
      "[epoch 12] loss: 0.1923158\n",
      "Test set: Average loss: 1.6802, Accuracy: 2921/5000 (58%)\n",
      "[epoch 13] loss: 0.1626385\n",
      "Test set: Average loss: 1.7827, Accuracy: 2848/5000 (57%)\n",
      "[epoch 14] loss: 0.1509970\n",
      "Test set: Average loss: 1.8902, Accuracy: 2840/5000 (57%)\n",
      "[epoch 15] loss: 0.1830643\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8973, Accuracy: 2888/5000 (58%)\n",
      "[epoch 16] loss: 0.0635882\n",
      "Test set: Average loss: 1.7707, Accuracy: 3038/5000 (61%)\n",
      "[epoch 17] loss: 0.0230351\n",
      "Test set: Average loss: 1.7851, Accuracy: 3035/5000 (61%)\n",
      "[epoch 18] loss: 0.0150403\n",
      "Test set: Average loss: 1.7920, Accuracy: 3045/5000 (61%)\n",
      "[epoch 19] loss: 0.0110265\n",
      "Test set: Average loss: 1.8102, Accuracy: 3056/5000 (61%)\n",
      "[epoch 20] loss: 0.0082762\n",
      "Test set: Average loss: 1.8273, Accuracy: 3045/5000 (61%)\n",
      "[epoch 21] loss: 0.0063542\n",
      "Test set: Average loss: 1.8519, Accuracy: 3069/5000 (61%)\n",
      "[epoch 22] loss: 0.0048654\n",
      "Test set: Average loss: 1.8767, Accuracy: 3062/5000 (61%)\n",
      "[epoch 23] loss: 0.0037230\n",
      "Test set: Average loss: 1.9076, Accuracy: 3060/5000 (61%)\n",
      "[epoch 24] loss: 0.0028253\n",
      "Test set: Average loss: 1.9410, Accuracy: 3072/5000 (61%)\n",
      "[epoch 25] loss: 0.0021320\n",
      "Test set: Average loss: 1.9759, Accuracy: 3068/5000 (61%)\n",
      "[epoch 26] loss: 0.0015988\n",
      "Test set: Average loss: 2.0138, Accuracy: 3070/5000 (61%)\n",
      "[epoch 27] loss: 0.0011895\n",
      "Test set: Average loss: 2.0567, Accuracy: 3069/5000 (61%)\n",
      "[epoch 28] loss: 0.0008774\n",
      "Test set: Average loss: 2.0971, Accuracy: 3074/5000 (61%)\n",
      "[epoch 29] loss: 0.0006432\n",
      "Test set: Average loss: 2.1415, Accuracy: 3079/5000 (62%)\n",
      "[epoch 30] loss: 0.0004714\n",
      "Test set: Average loss: 2.1859, Accuracy: 3087/5000 (62%)\n",
      "[epoch 31] loss: 0.0003424\n",
      "Test set: Average loss: 2.2377, Accuracy: 3075/5000 (62%)\n",
      "[epoch 32] loss: 0.0002483\n",
      "Test set: Average loss: 2.2854, Accuracy: 3083/5000 (62%)\n",
      "[epoch 33] loss: 0.0001797\n",
      "Test set: Average loss: 2.3302, Accuracy: 3098/5000 (62%)\n",
      "[epoch 34] loss: 0.0001287\n",
      "Test set: Average loss: 2.3812, Accuracy: 3098/5000 (62%)\n",
      "[epoch 35] loss: 0.0000930\n",
      "Test set: Average loss: 2.4418, Accuracy: 3101/5000 (62%)\n",
      "[epoch 36] loss: 0.0000665\n",
      "Test set: Average loss: 2.4935, Accuracy: 3095/5000 (62%)\n",
      "[epoch 37] loss: 0.0000474\n",
      "Test set: Average loss: 2.5495, Accuracy: 3096/5000 (62%)\n",
      "[epoch 38] loss: 0.0000339\n",
      "Test set: Average loss: 2.6119, Accuracy: 3089/5000 (62%)\n",
      "[epoch 39] loss: 0.0000240\n",
      "Test set: Average loss: 2.6559, Accuracy: 3097/5000 (62%)\n",
      "[epoch 40] loss: 0.0000171\n",
      "Test set: Average loss: 2.7250, Accuracy: 3098/5000 (62%)\n",
      "[epoch 41] loss: 0.0000121\n",
      "Test set: Average loss: 2.7795, Accuracy: 3101/5000 (62%)\n",
      "[epoch 42] loss: 0.0000086\n",
      "Test set: Average loss: 2.8308, Accuracy: 3093/5000 (62%)\n",
      "[epoch 43] loss: 0.0000060\n",
      "Test set: Average loss: 2.8882, Accuracy: 3093/5000 (62%)\n",
      "[epoch 44] loss: 0.0000043\n",
      "Test set: Average loss: 2.9424, Accuracy: 3097/5000 (62%)\n",
      "[epoch 45] loss: 0.0000030\n",
      "Test set: Average loss: 3.0009, Accuracy: 3099/5000 (62%)\n",
      "[epoch 46] loss: 0.0000021\n",
      "Test set: Average loss: 3.0576, Accuracy: 3080/5000 (62%)\n",
      "[epoch 47] loss: 0.0000015\n",
      "Test set: Average loss: 3.1048, Accuracy: 3085/5000 (62%)\n",
      "[epoch 48] loss: 0.0000010\n",
      "Test set: Average loss: 3.1404, Accuracy: 3099/5000 (62%)\n",
      "[epoch 49] loss: 0.0000007\n",
      "Test set: Average loss: 3.1656, Accuracy: 3080/5000 (62%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 3.1935, Accuracy: 3080/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7795, Accuracy: 3101/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.7114, Accuracy: 6206/10000 (62%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3007, Accuracy: 578/5000 (12%)\n",
      "[epoch 1] loss: 1.5527382\n",
      "Test set: Average loss: 1.4712, Accuracy: 2302/5000 (46%)\n",
      "[epoch 2] loss: 1.3249425\n",
      "Test set: Average loss: 1.3422, Accuracy: 2609/5000 (52%)\n",
      "[epoch 3] loss: 1.1902847\n",
      "Test set: Average loss: 1.2953, Accuracy: 2724/5000 (54%)\n",
      "[epoch 4] loss: 1.0652602\n",
      "Test set: Average loss: 1.2191, Accuracy: 2859/5000 (57%)\n",
      "[epoch 5] loss: 0.9466606\n",
      "Test set: Average loss: 1.2231, Accuracy: 2893/5000 (58%)\n",
      "[epoch 6] loss: 0.8258102\n",
      "Test set: Average loss: 1.2587, Accuracy: 2815/5000 (56%)\n",
      "[epoch 7] loss: 0.6884330\n",
      "Test set: Average loss: 1.2351, Accuracy: 2945/5000 (59%)\n",
      "[epoch 8] loss: 0.5685963\n",
      "Test set: Average loss: 1.2860, Accuracy: 2953/5000 (59%)\n",
      "[epoch 9] loss: 0.4339553\n",
      "Test set: Average loss: 1.3410, Accuracy: 2902/5000 (58%)\n",
      "[epoch 10] loss: 0.3180549\n",
      "Test set: Average loss: 1.4526, Accuracy: 2891/5000 (58%)\n",
      "[epoch 11] loss: 0.2437497\n",
      "Test set: Average loss: 1.5877, Accuracy: 2894/5000 (58%)\n",
      "[epoch 12] loss: 0.1995431\n",
      "Test set: Average loss: 1.6859, Accuracy: 2876/5000 (58%)\n",
      "[epoch 13] loss: 0.1693535\n",
      "Test set: Average loss: 1.7812, Accuracy: 2915/5000 (58%)\n",
      "[epoch 14] loss: 0.1626355\n",
      "Test set: Average loss: 1.8095, Accuracy: 2852/5000 (57%)\n",
      "[epoch 15] loss: 0.1429784\n",
      "Test set: Average loss: 1.9431, Accuracy: 2796/5000 (56%)\n",
      "[epoch 16] loss: 0.1659898\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0360, Accuracy: 2823/5000 (56%)\n",
      "[epoch 17] loss: 0.0612484\n",
      "Test set: Average loss: 1.8437, Accuracy: 2979/5000 (60%)\n",
      "[epoch 18] loss: 0.0203457\n",
      "Test set: Average loss: 1.8598, Accuracy: 2989/5000 (60%)\n",
      "[epoch 19] loss: 0.0130477\n",
      "Test set: Average loss: 1.8699, Accuracy: 3011/5000 (60%)\n",
      "[epoch 20] loss: 0.0094998\n",
      "Test set: Average loss: 1.8873, Accuracy: 2997/5000 (60%)\n",
      "[epoch 21] loss: 0.0071782\n",
      "Test set: Average loss: 1.9032, Accuracy: 3020/5000 (60%)\n",
      "[epoch 22] loss: 0.0054938\n",
      "Test set: Average loss: 1.9276, Accuracy: 3005/5000 (60%)\n",
      "[epoch 23] loss: 0.0042038\n",
      "Test set: Average loss: 1.9495, Accuracy: 3009/5000 (60%)\n",
      "[epoch 24] loss: 0.0032348\n",
      "Test set: Average loss: 1.9765, Accuracy: 3019/5000 (60%)\n",
      "[epoch 25] loss: 0.0024509\n",
      "Test set: Average loss: 2.0072, Accuracy: 3023/5000 (60%)\n",
      "[epoch 26] loss: 0.0018549\n",
      "Test set: Average loss: 2.0361, Accuracy: 3024/5000 (60%)\n",
      "[epoch 27] loss: 0.0014014\n",
      "Test set: Average loss: 2.0742, Accuracy: 3019/5000 (60%)\n",
      "[epoch 28] loss: 0.0010459\n",
      "Test set: Average loss: 2.1078, Accuracy: 3017/5000 (60%)\n",
      "[epoch 29] loss: 0.0007738\n",
      "Test set: Average loss: 2.1577, Accuracy: 3014/5000 (60%)\n",
      "[epoch 30] loss: 0.0005724\n",
      "Test set: Average loss: 2.1944, Accuracy: 3030/5000 (61%)\n",
      "[epoch 31] loss: 0.0004216\n",
      "Test set: Average loss: 2.2384, Accuracy: 3029/5000 (61%)\n",
      "[epoch 32] loss: 0.0003068\n",
      "Test set: Average loss: 2.2864, Accuracy: 3037/5000 (61%)\n",
      "[epoch 33] loss: 0.0002236\n",
      "Test set: Average loss: 2.3389, Accuracy: 3041/5000 (61%)\n",
      "[epoch 34] loss: 0.0001622\n",
      "Test set: Average loss: 2.3873, Accuracy: 3045/5000 (61%)\n",
      "[epoch 35] loss: 0.0001162\n",
      "Test set: Average loss: 2.4292, Accuracy: 3035/5000 (61%)\n",
      "[epoch 36] loss: 0.0000837\n",
      "Test set: Average loss: 2.4920, Accuracy: 3034/5000 (61%)\n",
      "[epoch 37] loss: 0.0000601\n",
      "Test set: Average loss: 2.5355, Accuracy: 3037/5000 (61%)\n",
      "[epoch 38] loss: 0.0000428\n",
      "Test set: Average loss: 2.5863, Accuracy: 3050/5000 (61%)\n",
      "[epoch 39] loss: 0.0000307\n",
      "Test set: Average loss: 2.6515, Accuracy: 3043/5000 (61%)\n",
      "[epoch 40] loss: 0.0000220\n",
      "Test set: Average loss: 2.7046, Accuracy: 3044/5000 (61%)\n",
      "[epoch 41] loss: 0.0000156\n",
      "Test set: Average loss: 2.7586, Accuracy: 3045/5000 (61%)\n",
      "[epoch 42] loss: 0.0000110\n",
      "Test set: Average loss: 2.8150, Accuracy: 3043/5000 (61%)\n",
      "[epoch 43] loss: 0.0000078\n",
      "Test set: Average loss: 2.8724, Accuracy: 3039/5000 (61%)\n",
      "[epoch 44] loss: 0.0000056\n",
      "Test set: Average loss: 2.9250, Accuracy: 3042/5000 (61%)\n",
      "[epoch 45] loss: 0.0000039\n",
      "Test set: Average loss: 2.9787, Accuracy: 3050/5000 (61%)\n",
      "[epoch 46] loss: 0.0000027\n",
      "Test set: Average loss: 3.0285, Accuracy: 3045/5000 (61%)\n",
      "[epoch 47] loss: 0.0000019\n",
      "Test set: Average loss: 3.0833, Accuracy: 3036/5000 (61%)\n",
      "[epoch 48] loss: 0.0000013\n",
      "Test set: Average loss: 3.1263, Accuracy: 3035/5000 (61%)\n",
      "[epoch 49] loss: 0.0000009\n",
      "Test set: Average loss: 3.1656, Accuracy: 3039/5000 (61%)\n",
      "[epoch 50] loss: 0.0000006\n",
      "Test set: Average loss: 3.1908, Accuracy: 3030/5000 (61%)\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.9787, Accuracy: 3050/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.8915, Accuracy: 6129/10000 (61%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3002, Accuracy: 504/5000 (10%)\n",
      "[epoch 1] loss: 1.5499709\n",
      "Test set: Average loss: 1.3685, Accuracy: 2533/5000 (51%)\n",
      "[epoch 2] loss: 1.3001422\n",
      "Test set: Average loss: 1.2977, Accuracy: 2687/5000 (54%)\n",
      "[epoch 3] loss: 1.1788254\n",
      "Test set: Average loss: 1.2613, Accuracy: 2807/5000 (56%)\n",
      "[epoch 4] loss: 1.0703500\n",
      "Test set: Average loss: 1.2473, Accuracy: 2782/5000 (56%)\n",
      "[epoch 5] loss: 0.9754728\n",
      "Test set: Average loss: 1.2006, Accuracy: 2884/5000 (58%)\n",
      "[epoch 6] loss: 0.8680903\n",
      "Test set: Average loss: 1.2128, Accuracy: 2908/5000 (58%)\n",
      "[epoch 7] loss: 0.7598117\n",
      "Test set: Average loss: 1.2194, Accuracy: 2968/5000 (59%)\n",
      "[epoch 8] loss: 0.6403886\n",
      "Test set: Average loss: 1.2515, Accuracy: 2984/5000 (60%)\n",
      "[epoch 9] loss: 0.5270382\n",
      "Test set: Average loss: 1.3691, Accuracy: 2928/5000 (59%)\n",
      "[epoch 10] loss: 0.4172624\n",
      "Test set: Average loss: 1.3887, Accuracy: 2952/5000 (59%)\n",
      "[epoch 11] loss: 0.3216255\n",
      "Test set: Average loss: 1.4652, Accuracy: 2953/5000 (59%)\n",
      "[epoch 12] loss: 0.2717947\n",
      "Test set: Average loss: 1.5848, Accuracy: 2875/5000 (58%)\n",
      "[epoch 13] loss: 0.2230764\n",
      "Test set: Average loss: 1.6754, Accuracy: 2906/5000 (58%)\n",
      "[epoch 14] loss: 0.1982619\n",
      "Test set: Average loss: 1.7425, Accuracy: 2946/5000 (59%)\n",
      "[epoch 15] loss: 0.1811059\n",
      "Test set: Average loss: 1.8161, Accuracy: 2897/5000 (58%)\n",
      "[epoch 16] loss: 0.1865821\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9195, Accuracy: 2819/5000 (56%)\n",
      "[epoch 17] loss: 0.0779155\n",
      "Test set: Average loss: 1.7848, Accuracy: 2980/5000 (60%)\n",
      "[epoch 18] loss: 0.0280863\n",
      "Test set: Average loss: 1.7939, Accuracy: 2991/5000 (60%)\n",
      "[epoch 19] loss: 0.0177211\n",
      "Test set: Average loss: 1.8128, Accuracy: 2995/5000 (60%)\n",
      "[epoch 20] loss: 0.0125095\n",
      "Test set: Average loss: 1.8292, Accuracy: 3007/5000 (60%)\n",
      "[epoch 21] loss: 0.0091493\n",
      "Test set: Average loss: 1.8520, Accuracy: 3006/5000 (60%)\n",
      "[epoch 22] loss: 0.0067902\n",
      "Test set: Average loss: 1.8838, Accuracy: 3015/5000 (60%)\n",
      "[epoch 23] loss: 0.0050044\n",
      "Test set: Average loss: 1.9164, Accuracy: 3032/5000 (61%)\n",
      "[epoch 24] loss: 0.0036868\n",
      "Test set: Average loss: 1.9513, Accuracy: 3020/5000 (60%)\n",
      "[epoch 25] loss: 0.0026974\n",
      "Test set: Average loss: 1.9926, Accuracy: 3008/5000 (60%)\n",
      "[epoch 26] loss: 0.0019994\n",
      "Test set: Average loss: 2.0336, Accuracy: 3033/5000 (61%)\n",
      "[epoch 27] loss: 0.0014312\n",
      "Test set: Average loss: 2.0671, Accuracy: 3036/5000 (61%)\n",
      "[epoch 28] loss: 0.0010284\n",
      "Test set: Average loss: 2.1177, Accuracy: 3040/5000 (61%)\n",
      "[epoch 29] loss: 0.0007302\n",
      "Test set: Average loss: 2.1726, Accuracy: 3040/5000 (61%)\n",
      "[epoch 30] loss: 0.0005236\n",
      "Test set: Average loss: 2.2215, Accuracy: 3047/5000 (61%)\n",
      "[epoch 31] loss: 0.0003692\n",
      "Test set: Average loss: 2.2811, Accuracy: 3040/5000 (61%)\n",
      "[epoch 32] loss: 0.0002597\n",
      "Test set: Average loss: 2.3290, Accuracy: 3062/5000 (61%)\n",
      "[epoch 33] loss: 0.0001830\n",
      "Test set: Average loss: 2.3933, Accuracy: 3040/5000 (61%)\n",
      "[epoch 34] loss: 0.0010108\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4204, Accuracy: 3025/5000 (60%)\n",
      "[epoch 35] loss: 0.0002156\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.4242, Accuracy: 3020/5000 (60%)\n",
      "[epoch 36] loss: 0.0001870\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3022/5000 (60%)\n",
      "[epoch 37] loss: 0.0001854\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 38] loss: 0.0001851\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 39] loss: 0.0001851\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 40] loss: 0.0001851\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 41] loss: 0.0001850\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 42] loss: 0.0001850\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 43] loss: 0.0001851\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 44] loss: 0.0001850\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 45] loss: 0.0001850\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 46] loss: 0.0001851\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 47] loss: 0.0001851\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 48] loss: 0.0001850\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 49] loss: 0.0001851\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "[epoch 50] loss: 0.0001851\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.4247, Accuracy: 3021/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3290, Accuracy: 3062/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.3577, Accuracy: 6095/10000 (61%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 532/5000 (11%)\n",
      "[epoch 1] loss: 1.5760617\n",
      "Test set: Average loss: 1.4110, Accuracy: 2405/5000 (48%)\n",
      "[epoch 2] loss: 1.3373740\n",
      "Test set: Average loss: 1.3213, Accuracy: 2645/5000 (53%)\n",
      "[epoch 3] loss: 1.2187513\n",
      "Test set: Average loss: 1.2579, Accuracy: 2738/5000 (55%)\n",
      "[epoch 4] loss: 1.1147040\n",
      "Test set: Average loss: 1.2604, Accuracy: 2742/5000 (55%)\n",
      "[epoch 5] loss: 1.0142476\n",
      "Test set: Average loss: 1.2318, Accuracy: 2812/5000 (56%)\n",
      "[epoch 6] loss: 0.9168860\n",
      "Test set: Average loss: 1.2197, Accuracy: 2870/5000 (57%)\n",
      "[epoch 7] loss: 0.8059029\n",
      "Test set: Average loss: 1.2927, Accuracy: 2807/5000 (56%)\n",
      "[epoch 8] loss: 0.7040246\n",
      "Test set: Average loss: 1.2939, Accuracy: 2868/5000 (57%)\n",
      "[epoch 9] loss: 0.5800764\n",
      "Test set: Average loss: 1.3527, Accuracy: 2907/5000 (58%)\n",
      "[epoch 10] loss: 0.4801554\n",
      "Test set: Average loss: 1.4339, Accuracy: 2838/5000 (57%)\n",
      "[epoch 11] loss: 0.3957189\n",
      "Test set: Average loss: 1.5218, Accuracy: 2791/5000 (56%)\n",
      "[epoch 12] loss: 0.3025587\n",
      "Test set: Average loss: 1.5738, Accuracy: 2853/5000 (57%)\n",
      "[epoch 13] loss: 0.2448565\n",
      "Test set: Average loss: 1.6929, Accuracy: 2799/5000 (56%)\n",
      "[epoch 14] loss: 0.2152751\n",
      "Test set: Average loss: 1.7870, Accuracy: 2775/5000 (56%)\n",
      "[epoch 15] loss: 0.2101851\n",
      "Test set: Average loss: 1.8503, Accuracy: 2780/5000 (56%)\n",
      "[epoch 16] loss: 0.2004992\n",
      "Test set: Average loss: 1.9303, Accuracy: 2782/5000 (56%)\n",
      "[epoch 17] loss: 0.1775415\n",
      "Test set: Average loss: 1.9311, Accuracy: 2780/5000 (56%)\n",
      "[epoch 18] loss: 0.1727239\n",
      "Test set: Average loss: 2.1243, Accuracy: 2732/5000 (55%)\n",
      "[epoch 19] loss: 0.1722078\n",
      "Test set: Average loss: 2.1860, Accuracy: 2742/5000 (55%)\n",
      "[epoch 20] loss: 0.1639975\n",
      "Test set: Average loss: 2.1701, Accuracy: 2739/5000 (55%)\n",
      "[epoch 21] loss: 0.1536573\n",
      "Test set: Average loss: 2.1910, Accuracy: 2765/5000 (55%)\n",
      "[epoch 22] loss: 0.1669896\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2655, Accuracy: 2722/5000 (54%)\n",
      "[epoch 23] loss: 0.0784572\n",
      "Test set: Average loss: 2.1775, Accuracy: 2813/5000 (56%)\n",
      "[epoch 24] loss: 0.0228960\n",
      "Test set: Average loss: 2.1736, Accuracy: 2832/5000 (57%)\n",
      "[epoch 25] loss: 0.0134713\n",
      "Test set: Average loss: 2.1831, Accuracy: 2844/5000 (57%)\n",
      "[epoch 26] loss: 0.0094495\n",
      "Test set: Average loss: 2.1889, Accuracy: 2858/5000 (57%)\n",
      "[epoch 27] loss: 0.0069023\n",
      "Test set: Average loss: 2.2066, Accuracy: 2873/5000 (57%)\n",
      "[epoch 28] loss: 0.0051534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.2189, Accuracy: 2891/5000 (58%)\n",
      "[epoch 29] loss: 0.0038022\n",
      "Test set: Average loss: 2.2418, Accuracy: 2896/5000 (58%)\n",
      "[epoch 30] loss: 0.0028266\n",
      "Test set: Average loss: 2.2666, Accuracy: 2897/5000 (58%)\n",
      "[epoch 31] loss: 0.0021062\n",
      "Test set: Average loss: 2.3008, Accuracy: 2908/5000 (58%)\n",
      "[epoch 32] loss: 0.0015368\n",
      "Test set: Average loss: 2.3296, Accuracy: 2901/5000 (58%)\n",
      "[epoch 33] loss: 0.0011265\n",
      "Test set: Average loss: 2.3587, Accuracy: 2906/5000 (58%)\n",
      "[epoch 34] loss: 0.0008236\n",
      "Test set: Average loss: 2.4025, Accuracy: 2910/5000 (58%)\n",
      "[epoch 35] loss: 0.0005928\n",
      "Test set: Average loss: 2.4428, Accuracy: 2904/5000 (58%)\n",
      "[epoch 36] loss: 0.0004293\n",
      "Test set: Average loss: 2.4952, Accuracy: 2898/5000 (58%)\n",
      "[epoch 37] loss: 0.0003073\n",
      "Test set: Average loss: 2.5385, Accuracy: 2911/5000 (58%)\n",
      "[epoch 38] loss: 0.0002206\n",
      "Test set: Average loss: 2.5874, Accuracy: 2902/5000 (58%)\n",
      "[epoch 39] loss: 0.0001581\n",
      "Test set: Average loss: 2.6424, Accuracy: 2909/5000 (58%)\n",
      "[epoch 40] loss: 0.0001127\n",
      "Test set: Average loss: 2.6913, Accuracy: 2913/5000 (58%)\n",
      "[epoch 41] loss: 0.0000798\n",
      "Test set: Average loss: 2.7465, Accuracy: 2889/5000 (58%)\n",
      "[epoch 42] loss: 0.0000565\n",
      "Test set: Average loss: 2.7978, Accuracy: 2899/5000 (58%)\n",
      "[epoch 43] loss: 0.0000401\n",
      "Test set: Average loss: 2.8634, Accuracy: 2895/5000 (58%)\n",
      "[epoch 44] loss: 0.0000283\n",
      "Test set: Average loss: 2.9264, Accuracy: 2901/5000 (58%)\n",
      "[epoch 45] loss: 0.0000198\n",
      "Test set: Average loss: 2.9776, Accuracy: 2902/5000 (58%)\n",
      "[epoch 46] loss: 0.0000140\n",
      "Test set: Average loss: 3.0302, Accuracy: 2898/5000 (58%)\n",
      "[epoch 47] loss: 0.0000098\n",
      "Test set: Average loss: 3.0989, Accuracy: 2888/5000 (58%)\n",
      "[epoch 48] loss: 0.0000069\n",
      "Test set: Average loss: 3.1546, Accuracy: 2898/5000 (58%)\n",
      "[epoch 49] loss: 0.0000048\n",
      "Test set: Average loss: 3.2159, Accuracy: 2892/5000 (58%)\n",
      "[epoch 50] loss: 0.0000033\n",
      "Test set: Average loss: 3.2825, Accuracy: 2892/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6913, Accuracy: 2913/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 2.6535, Accuracy: 5887/10000 (59%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2984, Accuracy: 586/5000 (12%)\n",
      "[epoch 1] loss: 1.5739076\n",
      "Test set: Average loss: 1.5426, Accuracy: 2258/5000 (45%)\n",
      "[epoch 2] loss: 1.3300479\n",
      "Test set: Average loss: 1.2920, Accuracy: 2660/5000 (53%)\n",
      "[epoch 3] loss: 1.1878620\n",
      "Test set: Average loss: 1.2240, Accuracy: 2828/5000 (57%)\n",
      "[epoch 4] loss: 1.0602673\n",
      "Test set: Average loss: 1.2732, Accuracy: 2758/5000 (55%)\n",
      "[epoch 5] loss: 0.9567017\n",
      "Test set: Average loss: 1.1480, Accuracy: 2958/5000 (59%)\n",
      "[epoch 6] loss: 0.8422381\n",
      "Test set: Average loss: 1.1920, Accuracy: 2994/5000 (60%)\n",
      "[epoch 7] loss: 0.7325872\n",
      "Test set: Average loss: 1.2183, Accuracy: 2971/5000 (59%)\n",
      "[epoch 8] loss: 0.6135715\n",
      "Test set: Average loss: 1.2533, Accuracy: 2949/5000 (59%)\n",
      "[epoch 9] loss: 0.4946639\n",
      "Test set: Average loss: 1.3069, Accuracy: 2970/5000 (59%)\n",
      "[epoch 10] loss: 0.3825844\n",
      "Test set: Average loss: 1.4565, Accuracy: 2872/5000 (57%)\n",
      "[epoch 11] loss: 0.2836677\n",
      "Test set: Average loss: 1.4871, Accuracy: 2929/5000 (59%)\n",
      "[epoch 12] loss: 0.2260520\n",
      "Test set: Average loss: 1.5909, Accuracy: 2944/5000 (59%)\n",
      "[epoch 13] loss: 0.1968651\n",
      "Test set: Average loss: 1.7382, Accuracy: 2875/5000 (58%)\n",
      "[epoch 14] loss: 0.1701579\n",
      "Test set: Average loss: 1.7881, Accuracy: 2893/5000 (58%)\n",
      "[epoch 15] loss: 0.1791611\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7916, Accuracy: 2912/5000 (58%)\n",
      "[epoch 16] loss: 0.0700439\n",
      "Test set: Average loss: 1.7024, Accuracy: 3009/5000 (60%)\n",
      "[epoch 17] loss: 0.0273029\n",
      "Test set: Average loss: 1.7020, Accuracy: 3013/5000 (60%)\n",
      "[epoch 18] loss: 0.0176394\n",
      "Test set: Average loss: 1.7142, Accuracy: 3012/5000 (60%)\n",
      "[epoch 19] loss: 0.0127352\n",
      "Test set: Average loss: 1.7286, Accuracy: 3015/5000 (60%)\n",
      "[epoch 20] loss: 0.0095317\n",
      "Test set: Average loss: 1.7556, Accuracy: 3018/5000 (60%)\n",
      "[epoch 21] loss: 0.0071438\n",
      "Test set: Average loss: 1.7788, Accuracy: 3035/5000 (61%)\n",
      "[epoch 22] loss: 0.0053519\n",
      "Test set: Average loss: 1.8063, Accuracy: 3039/5000 (61%)\n",
      "[epoch 23] loss: 0.0039826\n",
      "Test set: Average loss: 1.8380, Accuracy: 3037/5000 (61%)\n",
      "[epoch 24] loss: 0.0029484\n",
      "Test set: Average loss: 1.8767, Accuracy: 3035/5000 (61%)\n",
      "[epoch 25] loss: 0.0021838\n",
      "Test set: Average loss: 1.9082, Accuracy: 3032/5000 (61%)\n",
      "[epoch 26] loss: 0.0015928\n",
      "Test set: Average loss: 1.9550, Accuracy: 3056/5000 (61%)\n",
      "[epoch 27] loss: 0.0011661\n",
      "Test set: Average loss: 1.9956, Accuracy: 3051/5000 (61%)\n",
      "[epoch 28] loss: 0.0008449\n",
      "Test set: Average loss: 2.0408, Accuracy: 3038/5000 (61%)\n",
      "[epoch 29] loss: 0.0006078\n",
      "Test set: Average loss: 2.0844, Accuracy: 3040/5000 (61%)\n",
      "[epoch 30] loss: 0.0004398\n",
      "Test set: Average loss: 2.1366, Accuracy: 3039/5000 (61%)\n",
      "[epoch 31] loss: 0.0003130\n",
      "Test set: Average loss: 2.1813, Accuracy: 3029/5000 (61%)\n",
      "[epoch 32] loss: 0.0002246\n",
      "Test set: Average loss: 2.2709, Accuracy: 3049/5000 (61%)\n",
      "[epoch 33] loss: 0.0001589\n",
      "Test set: Average loss: 2.2843, Accuracy: 3055/5000 (61%)\n",
      "[epoch 34] loss: 0.0001131\n",
      "Test set: Average loss: 2.3495, Accuracy: 3051/5000 (61%)\n",
      "[epoch 35] loss: 0.0000796\n",
      "Test set: Average loss: 2.4017, Accuracy: 3047/5000 (61%)\n",
      "[epoch 36] loss: 0.0000565\n",
      "Test set: Average loss: 2.4476, Accuracy: 3057/5000 (61%)\n",
      "[epoch 37] loss: 0.0000396\n",
      "Test set: Average loss: 2.5113, Accuracy: 3046/5000 (61%)\n",
      "[epoch 38] loss: 0.0000278\n",
      "Test set: Average loss: 2.5695, Accuracy: 3056/5000 (61%)\n",
      "[epoch 39] loss: 0.0000194\n",
      "Test set: Average loss: 2.6235, Accuracy: 3046/5000 (61%)\n",
      "[epoch 40] loss: 0.0000136\n",
      "Test set: Average loss: 2.6826, Accuracy: 3064/5000 (61%)\n",
      "[epoch 41] loss: 0.0000094\n",
      "Test set: Average loss: 2.7400, Accuracy: 3054/5000 (61%)\n",
      "[epoch 42] loss: 0.0000066\n",
      "Test set: Average loss: 2.8048, Accuracy: 3060/5000 (61%)\n",
      "[epoch 43] loss: 0.0000045\n",
      "Test set: Average loss: 2.8490, Accuracy: 3074/5000 (61%)\n",
      "[epoch 44] loss: 0.0000031\n",
      "Test set: Average loss: 2.9124, Accuracy: 3064/5000 (61%)\n",
      "[epoch 45] loss: 0.0000021\n",
      "Test set: Average loss: 2.9649, Accuracy: 3065/5000 (61%)\n",
      "[epoch 46] loss: 0.0000015\n",
      "Test set: Average loss: 3.0234, Accuracy: 3060/5000 (61%)\n",
      "[epoch 47] loss: 0.0000010\n",
      "Test set: Average loss: 3.0636, Accuracy: 3056/5000 (61%)\n",
      "[epoch 48] loss: 0.0000007\n",
      "Test set: Average loss: 3.0871, Accuracy: 3062/5000 (61%)\n",
      "[epoch 49] loss: 0.0000005\n",
      "Test set: Average loss: 3.1045, Accuracy: 3040/5000 (61%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.1139, Accuracy: 3052/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8490, Accuracy: 3074/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.8552, Accuracy: 6205/10000 (62%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3095, Accuracy: 399/5000 (8%)\n",
      "[epoch 1] loss: 1.5607000\n",
      "Test set: Average loss: 1.4221, Accuracy: 2454/5000 (49%)\n",
      "[epoch 2] loss: 1.3164812\n",
      "Test set: Average loss: 1.2847, Accuracy: 2721/5000 (54%)\n",
      "[epoch 3] loss: 1.1671753\n",
      "Test set: Average loss: 1.2569, Accuracy: 2803/5000 (56%)\n",
      "[epoch 4] loss: 1.0447195\n",
      "Test set: Average loss: 1.1807, Accuracy: 2898/5000 (58%)\n",
      "[epoch 5] loss: 0.9322548\n",
      "Test set: Average loss: 1.1467, Accuracy: 3025/5000 (60%)\n",
      "[epoch 6] loss: 0.8168380\n",
      "Test set: Average loss: 1.1793, Accuracy: 3003/5000 (60%)\n",
      "[epoch 7] loss: 0.6876304\n",
      "Test set: Average loss: 1.2626, Accuracy: 2938/5000 (59%)\n",
      "[epoch 8] loss: 0.5594257\n",
      "Test set: Average loss: 1.2838, Accuracy: 2980/5000 (60%)\n",
      "[epoch 9] loss: 0.4465593\n",
      "Test set: Average loss: 1.3429, Accuracy: 3004/5000 (60%)\n",
      "[epoch 10] loss: 0.3355617\n",
      "Test set: Average loss: 1.4305, Accuracy: 3016/5000 (60%)\n",
      "[epoch 11] loss: 0.2490804\n",
      "Test set: Average loss: 1.5764, Accuracy: 2914/5000 (58%)\n",
      "[epoch 12] loss: 0.2096932\n",
      "Test set: Average loss: 1.7069, Accuracy: 2908/5000 (58%)\n",
      "[epoch 13] loss: 0.1761218\n",
      "Test set: Average loss: 1.7575, Accuracy: 2933/5000 (59%)\n",
      "[epoch 14] loss: 0.1784861\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7840, Accuracy: 2933/5000 (59%)\n",
      "[epoch 15] loss: 0.0667421\n",
      "Test set: Average loss: 1.7086, Accuracy: 3057/5000 (61%)\n",
      "[epoch 16] loss: 0.0254247\n",
      "Test set: Average loss: 1.7231, Accuracy: 3056/5000 (61%)\n",
      "[epoch 17] loss: 0.0158771\n",
      "Test set: Average loss: 1.7438, Accuracy: 3079/5000 (62%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0109755\n",
      "Test set: Average loss: 1.7660, Accuracy: 3072/5000 (61%)\n",
      "[epoch 19] loss: 0.0078338\n",
      "Test set: Average loss: 1.7937, Accuracy: 3080/5000 (62%)\n",
      "[epoch 20] loss: 0.0055322\n",
      "Test set: Average loss: 1.8331, Accuracy: 3080/5000 (62%)\n",
      "[epoch 21] loss: 0.0038982\n",
      "Test set: Average loss: 1.8716, Accuracy: 3085/5000 (62%)\n",
      "[epoch 22] loss: 0.0027141\n",
      "Test set: Average loss: 1.9210, Accuracy: 3082/5000 (62%)\n",
      "[epoch 23] loss: 0.0018758\n",
      "Test set: Average loss: 1.9637, Accuracy: 3078/5000 (62%)\n",
      "[epoch 24] loss: 0.0012852\n",
      "Test set: Average loss: 2.0114, Accuracy: 3084/5000 (62%)\n",
      "[epoch 25] loss: 0.0008738\n",
      "Test set: Average loss: 2.0730, Accuracy: 3094/5000 (62%)\n",
      "[epoch 26] loss: 0.0005906\n",
      "Test set: Average loss: 2.1228, Accuracy: 3102/5000 (62%)\n",
      "[epoch 27] loss: 0.0004000\n",
      "Test set: Average loss: 2.1871, Accuracy: 3093/5000 (62%)\n",
      "[epoch 28] loss: 0.0002718\n",
      "Test set: Average loss: 2.2484, Accuracy: 3101/5000 (62%)\n",
      "[epoch 29] loss: 0.0001788\n",
      "Test set: Average loss: 2.3216, Accuracy: 3099/5000 (62%)\n",
      "[epoch 30] loss: 0.0001193\n",
      "Test set: Average loss: 2.3741, Accuracy: 3090/5000 (62%)\n",
      "[epoch 31] loss: 0.0000793\n",
      "Test set: Average loss: 2.4461, Accuracy: 3095/5000 (62%)\n",
      "[epoch 32] loss: 0.0000521\n",
      "Test set: Average loss: 2.5103, Accuracy: 3092/5000 (62%)\n",
      "[epoch 33] loss: 0.0000342\n",
      "Test set: Average loss: 2.5816, Accuracy: 3085/5000 (62%)\n",
      "[epoch 34] loss: 0.0000224\n",
      "Test set: Average loss: 2.6525, Accuracy: 3094/5000 (62%)\n",
      "[epoch 35] loss: 0.0000144\n",
      "Test set: Average loss: 2.7287, Accuracy: 3094/5000 (62%)\n",
      "[epoch 36] loss: 0.0000094\n",
      "Test set: Average loss: 2.7968, Accuracy: 3075/5000 (62%)\n",
      "[epoch 37] loss: 0.0000060\n",
      "Test set: Average loss: 2.8633, Accuracy: 3091/5000 (62%)\n",
      "[epoch 38] loss: 0.0000039\n",
      "Test set: Average loss: 2.9354, Accuracy: 3093/5000 (62%)\n",
      "[epoch 39] loss: 0.0000025\n",
      "Test set: Average loss: 3.0053, Accuracy: 3087/5000 (62%)\n",
      "[epoch 40] loss: 0.0000016\n",
      "Test set: Average loss: 3.0629, Accuracy: 3084/5000 (62%)\n",
      "[epoch 41] loss: 0.0000010\n",
      "Test set: Average loss: 3.1194, Accuracy: 3081/5000 (62%)\n",
      "[epoch 42] loss: 0.0000006\n",
      "Test set: Average loss: 3.1508, Accuracy: 3068/5000 (61%)\n",
      "[epoch 43] loss: 0.0000004\n",
      "Test set: Average loss: 3.1684, Accuracy: 3068/5000 (61%)\n",
      "[epoch 44] loss: 0.0000003\n",
      "Test set: Average loss: 3.1829, Accuracy: 3067/5000 (61%)\n",
      "[epoch 45] loss: 0.0000003\n",
      "Test set: Average loss: 3.1821, Accuracy: 3065/5000 (61%)\n",
      "[epoch 46] loss: 0.0000002\n",
      "Test set: Average loss: 3.2013, Accuracy: 3067/5000 (61%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 3.2062, Accuracy: 3056/5000 (61%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.2230, Accuracy: 3051/5000 (61%)\n",
      "[epoch 49] loss: 0.0000001\n",
      "Test set: Average loss: 3.2453, Accuracy: 3063/5000 (61%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.2549, Accuracy: 3059/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1228, Accuracy: 3102/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.1280, Accuracy: 6203/10000 (62%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2968, Accuracy: 607/5000 (12%)\n",
      "[epoch 1] loss: 1.4933661\n",
      "Test set: Average loss: 1.3157, Accuracy: 2643/5000 (53%)\n",
      "[epoch 2] loss: 1.2303908\n",
      "Test set: Average loss: 1.2763, Accuracy: 2722/5000 (54%)\n",
      "[epoch 3] loss: 1.0998482\n",
      "Test set: Average loss: 1.1985, Accuracy: 2886/5000 (58%)\n",
      "[epoch 4] loss: 0.9976310\n",
      "Test set: Average loss: 1.1309, Accuracy: 2992/5000 (60%)\n",
      "[epoch 5] loss: 0.8916015\n",
      "Test set: Average loss: 1.1425, Accuracy: 3070/5000 (61%)\n",
      "[epoch 6] loss: 0.8079335\n",
      "Test set: Average loss: 1.1559, Accuracy: 3045/5000 (61%)\n",
      "[epoch 7] loss: 0.7032840\n",
      "Test set: Average loss: 1.1734, Accuracy: 3077/5000 (62%)\n",
      "[epoch 8] loss: 0.6172227\n",
      "Test set: Average loss: 1.2102, Accuracy: 3056/5000 (61%)\n",
      "[epoch 9] loss: 0.5174420\n",
      "Test set: Average loss: 1.3013, Accuracy: 3014/5000 (60%)\n",
      "[epoch 10] loss: 0.4371765\n",
      "Test set: Average loss: 1.3298, Accuracy: 3068/5000 (61%)\n",
      "[epoch 11] loss: 0.3665872\n",
      "Test set: Average loss: 1.4590, Accuracy: 2989/5000 (60%)\n",
      "[epoch 12] loss: 0.3254291\n",
      "Test set: Average loss: 1.4709, Accuracy: 3070/5000 (61%)\n",
      "[epoch 13] loss: 0.2705867\n",
      "Test set: Average loss: 1.5959, Accuracy: 3035/5000 (61%)\n",
      "[epoch 14] loss: 0.2570887\n",
      "Test set: Average loss: 1.6716, Accuracy: 2956/5000 (59%)\n",
      "[epoch 15] loss: 0.2445990\n",
      "Test set: Average loss: 1.7055, Accuracy: 2954/5000 (59%)\n",
      "[epoch 16] loss: 0.2161732\n",
      "Test set: Average loss: 1.7758, Accuracy: 3004/5000 (60%)\n",
      "[epoch 17] loss: 0.2034717\n",
      "Test set: Average loss: 1.8249, Accuracy: 2971/5000 (59%)\n",
      "[epoch 18] loss: 0.2074079\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9069, Accuracy: 2980/5000 (60%)\n",
      "[epoch 19] loss: 0.0880626\n",
      "Test set: Average loss: 1.7826, Accuracy: 3084/5000 (62%)\n",
      "[epoch 20] loss: 0.0319511\n",
      "Test set: Average loss: 1.7862, Accuracy: 3091/5000 (62%)\n",
      "[epoch 21] loss: 0.0187554\n",
      "Test set: Average loss: 1.8082, Accuracy: 3090/5000 (62%)\n",
      "[epoch 22] loss: 0.0126579\n",
      "Test set: Average loss: 1.8394, Accuracy: 3099/5000 (62%)\n",
      "[epoch 23] loss: 0.0087768\n",
      "Test set: Average loss: 1.8619, Accuracy: 3105/5000 (62%)\n",
      "[epoch 24] loss: 0.0061495\n",
      "Test set: Average loss: 1.9003, Accuracy: 3122/5000 (62%)\n",
      "[epoch 25] loss: 0.0043414\n",
      "Test set: Average loss: 1.9258, Accuracy: 3118/5000 (62%)\n",
      "[epoch 26] loss: 0.0030237\n",
      "Test set: Average loss: 1.9826, Accuracy: 3130/5000 (63%)\n",
      "[epoch 27] loss: 0.0020917\n",
      "Test set: Average loss: 2.0142, Accuracy: 3136/5000 (63%)\n",
      "[epoch 28] loss: 0.0014375\n",
      "Test set: Average loss: 2.0673, Accuracy: 3132/5000 (63%)\n",
      "[epoch 29] loss: 0.0010077\n",
      "Test set: Average loss: 2.1248, Accuracy: 3128/5000 (63%)\n",
      "[epoch 30] loss: 0.0006682\n",
      "Test set: Average loss: 2.1603, Accuracy: 3125/5000 (62%)\n",
      "[epoch 31] loss: 0.0004497\n",
      "Test set: Average loss: 2.2145, Accuracy: 3140/5000 (63%)\n",
      "[epoch 32] loss: 0.0003051\n",
      "Test set: Average loss: 2.2818, Accuracy: 3132/5000 (63%)\n",
      "[epoch 33] loss: 0.0002031\n",
      "Test set: Average loss: 2.3272, Accuracy: 3138/5000 (63%)\n",
      "[epoch 34] loss: 0.0001349\n",
      "Test set: Average loss: 2.4000, Accuracy: 3137/5000 (63%)\n",
      "[epoch 35] loss: 0.0000890\n",
      "Test set: Average loss: 2.4631, Accuracy: 3152/5000 (63%)\n",
      "[epoch 36] loss: 0.0000584\n",
      "Test set: Average loss: 2.5287, Accuracy: 3136/5000 (63%)\n",
      "[epoch 37] loss: 0.0000383\n",
      "Test set: Average loss: 2.6020, Accuracy: 3134/5000 (63%)\n",
      "[epoch 38] loss: 0.0000249\n",
      "Test set: Average loss: 2.6750, Accuracy: 3126/5000 (63%)\n",
      "[epoch 39] loss: 0.0000162\n",
      "Test set: Average loss: 2.7365, Accuracy: 3134/5000 (63%)\n",
      "[epoch 40] loss: 0.0000105\n",
      "Test set: Average loss: 2.8165, Accuracy: 3128/5000 (63%)\n",
      "[epoch 41] loss: 0.0000068\n",
      "Test set: Average loss: 2.8747, Accuracy: 3138/5000 (63%)\n",
      "[epoch 42] loss: 0.0000043\n",
      "Test set: Average loss: 2.9506, Accuracy: 3128/5000 (63%)\n",
      "[epoch 43] loss: 0.0000028\n",
      "Test set: Average loss: 3.0161, Accuracy: 3138/5000 (63%)\n",
      "[epoch 44] loss: 0.0000018\n",
      "Test set: Average loss: 3.0898, Accuracy: 3138/5000 (63%)\n",
      "[epoch 45] loss: 0.0000011\n",
      "Test set: Average loss: 3.1445, Accuracy: 3125/5000 (62%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Test set: Average loss: 3.1891, Accuracy: 3132/5000 (63%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 3.2114, Accuracy: 3116/5000 (62%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.2266, Accuracy: 3127/5000 (63%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.2505, Accuracy: 3125/5000 (62%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.2595, Accuracy: 3108/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4631, Accuracy: 3152/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.4189, Accuracy: 6358/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2976, Accuracy: 555/5000 (11%)\n",
      "[epoch 1] loss: 1.5554787\n",
      "Test set: Average loss: 1.4257, Accuracy: 2429/5000 (49%)\n",
      "[epoch 2] loss: 1.3172917\n",
      "Test set: Average loss: 1.3135, Accuracy: 2657/5000 (53%)\n",
      "[epoch 3] loss: 1.1924044\n",
      "Test set: Average loss: 1.2207, Accuracy: 2822/5000 (56%)\n",
      "[epoch 4] loss: 1.0838035\n",
      "Test set: Average loss: 1.2090, Accuracy: 2812/5000 (56%)\n",
      "[epoch 5] loss: 0.9905750\n",
      "Test set: Average loss: 1.2114, Accuracy: 2886/5000 (58%)\n",
      "[epoch 6] loss: 0.8911653\n",
      "Test set: Average loss: 1.1863, Accuracy: 2964/5000 (59%)\n",
      "[epoch 7] loss: 0.7961904\n",
      "Test set: Average loss: 1.2333, Accuracy: 2875/5000 (58%)\n",
      "[epoch 8] loss: 0.6940874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.2334, Accuracy: 2984/5000 (60%)\n",
      "[epoch 9] loss: 0.5855128\n",
      "Test set: Average loss: 1.3022, Accuracy: 2961/5000 (59%)\n",
      "[epoch 10] loss: 0.4900215\n",
      "Test set: Average loss: 1.3272, Accuracy: 2994/5000 (60%)\n",
      "[epoch 11] loss: 0.3885712\n",
      "Test set: Average loss: 1.4724, Accuracy: 2930/5000 (59%)\n",
      "[epoch 12] loss: 0.3295723\n",
      "Test set: Average loss: 1.5215, Accuracy: 2941/5000 (59%)\n",
      "[epoch 13] loss: 0.2732831\n",
      "Test set: Average loss: 1.5907, Accuracy: 2953/5000 (59%)\n",
      "[epoch 14] loss: 0.2265396\n",
      "Test set: Average loss: 1.7082, Accuracy: 2908/5000 (58%)\n",
      "[epoch 15] loss: 0.2216848\n",
      "Test set: Average loss: 1.7219, Accuracy: 2908/5000 (58%)\n",
      "[epoch 16] loss: 0.2029570\n",
      "Test set: Average loss: 1.8679, Accuracy: 2873/5000 (57%)\n",
      "[epoch 17] loss: 0.1975786\n",
      "Test set: Average loss: 1.8742, Accuracy: 2876/5000 (58%)\n",
      "[epoch 18] loss: 0.1720291\n",
      "Test set: Average loss: 1.9426, Accuracy: 2910/5000 (58%)\n",
      "[epoch 19] loss: 0.1751042\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9944, Accuracy: 2894/5000 (58%)\n",
      "[epoch 20] loss: 0.0726222\n",
      "Test set: Average loss: 1.8943, Accuracy: 3012/5000 (60%)\n",
      "[epoch 21] loss: 0.0249840\n",
      "Test set: Average loss: 1.9088, Accuracy: 3037/5000 (61%)\n",
      "[epoch 22] loss: 0.0148913\n",
      "Test set: Average loss: 1.9203, Accuracy: 3057/5000 (61%)\n",
      "[epoch 23] loss: 0.0102317\n",
      "Test set: Average loss: 1.9403, Accuracy: 3052/5000 (61%)\n",
      "[epoch 24] loss: 0.0073255\n",
      "Test set: Average loss: 1.9628, Accuracy: 3062/5000 (61%)\n",
      "[epoch 25] loss: 0.0052666\n",
      "Test set: Average loss: 1.9889, Accuracy: 3046/5000 (61%)\n",
      "[epoch 26] loss: 0.0037860\n",
      "Test set: Average loss: 2.0205, Accuracy: 3057/5000 (61%)\n",
      "[epoch 27] loss: 0.0026964\n",
      "Test set: Average loss: 2.0538, Accuracy: 3064/5000 (61%)\n",
      "[epoch 28] loss: 0.0019038\n",
      "Test set: Average loss: 2.0931, Accuracy: 3076/5000 (62%)\n",
      "[epoch 29] loss: 0.0013427\n",
      "Test set: Average loss: 2.1337, Accuracy: 3087/5000 (62%)\n",
      "[epoch 30] loss: 0.0009425\n",
      "Test set: Average loss: 2.1872, Accuracy: 3079/5000 (62%)\n",
      "[epoch 31] loss: 0.0006533\n",
      "Test set: Average loss: 2.2425, Accuracy: 3080/5000 (62%)\n",
      "[epoch 32] loss: 0.0004541\n",
      "Test set: Average loss: 2.3006, Accuracy: 3068/5000 (61%)\n",
      "[epoch 33] loss: 0.0003146\n",
      "Test set: Average loss: 2.3438, Accuracy: 3073/5000 (61%)\n",
      "[epoch 34] loss: 0.0002150\n",
      "Test set: Average loss: 2.4087, Accuracy: 3082/5000 (62%)\n",
      "[epoch 35] loss: 0.0001598\n",
      "Test set: Average loss: 2.4637, Accuracy: 3072/5000 (61%)\n",
      "[epoch 36] loss: 0.0001032\n",
      "Test set: Average loss: 2.5199, Accuracy: 3075/5000 (62%)\n",
      "[epoch 37] loss: 0.0000717\n",
      "Test set: Average loss: 2.5768, Accuracy: 3072/5000 (61%)\n",
      "[epoch 38] loss: 0.0000494\n",
      "Test set: Average loss: 2.6391, Accuracy: 3079/5000 (62%)\n",
      "[epoch 39] loss: 0.0000337\n",
      "Test set: Average loss: 2.7083, Accuracy: 3083/5000 (62%)\n",
      "[epoch 40] loss: 0.0000227\n",
      "Test set: Average loss: 2.7817, Accuracy: 3071/5000 (61%)\n",
      "[epoch 41] loss: 0.0000153\n",
      "Test set: Average loss: 2.8458, Accuracy: 3065/5000 (61%)\n",
      "[epoch 42] loss: 0.0000103\n",
      "Test set: Average loss: 2.9026, Accuracy: 3081/5000 (62%)\n",
      "[epoch 43] loss: 0.0000069\n",
      "Test set: Average loss: 2.9755, Accuracy: 3083/5000 (62%)\n",
      "[epoch 44] loss: 0.0000046\n",
      "Test set: Average loss: 3.0454, Accuracy: 3078/5000 (62%)\n",
      "[epoch 45] loss: 0.0000030\n",
      "Test set: Average loss: 3.1018, Accuracy: 3070/5000 (61%)\n",
      "[epoch 46] loss: 0.0000020\n",
      "Test set: Average loss: 3.1633, Accuracy: 3079/5000 (62%)\n",
      "[epoch 47] loss: 0.0000013\n",
      "Test set: Average loss: 3.2241, Accuracy: 3081/5000 (62%)\n",
      "[epoch 48] loss: 0.0000009\n",
      "Test set: Average loss: 3.2635, Accuracy: 3085/5000 (62%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 3.2926, Accuracy: 3087/5000 (62%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.3080, Accuracy: 3082/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.2926, Accuracy: 3087/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 3.1730, Accuracy: 6187/10000 (62%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3022, Accuracy: 557/5000 (11%)\n",
      "[epoch 1] loss: 1.5093888\n",
      "Test set: Average loss: 1.3233, Accuracy: 2629/5000 (53%)\n",
      "[epoch 2] loss: 1.2601424\n",
      "Test set: Average loss: 1.3530, Accuracy: 2636/5000 (53%)\n",
      "[epoch 3] loss: 1.1450010\n",
      "Test set: Average loss: 1.1906, Accuracy: 2863/5000 (57%)\n",
      "[epoch 4] loss: 1.0373688\n",
      "Test set: Average loss: 1.2064, Accuracy: 2905/5000 (58%)\n",
      "[epoch 5] loss: 0.9544116\n",
      "Test set: Average loss: 1.1479, Accuracy: 3015/5000 (60%)\n",
      "[epoch 6] loss: 0.8666080\n",
      "Test set: Average loss: 1.1471, Accuracy: 3038/5000 (61%)\n",
      "[epoch 7] loss: 0.7706043\n",
      "Test set: Average loss: 1.1838, Accuracy: 3035/5000 (61%)\n",
      "[epoch 8] loss: 0.6799717\n",
      "Test set: Average loss: 1.1786, Accuracy: 3043/5000 (61%)\n",
      "[epoch 9] loss: 0.5851245\n",
      "Test set: Average loss: 1.2778, Accuracy: 3022/5000 (60%)\n",
      "[epoch 10] loss: 0.4967041\n",
      "Test set: Average loss: 1.3153, Accuracy: 3049/5000 (61%)\n",
      "[epoch 11] loss: 0.4160136\n",
      "Test set: Average loss: 1.3884, Accuracy: 3048/5000 (61%)\n",
      "[epoch 12] loss: 0.3495775\n",
      "Test set: Average loss: 1.4814, Accuracy: 3015/5000 (60%)\n",
      "[epoch 13] loss: 0.3075573\n",
      "Test set: Average loss: 1.5447, Accuracy: 3024/5000 (60%)\n",
      "[epoch 14] loss: 0.2657682\n",
      "Test set: Average loss: 1.6084, Accuracy: 3009/5000 (60%)\n",
      "[epoch 15] loss: 0.2391566\n",
      "Test set: Average loss: 1.7142, Accuracy: 2933/5000 (59%)\n",
      "[epoch 16] loss: 0.2289691\n",
      "Test set: Average loss: 1.8242, Accuracy: 2922/5000 (58%)\n",
      "[epoch 17] loss: 0.2237212\n",
      "Test set: Average loss: 1.8841, Accuracy: 2961/5000 (59%)\n",
      "[epoch 18] loss: 0.2027020\n",
      "Test set: Average loss: 1.8949, Accuracy: 2988/5000 (60%)\n",
      "[epoch 19] loss: 0.2026055\n",
      "Test set: Average loss: 1.8955, Accuracy: 2929/5000 (59%)\n",
      "[epoch 20] loss: 0.2180869\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9542, Accuracy: 2943/5000 (59%)\n",
      "[epoch 21] loss: 0.0860249\n",
      "Test set: Average loss: 1.8657, Accuracy: 3026/5000 (61%)\n",
      "[epoch 22] loss: 0.0318496\n",
      "Test set: Average loss: 1.8655, Accuracy: 3050/5000 (61%)\n",
      "[epoch 23] loss: 0.0179523\n",
      "Test set: Average loss: 1.8772, Accuracy: 3061/5000 (61%)\n",
      "[epoch 24] loss: 0.0119261\n",
      "Test set: Average loss: 1.8945, Accuracy: 3072/5000 (61%)\n",
      "[epoch 25] loss: 0.0081604\n",
      "Test set: Average loss: 1.9311, Accuracy: 3081/5000 (62%)\n",
      "[epoch 26] loss: 0.0056539\n",
      "Test set: Average loss: 1.9559, Accuracy: 3074/5000 (61%)\n",
      "[epoch 27] loss: 0.0039186\n",
      "Test set: Average loss: 2.0064, Accuracy: 3089/5000 (62%)\n",
      "[epoch 28] loss: 0.0026770\n",
      "Test set: Average loss: 2.0399, Accuracy: 3065/5000 (61%)\n",
      "[epoch 29] loss: 0.0018321\n",
      "Test set: Average loss: 2.0896, Accuracy: 3089/5000 (62%)\n",
      "[epoch 30] loss: 0.0012381\n",
      "Test set: Average loss: 2.1380, Accuracy: 3096/5000 (62%)\n",
      "[epoch 31] loss: 0.0008373\n",
      "Test set: Average loss: 2.1993, Accuracy: 3085/5000 (62%)\n",
      "[epoch 32] loss: 0.0005640\n",
      "Test set: Average loss: 2.2472, Accuracy: 3101/5000 (62%)\n",
      "[epoch 33] loss: 0.0003775\n",
      "Test set: Average loss: 2.3210, Accuracy: 3085/5000 (62%)\n",
      "[epoch 34] loss: 0.0002532\n",
      "Test set: Average loss: 2.3764, Accuracy: 3101/5000 (62%)\n",
      "[epoch 35] loss: 0.0001668\n",
      "Test set: Average loss: 2.4386, Accuracy: 3092/5000 (62%)\n",
      "[epoch 36] loss: 0.0001102\n",
      "Test set: Average loss: 2.5032, Accuracy: 3099/5000 (62%)\n",
      "[epoch 37] loss: 0.0000722\n",
      "Test set: Average loss: 2.5730, Accuracy: 3098/5000 (62%)\n",
      "[epoch 38] loss: 0.0000476\n",
      "Test set: Average loss: 2.6558, Accuracy: 3095/5000 (62%)\n",
      "[epoch 39] loss: 0.0000310\n",
      "Test set: Average loss: 2.7181, Accuracy: 3095/5000 (62%)\n",
      "[epoch 40] loss: 0.0000203\n",
      "Test set: Average loss: 2.7826, Accuracy: 3098/5000 (62%)\n",
      "[epoch 41] loss: 0.0000130\n",
      "Test set: Average loss: 2.8583, Accuracy: 3107/5000 (62%)\n",
      "[epoch 42] loss: 0.0000084\n",
      "Test set: Average loss: 2.9325, Accuracy: 3102/5000 (62%)\n",
      "[epoch 43] loss: 0.0000054\n",
      "Test set: Average loss: 3.0051, Accuracy: 3097/5000 (62%)\n",
      "[epoch 44] loss: 0.0000035\n",
      "Test set: Average loss: 3.0699, Accuracy: 3110/5000 (62%)\n",
      "[epoch 45] loss: 0.0000022\n",
      "Test set: Average loss: 3.1474, Accuracy: 3100/5000 (62%)\n",
      "[epoch 46] loss: 0.0000014\n",
      "Test set: Average loss: 3.2034, Accuracy: 3096/5000 (62%)\n",
      "[epoch 47] loss: 0.0000009\n",
      "Test set: Average loss: 3.2434, Accuracy: 3090/5000 (62%)\n",
      "[epoch 48] loss: 0.0000006\n",
      "Test set: Average loss: 3.2933, Accuracy: 3085/5000 (62%)\n",
      "[epoch 49] loss: 0.0000004\n",
      "Test set: Average loss: 3.3125, Accuracy: 3081/5000 (62%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 3.3233, Accuracy: 3063/5000 (61%)\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.0699, Accuracy: 3110/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 3.0383, Accuracy: 6239/10000 (62%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3080, Accuracy: 475/5000 (10%)\n",
      "[epoch 1] loss: 1.5078065\n",
      "Test set: Average loss: 1.3221, Accuracy: 2666/5000 (53%)\n",
      "[epoch 2] loss: 1.2552307\n",
      "Test set: Average loss: 1.2502, Accuracy: 2731/5000 (55%)\n",
      "[epoch 3] loss: 1.1215240\n",
      "Test set: Average loss: 1.1651, Accuracy: 2938/5000 (59%)\n",
      "[epoch 4] loss: 1.0188574\n",
      "Test set: Average loss: 1.1491, Accuracy: 2971/5000 (59%)\n",
      "[epoch 5] loss: 0.9343090\n",
      "Test set: Average loss: 1.1077, Accuracy: 3052/5000 (61%)\n",
      "[epoch 6] loss: 0.8547348\n",
      "Test set: Average loss: 1.1360, Accuracy: 3040/5000 (61%)\n",
      "[epoch 7] loss: 0.7679417\n",
      "Test set: Average loss: 1.1119, Accuracy: 3094/5000 (62%)\n",
      "[epoch 8] loss: 0.6923497\n",
      "Test set: Average loss: 1.1375, Accuracy: 3160/5000 (63%)\n",
      "[epoch 9] loss: 0.6049012\n",
      "Test set: Average loss: 1.1989, Accuracy: 3101/5000 (62%)\n",
      "[epoch 10] loss: 0.5300784\n",
      "Test set: Average loss: 1.2547, Accuracy: 3113/5000 (62%)\n",
      "[epoch 11] loss: 0.4599831\n",
      "Test set: Average loss: 1.3158, Accuracy: 3079/5000 (62%)\n",
      "[epoch 12] loss: 0.3945590\n",
      "Test set: Average loss: 1.3591, Accuracy: 3075/5000 (62%)\n",
      "[epoch 13] loss: 0.3341199\n",
      "Test set: Average loss: 1.4399, Accuracy: 3061/5000 (61%)\n",
      "[epoch 14] loss: 0.3077416\n",
      "Test set: Average loss: 1.5024, Accuracy: 3018/5000 (60%)\n",
      "[epoch 15] loss: 0.2667707\n",
      "Test set: Average loss: 1.5889, Accuracy: 3042/5000 (61%)\n",
      "[epoch 16] loss: 0.2600115\n",
      "Test set: Average loss: 1.5818, Accuracy: 3072/5000 (61%)\n",
      "[epoch 17] loss: 0.2373631\n",
      "Test set: Average loss: 1.6901, Accuracy: 3044/5000 (61%)\n",
      "[epoch 18] loss: 0.2415136\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7324, Accuracy: 3044/5000 (61%)\n",
      "[epoch 19] loss: 0.0996221\n",
      "Test set: Average loss: 1.6226, Accuracy: 3139/5000 (63%)\n",
      "[epoch 20] loss: 0.0412500\n",
      "Test set: Average loss: 1.6250, Accuracy: 3139/5000 (63%)\n",
      "[epoch 21] loss: 0.0252997\n",
      "Test set: Average loss: 1.6597, Accuracy: 3162/5000 (63%)\n",
      "[epoch 22] loss: 0.0169830\n",
      "Test set: Average loss: 1.6779, Accuracy: 3162/5000 (63%)\n",
      "[epoch 23] loss: 0.0118068\n",
      "Test set: Average loss: 1.7061, Accuracy: 3157/5000 (63%)\n",
      "[epoch 24] loss: 0.0082341\n",
      "Test set: Average loss: 1.7391, Accuracy: 3187/5000 (64%)\n",
      "[epoch 25] loss: 0.0057322\n",
      "Test set: Average loss: 1.7794, Accuracy: 3184/5000 (64%)\n",
      "[epoch 26] loss: 0.0039903\n",
      "Test set: Average loss: 1.8270, Accuracy: 3187/5000 (64%)\n",
      "[epoch 27] loss: 0.0027565\n",
      "Test set: Average loss: 1.8715, Accuracy: 3184/5000 (64%)\n",
      "[epoch 28] loss: 0.0019062\n",
      "Test set: Average loss: 1.9368, Accuracy: 3187/5000 (64%)\n",
      "[epoch 29] loss: 0.0013052\n",
      "Test set: Average loss: 1.9836, Accuracy: 3193/5000 (64%)\n",
      "[epoch 30] loss: 0.0008838\n",
      "Test set: Average loss: 2.0446, Accuracy: 3205/5000 (64%)\n",
      "[epoch 31] loss: 0.0006004\n",
      "Test set: Average loss: 2.1011, Accuracy: 3193/5000 (64%)\n",
      "[epoch 32] loss: 0.0004042\n",
      "Test set: Average loss: 2.1599, Accuracy: 3196/5000 (64%)\n",
      "[epoch 33] loss: 0.0002702\n",
      "Test set: Average loss: 2.2296, Accuracy: 3193/5000 (64%)\n",
      "[epoch 34] loss: 0.0001818\n",
      "Test set: Average loss: 2.2936, Accuracy: 3200/5000 (64%)\n",
      "[epoch 35] loss: 0.0001202\n",
      "Test set: Average loss: 2.3501, Accuracy: 3198/5000 (64%)\n",
      "[epoch 36] loss: 0.0000787\n",
      "Test set: Average loss: 2.4130, Accuracy: 3201/5000 (64%)\n",
      "[epoch 37] loss: 0.0000535\n",
      "Test set: Average loss: 2.4797, Accuracy: 3205/5000 (64%)\n",
      "[epoch 38] loss: 0.0000339\n",
      "Test set: Average loss: 2.5588, Accuracy: 3208/5000 (64%)\n",
      "[epoch 39] loss: 0.0000224\n",
      "Test set: Average loss: 2.6243, Accuracy: 3204/5000 (64%)\n",
      "[epoch 40] loss: 0.0000147\n",
      "Test set: Average loss: 2.6839, Accuracy: 3211/5000 (64%)\n",
      "[epoch 41] loss: 0.0000095\n",
      "Test set: Average loss: 2.7730, Accuracy: 3199/5000 (64%)\n",
      "[epoch 42] loss: 0.0000061\n",
      "Test set: Average loss: 2.8396, Accuracy: 3192/5000 (64%)\n",
      "[epoch 43] loss: 0.0006655\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9628, Accuracy: 3179/5000 (64%)\n",
      "[epoch 44] loss: 0.0003650\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.9020, Accuracy: 3191/5000 (64%)\n",
      "[epoch 45] loss: 0.0001144\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.9011, Accuracy: 3191/5000 (64%)\n",
      "[epoch 46] loss: 0.0001102\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.9010, Accuracy: 3191/5000 (64%)\n",
      "[epoch 47] loss: 0.0001097\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.9010, Accuracy: 3191/5000 (64%)\n",
      "[epoch 48] loss: 0.0001096\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.9010, Accuracy: 3191/5000 (64%)\n",
      "[epoch 49] loss: 0.0001096\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.9010, Accuracy: 3191/5000 (64%)\n",
      "[epoch 50] loss: 0.0001096\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.9010, Accuracy: 3191/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6839, Accuracy: 3211/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.6844, Accuracy: 6411/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3046, Accuracy: 439/5000 (9%)\n",
      "[epoch 1] loss: 1.5328479\n",
      "Test set: Average loss: 1.3860, Accuracy: 2497/5000 (50%)\n",
      "[epoch 2] loss: 1.2881401\n",
      "Test set: Average loss: 1.2898, Accuracy: 2694/5000 (54%)\n",
      "[epoch 3] loss: 1.1535895\n",
      "Test set: Average loss: 1.2073, Accuracy: 2866/5000 (57%)\n",
      "[epoch 4] loss: 1.0486604\n",
      "Test set: Average loss: 1.2300, Accuracy: 2833/5000 (57%)\n",
      "[epoch 5] loss: 0.9464829\n",
      "Test set: Average loss: 1.1411, Accuracy: 2997/5000 (60%)\n",
      "[epoch 6] loss: 0.8532943\n",
      "Test set: Average loss: 1.1572, Accuracy: 3030/5000 (61%)\n",
      "[epoch 7] loss: 0.7560779\n",
      "Test set: Average loss: 1.1535, Accuracy: 3071/5000 (61%)\n",
      "[epoch 8] loss: 0.6611647\n",
      "Test set: Average loss: 1.1798, Accuracy: 3094/5000 (62%)\n",
      "[epoch 9] loss: 0.5549899\n",
      "Test set: Average loss: 1.2756, Accuracy: 3050/5000 (61%)\n",
      "[epoch 10] loss: 0.4724112\n",
      "Test set: Average loss: 1.2770, Accuracy: 3072/5000 (61%)\n",
      "[epoch 11] loss: 0.3870724\n",
      "Test set: Average loss: 1.4057, Accuracy: 3010/5000 (60%)\n",
      "[epoch 12] loss: 0.3300965\n",
      "Test set: Average loss: 1.4473, Accuracy: 3029/5000 (61%)\n",
      "[epoch 13] loss: 0.2812491\n",
      "Test set: Average loss: 1.5742, Accuracy: 3004/5000 (60%)\n",
      "[epoch 14] loss: 0.2481031\n",
      "Test set: Average loss: 1.6661, Accuracy: 2950/5000 (59%)\n",
      "[epoch 15] loss: 0.2334030\n",
      "Test set: Average loss: 1.7227, Accuracy: 2955/5000 (59%)\n",
      "[epoch 16] loss: 0.2073679\n",
      "Test set: Average loss: 1.7873, Accuracy: 2967/5000 (59%)\n",
      "[epoch 17] loss: 0.2093892\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8134, Accuracy: 3022/5000 (60%)\n",
      "[epoch 18] loss: 0.0916576\n",
      "Test set: Average loss: 1.7409, Accuracy: 3079/5000 (62%)\n",
      "[epoch 19] loss: 0.0341546\n",
      "Test set: Average loss: 1.7522, Accuracy: 3100/5000 (62%)\n",
      "[epoch 20] loss: 0.0202020\n",
      "Test set: Average loss: 1.7689, Accuracy: 3109/5000 (62%)\n",
      "[epoch 21] loss: 0.0134802\n",
      "Test set: Average loss: 1.7812, Accuracy: 3128/5000 (63%)\n",
      "[epoch 22] loss: 0.0093216\n",
      "Test set: Average loss: 1.8096, Accuracy: 3143/5000 (63%)\n",
      "[epoch 23] loss: 0.0064700\n",
      "Test set: Average loss: 1.8523, Accuracy: 3136/5000 (63%)\n",
      "[epoch 24] loss: 0.0044836\n",
      "Test set: Average loss: 1.8867, Accuracy: 3127/5000 (63%)\n",
      "[epoch 25] loss: 0.0030604\n",
      "Test set: Average loss: 1.9326, Accuracy: 3133/5000 (63%)\n",
      "[epoch 26] loss: 0.0020975\n",
      "Test set: Average loss: 1.9796, Accuracy: 3119/5000 (62%)\n",
      "[epoch 27] loss: 0.0014242\n",
      "Test set: Average loss: 2.0382, Accuracy: 3140/5000 (63%)\n",
      "[epoch 28] loss: 0.0009638\n",
      "Test set: Average loss: 2.0931, Accuracy: 3133/5000 (63%)\n",
      "[epoch 29] loss: 0.0006469\n",
      "Test set: Average loss: 2.1554, Accuracy: 3138/5000 (63%)\n",
      "[epoch 30] loss: 0.0004331\n",
      "Test set: Average loss: 2.2129, Accuracy: 3135/5000 (63%)\n",
      "[epoch 31] loss: 0.0002877\n",
      "Test set: Average loss: 2.2774, Accuracy: 3127/5000 (63%)\n",
      "[epoch 32] loss: 0.0001899\n",
      "Test set: Average loss: 2.3351, Accuracy: 3142/5000 (63%)\n",
      "[epoch 33] loss: 0.0001253\n",
      "Test set: Average loss: 2.4112, Accuracy: 3133/5000 (63%)\n",
      "[epoch 34] loss: 0.0000821\n",
      "Test set: Average loss: 2.4762, Accuracy: 3120/5000 (62%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0000540\n",
      "Test set: Average loss: 2.5449, Accuracy: 3120/5000 (62%)\n",
      "[epoch 36] loss: 0.0000349\n",
      "Test set: Average loss: 2.6157, Accuracy: 3118/5000 (62%)\n",
      "[epoch 37] loss: 0.0000225\n",
      "Test set: Average loss: 2.6910, Accuracy: 3123/5000 (62%)\n",
      "[epoch 38] loss: 0.0000145\n",
      "Test set: Average loss: 2.7584, Accuracy: 3122/5000 (62%)\n",
      "[epoch 39] loss: 0.0000093\n",
      "Test set: Average loss: 2.8314, Accuracy: 3132/5000 (63%)\n",
      "[epoch 40] loss: 0.0000060\n",
      "Test set: Average loss: 2.9013, Accuracy: 3119/5000 (62%)\n",
      "[epoch 41] loss: 0.0000038\n",
      "Test set: Average loss: 2.9753, Accuracy: 3107/5000 (62%)\n",
      "[epoch 42] loss: 0.0000024\n",
      "Test set: Average loss: 3.0431, Accuracy: 3112/5000 (62%)\n",
      "[epoch 43] loss: 0.0000015\n",
      "Test set: Average loss: 3.1133, Accuracy: 3110/5000 (62%)\n",
      "[epoch 44] loss: 0.0000009\n",
      "Test set: Average loss: 3.1670, Accuracy: 3106/5000 (62%)\n",
      "[epoch 45] loss: 0.0000006\n",
      "Test set: Average loss: 3.1983, Accuracy: 3100/5000 (62%)\n",
      "[epoch 46] loss: 0.0000004\n",
      "Test set: Average loss: 3.2279, Accuracy: 3096/5000 (62%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 3.2277, Accuracy: 3090/5000 (62%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.2472, Accuracy: 3101/5000 (62%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.2807, Accuracy: 3087/5000 (62%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.2771, Accuracy: 3097/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8096, Accuracy: 3143/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 1.7690, Accuracy: 6294/10000 (63%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 522/5000 (10%)\n",
      "[epoch 1] loss: 1.4942263\n",
      "Test set: Average loss: 1.3312, Accuracy: 2605/5000 (52%)\n",
      "[epoch 2] loss: 1.2491258\n",
      "Test set: Average loss: 1.2375, Accuracy: 2768/5000 (55%)\n",
      "[epoch 3] loss: 1.1170666\n",
      "Test set: Average loss: 1.1747, Accuracy: 2914/5000 (58%)\n",
      "[epoch 4] loss: 1.0114860\n",
      "Test set: Average loss: 1.1205, Accuracy: 3007/5000 (60%)\n",
      "[epoch 5] loss: 0.9253495\n",
      "Test set: Average loss: 1.1319, Accuracy: 3038/5000 (61%)\n",
      "[epoch 6] loss: 0.8422471\n",
      "Test set: Average loss: 1.1288, Accuracy: 3102/5000 (62%)\n",
      "[epoch 7] loss: 0.7529594\n",
      "Test set: Average loss: 1.1756, Accuracy: 3061/5000 (61%)\n",
      "[epoch 8] loss: 0.6758467\n",
      "Test set: Average loss: 1.1632, Accuracy: 3124/5000 (62%)\n",
      "[epoch 9] loss: 0.5936989\n",
      "Test set: Average loss: 1.2237, Accuracy: 3067/5000 (61%)\n",
      "[epoch 10] loss: 0.5239898\n",
      "Test set: Average loss: 1.2765, Accuracy: 3060/5000 (61%)\n",
      "[epoch 11] loss: 0.4476407\n",
      "Test set: Average loss: 1.2886, Accuracy: 3111/5000 (62%)\n",
      "[epoch 12] loss: 0.3957264\n",
      "Test set: Average loss: 1.3700, Accuracy: 3137/5000 (63%)\n",
      "[epoch 13] loss: 0.3467384\n",
      "Test set: Average loss: 1.4266, Accuracy: 3084/5000 (62%)\n",
      "[epoch 14] loss: 0.3026153\n",
      "Test set: Average loss: 1.4909, Accuracy: 3108/5000 (62%)\n",
      "[epoch 15] loss: 0.2791636\n",
      "Test set: Average loss: 1.5518, Accuracy: 3076/5000 (62%)\n",
      "[epoch 16] loss: 0.2542400\n",
      "Test set: Average loss: 1.6239, Accuracy: 3067/5000 (61%)\n",
      "[epoch 17] loss: 0.2461150\n",
      "Test set: Average loss: 1.7175, Accuracy: 3036/5000 (61%)\n",
      "[epoch 18] loss: 0.2373444\n",
      "Test set: Average loss: 1.7568, Accuracy: 3037/5000 (61%)\n",
      "[epoch 19] loss: 0.2292532\n",
      "Test set: Average loss: 1.8068, Accuracy: 3059/5000 (61%)\n",
      "[epoch 20] loss: 0.2233310\n",
      "Test set: Average loss: 1.8056, Accuracy: 3034/5000 (61%)\n",
      "[epoch 21] loss: 0.2056995\n",
      "Test set: Average loss: 1.8612, Accuracy: 3040/5000 (61%)\n",
      "[epoch 22] loss: 0.2176024\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9306, Accuracy: 3044/5000 (61%)\n",
      "[epoch 23] loss: 0.0976108\n",
      "Test set: Average loss: 1.8298, Accuracy: 3107/5000 (62%)\n",
      "[epoch 24] loss: 0.0341405\n",
      "Test set: Average loss: 1.8515, Accuracy: 3127/5000 (63%)\n",
      "[epoch 25] loss: 0.0184708\n",
      "Test set: Average loss: 1.8624, Accuracy: 3148/5000 (63%)\n",
      "[epoch 26] loss: 0.0115860\n",
      "Test set: Average loss: 1.8942, Accuracy: 3159/5000 (63%)\n",
      "[epoch 27] loss: 0.0210279\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9263, Accuracy: 3153/5000 (63%)\n",
      "[epoch 28] loss: 0.0050858\n",
      "Test set: Average loss: 1.9296, Accuracy: 3165/5000 (63%)\n",
      "[epoch 29] loss: 0.0046324\n",
      "Test set: Average loss: 1.9347, Accuracy: 3169/5000 (63%)\n",
      "[epoch 30] loss: 0.0043372\n",
      "Test set: Average loss: 1.9419, Accuracy: 3167/5000 (63%)\n",
      "[epoch 31] loss: 0.0040311\n",
      "Test set: Average loss: 1.9484, Accuracy: 3165/5000 (63%)\n",
      "[epoch 32] loss: 0.0037227\n",
      "Test set: Average loss: 1.9579, Accuracy: 3172/5000 (63%)\n",
      "[epoch 33] loss: 0.0034196\n",
      "Test set: Average loss: 1.9665, Accuracy: 3163/5000 (63%)\n",
      "[epoch 34] loss: 0.0031369\n",
      "Test set: Average loss: 1.9760, Accuracy: 3169/5000 (63%)\n",
      "[epoch 35] loss: 0.0028786\n",
      "Test set: Average loss: 1.9846, Accuracy: 3169/5000 (63%)\n",
      "[epoch 36] loss: 0.0026410\n",
      "Test set: Average loss: 1.9954, Accuracy: 3168/5000 (63%)\n",
      "[epoch 37] loss: 0.0024249\n",
      "Test set: Average loss: 2.0046, Accuracy: 3167/5000 (63%)\n",
      "[epoch 38] loss: 0.0022294\n",
      "Test set: Average loss: 2.0140, Accuracy: 3169/5000 (63%)\n",
      "[epoch 39] loss: 0.0020476\n",
      "Test set: Average loss: 2.0224, Accuracy: 3175/5000 (64%)\n",
      "[epoch 40] loss: 0.0018822\n",
      "Test set: Average loss: 2.0334, Accuracy: 3177/5000 (64%)\n",
      "[epoch 41] loss: 0.0017313\n",
      "Test set: Average loss: 2.0446, Accuracy: 3173/5000 (63%)\n",
      "[epoch 42] loss: 0.0015923\n",
      "Test set: Average loss: 2.0539, Accuracy: 3174/5000 (63%)\n",
      "[epoch 43] loss: 0.0014647\n",
      "Test set: Average loss: 2.0646, Accuracy: 3171/5000 (63%)\n",
      "[epoch 44] loss: 0.0013477\n",
      "Test set: Average loss: 2.0754, Accuracy: 3173/5000 (63%)\n",
      "[epoch 45] loss: 0.0012401\n",
      "Test set: Average loss: 2.0865, Accuracy: 3170/5000 (63%)\n",
      "[epoch 46] loss: 0.0011410\n",
      "Test set: Average loss: 2.0968, Accuracy: 3179/5000 (64%)\n",
      "[epoch 47] loss: 0.0010500\n",
      "Test set: Average loss: 2.1085, Accuracy: 3173/5000 (63%)\n",
      "[epoch 48] loss: 0.0009667\n",
      "Test set: Average loss: 2.1189, Accuracy: 3181/5000 (64%)\n",
      "[epoch 49] loss: 0.0008899\n",
      "Test set: Average loss: 2.1304, Accuracy: 3180/5000 (64%)\n",
      "[epoch 50] loss: 0.0008184\n",
      "Test set: Average loss: 2.1421, Accuracy: 3184/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1421, Accuracy: 3184/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.0734, Accuracy: 6433/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3076, Accuracy: 467/5000 (9%)\n",
      "[epoch 1] loss: 1.4575554\n",
      "Test set: Average loss: 1.3263, Accuracy: 2647/5000 (53%)\n",
      "[epoch 2] loss: 1.2058017\n",
      "Test set: Average loss: 1.2210, Accuracy: 2834/5000 (57%)\n",
      "[epoch 3] loss: 1.0850631\n",
      "Test set: Average loss: 1.1973, Accuracy: 2925/5000 (58%)\n",
      "[epoch 4] loss: 0.9921414\n",
      "Test set: Average loss: 1.1288, Accuracy: 3028/5000 (61%)\n",
      "[epoch 5] loss: 0.9119701\n",
      "Test set: Average loss: 1.1112, Accuracy: 3099/5000 (62%)\n",
      "[epoch 6] loss: 0.8224998\n",
      "Test set: Average loss: 1.1570, Accuracy: 3036/5000 (61%)\n",
      "[epoch 7] loss: 0.7475640\n",
      "Test set: Average loss: 1.1488, Accuracy: 3081/5000 (62%)\n",
      "[epoch 8] loss: 0.6604993\n",
      "Test set: Average loss: 1.1763, Accuracy: 3130/5000 (63%)\n",
      "[epoch 9] loss: 0.5835395\n",
      "Test set: Average loss: 1.1971, Accuracy: 3116/5000 (62%)\n",
      "[epoch 10] loss: 0.5066765\n",
      "Test set: Average loss: 1.3081, Accuracy: 3067/5000 (61%)\n",
      "[epoch 11] loss: 0.4436881\n",
      "Test set: Average loss: 1.3332, Accuracy: 3079/5000 (62%)\n",
      "[epoch 12] loss: 0.3833339\n",
      "Test set: Average loss: 1.3927, Accuracy: 3066/5000 (61%)\n",
      "[epoch 13] loss: 0.3444753\n",
      "Test set: Average loss: 1.4777, Accuracy: 3104/5000 (62%)\n",
      "[epoch 14] loss: 0.3018350\n",
      "Test set: Average loss: 1.5135, Accuracy: 3075/5000 (62%)\n",
      "[epoch 15] loss: 0.2777069\n",
      "Test set: Average loss: 1.6438, Accuracy: 3020/5000 (60%)\n",
      "[epoch 16] loss: 0.2611147\n",
      "Test set: Average loss: 1.7079, Accuracy: 3021/5000 (60%)\n",
      "[epoch 17] loss: 0.2562485\n",
      "Test set: Average loss: 1.7328, Accuracy: 3046/5000 (61%)\n",
      "[epoch 18] loss: 0.2489595\n",
      "Test set: Average loss: 1.7572, Accuracy: 3046/5000 (61%)\n",
      "[epoch 19] loss: 0.2211137\n",
      "Test set: Average loss: 1.8210, Accuracy: 3070/5000 (61%)\n",
      "[epoch 20] loss: 0.2266379\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7977, Accuracy: 3029/5000 (61%)\n",
      "[epoch 21] loss: 0.0956326\n",
      "Test set: Average loss: 1.7396, Accuracy: 3138/5000 (63%)\n",
      "[epoch 22] loss: 0.0376128\n",
      "Test set: Average loss: 1.7420, Accuracy: 3148/5000 (63%)\n",
      "[epoch 23] loss: 0.0215448\n",
      "Test set: Average loss: 1.7723, Accuracy: 3175/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24] loss: 0.0138926\n",
      "Test set: Average loss: 1.7986, Accuracy: 3174/5000 (63%)\n",
      "[epoch 25] loss: 0.0093009\n",
      "Test set: Average loss: 1.8347, Accuracy: 3177/5000 (64%)\n",
      "[epoch 26] loss: 0.0062472\n",
      "Test set: Average loss: 1.8786, Accuracy: 3196/5000 (64%)\n",
      "[epoch 27] loss: 0.0042404\n",
      "Test set: Average loss: 1.9182, Accuracy: 3189/5000 (64%)\n",
      "[epoch 28] loss: 0.0028452\n",
      "Test set: Average loss: 1.9717, Accuracy: 3184/5000 (64%)\n",
      "[epoch 29] loss: 0.0018783\n",
      "Test set: Average loss: 2.0270, Accuracy: 3199/5000 (64%)\n",
      "[epoch 30] loss: 0.0012303\n",
      "Test set: Average loss: 2.0744, Accuracy: 3220/5000 (64%)\n",
      "[epoch 31] loss: 0.0008198\n",
      "Test set: Average loss: 2.1407, Accuracy: 3210/5000 (64%)\n",
      "[epoch 32] loss: 0.0005338\n",
      "Test set: Average loss: 2.2088, Accuracy: 3217/5000 (64%)\n",
      "[epoch 33] loss: 0.0003462\n",
      "Test set: Average loss: 2.2740, Accuracy: 3217/5000 (64%)\n",
      "[epoch 34] loss: 0.0002234\n",
      "Test set: Average loss: 2.3515, Accuracy: 3209/5000 (64%)\n",
      "[epoch 35] loss: 0.0001423\n",
      "Test set: Average loss: 2.4269, Accuracy: 3199/5000 (64%)\n",
      "[epoch 36] loss: 0.0000896\n",
      "Test set: Average loss: 2.4940, Accuracy: 3222/5000 (64%)\n",
      "[epoch 37] loss: 0.0000569\n",
      "Test set: Average loss: 2.5790, Accuracy: 3198/5000 (64%)\n",
      "[epoch 38] loss: 0.0000356\n",
      "Test set: Average loss: 2.6581, Accuracy: 3202/5000 (64%)\n",
      "[epoch 39] loss: 0.0000222\n",
      "Test set: Average loss: 2.7382, Accuracy: 3198/5000 (64%)\n",
      "[epoch 40] loss: 0.0000143\n",
      "Test set: Average loss: 2.8220, Accuracy: 3188/5000 (64%)\n",
      "[epoch 41] loss: 0.0000088\n",
      "Test set: Average loss: 2.8981, Accuracy: 3208/5000 (64%)\n",
      "[epoch 42] loss: 0.0000053\n",
      "Test set: Average loss: 2.9760, Accuracy: 3192/5000 (64%)\n",
      "[epoch 43] loss: 0.0000033\n",
      "Test set: Average loss: 3.0553, Accuracy: 3199/5000 (64%)\n",
      "[epoch 44] loss: 0.0000020\n",
      "Test set: Average loss: 3.1376, Accuracy: 3197/5000 (64%)\n",
      "[epoch 45] loss: 0.0000012\n",
      "Test set: Average loss: 3.1992, Accuracy: 3187/5000 (64%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Test set: Average loss: 3.2559, Accuracy: 3197/5000 (64%)\n",
      "[epoch 47] loss: 0.0000005\n",
      "Test set: Average loss: 3.2892, Accuracy: 3185/5000 (64%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.3021, Accuracy: 3178/5000 (64%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.3256, Accuracy: 3179/5000 (64%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.3458, Accuracy: 3176/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4940, Accuracy: 3222/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.3925, Accuracy: 6554/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3082, Accuracy: 453/5000 (9%)\n",
      "[epoch 1] loss: 1.4917855\n",
      "Test set: Average loss: 1.4375, Accuracy: 2418/5000 (48%)\n",
      "[epoch 2] loss: 1.2611710\n",
      "Test set: Average loss: 1.2563, Accuracy: 2734/5000 (55%)\n",
      "[epoch 3] loss: 1.1288431\n",
      "Test set: Average loss: 1.1878, Accuracy: 2886/5000 (58%)\n",
      "[epoch 4] loss: 1.0203764\n",
      "Test set: Average loss: 1.1440, Accuracy: 2968/5000 (59%)\n",
      "[epoch 5] loss: 0.9192366\n",
      "Test set: Average loss: 1.1306, Accuracy: 3065/5000 (61%)\n",
      "[epoch 6] loss: 0.8226999\n",
      "Test set: Average loss: 1.1912, Accuracy: 2940/5000 (59%)\n",
      "[epoch 7] loss: 0.7400383\n",
      "Test set: Average loss: 1.1785, Accuracy: 3047/5000 (61%)\n",
      "[epoch 8] loss: 0.6430008\n",
      "Test set: Average loss: 1.1843, Accuracy: 3064/5000 (61%)\n",
      "[epoch 9] loss: 0.5678497\n",
      "Test set: Average loss: 1.2421, Accuracy: 3053/5000 (61%)\n",
      "[epoch 10] loss: 0.4876745\n",
      "Test set: Average loss: 1.3430, Accuracy: 3028/5000 (61%)\n",
      "[epoch 11] loss: 0.4157953\n",
      "Test set: Average loss: 1.3406, Accuracy: 3073/5000 (61%)\n",
      "[epoch 12] loss: 0.3567055\n",
      "Test set: Average loss: 1.4415, Accuracy: 3043/5000 (61%)\n",
      "[epoch 13] loss: 0.3204106\n",
      "Test set: Average loss: 1.5080, Accuracy: 3014/5000 (60%)\n",
      "[epoch 14] loss: 0.2892611\n",
      "Test set: Average loss: 1.5838, Accuracy: 3042/5000 (61%)\n",
      "[epoch 15] loss: 0.2541640\n",
      "Test set: Average loss: 1.7247, Accuracy: 2943/5000 (59%)\n",
      "[epoch 16] loss: 0.2589224\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8125, Accuracy: 2904/5000 (58%)\n",
      "[epoch 17] loss: 0.1155271\n",
      "Test set: Average loss: 1.6267, Accuracy: 3121/5000 (62%)\n",
      "[epoch 18] loss: 0.0493041\n",
      "Test set: Average loss: 1.6271, Accuracy: 3103/5000 (62%)\n",
      "[epoch 19] loss: 0.0294669\n",
      "Test set: Average loss: 1.6461, Accuracy: 3152/5000 (63%)\n",
      "[epoch 20] loss: 0.0196525\n",
      "Test set: Average loss: 1.6815, Accuracy: 3143/5000 (63%)\n",
      "[epoch 21] loss: 0.0134752\n",
      "Test set: Average loss: 1.7204, Accuracy: 3159/5000 (63%)\n",
      "[epoch 22] loss: 0.0091679\n",
      "Test set: Average loss: 1.7612, Accuracy: 3156/5000 (63%)\n",
      "[epoch 23] loss: 0.0062655\n",
      "Test set: Average loss: 1.8122, Accuracy: 3166/5000 (63%)\n",
      "[epoch 24] loss: 0.0042529\n",
      "Test set: Average loss: 1.8631, Accuracy: 3165/5000 (63%)\n",
      "[epoch 25] loss: 0.0028915\n",
      "Test set: Average loss: 1.9143, Accuracy: 3160/5000 (63%)\n",
      "[epoch 26] loss: 0.0019336\n",
      "Test set: Average loss: 1.9688, Accuracy: 3179/5000 (64%)\n",
      "[epoch 27] loss: 0.0012998\n",
      "Test set: Average loss: 2.0396, Accuracy: 3171/5000 (63%)\n",
      "[epoch 28] loss: 0.0008604\n",
      "Test set: Average loss: 2.0995, Accuracy: 3161/5000 (63%)\n",
      "[epoch 29] loss: 0.0005715\n",
      "Test set: Average loss: 2.1707, Accuracy: 3173/5000 (63%)\n",
      "[epoch 30] loss: 0.0003741\n",
      "Test set: Average loss: 2.2401, Accuracy: 3179/5000 (64%)\n",
      "[epoch 31] loss: 0.0002444\n",
      "Test set: Average loss: 2.3136, Accuracy: 3173/5000 (63%)\n",
      "[epoch 32] loss: 0.0001595\n",
      "Test set: Average loss: 2.3847, Accuracy: 3178/5000 (64%)\n",
      "[epoch 33] loss: 0.0001030\n",
      "Test set: Average loss: 2.4510, Accuracy: 3166/5000 (63%)\n",
      "[epoch 34] loss: 0.0000665\n",
      "Test set: Average loss: 2.5246, Accuracy: 3185/5000 (64%)\n",
      "[epoch 35] loss: 0.0000421\n",
      "Test set: Average loss: 2.6005, Accuracy: 3196/5000 (64%)\n",
      "[epoch 36] loss: 0.0000273\n",
      "Test set: Average loss: 2.6781, Accuracy: 3186/5000 (64%)\n",
      "[epoch 37] loss: 0.0000172\n",
      "Test set: Average loss: 2.7554, Accuracy: 3186/5000 (64%)\n",
      "[epoch 38] loss: 0.0000107\n",
      "Test set: Average loss: 2.8365, Accuracy: 3192/5000 (64%)\n",
      "[epoch 39] loss: 0.0000068\n",
      "Test set: Average loss: 2.9179, Accuracy: 3182/5000 (64%)\n",
      "[epoch 40] loss: 0.0000042\n",
      "Test set: Average loss: 2.9985, Accuracy: 3179/5000 (64%)\n",
      "[epoch 41] loss: 0.0000026\n",
      "Test set: Average loss: 3.0777, Accuracy: 3174/5000 (63%)\n",
      "[epoch 42] loss: 0.0000016\n",
      "Test set: Average loss: 3.1471, Accuracy: 3164/5000 (63%)\n",
      "[epoch 43] loss: 0.0000010\n",
      "Test set: Average loss: 3.2028, Accuracy: 3172/5000 (63%)\n",
      "[epoch 44] loss: 0.0000006\n",
      "Test set: Average loss: 3.2478, Accuracy: 3157/5000 (63%)\n",
      "[epoch 45] loss: 0.0000004\n",
      "Test set: Average loss: 3.2839, Accuracy: 3159/5000 (63%)\n",
      "[epoch 46] loss: 0.0000003\n",
      "Test set: Average loss: 3.3013, Accuracy: 3145/5000 (63%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 3.3177, Accuracy: 3153/5000 (63%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.3423, Accuracy: 3140/5000 (63%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.3530, Accuracy: 3130/5000 (63%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.3807, Accuracy: 3123/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6005, Accuracy: 3196/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.5205, Accuracy: 6381/10000 (64%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB1CAYAAABeSBpCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztvWmULdlVHvjtuBF3zPnlm8eaVFIJAZLVIAY3NmAms4Duhd3Cg0QjXG08tbvttiXjZVssuxnabcCstjENbtMgg9WyZLRYpsFm8GoZLAmBBBKqkmp883uZ+XK88404/WN/X2TeS76qN1TlfUqdvVauyHsjbsSJEycivr3Pt79tIQREixYtWrTPfUum3YBo0aJFi/bKWHygR4sWLdohsfhAjxYtWrRDYvGBHi1atGiHxOIDPVq0aNEOicUHerRo0aIdEosP9Gh3ZGZ2wcyCmaXTbsuDZJ/v/WJmv2Fm332bdefMbMfMKgfdrlfSzOw7zexDL7H+l8zs7Xexv1dtzHxeDsJo0aK9+hZCuAhgZtrteLUthPCN026DLCL0KdnnK6KbtNgP0Q6zHfT4jg/0ezAz+0oz+00z2zCzS2b2nfz+T5rZ75rZFr//B3t+IzfrHWZ2EcCvTan5d2RmVjGzf2xmq2b2HIA/ObF+3sx+ysyumdkVM/uHe11rM/suM/u0ma2b2S+b2fk964KZ/WUz+yyAzx7cWd2/3UG/nDKzD5rZLTN7xsz+wp51DTP7afbJp83sb5nZ5QM/ibs0M6ub2c+a2RrH/EfN7PieTc6b2X82s20z+xUzW+bvxkILDM98v5l9xMw2zewXzGxpKid192Zm9mNs91Nm9jV7VpRhJ4Zn/rOZ/bCZ3QLwD15uzLySFh/od2lmdg7ALwH4MQBHAXwxgI9zdRvA2wAswC/a95jZt03s4qsAvA7A1x9Ig+/d/gKAbwbwRgBvBvDtE+t/GsAIwKPc5usAaFB/G4C/A+C/hffR/wfg5yZ+/20AvhTAE69O8181e7l++TkAlwGc4rr/dc/N//cBXADwMIA/AeDPHUB7Xwl7O4B5AGcBHAHwFwF096z/MwD+ewDHAFQB/M2X2NfbAHwXvH9GAP7pq9DeV8O+FMBzAJbh1/H9L/Ey0rbHAPwjvPyYeeUshBD/7uIPwLsAfOAOt/0RAD/M/y8ACAAenvY53GHbfw3AX9zz+evY/hTAcQB9AI09678DwK/z/18C8I496xIAHQDn+TkA+Oppn+Or0C9nAeQAZves/34A/4r/Pwfg6/es+24Al6d9Tndwzt8F4DcBfOE+634DwN/d8/kvAfh/+b/GfLpn2x/Ys+0TAAYAKtM+x5c5/+8EcBWA7fnuIwD+/J7z+u4921680zHzSrc1IvS7t7MAnt1vhZl9qZn9upmtmNkmHMksT2x26dVu4CtkpzDe1hf3/H8eQAbgGl3wDQD/Ao5ItP5H96y7BcAAnN6zj8+Vfpi0l+qXUwBuhRC2J9af3rN+728/V/rgZwD8MoCfN7OrZvZDZpbtWX99z/8dvPRE6GTfZfjD98iDaFcCn8a0F+HXcz+bvK4vNWZeUYsP9Lu3SwAeuc26fw3ggwDOhhDmAfw4/EG21z5X5C2vwV9esnN7/r8ER+jLIYQF/s2FEF6/Z/3/sGfdQgihEUL4zT37+Fzph0l7qX65CmDJzGYn1l/Z89sze9bt3c8DayGEYQjh3SGEJwB8OTx88LZ73N1k3w0BrN5nEw/CTpvZ3nv5HPx672eTY/ulxswravGBfvf2HgBfa2Z/2sxSMztiZl/MdbNwhNYzsy+BxxY/V+29AP6amZ0xs0UA79SKEMI1AL8C4H83szkzS8zsETP7Km7y4wDeZWavB8oJ1D910CfwKtlL9csleGji+zmR+IUA3gEfM/rtu8xs0cxOA/grB9z2ezIz++Nm9gZOem/BH8L5Pe7uz5nZE2bWBPB9AN4XQrjXfR2kHYNf94xj+XUA/v0d/va2Y+aVtvhAv0sLzq39JgB/Ax5K+DiAL+LqvwTg+8xsG8Dfg1/Iz1X7P+Fu9icA/A6A90+sfxt8AuwPAKwDeB+AkwAQQvgAgB+Eu+hbAD4J4IHh6t6nvVy/fAc8dnwVwAcA/P0Qwn/guu+DT5g+D+A/wvus/+o3+b7tBLytWwA+DeA/AfjZe9zXzwD4V/AwTR3AX3sF2ncQ9mEAj8G9iX8E4NtDCGt3+NuXGzOvmNl4WChatGgHZWb2PQDeGkL4qpfd+BCYmf0GgJ8NIfzktNtyWC0i9GjRDsjM7KSZfQVDVI/DvbwPTLtd0Q6PxSy9aNEOzqpwNtBDADYA/DyAfzbVFkU7VHZfIRcz+wYAPwqgAuAnQwg/8Eo1LFq0aNGi3Z3d8wOdM96fgWe8XQbwUQDfEUL4g1euedGiRYsW7U7tfmLoXwLgmRDCcyGEAdx9/NZXplnRokWLFu1u7X5i6Kcxnv10Ga5hcFtrNpthYWHhPg4ZLVq0aJ9/du3atdUQwtGX2+5+HuiTGZDAPtl/ZvYkgCcBYH5+Hk8++eR9HDJatGjRPv/s3e9+9x3JBdxPyOUyxtNZz2CfVNgQwk+EEN4cQnhzs9m8j8NFixYtWrSXsvtB6B8F8JiZPQTXqngr7jLVfbXmmkWNRgMA0JpxTZ9avQYAqNfqAIClJVepPHPmJADg5PFlzM/4uyijAveI+XZrq5689fSnfW72d3/7YwCAiy9e9O3rvs/Hn3DZkTe++Y8AAM4//DAAYG6hCmC3Y4ZcdgpfbnW0HAEAekPPWu6PAoYj3ygv5Kh4G+XK5MOBt+29PzzWD9WFT/h2ybjTU+Q8KB2fLPVWZVmVS9dHShJ2QijGf2cBlYqvq1TSPXsC8jzntvzGvK3lHHkxfmzT9+UGviz4OfDYo9GIPx+Nry9/HoDg59nflmKC20effQYAsNPeAQCsr28AANodv7hZvcW2ZtyuBwDYXHctrNwPiZPHTgAAvuAJV+Z9+KGHAOyOp3WOkeeffwEAcOXKVWxu+T5G7I+C0u5F4v1Wm/FQ4fJJl+E4dvYCAKA5fwQAMCi8/3p9v8a9Xtu/77vK7LDv59TecNmStRXXs9re8nP8u//dm8f64s/8Vc8OHw6GSBLfd5r6ssJhklBaRMOmWuV4YNsT9nolGd9Ow2XIwT0YjHjufg11ifNi/HMl3X1c6DoPuZPJ4RF4DwyGo7Httb7gGCh4j+j3v/LzPzbWD5+89nG2zcer7pGsynuBnZGlCZpNPTdSts3Hx/bONs/Tr03CfbRmXXJnhkvJ+aep9+PCoj93Tp9x3Low72Og1/H9Xrl8mUuX6tne2PL9q/EB6Oz4de/yN9Wq37szM37MtOpjstv1tu1se1tfe/ZNuBe75wd6CGFkZn8FntJaAfAvQwifutf9RYsWLVq0+7P7SiwKIfx73LlAzR+yzfVbAIBux9+sA77tq0SeQqBDIlu+lFG1AjacBwA0qoQbuf827zoy6m468rl5yZH5s5/yd40RqVb4xp9r+RuyGDoKXFhyxNVa8P235iicx8MI3aRsTML3cWJAViUiF+oVNi+EZoV6xy3NhAx8KVG3nIjJSqSl7YTU2Qaha+6+EBJLdvdZqSRsg+9rxLYVRH9mwhXGfQmZh71nsvu9jSN06dDlRcolPQAuS/RXhBL8T4qY1Gre1l634Hk5qqtwmSX0gKQLFYj66A1UU7+Wx4+6Guvjj7nX9dgjj3A/3sgXRj6ernI/odtG6DqSSunRFKwc1iOqG/BWaW/7dlvbjrxHGREo13f6vs/BQFCV14ZIH9y/kGbA/mMiI3KDVZDy2glZ6kInvAZVjodq1ddbiZJt7yHB3ex6jOU48Q2qk14cm6bPAuiWAKMh7yOi2UlUX/D+go17iELm8oTo1CK/DX065TMgaIBNBIl1vKQI5Zis1v03adU/90c9HmPI9rM/U95nkLfh1xoD377e8shBkvn2jZkG20CPue5ou97072s1f461Gh5aDqMhVldWAADrq+tssbGN9CaaLfYHV+sBc48WU/+jRYsW7ZDYVFP/Bz0PSJfAI/c3ZOAbMCd66XccFe1s+FtuPUuQFr5t3nAkU634b5LC38I1voVbNX+LErxge9vjXJcYrw1Ea88+9ZRvT0R+9KTH68899hgA4OQFj8NW5+gZ8GUNovJkBAiYD0c6IV8kRCUJ6vv2g2KjWSY048uJcHW5NKI+xaKLMvZJtMIOrZiVfVvCdy6FZoRaK/IO+I7POTdQwmkheyLu4YixU35fIZISYlO8VQgKiqEWAflof7XU2Rl6SyO/Zr0OhyeReFrztvaGckW8DQ3GTE8e8zKXb3j94wCAJ177KADg+BFH7CvXbgAANlZuAgBWr3oMdOfWCoz90qo5YqrQ8+sQaecVnQcRe9cRek7E3i98+x1+Pxj42K4kfq4Z/RF5LBXGflMFxCdMgN6KFEFovpwqkQfHffEaBjmE3Ie6WSiYIfYSoY+EqvnDCSetXJZDiOuLsOe3HC86pto0HHBuiXMKw9E4Ytd805BjV7+bNI2n0o9hY+Rx5vTM+4MhugP/bi7xa1ir+006w3GSVDQ/4vsQ8h5wH9s7mvcY8Nje1rW1m+wAb0WvN+D2Hu+u8hmzvOTj7MQJn8MZ9ntlPL6746i/3fZxoWk2nV9CD+Z+a0pHhB4tWrRoh8SmitAVE00ZI62av6XrQnmKWxONj/r+dut3augw3loherMa42ZE5nNzzpg5fcaZNGsrzi64dvU69+FI6sVnnwMAPPsMi8/zoMsnHO29lmju9QNHWKceeQ0AYGZ5EQBQMjGHQJtlcwU2BL748kWW7v/+TEokVPB343HHEjUT1fT7jihGA8Wpx1F3jVCsklXKmHewcdaKEKLi9fos1ksiTKTYOE9q0PN+aHc6Y99nZJA0Wi1+rvJoOg53Vylwm6kEMCSJUcPPfzDrcUbFboUGez1HO6O+I6pG1ZHYow/7tX7itR47X5z3tqxcdxbCxz76OwCA3/qt3wIAPM9rP+j1MDdLVMcxlzG+appr4JxJyu9rRPBJJsTpvwtE4IO+txEF47dGhgXjufIIbjcm2p1d5FleI3ZEn/seMr5fZ9uqZD8VvOa9rl8rXaM6Y7ypYuUcN5rfMMZvTfMIYigV4+i5KIqS3SIWi7xEtWnE74Vmh0OxVLhveRkTbKpJG5Vjnh1c3lO6Jzh3NuqX4ecdMkYaJnSvY417/tC1YpvbHSF077eNTZ/ju379GoBdBt3Oto/99o7f8HOz7rUfP+7jrzXnbJjRoI+07g+ILs9jk0gdVT9Glc8P4/xPku3vxd+pRYQeLVq0aIfEporQ6ylni8X2JuLSbHROZMKvgaHQzQgVxtlT87djjW/sasXfykcZT33iDW/wY9UcxT3/nKOyVb5tu+QJ7/Dt3OXb+daqz04/+xmPrWecyU6IRM+33ANoEQ0XGdBmO3Oik4pQnVAuZ9MnrWQfELUFEar5vq2UiMl3NCSTQihI8FesF9uD8BU33BOA5zqyWxLF64lEGesU2k/EelGclnsTks8ZTDXNe5A6UbVxL6uidoQcwyB2/7gVuV/fNPHzajXFCCHvvCPPZIe78u0XF91bevicz3ucPu6f++1NAMDvffx3AQAf+tCHAABPPeXemFhVc60mWrMOlRQP1byGWEAVcpyr9BpqVbGEiF6JghNe4wrE6iGzQmOcjByGZ9Fs7K21vGtXrrkn2e30SkaMkHObA63XZX+J5ZJ52zT3srPjSFLzHeJAi0VWeh+aBxFyVyyeCDbn/Ic8hRBy9Im8haDLfAaNYX4svUnlPRCZi1mjfd5uLqFLL0OxZ14O1BtiAfliMCyw06HHQuSsfpPH3OdYVVvk+ee830KZ7yEvwrdr7/i8mzzi1RWfy5P3MTjivz92wo/bpjdRDAMGuTd4yAmIkehymT9P6rPOda+2yP4J+4+HO7WI0KNFixbtkNhUEfpMnUhSQeShv4V7PTIHiEAHRI1bnLXuD7olN7dJuskMs0yVDbhALmitSSTdYlYYWSqXmd210/a374A89G1mdq2sMaPvpsfQP8PM08bsHABg+bjPZC/NuydQAzAg88XIxSaNFQ3GhjvF/t1dIiUigjASc8S3V4yz32XckkvFBIUqs1QIzPsgTRMUQsOmOKkYDYwBc1lmSCrbtIxtEqlqWp7wLU0dDQrJ63Oa+LKSEOmWXoPYDMNdmsGEtXccUSsnICejpFIycrx/WuIZL/m1PHPSNYtOn/AcgvkZb8OVS65E8dxzn/HPZLWIrbF0zLdfnJ9FTR5LybX29taJZhtzfjEzMnFCxdvSYQZon7HRYY+MCiLxXZYQESrRrsZ8Wt8/ZvriRR+f7U63pJ/sInS/T7pk1KSMnTc51o0UGW2nOLXmVoTQ5fntIm95cWxyORbEplHmc4HBgMh7ND5ONJa1HHEsD0fy6Hj+FY0bjvFi/4mVwUBzEsxFyJQhypuKnmG/P0CfnmuHnlxWHY+754EZpBzLKbN7k4oyTNl2Xrs6j1UMx5lNJiZdNp7B26fHp6xjFECg19Occ6+xML/eyyfOAABOnX+Y+2AG6aw/b4aXV/btj5eziNCjRYsW7ZDYVBH6/AzjloxZKfbcJl2kS4TWo5aH3oD1RgNdckXz3WlvALtaLTXGC4U6qkTyadXfxmJhzKWO8upkyXSYaTokN/UZMiHaZFYsLTvX9NHHne1y7rwj9DqARd81WgyT1cVu4flatv9MvrQ6duOQRMsKzzIG2iYKlO5DUmaOipfOrDqIAx5K5C2ELA0MoT6h/CGRkzI8laVafibCEpCqcK5C6E782aDMyDINcWKZB9wmORJb1LFQ3FnQShxdxU0t8WtpRFxHFv0aKm7d2Xakv7XBeRLmMVQ4mXHkqMctdS2TxNBmjkN7u8fm+r7mqNWyTDdrZsFR8JDMmu6Gbz/ouKen+Q3lFAhBlqQhouIqY6iaC5q0DTIpOr0BjCg2zcjDZx/3eP5CmqnRKyJ6NQ5A5R7q2ElNKJdr5CBLh4fehLRi5L1UymsNVMRuKa/leIajspo1joYlG4ZoX3MTctY4zjYm+iHjOJPnXeN922z4dRjlpdoSRmTSdNp+f8hTychIGo04XyTmVxjP9yjYj4H76RWc0yv1eHy/YtK1ZtxbXyCbSpnNnbaP4yRJkdErml9yhF6ptvjZx9XSUX9+KIJQq/kz8YWI0KNFixbt89umitATIoEKFItizIpv4YEU3RhDL5QBWbFyJrrKOFeLLJS5WV9WxQzpMr5FlCaVu41Vj1UpJjfTcNQ2y8C3lkJ9ww4V/bqO/kY71KG55UvMzKEgCgnkteY8j5yxyPattX37oUIWh6jiI26vuKF0QQZitxAtC/T2pXlSIYMi8+3SsEejpUwZHY+Jq29LlcRSfHFc+ENAskq0IyJOGSMdMkYqbjxjzNpfkojBk6MY7s9y6an/OC40HnTsCuOM9bK/xj27m9ecL2w8p23GMheZk/Dw+VO+H6LrjPMs21tb2KZcZ4fMGDGNNEcjTvtjj7suTGg44nrqeR9Pm0T2PY6PnAqG1UzcbvppUvpjnD9Lb6NhQi2XLKki49xRlSi1zrh1lSwXIcx601FehTH1Sj2MrZcmUJWxX3HgS+0WMrwUO5cOkFQ+d5OOc2SJUPyEVku5DRkmvBYZdVUCEfWuAqS0g/z7SYTeUl4Dc1Pq9MAzMnr6Uooc7I7FEe+XYU/PFz4L6DWKHNYfaH5JHrHftwVzTow5AykZSprLmaM641zTz3luhh4kL7Gyg+v1BmrVeR6TB00c9StSUOX5NDkHKB7/vVpE6NGiRYt2SGyqCP3KJS/CURM7g28tYQG9QQc96maQYTHozGIkHRi+VVtEjgtc6sR6RIYDIq/2uqPkzpbHPFtUUCtRo0LyxC1Lc47iFKc+veRxs0ag1vJ1P4ctS0rN4zY1HvIg3RN/O0vfe9IUbyxfr0GeiZgh4iGLpTAeC8zZTzsjPydpnDRbVaQ1xiqlvVEKQDI2LmYN5P0QcRGVlcwGIq5hjxmAhdo45PdCNX6gOhGbdGUsF4NneFuEHoRig1TwqLVBcFPnOGkQidIxwYAxz5s33VsSwWSGabznzzujoElk1SETpcM2F6MqsOzZfTtEkmI0zHKe58Qx9+Be/1rX9pk56vusNv36b2wxn2FnN/YNAMWEGmFpZFZUbpMpmjGrE9UKMmYbSnmwKOdFmKU6VFx6HC0rP0F6KsrmtFK0nOwhInHNVej78jPvBXnMxXCIJIizXSZRANhlq2jORZpAVurqcxzkE/kQt0kfbjWE0Iloq+MZyIqDJ0mGKudIqmJc8SkwJCtM2c09jr9CDC3pPdETEhNsJE1/zuUpo73MTqUq42igGDtj7rxe9fn5MoO6x0HcHzEakY3zzeURl9fuHi0i9GjRokU7JDZVhP7Zp5/2f/hyrjEuJo60+OcdoqVEymVb22hwenyZCPrEoqOv+Tq1i4lwumQ89MigMCIIrVcsTihnRHQrvrDir8vUbjl38pj/nq/CDXKbNzY3sb3lx9rcdMbEBj9vbPpym7zgR048OtYPio0q7iyEXeo70+uY4eUSulGmYE8aFIz9FQOi7WYFVRvX0harQOhXIfbdWLdyA7gUQjdlRlLREWoqY5jM6DPG8RMyUrKamASqkJQjyfdHY6l0LLitdEK6jMtXuK8ZMgVqZCbl7NdeqUVOTZwFVrwiP1ua5qvPOaq+fv0GDzcqx0OVVWq2bHPsvLWU5svRZd/uxLJvN98iKiPyGhXijvPzSLxt5lS0ifKaugXHb0Wp9OVFUnpiYlmEUsGSsV0hbdO1oVc6kvJhb+J31HDpE6FmJQ/GF2V8O4x9HnF8jQb93epZkLdIz41jcjTUnInaBm6Xjy11jMrLQEuxYkalNhHHc7bLgikYn884xzLqqQqQe64bG+4hy9Ovz86wDRyrzP5OpKsixlbppfq59Tm+blLjfGXDx19ad2bK8nEynvKAmXl/bvQGyq3wNnbJprvFOThd4x7H8r1aROjRokWLdkhsqgj9KqsJKQOyrIUotgvfWh3GphPGdzfW1soYeHvTl5urntl5/qwrns3OOJJqbzm7ZYP1/hQnmycPOBEHnm0qNV34dhcDRfzQIZHH2oq/7W/d8uX6+hqGVIPsdhy13bjpDIiLPM+dzv4IXdmUIVFdT8bTGBNUG8rsOCJcASsrFOPzs6hJaxtAaoorqooLY7qkjgzzfO8ud7nK4oCzjSVSVeZnnYidaGXAa6RClYGKgEE64kSPaciR3bY6jSMj0aMDFQq73Fc+EkOH3gP1eepkjFSUAZj5tWq2mGNA9LzedpS0vuXX+EVmkqYWcIyIW+ypHeZCbG36tpdevAQAuEG1zqTqHuE6NX926IUpXg1myhrPSRmVbc5BDKRtgqrOfqwvdgv0hDJzNmgeQvU1GXeuqQoX514KsaLamiMgcuWAkcqpadRLj0WXpdRX97bnypOQllI+KvMalCth4qETJQvcC1mXaQiqUyqtmyCVxv11jvpEtlJEFLoWC6jUmYEhlbcgr5H344Ca9SPWoA3KmeA0RZFpfoj3ihgoqc+XKb6dcjwaiPypqbOxQ+QPn5/bJA++nxvmFzwy0CPjZm2FLDly4jdv+XNpYcGRfLiN93qnFhF6tGjRoh0Smy4P3aTUp8/jfPSE8ccklc6zv712djp46mlXzLt42bnHn/qUqyKeO+cI/fQp5xyrUneV3OPqjL8JpcrY55t/bc1jWVeve1zsxjXGtnKqvRH1bA80S+1v8S1ynYt8gIVZaqgQnQXGUUdEH6oAPmll5fSJ2qNl7I5oOhEhm+urrJY00/K2FJw/EMfXEMq5gCA2Ql7CX9+npPVkEzVElQpYkhCkCyKkTr7+QBrR1JnfWfd+7JN4Y/QesnqKIAg+YTUi7iyT/rf344iKdRmRqLKAF6jLM0tElbL/6vy8tOiZoEdOejaeYugLi16tSuOr3+uhzexbUWS2t8lY4NzKFj3BLbGjiMjbm3792xwHHcZAA3WKGvQemMSJIehtEImlg/29FaFqKwyZasYSFVcyeWBE5opxk/HVZU6AYuw1eh1NqldWdb+VzBMyUib00SslIhXKJopOCyTioXO+J6d3oNyS0qMrx6K0cpRRLB0ZsWH274chszQ7RMPyXutNuQZJeY7lXADv2QbrdjaOMDN41p8FklbXeBjS8+vv8F6RVhCRea3i47LJ+p9gv+RlzVZqLUkDXoyWfh/djrx2/806c1E2N/28bt5YYVuZNc+x/bqFE/v2x8tZROjRokWLdkhsqgj9zBnn8o6G4r3626lG7mmdy5CM8203NrdKtcTnXnSWyVOffR4AcPSYs1DeQB30N77xTQCA8xdcK3t2wd/WEonbZiWjlW1nPLx43eNh1646wuwwQ7R6xRH73Iu+lNcgXDE328S5U9RtmGUmY83jrI0ZxnL7k3Xu3aSap3iisuw0pyAOb1ntveQJ+7JFBUAUZEaMdjnm0kwv9StUkaiqKuzj+tWmCvOiHaiKOzsslPrn45XiU10jxpC7nPnPWVuzYJx/Zn4GdTKHoGpPtIwZjg1qhDcaiv8r+9fP88i89+tJMo/myBIadcUC8f01mIV3nHoZ4rmfv3ABAPAc2S4r16+hS3aGTrs5Q9bUvF+7xx73OqWPPOrzH/NH3AO8dtPPb4ZVa7LMx82gnA/imGYsfVb6IeyPLN2/lqaC0xUkqKaK4Qphs1+UzcuL15Veiipfcd6kSS59q0VVTtY3rUCsEN+NdH2UcWnSR6I3uovg8/Je7PbE2qBHUZF3Sf0U6RLt0qi40PyQTmH/GHpOr0PzU2WmM92MjJ53Ja2UdQfkIbfo8c1TIVWKoNtUY7x60+/1tU3G1ksJISo4qn5swVJkQ2kKiQHGKl01eiXM0G5ynq7ZqKFJJlbC68mP5X2xRuZNwnmyJrOXI0KPFi1atM9zmypCP3bc0XSRi91BNgeV1JrkcErTXG/9ra0tWN0R1C3yeQfXPBbFly16fHum866VPXfyHABghnG0Us1uxWNzW3k2ttwu/G3epsbHsOsIYpVa7S2+9VVZfDRIkW0ze1IIKmVcjHH7+mB/hK7KOaqYkpQohoqIQXr1QWW4AAAgAElEQVQVjFMywp1pu8p41SGhosEwL9UmVQtT8T5V1tG8hDJEUy2tLOjqbWAMPM2U2ef91CYi7ymDtCemBTnhXdWU9H5O0gQJM/MmEbqq2Ui5sUaOsbjODSKsI4xLH51lLJ2c9zbb2ibLICWLI+Pcwzzj/cePUgd9wcfQjSuXsENe8By5yUtL7sk99pgj89d/wRcCAM6dP+/7ZLZqi0hemiMNIqwc8oD83CqM6zfnCdGI0KuJYOHmWF/0mQldsRRpUG1M5kqoLmypsUIvaii2GDW4GfNdWPTzbjBrGMxszLifFmPN0lXP2d+VTNmZzKAkAu71h9ggUyjZUpWxcXRfECuWGj8ah9JgL70LulO3g5bySkuVGDJ0ivGYfZHveigZf6Ns5Tq9o+Vl99QWlXmdeP+k6Q73rGpKvtzZcm98k/Mnazt+rpqLqFTZ7+yXJvtxhjkNtSRBi33eYJ2A/qIfc8CMYpVTKudU9p9eumOLCD1atGjRDolNFaFXSjaLI4P+0N8vbWawDTr+1mpy5rfFTK7m4gyOnPFtj21I2dBR8CxZLfUlj3GOMv/NRs/3ud7zt+3qui8vrVKFkRzUQUrFullH9o0auaiMfwsNp0RyNaKgIgW2lKFIND/HWFtS55xAa27/jijrfDJGWlVFGVVn982kcKjaooWqDaniEYSmpfAHVEpNcXG4ieJ7KlNPTQ7GrTNTHVRpuvCdX6b6+foer80Wef7rG8oVcIR69KQzTGr0CHpd7+9KBmRNR0yrk/2QiAGhWpBEpINxtkWDSHyOYPfojP8zY46C1tkPDdYmzZkXEKh5M0sGyrFFv4ar80302v6bZX537pyPn0cf9Yoy8iY1J7G54udza131JcnRLlNoxfNnPc+EFbSYz2Cc70ipCTSJ0LvMh8iSCvI+x2abtVTJXqlXpWPivxlIT59e40JD95f0eujpUUVQTJVqTbx9epuhMrYsbLwOaKWaIKszxs+aoZkmpUZifGjQco5AWkLSR5EaY64qXPtnSIqpUoFfFw3DjKhbtO3+cIg+vUFh+R7nEMSSajT83j6+QA9t0efwNreZASuWWS71Tp+ne5FtX111Rl13wz2cCmPnFd7naV1UJnrq7TaGmTxeng//0TiThx94X1UZ979Xiwg9WrRo0Q6JTRWh90uNYH+zdfjW3uZbPx+yZiLJzHMLjKU26ugq/jXvyGlmxAxIQqRbbX97fupZf8s+e9njYW1qjmyxMvgWs8e6jE9LCDBnJiASZi8mfCuLw0v2grJakxTIOU3eJwNgwJl4bVNTpfIJk5JjhW/z3crzrDykykWMY4sVNFl1KGB8P7VqpYy3i48+HCqmzROVDkgiTjNZMcoeVNUXxq9B1NYlU2DjliPJ9pZ/PnbEPaXXvtYrOp045uyPbttn83c6G2gzhrt6Y6IfpLbJTu4xMzFnnH6USFOD8VMyIKRbXSV7o8G49KjDbN7rHFfSauc8yIklH0P22FkYWQinTzu74MLDrnt+/uHXAgBOnnCPQ3rVN2/4mFynFodi3iGM96t0eTRnofi2IGu4TS1NVdlJgyHn3EublXCk7V8vNVhYnV79xLE5lMQmEbra0N9xr6Kh8cn+lmfXpae5yQpZO/Q4A+RB1krvcajKVvKmlM2qIapatuX5ssU87z6zgLs8N+XNyhYXfTxZQYTO78Xa2tkhuu71kKlOq7xLPlcqqTTHfSyePO3zaadY+arTFSvM9ym11JbYU/LOeQ79PrOC8x3+zn/fZ2buluQ+8yH61JFRXkef91VC5tYx1rWdnfNlhSqcWLsN++llbKoP9B4fMgkHVs7Jlz4veqeQL0kJgB0mSowStPlA6cotTJUK7Nuu3PKLss4LLqGnLU6G9kv6Hid+ePEadT1MJW9JGtZgvJCz0qYNumENJuqVXFT6h0qIsXxcMlOmiUm50ipKoVtdhXK3dsZFqMqHMJMtqnSJGypwkKXlviQ3KnGoYV90Rk0y+bFUmEESraIpZhxoxiGzse434gYlEAZ8UYp2dYqJXWdP+4Nw85Zf2xurQL69bzegwnTuAR/Ug54KhvCGU6o2byy563oY6ME3YHLPrTVP4hiQ4tpnPymcsdj067H0yBkszPnD/dwZp7eePus3/eJxd8vrFOXaJD1PNLqE46BRF42Tbrse8BrCkonlw0EPtCTff6K82VDR7QqGPU4wDrxvKxpXvHv1gG9zYner79ekz2Nv8/t+j6nqqy5fMMsw29qqv5SOnfBr1hv5/lfWfL/X1/yh1CeQOLK0hJMnfIJxloVlBnyZKEVfY1eJWbmKkJcVMBSD4UvZ9n+xaWI3Z3+P+hKkU0ESBwfFKKBJueRUoTuO/R1ue2vdx8nCMl/8lIQoExdLuq/uX78GKkOoydJRYBJd11+Mm21f7vT8QS+pkrzoo93WJDDlFEhPnF3wYy6RwnuMyW96Ca2sXdu3P17OYsglWrRo0Q6JvSxCN7OzAP5vACfgL96fCCH8qJktAfg3AC4AeAHAnw4hrN/NwYd8XdeJirOUiUR0WcTys1K0ii7Rdht9yXTyxV4Wf2ZadMbPmsiRK5yURXqVmu1vyDpLjZUCR0wqkN58lWimIGKV2L1iNP1uHwW/q3KCY1SjOD/pTXab1+eAqE1JPoOMRaB7DEVRKExhom5f9EW6lnwv15k4M6S3kdfzMvFHssFlcYSyoAXXq3gIRYTaPFaHKfByPpTcI4EsJbkoWegoqYAtZlAURFRbTKC4tbqKra4kEBbH+oFgrjz2gMiqquiFRJWUtMLJq15fEr6kolIqeWOLSEouHz2XOidl54+4C17NEhxh8ecTR/27RSbh1BIJXTG1f5vuNVGvSqql3C4T0mTiiEJcQSJS9CRLWYcym2Wcr5ZrBjzsSsXWmuOTlzWGZbY2GJ5hejyINBXSXN9W+UWPcV190ZPwmrxX2rzGzBFClZOHQrQ3rrun0+trDCVYIKW4yQl88H6xgeiWbL5CMkqHV/KXRLYkw3sbul6bIdFtFfGWFDXpkgN6DbMzC5gnJVD3/A6v/8VL7pFsbfsJ3tryNswtOPGhStKCvIieCmFIboCIX4WdMxIwOn2GgdZYiGWF3gPliof5EKbEsSCvmxO0KghCX2bEG8zC/fEW7wShjwD8jRDC6wC8BcBfNrMnALwTwK+GEB4D8Kv8HC1atGjRpmQvi9BDCNcAXOP/22b2aQCnAXwrgD/GzX4awG8A+Nt3c3DFSutCNUS4fU5adUmNC6RAmSZ9BiOMiJAUq0zCeCxYscuEcdk6Jx6TJiczM5WdIl0vK3hMxep2xn5H5iQCCzhkbGsguu5sbZSiQKMOEzuqpD4uMFYnTdEJC2Vqv9LziWrKdGiJVZFSqPkSyewm4+9liemHUUBNsrkqCCA5XaL4Mr4PFfXVbBavBecv+kRKjYyIqOkUzONHnCY6T0/n7AlHMS2ivz6pdhuMZ2+s3UL3NnFjEHkX9HA0mTXDePI8i09IyEjx2k0KOA0poSCBsIL9qUIYVcZMFzlxO8u4eZoELFA+YZZ0VPX5JkW3bhIZXlnzfa9sOtpbYVnBLseBlQVAGFPm+efy+ErZZk0269q1xrpimyJgLtVAVEcpgxaloes130efx9Y1rdJtVZmzUiBLk8plYebxYtBNTtrPzDlCz4ecTF73e2KLJIVGYmix/U0i8SFvvEbVv2jwmsm7kHfZ54RjR2Jo9IxLWi3GrdAkvORn1/2+X13x8RT4CLOkjmOmY/t17nMOZnOTE/Jd91A69DRacz53UCNCT9jPoqZKGEzefZ000EaLYl5KOmRyE1jwOykdwgrSmqifOh8lI/myw3mNlRUvWl8x3q/3GA2/q1+Z2QUAbwTwYQDH+bDXQ//YPbUgWrRo0aK9InbHLBczmwHwbwH89RDClt7yd/C7JwE8CewKHcny3N+AFlhiTvEjFjseMYaqWXwV1s37QwwZLw1Eo4lixIzV7QSJ9xC1cDY+JQpJVaSX1DhBg2To+60HikllKswsgSTfjgAUXbJo+tbFYMT4IdHWrFgULI9XjPaPj6mcl5CUYoBgTLzCeKNYIHUlbQi5q2DuRDm4Tq+NbiEZAncxhMJUGm235JxS1Rljr6q/RMNj4gO307yHWA7HjzrqPXnCl4uMSbd3/FqqwEEIVtIrJ63FdHq1pUEax4lFHzfnjxFZG5NRbhFxEZHnQzEseM5sW8IklNaC72eBqf9K10+TgBbj0lXGqXd63seXmED09EVHcy9cY0GVngSx6NmpYIVEpzhQJL884v4qQQwl0mGxP/NpOFS5txx1IsgGGR9KnpNoV5uyzPW693lLcrf0QoXMG1UxK9y7muP4PE3GynkyfJaW3LM8uuDjucGxssWY9OnTp/HIQ87+qZHV097UOPP2H2ExdRWavnzDEXWb8Xy1mU46Ml6rSYR+5gLF0Bb9ms2QcZLbswCAm5T82Fjfwvotj7Onklkm/bfGfedk7/Q5Tkabfk2rXT2HiLyZJLbDsTtQgRWiat4aqGRkpaWa7FOCID+iKAX3dotkcE6PcySSZd6gF1ThffZQ8xzuxe4IoZtZBn+YvyeE8H5+fcPMTnL9SQA39/ttCOEnQghvDiG8WbSiaNGiRYv2ytudsFwMwE8B+HQI4Z/sWfVBAG8H8ANc/sLdHjzk/uYrRh5HqjCOVmMST6PCN99QBXaJyvsDpEMJMPGtqTJuKjCswtJErSnjijUi0AbfmFUGpPVWbTUlIkQkypigCtBK5F9846ROFkQtlHHqhQV/hR8hi2L5qCOqUY9obDDeD5WKkpTGxbbK5CW+d1MJ/Yj1obxnyZr2iOpUPLrfK4v1Nmo8L6K0XHxhyZ6KOcKwfZ9c96Ep/sw5B3oTUhFKlMTUkDwDpUNn+fLmPIBYRFmtVhbZxYRi6iwR8xyXM0z7PsU4/fFF8oyZaLZFVDgq50vIliIjyRivDuT29gtv+3qHbAZyyOtZgpFJGsL7cKPj6z5zxeOvT11y9Hf1FvMYMF7QXHM1LaLf/lCyspQR5jisMcmnmuzK4+5ndaLLIt0tT3biOMWl6GmISaKC3hlj6B16nQOOi3XG4wdkbaTLjnJP0at6jJLAr3uNJ1OdoIiVGCYneTzlQ5w/fwEn5snA4hzLxecok8w4+3xdCXd+LTYZS64o+Y6y1KMhr1l1f4//j3zpH/Xf0eNZu+le2ZH/8hEAwId/878AAHbWN7Cx4ftUoRwx3VQgJpVUghKt6OlVTBIJ5PszMa3IVbLQr/0tFn3PWeCCUzlYWvJzWFyiR837OBS9kj0mSV+5qmLyqbD8NnNsKkyteuihe0PodxJy+QoAfx7A75vZx/nd34E/yN9rZu8AcBHAn7qnFkSLFi1atFfE7oTl8iHsqUg2YV9zPwcfDhX7JEInyq6Z+Mcs8spZ6T6zQ4tRgYxoeJGsBBU9ALmkKu6rVFsjOyVlenimmWgVHNYs9J60XQDY5uz8Jnmw8gCaTZWpIn970MGIv8mZPTqgRGqf8dA+Z83rNs6/lsSqik+UWYQqEVayFFQUYLfEHLCbWRp0EipVlxgq5AknnAsYEjG0lWnXURFecuCHu1xjYJefLrSsogkZ0UzgNdO1U9FtjZguIf8245Kb7TZ2yNMlyC2tKgaOihkzZhmUJUjWk+Y5xH0uCxMrrZ79IcLONst/rTJu2889dmqlZLDtFuggYh5I6Kvv31+htMHGgJl/NeU5MO+Bcy4SWMt4LeqaFmIWcJp721Uur6IqyxM2S4ngIgcaRLcqBt5tU+jMhP58eXTJx1VOr7VD9suQeQw7plJ05Nwve6z8DGPoxxfIWCInvk6myqDFFPiqt7WFIQYUs7vy/HMAgD/4hGO99TWPvC4suqeiAt3bZLXcuEJOOCUTMuV/cFJqUhzjdV/wRd4f7M/Nx5ijwevToVTypeeeRcFxpULdKgVnnJNRyUYxkSr0kjIidrGGJLcrfefNriN/60pGQ5LAYNs558Nz0fjNhwVSMl9SjpchnzeSzN7ZohdACY0svb+wdMwUjRYtWrRDYlPVcikoXDRgzC/0+Pbq+Ruxt+Pxpa11oWQiswJYZKxy9ojHW48xvmqlGJW/pTurjqxVpLXSI/+3I0QpYX5qdEgQivGzHmOg2+QhC/3OzPtxW01lTgZUOMW/0/P23lj1GfhO389nwAzJpbOnxvpBscmSj64sQsYnVVhXiFIMo4LMCgHzsng046/NGSCRQFGiQtu+aZ+/7ZZZhfSC2JYOY+sjpg82iPCLI+TwNskUmed1WHJ0VyGLZpNx/IvXHbF9lqUCn3nhIgj+sXB+rBtKnY6K2Ai8hrc2eZ5b3g8tTkIMGdtsMw4pGeZyXoPoWJmBl276dbjVludEvn9R7JZXky7OjJ9PMuNaNG0ylPrUF0qVocw4fJ9eRE5dj866szqG2/65oJdWISdeUrZW3V+wTegxH/Sxcs33cekZIlCymHQtNd+TZuPjpM9re+2mj8NVxp+V1Zqwv1N6URtXfb0KNOxQGnmVDJUudVOqtSpyeqpXr1D87rOfAQBsbvq28xwPy8fcC2jOew5Bt9QGYvarPDx5lRMmD0jsFxUOXz7qjJwnnvBSk0fm5tDe8vkOeQkbKuCuQuji32vfjHU3mJvSoDercnmDkbRcWGCHcf6RygfSw2zO0FPi7zN6VLW6oS7vih7gJllxyobeYDZum9/LM7tXiwg9WrRo0Q6JTRWhK9bXY2y5Q9lcZXZtU5NjR+WatAwJRnWhVQrsEzIVRFgDakpsESG1yV5ISq0X6YKQFcP4W0FWRpJIkpbvc82Qc7bdFCfjK9HSBIFv/A73JYS+QinMHvVA3nT2LWP90KU6m5B5yUMnSisY91fWnZVLb1s1Uzxfs/tkeVhaqiOWErzisDMGnqr8GFkJKdcPCuqhbHi8docyoDXy8c+ccuS6QPnPxRMsJ8i2XF3za/j0pasAgKcuOpK7dO0mMmbnTiJ0oVgxc4xzLCNmDmdddrZADLOFR1I2JPugwjhlIaYFcUstk5Km/3xAj6bf7ZVzJULtzZyoLaHHRvaBlC3rKosnr4njb5PFNIbrjhJzljETIkdQHoB/HOUTlCdaYI7GoLuF1esed14jUl5fk6oflRulzyP1TRV1VrYrud/iPCtj+dYNb+MLzzine7YmbjzKfgGA7U3//YgFQrJqdfc+MMnlsngIcwbmmY1bYwaxPLlFcuqH7EcjMykQiXc2Vsb6YXVFErXMWO5KI8f789w558OfP30MXTJnrl2+CAC4eMnH3Oo6PX31A+dSwOLZViFnnuNCcw6a+xJLZpaKm5WMmbTGyELhyzajAKo4MttsodFUIQ4V2GbsXOONx1KeiCIP92oRoUeLFi3aIbHpxtDJCe8QPQ+JVjQ732c2VUJUmDcFzRKkVWk/MBYsJkSuDD4q7/H7IdkraZB2iSJp1GkmoyJljHOGPOpMvO1SsZ/xx0xqhSqlNcKQCEYIfbTJjDS+6QdElJOWS/S+Ml6ktmSvEJ3kjHWKaaMi0lZJxn4npokhlKW+5GlIF0fHajJ+qELA0oIOZF9sr9PjIeddSFMaOE3OJSRkRGwyzvriTS8wd3mNWtE8x1Cr76YTTpiuifRNpO8uBTrlBCguWWGBgoye3kC0FnpPgXMJs8x0XCIzIp1hdiO1PtY3t9EjGm1TL3+nYOy7UPEH30eN8eVji14I4/RxR6QZkffFnp/34Cq9DbJalCkrHZ7hjjJLJ0s6uBUqiJHkaEprnVm4x5b9mJ1SE5w5Bcq05vnm/LywxLmqgbJ+/di1bJzh1ctVVJtMHer1zGVEsqb+z1DnuFlkFvRJemzLxzxWrniyPJ8h78tM5G22ccCxrXt+shBdn3M43Y4QbYdt9+tw9hEvEbg41yznMa4TtR99/gUAwGeecSbOU099FgBwc4VFSXjMOWrX1DguhypY0Vd5QM4bUSOmRtZPf+j91O5I9VPKmWS2JCmyTMWyfR/bnM/p8jfKjl5ecg/3zKl745/LIkKPFi1atENi00XojPF1idB75EJ3iCQCkUKNSni1BqFEjjJTcYv85qTkifsmypYDkXytQo4oMxpToUQi7pQl7GpEmi3Gy7TdoCzhJobBaOz3w2KEUaH6daxmpMpDuZD1/lVZ6oxjZxWhQJXOoq46429DMnFU7kux0CwVn5qIXUwfs1J/udSfFvc6FcpnHxN5qsxYonMZeIx8yGt0dMnR4cwcdb3J6d3k/MAaWUU3yDPOCU2PnXFmz8LxJeTa94TpvCrSxzeVvSP3mEqPFc5nCKnr/GtEQUNTCTb/eZWezIz0fYh4G3UpdA6xsert3GEsOPSphd3mbxjjPLnonO0vPOf98pqHzvpBRo4ga9tkWLzA/uxwfkNeE1kdO9RwV5x20pRp2s9ztJhjcXTJ0e+SyrIRgQ/IhhJCL1gVZ1RIu0Tqnew/G/fCOswgLShIX6eqY10xdal5cvymlVDWCWi1/DyXmXWqDOFtqkzuPOfx7C2Oi8pQSL0URPFd3wZbzlC/JuG1E9uqxWzg4/RWFjND0fJ+WqBm1PIxlqckv36bma8vvuix9Ruck5ihJElN5SR5vronVHOhyTbXqQ1THdHbV85Fl/NqijR0Cow4DyRvoMfSmK061UqPO1vnEZY8PHniNABg9Zk/VEL9jiwi9GjRokU7JDZVhC6dB8X0hoyH52Jx8A2p+K4KFBfDUaljstkb162QBvRIcdhZxlmr0j+nAp0K4/LYlo8XWB4ybiYtjl5fMVFyUDNVCZJ2tyExxXqp8sbMs3zAOHRyG4RenqeUHcVSIRMlSF9G71/G8aVhoti54uTSVQ9WMh8SIqFRTVWiVElFcwGMOxPdJ/NUqUwcFY6IGJs16WMwc3LTkcQmOeErq85uWeNnsWdOzp/g/gt0iN76E1MKQxXqVoFkDg9J1tzaUf1IZjySaVEplPkndpA6hjumh9QgSm7RA1qm3vpiq4YGf3r6yNxYP1RrrA7E/jtPT+OLHvXlhbOOArep3HeZGcSzPEZP11YFwtnPw5wVd0YTgja0NeqSdNs7pR78EY3hOUeg9apqjJJ/z2VBL6vHnALVkVWWr0TyNCej+LSmlSqZ4vqaH6I3J93vMEKnQz0d6nl3OGeS35BuuV//557x6kg3bzoalvrpgtQTyerIavvzr2epIZQyC3hEddWUDLAOC1mHeoqU46HJTM+Hj/o1aracabPGsfnJT3wKAHCJMfZLZLEY721pCqnfVAFK48hyVS1jXkSD14PzAwU1qkajbqkq2aF3EPicWWLFpwtnLwAAXvOoF1U/esTHU0To0aJFi/Z5blNF6PNHHP3VyU6o8C1mKVExY+rBFKvirHw1RT6QIhpnpIXymWVIckIZj5WWSSENEpNuCr0C/l7VSsC3bFkTkttJD2JuxpHbLNUFk5DDiOoVk8sYL+0yRrm1sb8kTpVxeilGiu0xHKhC/HgWXSUVy2Oc3aJYnn7v7BiVcKJaJD+rhqOy4qyM76uivDRrqMIodgzZFx3yra/fVBv919LMFnOpQXRUo85FCIbhkLrTkwhd2at9XVteS6kzKhZMxLTFa5aW7Bh5I7ym9Ih6rLxjRLCLnB9R3Ldx4TQef8jRXF/5CtyXlPikSb/AakEnjpFvTWi/tcoMwK3x3AnVOxUrarfGreKt+yP0i9c8Fr+9tYU6x8cGtYyeu+reQKo5FyLSTPxzAkppmqhKTpPXQFWZcjGXVDBMbaNnqGvYZj6IFEfTCtBmFvfamvPGpTGec2eKy68ydr7NuqUzMx7nPnXa769jvN9abNOkkglvCeT0uAteyyG9jw166Ou3BqjRGzx32lGuHm4nyNb5yi//EgDAs08/DQC4dd1zJHrkr69e90zZ/oyqR4k1RhVFeuPy3oJyELisK97P+br2TgVtxdCpQ1QyuTjP0aDH0qAyZFVu6T1aROjRokWLdkhsqgh9QTrLynTj20lc8jxQu4JvcfHWE0sQpMSXaNvxTCxlXaq2aE5kqbhhSb7lfpKytiPjsfxcqwr9+OcW+dfi3wqpV2yXddKojcfAO6xFWMH+ynqVUkWRKEReA9HbkIi0rAmpcypBNZE6Ibp0nS0J5VzDaKRq62HsWOJHK04qZ0Bon45NOfMvTrxyBgJ104X0c3oCKRkpqWQtg7JARxiRETJpZdV1xtLzMmSrmCV1zYlyekSFJu9JabscEwNmW/bIN68Q0aryj4Qhl+ZbOLroCFEISgyPRDog7MeE/UfHr9T/7nUcgXbbylD2z7c2qPrJ7FUxLqzCylnZ/l7bVXKlNzc3yz6/eJ0qkbzeOVkp0nIRuhPiHvSlTOifG2RTVYkoe+RZl/MFdenH+3qh6k3WTRU7qVmvlhnVW9TREQOrUnpJVLwkRUTXUhMjfTG25E1i3AuVjVQSgR65qgkN++PLXq8D073M83uE9W1ly8xefc2jzl1//jFfXqRiZI/XbpPzRRnnEurknw/Zn/JgCuVJKFM7E9uMcf+khoxoPUuYzcx7OqeHsc1M7LUbzJDd32G7Y4sIPVq0aNEOiU0VoQslVsJ4fCnw7R8K6Z/z9S4BjEq6Wy2dCErIU4jUKqpyL7EVZTqOa4hLk6Ki+HyqWpvj9QGllSwtk6oIFUTdCazUaJc+tbRVCum8V29TP3KkrMAJhF5IJ2M8dqzvE8aiKxM8dJE8bE9/lPsi2kvLOqblibhxvTJJ0zJ+SH1uIXF6TSWnWbVI+TspAar/8hHZSINBqWg5aVLFGyrjU7UxicwlMpLrGIGIlP2XS6UyiH/t8K47GOftd4m05K0lZnuyJnndCZUKnoiNJxYjsXF+eZPc5LkFqk+SC71KHZRhoYxk8qk5t2DiY0+YdOwbMzPleFB+wYjXVPNE8lJ1e1Sr47kFWTI+LvORvCWqgJbzUarBSn2VXBx5eVQcfyhKLyiVp6Jj8P4Qus2C5g5S9o97tk3qqDTIY1fm8U9ORyMAAAmkSURBVKQpVj7gfJLmtLrM7O0y+3pjYwPbVFu8du0aAODqGWdWLZOr3t52b2LQk7Khe2oZx/ga4/7ybGqMa8/O8XnE8VinuxF4TiVCF9us0DJBk9o1yRyvP/veuM0mNY8uV5wb3+vsn6NxpxYRerRo0aIdEpsqQu91pXDHWLG0E6ThQqSeCXGW6oKGTKyVQuhViKoUB/fPGI8/52UWJ2PlQnUlMlO1dm1HhgQRVpBWd49vaSLPNElKLQhTXVO+L8U2yPP9Y+iqWl9qbUAa7TqnsOdboCwHZOKQk6+umqS22wdC5EGQGRNVkUqN9WTsGIZxnZjdQ4/H6UtOPLcXGixyZS8y5s5zGQ2HJTNp0lQTs+TTi4mkfQjlqqYqdXn0OZWWSVAMndecw1zeRrXm6LA142h6Zm4eDWUES82PY7FQTVrFqckFb8yIveP7mqPS3pETjgqPnvIMwDVy50FPSL+rE6HP7NsTu4yUarVaXm6NgxFRqtwgeUnSFm9yDqeWKi+C513R2PU2kaCFHsdnlYg0Y6boYOTn1l/2VhbY9cLkNXZ5D0v9UHkPUgYdld6Wt2WWyLxaU6x9XBNp0pQf0aC3sXuu9GDI70/MyoxsabrcYFy622GVKHrjc3M+j3Hu3AUAQIexc53Lyg3ngMuTy7Qkstdcn6osJfKcyM4aJKpetVuDt061ycA5vlFZxczbfItIXbdGvXJvlYsiQo8WLVq0Q2JTReh6q5d82ZHisr5es/FlhRWpwFVTpFI5JCLPFX8uY8bjvGrF0CtClCp9aYpPTiBZxfUVqCxKN8FXcza6jGfabixXtUHFNhhy1nw02B+ZdllvMamMT3GHknKiQ9NbEG1Bmi3aXvHdsuYogHJeYmxX5Y+KkoRM9FuMb58Yr4lYLmJ9KGYuz0YdqqNqToO7F+e5KIpy35NWMiQmEKl+UDJxGFNW3VMQqYvSpHOsMMM4rSpnwFHPzLwjtBpra1aqdSTyrsTKENNGpyuPhcfY4bVsk0mzTVVAVSCapd7KMhG76k82Z8drbRa36YxSoXMw3K2mJS9nwPtFGkEjeRGMzwuhc15AlXg075ST8aRqXMqIHDFmnnKplume2q19u3t9oZqoQcwsVd9SosP4mC2rlFE1UVWGAts0qQZOYg6M56R5E4TW2OEX52exxDqmyu7W/E2TKL5KV3+enHflLWipmPnFea+uJc9ZcxFNemPZhNZSyvmCKreT0mSS7JlrkZIqbzxlXuvZoGdb6bzqdrpLiwg9WrRo0Q6JWbgdXHoV7NSpU+HJJ588sONFixYt2mGwd7/73R8LIbz55baLCD1atGjRDonFB3q0aNGiHRKLD/Ro0aJFOyR2oDF0M1sB0AZwb2K/r74tI7btXiy27e7tQW0XENt2r/Zqtu18COHoy210oA90ADCz376T4P40LLbt3iy27e7tQW0XENt2r/YgtC2GXKJFixbtkFh8oEeLFi3aIbFpPNB/YgrHvFOLbbs3i227e3tQ2wXEtt2rTb1tBx5DjxYtWrRor47FkEu0aNGiHRI7sAe6mX2DmT1tZs+Y2TsP6ri3actZM/t1M/u0mX3KzP5Hfr9kZv/BzD7L5eIU21gxs981s1/k54fM7MNs278xU9WHA2/Xgpm9z8yeYv992YPSb2b2P/F6ftLMfs7M6tPqNzP7l2Z208w+uee7ffvJ3P4p743fM7M3TaFt/xuv6e+Z2QfMbGHPunexbU+b2dcfdNv2rPubZhbMbJmfp95v/P6vsm8+ZWY/tOf7A+u30kIIr/ofXDvsWQAPA6gC+ASAJw7i2Ldpz0kAb+L/swA+A+AJAD8E4J38/p0AfnCKbfyfAfxrAL/Iz+8F8Fb+/+MAvmdK7fppAN/N/6sAFh6EfgNwGsDzABp7+us7p9VvAP5rAG8C8Mk93+3bTwC+CcAvwYUi3wLgw1No29cBSPn/D+5p2xO8X2sAHuJ9XDnItvH7swB+GcCLAJYfoH774wD+I4AaPx+bRr+V7Xm1D8CT+zIAv7zn87sAvOsgjn2H7fsFAH8CwNMATvK7kwCenlJ7zgD4VQBfDeAXOWBX99xwY/15gO2a40PTJr6fer/xgX4JwBJcFvoXAXz9NPsNwIWJm3/ffgLwLwB8x37bHVTbJtb9NwDew//H7lU+VL/soNsG4H0AvgjAC3se6FPvNzhg+Np9tjvwfgshHFjIRTeb7DK/m7qZ2QUAbwTwYQDHQwjXAIDLY1Nq1o8A+FvYlTo/AmAjqNjq9PrvYQArAP4vhoN+0sxaeAD6LYRwBcA/BnARwDUAmwA+hgej32S366cH7f74LjjyBR6AtpnZtwC4EkL4xMSqqbcNwGsA/FGG9f6Tmf1X02zbQT3Q96svNXV6jZnNAPi3AP56CGFr2u0BADP7ZgA3Qwgf2/v1PptOo/9SuMv5z0MIb4TLOEx1PkTGePS3wt3bUwBaAL5xn02nPu72sQfl+sLMvhfACMB79NU+mx1Y28ysCeB7Afy9/Vbv891B91sKYBEe8vlfALzXvBLNVNp2UA/0y/AYmOwMgKsHdOx9zcwy+MP8PSGE9/PrG2Z2kutPArg5haZ9BYBvMbMXAPw8POzyIwAWzEwVpqbVf5cBXA4hfJif3wd/wD8I/fa1AJ4PIayEEIYA3g/gy/Fg9Jvsdv30QNwfZvZ2AN8M4M8GxgkegLY9An9Jf4L3xBkAv2NmJx6AtoFteH9w+wjcq16eVtsO6oH+UQCPkXFQBfBWAB88oGP/IeMb9KcAfDqE8E/2rPoggLfz/7fDY+sHaiGEd4UQzoQQLsD76ddCCH8WwK8D+PYpt+06gEtm9ji/+hoAf4AHoN/goZa3mFmT11dtm3q/7bHb9dMHAbyNrI23ANhUaOagzMy+AcDfBvAtIYTOnlUfBPBWM6uZ2UMAHgPwkYNqVwjh90MIx0IIF3hPXIYTGq7jAeg3AP8ODrpgZq+BEwVWMa1+e7WD9HsmBb4JziZ5FsD3HtRxb9OWr4S7P78H4OP8+yZ4rPpXAXyWy6Upt/OPYZfl8jAHxDMA/h9wVn0KbfpiAL/Nvvt3cHfzgeg3AO8G8BSATwL4GTjDYCr9BuDn4LH8Ifwh9I7b9RPcPf8/eG/8PoA3T6Ftz8BjvroffnzP9t/Ltj0N4BsPum0T61/A7qTog9BvVQA/yzH3OwC+ehr9pr+YKRotWrRoh8Ripmi0aNGiHRKLD/Ro0aJFOyQWH+jRokWLdkgsPtCjRYsW7ZBYfKBHixYt2iGx+ECPFi1atENi8YEeLVq0aIfE4gM9WrRo0Q6J/f/nqp94EXMzBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train simplified 1 linear layer decoder AE\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = AE1L(cnn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=0, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader_all):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('[epoch %d] loss: %.7f' % (epoch + 1, running_loss / (batch_idx + 1)))\n",
    "    lr_scheduler.step(running_loss)\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.encoder.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# check how well some test images match\n",
    "model.eval()\n",
    "dataiter = iter(test_loader_all)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images[:5]))\n",
    "images = images.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructed_images = model(images).cpu()\n",
    "    imshow(torchvision.utils.make_grid(reconstructed_images[:5]))\n",
    "plt.title(' '.join('%13s' % classes[labels[j]] for j in range(5)))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_ae1l = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_ae1l.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining with SimEc (unsupervised (t1+t2) and supervised (t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:30:33.719308Z",
     "start_time": "2019-07-24T09:30:22.260784Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform data into a numpy matrix by first applying the required transformations manually\n",
    "n_targets = 3000\n",
    "X = np.stack([train_dataset.transform(train_dataset.data[i]).numpy() for i in indices])\n",
    "# compute similarity matrix for n_targets\n",
    "X_flat = X.reshape(X.shape[0], 3*32*32)\n",
    "S = linear_kernel(X_flat, X_flat[:n_targets])\n",
    "S -= S.min()\n",
    "S /= S.max()\n",
    "S_ll = S[:n_targets, :]\n",
    "del X_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:30:54.417821Z",
     "start_time": "2019-07-24T09:30:33.720590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.1470783e-09, 0.9999974966064862, 0.9999981368566736)\n"
     ]
    }
   ],
   "source": [
    "# check what the similarity approximation *should* be\n",
    "D, V = np.linalg.eig(S_ll)\n",
    "D, V = D[np.argsort(D)[::-1]], V[:,np.argsort(D)[::-1]]\n",
    "X_embed = np.dot(V.real, np.diag(np.sqrt(np.abs(D.real))))\n",
    "print(check_similarity_match(X_embed[:n_targets,:512], S_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:21:17.621355Z",
     "start_time": "2019-07-24T09:30:54.419211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.1393181\n",
      "[epoch 2] loss: 0.0329879\n",
      "[epoch 3] loss: 0.0193295\n",
      "[epoch 4] loss: 0.0131776\n",
      "[epoch 5] loss: 0.0092021\n",
      "[epoch 6] loss: 0.0067313\n",
      "[epoch 7] loss: 0.0054195\n",
      "[epoch 8] loss: 0.0047080\n",
      "[epoch 9] loss: 0.0042391\n",
      "[epoch 10] loss: 0.0038878\n",
      "[epoch 11] loss: 0.0036100\n",
      "[epoch 12] loss: 0.0033830\n",
      "[epoch 13] loss: 0.0031934\n",
      "[epoch 14] loss: 0.0030322\n",
      "[epoch 15] loss: 0.0028943\n",
      "[epoch 16] loss: 0.0027732\n",
      "[epoch 17] loss: 0.0026661\n",
      "[epoch 18] loss: 0.0025614\n",
      "[epoch 19] loss: 0.0024557\n",
      "[epoch 20] loss: 0.0023416\n",
      "[epoch 21] loss: 0.0022039\n",
      "[epoch 22] loss: 0.0020542\n",
      "[epoch 23] loss: 0.0018843\n",
      "[epoch 24] loss: 0.0015925\n",
      "[epoch 25] loss: 0.0011582\n",
      "[epoch 26] loss: 0.0008302\n",
      "[epoch 27] loss: 0.0006890\n",
      "[epoch 28] loss: 0.0006135\n",
      "[epoch 29] loss: 0.0005397\n",
      "[epoch 30] loss: 0.0004701\n",
      "[epoch 31] loss: 0.0004066\n",
      "[epoch 32] loss: 0.0003495\n",
      "[epoch 33] loss: 0.0002999\n",
      "[epoch 34] loss: 0.0002581\n",
      "[epoch 35] loss: 0.0002223\n",
      "[epoch 36] loss: 0.0001912\n",
      "[epoch 37] loss: 0.0001649\n",
      "[epoch 38] loss: 0.0001431\n",
      "[epoch 39] loss: 0.0001250\n",
      "[epoch 40] loss: 0.0001098\n",
      "[epoch 41] loss: 0.0000973\n",
      "[epoch 42] loss: 0.0000870\n",
      "[epoch 43] loss: 0.0000786\n",
      "[epoch 44] loss: 0.0000718\n",
      "[epoch 45] loss: 0.0000661\n",
      "[epoch 46] loss: 0.0000613\n",
      "[epoch 47] loss: 0.0000572\n",
      "[epoch 48] loss: 0.0000537\n",
      "[epoch 49] loss: 0.0000505\n",
      "[epoch 50] loss: 0.0000477\n",
      "(4.723214e-05, 0.978600476291863, 0.9824274267304667)\n",
      "(0.00038906696, 0.947447098686073, 0.956926527465757)\n",
      "Took 900 sec to train.\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 505/5000 (10%)\n",
      "[epoch 1] loss: 2.3063834\n",
      "Test set: Average loss: 2.3118, Accuracy: 481/5000 (10%)\n",
      "[epoch 2] loss: 2.1958203\n",
      "Test set: Average loss: 2.3653, Accuracy: 489/5000 (10%)\n",
      "[epoch 3] loss: 2.0537477\n",
      "Test set: Average loss: 2.5479, Accuracy: 568/5000 (11%)\n",
      "[epoch 4] loss: 1.9101515\n",
      "Test set: Average loss: 2.7939, Accuracy: 667/5000 (13%)\n",
      "[epoch 5] loss: 1.7862697\n",
      "Test set: Average loss: 2.8974, Accuracy: 713/5000 (14%)\n",
      "[epoch 6] loss: 1.6233290\n",
      "Test set: Average loss: 2.9141, Accuracy: 701/5000 (14%)\n",
      "[epoch 7] loss: 1.4246354\n",
      "Test set: Average loss: 2.9231, Accuracy: 742/5000 (15%)\n",
      "[epoch 8] loss: 1.2063861\n",
      "Test set: Average loss: 2.9844, Accuracy: 753/5000 (15%)\n",
      "[epoch 9] loss: 0.9967980\n",
      "Test set: Average loss: 3.1362, Accuracy: 765/5000 (15%)\n",
      "[epoch 10] loss: 0.8047124\n",
      "Test set: Average loss: 3.3793, Accuracy: 734/5000 (15%)\n",
      "[epoch 11] loss: 0.6116130\n",
      "Test set: Average loss: 3.7108, Accuracy: 721/5000 (14%)\n",
      "[epoch 12] loss: 0.4353908\n",
      "Test set: Average loss: 4.0967, Accuracy: 736/5000 (15%)\n",
      "[epoch 13] loss: 0.2966114\n",
      "Test set: Average loss: 4.4906, Accuracy: 748/5000 (15%)\n",
      "[epoch 14] loss: 0.1984206\n",
      "Test set: Average loss: 4.8571, Accuracy: 750/5000 (15%)\n",
      "[epoch 15] loss: 0.1317316\n",
      "Test set: Average loss: 5.1765, Accuracy: 750/5000 (15%)\n",
      "[epoch 16] loss: 0.0863964\n",
      "Test set: Average loss: 5.4610, Accuracy: 746/5000 (15%)\n",
      "[epoch 17] loss: 0.0571302\n",
      "Test set: Average loss: 5.7359, Accuracy: 749/5000 (15%)\n",
      "[epoch 18] loss: 0.0382844\n",
      "Test set: Average loss: 6.0158, Accuracy: 763/5000 (15%)\n",
      "[epoch 19] loss: 0.0257570\n",
      "Test set: Average loss: 6.3060, Accuracy: 761/5000 (15%)\n",
      "[epoch 20] loss: 0.0178124\n",
      "Test set: Average loss: 6.6036, Accuracy: 766/5000 (15%)\n",
      "[epoch 21] loss: 0.0126756\n",
      "Test set: Average loss: 6.8999, Accuracy: 758/5000 (15%)\n",
      "[epoch 22] loss: 0.0092213\n",
      "Test set: Average loss: 7.1831, Accuracy: 747/5000 (15%)\n",
      "[epoch 23] loss: 0.0069903\n",
      "Test set: Average loss: 7.4381, Accuracy: 746/5000 (15%)\n",
      "[epoch 24] loss: 0.0055763\n",
      "Test set: Average loss: 7.6514, Accuracy: 739/5000 (15%)\n",
      "[epoch 25] loss: 0.0043869\n",
      "Test set: Average loss: 7.8239, Accuracy: 737/5000 (15%)\n",
      "[epoch 26] loss: 0.0033375\n",
      "Test set: Average loss: 7.9661, Accuracy: 739/5000 (15%)\n",
      "[epoch 27] loss: 0.0026017\n",
      "Test set: Average loss: 8.0868, Accuracy: 742/5000 (15%)\n",
      "[epoch 28] loss: 0.0021165\n",
      "Test set: Average loss: 8.1909, Accuracy: 743/5000 (15%)\n",
      "[epoch 29] loss: 0.0017797\n",
      "Test set: Average loss: 8.2817, Accuracy: 744/5000 (15%)\n",
      "[epoch 30] loss: 0.0015302\n",
      "Test set: Average loss: 8.3611, Accuracy: 749/5000 (15%)\n",
      "[epoch 31] loss: 0.0013356\n",
      "Test set: Average loss: 8.4312, Accuracy: 752/5000 (15%)\n",
      "[epoch 32] loss: 0.0011790\n",
      "Test set: Average loss: 8.4932, Accuracy: 743/5000 (15%)\n",
      "[epoch 33] loss: 0.0010501\n",
      "Test set: Average loss: 8.5484, Accuracy: 746/5000 (15%)\n",
      "[epoch 34] loss: 0.0009420\n",
      "Test set: Average loss: 8.5978, Accuracy: 745/5000 (15%)\n",
      "[epoch 35] loss: 0.0008506\n",
      "Test set: Average loss: 8.6423, Accuracy: 748/5000 (15%)\n",
      "[epoch 36] loss: 0.0007727\n",
      "Test set: Average loss: 8.6827, Accuracy: 744/5000 (15%)\n",
      "[epoch 37] loss: 0.0007060\n",
      "Test set: Average loss: 8.7196, Accuracy: 742/5000 (15%)\n",
      "[epoch 38] loss: 0.0006487\n",
      "Test set: Average loss: 8.7534, Accuracy: 741/5000 (15%)\n",
      "[epoch 39] loss: 0.0005993\n",
      "Test set: Average loss: 8.7847, Accuracy: 742/5000 (15%)\n",
      "[epoch 40] loss: 0.0005566\n",
      "Test set: Average loss: 8.8137, Accuracy: 742/5000 (15%)\n",
      "[epoch 41] loss: 0.0005194\n",
      "Test set: Average loss: 8.8407, Accuracy: 742/5000 (15%)\n",
      "[epoch 42] loss: 0.0004870\n",
      "Test set: Average loss: 8.8661, Accuracy: 742/5000 (15%)\n",
      "[epoch 43] loss: 0.0004585\n",
      "Test set: Average loss: 8.8899, Accuracy: 744/5000 (15%)\n",
      "[epoch 44] loss: 0.0004335\n",
      "Test set: Average loss: 8.9124, Accuracy: 750/5000 (15%)\n",
      "[epoch 45] loss: 0.0004112\n",
      "Test set: Average loss: 8.9336, Accuracy: 752/5000 (15%)\n",
      "[epoch 46] loss: 0.0003913\n",
      "Test set: Average loss: 8.9538, Accuracy: 753/5000 (15%)\n",
      "[epoch 47] loss: 0.0003734\n",
      "Test set: Average loss: 8.9729, Accuracy: 751/5000 (15%)\n",
      "[epoch 48] loss: 0.0003572\n",
      "Test set: Average loss: 8.9911, Accuracy: 747/5000 (15%)\n",
      "[epoch 49] loss: 0.0003424\n",
      "Test set: Average loss: 9.0084, Accuracy: 746/5000 (15%)\n",
      "[epoch 50] loss: 0.0003292\n",
      "Test set: Average loss: 9.0249, Accuracy: 744/5000 (15%)\n",
      "Validation:\n",
      "Test set: Average loss: 6.6036, Accuracy: 766/5000 (15%)\n",
      "Test\n",
      "Test set: Average loss: 6.4286, Accuracy: 1632/10000 (16%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 512/5000 (10%)\n",
      "[epoch 1] loss: 2.2965231\n",
      "Test set: Average loss: 2.3088, Accuracy: 651/5000 (13%)\n",
      "[epoch 2] loss: 2.1642046\n",
      "Test set: Average loss: 2.3665, Accuracy: 568/5000 (11%)\n",
      "[epoch 3] loss: 2.0056736\n",
      "Test set: Average loss: 2.5365, Accuracy: 608/5000 (12%)\n",
      "[epoch 4] loss: 1.8712825\n",
      "Test set: Average loss: 2.6655, Accuracy: 680/5000 (14%)\n",
      "[epoch 5] loss: 1.7231436\n",
      "Test set: Average loss: 2.7399, Accuracy: 708/5000 (14%)\n",
      "[epoch 6] loss: 1.5536009\n",
      "Test set: Average loss: 2.8202, Accuracy: 700/5000 (14%)\n",
      "[epoch 7] loss: 1.3847204\n",
      "Test set: Average loss: 2.9059, Accuracy: 721/5000 (14%)\n",
      "[epoch 8] loss: 1.1959758\n",
      "Test set: Average loss: 3.0199, Accuracy: 754/5000 (15%)\n",
      "[epoch 9] loss: 1.0071728\n",
      "Test set: Average loss: 3.1674, Accuracy: 769/5000 (15%)\n",
      "[epoch 10] loss: 0.8217313\n",
      "Test set: Average loss: 3.3118, Accuracy: 773/5000 (15%)\n",
      "[epoch 11] loss: 0.6292163\n",
      "Test set: Average loss: 3.4549, Accuracy: 767/5000 (15%)\n",
      "[epoch 12] loss: 0.4556907\n",
      "Test set: Average loss: 3.6262, Accuracy: 760/5000 (15%)\n",
      "[epoch 13] loss: 0.3267198\n",
      "Test set: Average loss: 3.8407, Accuracy: 731/5000 (15%)\n",
      "[epoch 14] loss: 0.2415619\n",
      "Test set: Average loss: 4.0879, Accuracy: 715/5000 (14%)\n",
      "[epoch 15] loss: 0.1771726\n",
      "Test set: Average loss: 4.3503, Accuracy: 743/5000 (15%)\n",
      "[epoch 16] loss: 0.1177531\n",
      "Test set: Average loss: 4.6272, Accuracy: 764/5000 (15%)\n",
      "[epoch 17] loss: 0.0787878\n",
      "Test set: Average loss: 4.8963, Accuracy: 768/5000 (15%)\n",
      "[epoch 18] loss: 0.0570162\n",
      "Test set: Average loss: 5.1290, Accuracy: 769/5000 (15%)\n",
      "[epoch 19] loss: 0.0396094\n",
      "Test set: Average loss: 5.3240, Accuracy: 760/5000 (15%)\n",
      "[epoch 20] loss: 0.0249254\n",
      "Test set: Average loss: 5.4984, Accuracy: 747/5000 (15%)\n",
      "[epoch 21] loss: 0.0156492\n",
      "Test set: Average loss: 5.6662, Accuracy: 730/5000 (15%)\n",
      "[epoch 22] loss: 0.0106549\n",
      "Test set: Average loss: 5.8316, Accuracy: 726/5000 (15%)\n",
      "[epoch 23] loss: 0.0076953\n",
      "Test set: Average loss: 5.9939, Accuracy: 734/5000 (15%)\n",
      "[epoch 24] loss: 0.0056203\n",
      "Test set: Average loss: 6.1508, Accuracy: 740/5000 (15%)\n",
      "[epoch 25] loss: 0.0041019\n",
      "Test set: Average loss: 6.3004, Accuracy: 737/5000 (15%)\n",
      "[epoch 26] loss: 0.0030262\n",
      "Test set: Average loss: 6.4415, Accuracy: 731/5000 (15%)\n",
      "[epoch 27] loss: 0.0022795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 6.5739, Accuracy: 731/5000 (15%)\n",
      "[epoch 28] loss: 0.0017593\n",
      "Test set: Average loss: 6.6974, Accuracy: 734/5000 (15%)\n",
      "[epoch 29] loss: 0.0013926\n",
      "Test set: Average loss: 6.8121, Accuracy: 723/5000 (14%)\n",
      "[epoch 30] loss: 0.0011312\n",
      "Test set: Average loss: 6.9183, Accuracy: 723/5000 (14%)\n",
      "[epoch 31] loss: 0.0009433\n",
      "Test set: Average loss: 7.0163, Accuracy: 723/5000 (14%)\n",
      "[epoch 32] loss: 0.0008067\n",
      "Test set: Average loss: 7.1063, Accuracy: 723/5000 (14%)\n",
      "[epoch 33] loss: 0.0007058\n",
      "Test set: Average loss: 7.1888, Accuracy: 725/5000 (14%)\n",
      "[epoch 34] loss: 0.0006293\n",
      "Test set: Average loss: 7.2641, Accuracy: 723/5000 (14%)\n",
      "[epoch 35] loss: 0.0005690\n",
      "Test set: Average loss: 7.3327, Accuracy: 716/5000 (14%)\n",
      "[epoch 36] loss: 0.0005187\n",
      "Test set: Average loss: 7.3950, Accuracy: 715/5000 (14%)\n",
      "[epoch 37] loss: 0.0004750\n",
      "Test set: Average loss: 7.4516, Accuracy: 714/5000 (14%)\n",
      "[epoch 38] loss: 0.0004356\n",
      "Test set: Average loss: 7.5029, Accuracy: 718/5000 (14%)\n",
      "[epoch 39] loss: 0.0004002\n",
      "Test set: Average loss: 7.5495, Accuracy: 720/5000 (14%)\n",
      "[epoch 40] loss: 0.0003679\n",
      "Test set: Average loss: 7.5919, Accuracy: 719/5000 (14%)\n",
      "[epoch 41] loss: 0.0003393\n",
      "Test set: Average loss: 7.6304, Accuracy: 721/5000 (14%)\n",
      "[epoch 42] loss: 0.0003142\n",
      "Test set: Average loss: 7.6656, Accuracy: 722/5000 (14%)\n",
      "[epoch 43] loss: 0.0002921\n",
      "Test set: Average loss: 7.6977, Accuracy: 719/5000 (14%)\n",
      "[epoch 44] loss: 0.0002731\n",
      "Test set: Average loss: 7.7270, Accuracy: 717/5000 (14%)\n",
      "[epoch 45] loss: 0.0002566\n",
      "Test set: Average loss: 7.7539, Accuracy: 719/5000 (14%)\n",
      "[epoch 46] loss: 0.0002422\n",
      "Test set: Average loss: 7.7785, Accuracy: 715/5000 (14%)\n",
      "[epoch 47] loss: 0.0002295\n",
      "Test set: Average loss: 7.8011, Accuracy: 714/5000 (14%)\n",
      "[epoch 48] loss: 0.0002186\n",
      "Test set: Average loss: 7.8219, Accuracy: 717/5000 (14%)\n",
      "[epoch 49] loss: 0.0002087\n",
      "Test set: Average loss: 7.8410, Accuracy: 718/5000 (14%)\n",
      "[epoch 50] loss: 0.0001998\n",
      "Test set: Average loss: 7.8586, Accuracy: 716/5000 (14%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.3118, Accuracy: 773/5000 (15%)\n",
      "Test\n",
      "Test set: Average loss: 3.2989, Accuracy: 1578/10000 (16%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 458/5000 (9%)\n",
      "[epoch 1] loss: 2.3155646\n",
      "Test set: Average loss: 2.2963, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 2.1897111\n",
      "Test set: Average loss: 2.3187, Accuracy: 525/5000 (10%)\n",
      "[epoch 3] loss: 2.0190418\n",
      "Test set: Average loss: 2.4859, Accuracy: 526/5000 (11%)\n",
      "[epoch 4] loss: 1.8631885\n",
      "Test set: Average loss: 2.7700, Accuracy: 564/5000 (11%)\n",
      "[epoch 5] loss: 1.8021317\n",
      "Test set: Average loss: 2.7754, Accuracy: 687/5000 (14%)\n",
      "[epoch 6] loss: 1.6644800\n",
      "Test set: Average loss: 2.6847, Accuracy: 702/5000 (14%)\n",
      "[epoch 7] loss: 1.5086480\n",
      "Test set: Average loss: 2.5978, Accuracy: 745/5000 (15%)\n",
      "[epoch 8] loss: 1.3446126\n",
      "Test set: Average loss: 2.5680, Accuracy: 785/5000 (16%)\n",
      "[epoch 9] loss: 1.1859521\n",
      "Test set: Average loss: 2.6320, Accuracy: 796/5000 (16%)\n",
      "[epoch 10] loss: 1.0445750\n",
      "Test set: Average loss: 2.7830, Accuracy: 792/5000 (16%)\n",
      "[epoch 11] loss: 0.8927048\n",
      "Test set: Average loss: 3.0001, Accuracy: 788/5000 (16%)\n",
      "[epoch 12] loss: 0.7167459\n",
      "Test set: Average loss: 3.2891, Accuracy: 774/5000 (15%)\n",
      "[epoch 13] loss: 0.5537540\n",
      "Test set: Average loss: 3.6406, Accuracy: 750/5000 (15%)\n",
      "[epoch 14] loss: 0.4289982\n",
      "Test set: Average loss: 4.0018, Accuracy: 756/5000 (15%)\n",
      "[epoch 15] loss: 0.3282412\n",
      "Test set: Average loss: 4.3112, Accuracy: 755/5000 (15%)\n",
      "[epoch 16] loss: 0.2379827\n",
      "Test set: Average loss: 4.5364, Accuracy: 742/5000 (15%)\n",
      "[epoch 17] loss: 0.1578582\n",
      "Test set: Average loss: 4.7072, Accuracy: 740/5000 (15%)\n",
      "[epoch 18] loss: 0.0974976\n",
      "Test set: Average loss: 4.8767, Accuracy: 763/5000 (15%)\n",
      "[epoch 19] loss: 0.0638884\n",
      "Test set: Average loss: 5.0638, Accuracy: 755/5000 (15%)\n",
      "[epoch 20] loss: 0.0468922\n",
      "Test set: Average loss: 5.2575, Accuracy: 764/5000 (15%)\n",
      "[epoch 21] loss: 0.0325681\n",
      "Test set: Average loss: 5.4487, Accuracy: 763/5000 (15%)\n",
      "[epoch 22] loss: 0.0210409\n",
      "Test set: Average loss: 5.6341, Accuracy: 780/5000 (16%)\n",
      "[epoch 23] loss: 0.0143613\n",
      "Test set: Average loss: 5.8117, Accuracy: 789/5000 (16%)\n",
      "[epoch 24] loss: 0.0109646\n",
      "Test set: Average loss: 5.9802, Accuracy: 789/5000 (16%)\n",
      "[epoch 25] loss: 0.0088559\n",
      "Test set: Average loss: 6.1398, Accuracy: 795/5000 (16%)\n",
      "[epoch 26] loss: 0.0071054\n",
      "Test set: Average loss: 6.2915, Accuracy: 797/5000 (16%)\n",
      "[epoch 27] loss: 0.0055065\n",
      "Test set: Average loss: 6.4364, Accuracy: 810/5000 (16%)\n",
      "[epoch 28] loss: 0.0041411\n",
      "Test set: Average loss: 6.5743, Accuracy: 811/5000 (16%)\n",
      "[epoch 29] loss: 0.0030896\n",
      "Test set: Average loss: 6.7046, Accuracy: 814/5000 (16%)\n",
      "[epoch 30] loss: 0.0023430\n",
      "Test set: Average loss: 6.8266, Accuracy: 813/5000 (16%)\n",
      "[epoch 31] loss: 0.0018356\n",
      "Test set: Average loss: 6.9399, Accuracy: 817/5000 (16%)\n",
      "[epoch 32] loss: 0.0014939\n",
      "Test set: Average loss: 7.0443, Accuracy: 817/5000 (16%)\n",
      "[epoch 33] loss: 0.0012602\n",
      "Test set: Average loss: 7.1401, Accuracy: 819/5000 (16%)\n",
      "[epoch 34] loss: 0.0010944\n",
      "Test set: Average loss: 7.2276, Accuracy: 810/5000 (16%)\n",
      "[epoch 35] loss: 0.0009713\n",
      "Test set: Average loss: 7.3074, Accuracy: 806/5000 (16%)\n",
      "[epoch 36] loss: 0.0008743\n",
      "Test set: Average loss: 7.3800, Accuracy: 808/5000 (16%)\n",
      "[epoch 37] loss: 0.0007941\n",
      "Test set: Average loss: 7.4460, Accuracy: 805/5000 (16%)\n",
      "[epoch 38] loss: 0.0007249\n",
      "Test set: Average loss: 7.5059, Accuracy: 805/5000 (16%)\n",
      "[epoch 39] loss: 0.0006642\n",
      "Test set: Average loss: 7.5603, Accuracy: 804/5000 (16%)\n",
      "[epoch 40] loss: 0.0006105\n",
      "Test set: Average loss: 7.6097, Accuracy: 805/5000 (16%)\n",
      "[epoch 41] loss: 0.0005627\n",
      "Test set: Average loss: 7.6546, Accuracy: 806/5000 (16%)\n",
      "[epoch 42] loss: 0.0005206\n",
      "Test set: Average loss: 7.6953, Accuracy: 802/5000 (16%)\n",
      "[epoch 43] loss: 0.0004834\n",
      "Test set: Average loss: 7.7324, Accuracy: 801/5000 (16%)\n",
      "[epoch 44] loss: 0.0004503\n",
      "Test set: Average loss: 7.7661, Accuracy: 801/5000 (16%)\n",
      "[epoch 45] loss: 0.0004212\n",
      "Test set: Average loss: 7.7968, Accuracy: 799/5000 (16%)\n",
      "[epoch 46] loss: 0.0003955\n",
      "Test set: Average loss: 7.8246, Accuracy: 798/5000 (16%)\n",
      "[epoch 47] loss: 0.0003725\n",
      "Test set: Average loss: 7.8499, Accuracy: 799/5000 (16%)\n",
      "[epoch 48] loss: 0.0003520\n",
      "Test set: Average loss: 7.8729, Accuracy: 800/5000 (16%)\n",
      "[epoch 49] loss: 0.0003337\n",
      "Test set: Average loss: 7.8937, Accuracy: 799/5000 (16%)\n",
      "[epoch 50] loss: 0.0003174\n",
      "Test set: Average loss: 7.9126, Accuracy: 794/5000 (16%)\n",
      "Validation:\n",
      "Test set: Average loss: 7.1401, Accuracy: 819/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 7.1719, Accuracy: 1625/10000 (16%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 494/5000 (10%)\n",
      "[epoch 1] loss: 2.2793779\n",
      "Test set: Average loss: 2.3021, Accuracy: 645/5000 (13%)\n",
      "[epoch 2] loss: 2.1071650\n",
      "Test set: Average loss: 2.4648, Accuracy: 684/5000 (14%)\n",
      "[epoch 3] loss: 1.9512603\n",
      "Test set: Average loss: 2.6364, Accuracy: 691/5000 (14%)\n",
      "[epoch 4] loss: 1.8271875\n",
      "Test set: Average loss: 2.6410, Accuracy: 922/5000 (18%)\n",
      "[epoch 5] loss: 1.5912915\n",
      "Test set: Average loss: 2.6316, Accuracy: 940/5000 (19%)\n",
      "[epoch 6] loss: 1.3732020\n",
      "Test set: Average loss: 2.6141, Accuracy: 933/5000 (19%)\n",
      "[epoch 7] loss: 1.1569839\n",
      "Test set: Average loss: 2.7697, Accuracy: 951/5000 (19%)\n",
      "[epoch 8] loss: 0.9780336\n",
      "Test set: Average loss: 3.1056, Accuracy: 898/5000 (18%)\n",
      "[epoch 9] loss: 0.8456079\n",
      "Test set: Average loss: 3.2915, Accuracy: 959/5000 (19%)\n",
      "[epoch 10] loss: 0.6037715\n",
      "Test set: Average loss: 3.4356, Accuracy: 1020/5000 (20%)\n",
      "[epoch 11] loss: 0.4349336\n",
      "Test set: Average loss: 3.6705, Accuracy: 996/5000 (20%)\n",
      "[epoch 12] loss: 0.2889304\n",
      "Test set: Average loss: 4.0197, Accuracy: 946/5000 (19%)\n",
      "[epoch 13] loss: 0.2365161\n",
      "Test set: Average loss: 4.3047, Accuracy: 949/5000 (19%)\n",
      "[epoch 14] loss: 0.1336340\n",
      "Test set: Average loss: 4.4045, Accuracy: 996/5000 (20%)\n",
      "[epoch 15] loss: 0.0929959\n",
      "Test set: Average loss: 4.5570, Accuracy: 998/5000 (20%)\n",
      "[epoch 16] loss: 0.0681922\n",
      "Test set: Average loss: 4.7760, Accuracy: 987/5000 (20%)\n",
      "[epoch 17] loss: 0.0396566\n",
      "Test set: Average loss: 5.0394, Accuracy: 983/5000 (20%)\n",
      "[epoch 18] loss: 0.0250873\n",
      "Test set: Average loss: 5.2852, Accuracy: 985/5000 (20%)\n",
      "[epoch 19] loss: 0.0175739\n",
      "Test set: Average loss: 5.4821, Accuracy: 983/5000 (20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] loss: 0.0138861\n",
      "Test set: Average loss: 5.6484, Accuracy: 973/5000 (19%)\n",
      "[epoch 21] loss: 0.0097432\n",
      "Test set: Average loss: 5.7713, Accuracy: 977/5000 (20%)\n",
      "[epoch 22] loss: 0.0069699\n",
      "Test set: Average loss: 5.8560, Accuracy: 981/5000 (20%)\n",
      "[epoch 23] loss: 0.0055700\n",
      "Test set: Average loss: 5.9152, Accuracy: 977/5000 (20%)\n",
      "[epoch 24] loss: 0.0041432\n",
      "Test set: Average loss: 5.9552, Accuracy: 985/5000 (20%)\n",
      "[epoch 25] loss: 0.0032183\n",
      "Test set: Average loss: 5.9956, Accuracy: 983/5000 (20%)\n",
      "[epoch 26] loss: 0.0028812\n",
      "Test set: Average loss: 6.0370, Accuracy: 989/5000 (20%)\n",
      "[epoch 27] loss: 0.0023089\n",
      "Test set: Average loss: 6.0806, Accuracy: 986/5000 (20%)\n",
      "[epoch 28] loss: 0.0022959\n",
      "Test set: Average loss: 6.1236, Accuracy: 989/5000 (20%)\n",
      "[epoch 29] loss: 0.0019503\n",
      "Test set: Average loss: 6.1662, Accuracy: 999/5000 (20%)\n",
      "[epoch 30] loss: 0.0018351\n",
      "Test set: Average loss: 6.2071, Accuracy: 995/5000 (20%)\n",
      "[epoch 31] loss: 0.0016635\n",
      "Test set: Average loss: 6.2446, Accuracy: 991/5000 (20%)\n",
      "[epoch 32] loss: 0.0015455\n",
      "Test set: Average loss: 6.2857, Accuracy: 991/5000 (20%)\n",
      "[epoch 33] loss: 0.0014759\n",
      "Test set: Average loss: 6.3111, Accuracy: 989/5000 (20%)\n",
      "[epoch 34] loss: 0.0013244\n",
      "Test set: Average loss: 6.3390, Accuracy: 985/5000 (20%)\n",
      "[epoch 35] loss: 0.0011545\n",
      "Test set: Average loss: 6.3625, Accuracy: 983/5000 (20%)\n",
      "[epoch 36] loss: 0.0011129\n",
      "Test set: Average loss: 6.3819, Accuracy: 981/5000 (20%)\n",
      "[epoch 37] loss: 0.0010862\n",
      "Test set: Average loss: 6.3971, Accuracy: 976/5000 (20%)\n",
      "[epoch 38] loss: 0.0010586\n",
      "Test set: Average loss: 6.4089, Accuracy: 975/5000 (20%)\n",
      "[epoch 39] loss: 0.0010007\n",
      "Test set: Average loss: 6.4172, Accuracy: 983/5000 (20%)\n",
      "[epoch 40] loss: 0.0009259\n",
      "Test set: Average loss: 6.4237, Accuracy: 979/5000 (20%)\n",
      "[epoch 41] loss: 0.0008838\n",
      "Test set: Average loss: 6.4290, Accuracy: 979/5000 (20%)\n",
      "[epoch 42] loss: 0.0008730\n",
      "Test set: Average loss: 6.4334, Accuracy: 978/5000 (20%)\n",
      "[epoch 43] loss: 0.0008158\n",
      "Test set: Average loss: 6.4365, Accuracy: 982/5000 (20%)\n",
      "[epoch 44] loss: 0.0008183\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 6.4394, Accuracy: 982/5000 (20%)\n",
      "[epoch 45] loss: 0.0008253\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 6.4398, Accuracy: 982/5000 (20%)\n",
      "[epoch 46] loss: 0.0007933\n",
      "Test set: Average loss: 6.4398, Accuracy: 982/5000 (20%)\n",
      "[epoch 47] loss: 0.0008579\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 6.4398, Accuracy: 982/5000 (20%)\n",
      "[epoch 48] loss: 0.0008290\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 6.4398, Accuracy: 982/5000 (20%)\n",
      "[epoch 49] loss: 0.0007906\n",
      "Test set: Average loss: 6.4398, Accuracy: 982/5000 (20%)\n",
      "[epoch 50] loss: 0.0008308\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 6.4398, Accuracy: 982/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.4356, Accuracy: 1020/5000 (20%)\n",
      "Test\n",
      "Test set: Average loss: 3.3411, Accuracy: 2141/10000 (21%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 409/5000 (8%)\n",
      "[epoch 1] loss: 2.3073347\n",
      "Test set: Average loss: 2.3002, Accuracy: 559/5000 (11%)\n",
      "[epoch 2] loss: 2.1854800\n",
      "Test set: Average loss: 2.3194, Accuracy: 745/5000 (15%)\n",
      "[epoch 3] loss: 1.9398602\n",
      "Test set: Average loss: 2.4063, Accuracy: 781/5000 (16%)\n",
      "[epoch 4] loss: 1.8583587\n",
      "Test set: Average loss: 2.5559, Accuracy: 862/5000 (17%)\n",
      "[epoch 5] loss: 1.5483052\n",
      "Test set: Average loss: 2.6174, Accuracy: 826/5000 (17%)\n",
      "[epoch 6] loss: 1.3910514\n",
      "Test set: Average loss: 2.7169, Accuracy: 780/5000 (16%)\n",
      "[epoch 7] loss: 1.1989611\n",
      "Test set: Average loss: 2.7707, Accuracy: 884/5000 (18%)\n",
      "[epoch 8] loss: 0.9180918\n",
      "Test set: Average loss: 2.8831, Accuracy: 945/5000 (19%)\n",
      "[epoch 9] loss: 0.7199823\n",
      "Test set: Average loss: 3.0408, Accuracy: 935/5000 (19%)\n",
      "[epoch 10] loss: 0.5573321\n",
      "Test set: Average loss: 3.2084, Accuracy: 897/5000 (18%)\n",
      "[epoch 11] loss: 0.4089998\n",
      "Test set: Average loss: 3.3962, Accuracy: 886/5000 (18%)\n",
      "[epoch 12] loss: 0.2864178\n",
      "Test set: Average loss: 3.6684, Accuracy: 879/5000 (18%)\n",
      "[epoch 13] loss: 0.1907424\n",
      "Test set: Average loss: 4.0324, Accuracy: 876/5000 (18%)\n",
      "[epoch 14] loss: 0.1196454\n",
      "Test set: Average loss: 4.3325, Accuracy: 860/5000 (17%)\n",
      "[epoch 15] loss: 0.0729139\n",
      "Test set: Average loss: 4.5819, Accuracy: 848/5000 (17%)\n",
      "[epoch 16] loss: 0.0431163\n",
      "Test set: Average loss: 4.7980, Accuracy: 817/5000 (16%)\n",
      "[epoch 17] loss: 0.0284170\n",
      "Test set: Average loss: 5.0115, Accuracy: 796/5000 (16%)\n",
      "[epoch 18] loss: 0.0184750\n",
      "Test set: Average loss: 5.2210, Accuracy: 798/5000 (16%)\n",
      "[epoch 19] loss: 0.0126875\n",
      "Test set: Average loss: 5.4042, Accuracy: 799/5000 (16%)\n",
      "[epoch 20] loss: 0.0088068\n",
      "Test set: Average loss: 5.5642, Accuracy: 801/5000 (16%)\n",
      "[epoch 21] loss: 0.0072358\n",
      "Test set: Average loss: 5.7009, Accuracy: 810/5000 (16%)\n",
      "[epoch 22] loss: 0.0054683\n",
      "Test set: Average loss: 5.8132, Accuracy: 822/5000 (16%)\n",
      "[epoch 23] loss: 0.0044525\n",
      "Test set: Average loss: 5.9088, Accuracy: 829/5000 (17%)\n",
      "[epoch 24] loss: 0.0035138\n",
      "Test set: Average loss: 5.9901, Accuracy: 835/5000 (17%)\n",
      "[epoch 25] loss: 0.0031503\n",
      "Test set: Average loss: 6.0603, Accuracy: 834/5000 (17%)\n",
      "[epoch 26] loss: 0.0029092\n",
      "Test set: Average loss: 6.1184, Accuracy: 833/5000 (17%)\n",
      "[epoch 27] loss: 0.0022772\n",
      "Test set: Average loss: 6.1677, Accuracy: 832/5000 (17%)\n",
      "[epoch 28] loss: 0.0020073\n",
      "Test set: Average loss: 6.2092, Accuracy: 833/5000 (17%)\n",
      "[epoch 29] loss: 0.0018173\n",
      "Test set: Average loss: 6.2445, Accuracy: 831/5000 (17%)\n",
      "[epoch 30] loss: 0.0015101\n",
      "Test set: Average loss: 6.2750, Accuracy: 829/5000 (17%)\n",
      "[epoch 31] loss: 0.0013622\n",
      "Test set: Average loss: 6.3014, Accuracy: 829/5000 (17%)\n",
      "[epoch 32] loss: 0.0012995\n",
      "Test set: Average loss: 6.3246, Accuracy: 830/5000 (17%)\n",
      "[epoch 33] loss: 0.0011864\n",
      "Test set: Average loss: 6.3443, Accuracy: 829/5000 (17%)\n",
      "[epoch 34] loss: 0.0011206\n",
      "Test set: Average loss: 6.3603, Accuracy: 829/5000 (17%)\n",
      "[epoch 35] loss: 0.0010742\n",
      "Test set: Average loss: 6.3749, Accuracy: 827/5000 (17%)\n",
      "[epoch 36] loss: 0.0010063\n",
      "Test set: Average loss: 6.3876, Accuracy: 827/5000 (17%)\n",
      "[epoch 37] loss: 0.0009871\n",
      "Test set: Average loss: 6.3996, Accuracy: 828/5000 (17%)\n",
      "[epoch 38] loss: 0.0009352\n",
      "Test set: Average loss: 6.4097, Accuracy: 828/5000 (17%)\n",
      "[epoch 39] loss: 0.0008734\n",
      "Test set: Average loss: 6.4182, Accuracy: 825/5000 (16%)\n",
      "[epoch 40] loss: 0.0008522\n",
      "Test set: Average loss: 6.4255, Accuracy: 826/5000 (17%)\n",
      "[epoch 41] loss: 0.0008375\n",
      "Test set: Average loss: 6.4318, Accuracy: 826/5000 (17%)\n",
      "[epoch 42] loss: 0.0007959\n",
      "Test set: Average loss: 6.4373, Accuracy: 826/5000 (17%)\n",
      "[epoch 43] loss: 0.0007632\n",
      "Test set: Average loss: 6.4419, Accuracy: 828/5000 (17%)\n",
      "[epoch 44] loss: 0.0007860\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 6.4459, Accuracy: 829/5000 (17%)\n",
      "[epoch 45] loss: 0.0007181\n",
      "Test set: Average loss: 6.4464, Accuracy: 829/5000 (17%)\n",
      "[epoch 46] loss: 0.0007163\n",
      "Test set: Average loss: 6.4468, Accuracy: 830/5000 (17%)\n",
      "[epoch 47] loss: 0.0007253\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 6.4472, Accuracy: 829/5000 (17%)\n",
      "[epoch 48] loss: 0.0007540\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 6.4472, Accuracy: 829/5000 (17%)\n",
      "[epoch 49] loss: 0.0007617\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 6.4472, Accuracy: 829/5000 (17%)\n",
      "[epoch 50] loss: 0.0007213\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 6.4472, Accuracy: 829/5000 (17%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8831, Accuracy: 945/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 2.8532, Accuracy: 1990/10000 (20%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3035, Accuracy: 507/5000 (10%)\n",
      "[epoch 1] loss: 2.2756411\n",
      "Test set: Average loss: 2.3159, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 2.0678093\n",
      "Test set: Average loss: 2.5452, Accuracy: 577/5000 (12%)\n",
      "[epoch 3] loss: 2.0569254\n",
      "Test set: Average loss: 2.4534, Accuracy: 828/5000 (17%)\n",
      "[epoch 4] loss: 1.7322442\n",
      "Test set: Average loss: 2.3470, Accuracy: 873/5000 (17%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 1.5944341\n",
      "Test set: Average loss: 2.3988, Accuracy: 853/5000 (17%)\n",
      "[epoch 6] loss: 1.4699259\n",
      "Test set: Average loss: 2.5587, Accuracy: 863/5000 (17%)\n",
      "[epoch 7] loss: 1.2909182\n",
      "Test set: Average loss: 2.8061, Accuracy: 897/5000 (18%)\n",
      "[epoch 8] loss: 1.0940140\n",
      "Test set: Average loss: 2.8518, Accuracy: 943/5000 (19%)\n",
      "[epoch 9] loss: 0.9130111\n",
      "Test set: Average loss: 2.8639, Accuracy: 932/5000 (19%)\n",
      "[epoch 10] loss: 0.7529853\n",
      "Test set: Average loss: 2.9441, Accuracy: 961/5000 (19%)\n",
      "[epoch 11] loss: 0.6741250\n",
      "Test set: Average loss: 3.2499, Accuracy: 887/5000 (18%)\n",
      "[epoch 12] loss: 0.4419291\n",
      "Test set: Average loss: 3.6690, Accuracy: 875/5000 (18%)\n",
      "[epoch 13] loss: 0.4058663\n",
      "Test set: Average loss: 3.7691, Accuracy: 899/5000 (18%)\n",
      "[epoch 14] loss: 0.2469993\n",
      "Test set: Average loss: 3.8651, Accuracy: 934/5000 (19%)\n",
      "[epoch 15] loss: 0.2199968\n",
      "Test set: Average loss: 3.9966, Accuracy: 953/5000 (19%)\n",
      "[epoch 16] loss: 0.1592345\n",
      "Test set: Average loss: 4.1569, Accuracy: 938/5000 (19%)\n",
      "[epoch 17] loss: 0.0846264\n",
      "Test set: Average loss: 4.4158, Accuracy: 914/5000 (18%)\n",
      "[epoch 18] loss: 0.0799177\n",
      "Test set: Average loss: 4.5897, Accuracy: 900/5000 (18%)\n",
      "[epoch 19] loss: 0.0522553\n",
      "Test set: Average loss: 4.7062, Accuracy: 910/5000 (18%)\n",
      "[epoch 20] loss: 0.0336642\n",
      "Test set: Average loss: 4.8027, Accuracy: 930/5000 (19%)\n",
      "[epoch 21] loss: 0.0281936\n",
      "Test set: Average loss: 4.8772, Accuracy: 934/5000 (19%)\n",
      "[epoch 22] loss: 0.0173940\n",
      "Test set: Average loss: 4.9704, Accuracy: 931/5000 (19%)\n",
      "[epoch 23] loss: 0.0133117\n",
      "Test set: Average loss: 5.0835, Accuracy: 923/5000 (18%)\n",
      "[epoch 24] loss: 0.0098831\n",
      "Test set: Average loss: 5.1977, Accuracy: 919/5000 (18%)\n",
      "[epoch 25] loss: 0.0088245\n",
      "Test set: Average loss: 5.2952, Accuracy: 922/5000 (18%)\n",
      "[epoch 26] loss: 0.0075846\n",
      "Test set: Average loss: 5.3813, Accuracy: 926/5000 (19%)\n",
      "[epoch 27] loss: 0.0053721\n",
      "Test set: Average loss: 5.4558, Accuracy: 931/5000 (19%)\n",
      "[epoch 28] loss: 0.0046311\n",
      "Test set: Average loss: 5.5263, Accuracy: 932/5000 (19%)\n",
      "[epoch 29] loss: 0.0043243\n",
      "Test set: Average loss: 5.5923, Accuracy: 935/5000 (19%)\n",
      "[epoch 30] loss: 0.0041058\n",
      "Test set: Average loss: 5.6508, Accuracy: 933/5000 (19%)\n",
      "[epoch 31] loss: 0.0041092\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.7018, Accuracy: 935/5000 (19%)\n",
      "[epoch 32] loss: 0.0037501\n",
      "Test set: Average loss: 5.7057, Accuracy: 932/5000 (19%)\n",
      "[epoch 33] loss: 0.0035764\n",
      "Test set: Average loss: 5.7086, Accuracy: 932/5000 (19%)\n",
      "[epoch 34] loss: 0.0033631\n",
      "Test set: Average loss: 5.7109, Accuracy: 931/5000 (19%)\n",
      "[epoch 35] loss: 0.0032640\n",
      "Test set: Average loss: 5.7127, Accuracy: 933/5000 (19%)\n",
      "[epoch 36] loss: 0.0034497\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.7140, Accuracy: 932/5000 (19%)\n",
      "[epoch 37] loss: 0.0032093\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 38] loss: 0.0035017\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 39] loss: 0.0032387\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 40] loss: 0.0031945\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 41] loss: 0.0033537\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 42] loss: 0.0032582\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 43] loss: 0.0034829\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 44] loss: 0.0031722\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 45] loss: 0.0033609\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 46] loss: 0.0031702\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 47] loss: 0.0033967\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 48] loss: 0.0030770\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 49] loss: 0.0031739\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "[epoch 50] loss: 0.0032254\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 5.7141, Accuracy: 932/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9441, Accuracy: 961/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 2.8953, Accuracy: 1906/10000 (19%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 527/5000 (11%)\n",
      "[epoch 1] loss: 2.2972660\n",
      "Test set: Average loss: 2.3033, Accuracy: 602/5000 (12%)\n",
      "[epoch 2] loss: 2.1184446\n",
      "Test set: Average loss: 2.3682, Accuracy: 820/5000 (16%)\n",
      "[epoch 3] loss: 2.1667349\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4279, Accuracy: 832/5000 (17%)\n",
      "[epoch 4] loss: 1.7384567\n",
      "Test set: Average loss: 2.4009, Accuracy: 844/5000 (17%)\n",
      "[epoch 5] loss: 1.6575460\n",
      "Test set: Average loss: 2.3715, Accuracy: 860/5000 (17%)\n",
      "[epoch 6] loss: 1.7393529\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3521, Accuracy: 867/5000 (17%)\n",
      "[epoch 7] loss: 1.6673869\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3520, Accuracy: 871/5000 (17%)\n",
      "[epoch 8] loss: 1.5454520\n",
      "Test set: Average loss: 2.3520, Accuracy: 873/5000 (17%)\n",
      "[epoch 9] loss: 1.7151618\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 10] loss: 1.6735963\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 11] loss: 1.6698799\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 12] loss: 1.6293563\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 13] loss: 1.7440349\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 14] loss: 1.7706282\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 15] loss: 1.6775647\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 16] loss: 1.5719776\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 17] loss: 1.6012591\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 18] loss: 1.6998100\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 19] loss: 1.7189420\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 20] loss: 1.7081420\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 21] loss: 1.6085401\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 22] loss: 1.7485464\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 23] loss: 1.5608926\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 24] loss: 1.6074449\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 25] loss: 1.9610822\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 26] loss: 1.9320260\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 27] loss: 1.6832741\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 28] loss: 1.7442583\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 29] loss: 1.9592626\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 30] loss: 1.7364541\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 31] loss: 1.8098247\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 32] loss: 1.5612310\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 33] loss: 1.7356646\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 34] loss: 1.6335093\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 35] loss: 1.9481360\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 36] loss: 1.7211109\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 37] loss: 1.6310124\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 38] loss: 1.7818320\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 39] loss: 1.8302628\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 40] loss: 1.7230482\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 41] loss: 1.8500572\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 42] loss: 1.8012722\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 43] loss: 1.7209092\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 44] loss: 1.6546101\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 45] loss: 1.7639110\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 46] loss: 1.6938027\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 47] loss: 1.6804116\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 48] loss: 1.8308314\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 49] loss: 1.7309750\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-47.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "[epoch 50] loss: 1.7899889\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-48.\n",
      "Test set: Average loss: 2.3521, Accuracy: 871/5000 (17%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3520, Accuracy: 873/5000 (17%)\n",
      "Test\n",
      "Test set: Average loss: 2.3193, Accuracy: 1825/10000 (18%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 458/5000 (9%)\n",
      "[epoch 1] loss: 2.3211049\n",
      "Test set: Average loss: 2.2738, Accuracy: 672/5000 (13%)\n",
      "[epoch 2] loss: 2.1178015\n",
      "Test set: Average loss: 2.2925, Accuracy: 735/5000 (15%)\n",
      "[epoch 3] loss: 2.0424828\n",
      "Test set: Average loss: 2.3526, Accuracy: 743/5000 (15%)\n",
      "[epoch 4] loss: 2.0581332\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2459, Accuracy: 920/5000 (18%)\n",
      "[epoch 5] loss: 1.8139983\n",
      "Test set: Average loss: 2.2263, Accuracy: 962/5000 (19%)\n",
      "[epoch 6] loss: 1.8501732\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.2176, Accuracy: 1018/5000 (20%)\n",
      "[epoch 7] loss: 1.7393072\n",
      "Test set: Average loss: 2.2162, Accuracy: 1020/5000 (20%)\n",
      "[epoch 8] loss: 1.8050574\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.2153, Accuracy: 1020/5000 (20%)\n",
      "[epoch 9] loss: 1.7001694\n",
      "Test set: Average loss: 2.2152, Accuracy: 1021/5000 (20%)\n",
      "[epoch 10] loss: 1.8894559\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 11] loss: 1.7418616\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 12] loss: 1.6712579\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 13] loss: 1.7449440\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 14] loss: 1.7492243\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 15] loss: 1.8622355\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 16] loss: 1.6856315\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 17] loss: 1.6195993\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 18] loss: 1.7789094\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 19] loss: 1.7321731\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 20] loss: 1.6776074\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 21] loss: 1.5961660\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 22] loss: 1.7083000\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 23] loss: 1.9794458\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 24] loss: 2.2009391\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 25] loss: 1.7510841\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 26] loss: 1.7161702\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 27] loss: 1.9023525\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 28] loss: 1.7862858\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 29] loss: 1.7122402\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 30] loss: 1.6430276\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 31] loss: 1.7191889\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 32] loss: 1.7630960\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 33] loss: 1.7207352\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 34] loss: 1.6386531\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 1.7294502\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 36] loss: 1.7592334\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 37] loss: 1.7577040\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 38] loss: 1.7106058\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 39] loss: 1.8040525\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 40] loss: 1.7359855\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 41] loss: 1.7196858\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 42] loss: 2.1389925\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 43] loss: 2.0225823\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 44] loss: 1.7932437\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 45] loss: 1.7437570\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 46] loss: 1.7232011\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 47] loss: 1.7439524\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 48] loss: 1.7955658\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 49] loss: 1.7786474\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "[epoch 50] loss: 1.7886035\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2151, Accuracy: 1021/5000 (20%)\n",
      "Test\n",
      "Test set: Average loss: 2.1942, Accuracy: 2151/10000 (22%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 550/5000 (11%)\n",
      "[epoch 1] loss: 2.2148974\n",
      "Test set: Average loss: 2.5778, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 2.0222747\n",
      "Test set: Average loss: 2.3714, Accuracy: 841/5000 (17%)\n",
      "[epoch 3] loss: 1.9571367\n",
      "Test set: Average loss: 2.3293, Accuracy: 779/5000 (16%)\n",
      "[epoch 4] loss: 1.8577902\n",
      "Test set: Average loss: 2.4089, Accuracy: 858/5000 (17%)\n",
      "[epoch 5] loss: 1.8090655\n",
      "Test set: Average loss: 2.4030, Accuracy: 901/5000 (18%)\n",
      "[epoch 6] loss: 1.5406607\n",
      "Test set: Average loss: 2.3847, Accuracy: 910/5000 (18%)\n",
      "[epoch 7] loss: 1.5279462\n",
      "Test set: Average loss: 2.5384, Accuracy: 934/5000 (19%)\n",
      "[epoch 8] loss: 1.3817567\n",
      "Test set: Average loss: 2.5150, Accuracy: 1010/5000 (20%)\n",
      "[epoch 9] loss: 1.1938007\n",
      "Test set: Average loss: 2.5742, Accuracy: 1053/5000 (21%)\n",
      "[epoch 10] loss: 0.8870910\n",
      "Test set: Average loss: 2.8926, Accuracy: 969/5000 (19%)\n",
      "[epoch 11] loss: 1.5174824\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.1616, Accuracy: 924/5000 (18%)\n",
      "[epoch 12] loss: 1.1132696\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.1644, Accuracy: 928/5000 (19%)\n",
      "[epoch 13] loss: 0.8429170\n",
      "Test set: Average loss: 3.1575, Accuracy: 930/5000 (19%)\n",
      "[epoch 14] loss: 0.8769012\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.1479, Accuracy: 936/5000 (19%)\n",
      "[epoch 15] loss: 0.8656886\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.1467, Accuracy: 940/5000 (19%)\n",
      "[epoch 16] loss: 0.8762120\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 17] loss: 0.8648427\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 18] loss: 0.8941068\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 19] loss: 0.8432271\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 20] loss: 0.8313544\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 21] loss: 0.8781733\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 22] loss: 0.8265152\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 23] loss: 0.8363835\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 24] loss: 0.9341175\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 25] loss: 0.6877797\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 26] loss: 0.7601861\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 27] loss: 0.8315062\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 28] loss: 0.8286100\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 29] loss: 0.7851682\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 30] loss: 1.5522252\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 31] loss: 0.8161029\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 32] loss: 0.7759397\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 33] loss: 0.8222473\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 34] loss: 0.7127354\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 35] loss: 0.8968063\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 36] loss: 0.9896894\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 37] loss: 0.9016762\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 38] loss: 0.7413175\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 39] loss: 0.9847889\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 40] loss: 0.8966265\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 41] loss: 0.8802923\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 42] loss: 0.7968686\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 43] loss: 1.0349026\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 44] loss: 0.8460319\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 45] loss: 0.9464674\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-34.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 46] loss: 0.7780232\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 47] loss: 0.8901805\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 48] loss: 0.9221103\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 49] loss: 0.8810097\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "[epoch 50] loss: 0.8942665\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 3.1466, Accuracy: 941/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5742, Accuracy: 1053/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 2.5864, Accuracy: 2083/10000 (21%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 475/5000 (10%)\n",
      "[epoch 1] loss: 2.2827322\n",
      "Test set: Average loss: 2.2383, Accuracy: 613/5000 (12%)\n",
      "[epoch 2] loss: 2.0921188\n",
      "Test set: Average loss: 2.1587, Accuracy: 986/5000 (20%)\n",
      "[epoch 3] loss: 1.8770615\n",
      "Test set: Average loss: 2.0812, Accuracy: 1186/5000 (24%)\n",
      "[epoch 4] loss: 1.7644962\n",
      "Test set: Average loss: 2.1440, Accuracy: 1187/5000 (24%)\n",
      "[epoch 5] loss: 1.5281363\n",
      "Test set: Average loss: 2.1044, Accuracy: 1275/5000 (26%)\n",
      "[epoch 6] loss: 1.3043247\n",
      "Test set: Average loss: 2.2297, Accuracy: 1335/5000 (27%)\n",
      "[epoch 7] loss: 1.0512311\n",
      "Test set: Average loss: 2.2532, Accuracy: 1434/5000 (29%)\n",
      "[epoch 8] loss: 0.9516099\n",
      "Test set: Average loss: 2.5329, Accuracy: 1313/5000 (26%)\n",
      "[epoch 9] loss: 0.7668221\n",
      "Test set: Average loss: 2.4850, Accuracy: 1477/5000 (30%)\n",
      "[epoch 10] loss: 0.5788044\n",
      "Test set: Average loss: 2.6464, Accuracy: 1493/5000 (30%)\n",
      "[epoch 11] loss: 0.4268559\n",
      "Test set: Average loss: 2.8970, Accuracy: 1421/5000 (28%)\n",
      "[epoch 12] loss: 0.3193241\n",
      "Test set: Average loss: 3.1480, Accuracy: 1422/5000 (28%)\n",
      "[epoch 13] loss: 0.1988030\n",
      "Test set: Average loss: 3.3611, Accuracy: 1451/5000 (29%)\n",
      "[epoch 14] loss: 0.1508411\n",
      "Test set: Average loss: 3.3922, Accuracy: 1495/5000 (30%)\n",
      "[epoch 15] loss: 0.1027041\n",
      "Test set: Average loss: 3.5415, Accuracy: 1444/5000 (29%)\n",
      "[epoch 16] loss: 0.0607753\n",
      "Test set: Average loss: 3.6491, Accuracy: 1522/5000 (30%)\n",
      "[epoch 17] loss: 0.0453479\n",
      "Test set: Average loss: 3.8069, Accuracy: 1489/5000 (30%)\n",
      "[epoch 18] loss: 0.0265717\n",
      "Test set: Average loss: 3.9642, Accuracy: 1448/5000 (29%)\n",
      "[epoch 19] loss: 0.0181517\n",
      "Test set: Average loss: 3.9543, Accuracy: 1527/5000 (31%)\n",
      "[epoch 20] loss: 0.0133490\n",
      "Test set: Average loss: 4.0389, Accuracy: 1501/5000 (30%)\n",
      "[epoch 21] loss: 0.0103952\n",
      "Test set: Average loss: 4.1514, Accuracy: 1472/5000 (29%)\n",
      "[epoch 22] loss: 0.0089002\n",
      "Test set: Average loss: 4.1852, Accuracy: 1496/5000 (30%)\n",
      "[epoch 23] loss: 0.0075424\n",
      "Test set: Average loss: 4.2040, Accuracy: 1504/5000 (30%)\n",
      "[epoch 24] loss: 0.0066694\n",
      "Test set: Average loss: 4.2739, Accuracy: 1480/5000 (30%)\n",
      "[epoch 25] loss: 0.0060086\n",
      "Test set: Average loss: 4.3001, Accuracy: 1485/5000 (30%)\n",
      "[epoch 26] loss: 0.0053376\n",
      "Test set: Average loss: 4.3167, Accuracy: 1484/5000 (30%)\n",
      "[epoch 27] loss: 0.0049592\n",
      "Test set: Average loss: 4.3524, Accuracy: 1492/5000 (30%)\n",
      "[epoch 28] loss: 0.0045488\n",
      "Test set: Average loss: 4.4001, Accuracy: 1489/5000 (30%)\n",
      "[epoch 29] loss: 0.0042633\n",
      "Test set: Average loss: 4.4211, Accuracy: 1480/5000 (30%)\n",
      "[epoch 30] loss: 0.0039159\n",
      "Test set: Average loss: 4.4451, Accuracy: 1481/5000 (30%)\n",
      "[epoch 31] loss: 0.0036601\n",
      "Test set: Average loss: 4.4634, Accuracy: 1492/5000 (30%)\n",
      "[epoch 32] loss: 0.0034818\n",
      "Test set: Average loss: 4.4994, Accuracy: 1482/5000 (30%)\n",
      "[epoch 33] loss: 0.0032164\n",
      "Test set: Average loss: 4.5137, Accuracy: 1488/5000 (30%)\n",
      "[epoch 34] loss: 0.0030603\n",
      "Test set: Average loss: 4.5393, Accuracy: 1485/5000 (30%)\n",
      "[epoch 35] loss: 0.0028767\n",
      "Test set: Average loss: 4.5673, Accuracy: 1482/5000 (30%)\n",
      "[epoch 36] loss: 0.0027087\n",
      "Test set: Average loss: 4.5872, Accuracy: 1478/5000 (30%)\n",
      "[epoch 37] loss: 0.0025799\n",
      "Test set: Average loss: 4.6010, Accuracy: 1484/5000 (30%)\n",
      "[epoch 38] loss: 0.0024240\n",
      "Test set: Average loss: 4.6233, Accuracy: 1482/5000 (30%)\n",
      "[epoch 39] loss: 0.0022978\n",
      "Test set: Average loss: 4.6455, Accuracy: 1480/5000 (30%)\n",
      "[epoch 40] loss: 0.0022292\n",
      "Test set: Average loss: 4.6674, Accuracy: 1476/5000 (30%)\n",
      "[epoch 41] loss: 0.0021271\n",
      "Test set: Average loss: 4.6845, Accuracy: 1478/5000 (30%)\n",
      "[epoch 42] loss: 0.0020205\n",
      "Test set: Average loss: 4.6955, Accuracy: 1479/5000 (30%)\n",
      "[epoch 43] loss: 0.0019299\n",
      "Test set: Average loss: 4.7172, Accuracy: 1482/5000 (30%)\n",
      "[epoch 44] loss: 0.0018448\n",
      "Test set: Average loss: 4.7304, Accuracy: 1481/5000 (30%)\n",
      "[epoch 45] loss: 0.0017648\n",
      "Test set: Average loss: 4.7444, Accuracy: 1488/5000 (30%)\n",
      "[epoch 46] loss: 0.0017224\n",
      "Test set: Average loss: 4.7619, Accuracy: 1480/5000 (30%)\n",
      "[epoch 47] loss: 0.0016296\n",
      "Test set: Average loss: 4.7801, Accuracy: 1484/5000 (30%)\n",
      "[epoch 48] loss: 0.0015594\n",
      "Test set: Average loss: 4.7969, Accuracy: 1484/5000 (30%)\n",
      "[epoch 49] loss: 0.0014948\n",
      "Test set: Average loss: 4.8134, Accuracy: 1480/5000 (30%)\n",
      "[epoch 50] loss: 0.0014473\n",
      "Test set: Average loss: 4.8257, Accuracy: 1481/5000 (30%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.9543, Accuracy: 1527/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 3.8939, Accuracy: 3075/10000 (31%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3030, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 2.2832870\n",
      "Test set: Average loss: 2.1944, Accuracy: 1072/5000 (21%)\n",
      "[epoch 2] loss: 2.0595618\n",
      "Test set: Average loss: 2.1016, Accuracy: 1306/5000 (26%)\n",
      "[epoch 3] loss: 1.8494492\n",
      "Test set: Average loss: 2.0944, Accuracy: 1238/5000 (25%)\n",
      "[epoch 4] loss: 1.6409182\n",
      "Test set: Average loss: 2.1513, Accuracy: 1295/5000 (26%)\n",
      "[epoch 5] loss: 1.4789089\n",
      "Test set: Average loss: 2.0456, Accuracy: 1413/5000 (28%)\n",
      "[epoch 6] loss: 1.3021625\n",
      "Test set: Average loss: 2.0489, Accuracy: 1497/5000 (30%)\n",
      "[epoch 7] loss: 1.1015733\n",
      "Test set: Average loss: 2.1563, Accuracy: 1473/5000 (29%)\n",
      "[epoch 8] loss: 0.9725132\n",
      "Test set: Average loss: 2.1854, Accuracy: 1488/5000 (30%)\n",
      "[epoch 9] loss: 0.7889293\n",
      "Test set: Average loss: 2.3143, Accuracy: 1551/5000 (31%)\n",
      "[epoch 10] loss: 0.6351328\n",
      "Test set: Average loss: 2.4432, Accuracy: 1470/5000 (29%)\n",
      "[epoch 11] loss: 0.5192338\n",
      "Test set: Average loss: 2.4540, Accuracy: 1602/5000 (32%)\n",
      "[epoch 12] loss: 0.3925892\n",
      "Test set: Average loss: 2.6435, Accuracy: 1579/5000 (32%)\n",
      "[epoch 13] loss: 0.2814485\n",
      "Test set: Average loss: 2.7470, Accuracy: 1572/5000 (31%)\n",
      "[epoch 14] loss: 0.2047432\n",
      "Test set: Average loss: 2.8727, Accuracy: 1625/5000 (32%)\n",
      "[epoch 15] loss: 0.1420907\n",
      "Test set: Average loss: 3.0595, Accuracy: 1610/5000 (32%)\n",
      "[epoch 16] loss: 0.1139529\n",
      "Test set: Average loss: 3.3123, Accuracy: 1524/5000 (30%)\n",
      "[epoch 17] loss: 0.0882800\n",
      "Test set: Average loss: 3.3345, Accuracy: 1543/5000 (31%)\n",
      "[epoch 18] loss: 0.0798486\n",
      "Test set: Average loss: 3.5756, Accuracy: 1540/5000 (31%)\n",
      "[epoch 19] loss: 0.0472406\n",
      "Test set: Average loss: 3.5244, Accuracy: 1578/5000 (32%)\n",
      "[epoch 20] loss: 0.0359571\n",
      "Test set: Average loss: 3.6733, Accuracy: 1575/5000 (32%)\n",
      "[epoch 21] loss: 0.0269432\n",
      "Test set: Average loss: 3.7674, Accuracy: 1553/5000 (31%)\n",
      "[epoch 22] loss: 0.0161271\n",
      "Test set: Average loss: 3.7957, Accuracy: 1572/5000 (31%)\n",
      "[epoch 23] loss: 0.0131129\n",
      "Test set: Average loss: 3.8157, Accuracy: 1589/5000 (32%)\n",
      "[epoch 24] loss: 0.0103581\n",
      "Test set: Average loss: 3.9167, Accuracy: 1569/5000 (31%)\n",
      "[epoch 25] loss: 0.0082872\n",
      "Test set: Average loss: 3.9719, Accuracy: 1559/5000 (31%)\n",
      "[epoch 26] loss: 0.0076888\n",
      "Test set: Average loss: 4.0072, Accuracy: 1571/5000 (31%)\n",
      "[epoch 27] loss: 0.0065088\n",
      "Test set: Average loss: 4.0483, Accuracy: 1560/5000 (31%)\n",
      "[epoch 28] loss: 0.0060737\n",
      "Test set: Average loss: 4.0812, Accuracy: 1561/5000 (31%)\n",
      "[epoch 29] loss: 0.0054920\n",
      "Test set: Average loss: 4.1126, Accuracy: 1571/5000 (31%)\n",
      "[epoch 30] loss: 0.0049854\n",
      "Test set: Average loss: 4.1576, Accuracy: 1563/5000 (31%)\n",
      "[epoch 31] loss: 0.0046876\n",
      "Test set: Average loss: 4.1771, Accuracy: 1563/5000 (31%)\n",
      "[epoch 32] loss: 0.0042913\n",
      "Test set: Average loss: 4.1975, Accuracy: 1571/5000 (31%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] loss: 0.0039814\n",
      "Test set: Average loss: 4.2366, Accuracy: 1557/5000 (31%)\n",
      "[epoch 34] loss: 0.0038053\n",
      "Test set: Average loss: 4.2577, Accuracy: 1558/5000 (31%)\n",
      "[epoch 35] loss: 0.0035414\n",
      "Test set: Average loss: 4.2746, Accuracy: 1569/5000 (31%)\n",
      "[epoch 36] loss: 0.0033888\n",
      "Test set: Average loss: 4.2940, Accuracy: 1572/5000 (31%)\n",
      "[epoch 37] loss: 0.0031668\n",
      "Test set: Average loss: 4.3261, Accuracy: 1561/5000 (31%)\n",
      "[epoch 38] loss: 0.0029827\n",
      "Test set: Average loss: 4.3421, Accuracy: 1565/5000 (31%)\n",
      "[epoch 39] loss: 0.0028026\n",
      "Test set: Average loss: 4.3619, Accuracy: 1570/5000 (31%)\n",
      "[epoch 40] loss: 0.0026942\n",
      "Test set: Average loss: 4.3779, Accuracy: 1565/5000 (31%)\n",
      "[epoch 41] loss: 0.0025151\n",
      "Test set: Average loss: 4.4042, Accuracy: 1566/5000 (31%)\n",
      "[epoch 42] loss: 0.0024095\n",
      "Test set: Average loss: 4.4216, Accuracy: 1569/5000 (31%)\n",
      "[epoch 43] loss: 0.0023152\n",
      "Test set: Average loss: 4.4374, Accuracy: 1572/5000 (31%)\n",
      "[epoch 44] loss: 0.0021951\n",
      "Test set: Average loss: 4.4550, Accuracy: 1566/5000 (31%)\n",
      "[epoch 45] loss: 0.0021422\n",
      "Test set: Average loss: 4.4727, Accuracy: 1568/5000 (31%)\n",
      "[epoch 46] loss: 0.0020360\n",
      "Test set: Average loss: 4.4877, Accuracy: 1564/5000 (31%)\n",
      "[epoch 47] loss: 0.0019208\n",
      "Test set: Average loss: 4.4968, Accuracy: 1571/5000 (31%)\n",
      "[epoch 48] loss: 0.0018592\n",
      "Test set: Average loss: 4.5155, Accuracy: 1571/5000 (31%)\n",
      "[epoch 49] loss: 0.0017872\n",
      "Test set: Average loss: 4.5341, Accuracy: 1567/5000 (31%)\n",
      "[epoch 50] loss: 0.0017195\n",
      "Test set: Average loss: 4.5491, Accuracy: 1572/5000 (31%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8727, Accuracy: 1625/5000 (32%)\n",
      "Test\n",
      "Test set: Average loss: 2.8321, Accuracy: 3249/10000 (32%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 2.2976987\n",
      "Test set: Average loss: 2.2492, Accuracy: 784/5000 (16%)\n",
      "[epoch 2] loss: 2.1481793\n",
      "Test set: Average loss: 2.2110, Accuracy: 956/5000 (19%)\n",
      "[epoch 3] loss: 2.0374908\n",
      "Test set: Average loss: 2.1110, Accuracy: 1164/5000 (23%)\n",
      "[epoch 4] loss: 1.8476980\n",
      "Test set: Average loss: 2.0618, Accuracy: 1364/5000 (27%)\n",
      "[epoch 5] loss: 1.6331460\n",
      "Test set: Average loss: 2.1156, Accuracy: 1344/5000 (27%)\n",
      "[epoch 6] loss: 1.3848037\n",
      "Test set: Average loss: 2.2373, Accuracy: 1335/5000 (27%)\n",
      "[epoch 7] loss: 1.2177058\n",
      "Test set: Average loss: 2.3228, Accuracy: 1362/5000 (27%)\n",
      "[epoch 8] loss: 1.0013368\n",
      "Test set: Average loss: 2.3836, Accuracy: 1432/5000 (29%)\n",
      "[epoch 9] loss: 0.7936344\n",
      "Test set: Average loss: 2.5120, Accuracy: 1428/5000 (29%)\n",
      "[epoch 10] loss: 0.5881136\n",
      "Test set: Average loss: 2.9274, Accuracy: 1421/5000 (28%)\n",
      "[epoch 11] loss: 0.5235222\n",
      "Test set: Average loss: 2.9157, Accuracy: 1393/5000 (28%)\n",
      "[epoch 12] loss: 0.3903424\n",
      "Test set: Average loss: 3.1686, Accuracy: 1434/5000 (29%)\n",
      "[epoch 13] loss: 0.2701786\n",
      "Test set: Average loss: 3.2492, Accuracy: 1442/5000 (29%)\n",
      "[epoch 14] loss: 0.1913550\n",
      "Test set: Average loss: 3.4532, Accuracy: 1472/5000 (29%)\n",
      "[epoch 15] loss: 0.1299699\n",
      "Test set: Average loss: 3.6027, Accuracy: 1462/5000 (29%)\n",
      "[epoch 16] loss: 0.1003177\n",
      "Test set: Average loss: 3.8232, Accuracy: 1463/5000 (29%)\n",
      "[epoch 17] loss: 0.0888041\n",
      "Test set: Average loss: 3.9271, Accuracy: 1450/5000 (29%)\n",
      "[epoch 18] loss: 0.0526803\n",
      "Test set: Average loss: 4.1107, Accuracy: 1399/5000 (28%)\n",
      "[epoch 19] loss: 0.0246922\n",
      "Test set: Average loss: 4.1478, Accuracy: 1440/5000 (29%)\n",
      "[epoch 20] loss: 0.0180682\n",
      "Test set: Average loss: 4.2236, Accuracy: 1483/5000 (30%)\n",
      "[epoch 21] loss: 0.0134159\n",
      "Test set: Average loss: 4.2990, Accuracy: 1441/5000 (29%)\n",
      "[epoch 22] loss: 0.0097222\n",
      "Test set: Average loss: 4.3963, Accuracy: 1448/5000 (29%)\n",
      "[epoch 23] loss: 0.0080117\n",
      "Test set: Average loss: 4.4708, Accuracy: 1448/5000 (29%)\n",
      "[epoch 24] loss: 0.0062448\n",
      "Test set: Average loss: 4.5009, Accuracy: 1457/5000 (29%)\n",
      "[epoch 25] loss: 0.0055492\n",
      "Test set: Average loss: 4.5321, Accuracy: 1449/5000 (29%)\n",
      "[epoch 26] loss: 0.0049533\n",
      "Test set: Average loss: 4.5650, Accuracy: 1444/5000 (29%)\n",
      "[epoch 27] loss: 0.0045198\n",
      "Test set: Average loss: 4.5979, Accuracy: 1447/5000 (29%)\n",
      "[epoch 28] loss: 0.0041264\n",
      "Test set: Average loss: 4.6272, Accuracy: 1456/5000 (29%)\n",
      "[epoch 29] loss: 0.0038265\n",
      "Test set: Average loss: 4.6544, Accuracy: 1456/5000 (29%)\n",
      "[epoch 30] loss: 0.0036411\n",
      "Test set: Average loss: 4.6795, Accuracy: 1461/5000 (29%)\n",
      "[epoch 31] loss: 0.0034094\n",
      "Test set: Average loss: 4.7076, Accuracy: 1451/5000 (29%)\n",
      "[epoch 32] loss: 0.0031738\n",
      "Test set: Average loss: 4.7371, Accuracy: 1457/5000 (29%)\n",
      "[epoch 33] loss: 0.0030155\n",
      "Test set: Average loss: 4.7625, Accuracy: 1456/5000 (29%)\n",
      "[epoch 34] loss: 0.0028287\n",
      "Test set: Average loss: 4.7788, Accuracy: 1454/5000 (29%)\n",
      "[epoch 35] loss: 0.0027080\n",
      "Test set: Average loss: 4.8021, Accuracy: 1453/5000 (29%)\n",
      "[epoch 36] loss: 0.0025807\n",
      "Test set: Average loss: 4.8217, Accuracy: 1456/5000 (29%)\n",
      "[epoch 37] loss: 0.0024615\n",
      "Test set: Average loss: 4.8429, Accuracy: 1459/5000 (29%)\n",
      "[epoch 38] loss: 0.0023634\n",
      "Test set: Average loss: 4.8630, Accuracy: 1456/5000 (29%)\n",
      "[epoch 39] loss: 0.0022229\n",
      "Test set: Average loss: 4.8794, Accuracy: 1453/5000 (29%)\n",
      "[epoch 40] loss: 0.0021482\n",
      "Test set: Average loss: 4.8978, Accuracy: 1457/5000 (29%)\n",
      "[epoch 41] loss: 0.0020517\n",
      "Test set: Average loss: 4.9165, Accuracy: 1459/5000 (29%)\n",
      "[epoch 42] loss: 0.0019626\n",
      "Test set: Average loss: 4.9322, Accuracy: 1454/5000 (29%)\n",
      "[epoch 43] loss: 0.0018962\n",
      "Test set: Average loss: 4.9521, Accuracy: 1454/5000 (29%)\n",
      "[epoch 44] loss: 0.0018327\n",
      "Test set: Average loss: 4.9692, Accuracy: 1453/5000 (29%)\n",
      "[epoch 45] loss: 0.0017419\n",
      "Test set: Average loss: 4.9854, Accuracy: 1450/5000 (29%)\n",
      "[epoch 46] loss: 0.0016731\n",
      "Test set: Average loss: 4.9976, Accuracy: 1453/5000 (29%)\n",
      "[epoch 47] loss: 0.0016255\n",
      "Test set: Average loss: 5.0124, Accuracy: 1456/5000 (29%)\n",
      "[epoch 48] loss: 0.0015630\n",
      "Test set: Average loss: 5.0336, Accuracy: 1453/5000 (29%)\n",
      "[epoch 49] loss: 0.0014976\n",
      "Test set: Average loss: 5.0464, Accuracy: 1453/5000 (29%)\n",
      "[epoch 50] loss: 0.0014503\n",
      "Test set: Average loss: 5.0597, Accuracy: 1455/5000 (29%)\n",
      "Validation:\n",
      "Test set: Average loss: 4.2236, Accuracy: 1483/5000 (30%)\n",
      "Test\n",
      "Test set: Average loss: 4.1946, Accuracy: 3045/10000 (30%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 494/5000 (10%)\n",
      "[epoch 1] loss: 2.2285833\n",
      "Test set: Average loss: 2.1132, Accuracy: 1074/5000 (21%)\n",
      "[epoch 2] loss: 1.9856062\n",
      "Test set: Average loss: 2.0571, Accuracy: 1351/5000 (27%)\n",
      "[epoch 3] loss: 1.7893735\n",
      "Test set: Average loss: 1.9382, Accuracy: 1512/5000 (30%)\n",
      "[epoch 4] loss: 1.5945676\n",
      "Test set: Average loss: 1.9780, Accuracy: 1541/5000 (31%)\n",
      "[epoch 5] loss: 1.3969796\n",
      "Test set: Average loss: 1.8690, Accuracy: 1720/5000 (34%)\n",
      "[epoch 6] loss: 1.2106621\n",
      "Test set: Average loss: 2.0642, Accuracy: 1623/5000 (32%)\n",
      "[epoch 7] loss: 1.0584870\n",
      "Test set: Average loss: 2.0024, Accuracy: 1677/5000 (34%)\n",
      "[epoch 8] loss: 0.8604825\n",
      "Test set: Average loss: 2.2005, Accuracy: 1665/5000 (33%)\n",
      "[epoch 9] loss: 0.6437765\n",
      "Test set: Average loss: 2.3033, Accuracy: 1688/5000 (34%)\n",
      "[epoch 10] loss: 0.5125748\n",
      "Test set: Average loss: 2.4872, Accuracy: 1731/5000 (35%)\n",
      "[epoch 11] loss: 0.3301517\n",
      "Test set: Average loss: 2.8339, Accuracy: 1688/5000 (34%)\n",
      "[epoch 12] loss: 0.2752599\n",
      "Test set: Average loss: 2.9103, Accuracy: 1673/5000 (33%)\n",
      "[epoch 13] loss: 0.1560754\n",
      "Test set: Average loss: 3.2127, Accuracy: 1663/5000 (33%)\n",
      "[epoch 14] loss: 0.0887448\n",
      "Test set: Average loss: 3.4773, Accuracy: 1706/5000 (34%)\n",
      "[epoch 15] loss: 0.0637579\n",
      "Test set: Average loss: 3.5591, Accuracy: 1674/5000 (33%)\n",
      "[epoch 16] loss: 0.0369608\n",
      "Test set: Average loss: 3.7568, Accuracy: 1694/5000 (34%)\n",
      "[epoch 17] loss: 0.0230060\n",
      "Test set: Average loss: 3.8113, Accuracy: 1692/5000 (34%)\n",
      "[epoch 18] loss: 0.0132157\n",
      "Test set: Average loss: 3.9253, Accuracy: 1691/5000 (34%)\n",
      "[epoch 19] loss: 0.0107249\n",
      "Test set: Average loss: 3.9806, Accuracy: 1698/5000 (34%)\n",
      "[epoch 20] loss: 0.0084207\n",
      "Test set: Average loss: 4.0474, Accuracy: 1697/5000 (34%)\n",
      "[epoch 21] loss: 0.0070635\n",
      "Test set: Average loss: 4.1003, Accuracy: 1687/5000 (34%)\n",
      "[epoch 22] loss: 0.0062104\n",
      "Test set: Average loss: 4.1424, Accuracy: 1708/5000 (34%)\n",
      "[epoch 23] loss: 0.0054045\n",
      "Test set: Average loss: 4.1899, Accuracy: 1697/5000 (34%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24] loss: 0.0048706\n",
      "Test set: Average loss: 4.2268, Accuracy: 1695/5000 (34%)\n",
      "[epoch 25] loss: 0.0044653\n",
      "Test set: Average loss: 4.2691, Accuracy: 1694/5000 (34%)\n",
      "[epoch 26] loss: 0.0040495\n",
      "Test set: Average loss: 4.2954, Accuracy: 1700/5000 (34%)\n",
      "[epoch 27] loss: 0.0037611\n",
      "Test set: Average loss: 4.3341, Accuracy: 1694/5000 (34%)\n",
      "[epoch 28] loss: 0.0034523\n",
      "Test set: Average loss: 4.3646, Accuracy: 1704/5000 (34%)\n",
      "[epoch 29] loss: 0.0031765\n",
      "Test set: Average loss: 4.4016, Accuracy: 1697/5000 (34%)\n",
      "[epoch 30] loss: 0.0029661\n",
      "Test set: Average loss: 4.4322, Accuracy: 1705/5000 (34%)\n",
      "[epoch 31] loss: 0.0027269\n",
      "Test set: Average loss: 4.4539, Accuracy: 1696/5000 (34%)\n",
      "[epoch 32] loss: 0.0025819\n",
      "Test set: Average loss: 4.4845, Accuracy: 1695/5000 (34%)\n",
      "[epoch 33] loss: 0.0024198\n",
      "Test set: Average loss: 4.5100, Accuracy: 1695/5000 (34%)\n",
      "[epoch 34] loss: 0.0022847\n",
      "Test set: Average loss: 4.5361, Accuracy: 1704/5000 (34%)\n",
      "[epoch 35] loss: 0.0021340\n",
      "Test set: Average loss: 4.5558, Accuracy: 1693/5000 (34%)\n",
      "[epoch 36] loss: 0.0020258\n",
      "Test set: Average loss: 4.5804, Accuracy: 1709/5000 (34%)\n",
      "[epoch 37] loss: 0.0018984\n",
      "Test set: Average loss: 4.6042, Accuracy: 1706/5000 (34%)\n",
      "[epoch 38] loss: 0.0017934\n",
      "Test set: Average loss: 4.6270, Accuracy: 1703/5000 (34%)\n",
      "[epoch 39] loss: 0.0017123\n",
      "Test set: Average loss: 4.6451, Accuracy: 1703/5000 (34%)\n",
      "[epoch 40] loss: 0.0016305\n",
      "Test set: Average loss: 4.6677, Accuracy: 1694/5000 (34%)\n",
      "[epoch 41] loss: 0.0015481\n",
      "Test set: Average loss: 4.6868, Accuracy: 1702/5000 (34%)\n",
      "[epoch 42] loss: 0.0014955\n",
      "Test set: Average loss: 4.7039, Accuracy: 1696/5000 (34%)\n",
      "[epoch 43] loss: 0.0014348\n",
      "Test set: Average loss: 4.7251, Accuracy: 1699/5000 (34%)\n",
      "[epoch 44] loss: 0.0013447\n",
      "Test set: Average loss: 4.7437, Accuracy: 1690/5000 (34%)\n",
      "[epoch 45] loss: 0.0012809\n",
      "Test set: Average loss: 4.7635, Accuracy: 1702/5000 (34%)\n",
      "[epoch 46] loss: 0.0012231\n",
      "Test set: Average loss: 4.7798, Accuracy: 1699/5000 (34%)\n",
      "[epoch 47] loss: 0.0011797\n",
      "Test set: Average loss: 4.7992, Accuracy: 1688/5000 (34%)\n",
      "[epoch 48] loss: 0.0011257\n",
      "Test set: Average loss: 4.8142, Accuracy: 1696/5000 (34%)\n",
      "[epoch 49] loss: 0.0010754\n",
      "Test set: Average loss: 4.8293, Accuracy: 1694/5000 (34%)\n",
      "[epoch 50] loss: 0.0010485\n",
      "Test set: Average loss: 4.8446, Accuracy: 1696/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4872, Accuracy: 1731/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 2.4387, Accuracy: 3556/10000 (36%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 2.2252888\n",
      "Test set: Average loss: 2.1984, Accuracy: 1114/5000 (22%)\n",
      "[epoch 2] loss: 1.9707280\n",
      "Test set: Average loss: 2.0645, Accuracy: 1265/5000 (25%)\n",
      "[epoch 3] loss: 1.7624294\n",
      "Test set: Average loss: 1.9172, Accuracy: 1545/5000 (31%)\n",
      "[epoch 4] loss: 1.5606222\n",
      "Test set: Average loss: 1.9199, Accuracy: 1543/5000 (31%)\n",
      "[epoch 5] loss: 1.3700881\n",
      "Test set: Average loss: 1.9024, Accuracy: 1562/5000 (31%)\n",
      "[epoch 6] loss: 1.1619130\n",
      "Test set: Average loss: 1.9655, Accuracy: 1694/5000 (34%)\n",
      "[epoch 7] loss: 1.0047785\n",
      "Test set: Average loss: 2.0593, Accuracy: 1716/5000 (34%)\n",
      "[epoch 8] loss: 0.8877603\n",
      "Test set: Average loss: 2.0589, Accuracy: 1769/5000 (35%)\n",
      "[epoch 9] loss: 0.6934779\n",
      "Test set: Average loss: 2.2509, Accuracy: 1660/5000 (33%)\n",
      "[epoch 10] loss: 0.5272169\n",
      "Test set: Average loss: 2.3660, Accuracy: 1716/5000 (34%)\n",
      "[epoch 11] loss: 0.3788563\n",
      "Test set: Average loss: 2.6128, Accuracy: 1658/5000 (33%)\n",
      "[epoch 12] loss: 0.2676729\n",
      "Test set: Average loss: 2.9490, Accuracy: 1579/5000 (32%)\n",
      "[epoch 13] loss: 0.2157172\n",
      "Test set: Average loss: 2.9668, Accuracy: 1701/5000 (34%)\n",
      "[epoch 14] loss: 0.1377241\n",
      "Test set: Average loss: 3.1882, Accuracy: 1702/5000 (34%)\n",
      "[epoch 15] loss: 0.1239117\n",
      "Test set: Average loss: 3.2848, Accuracy: 1656/5000 (33%)\n",
      "[epoch 16] loss: 0.0915224\n",
      "Test set: Average loss: 3.5415, Accuracy: 1674/5000 (33%)\n",
      "[epoch 17] loss: 0.0815018\n",
      "Test set: Average loss: 3.5255, Accuracy: 1729/5000 (35%)\n",
      "[epoch 18] loss: 0.0476167\n",
      "Test set: Average loss: 3.6804, Accuracy: 1685/5000 (34%)\n",
      "[epoch 19] loss: 0.0304019\n",
      "Test set: Average loss: 3.7436, Accuracy: 1652/5000 (33%)\n",
      "[epoch 20] loss: 0.0192149\n",
      "Test set: Average loss: 3.8239, Accuracy: 1700/5000 (34%)\n",
      "[epoch 21] loss: 0.0144078\n",
      "Test set: Average loss: 3.8851, Accuracy: 1705/5000 (34%)\n",
      "[epoch 22] loss: 0.0092793\n",
      "Test set: Average loss: 3.9686, Accuracy: 1703/5000 (34%)\n",
      "[epoch 23] loss: 0.0065468\n",
      "Test set: Average loss: 3.9972, Accuracy: 1700/5000 (34%)\n",
      "[epoch 24] loss: 0.0052596\n",
      "Test set: Average loss: 4.0466, Accuracy: 1709/5000 (34%)\n",
      "[epoch 25] loss: 0.0044937\n",
      "Test set: Average loss: 4.0767, Accuracy: 1704/5000 (34%)\n",
      "[epoch 26] loss: 0.0041527\n",
      "Test set: Average loss: 4.1090, Accuracy: 1709/5000 (34%)\n",
      "[epoch 27] loss: 0.0038156\n",
      "Test set: Average loss: 4.1433, Accuracy: 1707/5000 (34%)\n",
      "[epoch 28] loss: 0.0035276\n",
      "Test set: Average loss: 4.1787, Accuracy: 1695/5000 (34%)\n",
      "[epoch 29] loss: 0.0032584\n",
      "Test set: Average loss: 4.2041, Accuracy: 1710/5000 (34%)\n",
      "[epoch 30] loss: 0.0030480\n",
      "Test set: Average loss: 4.2357, Accuracy: 1710/5000 (34%)\n",
      "[epoch 31] loss: 0.0028847\n",
      "Test set: Average loss: 4.2601, Accuracy: 1709/5000 (34%)\n",
      "[epoch 32] loss: 0.0026580\n",
      "Test set: Average loss: 4.2883, Accuracy: 1703/5000 (34%)\n",
      "[epoch 33] loss: 0.0025011\n",
      "Test set: Average loss: 4.3085, Accuracy: 1706/5000 (34%)\n",
      "[epoch 34] loss: 0.0023796\n",
      "Test set: Average loss: 4.3298, Accuracy: 1706/5000 (34%)\n",
      "[epoch 35] loss: 0.0022537\n",
      "Test set: Average loss: 4.3539, Accuracy: 1702/5000 (34%)\n",
      "[epoch 36] loss: 0.0021480\n",
      "Test set: Average loss: 4.3771, Accuracy: 1705/5000 (34%)\n",
      "[epoch 37] loss: 0.0020228\n",
      "Test set: Average loss: 4.4002, Accuracy: 1699/5000 (34%)\n",
      "[epoch 38] loss: 0.0019437\n",
      "Test set: Average loss: 4.4170, Accuracy: 1700/5000 (34%)\n",
      "[epoch 39] loss: 0.0018366\n",
      "Test set: Average loss: 4.4367, Accuracy: 1703/5000 (34%)\n",
      "[epoch 40] loss: 0.0017490\n",
      "Test set: Average loss: 4.4600, Accuracy: 1696/5000 (34%)\n",
      "[epoch 41] loss: 0.0016776\n",
      "Test set: Average loss: 4.4766, Accuracy: 1696/5000 (34%)\n",
      "[epoch 42] loss: 0.0016056\n",
      "Test set: Average loss: 4.4931, Accuracy: 1698/5000 (34%)\n",
      "[epoch 43] loss: 0.0015249\n",
      "Test set: Average loss: 4.5139, Accuracy: 1703/5000 (34%)\n",
      "[epoch 44] loss: 0.0014777\n",
      "Test set: Average loss: 4.5305, Accuracy: 1698/5000 (34%)\n",
      "[epoch 45] loss: 0.0014138\n",
      "Test set: Average loss: 4.5480, Accuracy: 1703/5000 (34%)\n",
      "[epoch 46] loss: 0.0013602\n",
      "Test set: Average loss: 4.5641, Accuracy: 1703/5000 (34%)\n",
      "[epoch 47] loss: 0.0012984\n",
      "Test set: Average loss: 4.5809, Accuracy: 1705/5000 (34%)\n",
      "[epoch 48] loss: 0.0012528\n",
      "Test set: Average loss: 4.5964, Accuracy: 1700/5000 (34%)\n",
      "[epoch 49] loss: 0.0012029\n",
      "Test set: Average loss: 4.6106, Accuracy: 1702/5000 (34%)\n",
      "[epoch 50] loss: 0.0011611\n",
      "Test set: Average loss: 4.6265, Accuracy: 1701/5000 (34%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0589, Accuracy: 1769/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 2.0173, Accuracy: 3636/10000 (36%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 504/5000 (10%)\n",
      "[epoch 1] loss: 2.2709682\n",
      "Test set: Average loss: 2.1519, Accuracy: 1068/5000 (21%)\n",
      "[epoch 2] loss: 2.0301381\n",
      "Test set: Average loss: 2.0140, Accuracy: 1259/5000 (25%)\n",
      "[epoch 3] loss: 1.8469069\n",
      "Test set: Average loss: 1.9485, Accuracy: 1528/5000 (31%)\n",
      "[epoch 4] loss: 1.6555863\n",
      "Test set: Average loss: 1.9419, Accuracy: 1628/5000 (33%)\n",
      "[epoch 5] loss: 1.4407385\n",
      "Test set: Average loss: 1.9390, Accuracy: 1722/5000 (34%)\n",
      "[epoch 6] loss: 1.2441645\n",
      "Test set: Average loss: 2.0303, Accuracy: 1740/5000 (35%)\n",
      "[epoch 7] loss: 1.0226209\n",
      "Test set: Average loss: 2.2067, Accuracy: 1674/5000 (33%)\n",
      "[epoch 8] loss: 0.8765580\n",
      "Test set: Average loss: 2.3100, Accuracy: 1621/5000 (32%)\n",
      "[epoch 9] loss: 0.6340868\n",
      "Test set: Average loss: 2.5153, Accuracy: 1602/5000 (32%)\n",
      "[epoch 10] loss: 0.5015427\n",
      "Test set: Average loss: 2.8214, Accuracy: 1606/5000 (32%)\n",
      "[epoch 11] loss: 0.4379545\n",
      "Test set: Average loss: 2.9597, Accuracy: 1561/5000 (31%)\n",
      "[epoch 12] loss: 0.3154487\n",
      "Test set: Average loss: 3.0899, Accuracy: 1646/5000 (33%)\n",
      "[epoch 13] loss: 0.2143462\n",
      "Test set: Average loss: 3.5367, Accuracy: 1531/5000 (31%)\n",
      "[epoch 14] loss: 0.1727194\n",
      "Test set: Average loss: 3.4757, Accuracy: 1590/5000 (32%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] loss: 0.1081534\n",
      "Test set: Average loss: 3.6640, Accuracy: 1581/5000 (32%)\n",
      "[epoch 16] loss: 0.0599617\n",
      "Test set: Average loss: 3.8779, Accuracy: 1611/5000 (32%)\n",
      "[epoch 17] loss: 0.0484078\n",
      "Test set: Average loss: 4.0082, Accuracy: 1595/5000 (32%)\n",
      "[epoch 18] loss: 0.0349047\n",
      "Test set: Average loss: 4.0678, Accuracy: 1633/5000 (33%)\n",
      "[epoch 19] loss: 0.0199189\n",
      "Test set: Average loss: 4.1613, Accuracy: 1601/5000 (32%)\n",
      "[epoch 20] loss: 0.0118822\n",
      "Test set: Average loss: 4.1772, Accuracy: 1637/5000 (33%)\n",
      "[epoch 21] loss: 0.0082746\n",
      "Test set: Average loss: 4.2499, Accuracy: 1648/5000 (33%)\n",
      "[epoch 22] loss: 0.0063438\n",
      "Test set: Average loss: 4.3162, Accuracy: 1637/5000 (33%)\n",
      "[epoch 23] loss: 0.0056944\n",
      "Test set: Average loss: 4.3579, Accuracy: 1643/5000 (33%)\n",
      "[epoch 24] loss: 0.0048702\n",
      "Test set: Average loss: 4.4055, Accuracy: 1655/5000 (33%)\n",
      "[epoch 25] loss: 0.0043879\n",
      "Test set: Average loss: 4.4475, Accuracy: 1661/5000 (33%)\n",
      "[epoch 26] loss: 0.0039862\n",
      "Test set: Average loss: 4.4790, Accuracy: 1649/5000 (33%)\n",
      "[epoch 27] loss: 0.0036368\n",
      "Test set: Average loss: 4.5163, Accuracy: 1650/5000 (33%)\n",
      "[epoch 28] loss: 0.0033346\n",
      "Test set: Average loss: 4.5473, Accuracy: 1650/5000 (33%)\n",
      "[epoch 29] loss: 0.0031113\n",
      "Test set: Average loss: 4.5772, Accuracy: 1650/5000 (33%)\n",
      "[epoch 30] loss: 0.0029789\n",
      "Test set: Average loss: 4.6037, Accuracy: 1660/5000 (33%)\n",
      "[epoch 31] loss: 0.0027658\n",
      "Test set: Average loss: 4.6384, Accuracy: 1644/5000 (33%)\n",
      "[epoch 32] loss: 0.0025817\n",
      "Test set: Average loss: 4.6589, Accuracy: 1661/5000 (33%)\n",
      "[epoch 33] loss: 0.0024050\n",
      "Test set: Average loss: 4.6861, Accuracy: 1652/5000 (33%)\n",
      "[epoch 34] loss: 0.0022834\n",
      "Test set: Average loss: 4.7144, Accuracy: 1640/5000 (33%)\n",
      "[epoch 35] loss: 0.0021658\n",
      "Test set: Average loss: 4.7282, Accuracy: 1658/5000 (33%)\n",
      "[epoch 36] loss: 0.0020269\n",
      "Test set: Average loss: 4.7593, Accuracy: 1651/5000 (33%)\n",
      "[epoch 37] loss: 0.0019180\n",
      "Test set: Average loss: 4.7811, Accuracy: 1647/5000 (33%)\n",
      "[epoch 38] loss: 0.0018260\n",
      "Test set: Average loss: 4.8006, Accuracy: 1646/5000 (33%)\n",
      "[epoch 39] loss: 0.0017290\n",
      "Test set: Average loss: 4.8244, Accuracy: 1649/5000 (33%)\n",
      "[epoch 40] loss: 0.0016577\n",
      "Test set: Average loss: 4.8446, Accuracy: 1634/5000 (33%)\n",
      "[epoch 41] loss: 0.0015932\n",
      "Test set: Average loss: 4.8615, Accuracy: 1643/5000 (33%)\n",
      "[epoch 42] loss: 0.0015028\n",
      "Test set: Average loss: 4.8843, Accuracy: 1638/5000 (33%)\n",
      "[epoch 43] loss: 0.0014318\n",
      "Test set: Average loss: 4.9000, Accuracy: 1640/5000 (33%)\n",
      "[epoch 44] loss: 0.0013803\n",
      "Test set: Average loss: 4.9207, Accuracy: 1636/5000 (33%)\n",
      "[epoch 45] loss: 0.0013167\n",
      "Test set: Average loss: 4.9374, Accuracy: 1633/5000 (33%)\n",
      "[epoch 46] loss: 0.0012677\n",
      "Test set: Average loss: 4.9528, Accuracy: 1635/5000 (33%)\n",
      "[epoch 47] loss: 0.0012142\n",
      "Test set: Average loss: 4.9685, Accuracy: 1641/5000 (33%)\n",
      "[epoch 48] loss: 0.0011753\n",
      "Test set: Average loss: 4.9810, Accuracy: 1643/5000 (33%)\n",
      "[epoch 49] loss: 0.0011252\n",
      "Test set: Average loss: 5.0035, Accuracy: 1629/5000 (33%)\n",
      "[epoch 50] loss: 0.0010752\n",
      "Test set: Average loss: 5.0185, Accuracy: 1635/5000 (33%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0303, Accuracy: 1740/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 1.9895, Accuracy: 3541/10000 (35%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 427/5000 (9%)\n",
      "[epoch 1] loss: 2.2075893\n",
      "Test set: Average loss: 2.0590, Accuracy: 1173/5000 (23%)\n",
      "[epoch 2] loss: 1.9271025\n",
      "Test set: Average loss: 1.9141, Accuracy: 1461/5000 (29%)\n",
      "[epoch 3] loss: 1.7407734\n",
      "Test set: Average loss: 1.8058, Accuracy: 1692/5000 (34%)\n",
      "[epoch 4] loss: 1.5046681\n",
      "Test set: Average loss: 1.7647, Accuracy: 1841/5000 (37%)\n",
      "[epoch 5] loss: 1.2627185\n",
      "Test set: Average loss: 1.8233, Accuracy: 1804/5000 (36%)\n",
      "[epoch 6] loss: 1.0738465\n",
      "Test set: Average loss: 2.0782, Accuracy: 1713/5000 (34%)\n",
      "[epoch 7] loss: 0.9062767\n",
      "Test set: Average loss: 2.1114, Accuracy: 1781/5000 (36%)\n",
      "[epoch 8] loss: 0.6873507\n",
      "Test set: Average loss: 2.5228, Accuracy: 1750/5000 (35%)\n",
      "[epoch 9] loss: 0.6000296\n",
      "Test set: Average loss: 2.5095, Accuracy: 1807/5000 (36%)\n",
      "[epoch 10] loss: 0.4395333\n",
      "Test set: Average loss: 2.7378, Accuracy: 1799/5000 (36%)\n",
      "[epoch 11] loss: 0.3320619\n",
      "Test set: Average loss: 3.0072, Accuracy: 1749/5000 (35%)\n",
      "[epoch 12] loss: 0.2363842\n",
      "Test set: Average loss: 3.1191, Accuracy: 1731/5000 (35%)\n",
      "[epoch 13] loss: 0.1812656\n",
      "Test set: Average loss: 3.3063, Accuracy: 1763/5000 (35%)\n",
      "[epoch 14] loss: 0.1495605\n",
      "Test set: Average loss: 3.6863, Accuracy: 1753/5000 (35%)\n",
      "[epoch 15] loss: 0.1657496\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.6999, Accuracy: 1729/5000 (35%)\n",
      "[epoch 16] loss: 0.0675664\n",
      "Test set: Average loss: 3.6007, Accuracy: 1782/5000 (36%)\n",
      "[epoch 17] loss: 0.0395504\n",
      "Test set: Average loss: 3.6129, Accuracy: 1769/5000 (35%)\n",
      "[epoch 18] loss: 0.0340567\n",
      "Test set: Average loss: 3.6319, Accuracy: 1771/5000 (35%)\n",
      "[epoch 19] loss: 0.0294798\n",
      "Test set: Average loss: 3.6520, Accuracy: 1784/5000 (36%)\n",
      "[epoch 20] loss: 0.0269636\n",
      "Test set: Average loss: 3.6746, Accuracy: 1779/5000 (36%)\n",
      "[epoch 21] loss: 0.0258527\n",
      "Test set: Average loss: 3.6917, Accuracy: 1789/5000 (36%)\n",
      "[epoch 22] loss: 0.0240609\n",
      "Test set: Average loss: 3.7153, Accuracy: 1788/5000 (36%)\n",
      "[epoch 23] loss: 0.0225460\n",
      "Test set: Average loss: 3.7308, Accuracy: 1787/5000 (36%)\n",
      "[epoch 24] loss: 0.0216334\n",
      "Test set: Average loss: 3.7510, Accuracy: 1789/5000 (36%)\n",
      "[epoch 25] loss: 0.0205216\n",
      "Test set: Average loss: 3.7706, Accuracy: 1793/5000 (36%)\n",
      "[epoch 26] loss: 0.0194146\n",
      "Test set: Average loss: 3.7885, Accuracy: 1789/5000 (36%)\n",
      "[epoch 27] loss: 0.0185932\n",
      "Test set: Average loss: 3.8068, Accuracy: 1792/5000 (36%)\n",
      "[epoch 28] loss: 0.0179254\n",
      "Test set: Average loss: 3.8231, Accuracy: 1789/5000 (36%)\n",
      "[epoch 29] loss: 0.0169464\n",
      "Test set: Average loss: 3.8419, Accuracy: 1789/5000 (36%)\n",
      "[epoch 30] loss: 0.0164092\n",
      "Test set: Average loss: 3.8591, Accuracy: 1786/5000 (36%)\n",
      "[epoch 31] loss: 0.0156654\n",
      "Test set: Average loss: 3.8741, Accuracy: 1788/5000 (36%)\n",
      "[epoch 32] loss: 0.0152944\n",
      "Test set: Average loss: 3.8892, Accuracy: 1790/5000 (36%)\n",
      "[epoch 33] loss: 0.0146565\n",
      "Test set: Average loss: 3.9058, Accuracy: 1787/5000 (36%)\n",
      "[epoch 34] loss: 0.0138079\n",
      "Test set: Average loss: 3.9206, Accuracy: 1794/5000 (36%)\n",
      "[epoch 35] loss: 0.0135608\n",
      "Test set: Average loss: 3.9340, Accuracy: 1789/5000 (36%)\n",
      "[epoch 36] loss: 0.0128832\n",
      "Test set: Average loss: 3.9518, Accuracy: 1781/5000 (36%)\n",
      "[epoch 37] loss: 0.0126621\n",
      "Test set: Average loss: 3.9658, Accuracy: 1783/5000 (36%)\n",
      "[epoch 38] loss: 0.0121965\n",
      "Test set: Average loss: 3.9793, Accuracy: 1783/5000 (36%)\n",
      "[epoch 39] loss: 0.0117628\n",
      "Test set: Average loss: 3.9940, Accuracy: 1782/5000 (36%)\n",
      "[epoch 40] loss: 0.0112614\n",
      "Test set: Average loss: 4.0070, Accuracy: 1779/5000 (36%)\n",
      "[epoch 41] loss: 0.0110150\n",
      "Test set: Average loss: 4.0209, Accuracy: 1777/5000 (36%)\n",
      "[epoch 42] loss: 0.0106474\n",
      "Test set: Average loss: 4.0350, Accuracy: 1783/5000 (36%)\n",
      "[epoch 43] loss: 0.0103602\n",
      "Test set: Average loss: 4.0489, Accuracy: 1777/5000 (36%)\n",
      "[epoch 44] loss: 0.0099733\n",
      "Test set: Average loss: 4.0611, Accuracy: 1780/5000 (36%)\n",
      "[epoch 45] loss: 0.0097125\n",
      "Test set: Average loss: 4.0746, Accuracy: 1777/5000 (36%)\n",
      "[epoch 46] loss: 0.0092563\n",
      "Test set: Average loss: 4.0861, Accuracy: 1774/5000 (35%)\n",
      "[epoch 47] loss: 0.0090320\n",
      "Test set: Average loss: 4.1008, Accuracy: 1774/5000 (35%)\n",
      "[epoch 48] loss: 0.0088189\n",
      "Test set: Average loss: 4.1118, Accuracy: 1773/5000 (35%)\n",
      "[epoch 49] loss: 0.0084704\n",
      "Test set: Average loss: 4.1253, Accuracy: 1770/5000 (35%)\n",
      "[epoch 50] loss: 0.0082374\n",
      "Test set: Average loss: 4.1390, Accuracy: 1770/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7647, Accuracy: 1841/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 1.7480, Accuracy: 3732/10000 (37%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 497/5000 (10%)\n",
      "[epoch 1] loss: 2.1509186\n",
      "Test set: Average loss: 2.0777, Accuracy: 1089/5000 (22%)\n",
      "[epoch 2] loss: 1.9512585\n",
      "Test set: Average loss: 2.0673, Accuracy: 1364/5000 (27%)\n",
      "[epoch 3] loss: 1.7578072\n",
      "Test set: Average loss: 1.8994, Accuracy: 1578/5000 (32%)\n",
      "[epoch 4] loss: 1.5384521\n",
      "Test set: Average loss: 1.8890, Accuracy: 1652/5000 (33%)\n",
      "[epoch 5] loss: 1.2941643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.8263, Accuracy: 1848/5000 (37%)\n",
      "[epoch 6] loss: 1.0922105\n",
      "Test set: Average loss: 1.9738, Accuracy: 1761/5000 (35%)\n",
      "[epoch 7] loss: 0.9158391\n",
      "Test set: Average loss: 1.9964, Accuracy: 1821/5000 (36%)\n",
      "[epoch 8] loss: 0.7094809\n",
      "Test set: Average loss: 2.1721, Accuracy: 1794/5000 (36%)\n",
      "[epoch 9] loss: 0.5538845\n",
      "Test set: Average loss: 2.4227, Accuracy: 1793/5000 (36%)\n",
      "[epoch 10] loss: 0.4255312\n",
      "Test set: Average loss: 2.6551, Accuracy: 1799/5000 (36%)\n",
      "[epoch 11] loss: 0.3038804\n",
      "Test set: Average loss: 2.7944, Accuracy: 1817/5000 (36%)\n",
      "[epoch 12] loss: 0.2196652\n",
      "Test set: Average loss: 3.0156, Accuracy: 1798/5000 (36%)\n",
      "[epoch 13] loss: 0.1786976\n",
      "Test set: Average loss: 3.1952, Accuracy: 1836/5000 (37%)\n",
      "[epoch 14] loss: 0.1010638\n",
      "Test set: Average loss: 3.5507, Accuracy: 1701/5000 (34%)\n",
      "[epoch 15] loss: 0.0884476\n",
      "Test set: Average loss: 3.5969, Accuracy: 1746/5000 (35%)\n",
      "[epoch 16] loss: 0.0622691\n",
      "Test set: Average loss: 3.6415, Accuracy: 1794/5000 (36%)\n",
      "[epoch 17] loss: 0.0325586\n",
      "Test set: Average loss: 3.8449, Accuracy: 1757/5000 (35%)\n",
      "[epoch 18] loss: 0.0221902\n",
      "Test set: Average loss: 3.9682, Accuracy: 1766/5000 (35%)\n",
      "[epoch 19] loss: 0.0114620\n",
      "Test set: Average loss: 3.9841, Accuracy: 1811/5000 (36%)\n",
      "[epoch 20] loss: 0.0080442\n",
      "Test set: Average loss: 4.1119, Accuracy: 1793/5000 (36%)\n",
      "[epoch 21] loss: 0.0059018\n",
      "Test set: Average loss: 4.1447, Accuracy: 1785/5000 (36%)\n",
      "[epoch 22] loss: 0.0047982\n",
      "Test set: Average loss: 4.1824, Accuracy: 1813/5000 (36%)\n",
      "[epoch 23] loss: 0.0041605\n",
      "Test set: Average loss: 4.2416, Accuracy: 1801/5000 (36%)\n",
      "[epoch 24] loss: 0.0036616\n",
      "Test set: Average loss: 4.2767, Accuracy: 1806/5000 (36%)\n",
      "[epoch 25] loss: 0.0032463\n",
      "Test set: Average loss: 4.3171, Accuracy: 1812/5000 (36%)\n",
      "[epoch 26] loss: 0.0029506\n",
      "Test set: Average loss: 4.3560, Accuracy: 1810/5000 (36%)\n",
      "[epoch 27] loss: 0.0027654\n",
      "Test set: Average loss: 4.3877, Accuracy: 1807/5000 (36%)\n",
      "[epoch 28] loss: 0.0025640\n",
      "Test set: Average loss: 4.4212, Accuracy: 1809/5000 (36%)\n",
      "[epoch 29] loss: 0.0024153\n",
      "Test set: Average loss: 4.4489, Accuracy: 1809/5000 (36%)\n",
      "[epoch 30] loss: 0.0022303\n",
      "Test set: Average loss: 4.4761, Accuracy: 1807/5000 (36%)\n",
      "[epoch 31] loss: 0.0021319\n",
      "Test set: Average loss: 4.5074, Accuracy: 1808/5000 (36%)\n",
      "[epoch 32] loss: 0.0019459\n",
      "Test set: Average loss: 4.5350, Accuracy: 1811/5000 (36%)\n",
      "[epoch 33] loss: 0.0018217\n",
      "Test set: Average loss: 4.5568, Accuracy: 1809/5000 (36%)\n",
      "[epoch 34] loss: 0.0017368\n",
      "Test set: Average loss: 4.5885, Accuracy: 1808/5000 (36%)\n",
      "[epoch 35] loss: 0.0016433\n",
      "Test set: Average loss: 4.6103, Accuracy: 1809/5000 (36%)\n",
      "[epoch 36] loss: 0.0015416\n",
      "Test set: Average loss: 4.6313, Accuracy: 1807/5000 (36%)\n",
      "[epoch 37] loss: 0.0014716\n",
      "Test set: Average loss: 4.6564, Accuracy: 1812/5000 (36%)\n",
      "[epoch 38] loss: 0.0013981\n",
      "Test set: Average loss: 4.6754, Accuracy: 1809/5000 (36%)\n",
      "[epoch 39] loss: 0.0013330\n",
      "Test set: Average loss: 4.7019, Accuracy: 1801/5000 (36%)\n",
      "[epoch 40] loss: 0.0012652\n",
      "Test set: Average loss: 4.7162, Accuracy: 1812/5000 (36%)\n",
      "[epoch 41] loss: 0.0011811\n",
      "Test set: Average loss: 4.7418, Accuracy: 1811/5000 (36%)\n",
      "[epoch 42] loss: 0.0011682\n",
      "Test set: Average loss: 4.7591, Accuracy: 1804/5000 (36%)\n",
      "[epoch 43] loss: 0.0010937\n",
      "Test set: Average loss: 4.7821, Accuracy: 1804/5000 (36%)\n",
      "[epoch 44] loss: 0.0010451\n",
      "Test set: Average loss: 4.7957, Accuracy: 1806/5000 (36%)\n",
      "[epoch 45] loss: 0.0010023\n",
      "Test set: Average loss: 4.8185, Accuracy: 1806/5000 (36%)\n",
      "[epoch 46] loss: 0.0009451\n",
      "Test set: Average loss: 4.8355, Accuracy: 1799/5000 (36%)\n",
      "[epoch 47] loss: 0.0009159\n",
      "Test set: Average loss: 4.8518, Accuracy: 1810/5000 (36%)\n",
      "[epoch 48] loss: 0.0008827\n",
      "Test set: Average loss: 4.8710, Accuracy: 1805/5000 (36%)\n",
      "[epoch 49] loss: 0.0008628\n",
      "Test set: Average loss: 4.8884, Accuracy: 1803/5000 (36%)\n",
      "[epoch 50] loss: 0.0008235\n",
      "Test set: Average loss: 4.9021, Accuracy: 1809/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8263, Accuracy: 1848/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 1.7873, Accuracy: 3763/10000 (38%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 2.2265425\n",
      "Test set: Average loss: 2.1335, Accuracy: 993/5000 (20%)\n",
      "[epoch 2] loss: 2.0254087\n",
      "Test set: Average loss: 1.9415, Accuracy: 1440/5000 (29%)\n",
      "[epoch 3] loss: 1.8356696\n",
      "Test set: Average loss: 1.8342, Accuracy: 1673/5000 (33%)\n",
      "[epoch 4] loss: 1.6719116\n",
      "Test set: Average loss: 1.9431, Accuracy: 1591/5000 (32%)\n",
      "[epoch 5] loss: 1.5523584\n",
      "Test set: Average loss: 1.8310, Accuracy: 1762/5000 (35%)\n",
      "[epoch 6] loss: 1.3357409\n",
      "Test set: Average loss: 1.8164, Accuracy: 1804/5000 (36%)\n",
      "[epoch 7] loss: 1.1913146\n",
      "Test set: Average loss: 1.9737, Accuracy: 1704/5000 (34%)\n",
      "[epoch 8] loss: 0.9780081\n",
      "Test set: Average loss: 2.1095, Accuracy: 1792/5000 (36%)\n",
      "[epoch 9] loss: 0.8257389\n",
      "Test set: Average loss: 2.3770, Accuracy: 1746/5000 (35%)\n",
      "[epoch 10] loss: 0.7436284\n",
      "Test set: Average loss: 2.4586, Accuracy: 1763/5000 (35%)\n",
      "[epoch 11] loss: 0.5466310\n",
      "Test set: Average loss: 2.7082, Accuracy: 1707/5000 (34%)\n",
      "[epoch 12] loss: 0.4798008\n",
      "Test set: Average loss: 2.8673, Accuracy: 1688/5000 (34%)\n",
      "[epoch 13] loss: 0.3453848\n",
      "Test set: Average loss: 3.1309, Accuracy: 1721/5000 (34%)\n",
      "[epoch 14] loss: 0.2749853\n",
      "Test set: Average loss: 3.3294, Accuracy: 1613/5000 (32%)\n",
      "[epoch 15] loss: 0.2119783\n",
      "Test set: Average loss: 3.5239, Accuracy: 1598/5000 (32%)\n",
      "[epoch 16] loss: 0.1537320\n",
      "Test set: Average loss: 3.9013, Accuracy: 1717/5000 (34%)\n",
      "[epoch 17] loss: 0.1037485\n",
      "Test set: Average loss: 3.8846, Accuracy: 1697/5000 (34%)\n",
      "[epoch 18] loss: 0.1054456\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.0762, Accuracy: 1682/5000 (34%)\n",
      "[epoch 19] loss: 0.0473862\n",
      "Test set: Average loss: 4.0138, Accuracy: 1676/5000 (34%)\n",
      "[epoch 20] loss: 0.0249386\n",
      "Test set: Average loss: 4.0379, Accuracy: 1696/5000 (34%)\n",
      "[epoch 21] loss: 0.0226379\n",
      "Test set: Average loss: 4.0492, Accuracy: 1686/5000 (34%)\n",
      "[epoch 22] loss: 0.0210971\n",
      "Test set: Average loss: 4.0647, Accuracy: 1686/5000 (34%)\n",
      "[epoch 23] loss: 0.0193195\n",
      "Test set: Average loss: 4.0813, Accuracy: 1689/5000 (34%)\n",
      "[epoch 24] loss: 0.0183649\n",
      "Test set: Average loss: 4.0947, Accuracy: 1684/5000 (34%)\n",
      "[epoch 25] loss: 0.0177408\n",
      "Test set: Average loss: 4.1111, Accuracy: 1678/5000 (34%)\n",
      "[epoch 26] loss: 0.0166540\n",
      "Test set: Average loss: 4.1272, Accuracy: 1678/5000 (34%)\n",
      "[epoch 27] loss: 0.0159734\n",
      "Test set: Average loss: 4.1415, Accuracy: 1676/5000 (34%)\n",
      "[epoch 28] loss: 0.0154303\n",
      "Test set: Average loss: 4.1570, Accuracy: 1674/5000 (33%)\n",
      "[epoch 29] loss: 0.0148069\n",
      "Test set: Average loss: 4.1718, Accuracy: 1680/5000 (34%)\n",
      "[epoch 30] loss: 0.0142737\n",
      "Test set: Average loss: 4.1856, Accuracy: 1676/5000 (34%)\n",
      "[epoch 31] loss: 0.0138190\n",
      "Test set: Average loss: 4.2006, Accuracy: 1676/5000 (34%)\n",
      "[epoch 32] loss: 0.0132861\n",
      "Test set: Average loss: 4.2142, Accuracy: 1675/5000 (34%)\n",
      "[epoch 33] loss: 0.0127556\n",
      "Test set: Average loss: 4.2295, Accuracy: 1670/5000 (33%)\n",
      "[epoch 34] loss: 0.0124218\n",
      "Test set: Average loss: 4.2458, Accuracy: 1678/5000 (34%)\n",
      "[epoch 35] loss: 0.0122475\n",
      "Test set: Average loss: 4.2583, Accuracy: 1677/5000 (34%)\n",
      "[epoch 36] loss: 0.0116915\n",
      "Test set: Average loss: 4.2735, Accuracy: 1674/5000 (33%)\n",
      "[epoch 37] loss: 0.0112626\n",
      "Test set: Average loss: 4.2900, Accuracy: 1673/5000 (33%)\n",
      "[epoch 38] loss: 0.0110008\n",
      "Test set: Average loss: 4.3011, Accuracy: 1672/5000 (33%)\n",
      "[epoch 39] loss: 0.0107329\n",
      "Test set: Average loss: 4.3157, Accuracy: 1678/5000 (34%)\n",
      "[epoch 40] loss: 0.0105121\n",
      "Test set: Average loss: 4.3285, Accuracy: 1671/5000 (33%)\n",
      "[epoch 41] loss: 0.0101768\n",
      "Test set: Average loss: 4.3412, Accuracy: 1671/5000 (33%)\n",
      "[epoch 42] loss: 0.0098407\n",
      "Test set: Average loss: 4.3579, Accuracy: 1670/5000 (33%)\n",
      "[epoch 43] loss: 0.0095402\n",
      "Test set: Average loss: 4.3690, Accuracy: 1673/5000 (33%)\n",
      "[epoch 44] loss: 0.0092999\n",
      "Test set: Average loss: 4.3791, Accuracy: 1670/5000 (33%)\n",
      "[epoch 45] loss: 0.0090834\n",
      "Test set: Average loss: 4.3930, Accuracy: 1672/5000 (33%)\n",
      "[epoch 46] loss: 0.0087946\n",
      "Test set: Average loss: 4.4053, Accuracy: 1668/5000 (33%)\n",
      "[epoch 47] loss: 0.0086888\n",
      "Test set: Average loss: 4.4156, Accuracy: 1670/5000 (33%)\n",
      "[epoch 48] loss: 0.0083501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.4288, Accuracy: 1671/5000 (33%)\n",
      "[epoch 49] loss: 0.0082936\n",
      "Test set: Average loss: 4.4412, Accuracy: 1672/5000 (33%)\n",
      "[epoch 50] loss: 0.0079589\n",
      "Test set: Average loss: 4.4532, Accuracy: 1672/5000 (33%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8164, Accuracy: 1804/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.7960, Accuracy: 3707/10000 (37%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3030, Accuracy: 497/5000 (10%)\n",
      "[epoch 1] loss: 2.1872876\n",
      "Test set: Average loss: 2.0485, Accuracy: 1162/5000 (23%)\n",
      "[epoch 2] loss: 1.8971221\n",
      "Test set: Average loss: 1.8565, Accuracy: 1456/5000 (29%)\n",
      "[epoch 3] loss: 1.6725991\n",
      "Test set: Average loss: 1.8067, Accuracy: 1814/5000 (36%)\n",
      "[epoch 4] loss: 1.4814238\n",
      "Test set: Average loss: 1.7184, Accuracy: 1923/5000 (38%)\n",
      "[epoch 5] loss: 1.3066226\n",
      "Test set: Average loss: 1.7852, Accuracy: 1924/5000 (38%)\n",
      "[epoch 6] loss: 1.1452485\n",
      "Test set: Average loss: 1.9676, Accuracy: 1772/5000 (35%)\n",
      "[epoch 7] loss: 1.0529275\n",
      "Test set: Average loss: 2.0580, Accuracy: 1803/5000 (36%)\n",
      "[epoch 8] loss: 0.8515576\n",
      "Test set: Average loss: 2.1642, Accuracy: 1830/5000 (37%)\n",
      "[epoch 9] loss: 0.6987535\n",
      "Test set: Average loss: 2.3780, Accuracy: 1799/5000 (36%)\n",
      "[epoch 10] loss: 0.5094494\n",
      "Test set: Average loss: 2.5209, Accuracy: 1806/5000 (36%)\n",
      "[epoch 11] loss: 0.3812370\n",
      "Test set: Average loss: 2.7877, Accuracy: 1853/5000 (37%)\n",
      "[epoch 12] loss: 0.3356522\n",
      "Test set: Average loss: 3.1451, Accuracy: 1784/5000 (36%)\n",
      "[epoch 13] loss: 0.2753206\n",
      "Test set: Average loss: 3.4019, Accuracy: 1741/5000 (35%)\n",
      "[epoch 14] loss: 0.1765925\n",
      "Test set: Average loss: 3.6124, Accuracy: 1776/5000 (36%)\n",
      "[epoch 15] loss: 0.1008577\n",
      "Test set: Average loss: 3.8792, Accuracy: 1735/5000 (35%)\n",
      "[epoch 16] loss: 0.0876533\n",
      "Test set: Average loss: 4.0222, Accuracy: 1779/5000 (36%)\n",
      "[epoch 17] loss: 0.0542825\n",
      "Test set: Average loss: 4.1988, Accuracy: 1795/5000 (36%)\n",
      "[epoch 18] loss: 0.0372533\n",
      "Test set: Average loss: 4.3594, Accuracy: 1776/5000 (36%)\n",
      "[epoch 19] loss: 0.0290618\n",
      "Test set: Average loss: 4.4672, Accuracy: 1784/5000 (36%)\n",
      "[epoch 20] loss: 0.0213718\n",
      "Test set: Average loss: 4.5699, Accuracy: 1757/5000 (35%)\n",
      "[epoch 21] loss: 0.0177098\n",
      "Test set: Average loss: 4.7125, Accuracy: 1759/5000 (35%)\n",
      "[epoch 22] loss: 0.0103069\n",
      "Test set: Average loss: 4.7591, Accuracy: 1783/5000 (36%)\n",
      "[epoch 23] loss: 0.0056003\n",
      "Test set: Average loss: 4.8186, Accuracy: 1774/5000 (35%)\n",
      "[epoch 24] loss: 0.0041981\n",
      "Test set: Average loss: 4.8635, Accuracy: 1788/5000 (36%)\n",
      "[epoch 25] loss: 0.0036183\n",
      "Test set: Average loss: 4.9057, Accuracy: 1798/5000 (36%)\n",
      "[epoch 26] loss: 0.0031817\n",
      "Test set: Average loss: 4.9499, Accuracy: 1795/5000 (36%)\n",
      "[epoch 27] loss: 0.0028207\n",
      "Test set: Average loss: 4.9844, Accuracy: 1790/5000 (36%)\n",
      "[epoch 28] loss: 0.0025954\n",
      "Test set: Average loss: 5.0214, Accuracy: 1789/5000 (36%)\n",
      "[epoch 29] loss: 0.0023644\n",
      "Test set: Average loss: 5.0541, Accuracy: 1793/5000 (36%)\n",
      "[epoch 30] loss: 0.0022049\n",
      "Test set: Average loss: 5.0845, Accuracy: 1784/5000 (36%)\n",
      "[epoch 31] loss: 0.0020550\n",
      "Test set: Average loss: 5.1153, Accuracy: 1789/5000 (36%)\n",
      "[epoch 32] loss: 0.0019271\n",
      "Test set: Average loss: 5.1457, Accuracy: 1789/5000 (36%)\n",
      "[epoch 33] loss: 0.0018248\n",
      "Test set: Average loss: 5.1740, Accuracy: 1787/5000 (36%)\n",
      "[epoch 34] loss: 0.0017361\n",
      "Test set: Average loss: 5.1998, Accuracy: 1788/5000 (36%)\n",
      "[epoch 35] loss: 0.0016372\n",
      "Test set: Average loss: 5.2305, Accuracy: 1789/5000 (36%)\n",
      "[epoch 36] loss: 0.0014921\n",
      "Test set: Average loss: 5.2551, Accuracy: 1788/5000 (36%)\n",
      "[epoch 37] loss: 0.0014224\n",
      "Test set: Average loss: 5.2787, Accuracy: 1785/5000 (36%)\n",
      "[epoch 38] loss: 0.0013576\n",
      "Test set: Average loss: 5.3063, Accuracy: 1784/5000 (36%)\n",
      "[epoch 39] loss: 0.0012795\n",
      "Test set: Average loss: 5.3273, Accuracy: 1788/5000 (36%)\n",
      "[epoch 40] loss: 0.0012211\n",
      "Test set: Average loss: 5.3500, Accuracy: 1786/5000 (36%)\n",
      "[epoch 41] loss: 0.0011543\n",
      "Test set: Average loss: 5.3723, Accuracy: 1790/5000 (36%)\n",
      "[epoch 42] loss: 0.0011186\n",
      "Test set: Average loss: 5.3934, Accuracy: 1786/5000 (36%)\n",
      "[epoch 43] loss: 0.0010527\n",
      "Test set: Average loss: 5.4189, Accuracy: 1788/5000 (36%)\n",
      "[epoch 44] loss: 0.0009957\n",
      "Test set: Average loss: 5.4406, Accuracy: 1786/5000 (36%)\n",
      "[epoch 45] loss: 0.0009616\n",
      "Test set: Average loss: 5.4598, Accuracy: 1781/5000 (36%)\n",
      "[epoch 46] loss: 0.0009199\n",
      "Test set: Average loss: 5.4804, Accuracy: 1785/5000 (36%)\n",
      "[epoch 47] loss: 0.0008736\n",
      "Test set: Average loss: 5.4996, Accuracy: 1785/5000 (36%)\n",
      "[epoch 48] loss: 0.0008482\n",
      "Test set: Average loss: 5.5198, Accuracy: 1783/5000 (36%)\n",
      "[epoch 49] loss: 0.0008053\n",
      "Test set: Average loss: 5.5400, Accuracy: 1778/5000 (36%)\n",
      "[epoch 50] loss: 0.0007895\n",
      "Test set: Average loss: 5.5580, Accuracy: 1786/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7852, Accuracy: 1924/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 1.7544, Accuracy: 3866/10000 (39%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 449/5000 (9%)\n",
      "[epoch 1] loss: 2.1177180\n",
      "Test set: Average loss: 2.0463, Accuracy: 1328/5000 (27%)\n",
      "[epoch 2] loss: 1.8287839\n",
      "Test set: Average loss: 1.9141, Accuracy: 1586/5000 (32%)\n",
      "[epoch 3] loss: 1.6399657\n",
      "Test set: Average loss: 1.8847, Accuracy: 1548/5000 (31%)\n",
      "[epoch 4] loss: 1.4653563\n",
      "Test set: Average loss: 1.7768, Accuracy: 1802/5000 (36%)\n",
      "[epoch 5] loss: 1.2376492\n",
      "Test set: Average loss: 1.7919, Accuracy: 1972/5000 (39%)\n",
      "[epoch 6] loss: 1.1029269\n",
      "Test set: Average loss: 2.0043, Accuracy: 1834/5000 (37%)\n",
      "[epoch 7] loss: 0.9906076\n",
      "Test set: Average loss: 1.9740, Accuracy: 1911/5000 (38%)\n",
      "[epoch 8] loss: 0.8602243\n",
      "Test set: Average loss: 2.0557, Accuracy: 1956/5000 (39%)\n",
      "[epoch 9] loss: 0.7818371\n",
      "Test set: Average loss: 2.2003, Accuracy: 1856/5000 (37%)\n",
      "[epoch 10] loss: 0.6126091\n",
      "Test set: Average loss: 2.4002, Accuracy: 1837/5000 (37%)\n",
      "[epoch 11] loss: 0.5043286\n",
      "Test set: Average loss: 2.5715, Accuracy: 1782/5000 (36%)\n",
      "[epoch 12] loss: 0.4272039\n",
      "Test set: Average loss: 2.8820, Accuracy: 1763/5000 (35%)\n",
      "[epoch 13] loss: 0.3903805\n",
      "Test set: Average loss: 2.8628, Accuracy: 1916/5000 (38%)\n",
      "[epoch 14] loss: 0.3051544\n",
      "Test set: Average loss: 3.0977, Accuracy: 1819/5000 (36%)\n",
      "[epoch 15] loss: 0.2374740\n",
      "Test set: Average loss: 3.3494, Accuracy: 1900/5000 (38%)\n",
      "[epoch 16] loss: 0.2307583\n",
      "Test set: Average loss: 3.5249, Accuracy: 1729/5000 (35%)\n",
      "[epoch 17] loss: 0.1457297\n",
      "Test set: Average loss: 3.5763, Accuracy: 1803/5000 (36%)\n",
      "[epoch 18] loss: 0.1063513\n",
      "Test set: Average loss: 3.7735, Accuracy: 1776/5000 (36%)\n",
      "[epoch 19] loss: 0.0723296\n",
      "Test set: Average loss: 3.9022, Accuracy: 1793/5000 (36%)\n",
      "[epoch 20] loss: 0.0561559\n",
      "Test set: Average loss: 4.1364, Accuracy: 1765/5000 (35%)\n",
      "[epoch 21] loss: 0.0435713\n",
      "Test set: Average loss: 4.1623, Accuracy: 1810/5000 (36%)\n",
      "[epoch 22] loss: 0.0343581\n",
      "Test set: Average loss: 4.2166, Accuracy: 1834/5000 (37%)\n",
      "[epoch 23] loss: 0.0187544\n",
      "Test set: Average loss: 4.2909, Accuracy: 1853/5000 (37%)\n",
      "[epoch 24] loss: 0.0109440\n",
      "Test set: Average loss: 4.4222, Accuracy: 1816/5000 (36%)\n",
      "[epoch 25] loss: 0.0066101\n",
      "Test set: Average loss: 4.4728, Accuracy: 1851/5000 (37%)\n",
      "[epoch 26] loss: 0.0046133\n",
      "Test set: Average loss: 4.5243, Accuracy: 1828/5000 (37%)\n",
      "[epoch 27] loss: 0.0040159\n",
      "Test set: Average loss: 4.5569, Accuracy: 1831/5000 (37%)\n",
      "[epoch 28] loss: 0.0036320\n",
      "Test set: Average loss: 4.5953, Accuracy: 1829/5000 (37%)\n",
      "[epoch 29] loss: 0.0032839\n",
      "Test set: Average loss: 4.6349, Accuracy: 1830/5000 (37%)\n",
      "[epoch 30] loss: 0.0031130\n",
      "Test set: Average loss: 4.6624, Accuracy: 1841/5000 (37%)\n",
      "[epoch 31] loss: 0.0028280\n",
      "Test set: Average loss: 4.6903, Accuracy: 1831/5000 (37%)\n",
      "[epoch 32] loss: 0.0026282\n",
      "Test set: Average loss: 4.7241, Accuracy: 1827/5000 (37%)\n",
      "[epoch 33] loss: 0.0023756\n",
      "Test set: Average loss: 4.7575, Accuracy: 1831/5000 (37%)\n",
      "[epoch 34] loss: 0.0022380\n",
      "Test set: Average loss: 4.7831, Accuracy: 1824/5000 (36%)\n",
      "[epoch 35] loss: 0.0020569\n",
      "Test set: Average loss: 4.8070, Accuracy: 1829/5000 (37%)\n",
      "[epoch 36] loss: 0.0019620\n",
      "Test set: Average loss: 4.8305, Accuracy: 1829/5000 (37%)\n",
      "[epoch 37] loss: 0.0018877\n",
      "Test set: Average loss: 4.8605, Accuracy: 1826/5000 (37%)\n",
      "[epoch 38] loss: 0.0017405\n",
      "Test set: Average loss: 4.8827, Accuracy: 1827/5000 (37%)\n",
      "[epoch 39] loss: 0.0016413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.9026, Accuracy: 1830/5000 (37%)\n",
      "[epoch 40] loss: 0.0015705\n",
      "Test set: Average loss: 4.9246, Accuracy: 1829/5000 (37%)\n",
      "[epoch 41] loss: 0.0014708\n",
      "Test set: Average loss: 4.9508, Accuracy: 1828/5000 (37%)\n",
      "[epoch 42] loss: 0.0014160\n",
      "Test set: Average loss: 4.9722, Accuracy: 1821/5000 (36%)\n",
      "[epoch 43] loss: 0.0013510\n",
      "Test set: Average loss: 4.9956, Accuracy: 1827/5000 (37%)\n",
      "[epoch 44] loss: 0.0012792\n",
      "Test set: Average loss: 5.0150, Accuracy: 1823/5000 (36%)\n",
      "[epoch 45] loss: 0.0012043\n",
      "Test set: Average loss: 5.0336, Accuracy: 1829/5000 (37%)\n",
      "[epoch 46] loss: 0.0011759\n",
      "Test set: Average loss: 5.0593, Accuracy: 1824/5000 (36%)\n",
      "[epoch 47] loss: 0.0011443\n",
      "Test set: Average loss: 5.0759, Accuracy: 1830/5000 (37%)\n",
      "[epoch 48] loss: 0.0010657\n",
      "Test set: Average loss: 5.0954, Accuracy: 1822/5000 (36%)\n",
      "[epoch 49] loss: 0.0010288\n",
      "Test set: Average loss: 5.1147, Accuracy: 1824/5000 (36%)\n",
      "[epoch 50] loss: 0.0009826\n",
      "Test set: Average loss: 5.1344, Accuracy: 1823/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7919, Accuracy: 1972/5000 (39%)\n",
      "Test\n",
      "Test set: Average loss: 1.7481, Accuracy: 3981/10000 (40%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 538/5000 (11%)\n",
      "[epoch 1] loss: 2.2103401\n",
      "Test set: Average loss: 2.0625, Accuracy: 1164/5000 (23%)\n",
      "[epoch 2] loss: 1.9806100\n",
      "Test set: Average loss: 1.9079, Accuracy: 1504/5000 (30%)\n",
      "[epoch 3] loss: 1.8193947\n",
      "Test set: Average loss: 1.8560, Accuracy: 1633/5000 (33%)\n",
      "[epoch 4] loss: 1.6770032\n",
      "Test set: Average loss: 1.8054, Accuracy: 1780/5000 (36%)\n",
      "[epoch 5] loss: 1.5023758\n",
      "Test set: Average loss: 1.7825, Accuracy: 1824/5000 (36%)\n",
      "[epoch 6] loss: 1.3680393\n",
      "Test set: Average loss: 1.7520, Accuracy: 1899/5000 (38%)\n",
      "[epoch 7] loss: 1.1841299\n",
      "Test set: Average loss: 1.8952, Accuracy: 1746/5000 (35%)\n",
      "[epoch 8] loss: 1.0072789\n",
      "Test set: Average loss: 2.1512, Accuracy: 1715/5000 (34%)\n",
      "[epoch 9] loss: 0.8857250\n",
      "Test set: Average loss: 2.2857, Accuracy: 1805/5000 (36%)\n",
      "[epoch 10] loss: 0.7307098\n",
      "Test set: Average loss: 2.3897, Accuracy: 1758/5000 (35%)\n",
      "[epoch 11] loss: 0.5977139\n",
      "Test set: Average loss: 2.4618, Accuracy: 1776/5000 (36%)\n",
      "[epoch 12] loss: 0.4715424\n",
      "Test set: Average loss: 2.8012, Accuracy: 1695/5000 (34%)\n",
      "[epoch 13] loss: 0.3960164\n",
      "Test set: Average loss: 3.0269, Accuracy: 1697/5000 (34%)\n",
      "[epoch 14] loss: 0.3692496\n",
      "Test set: Average loss: 3.2975, Accuracy: 1622/5000 (32%)\n",
      "[epoch 15] loss: 0.3177109\n",
      "Test set: Average loss: 3.3750, Accuracy: 1783/5000 (36%)\n",
      "[epoch 16] loss: 0.2296789\n",
      "Test set: Average loss: 3.4521, Accuracy: 1772/5000 (35%)\n",
      "[epoch 17] loss: 0.1741531\n",
      "Test set: Average loss: 3.7558, Accuracy: 1726/5000 (35%)\n",
      "[epoch 18] loss: 0.1265569\n",
      "Test set: Average loss: 4.0559, Accuracy: 1701/5000 (34%)\n",
      "[epoch 19] loss: 0.0971982\n",
      "Test set: Average loss: 4.0179, Accuracy: 1691/5000 (34%)\n",
      "[epoch 20] loss: 0.0533200\n",
      "Test set: Average loss: 4.1569, Accuracy: 1708/5000 (34%)\n",
      "[epoch 21] loss: 0.0294347\n",
      "Test set: Average loss: 4.3324, Accuracy: 1754/5000 (35%)\n",
      "[epoch 22] loss: 0.0181320\n",
      "Test set: Average loss: 4.4064, Accuracy: 1742/5000 (35%)\n",
      "[epoch 23] loss: 0.0149219\n",
      "Test set: Average loss: 4.4962, Accuracy: 1748/5000 (35%)\n",
      "[epoch 24] loss: 0.0080192\n",
      "Test set: Average loss: 4.5650, Accuracy: 1744/5000 (35%)\n",
      "[epoch 25] loss: 0.0056094\n",
      "Test set: Average loss: 4.6217, Accuracy: 1756/5000 (35%)\n",
      "[epoch 26] loss: 0.0046209\n",
      "Test set: Average loss: 4.6794, Accuracy: 1766/5000 (35%)\n",
      "[epoch 27] loss: 0.0041494\n",
      "Test set: Average loss: 4.7171, Accuracy: 1762/5000 (35%)\n",
      "[epoch 28] loss: 0.0036830\n",
      "Test set: Average loss: 4.7546, Accuracy: 1767/5000 (35%)\n",
      "[epoch 29] loss: 0.0033870\n",
      "Test set: Average loss: 4.7982, Accuracy: 1764/5000 (35%)\n",
      "[epoch 30] loss: 0.0030838\n",
      "Test set: Average loss: 4.8316, Accuracy: 1771/5000 (35%)\n",
      "[epoch 31] loss: 0.0028483\n",
      "Test set: Average loss: 4.8711, Accuracy: 1757/5000 (35%)\n",
      "[epoch 32] loss: 0.0026589\n",
      "Test set: Average loss: 4.8992, Accuracy: 1773/5000 (35%)\n",
      "[epoch 33] loss: 0.0024431\n",
      "Test set: Average loss: 4.9334, Accuracy: 1765/5000 (35%)\n",
      "[epoch 34] loss: 0.0022953\n",
      "Test set: Average loss: 4.9639, Accuracy: 1767/5000 (35%)\n",
      "[epoch 35] loss: 0.0021784\n",
      "Test set: Average loss: 4.9925, Accuracy: 1775/5000 (36%)\n",
      "[epoch 36] loss: 0.0020152\n",
      "Test set: Average loss: 5.0243, Accuracy: 1765/5000 (35%)\n",
      "[epoch 37] loss: 0.0018881\n",
      "Test set: Average loss: 5.0526, Accuracy: 1768/5000 (35%)\n",
      "[epoch 38] loss: 0.0018097\n",
      "Test set: Average loss: 5.0796, Accuracy: 1769/5000 (35%)\n",
      "[epoch 39] loss: 0.0017004\n",
      "Test set: Average loss: 5.1093, Accuracy: 1764/5000 (35%)\n",
      "[epoch 40] loss: 0.0015895\n",
      "Test set: Average loss: 5.1315, Accuracy: 1769/5000 (35%)\n",
      "[epoch 41] loss: 0.0015016\n",
      "Test set: Average loss: 5.1571, Accuracy: 1768/5000 (35%)\n",
      "[epoch 42] loss: 0.0014122\n",
      "Test set: Average loss: 5.1781, Accuracy: 1771/5000 (35%)\n",
      "[epoch 43] loss: 0.0013367\n",
      "Test set: Average loss: 5.2046, Accuracy: 1775/5000 (36%)\n",
      "[epoch 44] loss: 0.0013115\n",
      "Test set: Average loss: 5.2239, Accuracy: 1774/5000 (35%)\n",
      "[epoch 45] loss: 0.0012222\n",
      "Test set: Average loss: 5.2493, Accuracy: 1764/5000 (35%)\n",
      "[epoch 46] loss: 0.0011676\n",
      "Test set: Average loss: 5.2687, Accuracy: 1770/5000 (35%)\n",
      "[epoch 47] loss: 0.0011388\n",
      "Test set: Average loss: 5.2908, Accuracy: 1759/5000 (35%)\n",
      "[epoch 48] loss: 0.0010628\n",
      "Test set: Average loss: 5.3114, Accuracy: 1767/5000 (35%)\n",
      "[epoch 49] loss: 0.0010284\n",
      "Test set: Average loss: 5.3314, Accuracy: 1766/5000 (35%)\n",
      "[epoch 50] loss: 0.0009826\n",
      "Test set: Average loss: 5.3531, Accuracy: 1760/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7520, Accuracy: 1899/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 1.7447, Accuracy: 3921/10000 (39%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 2.0177137\n",
      "Test set: Average loss: 1.7861, Accuracy: 1724/5000 (34%)\n",
      "[epoch 2] loss: 1.7133628\n",
      "Test set: Average loss: 1.6907, Accuracy: 1859/5000 (37%)\n",
      "[epoch 3] loss: 1.5514324\n",
      "Test set: Average loss: 1.6123, Accuracy: 2104/5000 (42%)\n",
      "[epoch 4] loss: 1.4238064\n",
      "Test set: Average loss: 1.5846, Accuracy: 2174/5000 (43%)\n",
      "[epoch 5] loss: 1.3297660\n",
      "Test set: Average loss: 1.6308, Accuracy: 2166/5000 (43%)\n",
      "[epoch 6] loss: 1.2599380\n",
      "Test set: Average loss: 1.6518, Accuracy: 2139/5000 (43%)\n",
      "[epoch 7] loss: 1.2276425\n",
      "Test set: Average loss: 1.7469, Accuracy: 2118/5000 (42%)\n",
      "[epoch 8] loss: 1.2733670\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8188, Accuracy: 2052/5000 (41%)\n",
      "[epoch 9] loss: 0.9410547\n",
      "Test set: Average loss: 1.6507, Accuracy: 2277/5000 (46%)\n",
      "[epoch 10] loss: 0.8662031\n",
      "Test set: Average loss: 1.6575, Accuracy: 2278/5000 (46%)\n",
      "[epoch 11] loss: 0.8305056\n",
      "Test set: Average loss: 1.6705, Accuracy: 2290/5000 (46%)\n",
      "[epoch 12] loss: 0.8224955\n",
      "Test set: Average loss: 1.6853, Accuracy: 2305/5000 (46%)\n",
      "[epoch 13] loss: 0.7828870\n",
      "Test set: Average loss: 1.7069, Accuracy: 2291/5000 (46%)\n",
      "[epoch 14] loss: 0.7662456\n",
      "Test set: Average loss: 1.7159, Accuracy: 2302/5000 (46%)\n",
      "[epoch 15] loss: 0.7430328\n",
      "Test set: Average loss: 1.7355, Accuracy: 2305/5000 (46%)\n",
      "[epoch 16] loss: 0.7214558\n",
      "Test set: Average loss: 1.7551, Accuracy: 2296/5000 (46%)\n",
      "[epoch 17] loss: 0.7000108\n",
      "Test set: Average loss: 1.7675, Accuracy: 2290/5000 (46%)\n",
      "[epoch 18] loss: 0.7967814\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7922, Accuracy: 2278/5000 (46%)\n",
      "[epoch 19] loss: 0.6520661\n",
      "Test set: Average loss: 1.7864, Accuracy: 2302/5000 (46%)\n",
      "[epoch 20] loss: 0.6462803\n",
      "Test set: Average loss: 1.7885, Accuracy: 2305/5000 (46%)\n",
      "[epoch 21] loss: 0.7036291\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7916, Accuracy: 2300/5000 (46%)\n",
      "[epoch 22] loss: 0.6327559\n",
      "Test set: Average loss: 1.7919, Accuracy: 2297/5000 (46%)\n",
      "[epoch 23] loss: 0.6312909\n",
      "Test set: Average loss: 1.7922, Accuracy: 2299/5000 (46%)\n",
      "[epoch 24] loss: 0.6389224\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 25] loss: 0.6381310\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 26] loss: 0.6316060\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 27] loss: 0.6338845\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 28] loss: 0.6373043\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 29] loss: 0.6330968\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 30] loss: 0.6321018\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 31] loss: 0.6332426\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 32] loss: 0.6331544\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 33] loss: 0.6324980\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 34] loss: 0.6404200\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 35] loss: 0.6335422\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 36] loss: 0.6376733\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 37] loss: 0.6469096\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 38] loss: 0.7294781\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 39] loss: 0.6352175\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 40] loss: 0.6346303\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 41] loss: 0.6331640\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 42] loss: 0.6371845\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 43] loss: 0.6314431\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 44] loss: 0.7092061\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 45] loss: 0.6328232\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 46] loss: 0.6326431\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 47] loss: 0.6329235\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 48] loss: 0.6442233\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 49] loss: 0.6354335\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "[epoch 50] loss: 0.7000955\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.7926, Accuracy: 2298/5000 (46%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7885, Accuracy: 2305/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.7920, Accuracy: 4507/10000 (45%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 315/5000 (6%)\n",
      "[epoch 1] loss: 2.0000206\n",
      "Test set: Average loss: 1.8339, Accuracy: 1637/5000 (33%)\n",
      "[epoch 2] loss: 1.6966182\n",
      "Test set: Average loss: 1.7606, Accuracy: 1832/5000 (37%)\n",
      "[epoch 3] loss: 1.5226777\n",
      "Test set: Average loss: 1.6293, Accuracy: 2049/5000 (41%)\n",
      "[epoch 4] loss: 1.3869966\n",
      "Test set: Average loss: 1.7040, Accuracy: 2029/5000 (41%)\n",
      "[epoch 5] loss: 1.3081865\n",
      "Test set: Average loss: 1.6392, Accuracy: 2124/5000 (42%)\n",
      "[epoch 6] loss: 1.1925001\n",
      "Test set: Average loss: 1.6187, Accuracy: 2113/5000 (42%)\n",
      "[epoch 7] loss: 1.0645316\n",
      "Test set: Average loss: 1.7646, Accuracy: 2050/5000 (41%)\n",
      "[epoch 8] loss: 0.9920293\n",
      "Test set: Average loss: 1.7985, Accuracy: 2075/5000 (42%)\n",
      "[epoch 9] loss: 0.9251271\n",
      "Test set: Average loss: 1.8653, Accuracy: 2084/5000 (42%)\n",
      "[epoch 10] loss: 0.8255381\n",
      "Test set: Average loss: 2.0143, Accuracy: 2059/5000 (41%)\n",
      "[epoch 11] loss: 0.7788997\n",
      "Test set: Average loss: 2.1250, Accuracy: 2008/5000 (40%)\n",
      "[epoch 12] loss: 0.7074653\n",
      "Test set: Average loss: 2.2346, Accuracy: 2041/5000 (41%)\n",
      "[epoch 13] loss: 0.6388224\n",
      "Test set: Average loss: 2.3548, Accuracy: 1994/5000 (40%)\n",
      "[epoch 14] loss: 0.6251424\n",
      "Test set: Average loss: 2.6134, Accuracy: 1953/5000 (39%)\n",
      "[epoch 15] loss: 0.5697816\n",
      "Test set: Average loss: 2.5790, Accuracy: 1978/5000 (40%)\n",
      "[epoch 16] loss: 0.5166643\n",
      "Test set: Average loss: 2.6949, Accuracy: 1947/5000 (39%)\n",
      "[epoch 17] loss: 0.4292054\n",
      "Test set: Average loss: 2.9324, Accuracy: 1927/5000 (39%)\n",
      "[epoch 18] loss: 0.3760464\n",
      "Test set: Average loss: 3.1148, Accuracy: 1961/5000 (39%)\n",
      "[epoch 19] loss: 0.3952243\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.2365, Accuracy: 1964/5000 (39%)\n",
      "[epoch 20] loss: 0.1967835\n",
      "Test set: Average loss: 3.1274, Accuracy: 2008/5000 (40%)\n",
      "[epoch 21] loss: 0.1466232\n",
      "Test set: Average loss: 3.1544, Accuracy: 1997/5000 (40%)\n",
      "[epoch 22] loss: 0.1194892\n",
      "Test set: Average loss: 3.2083, Accuracy: 1989/5000 (40%)\n",
      "[epoch 23] loss: 0.1089109\n",
      "Test set: Average loss: 3.2316, Accuracy: 1994/5000 (40%)\n",
      "[epoch 24] loss: 0.1001597\n",
      "Test set: Average loss: 3.2684, Accuracy: 1995/5000 (40%)\n",
      "[epoch 25] loss: 0.0937505\n",
      "Test set: Average loss: 3.3131, Accuracy: 1992/5000 (40%)\n",
      "[epoch 26] loss: 0.2055935\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.3460, Accuracy: 1979/5000 (40%)\n",
      "[epoch 27] loss: 0.0835926\n",
      "Test set: Average loss: 3.3488, Accuracy: 1980/5000 (40%)\n",
      "[epoch 28] loss: 0.0809275\n",
      "Test set: Average loss: 3.3529, Accuracy: 1990/5000 (40%)\n",
      "[epoch 29] loss: 0.0780287\n",
      "Test set: Average loss: 3.3581, Accuracy: 1985/5000 (40%)\n",
      "[epoch 30] loss: 0.0774213\n",
      "Test set: Average loss: 3.3630, Accuracy: 1990/5000 (40%)\n",
      "[epoch 31] loss: 0.0770988\n",
      "Test set: Average loss: 3.3680, Accuracy: 1988/5000 (40%)\n",
      "[epoch 32] loss: 0.0760237\n",
      "Test set: Average loss: 3.3723, Accuracy: 1985/5000 (40%)\n",
      "[epoch 33] loss: 0.0761404\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.3770, Accuracy: 1990/5000 (40%)\n",
      "[epoch 34] loss: 0.0744876\n",
      "Test set: Average loss: 3.3776, Accuracy: 1990/5000 (40%)\n",
      "[epoch 35] loss: 0.0743894\n",
      "Test set: Average loss: 3.3781, Accuracy: 1990/5000 (40%)\n",
      "[epoch 36] loss: 0.0753307\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.3785, Accuracy: 1990/5000 (40%)\n",
      "[epoch 37] loss: 0.2301913\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 38] loss: 0.0741658\n",
      "Test set: Average loss: 3.3785, Accuracy: 1990/5000 (40%)\n",
      "[epoch 39] loss: 0.0747392\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 40] loss: 0.0745459\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 41] loss: 0.0745036\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 42] loss: 0.0745848\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 43] loss: 0.0746173\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 44] loss: 0.0757848\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] loss: 0.0741400\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 46] loss: 0.0741575\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 47] loss: 0.0748714\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 48] loss: 0.0742730\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 49] loss: 0.0769940\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "[epoch 50] loss: 0.0740775\n",
      "Test set: Average loss: 3.3786, Accuracy: 1990/5000 (40%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6392, Accuracy: 2124/5000 (42%)\n",
      "Test\n",
      "Test set: Average loss: 1.6264, Accuracy: 4295/10000 (43%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 2.0665697\n",
      "Test set: Average loss: 1.7758, Accuracy: 1748/5000 (35%)\n",
      "[epoch 2] loss: 1.7537360\n",
      "Test set: Average loss: 1.6788, Accuracy: 1948/5000 (39%)\n",
      "[epoch 3] loss: 1.5258751\n",
      "Test set: Average loss: 1.6693, Accuracy: 1991/5000 (40%)\n",
      "[epoch 4] loss: 1.3961439\n",
      "Test set: Average loss: 1.6929, Accuracy: 2080/5000 (42%)\n",
      "[epoch 5] loss: 1.2600357\n",
      "Test set: Average loss: 1.6981, Accuracy: 2056/5000 (41%)\n",
      "[epoch 6] loss: 1.1718959\n",
      "Test set: Average loss: 1.7338, Accuracy: 2081/5000 (42%)\n",
      "[epoch 7] loss: 1.0683982\n",
      "Test set: Average loss: 1.8414, Accuracy: 1996/5000 (40%)\n",
      "[epoch 8] loss: 0.9991053\n",
      "Test set: Average loss: 1.9077, Accuracy: 2046/5000 (41%)\n",
      "[epoch 9] loss: 0.9868477\n",
      "Test set: Average loss: 2.0881, Accuracy: 1879/5000 (38%)\n",
      "[epoch 10] loss: 1.0869784\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0277, Accuracy: 1949/5000 (39%)\n",
      "[epoch 11] loss: 0.6901819\n",
      "Test set: Average loss: 1.8972, Accuracy: 2113/5000 (42%)\n",
      "[epoch 12] loss: 0.5924103\n",
      "Test set: Average loss: 1.9316, Accuracy: 2119/5000 (42%)\n",
      "[epoch 13] loss: 0.5619775\n",
      "Test set: Average loss: 1.9642, Accuracy: 2102/5000 (42%)\n",
      "[epoch 14] loss: 0.5449341\n",
      "Test set: Average loss: 1.9907, Accuracy: 2107/5000 (42%)\n",
      "[epoch 15] loss: 0.5307466\n",
      "Test set: Average loss: 2.0228, Accuracy: 2107/5000 (42%)\n",
      "[epoch 16] loss: 0.5100183\n",
      "Test set: Average loss: 2.0555, Accuracy: 2096/5000 (42%)\n",
      "[epoch 17] loss: 0.4880808\n",
      "Test set: Average loss: 2.0880, Accuracy: 2114/5000 (42%)\n",
      "[epoch 18] loss: 0.5912427\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.1179, Accuracy: 2098/5000 (42%)\n",
      "[epoch 19] loss: 0.4398309\n",
      "Test set: Average loss: 2.1167, Accuracy: 2097/5000 (42%)\n",
      "[epoch 20] loss: 0.4364182\n",
      "Test set: Average loss: 2.1211, Accuracy: 2103/5000 (42%)\n",
      "[epoch 21] loss: 0.4363560\n",
      "Test set: Average loss: 2.1253, Accuracy: 2104/5000 (42%)\n",
      "[epoch 22] loss: 0.4361733\n",
      "Test set: Average loss: 2.1287, Accuracy: 2100/5000 (42%)\n",
      "[epoch 23] loss: 0.4321217\n",
      "Test set: Average loss: 2.1331, Accuracy: 2104/5000 (42%)\n",
      "[epoch 24] loss: 0.4309620\n",
      "Test set: Average loss: 2.1387, Accuracy: 2099/5000 (42%)\n",
      "[epoch 25] loss: 0.4284182\n",
      "Test set: Average loss: 2.1421, Accuracy: 2105/5000 (42%)\n",
      "[epoch 26] loss: 0.4249058\n",
      "Test set: Average loss: 2.1463, Accuracy: 2102/5000 (42%)\n",
      "[epoch 27] loss: 0.4288518\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.1508, Accuracy: 2099/5000 (42%)\n",
      "[epoch 28] loss: 0.4195597\n",
      "Test set: Average loss: 2.1511, Accuracy: 2101/5000 (42%)\n",
      "[epoch 29] loss: 0.4262145\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 30] loss: 0.4221125\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 31] loss: 0.4193852\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 32] loss: 0.4290567\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 33] loss: 0.4233498\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 34] loss: 0.4198498\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 35] loss: 0.4210652\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 36] loss: 0.4189325\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 37] loss: 0.4195654\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 38] loss: 0.4202840\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 39] loss: 0.4190688\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 40] loss: 0.4191956\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 41] loss: 0.4196772\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 42] loss: 0.4361055\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 43] loss: 0.4214807\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 44] loss: 0.4278644\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 45] loss: 0.4210220\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 46] loss: 0.4191737\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 47] loss: 0.4208118\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 48] loss: 0.4223136\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 49] loss: 0.4186142\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "[epoch 50] loss: 0.4318942\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.1516, Accuracy: 2100/5000 (42%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9316, Accuracy: 2119/5000 (42%)\n",
      "Test\n",
      "Test set: Average loss: 1.8784, Accuracy: 4474/10000 (45%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3014, Accuracy: 528/5000 (11%)\n",
      "[epoch 1] loss: 1.8627217\n",
      "Test set: Average loss: 1.6824, Accuracy: 1865/5000 (37%)\n",
      "[epoch 2] loss: 1.5482925\n",
      "Test set: Average loss: 1.5631, Accuracy: 2176/5000 (44%)\n",
      "[epoch 3] loss: 1.3879584\n",
      "Test set: Average loss: 1.5638, Accuracy: 2247/5000 (45%)\n",
      "[epoch 4] loss: 1.3122929\n",
      "Test set: Average loss: 1.5211, Accuracy: 2287/5000 (46%)\n",
      "[epoch 5] loss: 1.2184735\n",
      "Test set: Average loss: 1.4707, Accuracy: 2488/5000 (50%)\n",
      "[epoch 6] loss: 1.1448039\n",
      "Test set: Average loss: 1.5012, Accuracy: 2411/5000 (48%)\n",
      "[epoch 7] loss: 1.0891045\n",
      "Test set: Average loss: 1.4783, Accuracy: 2427/5000 (49%)\n",
      "[epoch 8] loss: 1.0681559\n",
      "Test set: Average loss: 1.5852, Accuracy: 2399/5000 (48%)\n",
      "[epoch 9] loss: 1.0203973\n",
      "Test set: Average loss: 1.5300, Accuracy: 2438/5000 (49%)\n",
      "[epoch 10] loss: 0.9562413\n",
      "Test set: Average loss: 1.6070, Accuracy: 2426/5000 (49%)\n",
      "[epoch 11] loss: 0.9016967\n",
      "Test set: Average loss: 1.6578, Accuracy: 2387/5000 (48%)\n",
      "[epoch 12] loss: 0.8740609\n",
      "Test set: Average loss: 1.7267, Accuracy: 2307/5000 (46%)\n",
      "[epoch 13] loss: 0.8264642\n",
      "Test set: Average loss: 1.7212, Accuracy: 2382/5000 (48%)\n",
      "[epoch 14] loss: 0.7924337\n",
      "Test set: Average loss: 1.7935, Accuracy: 2362/5000 (47%)\n",
      "[epoch 15] loss: 0.7318473\n",
      "Test set: Average loss: 1.8352, Accuracy: 2341/5000 (47%)\n",
      "[epoch 16] loss: 0.6986107\n",
      "Test set: Average loss: 1.8848, Accuracy: 2337/5000 (47%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17] loss: 0.6524401\n",
      "Test set: Average loss: 1.9415, Accuracy: 2351/5000 (47%)\n",
      "[epoch 18] loss: 0.6049088\n",
      "Test set: Average loss: 1.9174, Accuracy: 2364/5000 (47%)\n",
      "[epoch 19] loss: 0.5315130\n",
      "Test set: Average loss: 2.0469, Accuracy: 2373/5000 (47%)\n",
      "[epoch 20] loss: 0.4995761\n",
      "Test set: Average loss: 2.0948, Accuracy: 2345/5000 (47%)\n",
      "[epoch 21] loss: 0.4539828\n",
      "Test set: Average loss: 2.2768, Accuracy: 2333/5000 (47%)\n",
      "[epoch 22] loss: 0.3935965\n",
      "Test set: Average loss: 2.2245, Accuracy: 2332/5000 (47%)\n",
      "[epoch 23] loss: 0.3057930\n",
      "Test set: Average loss: 2.4530, Accuracy: 2287/5000 (46%)\n",
      "[epoch 24] loss: 0.2429926\n",
      "Test set: Average loss: 2.4868, Accuracy: 2307/5000 (46%)\n",
      "[epoch 25] loss: 0.2063135\n",
      "Test set: Average loss: 2.5915, Accuracy: 2322/5000 (46%)\n",
      "[epoch 26] loss: 0.1543474\n",
      "Test set: Average loss: 2.7216, Accuracy: 2339/5000 (47%)\n",
      "[epoch 27] loss: 0.1218773\n",
      "Test set: Average loss: 2.8081, Accuracy: 2334/5000 (47%)\n",
      "[epoch 28] loss: 0.1193935\n",
      "Test set: Average loss: 2.8747, Accuracy: 2378/5000 (48%)\n",
      "[epoch 29] loss: 0.1152041\n",
      "Test set: Average loss: 2.9656, Accuracy: 2358/5000 (47%)\n",
      "[epoch 30] loss: 0.0664060\n",
      "Test set: Average loss: 3.1010, Accuracy: 2294/5000 (46%)\n",
      "[epoch 31] loss: 0.0315761\n",
      "Test set: Average loss: 3.1485, Accuracy: 2350/5000 (47%)\n",
      "[epoch 32] loss: 0.0137899\n",
      "Test set: Average loss: 3.2004, Accuracy: 2394/5000 (48%)\n",
      "[epoch 33] loss: 0.0088275\n",
      "Test set: Average loss: 3.2791, Accuracy: 2384/5000 (48%)\n",
      "[epoch 34] loss: 0.0068705\n",
      "Test set: Average loss: 3.3502, Accuracy: 2369/5000 (47%)\n",
      "[epoch 35] loss: 0.0056696\n",
      "Test set: Average loss: 3.4205, Accuracy: 2375/5000 (48%)\n",
      "[epoch 36] loss: 0.0047930\n",
      "Test set: Average loss: 3.4791, Accuracy: 2387/5000 (48%)\n",
      "[epoch 37] loss: 0.0040973\n",
      "Test set: Average loss: 3.5385, Accuracy: 2393/5000 (48%)\n",
      "[epoch 38] loss: 0.0035570\n",
      "Test set: Average loss: 3.5918, Accuracy: 2378/5000 (48%)\n",
      "[epoch 39] loss: 0.0031008\n",
      "Test set: Average loss: 3.6458, Accuracy: 2386/5000 (48%)\n",
      "[epoch 40] loss: 0.0027412\n",
      "Test set: Average loss: 3.7047, Accuracy: 2388/5000 (48%)\n",
      "[epoch 41] loss: 0.0024069\n",
      "Test set: Average loss: 3.7507, Accuracy: 2391/5000 (48%)\n",
      "[epoch 42] loss: 0.0021296\n",
      "Test set: Average loss: 3.8053, Accuracy: 2384/5000 (48%)\n",
      "[epoch 43] loss: 0.0018983\n",
      "Test set: Average loss: 3.8483, Accuracy: 2386/5000 (48%)\n",
      "[epoch 44] loss: 0.0016838\n",
      "Test set: Average loss: 3.8970, Accuracy: 2386/5000 (48%)\n",
      "[epoch 45] loss: 0.0015038\n",
      "Test set: Average loss: 3.9490, Accuracy: 2383/5000 (48%)\n",
      "[epoch 46] loss: 0.0013310\n",
      "Test set: Average loss: 3.9959, Accuracy: 2382/5000 (48%)\n",
      "[epoch 47] loss: 0.0011946\n",
      "Test set: Average loss: 4.0438, Accuracy: 2385/5000 (48%)\n",
      "[epoch 48] loss: 0.0010804\n",
      "Test set: Average loss: 4.0987, Accuracy: 2377/5000 (48%)\n",
      "[epoch 49] loss: 0.0009647\n",
      "Test set: Average loss: 4.1409, Accuracy: 2383/5000 (48%)\n",
      "[epoch 50] loss: 0.0008676\n",
      "Test set: Average loss: 4.1860, Accuracy: 2385/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4707, Accuracy: 2488/5000 (50%)\n",
      "Test\n",
      "Test set: Average loss: 1.4629, Accuracy: 4940/10000 (49%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 474/5000 (9%)\n",
      "[epoch 1] loss: 1.8742259\n",
      "Test set: Average loss: 1.6668, Accuracy: 1896/5000 (38%)\n",
      "[epoch 2] loss: 1.5652680\n",
      "Test set: Average loss: 1.6103, Accuracy: 2059/5000 (41%)\n",
      "[epoch 3] loss: 1.4329549\n",
      "Test set: Average loss: 1.4828, Accuracy: 2350/5000 (47%)\n",
      "[epoch 4] loss: 1.3162714\n",
      "Test set: Average loss: 1.5008, Accuracy: 2334/5000 (47%)\n",
      "[epoch 5] loss: 1.2195329\n",
      "Test set: Average loss: 1.5949, Accuracy: 2193/5000 (44%)\n",
      "[epoch 6] loss: 1.1865616\n",
      "Test set: Average loss: 1.4907, Accuracy: 2403/5000 (48%)\n",
      "[epoch 7] loss: 1.0984111\n",
      "Test set: Average loss: 1.5672, Accuracy: 2322/5000 (46%)\n",
      "[epoch 8] loss: 1.0368852\n",
      "Test set: Average loss: 1.5795, Accuracy: 2388/5000 (48%)\n",
      "[epoch 9] loss: 1.0165288\n",
      "Test set: Average loss: 1.5811, Accuracy: 2399/5000 (48%)\n",
      "[epoch 10] loss: 0.9548905\n",
      "Test set: Average loss: 1.6405, Accuracy: 2389/5000 (48%)\n",
      "[epoch 11] loss: 0.9314119\n",
      "Test set: Average loss: 1.6361, Accuracy: 2423/5000 (48%)\n",
      "[epoch 12] loss: 0.8855625\n",
      "Test set: Average loss: 1.6951, Accuracy: 2435/5000 (49%)\n",
      "[epoch 13] loss: 0.8093816\n",
      "Test set: Average loss: 1.7324, Accuracy: 2398/5000 (48%)\n",
      "[epoch 14] loss: 0.7930173\n",
      "Test set: Average loss: 1.8290, Accuracy: 2308/5000 (46%)\n",
      "[epoch 15] loss: 0.7579476\n",
      "Test set: Average loss: 1.9081, Accuracy: 2263/5000 (45%)\n",
      "[epoch 16] loss: 0.6958352\n",
      "Test set: Average loss: 1.9219, Accuracy: 2358/5000 (47%)\n",
      "[epoch 17] loss: 0.6559702\n",
      "Test set: Average loss: 1.9021, Accuracy: 2389/5000 (48%)\n",
      "[epoch 18] loss: 0.5944303\n",
      "Test set: Average loss: 1.9724, Accuracy: 2358/5000 (47%)\n",
      "[epoch 19] loss: 0.5468934\n",
      "Test set: Average loss: 2.0173, Accuracy: 2356/5000 (47%)\n",
      "[epoch 20] loss: 0.4811026\n",
      "Test set: Average loss: 2.2054, Accuracy: 2307/5000 (46%)\n",
      "[epoch 21] loss: 0.4372843\n",
      "Test set: Average loss: 2.1643, Accuracy: 2355/5000 (47%)\n",
      "[epoch 22] loss: 0.3552396\n",
      "Test set: Average loss: 2.3327, Accuracy: 2356/5000 (47%)\n",
      "[epoch 23] loss: 0.3275981\n",
      "Test set: Average loss: 2.4420, Accuracy: 2341/5000 (47%)\n",
      "[epoch 24] loss: 0.2566883\n",
      "Test set: Average loss: 2.5430, Accuracy: 2354/5000 (47%)\n",
      "[epoch 25] loss: 0.1850146\n",
      "Test set: Average loss: 2.6173, Accuracy: 2323/5000 (46%)\n",
      "[epoch 26] loss: 0.1531404\n",
      "Test set: Average loss: 2.8150, Accuracy: 2331/5000 (47%)\n",
      "[epoch 27] loss: 0.1274160\n",
      "Test set: Average loss: 2.7987, Accuracy: 2387/5000 (48%)\n",
      "[epoch 28] loss: 0.0856972\n",
      "Test set: Average loss: 2.8974, Accuracy: 2391/5000 (48%)\n",
      "[epoch 29] loss: 0.0470166\n",
      "Test set: Average loss: 3.0000, Accuracy: 2399/5000 (48%)\n",
      "[epoch 30] loss: 0.0275436\n",
      "Test set: Average loss: 3.1109, Accuracy: 2367/5000 (47%)\n",
      "[epoch 31] loss: 0.0159197\n",
      "Test set: Average loss: 3.1955, Accuracy: 2420/5000 (48%)\n",
      "[epoch 32] loss: 0.0112735\n",
      "Test set: Average loss: 3.2735, Accuracy: 2411/5000 (48%)\n",
      "[epoch 33] loss: 0.0084384\n",
      "Test set: Average loss: 3.3621, Accuracy: 2397/5000 (48%)\n",
      "[epoch 34] loss: 0.0071134\n",
      "Test set: Average loss: 3.4200, Accuracy: 2394/5000 (48%)\n",
      "[epoch 35] loss: 0.0057288\n",
      "Test set: Average loss: 3.5044, Accuracy: 2395/5000 (48%)\n",
      "[epoch 36] loss: 0.0048279\n",
      "Test set: Average loss: 3.5563, Accuracy: 2412/5000 (48%)\n",
      "[epoch 37] loss: 0.0041253\n",
      "Test set: Average loss: 3.6272, Accuracy: 2409/5000 (48%)\n",
      "[epoch 38] loss: 0.0035780\n",
      "Test set: Average loss: 3.6800, Accuracy: 2407/5000 (48%)\n",
      "[epoch 39] loss: 0.0030517\n",
      "Test set: Average loss: 3.7381, Accuracy: 2406/5000 (48%)\n",
      "[epoch 40] loss: 0.0026823\n",
      "Test set: Average loss: 3.8038, Accuracy: 2408/5000 (48%)\n",
      "[epoch 41] loss: 0.0023771\n",
      "Test set: Average loss: 3.8510, Accuracy: 2416/5000 (48%)\n",
      "[epoch 42] loss: 0.0020860\n",
      "Test set: Average loss: 3.9046, Accuracy: 2409/5000 (48%)\n",
      "[epoch 43] loss: 0.0018345\n",
      "Test set: Average loss: 3.9641, Accuracy: 2413/5000 (48%)\n",
      "[epoch 44] loss: 0.0016358\n",
      "Test set: Average loss: 4.0176, Accuracy: 2404/5000 (48%)\n",
      "[epoch 45] loss: 0.0014597\n",
      "Test set: Average loss: 4.0712, Accuracy: 2415/5000 (48%)\n",
      "[epoch 46] loss: 0.0012915\n",
      "Test set: Average loss: 4.1131, Accuracy: 2407/5000 (48%)\n",
      "[epoch 47] loss: 0.0011517\n",
      "Test set: Average loss: 4.1671, Accuracy: 2411/5000 (48%)\n",
      "[epoch 48] loss: 0.0010327\n",
      "Test set: Average loss: 4.2190, Accuracy: 2421/5000 (48%)\n",
      "[epoch 49] loss: 0.0009220\n",
      "Test set: Average loss: 4.2678, Accuracy: 2401/5000 (48%)\n",
      "[epoch 50] loss: 0.0008089\n",
      "Test set: Average loss: 4.3136, Accuracy: 2401/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6951, Accuracy: 2435/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 1.6972, Accuracy: 4848/10000 (48%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3049, Accuracy: 508/5000 (10%)\n",
      "[epoch 1] loss: 1.8929455\n",
      "Test set: Average loss: 1.6611, Accuracy: 1892/5000 (38%)\n",
      "[epoch 2] loss: 1.6036675\n",
      "Test set: Average loss: 1.5844, Accuracy: 2131/5000 (43%)\n",
      "[epoch 3] loss: 1.4806869\n",
      "Test set: Average loss: 1.6238, Accuracy: 2038/5000 (41%)\n",
      "[epoch 4] loss: 1.3914935\n",
      "Test set: Average loss: 1.5029, Accuracy: 2312/5000 (46%)\n",
      "[epoch 5] loss: 1.3023176\n",
      "Test set: Average loss: 1.5913, Accuracy: 2212/5000 (44%)\n",
      "[epoch 6] loss: 1.2169781\n",
      "Test set: Average loss: 1.4634, Accuracy: 2408/5000 (48%)\n",
      "[epoch 7] loss: 1.1732667\n",
      "Test set: Average loss: 1.4989, Accuracy: 2382/5000 (48%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 1.1004019\n",
      "Test set: Average loss: 1.4999, Accuracy: 2382/5000 (48%)\n",
      "[epoch 9] loss: 1.0421512\n",
      "Test set: Average loss: 1.5808, Accuracy: 2354/5000 (47%)\n",
      "[epoch 10] loss: 0.9789803\n",
      "Test set: Average loss: 1.5886, Accuracy: 2319/5000 (46%)\n",
      "[epoch 11] loss: 0.9637881\n",
      "Test set: Average loss: 1.6042, Accuracy: 2358/5000 (47%)\n",
      "[epoch 12] loss: 0.8829410\n",
      "Test set: Average loss: 1.6539, Accuracy: 2320/5000 (46%)\n",
      "[epoch 13] loss: 0.8488935\n",
      "Test set: Average loss: 1.7044, Accuracy: 2333/5000 (47%)\n",
      "[epoch 14] loss: 0.8175933\n",
      "Test set: Average loss: 1.7095, Accuracy: 2368/5000 (47%)\n",
      "[epoch 15] loss: 0.7539788\n",
      "Test set: Average loss: 1.7756, Accuracy: 2390/5000 (48%)\n",
      "[epoch 16] loss: 0.7222058\n",
      "Test set: Average loss: 1.8288, Accuracy: 2360/5000 (47%)\n",
      "[epoch 17] loss: 0.6612949\n",
      "Test set: Average loss: 1.9077, Accuracy: 2346/5000 (47%)\n",
      "[epoch 18] loss: 0.5962623\n",
      "Test set: Average loss: 1.9609, Accuracy: 2344/5000 (47%)\n",
      "[epoch 19] loss: 0.5573652\n",
      "Test set: Average loss: 2.0499, Accuracy: 2363/5000 (47%)\n",
      "[epoch 20] loss: 0.5213674\n",
      "Test set: Average loss: 2.1173, Accuracy: 2313/5000 (46%)\n",
      "[epoch 21] loss: 0.4912931\n",
      "Test set: Average loss: 2.1794, Accuracy: 2295/5000 (46%)\n",
      "[epoch 22] loss: 0.4029584\n",
      "Test set: Average loss: 2.2100, Accuracy: 2338/5000 (47%)\n",
      "[epoch 23] loss: 0.3281669\n",
      "Test set: Average loss: 2.3972, Accuracy: 2382/5000 (48%)\n",
      "[epoch 24] loss: 0.2847466\n",
      "Test set: Average loss: 2.4022, Accuracy: 2368/5000 (47%)\n",
      "[epoch 25] loss: 0.2173500\n",
      "Test set: Average loss: 2.5307, Accuracy: 2357/5000 (47%)\n",
      "[epoch 26] loss: 0.1788826\n",
      "Test set: Average loss: 2.6154, Accuracy: 2390/5000 (48%)\n",
      "[epoch 27] loss: 0.1962540\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.6219, Accuracy: 2383/5000 (48%)\n",
      "[epoch 28] loss: 0.0761908\n",
      "Test set: Average loss: 2.6157, Accuracy: 2415/5000 (48%)\n",
      "[epoch 29] loss: 0.0554911\n",
      "Test set: Average loss: 2.6401, Accuracy: 2413/5000 (48%)\n",
      "[epoch 30] loss: 0.0490967\n",
      "Test set: Average loss: 2.6644, Accuracy: 2421/5000 (48%)\n",
      "[epoch 31] loss: 0.0447866\n",
      "Test set: Average loss: 2.6853, Accuracy: 2420/5000 (48%)\n",
      "[epoch 32] loss: 0.0414816\n",
      "Test set: Average loss: 2.7036, Accuracy: 2428/5000 (49%)\n",
      "[epoch 33] loss: 0.0386059\n",
      "Test set: Average loss: 2.7247, Accuracy: 2427/5000 (49%)\n",
      "[epoch 34] loss: 0.0362705\n",
      "Test set: Average loss: 2.7478, Accuracy: 2421/5000 (48%)\n",
      "[epoch 35] loss: 0.0336601\n",
      "Test set: Average loss: 2.7683, Accuracy: 2419/5000 (48%)\n",
      "[epoch 36] loss: 0.0318308\n",
      "Test set: Average loss: 2.7927, Accuracy: 2423/5000 (48%)\n",
      "[epoch 37] loss: 0.0297808\n",
      "Test set: Average loss: 2.8164, Accuracy: 2422/5000 (48%)\n",
      "[epoch 38] loss: 0.0281580\n",
      "Test set: Average loss: 2.8390, Accuracy: 2415/5000 (48%)\n",
      "[epoch 39] loss: 0.0269026\n",
      "Test set: Average loss: 2.8650, Accuracy: 2416/5000 (48%)\n",
      "[epoch 40] loss: 0.0248345\n",
      "Test set: Average loss: 2.8902, Accuracy: 2420/5000 (48%)\n",
      "[epoch 41] loss: 0.0233112\n",
      "Test set: Average loss: 2.9123, Accuracy: 2410/5000 (48%)\n",
      "[epoch 42] loss: 0.0218518\n",
      "Test set: Average loss: 2.9432, Accuracy: 2418/5000 (48%)\n",
      "[epoch 43] loss: 0.0210189\n",
      "Test set: Average loss: 2.9679, Accuracy: 2407/5000 (48%)\n",
      "[epoch 44] loss: 0.0201149\n",
      "Test set: Average loss: 2.9975, Accuracy: 2406/5000 (48%)\n",
      "[epoch 45] loss: 0.0183292\n",
      "Test set: Average loss: 3.0185, Accuracy: 2412/5000 (48%)\n",
      "[epoch 46] loss: 0.0169289\n",
      "Test set: Average loss: 3.0430, Accuracy: 2405/5000 (48%)\n",
      "[epoch 47] loss: 0.0159391\n",
      "Test set: Average loss: 3.0741, Accuracy: 2399/5000 (48%)\n",
      "[epoch 48] loss: 0.0147846\n",
      "Test set: Average loss: 3.1125, Accuracy: 2397/5000 (48%)\n",
      "[epoch 49] loss: 0.0137020\n",
      "Test set: Average loss: 3.1393, Accuracy: 2408/5000 (48%)\n",
      "[epoch 50] loss: 0.0128216\n",
      "Test set: Average loss: 3.1709, Accuracy: 2410/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7036, Accuracy: 2428/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 2.6444, Accuracy: 4956/10000 (50%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3029, Accuracy: 470/5000 (9%)\n",
      "[epoch 1] loss: 1.7925587\n",
      "Test set: Average loss: 1.5860, Accuracy: 2114/5000 (42%)\n",
      "[epoch 2] loss: 1.5169518\n",
      "Test set: Average loss: 1.4927, Accuracy: 2301/5000 (46%)\n",
      "[epoch 3] loss: 1.3947645\n",
      "Test set: Average loss: 1.4589, Accuracy: 2371/5000 (47%)\n",
      "[epoch 4] loss: 1.3272854\n",
      "Test set: Average loss: 1.4136, Accuracy: 2452/5000 (49%)\n",
      "[epoch 5] loss: 1.2540996\n",
      "Test set: Average loss: 1.4085, Accuracy: 2486/5000 (50%)\n",
      "[epoch 6] loss: 1.2121424\n",
      "Test set: Average loss: 1.3623, Accuracy: 2573/5000 (51%)\n",
      "[epoch 7] loss: 1.1586682\n",
      "Test set: Average loss: 1.3581, Accuracy: 2573/5000 (51%)\n",
      "[epoch 8] loss: 1.1169562\n",
      "Test set: Average loss: 1.3496, Accuracy: 2586/5000 (52%)\n",
      "[epoch 9] loss: 1.0842658\n",
      "Test set: Average loss: 1.3563, Accuracy: 2621/5000 (52%)\n",
      "[epoch 10] loss: 1.0394596\n",
      "Test set: Average loss: 1.3564, Accuracy: 2645/5000 (53%)\n",
      "[epoch 11] loss: 0.9997312\n",
      "Test set: Average loss: 1.3411, Accuracy: 2660/5000 (53%)\n",
      "[epoch 12] loss: 0.9641560\n",
      "Test set: Average loss: 1.4313, Accuracy: 2632/5000 (53%)\n",
      "[epoch 13] loss: 0.9169221\n",
      "Test set: Average loss: 1.3689, Accuracy: 2703/5000 (54%)\n",
      "[epoch 14] loss: 0.8640257\n",
      "Test set: Average loss: 1.3902, Accuracy: 2653/5000 (53%)\n",
      "[epoch 15] loss: 0.8019256\n",
      "Test set: Average loss: 1.4236, Accuracy: 2724/5000 (54%)\n",
      "[epoch 16] loss: 0.7339118\n",
      "Test set: Average loss: 1.4604, Accuracy: 2666/5000 (53%)\n",
      "[epoch 17] loss: 0.6649298\n",
      "Test set: Average loss: 1.4735, Accuracy: 2670/5000 (53%)\n",
      "[epoch 18] loss: 0.5945336\n",
      "Test set: Average loss: 1.5224, Accuracy: 2716/5000 (54%)\n",
      "[epoch 19] loss: 0.5093263\n",
      "Test set: Average loss: 1.5603, Accuracy: 2701/5000 (54%)\n",
      "[epoch 20] loss: 0.4217407\n",
      "Test set: Average loss: 1.6699, Accuracy: 2628/5000 (53%)\n",
      "[epoch 21] loss: 0.3403767\n",
      "Test set: Average loss: 1.7338, Accuracy: 2629/5000 (53%)\n",
      "[epoch 22] loss: 0.2546701\n",
      "Test set: Average loss: 1.7954, Accuracy: 2685/5000 (54%)\n",
      "[epoch 23] loss: 0.1779614\n",
      "Test set: Average loss: 1.8919, Accuracy: 2670/5000 (53%)\n",
      "[epoch 24] loss: 0.1151330\n",
      "Test set: Average loss: 1.9616, Accuracy: 2675/5000 (54%)\n",
      "[epoch 25] loss: 0.0697128\n",
      "Test set: Average loss: 2.0317, Accuracy: 2714/5000 (54%)\n",
      "[epoch 26] loss: 0.0328374\n",
      "Test set: Average loss: 2.1315, Accuracy: 2690/5000 (54%)\n",
      "[epoch 27] loss: 0.0165613\n",
      "Test set: Average loss: 2.2038, Accuracy: 2695/5000 (54%)\n",
      "[epoch 28] loss: 0.0098250\n",
      "Test set: Average loss: 2.2817, Accuracy: 2714/5000 (54%)\n",
      "[epoch 29] loss: 0.0067306\n",
      "Test set: Average loss: 2.3542, Accuracy: 2753/5000 (55%)\n",
      "[epoch 30] loss: 0.0048125\n",
      "Test set: Average loss: 2.4307, Accuracy: 2727/5000 (55%)\n",
      "[epoch 31] loss: 0.0036301\n",
      "Test set: Average loss: 2.4874, Accuracy: 2712/5000 (54%)\n",
      "[epoch 32] loss: 0.0028125\n",
      "Test set: Average loss: 2.5549, Accuracy: 2725/5000 (54%)\n",
      "[epoch 33] loss: 0.0021960\n",
      "Test set: Average loss: 2.6108, Accuracy: 2737/5000 (55%)\n",
      "[epoch 34] loss: 0.0017346\n",
      "Test set: Average loss: 2.6754, Accuracy: 2731/5000 (55%)\n",
      "[epoch 35] loss: 0.0013566\n",
      "Test set: Average loss: 2.7415, Accuracy: 2735/5000 (55%)\n",
      "[epoch 36] loss: 0.0010722\n",
      "Test set: Average loss: 2.8075, Accuracy: 2730/5000 (55%)\n",
      "[epoch 37] loss: 0.0008501\n",
      "Test set: Average loss: 2.8631, Accuracy: 2729/5000 (55%)\n",
      "[epoch 38] loss: 0.0006841\n",
      "Test set: Average loss: 2.9270, Accuracy: 2729/5000 (55%)\n",
      "[epoch 39] loss: 0.0005416\n",
      "Test set: Average loss: 2.9862, Accuracy: 2715/5000 (54%)\n",
      "[epoch 40] loss: 0.0004340\n",
      "Test set: Average loss: 3.0431, Accuracy: 2720/5000 (54%)\n",
      "[epoch 41] loss: 0.0003461\n",
      "Test set: Average loss: 3.0986, Accuracy: 2725/5000 (54%)\n",
      "[epoch 42] loss: 0.0002773\n",
      "Test set: Average loss: 3.1754, Accuracy: 2729/5000 (55%)\n",
      "[epoch 43] loss: 0.0002219\n",
      "Test set: Average loss: 3.2149, Accuracy: 2722/5000 (54%)\n",
      "[epoch 44] loss: 0.0001790\n",
      "Test set: Average loss: 3.2758, Accuracy: 2724/5000 (54%)\n",
      "[epoch 45] loss: 0.0001475\n",
      "Test set: Average loss: 3.3294, Accuracy: 2728/5000 (55%)\n",
      "[epoch 46] loss: 0.0001154\n",
      "Test set: Average loss: 3.3863, Accuracy: 2715/5000 (54%)\n",
      "[epoch 47] loss: 0.0000929\n",
      "Test set: Average loss: 3.4371, Accuracy: 2708/5000 (54%)\n",
      "[epoch 48] loss: 0.0000754\n",
      "Test set: Average loss: 3.4971, Accuracy: 2725/5000 (54%)\n",
      "[epoch 49] loss: 0.0000608\n",
      "Test set: Average loss: 3.5532, Accuracy: 2736/5000 (55%)\n",
      "[epoch 50] loss: 0.0000488\n",
      "Test set: Average loss: 3.5991, Accuracy: 2721/5000 (54%)\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3542, Accuracy: 2753/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 2.4179, Accuracy: 5484/10000 (55%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 525/5000 (10%)\n",
      "[epoch 1] loss: 1.7374573\n",
      "Test set: Average loss: 1.5433, Accuracy: 2201/5000 (44%)\n",
      "[epoch 2] loss: 1.4790787\n",
      "Test set: Average loss: 1.4880, Accuracy: 2277/5000 (46%)\n",
      "[epoch 3] loss: 1.3755470\n",
      "Test set: Average loss: 1.4645, Accuracy: 2384/5000 (48%)\n",
      "[epoch 4] loss: 1.2955861\n",
      "Test set: Average loss: 1.4328, Accuracy: 2455/5000 (49%)\n",
      "[epoch 5] loss: 1.2256747\n",
      "Test set: Average loss: 1.4124, Accuracy: 2503/5000 (50%)\n",
      "[epoch 6] loss: 1.1853369\n",
      "Test set: Average loss: 1.4664, Accuracy: 2437/5000 (49%)\n",
      "[epoch 7] loss: 1.1402322\n",
      "Test set: Average loss: 1.4602, Accuracy: 2482/5000 (50%)\n",
      "[epoch 8] loss: 1.1051138\n",
      "Test set: Average loss: 1.4388, Accuracy: 2500/5000 (50%)\n",
      "[epoch 9] loss: 1.0686325\n",
      "Test set: Average loss: 1.4383, Accuracy: 2509/5000 (50%)\n",
      "[epoch 10] loss: 1.0217031\n",
      "Test set: Average loss: 1.4010, Accuracy: 2613/5000 (52%)\n",
      "[epoch 11] loss: 0.9894839\n",
      "Test set: Average loss: 1.3874, Accuracy: 2635/5000 (53%)\n",
      "[epoch 12] loss: 0.9439006\n",
      "Test set: Average loss: 1.4197, Accuracy: 2587/5000 (52%)\n",
      "[epoch 13] loss: 0.8938181\n",
      "Test set: Average loss: 1.4610, Accuracy: 2615/5000 (52%)\n",
      "[epoch 14] loss: 0.8371447\n",
      "Test set: Average loss: 1.4730, Accuracy: 2629/5000 (53%)\n",
      "[epoch 15] loss: 0.7760674\n",
      "Test set: Average loss: 1.4994, Accuracy: 2624/5000 (52%)\n",
      "[epoch 16] loss: 0.7057520\n",
      "Test set: Average loss: 1.5298, Accuracy: 2600/5000 (52%)\n",
      "[epoch 17] loss: 0.6475416\n",
      "Test set: Average loss: 1.5553, Accuracy: 2618/5000 (52%)\n",
      "[epoch 18] loss: 0.5617718\n",
      "Test set: Average loss: 1.6245, Accuracy: 2625/5000 (52%)\n",
      "[epoch 19] loss: 0.4755622\n",
      "Test set: Average loss: 1.6335, Accuracy: 2593/5000 (52%)\n",
      "[epoch 20] loss: 0.3793117\n",
      "Test set: Average loss: 1.7480, Accuracy: 2636/5000 (53%)\n",
      "[epoch 21] loss: 0.2919731\n",
      "Test set: Average loss: 1.7956, Accuracy: 2632/5000 (53%)\n",
      "[epoch 22] loss: 0.2078750\n",
      "Test set: Average loss: 1.8786, Accuracy: 2718/5000 (54%)\n",
      "[epoch 23] loss: 0.1340972\n",
      "Test set: Average loss: 1.9801, Accuracy: 2706/5000 (54%)\n",
      "[epoch 24] loss: 0.0805889\n",
      "Test set: Average loss: 2.0699, Accuracy: 2719/5000 (54%)\n",
      "[epoch 25] loss: 0.0496962\n",
      "Test set: Average loss: 2.1660, Accuracy: 2712/5000 (54%)\n",
      "[epoch 26] loss: 0.0255118\n",
      "Test set: Average loss: 2.2490, Accuracy: 2705/5000 (54%)\n",
      "[epoch 27] loss: 0.0170911\n",
      "Test set: Average loss: 2.3682, Accuracy: 2696/5000 (54%)\n",
      "[epoch 28] loss: 0.3503344\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3638, Accuracy: 2518/5000 (50%)\n",
      "[epoch 29] loss: 0.1470569\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0706, Accuracy: 2694/5000 (54%)\n",
      "[epoch 30] loss: 0.0681349\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0727, Accuracy: 2701/5000 (54%)\n",
      "[epoch 31] loss: 0.0649240\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 32] loss: 0.0645359\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 33] loss: 0.0644107\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 34] loss: 0.0645098\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 35] loss: 0.0645200\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 36] loss: 0.0644328\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 37] loss: 0.0645001\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 38] loss: 0.0644270\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 39] loss: 0.0644550\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 40] loss: 0.0644744\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 41] loss: 0.0645204\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 42] loss: 0.0644379\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 43] loss: 0.0645060\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 44] loss: 0.0644547\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 45] loss: 0.0645898\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 46] loss: 0.0644786\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 47] loss: 0.0645510\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 48] loss: 0.0645131\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 49] loss: 0.0644011\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "[epoch 50] loss: 0.0644463\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.0730, Accuracy: 2701/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0699, Accuracy: 2719/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.9876, Accuracy: 5469/10000 (55%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 511/5000 (10%)\n",
      "[epoch 1] loss: 1.7506934\n",
      "Test set: Average loss: 1.5620, Accuracy: 2132/5000 (43%)\n",
      "[epoch 2] loss: 1.4879201\n",
      "Test set: Average loss: 1.4289, Accuracy: 2354/5000 (47%)\n",
      "[epoch 3] loss: 1.3866592\n",
      "Test set: Average loss: 1.4756, Accuracy: 2369/5000 (47%)\n",
      "[epoch 4] loss: 1.3045790\n",
      "Test set: Average loss: 1.3739, Accuracy: 2563/5000 (51%)\n",
      "[epoch 5] loss: 1.2302036\n",
      "Test set: Average loss: 1.3274, Accuracy: 2620/5000 (52%)\n",
      "[epoch 6] loss: 1.1837883\n",
      "Test set: Average loss: 1.3531, Accuracy: 2583/5000 (52%)\n",
      "[epoch 7] loss: 1.1550837\n",
      "Test set: Average loss: 1.3934, Accuracy: 2575/5000 (52%)\n",
      "[epoch 8] loss: 1.0990651\n",
      "Test set: Average loss: 1.4034, Accuracy: 2574/5000 (51%)\n",
      "[epoch 9] loss: 1.0699758\n",
      "Test set: Average loss: 1.3545, Accuracy: 2667/5000 (53%)\n",
      "[epoch 10] loss: 1.0185065\n",
      "Test set: Average loss: 1.3862, Accuracy: 2594/5000 (52%)\n",
      "[epoch 11] loss: 0.9907986\n",
      "Test set: Average loss: 1.3818, Accuracy: 2660/5000 (53%)\n",
      "[epoch 12] loss: 0.9395103\n",
      "Test set: Average loss: 1.3581, Accuracy: 2728/5000 (55%)\n",
      "[epoch 13] loss: 0.8897444\n",
      "Test set: Average loss: 1.4234, Accuracy: 2637/5000 (53%)\n",
      "[epoch 14] loss: 0.8432522\n",
      "Test set: Average loss: 1.5291, Accuracy: 2556/5000 (51%)\n",
      "[epoch 15] loss: 0.7944992\n",
      "Test set: Average loss: 1.4899, Accuracy: 2636/5000 (53%)\n",
      "[epoch 16] loss: 0.7238719\n",
      "Test set: Average loss: 1.4861, Accuracy: 2664/5000 (53%)\n",
      "[epoch 17] loss: 0.6582836\n",
      "Test set: Average loss: 1.5306, Accuracy: 2625/5000 (52%)\n",
      "[epoch 18] loss: 0.5959105\n",
      "Test set: Average loss: 1.6060, Accuracy: 2650/5000 (53%)\n",
      "[epoch 19] loss: 0.5094563\n",
      "Test set: Average loss: 1.6194, Accuracy: 2651/5000 (53%)\n",
      "[epoch 20] loss: 0.4118309\n",
      "Test set: Average loss: 1.6924, Accuracy: 2649/5000 (53%)\n",
      "[epoch 21] loss: 0.3452824\n",
      "Test set: Average loss: 1.7853, Accuracy: 2651/5000 (53%)\n",
      "[epoch 22] loss: 0.2558733\n",
      "Test set: Average loss: 1.8889, Accuracy: 2659/5000 (53%)\n",
      "[epoch 23] loss: 0.2069352\n",
      "Test set: Average loss: 1.9647, Accuracy: 2600/5000 (52%)\n",
      "[epoch 24] loss: 0.1167681\n",
      "Test set: Average loss: 2.0695, Accuracy: 2654/5000 (53%)\n",
      "[epoch 25] loss: 0.0769038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.1359, Accuracy: 2637/5000 (53%)\n",
      "[epoch 26] loss: 0.0532197\n",
      "Test set: Average loss: 2.2358, Accuracy: 2694/5000 (54%)\n",
      "[epoch 27] loss: 0.0204876\n",
      "Test set: Average loss: 2.3072, Accuracy: 2649/5000 (53%)\n",
      "[epoch 28] loss: 0.0098769\n",
      "Test set: Average loss: 2.3814, Accuracy: 2696/5000 (54%)\n",
      "[epoch 29] loss: 0.0065764\n",
      "Test set: Average loss: 2.4570, Accuracy: 2686/5000 (54%)\n",
      "[epoch 30] loss: 0.0048822\n",
      "Test set: Average loss: 2.5301, Accuracy: 2696/5000 (54%)\n",
      "[epoch 31] loss: 0.0037324\n",
      "Test set: Average loss: 2.5968, Accuracy: 2702/5000 (54%)\n",
      "[epoch 32] loss: 0.0029229\n",
      "Test set: Average loss: 2.6564, Accuracy: 2697/5000 (54%)\n",
      "[epoch 33] loss: 0.0023040\n",
      "Test set: Average loss: 2.7328, Accuracy: 2694/5000 (54%)\n",
      "[epoch 34] loss: 0.0018256\n",
      "Test set: Average loss: 2.7880, Accuracy: 2700/5000 (54%)\n",
      "[epoch 35] loss: 0.0014517\n",
      "Test set: Average loss: 2.8554, Accuracy: 2712/5000 (54%)\n",
      "[epoch 36] loss: 0.0011574\n",
      "Test set: Average loss: 2.9146, Accuracy: 2692/5000 (54%)\n",
      "[epoch 37] loss: 0.0009241\n",
      "Test set: Average loss: 2.9820, Accuracy: 2713/5000 (54%)\n",
      "[epoch 38] loss: 0.0007429\n",
      "Test set: Average loss: 3.0419, Accuracy: 2704/5000 (54%)\n",
      "[epoch 39] loss: 0.0005878\n",
      "Test set: Average loss: 3.1039, Accuracy: 2698/5000 (54%)\n",
      "[epoch 40] loss: 0.0004729\n",
      "Test set: Average loss: 3.1621, Accuracy: 2704/5000 (54%)\n",
      "[epoch 41] loss: 0.0003814\n",
      "Test set: Average loss: 3.2255, Accuracy: 2705/5000 (54%)\n",
      "[epoch 42] loss: 0.0003078\n",
      "Test set: Average loss: 3.2912, Accuracy: 2706/5000 (54%)\n",
      "[epoch 43] loss: 0.0002470\n",
      "Test set: Average loss: 3.3475, Accuracy: 2713/5000 (54%)\n",
      "[epoch 44] loss: 0.0001995\n",
      "Test set: Average loss: 3.4071, Accuracy: 2716/5000 (54%)\n",
      "[epoch 45] loss: 0.0001605\n",
      "Test set: Average loss: 3.4662, Accuracy: 2697/5000 (54%)\n",
      "[epoch 46] loss: 0.0001305\n",
      "Test set: Average loss: 3.5254, Accuracy: 2703/5000 (54%)\n",
      "[epoch 47] loss: 0.0001049\n",
      "Test set: Average loss: 3.5807, Accuracy: 2701/5000 (54%)\n",
      "[epoch 48] loss: 0.0000847\n",
      "Test set: Average loss: 3.6437, Accuracy: 2723/5000 (54%)\n",
      "[epoch 49] loss: 0.0000694\n",
      "Test set: Average loss: 3.6972, Accuracy: 2710/5000 (54%)\n",
      "[epoch 50] loss: 0.0000561\n",
      "Test set: Average loss: 3.7517, Accuracy: 2722/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3581, Accuracy: 2728/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.3374, Accuracy: 5451/10000 (55%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 441/5000 (9%)\n",
      "[epoch 1] loss: 1.6487503\n",
      "Test set: Average loss: 1.4644, Accuracy: 2317/5000 (46%)\n",
      "[epoch 2] loss: 1.3998761\n",
      "Test set: Average loss: 1.4041, Accuracy: 2417/5000 (48%)\n",
      "[epoch 3] loss: 1.2918002\n",
      "Test set: Average loss: 1.3337, Accuracy: 2637/5000 (53%)\n",
      "[epoch 4] loss: 1.2082816\n",
      "Test set: Average loss: 1.3209, Accuracy: 2657/5000 (53%)\n",
      "[epoch 5] loss: 1.1621289\n",
      "Test set: Average loss: 1.3058, Accuracy: 2729/5000 (55%)\n",
      "[epoch 6] loss: 1.1149573\n",
      "Test set: Average loss: 1.2737, Accuracy: 2749/5000 (55%)\n",
      "[epoch 7] loss: 1.0750760\n",
      "Test set: Average loss: 1.2406, Accuracy: 2798/5000 (56%)\n",
      "[epoch 8] loss: 1.0254512\n",
      "Test set: Average loss: 1.2895, Accuracy: 2799/5000 (56%)\n",
      "[epoch 9] loss: 0.9854244\n",
      "Test set: Average loss: 1.2704, Accuracy: 2809/5000 (56%)\n",
      "[epoch 10] loss: 0.9507406\n",
      "Test set: Average loss: 1.2303, Accuracy: 2864/5000 (57%)\n",
      "[epoch 11] loss: 0.8995409\n",
      "Test set: Average loss: 1.2887, Accuracy: 2808/5000 (56%)\n",
      "[epoch 12] loss: 0.8377063\n",
      "Test set: Average loss: 1.2963, Accuracy: 2825/5000 (56%)\n",
      "[epoch 13] loss: 0.7719112\n",
      "Test set: Average loss: 1.3034, Accuracy: 2853/5000 (57%)\n",
      "[epoch 14] loss: 0.6938256\n",
      "Test set: Average loss: 1.3165, Accuracy: 2850/5000 (57%)\n",
      "[epoch 15] loss: 0.6131538\n",
      "Test set: Average loss: 1.4138, Accuracy: 2793/5000 (56%)\n",
      "[epoch 16] loss: 0.5276624\n",
      "Test set: Average loss: 1.4575, Accuracy: 2843/5000 (57%)\n",
      "[epoch 17] loss: 0.4373486\n",
      "Test set: Average loss: 1.5048, Accuracy: 2849/5000 (57%)\n",
      "[epoch 18] loss: 0.3286148\n",
      "Test set: Average loss: 1.5222, Accuracy: 2899/5000 (58%)\n",
      "[epoch 19] loss: 0.2240428\n",
      "Test set: Average loss: 1.6195, Accuracy: 2893/5000 (58%)\n",
      "[epoch 20] loss: 0.1555220\n",
      "Test set: Average loss: 1.6848, Accuracy: 2880/5000 (58%)\n",
      "[epoch 21] loss: 0.1020011\n",
      "Test set: Average loss: 1.8776, Accuracy: 2839/5000 (57%)\n",
      "[epoch 22] loss: 0.0866388\n",
      "Test set: Average loss: 2.0005, Accuracy: 2773/5000 (55%)\n",
      "[epoch 23] loss: 0.1091394\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1326, Accuracy: 2814/5000 (56%)\n",
      "[epoch 24] loss: 0.0506414\n",
      "Test set: Average loss: 1.9344, Accuracy: 2923/5000 (58%)\n",
      "[epoch 25] loss: 0.0197835\n",
      "Test set: Average loss: 1.9432, Accuracy: 2931/5000 (59%)\n",
      "[epoch 26] loss: 0.0142798\n",
      "Test set: Average loss: 1.9548, Accuracy: 2934/5000 (59%)\n",
      "[epoch 27] loss: 0.0112701\n",
      "Test set: Average loss: 1.9689, Accuracy: 2954/5000 (59%)\n",
      "[epoch 28] loss: 0.0092268\n",
      "Test set: Average loss: 1.9830, Accuracy: 2950/5000 (59%)\n",
      "[epoch 29] loss: 0.0076925\n",
      "Test set: Average loss: 2.0007, Accuracy: 2954/5000 (59%)\n",
      "[epoch 30] loss: 0.0064694\n",
      "Test set: Average loss: 2.0219, Accuracy: 2957/5000 (59%)\n",
      "[epoch 31] loss: 0.0054706\n",
      "Test set: Average loss: 2.0425, Accuracy: 2967/5000 (59%)\n",
      "[epoch 32] loss: 0.0046283\n",
      "Test set: Average loss: 2.0645, Accuracy: 2974/5000 (59%)\n",
      "[epoch 33] loss: 0.0039058\n",
      "Test set: Average loss: 2.0886, Accuracy: 2977/5000 (60%)\n",
      "[epoch 34] loss: 0.0032894\n",
      "Test set: Average loss: 2.1180, Accuracy: 2973/5000 (59%)\n",
      "[epoch 35] loss: 0.0027611\n",
      "Test set: Average loss: 2.1476, Accuracy: 2979/5000 (60%)\n",
      "[epoch 36] loss: 0.0023065\n",
      "Test set: Average loss: 2.1776, Accuracy: 2984/5000 (60%)\n",
      "[epoch 37] loss: 0.0019085\n",
      "Test set: Average loss: 2.2094, Accuracy: 2995/5000 (60%)\n",
      "[epoch 38] loss: 0.0015761\n",
      "Test set: Average loss: 2.2447, Accuracy: 2982/5000 (60%)\n",
      "[epoch 39] loss: 0.0012977\n",
      "Test set: Average loss: 2.2794, Accuracy: 2997/5000 (60%)\n",
      "[epoch 40] loss: 0.0010626\n",
      "Test set: Average loss: 2.3098, Accuracy: 2993/5000 (60%)\n",
      "[epoch 41] loss: 0.0008648\n",
      "Test set: Average loss: 2.3543, Accuracy: 3008/5000 (60%)\n",
      "[epoch 42] loss: 0.0007027\n",
      "Test set: Average loss: 2.3931, Accuracy: 2998/5000 (60%)\n",
      "[epoch 43] loss: 0.0005695\n",
      "Test set: Average loss: 2.4381, Accuracy: 2998/5000 (60%)\n",
      "[epoch 44] loss: 0.0004587\n",
      "Test set: Average loss: 2.4800, Accuracy: 3004/5000 (60%)\n",
      "[epoch 45] loss: 0.0003686\n",
      "Test set: Average loss: 2.5176, Accuracy: 2996/5000 (60%)\n",
      "[epoch 46] loss: 0.0002950\n",
      "Test set: Average loss: 2.5653, Accuracy: 3004/5000 (60%)\n",
      "[epoch 47] loss: 0.0002356\n",
      "Test set: Average loss: 2.6097, Accuracy: 2994/5000 (60%)\n",
      "[epoch 48] loss: 0.0001889\n",
      "Test set: Average loss: 2.6555, Accuracy: 2997/5000 (60%)\n",
      "[epoch 49] loss: 0.0001510\n",
      "Test set: Average loss: 2.6997, Accuracy: 2996/5000 (60%)\n",
      "[epoch 50] loss: 0.0001194\n",
      "Test set: Average loss: 2.7427, Accuracy: 2994/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3543, Accuracy: 3008/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.3602, Accuracy: 5992/10000 (60%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 451/5000 (9%)\n",
      "[epoch 1] loss: 1.6939742\n",
      "Test set: Average loss: 1.6150, Accuracy: 2141/5000 (43%)\n",
      "[epoch 2] loss: 1.4205401\n",
      "Test set: Average loss: 1.4278, Accuracy: 2436/5000 (49%)\n",
      "[epoch 3] loss: 1.3068584\n",
      "Test set: Average loss: 1.3977, Accuracy: 2482/5000 (50%)\n",
      "[epoch 4] loss: 1.2434954\n",
      "Test set: Average loss: 1.3259, Accuracy: 2679/5000 (54%)\n",
      "[epoch 5] loss: 1.1805808\n",
      "Test set: Average loss: 1.3189, Accuracy: 2676/5000 (54%)\n",
      "[epoch 6] loss: 1.1347738\n",
      "Test set: Average loss: 1.2991, Accuracy: 2718/5000 (54%)\n",
      "[epoch 7] loss: 1.0942155\n",
      "Test set: Average loss: 1.3416, Accuracy: 2714/5000 (54%)\n",
      "[epoch 8] loss: 1.0577564\n",
      "Test set: Average loss: 1.2820, Accuracy: 2797/5000 (56%)\n",
      "[epoch 9] loss: 1.0111377\n",
      "Test set: Average loss: 1.3172, Accuracy: 2760/5000 (55%)\n",
      "[epoch 10] loss: 0.9728372\n",
      "Test set: Average loss: 1.3199, Accuracy: 2743/5000 (55%)\n",
      "[epoch 11] loss: 0.9249263\n",
      "Test set: Average loss: 1.3251, Accuracy: 2800/5000 (56%)\n",
      "[epoch 12] loss: 0.8738030\n",
      "Test set: Average loss: 1.3471, Accuracy: 2780/5000 (56%)\n",
      "[epoch 13] loss: 0.8097907\n",
      "Test set: Average loss: 1.3117, Accuracy: 2841/5000 (57%)\n",
      "[epoch 14] loss: 0.7490876\n",
      "Test set: Average loss: 1.3780, Accuracy: 2826/5000 (57%)\n",
      "[epoch 15] loss: 0.6723475\n",
      "Test set: Average loss: 1.3847, Accuracy: 2836/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 0.5848531\n",
      "Test set: Average loss: 1.4270, Accuracy: 2860/5000 (57%)\n",
      "[epoch 17] loss: 0.4885046\n",
      "Test set: Average loss: 1.4798, Accuracy: 2891/5000 (58%)\n",
      "[epoch 18] loss: 0.4000900\n",
      "Test set: Average loss: 1.5453, Accuracy: 2889/5000 (58%)\n",
      "[epoch 19] loss: 0.2979641\n",
      "Test set: Average loss: 1.5801, Accuracy: 2896/5000 (58%)\n",
      "[epoch 20] loss: 0.2194469\n",
      "Test set: Average loss: 1.7470, Accuracy: 2829/5000 (57%)\n",
      "[epoch 21] loss: 0.1472863\n",
      "Test set: Average loss: 1.7931, Accuracy: 2877/5000 (58%)\n",
      "[epoch 22] loss: 0.0868291\n",
      "Test set: Average loss: 1.9118, Accuracy: 2884/5000 (58%)\n",
      "[epoch 23] loss: 0.0408156\n",
      "Test set: Average loss: 2.0070, Accuracy: 2860/5000 (57%)\n",
      "[epoch 24] loss: 0.0274090\n",
      "Test set: Average loss: 2.1286, Accuracy: 2863/5000 (57%)\n",
      "[epoch 25] loss: 0.2929735\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0407, Accuracy: 2720/5000 (54%)\n",
      "[epoch 26] loss: 0.1258739\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9573, Accuracy: 2861/5000 (57%)\n",
      "[epoch 27] loss: 0.0577380\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.9574, Accuracy: 2869/5000 (57%)\n",
      "[epoch 28] loss: 0.0542737\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.9578, Accuracy: 2870/5000 (57%)\n",
      "[epoch 29] loss: 0.0539617\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 30] loss: 0.0539424\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 31] loss: 0.0538896\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 32] loss: 0.0539351\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 33] loss: 0.0539365\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 34] loss: 0.0539015\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 35] loss: 0.0539082\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 36] loss: 0.0539041\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 37] loss: 0.0539024\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 38] loss: 0.0538970\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 39] loss: 0.0539065\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 40] loss: 0.0539060\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 41] loss: 0.0538912\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 42] loss: 0.0539025\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 43] loss: 0.0539113\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 44] loss: 0.0539032\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 45] loss: 0.0539160\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 46] loss: 0.0539060\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 47] loss: 0.0539047\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 48] loss: 0.0538997\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 49] loss: 0.0539054\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "[epoch 50] loss: 0.0538987\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.9579, Accuracy: 2870/5000 (57%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5801, Accuracy: 2896/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.5768, Accuracy: 5822/10000 (58%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 437/5000 (9%)\n",
      "[epoch 1] loss: 1.6689090\n",
      "Test set: Average loss: 1.5114, Accuracy: 2233/5000 (45%)\n",
      "[epoch 2] loss: 1.4108622\n",
      "Test set: Average loss: 1.4024, Accuracy: 2452/5000 (49%)\n",
      "[epoch 3] loss: 1.3140391\n",
      "Test set: Average loss: 1.3717, Accuracy: 2569/5000 (51%)\n",
      "[epoch 4] loss: 1.2372012\n",
      "Test set: Average loss: 1.4027, Accuracy: 2468/5000 (49%)\n",
      "[epoch 5] loss: 1.1924153\n",
      "Test set: Average loss: 1.3898, Accuracy: 2562/5000 (51%)\n",
      "[epoch 6] loss: 1.1441128\n",
      "Test set: Average loss: 1.3160, Accuracy: 2664/5000 (53%)\n",
      "[epoch 7] loss: 1.1054637\n",
      "Test set: Average loss: 1.3021, Accuracy: 2764/5000 (55%)\n",
      "[epoch 8] loss: 1.0538189\n",
      "Test set: Average loss: 1.3273, Accuracy: 2704/5000 (54%)\n",
      "[epoch 9] loss: 1.0288577\n",
      "Test set: Average loss: 1.2328, Accuracy: 2887/5000 (58%)\n",
      "[epoch 10] loss: 0.9757772\n",
      "Test set: Average loss: 1.3197, Accuracy: 2740/5000 (55%)\n",
      "[epoch 11] loss: 0.9268881\n",
      "Test set: Average loss: 1.2514, Accuracy: 2822/5000 (56%)\n",
      "[epoch 12] loss: 0.8738811\n",
      "Test set: Average loss: 1.2836, Accuracy: 2838/5000 (57%)\n",
      "[epoch 13] loss: 0.8217054\n",
      "Test set: Average loss: 1.3193, Accuracy: 2810/5000 (56%)\n",
      "[epoch 14] loss: 0.7554983\n",
      "Test set: Average loss: 1.3189, Accuracy: 2825/5000 (56%)\n",
      "[epoch 15] loss: 0.6765800\n",
      "Test set: Average loss: 1.3700, Accuracy: 2835/5000 (57%)\n",
      "[epoch 16] loss: 0.5917066\n",
      "Test set: Average loss: 1.4193, Accuracy: 2825/5000 (56%)\n",
      "[epoch 17] loss: 0.5042988\n",
      "Test set: Average loss: 1.4671, Accuracy: 2817/5000 (56%)\n",
      "[epoch 18] loss: 0.3989143\n",
      "Test set: Average loss: 1.4913, Accuracy: 2843/5000 (57%)\n",
      "[epoch 19] loss: 0.2960420\n",
      "Test set: Average loss: 1.5680, Accuracy: 2838/5000 (57%)\n",
      "[epoch 20] loss: 0.2050793\n",
      "Test set: Average loss: 1.6964, Accuracy: 2800/5000 (56%)\n",
      "[epoch 21] loss: 0.1505064\n",
      "Test set: Average loss: 1.8034, Accuracy: 2857/5000 (57%)\n",
      "[epoch 22] loss: 0.0750073\n",
      "Test set: Average loss: 1.8962, Accuracy: 2838/5000 (57%)\n",
      "[epoch 23] loss: 0.0444755\n",
      "Test set: Average loss: 1.9562, Accuracy: 2885/5000 (58%)\n",
      "[epoch 24] loss: 0.0139869\n",
      "Test set: Average loss: 2.0235, Accuracy: 2884/5000 (58%)\n",
      "[epoch 25] loss: 0.0052353\n",
      "Test set: Average loss: 2.0932, Accuracy: 2912/5000 (58%)\n",
      "[epoch 26] loss: 0.0031878\n",
      "Test set: Average loss: 2.1578, Accuracy: 2898/5000 (58%)\n",
      "[epoch 27] loss: 0.0022697\n",
      "Test set: Average loss: 2.2125, Accuracy: 2920/5000 (58%)\n",
      "[epoch 28] loss: 0.0016847\n",
      "Test set: Average loss: 2.2709, Accuracy: 2904/5000 (58%)\n",
      "[epoch 29] loss: 0.0012693\n",
      "Test set: Average loss: 2.3285, Accuracy: 2911/5000 (58%)\n",
      "[epoch 30] loss: 0.0009574\n",
      "Test set: Average loss: 2.3793, Accuracy: 2902/5000 (58%)\n",
      "[epoch 31] loss: 0.0007201\n",
      "Test set: Average loss: 2.4343, Accuracy: 2898/5000 (58%)\n",
      "[epoch 32] loss: 0.0005451\n",
      "Test set: Average loss: 2.4971, Accuracy: 2911/5000 (58%)\n",
      "[epoch 33] loss: 0.0004092\n",
      "Test set: Average loss: 2.5614, Accuracy: 2900/5000 (58%)\n",
      "[epoch 34] loss: 0.0003095\n",
      "Test set: Average loss: 2.6187, Accuracy: 2895/5000 (58%)\n",
      "[epoch 35] loss: 0.0002318\n",
      "Test set: Average loss: 2.6780, Accuracy: 2893/5000 (58%)\n",
      "[epoch 36] loss: 0.0001749\n",
      "Test set: Average loss: 2.7307, Accuracy: 2902/5000 (58%)\n",
      "[epoch 37] loss: 0.0001315\n",
      "Test set: Average loss: 2.7909, Accuracy: 2909/5000 (58%)\n",
      "[epoch 38] loss: 0.0000983\n",
      "Test set: Average loss: 2.8629, Accuracy: 2912/5000 (58%)\n",
      "[epoch 39] loss: 0.0000737\n",
      "Test set: Average loss: 2.9265, Accuracy: 2904/5000 (58%)\n",
      "[epoch 40] loss: 0.0000551\n",
      "Test set: Average loss: 2.9819, Accuracy: 2904/5000 (58%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.0000414\n",
      "Test set: Average loss: 3.0438, Accuracy: 2910/5000 (58%)\n",
      "[epoch 42] loss: 0.0000312\n",
      "Test set: Average loss: 3.1072, Accuracy: 2926/5000 (59%)\n",
      "[epoch 43] loss: 0.0000234\n",
      "Test set: Average loss: 3.1653, Accuracy: 2925/5000 (58%)\n",
      "[epoch 44] loss: 0.0000175\n",
      "Test set: Average loss: 3.2340, Accuracy: 2907/5000 (58%)\n",
      "[epoch 45] loss: 0.0000132\n",
      "Test set: Average loss: 3.2948, Accuracy: 2925/5000 (58%)\n",
      "[epoch 46] loss: 0.0000099\n",
      "Test set: Average loss: 3.3490, Accuracy: 2916/5000 (58%)\n",
      "[epoch 47] loss: 0.0000075\n",
      "Test set: Average loss: 3.4128, Accuracy: 2913/5000 (58%)\n",
      "[epoch 48] loss: 0.0000056\n",
      "Test set: Average loss: 3.4645, Accuracy: 2919/5000 (58%)\n",
      "[epoch 49] loss: 0.0000042\n",
      "Test set: Average loss: 3.5292, Accuracy: 2924/5000 (58%)\n",
      "[epoch 50] loss: 0.0000032\n",
      "Test set: Average loss: 3.5824, Accuracy: 2914/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1072, Accuracy: 2926/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 3.0803, Accuracy: 5939/10000 (59%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 487/5000 (10%)\n",
      "[epoch 1] loss: 1.6026542\n",
      "Test set: Average loss: 1.4192, Accuracy: 2443/5000 (49%)\n",
      "[epoch 2] loss: 1.3176419\n",
      "Test set: Average loss: 1.3185, Accuracy: 2602/5000 (52%)\n",
      "[epoch 3] loss: 1.2100543\n",
      "Test set: Average loss: 1.3243, Accuracy: 2616/5000 (52%)\n",
      "[epoch 4] loss: 1.1630736\n",
      "Test set: Average loss: 1.2730, Accuracy: 2788/5000 (56%)\n",
      "[epoch 5] loss: 1.1067780\n",
      "Test set: Average loss: 1.2747, Accuracy: 2818/5000 (56%)\n",
      "[epoch 6] loss: 1.0596266\n",
      "Test set: Average loss: 1.2089, Accuracy: 2864/5000 (57%)\n",
      "[epoch 7] loss: 1.0149819\n",
      "Test set: Average loss: 1.1808, Accuracy: 2924/5000 (58%)\n",
      "[epoch 8] loss: 0.9680046\n",
      "Test set: Average loss: 1.1961, Accuracy: 2934/5000 (59%)\n",
      "[epoch 9] loss: 0.9212323\n",
      "Test set: Average loss: 1.1733, Accuracy: 2984/5000 (60%)\n",
      "[epoch 10] loss: 0.8575844\n",
      "Test set: Average loss: 1.1896, Accuracy: 2958/5000 (59%)\n",
      "[epoch 11] loss: 0.8083153\n",
      "Test set: Average loss: 1.2341, Accuracy: 2913/5000 (58%)\n",
      "[epoch 12] loss: 0.7416012\n",
      "Test set: Average loss: 1.2047, Accuracy: 3013/5000 (60%)\n",
      "[epoch 13] loss: 0.6632461\n",
      "Test set: Average loss: 1.2570, Accuracy: 2977/5000 (60%)\n",
      "[epoch 14] loss: 0.5720873\n",
      "Test set: Average loss: 1.2508, Accuracy: 3054/5000 (61%)\n",
      "[epoch 15] loss: 0.4784504\n",
      "Test set: Average loss: 1.3424, Accuracy: 3012/5000 (60%)\n",
      "[epoch 16] loss: 0.3753289\n",
      "Test set: Average loss: 1.4103, Accuracy: 2986/5000 (60%)\n",
      "[epoch 17] loss: 0.2896971\n",
      "Test set: Average loss: 1.4614, Accuracy: 3076/5000 (62%)\n",
      "[epoch 18] loss: 0.2068540\n",
      "Test set: Average loss: 1.5986, Accuracy: 3015/5000 (60%)\n",
      "[epoch 19] loss: 0.1280184\n",
      "Test set: Average loss: 1.7159, Accuracy: 2976/5000 (60%)\n",
      "[epoch 20] loss: 0.0899965\n",
      "Test set: Average loss: 1.8011, Accuracy: 2974/5000 (59%)\n",
      "[epoch 21] loss: 0.1452920\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9031, Accuracy: 2917/5000 (58%)\n",
      "[epoch 22] loss: 0.0836007\n",
      "Test set: Average loss: 1.7434, Accuracy: 3070/5000 (61%)\n",
      "[epoch 23] loss: 0.0286313\n",
      "Test set: Average loss: 1.7624, Accuracy: 3086/5000 (62%)\n",
      "[epoch 24] loss: 0.0185807\n",
      "Test set: Average loss: 1.7753, Accuracy: 3103/5000 (62%)\n",
      "[epoch 25] loss: 0.0135976\n",
      "Test set: Average loss: 1.7951, Accuracy: 3108/5000 (62%)\n",
      "[epoch 26] loss: 0.0103755\n",
      "Test set: Average loss: 1.8210, Accuracy: 3115/5000 (62%)\n",
      "[epoch 27] loss: 0.0081127\n",
      "Test set: Average loss: 1.8450, Accuracy: 3119/5000 (62%)\n",
      "[epoch 28] loss: 0.0063739\n",
      "Test set: Average loss: 1.8704, Accuracy: 3126/5000 (63%)\n",
      "[epoch 29] loss: 0.0050324\n",
      "Test set: Average loss: 1.9003, Accuracy: 3128/5000 (63%)\n",
      "[epoch 30] loss: 0.0039670\n",
      "Test set: Average loss: 1.9317, Accuracy: 3120/5000 (62%)\n",
      "[epoch 31] loss: 0.0031129\n",
      "Test set: Average loss: 1.9665, Accuracy: 3129/5000 (63%)\n",
      "[epoch 32] loss: 0.0024328\n",
      "Test set: Average loss: 2.0002, Accuracy: 3129/5000 (63%)\n",
      "[epoch 33] loss: 0.0018982\n",
      "Test set: Average loss: 2.0402, Accuracy: 3135/5000 (63%)\n",
      "[epoch 34] loss: 0.0014687\n",
      "Test set: Average loss: 2.0867, Accuracy: 3126/5000 (63%)\n",
      "[epoch 35] loss: 0.0011334\n",
      "Test set: Average loss: 2.1236, Accuracy: 3132/5000 (63%)\n",
      "[epoch 36] loss: 0.0008677\n",
      "Test set: Average loss: 2.1653, Accuracy: 3127/5000 (63%)\n",
      "[epoch 37] loss: 0.0006622\n",
      "Test set: Average loss: 2.2138, Accuracy: 3139/5000 (63%)\n",
      "[epoch 38] loss: 0.0005031\n",
      "Test set: Average loss: 2.2619, Accuracy: 3147/5000 (63%)\n",
      "[epoch 39] loss: 0.0003813\n",
      "Test set: Average loss: 2.3092, Accuracy: 3136/5000 (63%)\n",
      "[epoch 40] loss: 0.0002869\n",
      "Test set: Average loss: 2.3597, Accuracy: 3140/5000 (63%)\n",
      "[epoch 41] loss: 0.0002159\n",
      "Test set: Average loss: 2.4096, Accuracy: 3142/5000 (63%)\n",
      "[epoch 42] loss: 0.0001619\n",
      "Test set: Average loss: 2.4594, Accuracy: 3143/5000 (63%)\n",
      "[epoch 43] loss: 0.0001209\n",
      "Test set: Average loss: 2.5153, Accuracy: 3142/5000 (63%)\n",
      "[epoch 44] loss: 0.0000899\n",
      "Test set: Average loss: 2.5728, Accuracy: 3134/5000 (63%)\n",
      "[epoch 45] loss: 0.0000669\n",
      "Test set: Average loss: 2.6227, Accuracy: 3147/5000 (63%)\n",
      "[epoch 46] loss: 0.0000496\n",
      "Test set: Average loss: 2.6834, Accuracy: 3146/5000 (63%)\n",
      "[epoch 47] loss: 0.0000369\n",
      "Test set: Average loss: 2.7382, Accuracy: 3143/5000 (63%)\n",
      "[epoch 48] loss: 0.0000272\n",
      "Test set: Average loss: 2.7871, Accuracy: 3134/5000 (63%)\n",
      "[epoch 49] loss: 0.0000201\n",
      "Test set: Average loss: 2.8491, Accuracy: 3153/5000 (63%)\n",
      "[epoch 50] loss: 0.0000148\n",
      "Test set: Average loss: 2.8941, Accuracy: 3151/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8491, Accuracy: 3153/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.8160, Accuracy: 6333/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 532/5000 (11%)\n",
      "[epoch 1] loss: 1.6775333\n",
      "Test set: Average loss: 1.5474, Accuracy: 2178/5000 (44%)\n",
      "[epoch 2] loss: 1.4561460\n",
      "Test set: Average loss: 1.4435, Accuracy: 2389/5000 (48%)\n",
      "[epoch 3] loss: 1.3648491\n",
      "Test set: Average loss: 1.4275, Accuracy: 2434/5000 (49%)\n",
      "[epoch 4] loss: 1.2968408\n",
      "Test set: Average loss: 1.3528, Accuracy: 2594/5000 (52%)\n",
      "[epoch 5] loss: 1.2424188\n",
      "Test set: Average loss: 1.3163, Accuracy: 2675/5000 (54%)\n",
      "[epoch 6] loss: 1.1990232\n",
      "Test set: Average loss: 1.3251, Accuracy: 2640/5000 (53%)\n",
      "[epoch 7] loss: 1.1634267\n",
      "Test set: Average loss: 1.3078, Accuracy: 2699/5000 (54%)\n",
      "[epoch 8] loss: 1.1132232\n",
      "Test set: Average loss: 1.2640, Accuracy: 2761/5000 (55%)\n",
      "[epoch 9] loss: 1.0629263\n",
      "Test set: Average loss: 1.2611, Accuracy: 2799/5000 (56%)\n",
      "[epoch 10] loss: 1.0089332\n",
      "Test set: Average loss: 1.2200, Accuracy: 2869/5000 (57%)\n",
      "[epoch 11] loss: 0.9620794\n",
      "Test set: Average loss: 1.2084, Accuracy: 2897/5000 (58%)\n",
      "[epoch 12] loss: 0.9128803\n",
      "Test set: Average loss: 1.3124, Accuracy: 2797/5000 (56%)\n",
      "[epoch 13] loss: 0.8463721\n",
      "Test set: Average loss: 1.2338, Accuracy: 2890/5000 (58%)\n",
      "[epoch 14] loss: 0.7900869\n",
      "Test set: Average loss: 1.2354, Accuracy: 2945/5000 (59%)\n",
      "[epoch 15] loss: 0.7120506\n",
      "Test set: Average loss: 1.2658, Accuracy: 2927/5000 (59%)\n",
      "[epoch 16] loss: 0.6413281\n",
      "Test set: Average loss: 1.3072, Accuracy: 2901/5000 (58%)\n",
      "[epoch 17] loss: 0.5599477\n",
      "Test set: Average loss: 1.3750, Accuracy: 2899/5000 (58%)\n",
      "[epoch 18] loss: 0.4704730\n",
      "Test set: Average loss: 1.4056, Accuracy: 2926/5000 (59%)\n",
      "[epoch 19] loss: 0.3739407\n",
      "Test set: Average loss: 1.4672, Accuracy: 2946/5000 (59%)\n",
      "[epoch 20] loss: 0.2777444\n",
      "Test set: Average loss: 1.5316, Accuracy: 2933/5000 (59%)\n",
      "[epoch 21] loss: 0.2006022\n",
      "Test set: Average loss: 1.6739, Accuracy: 2935/5000 (59%)\n",
      "[epoch 22] loss: 0.1508238\n",
      "Test set: Average loss: 1.8413, Accuracy: 2816/5000 (56%)\n",
      "[epoch 23] loss: 0.1267824\n",
      "Test set: Average loss: 1.8146, Accuracy: 2899/5000 (58%)\n",
      "[epoch 24] loss: 0.1225421\n",
      "Test set: Average loss: 2.0299, Accuracy: 2808/5000 (56%)\n",
      "[epoch 25] loss: 0.1172447\n",
      "Test set: Average loss: 2.0578, Accuracy: 2787/5000 (56%)\n",
      "[epoch 26] loss: 0.1327898\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0878, Accuracy: 2861/5000 (57%)\n",
      "[epoch 27] loss: 0.0423145\n",
      "Test set: Average loss: 1.9757, Accuracy: 2951/5000 (59%)\n",
      "[epoch 28] loss: 0.0156901\n",
      "Test set: Average loss: 1.9912, Accuracy: 2983/5000 (60%)\n",
      "[epoch 29] loss: 0.0108648\n",
      "Test set: Average loss: 2.0056, Accuracy: 2994/5000 (60%)\n",
      "[epoch 30] loss: 0.0083785\n",
      "Test set: Average loss: 2.0219, Accuracy: 2990/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0066733\n",
      "Test set: Average loss: 2.0381, Accuracy: 2993/5000 (60%)\n",
      "[epoch 32] loss: 0.0053811\n",
      "Test set: Average loss: 2.0615, Accuracy: 3008/5000 (60%)\n",
      "[epoch 33] loss: 0.0043879\n",
      "Test set: Average loss: 2.0808, Accuracy: 2999/5000 (60%)\n",
      "[epoch 34] loss: 0.0035732\n",
      "Test set: Average loss: 2.1071, Accuracy: 2997/5000 (60%)\n",
      "[epoch 35] loss: 0.0029072\n",
      "Test set: Average loss: 2.1342, Accuracy: 3011/5000 (60%)\n",
      "[epoch 36] loss: 0.0023529\n",
      "Test set: Average loss: 2.1646, Accuracy: 2998/5000 (60%)\n",
      "[epoch 37] loss: 0.0018831\n",
      "Test set: Average loss: 2.1885, Accuracy: 3007/5000 (60%)\n",
      "[epoch 38] loss: 0.0015094\n",
      "Test set: Average loss: 2.2223, Accuracy: 3009/5000 (60%)\n",
      "[epoch 39] loss: 0.0011936\n",
      "Test set: Average loss: 2.2559, Accuracy: 3013/5000 (60%)\n",
      "[epoch 40] loss: 0.0009422\n",
      "Test set: Average loss: 2.2965, Accuracy: 3018/5000 (60%)\n",
      "[epoch 41] loss: 0.0007381\n",
      "Test set: Average loss: 2.3320, Accuracy: 3007/5000 (60%)\n",
      "[epoch 42] loss: 0.0005762\n",
      "Test set: Average loss: 2.3676, Accuracy: 3020/5000 (60%)\n",
      "[epoch 43] loss: 0.0004471\n",
      "Test set: Average loss: 2.4098, Accuracy: 3022/5000 (60%)\n",
      "[epoch 44] loss: 0.0003444\n",
      "Test set: Average loss: 2.4528, Accuracy: 3019/5000 (60%)\n",
      "[epoch 45] loss: 0.0002645\n",
      "Test set: Average loss: 2.4992, Accuracy: 3020/5000 (60%)\n",
      "[epoch 46] loss: 0.0002026\n",
      "Test set: Average loss: 2.5452, Accuracy: 3022/5000 (60%)\n",
      "[epoch 47] loss: 0.0001548\n",
      "Test set: Average loss: 2.5936, Accuracy: 3025/5000 (60%)\n",
      "[epoch 48] loss: 0.0001175\n",
      "Test set: Average loss: 2.6382, Accuracy: 3024/5000 (60%)\n",
      "[epoch 49] loss: 0.0000891\n",
      "Test set: Average loss: 2.6880, Accuracy: 3025/5000 (60%)\n",
      "[epoch 50] loss: 0.0000675\n",
      "Test set: Average loss: 2.7343, Accuracy: 3028/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7343, Accuracy: 3028/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.6475, Accuracy: 6075/10000 (61%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 388/5000 (8%)\n",
      "[epoch 1] loss: 1.6180775\n",
      "Test set: Average loss: 1.4341, Accuracy: 2417/5000 (48%)\n",
      "[epoch 2] loss: 1.3633888\n",
      "Test set: Average loss: 1.4061, Accuracy: 2499/5000 (50%)\n",
      "[epoch 3] loss: 1.2534352\n",
      "Test set: Average loss: 1.3574, Accuracy: 2676/5000 (54%)\n",
      "[epoch 4] loss: 1.1919929\n",
      "Test set: Average loss: 1.2610, Accuracy: 2762/5000 (55%)\n",
      "[epoch 5] loss: 1.1308652\n",
      "Test set: Average loss: 1.2941, Accuracy: 2715/5000 (54%)\n",
      "[epoch 6] loss: 1.0878152\n",
      "Test set: Average loss: 1.2499, Accuracy: 2819/5000 (56%)\n",
      "[epoch 7] loss: 1.0405417\n",
      "Test set: Average loss: 1.2256, Accuracy: 2871/5000 (57%)\n",
      "[epoch 8] loss: 0.9989415\n",
      "Test set: Average loss: 1.2113, Accuracy: 2864/5000 (57%)\n",
      "[epoch 9] loss: 0.9540861\n",
      "Test set: Average loss: 1.2011, Accuracy: 2908/5000 (58%)\n",
      "[epoch 10] loss: 0.9023724\n",
      "Test set: Average loss: 1.2246, Accuracy: 2949/5000 (59%)\n",
      "[epoch 11] loss: 0.8554544\n",
      "Test set: Average loss: 1.1683, Accuracy: 3012/5000 (60%)\n",
      "[epoch 12] loss: 0.7846217\n",
      "Test set: Average loss: 1.2517, Accuracy: 2947/5000 (59%)\n",
      "[epoch 13] loss: 0.7425435\n",
      "Test set: Average loss: 1.2909, Accuracy: 2931/5000 (59%)\n",
      "[epoch 14] loss: 0.6470572\n",
      "Test set: Average loss: 1.3137, Accuracy: 2934/5000 (59%)\n",
      "[epoch 15] loss: 0.5537230\n",
      "Test set: Average loss: 1.3556, Accuracy: 2954/5000 (59%)\n",
      "[epoch 16] loss: 0.4629960\n",
      "Test set: Average loss: 1.4056, Accuracy: 2933/5000 (59%)\n",
      "[epoch 17] loss: 0.3669541\n",
      "Test set: Average loss: 1.4254, Accuracy: 2970/5000 (59%)\n",
      "[epoch 18] loss: 0.2624421\n",
      "Test set: Average loss: 1.5597, Accuracy: 2960/5000 (59%)\n",
      "[epoch 19] loss: 0.1854023\n",
      "Test set: Average loss: 1.6476, Accuracy: 2961/5000 (59%)\n",
      "[epoch 20] loss: 0.1194916\n",
      "Test set: Average loss: 1.7414, Accuracy: 2940/5000 (59%)\n",
      "[epoch 21] loss: 0.0730144\n",
      "Test set: Average loss: 1.8910, Accuracy: 2989/5000 (60%)\n",
      "[epoch 22] loss: 0.1241725\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9996, Accuracy: 2923/5000 (58%)\n",
      "[epoch 23] loss: 0.0610699\n",
      "Test set: Average loss: 1.8671, Accuracy: 3022/5000 (60%)\n",
      "[epoch 24] loss: 0.0206281\n",
      "Test set: Average loss: 1.8812, Accuracy: 3040/5000 (61%)\n",
      "[epoch 25] loss: 0.0139985\n",
      "Test set: Average loss: 1.8959, Accuracy: 3046/5000 (61%)\n",
      "[epoch 26] loss: 0.0105950\n",
      "Test set: Average loss: 1.9123, Accuracy: 3054/5000 (61%)\n",
      "[epoch 27] loss: 0.0082655\n",
      "Test set: Average loss: 1.9348, Accuracy: 3051/5000 (61%)\n",
      "[epoch 28] loss: 0.0065537\n",
      "Test set: Average loss: 1.9599, Accuracy: 3069/5000 (61%)\n",
      "[epoch 29] loss: 0.0052153\n",
      "Test set: Average loss: 1.9832, Accuracy: 3068/5000 (61%)\n",
      "[epoch 30] loss: 0.0041575\n",
      "Test set: Average loss: 2.0168, Accuracy: 3074/5000 (61%)\n",
      "[epoch 31] loss: 0.0033068\n",
      "Test set: Average loss: 2.0460, Accuracy: 3076/5000 (62%)\n",
      "[epoch 32] loss: 0.0026181\n",
      "Test set: Average loss: 2.0811, Accuracy: 3065/5000 (61%)\n",
      "[epoch 33] loss: 0.0020603\n",
      "Test set: Average loss: 2.1196, Accuracy: 3077/5000 (62%)\n",
      "[epoch 34] loss: 0.0016126\n",
      "Test set: Average loss: 2.1605, Accuracy: 3071/5000 (61%)\n",
      "[epoch 35] loss: 0.0012577\n",
      "Test set: Average loss: 2.1995, Accuracy: 3077/5000 (62%)\n",
      "[epoch 36] loss: 0.0009692\n",
      "Test set: Average loss: 2.2491, Accuracy: 3087/5000 (62%)\n",
      "[epoch 37] loss: 0.0007469\n",
      "Test set: Average loss: 2.2848, Accuracy: 3070/5000 (61%)\n",
      "[epoch 38] loss: 0.0005704\n",
      "Test set: Average loss: 2.3405, Accuracy: 3080/5000 (62%)\n",
      "[epoch 39] loss: 0.0004355\n",
      "Test set: Average loss: 2.3870, Accuracy: 3075/5000 (62%)\n",
      "[epoch 40] loss: 0.0003306\n",
      "Test set: Average loss: 2.4368, Accuracy: 3080/5000 (62%)\n",
      "[epoch 41] loss: 0.0002500\n",
      "Test set: Average loss: 2.4823, Accuracy: 3093/5000 (62%)\n",
      "[epoch 42] loss: 0.0001871\n",
      "Test set: Average loss: 2.5350, Accuracy: 3081/5000 (62%)\n",
      "[epoch 43] loss: 0.0001407\n",
      "Test set: Average loss: 2.5918, Accuracy: 3084/5000 (62%)\n",
      "[epoch 44] loss: 0.0001051\n",
      "Test set: Average loss: 2.6448, Accuracy: 3079/5000 (62%)\n",
      "[epoch 45] loss: 0.0000784\n",
      "Test set: Average loss: 2.7030, Accuracy: 3086/5000 (62%)\n",
      "[epoch 46] loss: 0.0000583\n",
      "Test set: Average loss: 2.7581, Accuracy: 3089/5000 (62%)\n",
      "[epoch 47] loss: 0.0000432\n",
      "Test set: Average loss: 2.8061, Accuracy: 3087/5000 (62%)\n",
      "[epoch 48] loss: 0.0000321\n",
      "Test set: Average loss: 2.8666, Accuracy: 3082/5000 (62%)\n",
      "[epoch 49] loss: 0.0000238\n",
      "Test set: Average loss: 2.9180, Accuracy: 3079/5000 (62%)\n",
      "[epoch 50] loss: 0.0000176\n",
      "Test set: Average loss: 2.9844, Accuracy: 3091/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4823, Accuracy: 3093/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.4072, Accuracy: 6233/10000 (62%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 561/5000 (11%)\n",
      "[epoch 1] loss: 1.5981426\n",
      "Test set: Average loss: 1.4507, Accuracy: 2391/5000 (48%)\n",
      "[epoch 2] loss: 1.3469297\n",
      "Test set: Average loss: 1.3196, Accuracy: 2684/5000 (54%)\n",
      "[epoch 3] loss: 1.2511421\n",
      "Test set: Average loss: 1.2525, Accuracy: 2754/5000 (55%)\n",
      "[epoch 4] loss: 1.1857234\n",
      "Test set: Average loss: 1.2295, Accuracy: 2820/5000 (56%)\n",
      "[epoch 5] loss: 1.1378133\n",
      "Test set: Average loss: 1.2309, Accuracy: 2795/5000 (56%)\n",
      "[epoch 6] loss: 1.0780915\n",
      "Test set: Average loss: 1.2228, Accuracy: 2881/5000 (58%)\n",
      "[epoch 7] loss: 1.0275662\n",
      "Test set: Average loss: 1.2057, Accuracy: 2848/5000 (57%)\n",
      "[epoch 8] loss: 0.9843473\n",
      "Test set: Average loss: 1.1747, Accuracy: 2950/5000 (59%)\n",
      "[epoch 9] loss: 0.9437989\n",
      "Test set: Average loss: 1.1871, Accuracy: 2899/5000 (58%)\n",
      "[epoch 10] loss: 0.8884715\n",
      "Test set: Average loss: 1.1552, Accuracy: 3051/5000 (61%)\n",
      "[epoch 11] loss: 0.8244285\n",
      "Test set: Average loss: 1.1848, Accuracy: 3007/5000 (60%)\n",
      "[epoch 12] loss: 0.7612056\n",
      "Test set: Average loss: 1.1369, Accuracy: 3066/5000 (61%)\n",
      "[epoch 13] loss: 0.6916881\n",
      "Test set: Average loss: 1.1858, Accuracy: 3070/5000 (61%)\n",
      "[epoch 14] loss: 0.6084374\n",
      "Test set: Average loss: 1.2290, Accuracy: 3036/5000 (61%)\n",
      "[epoch 15] loss: 0.5240137\n",
      "Test set: Average loss: 1.2472, Accuracy: 3079/5000 (62%)\n",
      "[epoch 16] loss: 0.4234052\n",
      "Test set: Average loss: 1.3518, Accuracy: 3066/5000 (61%)\n",
      "[epoch 17] loss: 0.3251140\n",
      "Test set: Average loss: 1.4103, Accuracy: 3054/5000 (61%)\n",
      "[epoch 18] loss: 0.2423891\n",
      "Test set: Average loss: 1.5007, Accuracy: 3051/5000 (61%)\n",
      "[epoch 19] loss: 0.1878955\n",
      "Test set: Average loss: 1.6318, Accuracy: 3028/5000 (61%)\n",
      "[epoch 20] loss: 0.1451485\n",
      "Test set: Average loss: 1.7047, Accuracy: 3055/5000 (61%)\n",
      "[epoch 21] loss: 0.1549980\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.7992, Accuracy: 3016/5000 (60%)\n",
      "[epoch 22] loss: 0.0577431\n",
      "Test set: Average loss: 1.7117, Accuracy: 3084/5000 (62%)\n",
      "[epoch 23] loss: 0.0230327\n",
      "Test set: Average loss: 1.7232, Accuracy: 3104/5000 (62%)\n",
      "[epoch 24] loss: 0.0156290\n",
      "Test set: Average loss: 1.7376, Accuracy: 3119/5000 (62%)\n",
      "[epoch 25] loss: 0.0115759\n",
      "Test set: Average loss: 1.7550, Accuracy: 3134/5000 (63%)\n",
      "[epoch 26] loss: 0.0088360\n",
      "Test set: Average loss: 1.7794, Accuracy: 3135/5000 (63%)\n",
      "[epoch 27] loss: 0.0068081\n",
      "Test set: Average loss: 1.8065, Accuracy: 3140/5000 (63%)\n",
      "[epoch 28] loss: 0.0051989\n",
      "Test set: Average loss: 1.8393, Accuracy: 3142/5000 (63%)\n",
      "[epoch 29] loss: 0.0039907\n",
      "Test set: Average loss: 1.8675, Accuracy: 3153/5000 (63%)\n",
      "[epoch 30] loss: 0.0030309\n",
      "Test set: Average loss: 1.9054, Accuracy: 3151/5000 (63%)\n",
      "[epoch 31] loss: 0.0022865\n",
      "Test set: Average loss: 1.9427, Accuracy: 3163/5000 (63%)\n",
      "[epoch 32] loss: 0.0017015\n",
      "Test set: Average loss: 1.9934, Accuracy: 3160/5000 (63%)\n",
      "[epoch 33] loss: 0.0012536\n",
      "Test set: Average loss: 2.0355, Accuracy: 3176/5000 (64%)\n",
      "[epoch 34] loss: 0.0009337\n",
      "Test set: Average loss: 2.0833, Accuracy: 3179/5000 (64%)\n",
      "[epoch 35] loss: 0.0006764\n",
      "Test set: Average loss: 2.1346, Accuracy: 3182/5000 (64%)\n",
      "[epoch 36] loss: 0.0004889\n",
      "Test set: Average loss: 2.1784, Accuracy: 3184/5000 (64%)\n",
      "[epoch 37] loss: 0.0003542\n",
      "Test set: Average loss: 2.2390, Accuracy: 3178/5000 (64%)\n",
      "[epoch 38] loss: 0.0002549\n",
      "Test set: Average loss: 2.2904, Accuracy: 3180/5000 (64%)\n",
      "[epoch 39] loss: 0.0001820\n",
      "Test set: Average loss: 2.3493, Accuracy: 3182/5000 (64%)\n",
      "[epoch 40] loss: 0.0001300\n",
      "Test set: Average loss: 2.4018, Accuracy: 3172/5000 (63%)\n",
      "[epoch 41] loss: 0.0000924\n",
      "Test set: Average loss: 2.4619, Accuracy: 3178/5000 (64%)\n",
      "[epoch 42] loss: 0.0000655\n",
      "Test set: Average loss: 2.5269, Accuracy: 3177/5000 (64%)\n",
      "[epoch 43] loss: 0.0000463\n",
      "Test set: Average loss: 2.5856, Accuracy: 3182/5000 (64%)\n",
      "[epoch 44] loss: 0.0000324\n",
      "Test set: Average loss: 2.6489, Accuracy: 3180/5000 (64%)\n",
      "[epoch 45] loss: 0.0000229\n",
      "Test set: Average loss: 2.7039, Accuracy: 3166/5000 (63%)\n",
      "[epoch 46] loss: 0.0000160\n",
      "Test set: Average loss: 2.7625, Accuracy: 3176/5000 (64%)\n",
      "[epoch 47] loss: 0.0000112\n",
      "Test set: Average loss: 2.8286, Accuracy: 3176/5000 (64%)\n",
      "[epoch 48] loss: 0.0000078\n",
      "Test set: Average loss: 2.8888, Accuracy: 3174/5000 (63%)\n",
      "[epoch 49] loss: 0.0000054\n",
      "Test set: Average loss: 2.9422, Accuracy: 3174/5000 (63%)\n",
      "[epoch 50] loss: 0.0000038\n",
      "Test set: Average loss: 3.0087, Accuracy: 3185/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0087, Accuracy: 3185/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 3.0418, Accuracy: 6426/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3023, Accuracy: 498/5000 (10%)\n",
      "[epoch 1] loss: 1.5575079\n",
      "Test set: Average loss: 1.3629, Accuracy: 2517/5000 (50%)\n",
      "[epoch 2] loss: 1.3012273\n",
      "Test set: Average loss: 1.3468, Accuracy: 2581/5000 (52%)\n",
      "[epoch 3] loss: 1.2203561\n",
      "Test set: Average loss: 1.2478, Accuracy: 2778/5000 (56%)\n",
      "[epoch 4] loss: 1.1473680\n",
      "Test set: Average loss: 1.2019, Accuracy: 2844/5000 (57%)\n",
      "[epoch 5] loss: 1.0936755\n",
      "Test set: Average loss: 1.2161, Accuracy: 2899/5000 (58%)\n",
      "[epoch 6] loss: 1.0467619\n",
      "Test set: Average loss: 1.2237, Accuracy: 2858/5000 (57%)\n",
      "[epoch 7] loss: 0.9970530\n",
      "Test set: Average loss: 1.1714, Accuracy: 2927/5000 (59%)\n",
      "[epoch 8] loss: 0.9496354\n",
      "Test set: Average loss: 1.1417, Accuracy: 2991/5000 (60%)\n",
      "[epoch 9] loss: 0.8990670\n",
      "Test set: Average loss: 1.1602, Accuracy: 2991/5000 (60%)\n",
      "[epoch 10] loss: 0.8357712\n",
      "Test set: Average loss: 1.1231, Accuracy: 3091/5000 (62%)\n",
      "[epoch 11] loss: 0.7690117\n",
      "Test set: Average loss: 1.2117, Accuracy: 2997/5000 (60%)\n",
      "[epoch 12] loss: 0.6882717\n",
      "Test set: Average loss: 1.2279, Accuracy: 2963/5000 (59%)\n",
      "[epoch 13] loss: 0.5994572\n",
      "Test set: Average loss: 1.2407, Accuracy: 3089/5000 (62%)\n",
      "[epoch 14] loss: 0.4911487\n",
      "Test set: Average loss: 1.2819, Accuracy: 3067/5000 (61%)\n",
      "[epoch 15] loss: 0.3968997\n",
      "Test set: Average loss: 1.3334, Accuracy: 3068/5000 (61%)\n",
      "[epoch 16] loss: 0.2918761\n",
      "Test set: Average loss: 1.4518, Accuracy: 3035/5000 (61%)\n",
      "[epoch 17] loss: 0.2110743\n",
      "Test set: Average loss: 1.5805, Accuracy: 3046/5000 (61%)\n",
      "[epoch 18] loss: 0.1609088\n",
      "Test set: Average loss: 1.7276, Accuracy: 2970/5000 (59%)\n",
      "[epoch 19] loss: 0.1241243\n",
      "Test set: Average loss: 1.8300, Accuracy: 3001/5000 (60%)\n",
      "[epoch 20] loss: 0.1395865\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9459, Accuracy: 2995/5000 (60%)\n",
      "[epoch 21] loss: 0.0482134\n",
      "Test set: Average loss: 1.7881, Accuracy: 3078/5000 (62%)\n",
      "[epoch 22] loss: 0.0186010\n",
      "Test set: Average loss: 1.8023, Accuracy: 3107/5000 (62%)\n",
      "[epoch 23] loss: 0.0125970\n",
      "Test set: Average loss: 1.8227, Accuracy: 3107/5000 (62%)\n",
      "[epoch 24] loss: 0.0093215\n",
      "Test set: Average loss: 1.8428, Accuracy: 3117/5000 (62%)\n",
      "[epoch 25] loss: 0.0070797\n",
      "Test set: Average loss: 1.8672, Accuracy: 3111/5000 (62%)\n",
      "[epoch 26] loss: 0.0054175\n",
      "Test set: Average loss: 1.8900, Accuracy: 3111/5000 (62%)\n",
      "[epoch 27] loss: 0.0041289\n",
      "Test set: Average loss: 1.9506, Accuracy: 3102/5000 (62%)\n",
      "[epoch 28] loss: 0.0031322\n",
      "Test set: Average loss: 1.9620, Accuracy: 3124/5000 (62%)\n",
      "[epoch 29] loss: 0.0023550\n",
      "Test set: Average loss: 2.0047, Accuracy: 3114/5000 (62%)\n",
      "[epoch 30] loss: 0.0017623\n",
      "Test set: Average loss: 2.0423, Accuracy: 3124/5000 (62%)\n",
      "[epoch 31] loss: 0.0012901\n",
      "Test set: Average loss: 2.0907, Accuracy: 3123/5000 (62%)\n",
      "[epoch 32] loss: 0.0009481\n",
      "Test set: Average loss: 2.1385, Accuracy: 3127/5000 (63%)\n",
      "[epoch 33] loss: 0.0006868\n",
      "Test set: Average loss: 2.1853, Accuracy: 3136/5000 (63%)\n",
      "[epoch 34] loss: 0.0004989\n",
      "Test set: Average loss: 2.2542, Accuracy: 3117/5000 (62%)\n",
      "[epoch 35] loss: 0.0004848\n",
      "Test set: Average loss: 2.2966, Accuracy: 3134/5000 (63%)\n",
      "[epoch 36] loss: 0.0002711\n",
      "Test set: Average loss: 2.3475, Accuracy: 3148/5000 (63%)\n",
      "[epoch 37] loss: 0.0001978\n",
      "Test set: Average loss: 2.3894, Accuracy: 3139/5000 (63%)\n",
      "[epoch 38] loss: 0.0001457\n",
      "Test set: Average loss: 2.4403, Accuracy: 3147/5000 (63%)\n",
      "[epoch 39] loss: 0.0001068\n",
      "Test set: Average loss: 2.5029, Accuracy: 3143/5000 (63%)\n",
      "[epoch 40] loss: 0.0000772\n",
      "Test set: Average loss: 2.5586, Accuracy: 3139/5000 (63%)\n",
      "[epoch 41] loss: 0.0000553\n",
      "Test set: Average loss: 2.6211, Accuracy: 3135/5000 (63%)\n",
      "[epoch 42] loss: 0.0000394\n",
      "Test set: Average loss: 2.6743, Accuracy: 3145/5000 (63%)\n",
      "[epoch 43] loss: 0.0000278\n",
      "Test set: Average loss: 2.7394, Accuracy: 3143/5000 (63%)\n",
      "[epoch 44] loss: 0.0000195\n",
      "Test set: Average loss: 2.8027, Accuracy: 3151/5000 (63%)\n",
      "[epoch 45] loss: 0.0000137\n",
      "Test set: Average loss: 2.8636, Accuracy: 3138/5000 (63%)\n",
      "[epoch 46] loss: 0.0000095\n",
      "Test set: Average loss: 2.9255, Accuracy: 3132/5000 (63%)\n",
      "[epoch 47] loss: 0.0000066\n",
      "Test set: Average loss: 2.9964, Accuracy: 3147/5000 (63%)\n",
      "[epoch 48] loss: 0.0000046\n",
      "Test set: Average loss: 3.0574, Accuracy: 3133/5000 (63%)\n",
      "[epoch 49] loss: 0.0000032\n",
      "Test set: Average loss: 3.1147, Accuracy: 3131/5000 (63%)\n",
      "[epoch 50] loss: 0.0000022\n",
      "Test set: Average loss: 3.1802, Accuracy: 3127/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8027, Accuracy: 3151/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.7287, Accuracy: 6369/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 498/5000 (10%)\n",
      "[epoch 1] loss: 1.5962482\n",
      "Test set: Average loss: 1.4149, Accuracy: 2475/5000 (50%)\n",
      "[epoch 2] loss: 1.3309280\n",
      "Test set: Average loss: 1.3014, Accuracy: 2683/5000 (54%)\n",
      "[epoch 3] loss: 1.2279952\n",
      "Test set: Average loss: 1.2625, Accuracy: 2808/5000 (56%)\n",
      "[epoch 4] loss: 1.1574277\n",
      "Test set: Average loss: 1.2795, Accuracy: 2751/5000 (55%)\n",
      "[epoch 5] loss: 1.1017191\n",
      "Test set: Average loss: 1.1954, Accuracy: 2858/5000 (57%)\n",
      "[epoch 6] loss: 1.0371747\n",
      "Test set: Average loss: 1.1548, Accuracy: 2999/5000 (60%)\n",
      "[epoch 7] loss: 0.9986989\n",
      "Test set: Average loss: 1.1623, Accuracy: 2971/5000 (59%)\n",
      "[epoch 8] loss: 0.9408807\n",
      "Test set: Average loss: 1.1458, Accuracy: 3019/5000 (60%)\n",
      "[epoch 9] loss: 0.8792676\n",
      "Test set: Average loss: 1.1112, Accuracy: 3070/5000 (61%)\n",
      "[epoch 10] loss: 0.8250957\n",
      "Test set: Average loss: 1.1250, Accuracy: 3097/5000 (62%)\n",
      "[epoch 11] loss: 0.7506666\n",
      "Test set: Average loss: 1.1443, Accuracy: 3075/5000 (62%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] loss: 0.6740442\n",
      "Test set: Average loss: 1.1994, Accuracy: 3082/5000 (62%)\n",
      "[epoch 13] loss: 0.5783347\n",
      "Test set: Average loss: 1.2064, Accuracy: 3130/5000 (63%)\n",
      "[epoch 14] loss: 0.4860236\n",
      "Test set: Average loss: 1.2998, Accuracy: 3061/5000 (61%)\n",
      "[epoch 15] loss: 0.3792097\n",
      "Test set: Average loss: 1.3612, Accuracy: 3099/5000 (62%)\n",
      "[epoch 16] loss: 0.2833918\n",
      "Test set: Average loss: 1.4394, Accuracy: 3131/5000 (63%)\n",
      "[epoch 17] loss: 0.2166678\n",
      "Test set: Average loss: 1.6092, Accuracy: 3007/5000 (60%)\n",
      "[epoch 18] loss: 0.1513794\n",
      "Test set: Average loss: 1.6517, Accuracy: 3060/5000 (61%)\n",
      "[epoch 19] loss: 0.1519116\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7155, Accuracy: 3089/5000 (62%)\n",
      "[epoch 20] loss: 0.0472277\n",
      "Test set: Average loss: 1.6477, Accuracy: 3181/5000 (64%)\n",
      "[epoch 21] loss: 0.0203819\n",
      "Test set: Average loss: 1.6589, Accuracy: 3183/5000 (64%)\n",
      "[epoch 22] loss: 0.0142244\n",
      "Test set: Average loss: 1.6788, Accuracy: 3192/5000 (64%)\n",
      "[epoch 23] loss: 0.0106732\n",
      "Test set: Average loss: 1.7009, Accuracy: 3175/5000 (64%)\n",
      "[epoch 24] loss: 0.0081453\n",
      "Test set: Average loss: 1.7296, Accuracy: 3184/5000 (64%)\n",
      "[epoch 25] loss: 0.0062475\n",
      "Test set: Average loss: 1.7616, Accuracy: 3190/5000 (64%)\n",
      "[epoch 26] loss: 0.0047711\n",
      "Test set: Average loss: 1.7966, Accuracy: 3202/5000 (64%)\n",
      "[epoch 27] loss: 0.0036149\n",
      "Test set: Average loss: 1.8357, Accuracy: 3195/5000 (64%)\n",
      "[epoch 28] loss: 0.0027114\n",
      "Test set: Average loss: 1.8782, Accuracy: 3192/5000 (64%)\n",
      "[epoch 29] loss: 0.0020042\n",
      "Test set: Average loss: 1.9224, Accuracy: 3190/5000 (64%)\n",
      "[epoch 30] loss: 0.0014785\n",
      "Test set: Average loss: 1.9657, Accuracy: 3201/5000 (64%)\n",
      "[epoch 31] loss: 0.0010755\n",
      "Test set: Average loss: 2.0167, Accuracy: 3208/5000 (64%)\n",
      "[epoch 32] loss: 0.0007773\n",
      "Test set: Average loss: 2.0675, Accuracy: 3204/5000 (64%)\n",
      "[epoch 33] loss: 0.0005592\n",
      "Test set: Average loss: 2.1224, Accuracy: 3205/5000 (64%)\n",
      "[epoch 34] loss: 0.0003978\n",
      "Test set: Average loss: 2.1798, Accuracy: 3192/5000 (64%)\n",
      "[epoch 35] loss: 0.0002841\n",
      "Test set: Average loss: 2.2354, Accuracy: 3210/5000 (64%)\n",
      "[epoch 36] loss: 0.0002009\n",
      "Test set: Average loss: 2.2933, Accuracy: 3205/5000 (64%)\n",
      "[epoch 37] loss: 0.0001410\n",
      "Test set: Average loss: 2.3542, Accuracy: 3227/5000 (65%)\n",
      "[epoch 38] loss: 0.0000993\n",
      "Test set: Average loss: 2.4151, Accuracy: 3226/5000 (65%)\n",
      "[epoch 39] loss: 0.0000697\n",
      "Test set: Average loss: 2.4793, Accuracy: 3213/5000 (64%)\n",
      "[epoch 40] loss: 0.0000485\n",
      "Test set: Average loss: 2.5417, Accuracy: 3216/5000 (64%)\n",
      "[epoch 41] loss: 0.0000337\n",
      "Test set: Average loss: 2.6374, Accuracy: 3203/5000 (64%)\n",
      "[epoch 42] loss: 0.0000234\n",
      "Test set: Average loss: 2.6695, Accuracy: 3213/5000 (64%)\n",
      "[epoch 43] loss: 0.0000163\n",
      "Test set: Average loss: 2.7329, Accuracy: 3205/5000 (64%)\n",
      "[epoch 44] loss: 0.0000112\n",
      "Test set: Average loss: 2.7932, Accuracy: 3200/5000 (64%)\n",
      "[epoch 45] loss: 0.0000078\n",
      "Test set: Average loss: 2.8614, Accuracy: 3207/5000 (64%)\n",
      "[epoch 46] loss: 0.0381545\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9259, Accuracy: 3189/5000 (64%)\n",
      "[epoch 47] loss: 0.0000127\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.9312, Accuracy: 3175/5000 (64%)\n",
      "[epoch 48] loss: 0.0000098\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.9302, Accuracy: 3175/5000 (64%)\n",
      "[epoch 49] loss: 0.0000096\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.9301, Accuracy: 3175/5000 (64%)\n",
      "[epoch 50] loss: 0.0000097\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.9301, Accuracy: 3175/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3542, Accuracy: 3227/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.3751, Accuracy: 6493/10000 (65%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3022, Accuracy: 436/5000 (9%)\n",
      "[epoch 1] loss: 1.5777321\n",
      "Test set: Average loss: 1.4297, Accuracy: 2418/5000 (48%)\n",
      "[epoch 2] loss: 1.3258615\n",
      "Test set: Average loss: 1.2875, Accuracy: 2679/5000 (54%)\n",
      "[epoch 3] loss: 1.2433839\n",
      "Test set: Average loss: 1.2801, Accuracy: 2730/5000 (55%)\n",
      "[epoch 4] loss: 1.1811671\n",
      "Test set: Average loss: 1.2501, Accuracy: 2784/5000 (56%)\n",
      "[epoch 5] loss: 1.1401593\n",
      "Test set: Average loss: 1.2351, Accuracy: 2841/5000 (57%)\n",
      "[epoch 6] loss: 1.0882313\n",
      "Test set: Average loss: 1.2070, Accuracy: 2916/5000 (58%)\n",
      "[epoch 7] loss: 1.0384829\n",
      "Test set: Average loss: 1.1990, Accuracy: 2900/5000 (58%)\n",
      "[epoch 8] loss: 0.9949448\n",
      "Test set: Average loss: 1.1687, Accuracy: 2972/5000 (59%)\n",
      "[epoch 9] loss: 0.9392377\n",
      "Test set: Average loss: 1.1538, Accuracy: 3011/5000 (60%)\n",
      "[epoch 10] loss: 0.8921366\n",
      "Test set: Average loss: 1.2166, Accuracy: 2939/5000 (59%)\n",
      "[epoch 11] loss: 0.8307786\n",
      "Test set: Average loss: 1.1575, Accuracy: 3036/5000 (61%)\n",
      "[epoch 12] loss: 0.7654723\n",
      "Test set: Average loss: 1.1704, Accuracy: 3096/5000 (62%)\n",
      "[epoch 13] loss: 0.6957141\n",
      "Test set: Average loss: 1.1897, Accuracy: 3135/5000 (63%)\n",
      "[epoch 14] loss: 0.6132168\n",
      "Test set: Average loss: 1.2182, Accuracy: 3048/5000 (61%)\n",
      "[epoch 15] loss: 0.5249706\n",
      "Test set: Average loss: 1.3055, Accuracy: 3108/5000 (62%)\n",
      "[epoch 16] loss: 0.4244989\n",
      "Test set: Average loss: 1.3254, Accuracy: 3138/5000 (63%)\n",
      "[epoch 17] loss: 0.3289626\n",
      "Test set: Average loss: 1.4526, Accuracy: 3123/5000 (62%)\n",
      "[epoch 18] loss: 0.2546839\n",
      "Test set: Average loss: 1.5177, Accuracy: 3073/5000 (61%)\n",
      "[epoch 19] loss: 0.1950407\n",
      "Test set: Average loss: 1.6860, Accuracy: 3083/5000 (62%)\n",
      "[epoch 20] loss: 0.1783814\n",
      "Test set: Average loss: 1.7237, Accuracy: 3071/5000 (61%)\n",
      "[epoch 21] loss: 0.1396057\n",
      "Test set: Average loss: 1.8432, Accuracy: 3025/5000 (60%)\n",
      "[epoch 22] loss: 0.1592125\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9143, Accuracy: 3066/5000 (61%)\n",
      "[epoch 23] loss: 0.0637670\n",
      "Test set: Average loss: 1.8182, Accuracy: 3150/5000 (63%)\n",
      "[epoch 24] loss: 0.0220316\n",
      "Test set: Average loss: 1.8374, Accuracy: 3150/5000 (63%)\n",
      "[epoch 25] loss: 0.0138174\n",
      "Test set: Average loss: 1.8587, Accuracy: 3161/5000 (63%)\n",
      "[epoch 26] loss: 0.0097835\n",
      "Test set: Average loss: 1.8831, Accuracy: 3159/5000 (63%)\n",
      "[epoch 27] loss: 0.0071156\n",
      "Test set: Average loss: 1.9090, Accuracy: 3166/5000 (63%)\n",
      "[epoch 28] loss: 0.0052004\n",
      "Test set: Average loss: 1.9490, Accuracy: 3170/5000 (63%)\n",
      "[epoch 29] loss: 0.0038292\n",
      "Test set: Average loss: 1.9870, Accuracy: 3174/5000 (63%)\n",
      "[epoch 30] loss: 0.0027640\n",
      "Test set: Average loss: 2.0195, Accuracy: 3186/5000 (64%)\n",
      "[epoch 31] loss: 0.0019792\n",
      "Test set: Average loss: 2.0709, Accuracy: 3190/5000 (64%)\n",
      "[epoch 32] loss: 0.0014142\n",
      "Test set: Average loss: 2.1131, Accuracy: 3181/5000 (64%)\n",
      "[epoch 33] loss: 0.0009919\n",
      "Test set: Average loss: 2.1706, Accuracy: 3189/5000 (64%)\n",
      "[epoch 34] loss: 0.0006970\n",
      "Test set: Average loss: 2.2230, Accuracy: 3193/5000 (64%)\n",
      "[epoch 35] loss: 0.0004873\n",
      "Test set: Average loss: 2.2793, Accuracy: 3200/5000 (64%)\n",
      "[epoch 36] loss: 0.0003334\n",
      "Test set: Average loss: 2.3422, Accuracy: 3198/5000 (64%)\n",
      "[epoch 37] loss: 0.0002284\n",
      "Test set: Average loss: 2.3972, Accuracy: 3194/5000 (64%)\n",
      "[epoch 38] loss: 0.0001577\n",
      "Test set: Average loss: 2.4669, Accuracy: 3193/5000 (64%)\n",
      "[epoch 39] loss: 0.0001062\n",
      "Test set: Average loss: 2.5323, Accuracy: 3194/5000 (64%)\n",
      "[epoch 40] loss: 0.0000721\n",
      "Test set: Average loss: 2.5932, Accuracy: 3200/5000 (64%)\n",
      "[epoch 41] loss: 0.0000487\n",
      "Test set: Average loss: 2.6639, Accuracy: 3193/5000 (64%)\n",
      "[epoch 42] loss: 0.0000327\n",
      "Test set: Average loss: 2.7333, Accuracy: 3187/5000 (64%)\n",
      "[epoch 43] loss: 0.0000218\n",
      "Test set: Average loss: 2.7997, Accuracy: 3194/5000 (64%)\n",
      "[epoch 44] loss: 0.0000146\n",
      "Test set: Average loss: 2.8678, Accuracy: 3185/5000 (64%)\n",
      "[epoch 45] loss: 0.0000097\n",
      "Test set: Average loss: 2.9347, Accuracy: 3187/5000 (64%)\n",
      "[epoch 46] loss: 0.0000064\n",
      "Test set: Average loss: 3.0110, Accuracy: 3194/5000 (64%)\n",
      "[epoch 47] loss: 0.0000042\n",
      "Test set: Average loss: 3.0801, Accuracy: 3181/5000 (64%)\n",
      "[epoch 48] loss: 0.0000028\n",
      "Test set: Average loss: 3.1448, Accuracy: 3188/5000 (64%)\n",
      "[epoch 49] loss: 0.0000018\n",
      "Test set: Average loss: 3.2070, Accuracy: 3177/5000 (64%)\n",
      "[epoch 50] loss: 0.0000012\n",
      "Test set: Average loss: 3.2679, Accuracy: 3170/5000 (63%)\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5932, Accuracy: 3200/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.5324, Accuracy: 6324/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 543/5000 (11%)\n",
      "[epoch 1] loss: 1.5626112\n",
      "Test set: Average loss: 1.4420, Accuracy: 2414/5000 (48%)\n",
      "[epoch 2] loss: 1.3267922\n",
      "Test set: Average loss: 1.3377, Accuracy: 2596/5000 (52%)\n",
      "[epoch 3] loss: 1.2316753\n",
      "Test set: Average loss: 1.2967, Accuracy: 2713/5000 (54%)\n",
      "[epoch 4] loss: 1.1574505\n",
      "Test set: Average loss: 1.2760, Accuracy: 2777/5000 (56%)\n",
      "[epoch 5] loss: 1.1074558\n",
      "Test set: Average loss: 1.2134, Accuracy: 2868/5000 (57%)\n",
      "[epoch 6] loss: 1.0485820\n",
      "Test set: Average loss: 1.1886, Accuracy: 2911/5000 (58%)\n",
      "[epoch 7] loss: 0.9941756\n",
      "Test set: Average loss: 1.1518, Accuracy: 2974/5000 (59%)\n",
      "[epoch 8] loss: 0.9419779\n",
      "Test set: Average loss: 1.1394, Accuracy: 3055/5000 (61%)\n",
      "[epoch 9] loss: 0.8835581\n",
      "Test set: Average loss: 1.1652, Accuracy: 3002/5000 (60%)\n",
      "[epoch 10] loss: 0.8130343\n",
      "Test set: Average loss: 1.1964, Accuracy: 2990/5000 (60%)\n",
      "[epoch 11] loss: 0.7412354\n",
      "Test set: Average loss: 1.2341, Accuracy: 2981/5000 (60%)\n",
      "[epoch 12] loss: 0.6572318\n",
      "Test set: Average loss: 1.1692, Accuracy: 3111/5000 (62%)\n",
      "[epoch 13] loss: 0.5732839\n",
      "Test set: Average loss: 1.2132, Accuracy: 3101/5000 (62%)\n",
      "[epoch 14] loss: 0.4663259\n",
      "Test set: Average loss: 1.3265, Accuracy: 3076/5000 (62%)\n",
      "[epoch 15] loss: 0.3631502\n",
      "Test set: Average loss: 1.3688, Accuracy: 3120/5000 (62%)\n",
      "[epoch 16] loss: 0.2765171\n",
      "Test set: Average loss: 1.5003, Accuracy: 3069/5000 (61%)\n",
      "[epoch 17] loss: 0.2190513\n",
      "Test set: Average loss: 1.6201, Accuracy: 3051/5000 (61%)\n",
      "[epoch 18] loss: 0.1862902\n",
      "Test set: Average loss: 1.6351, Accuracy: 3072/5000 (61%)\n",
      "[epoch 19] loss: 0.1527335\n",
      "Test set: Average loss: 1.7671, Accuracy: 3023/5000 (60%)\n",
      "[epoch 20] loss: 0.1616922\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8765, Accuracy: 3052/5000 (61%)\n",
      "[epoch 21] loss: 0.0628696\n",
      "Test set: Average loss: 1.7373, Accuracy: 3180/5000 (64%)\n",
      "[epoch 22] loss: 0.0213244\n",
      "Test set: Average loss: 1.7522, Accuracy: 3186/5000 (64%)\n",
      "[epoch 23] loss: 0.0132240\n",
      "Test set: Average loss: 1.7750, Accuracy: 3185/5000 (64%)\n",
      "[epoch 24] loss: 0.0092713\n",
      "Test set: Average loss: 1.8008, Accuracy: 3193/5000 (64%)\n",
      "[epoch 25] loss: 0.0067392\n",
      "Test set: Average loss: 1.8310, Accuracy: 3203/5000 (64%)\n",
      "[epoch 26] loss: 0.0048789\n",
      "Test set: Average loss: 1.8660, Accuracy: 3205/5000 (64%)\n",
      "[epoch 27] loss: 0.0035209\n",
      "Test set: Average loss: 1.9082, Accuracy: 3219/5000 (64%)\n",
      "[epoch 28] loss: 0.0025165\n",
      "Test set: Average loss: 1.9591, Accuracy: 3201/5000 (64%)\n",
      "[epoch 29] loss: 0.0017780\n",
      "Test set: Average loss: 2.0025, Accuracy: 3208/5000 (64%)\n",
      "[epoch 30] loss: 0.0012415\n",
      "Test set: Average loss: 2.0632, Accuracy: 3215/5000 (64%)\n",
      "[epoch 31] loss: 0.0008606\n",
      "Test set: Average loss: 2.1206, Accuracy: 3218/5000 (64%)\n",
      "[epoch 32] loss: 0.0005881\n",
      "Test set: Average loss: 2.1844, Accuracy: 3205/5000 (64%)\n",
      "[epoch 33] loss: 0.0003996\n",
      "Test set: Average loss: 2.2377, Accuracy: 3213/5000 (64%)\n",
      "[epoch 34] loss: 0.0002711\n",
      "Test set: Average loss: 2.3043, Accuracy: 3203/5000 (64%)\n",
      "[epoch 35] loss: 0.0001809\n",
      "Test set: Average loss: 2.3794, Accuracy: 3212/5000 (64%)\n",
      "[epoch 36] loss: 0.0001208\n",
      "Test set: Average loss: 2.4465, Accuracy: 3205/5000 (64%)\n",
      "[epoch 37] loss: 0.0000804\n",
      "Test set: Average loss: 2.5122, Accuracy: 3205/5000 (64%)\n",
      "[epoch 38] loss: 0.0000533\n",
      "Test set: Average loss: 2.5933, Accuracy: 3200/5000 (64%)\n",
      "[epoch 39] loss: 0.0000350\n",
      "Test set: Average loss: 2.6605, Accuracy: 3202/5000 (64%)\n",
      "[epoch 40] loss: 0.0000230\n",
      "Test set: Average loss: 2.7294, Accuracy: 3199/5000 (64%)\n",
      "[epoch 41] loss: 0.0000152\n",
      "Test set: Average loss: 2.8092, Accuracy: 3213/5000 (64%)\n",
      "[epoch 42] loss: 0.0000099\n",
      "Test set: Average loss: 2.8837, Accuracy: 3212/5000 (64%)\n",
      "[epoch 43] loss: 0.0000064\n",
      "Test set: Average loss: 2.9599, Accuracy: 3196/5000 (64%)\n",
      "[epoch 44] loss: 0.0000042\n",
      "Test set: Average loss: 3.0375, Accuracy: 3203/5000 (64%)\n",
      "[epoch 45] loss: 0.0000027\n",
      "Test set: Average loss: 3.1081, Accuracy: 3201/5000 (64%)\n",
      "[epoch 46] loss: 0.0000017\n",
      "Test set: Average loss: 3.1779, Accuracy: 3201/5000 (64%)\n",
      "[epoch 47] loss: 0.0000011\n",
      "Test set: Average loss: 3.2426, Accuracy: 3199/5000 (64%)\n",
      "[epoch 48] loss: 0.0000007\n",
      "Test set: Average loss: 3.2929, Accuracy: 3197/5000 (64%)\n",
      "[epoch 49] loss: 0.0000004\n",
      "Test set: Average loss: 3.3216, Accuracy: 3204/5000 (64%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 3.3224, Accuracy: 3202/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9082, Accuracy: 3219/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 1.8508, Accuracy: 6474/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 505/5000 (10%)\n",
      "[epoch 1] loss: 1.5407309\n",
      "Test set: Average loss: 1.3663, Accuracy: 2516/5000 (50%)\n",
      "[epoch 2] loss: 1.2865355\n",
      "Test set: Average loss: 1.2549, Accuracy: 2783/5000 (56%)\n",
      "[epoch 3] loss: 1.1847824\n",
      "Test set: Average loss: 1.2172, Accuracy: 2825/5000 (56%)\n",
      "[epoch 4] loss: 1.1315848\n",
      "Test set: Average loss: 1.1627, Accuracy: 2921/5000 (58%)\n",
      "[epoch 5] loss: 1.0624320\n",
      "Test set: Average loss: 1.1182, Accuracy: 3053/5000 (61%)\n",
      "[epoch 6] loss: 1.0161876\n",
      "Test set: Average loss: 1.1131, Accuracy: 3051/5000 (61%)\n",
      "[epoch 7] loss: 0.9587067\n",
      "Test set: Average loss: 1.1103, Accuracy: 3062/5000 (61%)\n",
      "[epoch 8] loss: 0.9125088\n",
      "Test set: Average loss: 1.1334, Accuracy: 3028/5000 (61%)\n",
      "[epoch 9] loss: 0.8475658\n",
      "Test set: Average loss: 1.1066, Accuracy: 3067/5000 (61%)\n",
      "[epoch 10] loss: 0.7797348\n",
      "Test set: Average loss: 1.0795, Accuracy: 3187/5000 (64%)\n",
      "[epoch 11] loss: 0.7084268\n",
      "Test set: Average loss: 1.1321, Accuracy: 3099/5000 (62%)\n",
      "[epoch 12] loss: 0.6180710\n",
      "Test set: Average loss: 1.1666, Accuracy: 3175/5000 (64%)\n",
      "[epoch 13] loss: 0.5142401\n",
      "Test set: Average loss: 1.1674, Accuracy: 3162/5000 (63%)\n",
      "[epoch 14] loss: 0.4170631\n",
      "Test set: Average loss: 1.2742, Accuracy: 3120/5000 (62%)\n",
      "[epoch 15] loss: 0.3159432\n",
      "Test set: Average loss: 1.3389, Accuracy: 3144/5000 (63%)\n",
      "[epoch 16] loss: 0.2459304\n",
      "Test set: Average loss: 1.4964, Accuracy: 3115/5000 (62%)\n",
      "[epoch 17] loss: 0.1826442\n",
      "Test set: Average loss: 1.6079, Accuracy: 3097/5000 (62%)\n",
      "[epoch 18] loss: 0.1807635\n",
      "Test set: Average loss: 1.6595, Accuracy: 3126/5000 (63%)\n",
      "[epoch 19] loss: 0.1527455\n",
      "Test set: Average loss: 1.7363, Accuracy: 3126/5000 (63%)\n",
      "[epoch 20] loss: 0.1557306\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8145, Accuracy: 3169/5000 (63%)\n",
      "[epoch 21] loss: 0.0507432\n",
      "Test set: Average loss: 1.7086, Accuracy: 3231/5000 (65%)\n",
      "[epoch 22] loss: 0.0181262\n",
      "Test set: Average loss: 1.7196, Accuracy: 3233/5000 (65%)\n",
      "[epoch 23] loss: 0.0115690\n",
      "Test set: Average loss: 1.7455, Accuracy: 3240/5000 (65%)\n",
      "[epoch 24] loss: 0.0082352\n",
      "Test set: Average loss: 1.7650, Accuracy: 3251/5000 (65%)\n",
      "[epoch 25] loss: 0.0059681\n",
      "Test set: Average loss: 1.7972, Accuracy: 3253/5000 (65%)\n",
      "[epoch 26] loss: 0.0043619\n",
      "Test set: Average loss: 1.8348, Accuracy: 3267/5000 (65%)\n",
      "[epoch 27] loss: 0.0031502\n",
      "Test set: Average loss: 1.8756, Accuracy: 3250/5000 (65%)\n",
      "[epoch 28] loss: 0.0022488\n",
      "Test set: Average loss: 1.9159, Accuracy: 3256/5000 (65%)\n",
      "[epoch 29] loss: 0.0015825\n",
      "Test set: Average loss: 1.9555, Accuracy: 3258/5000 (65%)\n",
      "[epoch 30] loss: 0.0011109\n",
      "Test set: Average loss: 2.0139, Accuracy: 3262/5000 (65%)\n",
      "[epoch 31] loss: 0.0007687\n",
      "Test set: Average loss: 2.0605, Accuracy: 3252/5000 (65%)\n",
      "[epoch 32] loss: 0.0005254\n",
      "Test set: Average loss: 2.1197, Accuracy: 3256/5000 (65%)\n",
      "[epoch 33] loss: 0.0003557\n",
      "Test set: Average loss: 2.1752, Accuracy: 3252/5000 (65%)\n",
      "[epoch 34] loss: 0.0002403\n",
      "Test set: Average loss: 2.2366, Accuracy: 3250/5000 (65%)\n",
      "[epoch 35] loss: 0.0001610\n",
      "Test set: Average loss: 2.2995, Accuracy: 3245/5000 (65%)\n",
      "[epoch 36] loss: 0.0001071\n",
      "Test set: Average loss: 2.3637, Accuracy: 3254/5000 (65%)\n",
      "[epoch 37] loss: 0.0000714\n",
      "Test set: Average loss: 2.4359, Accuracy: 3253/5000 (65%)\n",
      "[epoch 38] loss: 0.0000472\n",
      "Test set: Average loss: 2.4949, Accuracy: 3258/5000 (65%)\n",
      "[epoch 39] loss: 0.0000311\n",
      "Test set: Average loss: 2.5598, Accuracy: 3254/5000 (65%)\n",
      "[epoch 40] loss: 0.0000204\n",
      "Test set: Average loss: 2.6258, Accuracy: 3246/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.0000134\n",
      "Test set: Average loss: 2.7024, Accuracy: 3244/5000 (65%)\n",
      "[epoch 42] loss: 0.0000087\n",
      "Test set: Average loss: 2.7701, Accuracy: 3245/5000 (65%)\n",
      "[epoch 43] loss: 0.0000057\n",
      "Test set: Average loss: 2.8373, Accuracy: 3244/5000 (65%)\n",
      "[epoch 44] loss: 0.0000037\n",
      "Test set: Average loss: 2.9048, Accuracy: 3234/5000 (65%)\n",
      "[epoch 45] loss: 0.0000024\n",
      "Test set: Average loss: 2.9700, Accuracy: 3245/5000 (65%)\n",
      "[epoch 46] loss: 0.0000015\n",
      "Test set: Average loss: 3.0307, Accuracy: 3239/5000 (65%)\n",
      "[epoch 47] loss: 0.0000010\n",
      "Test set: Average loss: 3.0906, Accuracy: 3241/5000 (65%)\n",
      "[epoch 48] loss: 0.0000006\n",
      "Test set: Average loss: 3.1284, Accuracy: 3244/5000 (65%)\n",
      "[epoch 49] loss: 0.0000004\n",
      "Test set: Average loss: 3.1483, Accuracy: 3232/5000 (65%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 3.1509, Accuracy: 3236/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8348, Accuracy: 3267/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 1.7960, Accuracy: 6599/10000 (66%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 494/5000 (10%)\n",
      "[epoch 1] loss: 1.5477805\n",
      "Test set: Average loss: 1.3520, Accuracy: 2554/5000 (51%)\n",
      "[epoch 2] loss: 1.3177660\n",
      "Test set: Average loss: 1.3682, Accuracy: 2516/5000 (50%)\n",
      "[epoch 3] loss: 1.2288112\n",
      "Test set: Average loss: 1.2656, Accuracy: 2762/5000 (55%)\n",
      "[epoch 4] loss: 1.1550552\n",
      "Test set: Average loss: 1.1969, Accuracy: 2910/5000 (58%)\n",
      "[epoch 5] loss: 1.0961939\n",
      "Test set: Average loss: 1.2048, Accuracy: 2872/5000 (57%)\n",
      "[epoch 6] loss: 1.0469793\n",
      "Test set: Average loss: 1.1518, Accuracy: 2985/5000 (60%)\n",
      "[epoch 7] loss: 0.9939724\n",
      "Test set: Average loss: 1.1119, Accuracy: 3067/5000 (61%)\n",
      "[epoch 8] loss: 0.9401218\n",
      "Test set: Average loss: 1.1208, Accuracy: 3046/5000 (61%)\n",
      "[epoch 9] loss: 0.8801331\n",
      "Test set: Average loss: 1.0690, Accuracy: 3161/5000 (63%)\n",
      "[epoch 10] loss: 0.8247666\n",
      "Test set: Average loss: 1.1041, Accuracy: 3129/5000 (63%)\n",
      "[epoch 11] loss: 0.7557199\n",
      "Test set: Average loss: 1.0699, Accuracy: 3198/5000 (64%)\n",
      "[epoch 12] loss: 0.6880528\n",
      "Test set: Average loss: 1.1120, Accuracy: 3155/5000 (63%)\n",
      "[epoch 13] loss: 0.6063994\n",
      "Test set: Average loss: 1.1805, Accuracy: 3124/5000 (62%)\n",
      "[epoch 14] loss: 0.5199766\n",
      "Test set: Average loss: 1.2262, Accuracy: 3146/5000 (63%)\n",
      "[epoch 15] loss: 0.4437773\n",
      "Test set: Average loss: 1.3504, Accuracy: 3093/5000 (62%)\n",
      "[epoch 16] loss: 0.3456336\n",
      "Test set: Average loss: 1.3643, Accuracy: 3139/5000 (63%)\n",
      "[epoch 17] loss: 0.2929948\n",
      "Test set: Average loss: 1.4882, Accuracy: 3109/5000 (62%)\n",
      "[epoch 18] loss: 0.2465621\n",
      "Test set: Average loss: 1.5602, Accuracy: 3126/5000 (63%)\n",
      "[epoch 19] loss: 0.2125484\n",
      "Test set: Average loss: 1.6063, Accuracy: 3104/5000 (62%)\n",
      "[epoch 20] loss: 0.1903081\n",
      "Test set: Average loss: 1.7556, Accuracy: 3054/5000 (61%)\n",
      "[epoch 21] loss: 0.1780087\n",
      "Test set: Average loss: 1.7255, Accuracy: 3119/5000 (62%)\n",
      "[epoch 22] loss: 0.1605560\n",
      "Test set: Average loss: 1.9090, Accuracy: 3047/5000 (61%)\n",
      "[epoch 23] loss: 0.1710198\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8518, Accuracy: 3078/5000 (62%)\n",
      "[epoch 24] loss: 0.0573505\n",
      "Test set: Average loss: 1.7839, Accuracy: 3188/5000 (64%)\n",
      "[epoch 25] loss: 0.0194253\n",
      "Test set: Average loss: 1.7955, Accuracy: 3183/5000 (64%)\n",
      "[epoch 26] loss: 0.0117854\n",
      "Test set: Average loss: 1.8122, Accuracy: 3200/5000 (64%)\n",
      "[epoch 27] loss: 0.0080936\n",
      "Test set: Average loss: 1.8336, Accuracy: 3216/5000 (64%)\n",
      "[epoch 28] loss: 0.0056992\n",
      "Test set: Average loss: 1.8663, Accuracy: 3213/5000 (64%)\n",
      "[epoch 29] loss: 0.0040548\n",
      "Test set: Average loss: 1.9052, Accuracy: 3213/5000 (64%)\n",
      "[epoch 30] loss: 0.0028161\n",
      "Test set: Average loss: 1.9398, Accuracy: 3224/5000 (64%)\n",
      "[epoch 31] loss: 0.0019363\n",
      "Test set: Average loss: 1.9871, Accuracy: 3218/5000 (64%)\n",
      "[epoch 32] loss: 0.0013227\n",
      "Test set: Average loss: 2.0664, Accuracy: 3222/5000 (64%)\n",
      "[epoch 33] loss: 0.0008949\n",
      "Test set: Average loss: 2.0996, Accuracy: 3232/5000 (65%)\n",
      "[epoch 34] loss: 0.0006047\n",
      "Test set: Average loss: 2.1513, Accuracy: 3243/5000 (65%)\n",
      "[epoch 35] loss: 0.0004010\n",
      "Test set: Average loss: 2.2182, Accuracy: 3226/5000 (65%)\n",
      "[epoch 36] loss: 0.0002650\n",
      "Test set: Average loss: 2.2836, Accuracy: 3238/5000 (65%)\n",
      "[epoch 37] loss: 0.0001758\n",
      "Test set: Average loss: 2.3448, Accuracy: 3250/5000 (65%)\n",
      "[epoch 38] loss: 0.0001140\n",
      "Test set: Average loss: 2.4093, Accuracy: 3238/5000 (65%)\n",
      "[epoch 39] loss: 0.0000745\n",
      "Test set: Average loss: 2.4858, Accuracy: 3240/5000 (65%)\n",
      "[epoch 40] loss: 0.0000482\n",
      "Test set: Average loss: 2.5536, Accuracy: 3234/5000 (65%)\n",
      "[epoch 41] loss: 0.0000309\n",
      "Test set: Average loss: 2.6281, Accuracy: 3244/5000 (65%)\n",
      "[epoch 42] loss: 0.0000198\n",
      "Test set: Average loss: 2.6989, Accuracy: 3236/5000 (65%)\n",
      "[epoch 43] loss: 0.0000126\n",
      "Test set: Average loss: 2.7753, Accuracy: 3245/5000 (65%)\n",
      "[epoch 44] loss: 0.0000080\n",
      "Test set: Average loss: 2.8455, Accuracy: 3236/5000 (65%)\n",
      "[epoch 45] loss: 0.0000051\n",
      "Test set: Average loss: 2.9175, Accuracy: 3245/5000 (65%)\n",
      "[epoch 46] loss: 0.0000032\n",
      "Test set: Average loss: 2.9998, Accuracy: 3241/5000 (65%)\n",
      "[epoch 47] loss: 0.0000020\n",
      "Test set: Average loss: 3.0589, Accuracy: 3235/5000 (65%)\n",
      "[epoch 48] loss: 0.0000013\n",
      "Test set: Average loss: 3.1302, Accuracy: 3236/5000 (65%)\n",
      "[epoch 49] loss: 0.0000008\n",
      "Test set: Average loss: 3.1757, Accuracy: 3241/5000 (65%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 3.2176, Accuracy: 3228/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3448, Accuracy: 3250/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.2920, Accuracy: 6547/10000 (65%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 369/5000 (7%)\n",
      "[epoch 1] loss: 1.5320127\n",
      "Test set: Average loss: 1.4302, Accuracy: 2443/5000 (49%)\n",
      "[epoch 2] loss: 1.2842055\n",
      "Test set: Average loss: 1.2833, Accuracy: 2703/5000 (54%)\n",
      "[epoch 3] loss: 1.1897982\n",
      "Test set: Average loss: 1.2349, Accuracy: 2791/5000 (56%)\n",
      "[epoch 4] loss: 1.1099290\n",
      "Test set: Average loss: 1.2285, Accuracy: 2842/5000 (57%)\n",
      "[epoch 5] loss: 1.0506993\n",
      "Test set: Average loss: 1.1347, Accuracy: 3012/5000 (60%)\n",
      "[epoch 6] loss: 0.9919091\n",
      "Test set: Average loss: 1.0971, Accuracy: 3052/5000 (61%)\n",
      "[epoch 7] loss: 0.9413595\n",
      "Test set: Average loss: 1.1036, Accuracy: 3092/5000 (62%)\n",
      "[epoch 8] loss: 0.8881263\n",
      "Test set: Average loss: 1.0671, Accuracy: 3160/5000 (63%)\n",
      "[epoch 9] loss: 0.8373910\n",
      "Test set: Average loss: 1.0492, Accuracy: 3167/5000 (63%)\n",
      "[epoch 10] loss: 0.7703566\n",
      "Test set: Average loss: 1.0787, Accuracy: 3170/5000 (63%)\n",
      "[epoch 11] loss: 0.6937008\n",
      "Test set: Average loss: 1.1536, Accuracy: 3155/5000 (63%)\n",
      "[epoch 12] loss: 0.6098396\n",
      "Test set: Average loss: 1.1565, Accuracy: 3183/5000 (64%)\n",
      "[epoch 13] loss: 0.5186622\n",
      "Test set: Average loss: 1.1362, Accuracy: 3251/5000 (65%)\n",
      "[epoch 14] loss: 0.4379704\n",
      "Test set: Average loss: 1.2255, Accuracy: 3228/5000 (65%)\n",
      "[epoch 15] loss: 0.3504939\n",
      "Test set: Average loss: 1.3117, Accuracy: 3219/5000 (64%)\n",
      "[epoch 16] loss: 0.2804444\n",
      "Test set: Average loss: 1.3986, Accuracy: 3170/5000 (63%)\n",
      "[epoch 17] loss: 0.2210737\n",
      "Test set: Average loss: 1.5033, Accuracy: 3193/5000 (64%)\n",
      "[epoch 18] loss: 0.2046075\n",
      "Test set: Average loss: 1.5632, Accuracy: 3176/5000 (64%)\n",
      "[epoch 19] loss: 0.1714841\n",
      "Test set: Average loss: 1.6597, Accuracy: 3188/5000 (64%)\n",
      "[epoch 20] loss: 0.1609641\n",
      "Test set: Average loss: 1.7843, Accuracy: 3122/5000 (62%)\n",
      "[epoch 21] loss: 0.1511150\n",
      "Test set: Average loss: 1.8308, Accuracy: 3150/5000 (63%)\n",
      "[epoch 22] loss: 0.1537591\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9035, Accuracy: 3134/5000 (63%)\n",
      "[epoch 23] loss: 0.0557348\n",
      "Test set: Average loss: 1.8029, Accuracy: 3208/5000 (64%)\n",
      "[epoch 24] loss: 0.0174929\n",
      "Test set: Average loss: 1.8194, Accuracy: 3225/5000 (64%)\n",
      "[epoch 25] loss: 0.0103804\n",
      "Test set: Average loss: 1.8463, Accuracy: 3235/5000 (65%)\n",
      "[epoch 26] loss: 0.0070838\n",
      "Test set: Average loss: 1.8639, Accuracy: 3253/5000 (65%)\n",
      "[epoch 27] loss: 0.0049443\n",
      "Test set: Average loss: 1.8988, Accuracy: 3251/5000 (65%)\n",
      "[epoch 28] loss: 0.0034455\n",
      "Test set: Average loss: 1.9338, Accuracy: 3259/5000 (65%)\n",
      "[epoch 29] loss: 0.0023852\n",
      "Test set: Average loss: 1.9783, Accuracy: 3268/5000 (65%)\n",
      "[epoch 30] loss: 0.0016166\n",
      "Test set: Average loss: 2.0273, Accuracy: 3255/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0010878\n",
      "Test set: Average loss: 2.0790, Accuracy: 3266/5000 (65%)\n",
      "[epoch 32] loss: 0.0007196\n",
      "Test set: Average loss: 2.1396, Accuracy: 3277/5000 (66%)\n",
      "[epoch 33] loss: 0.0004715\n",
      "Test set: Average loss: 2.1946, Accuracy: 3270/5000 (65%)\n",
      "[epoch 34] loss: 0.0003072\n",
      "Test set: Average loss: 2.2555, Accuracy: 3274/5000 (65%)\n",
      "[epoch 35] loss: 0.0001985\n",
      "Test set: Average loss: 2.3276, Accuracy: 3261/5000 (65%)\n",
      "[epoch 36] loss: 0.0001271\n",
      "Test set: Average loss: 2.3891, Accuracy: 3290/5000 (66%)\n",
      "[epoch 37] loss: 0.0000809\n",
      "Test set: Average loss: 2.4662, Accuracy: 3283/5000 (66%)\n",
      "[epoch 38] loss: 0.0000513\n",
      "Test set: Average loss: 2.5395, Accuracy: 3281/5000 (66%)\n",
      "[epoch 39] loss: 0.0000324\n",
      "Test set: Average loss: 2.6092, Accuracy: 3279/5000 (66%)\n",
      "[epoch 40] loss: 0.0000203\n",
      "Test set: Average loss: 2.6856, Accuracy: 3282/5000 (66%)\n",
      "[epoch 41] loss: 0.0000128\n",
      "Test set: Average loss: 2.7584, Accuracy: 3277/5000 (66%)\n",
      "[epoch 42] loss: 0.0000079\n",
      "Test set: Average loss: 2.8313, Accuracy: 3277/5000 (66%)\n",
      "[epoch 43] loss: 0.0000049\n",
      "Test set: Average loss: 2.9108, Accuracy: 3275/5000 (66%)\n",
      "[epoch 44] loss: 0.0000030\n",
      "Test set: Average loss: 3.0057, Accuracy: 3276/5000 (66%)\n",
      "[epoch 45] loss: 0.0000019\n",
      "Test set: Average loss: 3.0534, Accuracy: 3291/5000 (66%)\n",
      "[epoch 46] loss: 0.0000011\n",
      "Test set: Average loss: 3.1187, Accuracy: 3271/5000 (65%)\n",
      "[epoch 47] loss: 0.0000007\n",
      "Test set: Average loss: 3.1746, Accuracy: 3279/5000 (66%)\n",
      "[epoch 48] loss: 0.0000004\n",
      "Test set: Average loss: 3.2036, Accuracy: 3283/5000 (66%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.2177, Accuracy: 3279/5000 (66%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.2265, Accuracy: 3281/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0534, Accuracy: 3291/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.8896, Accuracy: 6702/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 481/5000 (10%)\n",
      "[epoch 1] loss: 1.5183874\n",
      "Test set: Average loss: 1.3796, Accuracy: 2508/5000 (50%)\n",
      "[epoch 2] loss: 1.2822438\n",
      "Test set: Average loss: 1.2542, Accuracy: 2731/5000 (55%)\n",
      "[epoch 3] loss: 1.1860239\n",
      "Test set: Average loss: 1.1989, Accuracy: 2893/5000 (58%)\n",
      "[epoch 4] loss: 1.1241160\n",
      "Test set: Average loss: 1.2238, Accuracy: 2852/5000 (57%)\n",
      "[epoch 5] loss: 1.0684260\n",
      "Test set: Average loss: 1.1521, Accuracy: 2967/5000 (59%)\n",
      "[epoch 6] loss: 1.0083181\n",
      "Test set: Average loss: 1.1847, Accuracy: 2900/5000 (58%)\n",
      "[epoch 7] loss: 0.9546371\n",
      "Test set: Average loss: 1.1316, Accuracy: 3060/5000 (61%)\n",
      "[epoch 8] loss: 0.8979680\n",
      "Test set: Average loss: 1.0924, Accuracy: 3125/5000 (62%)\n",
      "[epoch 9] loss: 0.8335799\n",
      "Test set: Average loss: 1.1281, Accuracy: 3066/5000 (61%)\n",
      "[epoch 10] loss: 0.7627408\n",
      "Test set: Average loss: 1.1041, Accuracy: 3193/5000 (64%)\n",
      "[epoch 11] loss: 0.6910607\n",
      "Test set: Average loss: 1.1139, Accuracy: 3205/5000 (64%)\n",
      "[epoch 12] loss: 0.6075641\n",
      "Test set: Average loss: 1.1677, Accuracy: 3144/5000 (63%)\n",
      "[epoch 13] loss: 0.5169235\n",
      "Test set: Average loss: 1.2038, Accuracy: 3160/5000 (63%)\n",
      "[epoch 14] loss: 0.4239125\n",
      "Test set: Average loss: 1.2453, Accuracy: 3209/5000 (64%)\n",
      "[epoch 15] loss: 0.3428529\n",
      "Test set: Average loss: 1.3808, Accuracy: 3111/5000 (62%)\n",
      "[epoch 16] loss: 0.2649881\n",
      "Test set: Average loss: 1.4994, Accuracy: 3087/5000 (62%)\n",
      "[epoch 17] loss: 0.2208371\n",
      "Test set: Average loss: 1.5773, Accuracy: 3149/5000 (63%)\n",
      "[epoch 18] loss: 0.1965153\n",
      "Test set: Average loss: 1.5824, Accuracy: 3192/5000 (64%)\n",
      "[epoch 19] loss: 0.1852935\n",
      "Test set: Average loss: 1.7733, Accuracy: 3104/5000 (62%)\n",
      "[epoch 20] loss: 0.1582155\n",
      "Test set: Average loss: 1.7374, Accuracy: 3174/5000 (63%)\n",
      "[epoch 21] loss: 0.1609908\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8704, Accuracy: 3126/5000 (63%)\n",
      "[epoch 22] loss: 0.0529233\n",
      "Test set: Average loss: 1.7498, Accuracy: 3235/5000 (65%)\n",
      "[epoch 23] loss: 0.0189035\n",
      "Test set: Average loss: 1.7481, Accuracy: 3237/5000 (65%)\n",
      "[epoch 24] loss: 0.0116308\n",
      "Test set: Average loss: 1.7774, Accuracy: 3221/5000 (64%)\n",
      "[epoch 25] loss: 0.0079556\n",
      "Test set: Average loss: 1.8008, Accuracy: 3234/5000 (65%)\n",
      "[epoch 26] loss: 0.0055128\n",
      "Test set: Average loss: 1.8357, Accuracy: 3235/5000 (65%)\n",
      "[epoch 27] loss: 0.0038370\n",
      "Test set: Average loss: 1.8746, Accuracy: 3243/5000 (65%)\n",
      "[epoch 28] loss: 0.0026538\n",
      "Test set: Average loss: 1.9136, Accuracy: 3247/5000 (65%)\n",
      "[epoch 29] loss: 0.0018096\n",
      "Test set: Average loss: 1.9699, Accuracy: 3247/5000 (65%)\n",
      "[epoch 30] loss: 0.0012217\n",
      "Test set: Average loss: 2.0116, Accuracy: 3258/5000 (65%)\n",
      "[epoch 31] loss: 0.0008115\n",
      "Test set: Average loss: 2.0749, Accuracy: 3255/5000 (65%)\n",
      "[epoch 32] loss: 0.0005356\n",
      "Test set: Average loss: 2.1290, Accuracy: 3261/5000 (65%)\n",
      "[epoch 33] loss: 0.0003511\n",
      "Test set: Average loss: 2.1933, Accuracy: 3259/5000 (65%)\n",
      "[epoch 34] loss: 0.0002265\n",
      "Test set: Average loss: 2.2604, Accuracy: 3256/5000 (65%)\n",
      "[epoch 35] loss: 0.0001463\n",
      "Test set: Average loss: 2.3268, Accuracy: 3262/5000 (65%)\n",
      "[epoch 36] loss: 0.0000932\n",
      "Test set: Average loss: 2.3992, Accuracy: 3261/5000 (65%)\n",
      "[epoch 37] loss: 0.0000598\n",
      "Test set: Average loss: 2.4620, Accuracy: 3276/5000 (66%)\n",
      "[epoch 38] loss: 0.0000378\n",
      "Test set: Average loss: 2.5366, Accuracy: 3258/5000 (65%)\n",
      "[epoch 39] loss: 0.0000238\n",
      "Test set: Average loss: 2.6095, Accuracy: 3261/5000 (65%)\n",
      "[epoch 40] loss: 0.0000150\n",
      "Test set: Average loss: 2.6849, Accuracy: 3266/5000 (65%)\n",
      "[epoch 41] loss: 0.0000094\n",
      "Test set: Average loss: 2.7599, Accuracy: 3271/5000 (65%)\n",
      "[epoch 42] loss: 0.0000058\n",
      "Test set: Average loss: 2.8369, Accuracy: 3281/5000 (66%)\n",
      "[epoch 43] loss: 0.0000036\n",
      "Test set: Average loss: 2.9158, Accuracy: 3281/5000 (66%)\n",
      "[epoch 44] loss: 0.0000022\n",
      "Test set: Average loss: 2.9857, Accuracy: 3281/5000 (66%)\n",
      "[epoch 45] loss: 0.0000014\n",
      "Test set: Average loss: 3.0516, Accuracy: 3285/5000 (66%)\n",
      "[epoch 46] loss: 0.0000008\n",
      "Test set: Average loss: 3.1097, Accuracy: 3273/5000 (65%)\n",
      "[epoch 47] loss: 0.0000005\n",
      "Test set: Average loss: 3.1396, Accuracy: 3272/5000 (65%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.1593, Accuracy: 3265/5000 (65%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.1666, Accuracy: 3266/5000 (65%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.1845, Accuracy: 3264/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0516, Accuracy: 3285/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.9869, Accuracy: 6626/10000 (66%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3015, Accuracy: 650/5000 (13%)\n",
      "[epoch 1] loss: 1.5324973\n",
      "Test set: Average loss: 1.3115, Accuracy: 2647/5000 (53%)\n",
      "[epoch 2] loss: 1.2962923\n",
      "Test set: Average loss: 1.2887, Accuracy: 2682/5000 (54%)\n",
      "[epoch 3] loss: 1.2119512\n",
      "Test set: Average loss: 1.1920, Accuracy: 2889/5000 (58%)\n",
      "[epoch 4] loss: 1.1400367\n",
      "Test set: Average loss: 1.2483, Accuracy: 2808/5000 (56%)\n",
      "[epoch 5] loss: 1.0888198\n",
      "Test set: Average loss: 1.2327, Accuracy: 2854/5000 (57%)\n",
      "[epoch 6] loss: 1.0373543\n",
      "Test set: Average loss: 1.1283, Accuracy: 2992/5000 (60%)\n",
      "[epoch 7] loss: 0.9944106\n",
      "Test set: Average loss: 1.1206, Accuracy: 3043/5000 (61%)\n",
      "[epoch 8] loss: 0.9432914\n",
      "Test set: Average loss: 1.0719, Accuracy: 3158/5000 (63%)\n",
      "[epoch 9] loss: 0.8862943\n",
      "Test set: Average loss: 1.0831, Accuracy: 3099/5000 (62%)\n",
      "[epoch 10] loss: 0.8319458\n",
      "Test set: Average loss: 1.1753, Accuracy: 3087/5000 (62%)\n",
      "[epoch 11] loss: 0.7693528\n",
      "Test set: Average loss: 1.0889, Accuracy: 3149/5000 (63%)\n",
      "[epoch 12] loss: 0.7002712\n",
      "Test set: Average loss: 1.1218, Accuracy: 3141/5000 (63%)\n",
      "[epoch 13] loss: 0.6246689\n",
      "Test set: Average loss: 1.1143, Accuracy: 3193/5000 (64%)\n",
      "[epoch 14] loss: 0.5426610\n",
      "Test set: Average loss: 1.1859, Accuracy: 3154/5000 (63%)\n",
      "[epoch 15] loss: 0.4554758\n",
      "Test set: Average loss: 1.2329, Accuracy: 3183/5000 (64%)\n",
      "[epoch 16] loss: 0.3818033\n",
      "Test set: Average loss: 1.3934, Accuracy: 3096/5000 (62%)\n",
      "[epoch 17] loss: 0.2991489\n",
      "Test set: Average loss: 1.4301, Accuracy: 3167/5000 (63%)\n",
      "[epoch 18] loss: 0.2674204\n",
      "Test set: Average loss: 1.5678, Accuracy: 3087/5000 (62%)\n",
      "[epoch 19] loss: 0.2271238\n",
      "Test set: Average loss: 1.5910, Accuracy: 3055/5000 (61%)\n",
      "[epoch 20] loss: 0.1973291\n",
      "Test set: Average loss: 1.6698, Accuracy: 3057/5000 (61%)\n",
      "[epoch 21] loss: 0.1868751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.7300, Accuracy: 3069/5000 (61%)\n",
      "[epoch 22] loss: 0.1712955\n",
      "Test set: Average loss: 1.8501, Accuracy: 3046/5000 (61%)\n",
      "[epoch 23] loss: 0.1759076\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9217, Accuracy: 3060/5000 (61%)\n",
      "[epoch 24] loss: 0.0657794\n",
      "Test set: Average loss: 1.7911, Accuracy: 3148/5000 (63%)\n",
      "[epoch 25] loss: 0.0217568\n",
      "Test set: Average loss: 1.8048, Accuracy: 3177/5000 (64%)\n",
      "[epoch 26] loss: 0.0128344\n",
      "Test set: Average loss: 1.8235, Accuracy: 3165/5000 (63%)\n",
      "[epoch 27] loss: 0.0084342\n",
      "Test set: Average loss: 1.8519, Accuracy: 3186/5000 (64%)\n",
      "[epoch 28] loss: 0.0057109\n",
      "Test set: Average loss: 1.8939, Accuracy: 3182/5000 (64%)\n",
      "[epoch 29] loss: 0.0038575\n",
      "Test set: Average loss: 1.9417, Accuracy: 3188/5000 (64%)\n",
      "[epoch 30] loss: 0.0025835\n",
      "Test set: Average loss: 1.9804, Accuracy: 3197/5000 (64%)\n",
      "[epoch 31] loss: 0.0017068\n",
      "Test set: Average loss: 2.0413, Accuracy: 3197/5000 (64%)\n",
      "[epoch 32] loss: 0.0011090\n",
      "Test set: Average loss: 2.1058, Accuracy: 3186/5000 (64%)\n",
      "[epoch 33] loss: 0.0007206\n",
      "Test set: Average loss: 2.1715, Accuracy: 3196/5000 (64%)\n",
      "[epoch 34] loss: 0.0004620\n",
      "Test set: Average loss: 2.2311, Accuracy: 3199/5000 (64%)\n",
      "[epoch 35] loss: 0.0002938\n",
      "Test set: Average loss: 2.3026, Accuracy: 3213/5000 (64%)\n",
      "[epoch 36] loss: 0.0001864\n",
      "Test set: Average loss: 2.3846, Accuracy: 3223/5000 (64%)\n",
      "[epoch 37] loss: 0.0001167\n",
      "Test set: Average loss: 2.4537, Accuracy: 3222/5000 (64%)\n",
      "[epoch 38] loss: 0.0000725\n",
      "Test set: Average loss: 2.5299, Accuracy: 3222/5000 (64%)\n",
      "[epoch 39] loss: 0.0000453\n",
      "Test set: Average loss: 2.6165, Accuracy: 3228/5000 (65%)\n",
      "[epoch 40] loss: 0.0000280\n",
      "Test set: Average loss: 2.6875, Accuracy: 3223/5000 (64%)\n",
      "[epoch 41] loss: 0.0000171\n",
      "Test set: Average loss: 2.7813, Accuracy: 3219/5000 (64%)\n",
      "[epoch 42] loss: 0.0000105\n",
      "Test set: Average loss: 2.8681, Accuracy: 3218/5000 (64%)\n",
      "[epoch 43] loss: 0.0000063\n",
      "Test set: Average loss: 2.9443, Accuracy: 3212/5000 (64%)\n",
      "[epoch 44] loss: 0.0000038\n",
      "Test set: Average loss: 3.0314, Accuracy: 3206/5000 (64%)\n",
      "[epoch 45] loss: 0.0000023\n",
      "Test set: Average loss: 3.1164, Accuracy: 3227/5000 (65%)\n",
      "[epoch 46] loss: 0.0000014\n",
      "Test set: Average loss: 3.1971, Accuracy: 3217/5000 (64%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 3.2568, Accuracy: 3215/5000 (64%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 3.3034, Accuracy: 3211/5000 (64%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.3098, Accuracy: 3207/5000 (64%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.3301, Accuracy: 3203/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6165, Accuracy: 3228/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.5015, Accuracy: 6619/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 535/5000 (11%)\n",
      "[epoch 1] loss: 1.4923371\n",
      "Test set: Average loss: 1.3943, Accuracy: 2543/5000 (51%)\n",
      "[epoch 2] loss: 1.2408505\n",
      "Test set: Average loss: 1.2302, Accuracy: 2791/5000 (56%)\n",
      "[epoch 3] loss: 1.1497815\n",
      "Test set: Average loss: 1.1622, Accuracy: 2942/5000 (59%)\n",
      "[epoch 4] loss: 1.0850514\n",
      "Test set: Average loss: 1.1715, Accuracy: 2962/5000 (59%)\n",
      "[epoch 5] loss: 1.0277874\n",
      "Test set: Average loss: 1.1049, Accuracy: 3043/5000 (61%)\n",
      "[epoch 6] loss: 0.9715958\n",
      "Test set: Average loss: 1.1164, Accuracy: 3069/5000 (61%)\n",
      "[epoch 7] loss: 0.9189490\n",
      "Test set: Average loss: 1.0539, Accuracy: 3179/5000 (64%)\n",
      "[epoch 8] loss: 0.8472012\n",
      "Test set: Average loss: 1.0580, Accuracy: 3190/5000 (64%)\n",
      "[epoch 9] loss: 0.7785297\n",
      "Test set: Average loss: 1.1098, Accuracy: 3178/5000 (64%)\n",
      "[epoch 10] loss: 0.7094226\n",
      "Test set: Average loss: 1.0559, Accuracy: 3197/5000 (64%)\n",
      "[epoch 11] loss: 0.6234682\n",
      "Test set: Average loss: 1.1245, Accuracy: 3199/5000 (64%)\n",
      "[epoch 12] loss: 0.5519588\n",
      "Test set: Average loss: 1.1468, Accuracy: 3200/5000 (64%)\n",
      "[epoch 13] loss: 0.4594738\n",
      "Test set: Average loss: 1.2011, Accuracy: 3217/5000 (64%)\n",
      "[epoch 14] loss: 0.3906520\n",
      "Test set: Average loss: 1.2613, Accuracy: 3204/5000 (64%)\n",
      "[epoch 15] loss: 0.3275740\n",
      "Test set: Average loss: 1.3357, Accuracy: 3203/5000 (64%)\n",
      "[epoch 16] loss: 0.2691702\n",
      "Test set: Average loss: 1.4543, Accuracy: 3183/5000 (64%)\n",
      "[epoch 17] loss: 0.2492706\n",
      "Test set: Average loss: 1.5029, Accuracy: 3180/5000 (64%)\n",
      "[epoch 18] loss: 0.2274800\n",
      "Test set: Average loss: 1.5835, Accuracy: 3181/5000 (64%)\n",
      "[epoch 19] loss: 0.1906067\n",
      "Test set: Average loss: 1.7043, Accuracy: 3154/5000 (63%)\n",
      "[epoch 20] loss: 0.2024043\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7136, Accuracy: 3151/5000 (63%)\n",
      "[epoch 21] loss: 0.0781505\n",
      "Test set: Average loss: 1.5999, Accuracy: 3252/5000 (65%)\n",
      "[epoch 22] loss: 0.0290430\n",
      "Test set: Average loss: 1.6161, Accuracy: 3283/5000 (66%)\n",
      "[epoch 23] loss: 0.0170440\n",
      "Test set: Average loss: 1.6458, Accuracy: 3268/5000 (65%)\n",
      "[epoch 24] loss: 0.0112107\n",
      "Test set: Average loss: 1.6816, Accuracy: 3284/5000 (66%)\n",
      "[epoch 25] loss: 0.0074594\n",
      "Test set: Average loss: 1.7262, Accuracy: 3289/5000 (66%)\n",
      "[epoch 26] loss: 0.0049774\n",
      "Test set: Average loss: 1.7658, Accuracy: 3298/5000 (66%)\n",
      "[epoch 27] loss: 0.0033056\n",
      "Test set: Average loss: 1.8194, Accuracy: 3301/5000 (66%)\n",
      "[epoch 28] loss: 0.0021656\n",
      "Test set: Average loss: 1.8805, Accuracy: 3300/5000 (66%)\n",
      "[epoch 29] loss: 0.0014041\n",
      "Test set: Average loss: 1.9467, Accuracy: 3297/5000 (66%)\n",
      "[epoch 30] loss: 0.0009054\n",
      "Test set: Average loss: 2.0031, Accuracy: 3313/5000 (66%)\n",
      "[epoch 31] loss: 0.0005728\n",
      "Test set: Average loss: 2.0763, Accuracy: 3307/5000 (66%)\n",
      "[epoch 32] loss: 0.0003640\n",
      "Test set: Average loss: 2.1457, Accuracy: 3310/5000 (66%)\n",
      "[epoch 33] loss: 0.0002274\n",
      "Test set: Average loss: 2.2209, Accuracy: 3321/5000 (66%)\n",
      "[epoch 34] loss: 0.0001433\n",
      "Test set: Average loss: 2.2956, Accuracy: 3316/5000 (66%)\n",
      "[epoch 35] loss: 0.0000876\n",
      "Test set: Average loss: 2.3786, Accuracy: 3308/5000 (66%)\n",
      "[epoch 36] loss: 0.0000535\n",
      "Test set: Average loss: 2.4727, Accuracy: 3307/5000 (66%)\n",
      "[epoch 37] loss: 0.0000331\n",
      "Test set: Average loss: 2.5374, Accuracy: 3314/5000 (66%)\n",
      "[epoch 38] loss: 0.0000200\n",
      "Test set: Average loss: 2.6210, Accuracy: 3295/5000 (66%)\n",
      "[epoch 39] loss: 0.0000120\n",
      "Test set: Average loss: 2.7045, Accuracy: 3297/5000 (66%)\n",
      "[epoch 40] loss: 0.0000072\n",
      "Test set: Average loss: 2.7929, Accuracy: 3298/5000 (66%)\n",
      "[epoch 41] loss: 0.0000043\n",
      "Test set: Average loss: 2.8670, Accuracy: 3294/5000 (66%)\n",
      "[epoch 42] loss: 0.0000026\n",
      "Test set: Average loss: 2.9636, Accuracy: 3299/5000 (66%)\n",
      "[epoch 43] loss: 0.0000015\n",
      "Test set: Average loss: 3.0388, Accuracy: 3305/5000 (66%)\n",
      "[epoch 44] loss: 0.0000009\n",
      "Test set: Average loss: 3.0966, Accuracy: 3286/5000 (66%)\n",
      "[epoch 45] loss: 0.0000005\n",
      "Test set: Average loss: 3.1531, Accuracy: 3300/5000 (66%)\n",
      "[epoch 46] loss: 0.0000003\n",
      "Test set: Average loss: 3.1733, Accuracy: 3292/5000 (66%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 3.1879, Accuracy: 3283/5000 (66%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.2070, Accuracy: 3277/5000 (66%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.2225, Accuracy: 3275/5000 (66%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.2294, Accuracy: 3270/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2209, Accuracy: 3321/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.1630, Accuracy: 6699/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 1.4911605\n",
      "Test set: Average loss: 1.2760, Accuracy: 2731/5000 (55%)\n",
      "[epoch 2] loss: 1.2349982\n",
      "Test set: Average loss: 1.1983, Accuracy: 2899/5000 (58%)\n",
      "[epoch 3] loss: 1.1374869\n",
      "Test set: Average loss: 1.1816, Accuracy: 2940/5000 (59%)\n",
      "[epoch 4] loss: 1.0668734\n",
      "Test set: Average loss: 1.1100, Accuracy: 3002/5000 (60%)\n",
      "[epoch 5] loss: 1.0094165\n",
      "Test set: Average loss: 1.0919, Accuracy: 3064/5000 (61%)\n",
      "[epoch 6] loss: 0.9538278\n",
      "Test set: Average loss: 1.0819, Accuracy: 3106/5000 (62%)\n",
      "[epoch 7] loss: 0.8903876\n",
      "Test set: Average loss: 1.0806, Accuracy: 3144/5000 (63%)\n",
      "[epoch 8] loss: 0.8366732\n",
      "Test set: Average loss: 1.0853, Accuracy: 3171/5000 (63%)\n",
      "[epoch 9] loss: 0.7641664\n",
      "Test set: Average loss: 1.0331, Accuracy: 3251/5000 (65%)\n",
      "[epoch 10] loss: 0.6860463\n",
      "Test set: Average loss: 1.1147, Accuracy: 3149/5000 (63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] loss: 0.6083695\n",
      "Test set: Average loss: 1.1386, Accuracy: 3189/5000 (64%)\n",
      "[epoch 12] loss: 0.5214780\n",
      "Test set: Average loss: 1.1647, Accuracy: 3293/5000 (66%)\n",
      "[epoch 13] loss: 0.4321445\n",
      "Test set: Average loss: 1.2251, Accuracy: 3189/5000 (64%)\n",
      "[epoch 14] loss: 0.3537913\n",
      "Test set: Average loss: 1.2755, Accuracy: 3223/5000 (64%)\n",
      "[epoch 15] loss: 0.2951411\n",
      "Test set: Average loss: 1.3681, Accuracy: 3203/5000 (64%)\n",
      "[epoch 16] loss: 0.2486654\n",
      "Test set: Average loss: 1.5161, Accuracy: 3211/5000 (64%)\n",
      "[epoch 17] loss: 0.2024631\n",
      "Test set: Average loss: 1.5817, Accuracy: 3245/5000 (65%)\n",
      "[epoch 18] loss: 0.2018724\n",
      "Test set: Average loss: 1.6549, Accuracy: 3203/5000 (64%)\n",
      "[epoch 19] loss: 0.1881144\n",
      "Test set: Average loss: 1.7172, Accuracy: 3147/5000 (63%)\n",
      "[epoch 20] loss: 0.1810047\n",
      "Test set: Average loss: 1.7849, Accuracy: 3172/5000 (63%)\n",
      "[epoch 21] loss: 0.1532005\n",
      "Test set: Average loss: 1.8086, Accuracy: 3190/5000 (64%)\n",
      "[epoch 22] loss: 0.1723676\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9749, Accuracy: 3086/5000 (62%)\n",
      "[epoch 23] loss: 0.0691070\n",
      "Test set: Average loss: 1.8047, Accuracy: 3198/5000 (64%)\n",
      "[epoch 24] loss: 0.0212775\n",
      "Test set: Average loss: 1.8217, Accuracy: 3207/5000 (64%)\n",
      "[epoch 25] loss: 0.0115781\n",
      "Test set: Average loss: 1.8323, Accuracy: 3219/5000 (64%)\n",
      "[epoch 26] loss: 0.0074422\n",
      "Test set: Average loss: 1.8619, Accuracy: 3230/5000 (65%)\n",
      "[epoch 27] loss: 0.0049328\n",
      "Test set: Average loss: 1.8885, Accuracy: 3239/5000 (65%)\n",
      "[epoch 28] loss: 0.0032868\n",
      "Test set: Average loss: 1.9213, Accuracy: 3246/5000 (65%)\n",
      "[epoch 29] loss: 0.0021451\n",
      "Test set: Average loss: 1.9791, Accuracy: 3263/5000 (65%)\n",
      "[epoch 30] loss: 0.0013888\n",
      "Test set: Average loss: 2.0248, Accuracy: 3266/5000 (65%)\n",
      "[epoch 31] loss: 0.0008856\n",
      "Test set: Average loss: 2.0775, Accuracy: 3272/5000 (65%)\n",
      "[epoch 32] loss: 0.0005608\n",
      "Test set: Average loss: 2.1397, Accuracy: 3283/5000 (66%)\n",
      "[epoch 33] loss: 0.0003483\n",
      "Test set: Average loss: 2.2065, Accuracy: 3279/5000 (66%)\n",
      "[epoch 34] loss: 0.0002178\n",
      "Test set: Average loss: 2.2725, Accuracy: 3276/5000 (66%)\n",
      "[epoch 35] loss: 0.0001336\n",
      "Test set: Average loss: 2.3508, Accuracy: 3302/5000 (66%)\n",
      "[epoch 36] loss: 0.0000816\n",
      "Test set: Average loss: 2.4223, Accuracy: 3286/5000 (66%)\n",
      "[epoch 37] loss: 0.0000498\n",
      "Test set: Average loss: 2.5066, Accuracy: 3292/5000 (66%)\n",
      "[epoch 38] loss: 0.0000300\n",
      "Test set: Average loss: 2.5782, Accuracy: 3293/5000 (66%)\n",
      "[epoch 39] loss: 0.0000180\n",
      "Test set: Average loss: 2.6662, Accuracy: 3292/5000 (66%)\n",
      "[epoch 40] loss: 0.0000107\n",
      "Test set: Average loss: 2.7381, Accuracy: 3295/5000 (66%)\n",
      "[epoch 41] loss: 0.0000064\n",
      "Test set: Average loss: 2.8282, Accuracy: 3281/5000 (66%)\n",
      "[epoch 42] loss: 0.0000038\n",
      "Test set: Average loss: 2.9050, Accuracy: 3286/5000 (66%)\n",
      "[epoch 43] loss: 0.0000023\n",
      "Test set: Average loss: 2.9826, Accuracy: 3274/5000 (65%)\n",
      "[epoch 44] loss: 0.0000013\n",
      "Test set: Average loss: 3.0679, Accuracy: 3287/5000 (66%)\n",
      "[epoch 45] loss: 0.0000008\n",
      "Test set: Average loss: 3.1172, Accuracy: 3281/5000 (66%)\n",
      "[epoch 46] loss: 0.0000004\n",
      "Test set: Average loss: 3.1547, Accuracy: 3283/5000 (66%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 3.1741, Accuracy: 3269/5000 (65%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.1839, Accuracy: 3268/5000 (65%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.2140, Accuracy: 3272/5000 (65%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.2108, Accuracy: 3261/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3508, Accuracy: 3302/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.3459, Accuracy: 6666/10000 (67%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 499/5000 (10%)\n",
      "[epoch 1] loss: 1.5125901\n",
      "Test set: Average loss: 1.4184, Accuracy: 2479/5000 (50%)\n",
      "[epoch 2] loss: 1.2908167\n",
      "Test set: Average loss: 1.2920, Accuracy: 2685/5000 (54%)\n",
      "[epoch 3] loss: 1.2096710\n",
      "Test set: Average loss: 1.2769, Accuracy: 2730/5000 (55%)\n",
      "[epoch 4] loss: 1.1372143\n",
      "Test set: Average loss: 1.1557, Accuracy: 2935/5000 (59%)\n",
      "[epoch 5] loss: 1.0798989\n",
      "Test set: Average loss: 1.1607, Accuracy: 3005/5000 (60%)\n",
      "[epoch 6] loss: 1.0280736\n",
      "Test set: Average loss: 1.1286, Accuracy: 3028/5000 (61%)\n",
      "[epoch 7] loss: 0.9827968\n",
      "Test set: Average loss: 1.0843, Accuracy: 3115/5000 (62%)\n",
      "[epoch 8] loss: 0.9381430\n",
      "Test set: Average loss: 1.0589, Accuracy: 3150/5000 (63%)\n",
      "[epoch 9] loss: 0.8823237\n",
      "Test set: Average loss: 1.1026, Accuracy: 3118/5000 (62%)\n",
      "[epoch 10] loss: 0.8276234\n",
      "Test set: Average loss: 1.1667, Accuracy: 3040/5000 (61%)\n",
      "[epoch 11] loss: 0.7721358\n",
      "Test set: Average loss: 1.0652, Accuracy: 3169/5000 (63%)\n",
      "[epoch 12] loss: 0.7048876\n",
      "Test set: Average loss: 1.0449, Accuracy: 3257/5000 (65%)\n",
      "[epoch 13] loss: 0.6454724\n",
      "Test set: Average loss: 1.0876, Accuracy: 3231/5000 (65%)\n",
      "[epoch 14] loss: 0.5757217\n",
      "Test set: Average loss: 1.1330, Accuracy: 3220/5000 (64%)\n",
      "[epoch 15] loss: 0.5126927\n",
      "Test set: Average loss: 1.2087, Accuracy: 3153/5000 (63%)\n",
      "[epoch 16] loss: 0.4486473\n",
      "Test set: Average loss: 1.2218, Accuracy: 3204/5000 (64%)\n",
      "[epoch 17] loss: 0.3973085\n",
      "Test set: Average loss: 1.3268, Accuracy: 3179/5000 (64%)\n",
      "[epoch 18] loss: 0.3410876\n",
      "Test set: Average loss: 1.3504, Accuracy: 3155/5000 (63%)\n",
      "[epoch 19] loss: 0.3079067\n",
      "Test set: Average loss: 1.4983, Accuracy: 3118/5000 (62%)\n",
      "[epoch 20] loss: 0.2780106\n",
      "Test set: Average loss: 1.4907, Accuracy: 3215/5000 (64%)\n",
      "[epoch 21] loss: 0.2510577\n",
      "Test set: Average loss: 1.6074, Accuracy: 3154/5000 (63%)\n",
      "[epoch 22] loss: 0.2426134\n",
      "Test set: Average loss: 1.6460, Accuracy: 3149/5000 (63%)\n",
      "[epoch 23] loss: 0.2374835\n",
      "Test set: Average loss: 1.6817, Accuracy: 3157/5000 (63%)\n",
      "[epoch 24] loss: 0.2075595\n",
      "Test set: Average loss: 1.6899, Accuracy: 3108/5000 (62%)\n",
      "[epoch 25] loss: 0.2274932\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7599, Accuracy: 3124/5000 (62%)\n",
      "[epoch 26] loss: 0.0869705\n",
      "Test set: Average loss: 1.6658, Accuracy: 3233/5000 (65%)\n",
      "[epoch 27] loss: 0.0346128\n",
      "Test set: Average loss: 1.6737, Accuracy: 3247/5000 (65%)\n",
      "[epoch 28] loss: 0.0200344\n",
      "Test set: Average loss: 1.6953, Accuracy: 3264/5000 (65%)\n",
      "[epoch 29] loss: 0.0128783\n",
      "Test set: Average loss: 1.7232, Accuracy: 3262/5000 (65%)\n",
      "[epoch 30] loss: 0.0085587\n",
      "Test set: Average loss: 1.7557, Accuracy: 3267/5000 (65%)\n",
      "[epoch 31] loss: 0.0056821\n",
      "Test set: Average loss: 1.8080, Accuracy: 3280/5000 (66%)\n",
      "[epoch 32] loss: 0.0037983\n",
      "Test set: Average loss: 1.8493, Accuracy: 3273/5000 (65%)\n",
      "[epoch 33] loss: 0.0024801\n",
      "Test set: Average loss: 1.9083, Accuracy: 3277/5000 (66%)\n",
      "[epoch 34] loss: 0.0016287\n",
      "Test set: Average loss: 1.9596, Accuracy: 3280/5000 (66%)\n",
      "[epoch 35] loss: 0.0010631\n",
      "Test set: Average loss: 2.0261, Accuracy: 3264/5000 (65%)\n",
      "[epoch 36] loss: 0.0006822\n",
      "Test set: Average loss: 2.0908, Accuracy: 3263/5000 (65%)\n",
      "[epoch 37] loss: 0.0004347\n",
      "Test set: Average loss: 2.1599, Accuracy: 3261/5000 (65%)\n",
      "[epoch 38] loss: 0.0002775\n",
      "Test set: Average loss: 2.2299, Accuracy: 3274/5000 (65%)\n",
      "[epoch 39] loss: 0.0001762\n",
      "Test set: Average loss: 2.3087, Accuracy: 3268/5000 (65%)\n",
      "[epoch 40] loss: 0.0001106\n",
      "Test set: Average loss: 2.3759, Accuracy: 3277/5000 (66%)\n",
      "[epoch 41] loss: 0.0000685\n",
      "Test set: Average loss: 2.4561, Accuracy: 3264/5000 (65%)\n",
      "[epoch 42] loss: 0.0000430\n",
      "Test set: Average loss: 2.5431, Accuracy: 3276/5000 (66%)\n",
      "[epoch 43] loss: 0.0000270\n",
      "Test set: Average loss: 2.6279, Accuracy: 3272/5000 (65%)\n",
      "[epoch 44] loss: 0.0000161\n",
      "Test set: Average loss: 2.6969, Accuracy: 3275/5000 (66%)\n",
      "[epoch 45] loss: 0.0000099\n",
      "Test set: Average loss: 2.7748, Accuracy: 3281/5000 (66%)\n",
      "[epoch 46] loss: 0.0000061\n",
      "Test set: Average loss: 2.8664, Accuracy: 3285/5000 (66%)\n",
      "[epoch 47] loss: 0.0000036\n",
      "Test set: Average loss: 2.9494, Accuracy: 3289/5000 (66%)\n",
      "[epoch 48] loss: 0.0000021\n",
      "Test set: Average loss: 3.0289, Accuracy: 3280/5000 (66%)\n",
      "[epoch 49] loss: 0.0000013\n",
      "Test set: Average loss: 3.1020, Accuracy: 3296/5000 (66%)\n",
      "[epoch 50] loss: 0.0000008\n",
      "Test set: Average loss: 3.1556, Accuracy: 3290/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.1020, Accuracy: 3296/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 3.0697, Accuracy: 6603/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3027, Accuracy: 493/5000 (10%)\n",
      "[epoch 1] loss: 1.4745490\n",
      "Test set: Average loss: 1.3106, Accuracy: 2657/5000 (53%)\n",
      "[epoch 2] loss: 1.2273912\n",
      "Test set: Average loss: 1.2023, Accuracy: 2891/5000 (58%)\n",
      "[epoch 3] loss: 1.1254647\n",
      "Test set: Average loss: 1.2163, Accuracy: 2920/5000 (58%)\n",
      "[epoch 4] loss: 1.0544912\n",
      "Test set: Average loss: 1.1261, Accuracy: 3024/5000 (60%)\n",
      "[epoch 5] loss: 0.9898524\n",
      "Test set: Average loss: 1.1946, Accuracy: 2947/5000 (59%)\n",
      "[epoch 6] loss: 0.9326719\n",
      "Test set: Average loss: 1.0775, Accuracy: 3113/5000 (62%)\n",
      "[epoch 7] loss: 0.8758070\n",
      "Test set: Average loss: 1.0376, Accuracy: 3206/5000 (64%)\n",
      "[epoch 8] loss: 0.8059601\n",
      "Test set: Average loss: 1.0266, Accuracy: 3265/5000 (65%)\n",
      "[epoch 9] loss: 0.7375646\n",
      "Test set: Average loss: 0.9967, Accuracy: 3314/5000 (66%)\n",
      "[epoch 10] loss: 0.6635323\n",
      "Test set: Average loss: 1.0282, Accuracy: 3325/5000 (66%)\n",
      "[epoch 11] loss: 0.6019562\n",
      "Test set: Average loss: 1.0439, Accuracy: 3341/5000 (67%)\n",
      "[epoch 12] loss: 0.5225057\n",
      "Test set: Average loss: 1.0785, Accuracy: 3306/5000 (66%)\n",
      "[epoch 13] loss: 0.4507926\n",
      "Test set: Average loss: 1.1949, Accuracy: 3236/5000 (65%)\n",
      "[epoch 14] loss: 0.3885908\n",
      "Test set: Average loss: 1.2032, Accuracy: 3300/5000 (66%)\n",
      "[epoch 15] loss: 0.3355540\n",
      "Test set: Average loss: 1.3572, Accuracy: 3261/5000 (65%)\n",
      "[epoch 16] loss: 0.2961421\n",
      "Test set: Average loss: 1.3591, Accuracy: 3281/5000 (66%)\n",
      "[epoch 17] loss: 0.2574468\n",
      "Test set: Average loss: 1.4494, Accuracy: 3265/5000 (65%)\n",
      "[epoch 18] loss: 0.2468725\n",
      "Test set: Average loss: 1.4875, Accuracy: 3254/5000 (65%)\n",
      "[epoch 19] loss: 0.2141043\n",
      "Test set: Average loss: 1.5425, Accuracy: 3264/5000 (65%)\n",
      "[epoch 20] loss: 0.2128477\n",
      "Test set: Average loss: 1.6557, Accuracy: 3228/5000 (65%)\n",
      "[epoch 21] loss: 0.2016959\n",
      "Test set: Average loss: 1.6761, Accuracy: 3231/5000 (65%)\n",
      "[epoch 22] loss: 0.1817652\n",
      "Test set: Average loss: 1.6959, Accuracy: 3236/5000 (65%)\n",
      "[epoch 23] loss: 0.1852632\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6964, Accuracy: 3238/5000 (65%)\n",
      "[epoch 24] loss: 0.0702195\n",
      "Test set: Average loss: 1.6291, Accuracy: 3324/5000 (66%)\n",
      "[epoch 25] loss: 0.0250238\n",
      "Test set: Average loss: 1.6437, Accuracy: 3328/5000 (67%)\n",
      "[epoch 26] loss: 0.0137002\n",
      "Test set: Average loss: 1.6668, Accuracy: 3329/5000 (67%)\n",
      "[epoch 27] loss: 0.0085005\n",
      "Test set: Average loss: 1.6917, Accuracy: 3344/5000 (67%)\n",
      "[epoch 28] loss: 0.0054963\n",
      "Test set: Average loss: 1.7299, Accuracy: 3357/5000 (67%)\n",
      "[epoch 29] loss: 0.0035307\n",
      "Test set: Average loss: 1.7732, Accuracy: 3351/5000 (67%)\n",
      "[epoch 30] loss: 0.0022287\n",
      "Test set: Average loss: 1.8235, Accuracy: 3356/5000 (67%)\n",
      "[epoch 31] loss: 0.0013977\n",
      "Test set: Average loss: 1.8880, Accuracy: 3363/5000 (67%)\n",
      "[epoch 32] loss: 0.0008724\n",
      "Test set: Average loss: 1.9506, Accuracy: 3362/5000 (67%)\n",
      "[epoch 33] loss: 0.0005352\n",
      "Test set: Average loss: 2.0101, Accuracy: 3368/5000 (67%)\n",
      "[epoch 34] loss: 0.0003268\n",
      "Test set: Average loss: 2.0829, Accuracy: 3370/5000 (67%)\n",
      "[epoch 35] loss: 0.0002011\n",
      "Test set: Average loss: 2.1554, Accuracy: 3368/5000 (67%)\n",
      "[epoch 36] loss: 0.0001223\n",
      "Test set: Average loss: 2.2283, Accuracy: 3377/5000 (68%)\n",
      "[epoch 37] loss: 0.0000717\n",
      "Test set: Average loss: 2.3026, Accuracy: 3379/5000 (68%)\n",
      "[epoch 38] loss: 0.0000427\n",
      "Test set: Average loss: 2.3861, Accuracy: 3376/5000 (68%)\n",
      "[epoch 39] loss: 0.0000250\n",
      "Test set: Average loss: 2.4608, Accuracy: 3388/5000 (68%)\n",
      "[epoch 40] loss: 0.0000147\n",
      "Test set: Average loss: 2.5440, Accuracy: 3388/5000 (68%)\n",
      "[epoch 41] loss: 0.0000084\n",
      "Test set: Average loss: 2.6329, Accuracy: 3379/5000 (68%)\n",
      "[epoch 42] loss: 0.0000049\n",
      "Test set: Average loss: 2.7155, Accuracy: 3380/5000 (68%)\n",
      "[epoch 43] loss: 0.0000028\n",
      "Test set: Average loss: 2.7970, Accuracy: 3384/5000 (68%)\n",
      "[epoch 44] loss: 0.0000016\n",
      "Test set: Average loss: 2.8752, Accuracy: 3385/5000 (68%)\n",
      "[epoch 45] loss: 0.0000009\n",
      "Test set: Average loss: 2.9342, Accuracy: 3375/5000 (68%)\n",
      "[epoch 46] loss: 0.0000005\n",
      "Test set: Average loss: 2.9760, Accuracy: 3389/5000 (68%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 3.0025, Accuracy: 3373/5000 (67%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.0113, Accuracy: 3378/5000 (68%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0458, Accuracy: 3365/5000 (67%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.0453, Accuracy: 3371/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9760, Accuracy: 3389/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.9558, Accuracy: 6800/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 524/5000 (10%)\n",
      "[epoch 1] loss: 1.4854150\n",
      "Test set: Average loss: 1.3178, Accuracy: 2638/5000 (53%)\n",
      "[epoch 2] loss: 1.2268036\n",
      "Test set: Average loss: 1.2050, Accuracy: 2792/5000 (56%)\n",
      "[epoch 3] loss: 1.1374218\n",
      "Test set: Average loss: 1.1747, Accuracy: 2945/5000 (59%)\n",
      "[epoch 4] loss: 1.0737800\n",
      "Test set: Average loss: 1.1222, Accuracy: 3014/5000 (60%)\n",
      "[epoch 5] loss: 1.0190240\n",
      "Test set: Average loss: 1.0994, Accuracy: 3056/5000 (61%)\n",
      "[epoch 6] loss: 0.9639231\n",
      "Test set: Average loss: 1.1460, Accuracy: 3023/5000 (60%)\n",
      "[epoch 7] loss: 0.9124389\n",
      "Test set: Average loss: 1.1286, Accuracy: 3053/5000 (61%)\n",
      "[epoch 8] loss: 0.8490235\n",
      "Test set: Average loss: 1.0654, Accuracy: 3211/5000 (64%)\n",
      "[epoch 9] loss: 0.7895645\n",
      "Test set: Average loss: 1.0198, Accuracy: 3235/5000 (65%)\n",
      "[epoch 10] loss: 0.7227928\n",
      "Test set: Average loss: 1.0486, Accuracy: 3269/5000 (65%)\n",
      "[epoch 11] loss: 0.6512935\n",
      "Test set: Average loss: 1.1230, Accuracy: 3210/5000 (64%)\n",
      "[epoch 12] loss: 0.5862403\n",
      "Test set: Average loss: 1.1674, Accuracy: 3212/5000 (64%)\n",
      "[epoch 13] loss: 0.5068493\n",
      "Test set: Average loss: 1.1982, Accuracy: 3220/5000 (64%)\n",
      "[epoch 14] loss: 0.4420590\n",
      "Test set: Average loss: 1.2351, Accuracy: 3269/5000 (65%)\n",
      "[epoch 15] loss: 0.3738138\n",
      "Test set: Average loss: 1.2740, Accuracy: 3210/5000 (64%)\n",
      "[epoch 16] loss: 0.3166688\n",
      "Test set: Average loss: 1.4049, Accuracy: 3195/5000 (64%)\n",
      "[epoch 17] loss: 0.3010563\n",
      "Test set: Average loss: 1.4295, Accuracy: 3195/5000 (64%)\n",
      "[epoch 18] loss: 0.2492215\n",
      "Test set: Average loss: 1.5548, Accuracy: 3197/5000 (64%)\n",
      "[epoch 19] loss: 0.2500043\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5499, Accuracy: 3233/5000 (65%)\n",
      "[epoch 20] loss: 0.0969713\n",
      "Test set: Average loss: 1.4742, Accuracy: 3292/5000 (66%)\n",
      "[epoch 21] loss: 0.0558390\n",
      "Test set: Average loss: 1.4879, Accuracy: 3290/5000 (66%)\n",
      "[epoch 22] loss: 0.0281409\n",
      "Test set: Average loss: 1.5088, Accuracy: 3303/5000 (66%)\n",
      "[epoch 23] loss: 0.0178936\n",
      "Test set: Average loss: 1.5485, Accuracy: 3330/5000 (67%)\n",
      "[epoch 24] loss: 0.0120009\n",
      "Test set: Average loss: 1.5939, Accuracy: 3313/5000 (66%)\n",
      "[epoch 25] loss: 0.0080191\n",
      "Test set: Average loss: 1.6462, Accuracy: 3328/5000 (67%)\n",
      "[epoch 26] loss: 0.0052214\n",
      "Test set: Average loss: 1.7014, Accuracy: 3343/5000 (67%)\n",
      "[epoch 27] loss: 0.0033990\n",
      "Test set: Average loss: 1.7612, Accuracy: 3332/5000 (67%)\n",
      "[epoch 28] loss: 0.0021938\n",
      "Test set: Average loss: 1.8333, Accuracy: 3334/5000 (67%)\n",
      "[epoch 29] loss: 0.0013939\n",
      "Test set: Average loss: 1.8922, Accuracy: 3334/5000 (67%)\n",
      "[epoch 30] loss: 0.0008798\n",
      "Test set: Average loss: 1.9620, Accuracy: 3333/5000 (67%)\n",
      "[epoch 31] loss: 0.0005475\n",
      "Test set: Average loss: 2.0344, Accuracy: 3336/5000 (67%)\n",
      "[epoch 32] loss: 0.0003385\n",
      "Test set: Average loss: 2.1163, Accuracy: 3343/5000 (67%)\n",
      "[epoch 33] loss: 0.0002064\n",
      "Test set: Average loss: 2.1944, Accuracy: 3330/5000 (67%)\n",
      "[epoch 34] loss: 0.0001260\n",
      "Test set: Average loss: 2.2811, Accuracy: 3337/5000 (67%)\n",
      "[epoch 35] loss: 0.0000766\n",
      "Test set: Average loss: 2.3730, Accuracy: 3345/5000 (67%)\n",
      "[epoch 36] loss: 0.0000456\n",
      "Test set: Average loss: 2.4571, Accuracy: 3330/5000 (67%)\n",
      "[epoch 37] loss: 0.0000271\n",
      "Test set: Average loss: 2.5426, Accuracy: 3327/5000 (67%)\n",
      "[epoch 38] loss: 0.0000160\n",
      "Test set: Average loss: 2.6316, Accuracy: 3334/5000 (67%)\n",
      "[epoch 39] loss: 0.0000095\n",
      "Test set: Average loss: 2.7187, Accuracy: 3324/5000 (66%)\n",
      "[epoch 40] loss: 0.0000055\n",
      "Test set: Average loss: 2.8207, Accuracy: 3337/5000 (67%)\n",
      "[epoch 41] loss: 0.0000032\n",
      "Test set: Average loss: 2.9069, Accuracy: 3339/5000 (67%)\n",
      "[epoch 42] loss: 0.0000018\n",
      "Test set: Average loss: 2.9834, Accuracy: 3339/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 43] loss: 0.0000010\n",
      "Test set: Average loss: 3.0630, Accuracy: 3334/5000 (67%)\n",
      "[epoch 44] loss: 0.0000006\n",
      "Test set: Average loss: 3.1218, Accuracy: 3339/5000 (67%)\n",
      "[epoch 45] loss: 0.0000004\n",
      "Test set: Average loss: 3.1422, Accuracy: 3341/5000 (67%)\n",
      "[epoch 46] loss: 0.0000003\n",
      "Test set: Average loss: 3.1634, Accuracy: 3328/5000 (67%)\n",
      "[epoch 47] loss: 0.0013147\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2719, Accuracy: 3298/5000 (66%)\n",
      "[epoch 48] loss: 0.0002467\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2467, Accuracy: 3290/5000 (66%)\n",
      "[epoch 49] loss: 0.0000494\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2462, Accuracy: 3289/5000 (66%)\n",
      "[epoch 50] loss: 0.0000479\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2462, Accuracy: 3289/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3730, Accuracy: 3345/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.3496, Accuracy: 6776/10000 (68%)\n"
     ]
    }
   ],
   "source": [
    "# train the SimEc\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = SimilarityEncoder(cnn, 512, n_targets)\n",
    "model.fit(X, S, epochs=50, lr=0.000001, s_ll_reg=100., S_ll=S_ll, orth_reg=0.1)\n",
    "print(check_similarity_match(model.predict(X[:n_targets]), S_ll, X_embed_is_S_approx=True))\n",
    "print(check_similarity_match(model.transform(X[:n_targets]), S_ll))\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.model.embedding_net.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_se = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_se.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:21:29.859146Z",
     "start_time": "2019-07-24T12:21:17.623521Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute supervised simmat for T1\n",
    "X = np.stack([train_dataset.transform(train_dataset.data[i]).numpy() for i in indices])\n",
    "X_flat = X.reshape(X.shape[0], 3*32*32)\n",
    "S_lin = linear_kernel(X_flat, X_flat[:n_targets])\n",
    "del X_flat\n",
    "S_lin -= S_lin.min()\n",
    "S_lin /= S_lin.max()\n",
    "y = np.stack([train_dataset.targets[i] for i in indices])\n",
    "Y = np.tile(y[:n_targets], (len(y), 1))\n",
    "YT =  np.tile(np.array([y]).T, (1, n_targets))\n",
    "S_class = np.array(Y==YT, dtype=float)\n",
    "S = S_class\n",
    "S_ll = S[:n_targets, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:21:44.209718Z",
     "start_time": "2019-07-24T12:21:29.860454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1905550312906126e-05, 0.9997627882102682, 0.5204542648105146)\n"
     ]
    }
   ],
   "source": [
    "# check what the similarity approximation *should* be\n",
    "D, V = np.linalg.eig(S_ll)\n",
    "D, V = D[np.argsort(D)[::-1]], V[:,np.argsort(D)[::-1]]\n",
    "X_embed = np.dot(V.real, np.diag(np.sqrt(np.abs(D.real))))\n",
    "print(check_similarity_match(X_embed[:n_targets,:512], S_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T15:15:25.357120Z",
     "start_time": "2019-07-24T12:21:44.210996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.0751050\n",
      "[epoch 2] loss: 0.0697562\n",
      "[epoch 3] loss: 0.0678466\n",
      "[epoch 4] loss: 0.0665919\n",
      "[epoch 5] loss: 0.0656834\n",
      "[epoch 6] loss: 0.0649082\n",
      "[epoch 7] loss: 0.0642564\n",
      "[epoch 8] loss: 0.0637431\n",
      "[epoch 9] loss: 0.0632920\n",
      "[epoch 10] loss: 0.0629243\n",
      "[epoch 11] loss: 0.0626229\n",
      "[epoch 12] loss: 0.0623169\n",
      "[epoch 13] loss: 0.0620236\n",
      "[epoch 14] loss: 0.0618103\n",
      "[epoch 15] loss: 0.0616050\n",
      "[epoch 16] loss: 0.0613579\n",
      "[epoch 17] loss: 0.0611213\n",
      "[epoch 18] loss: 0.0608967\n",
      "[epoch 19] loss: 0.0612758\n",
      "[epoch 20] loss: 0.0605431\n",
      "[epoch 21] loss: 0.0601227\n",
      "[epoch 22] loss: 0.0598974\n",
      "[epoch 23] loss: 0.0596721\n",
      "[epoch 24] loss: 0.0595029\n",
      "[epoch 25] loss: 0.0594033\n",
      "[epoch 26] loss: 0.0592993\n",
      "[epoch 27] loss: 0.0592249\n",
      "[epoch 28] loss: 0.0591504\n",
      "[epoch 29] loss: 0.0590719\n",
      "[epoch 30] loss: 0.0589968\n",
      "[epoch 31] loss: 0.0589297\n",
      "[epoch 32] loss: 0.0588516\n",
      "[epoch 33] loss: 0.0588130\n",
      "[epoch 34] loss: 0.0587213\n",
      "[epoch 35] loss: 0.0587021\n",
      "[epoch 36] loss: 0.0586322\n",
      "[epoch 37] loss: 0.0585578\n",
      "[epoch 38] loss: 0.0585131\n",
      "[epoch 39] loss: 0.0584641\n",
      "[epoch 40] loss: 0.0584513\n",
      "[epoch 41] loss: 0.0583534\n",
      "[epoch 42] loss: 0.0583298\n",
      "[epoch 43] loss: 0.0582295\n",
      "[epoch 44] loss: 0.0582397\n",
      "[epoch 45] loss: 0.0581562\n",
      "[epoch 46] loss: 0.0580969\n",
      "[epoch 47] loss: 0.0581076\n",
      "[epoch 48] loss: 0.0580621\n",
      "[epoch 49] loss: 0.0579694\n",
      "[epoch 50] loss: 0.0579478\n",
      "(0.058258691509707285, 0.3545515243603156, 0.4437450231315159)\n",
      "(0.39770715945776075, 0.09292074475596461, 0.2766027772186752)\n",
      "Took 903 sec to train.\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3064, Accuracy: 204/5000 (4%)\n",
      "[epoch 1] loss: 2.3017550\n",
      "Test set: Average loss: 2.2697, Accuracy: 874/5000 (17%)\n",
      "[epoch 2] loss: 2.1469674\n",
      "Test set: Average loss: 2.2222, Accuracy: 898/5000 (18%)\n",
      "[epoch 3] loss: 1.9360328\n",
      "Test set: Average loss: 2.1911, Accuracy: 871/5000 (17%)\n",
      "[epoch 4] loss: 1.7090600\n",
      "Test set: Average loss: 2.1969, Accuracy: 953/5000 (19%)\n",
      "[epoch 5] loss: 1.5365471\n",
      "Test set: Average loss: 2.1481, Accuracy: 1081/5000 (22%)\n",
      "[epoch 6] loss: 1.3390311\n",
      "Test set: Average loss: 2.1165, Accuracy: 1135/5000 (23%)\n",
      "[epoch 7] loss: 1.1406876\n",
      "Test set: Average loss: 2.1534, Accuracy: 1263/5000 (25%)\n",
      "[epoch 8] loss: 0.9833964\n",
      "Test set: Average loss: 2.1617, Accuracy: 1342/5000 (27%)\n",
      "[epoch 9] loss: 0.8059363\n",
      "Test set: Average loss: 2.1526, Accuracy: 1369/5000 (27%)\n",
      "[epoch 10] loss: 0.6325209\n",
      "Test set: Average loss: 2.1673, Accuracy: 1413/5000 (28%)\n",
      "[epoch 11] loss: 0.4887234\n",
      "Test set: Average loss: 2.2243, Accuracy: 1438/5000 (29%)\n",
      "[epoch 12] loss: 0.3679660\n",
      "Test set: Average loss: 2.3206, Accuracy: 1399/5000 (28%)\n",
      "[epoch 13] loss: 0.2713256\n",
      "Test set: Average loss: 2.4151, Accuracy: 1385/5000 (28%)\n",
      "[epoch 14] loss: 0.1937529\n",
      "Test set: Average loss: 2.4885, Accuracy: 1397/5000 (28%)\n",
      "[epoch 15] loss: 0.1318111\n",
      "Test set: Average loss: 2.5519, Accuracy: 1451/5000 (29%)\n",
      "[epoch 16] loss: 0.0837247\n",
      "Test set: Average loss: 2.6253, Accuracy: 1476/5000 (30%)\n",
      "[epoch 17] loss: 0.0505103\n",
      "Test set: Average loss: 2.7277, Accuracy: 1483/5000 (30%)\n",
      "[epoch 18] loss: 0.0317554\n",
      "Test set: Average loss: 2.8571, Accuracy: 1480/5000 (30%)\n",
      "[epoch 19] loss: 0.0221795\n",
      "Test set: Average loss: 2.9938, Accuracy: 1474/5000 (29%)\n",
      "[epoch 20] loss: 0.0164091\n",
      "Test set: Average loss: 3.1204, Accuracy: 1466/5000 (29%)\n",
      "[epoch 21] loss: 0.0120103\n",
      "Test set: Average loss: 3.2311, Accuracy: 1471/5000 (29%)\n",
      "[epoch 22] loss: 0.0085559\n",
      "Test set: Average loss: 3.3283, Accuracy: 1464/5000 (29%)\n",
      "[epoch 23] loss: 0.0060795\n",
      "Test set: Average loss: 3.4165, Accuracy: 1469/5000 (29%)\n",
      "[epoch 24] loss: 0.0044036\n",
      "Test set: Average loss: 3.4990, Accuracy: 1478/5000 (30%)\n",
      "[epoch 25] loss: 0.0032725\n",
      "Test set: Average loss: 3.5778, Accuracy: 1479/5000 (30%)\n",
      "[epoch 26] loss: 0.0024926\n",
      "Test set: Average loss: 3.6537, Accuracy: 1467/5000 (29%)\n",
      "[epoch 27] loss: 0.0019401\n",
      "Test set: Average loss: 3.7273, Accuracy: 1458/5000 (29%)\n",
      "[epoch 28] loss: 0.0015409\n",
      "Test set: Average loss: 3.7985, Accuracy: 1450/5000 (29%)\n",
      "[epoch 29] loss: 0.0012493\n",
      "Test set: Average loss: 3.8673, Accuracy: 1440/5000 (29%)\n",
      "[epoch 30] loss: 0.0010341\n",
      "Test set: Average loss: 3.9336, Accuracy: 1432/5000 (29%)\n",
      "[epoch 31] loss: 0.0008740\n",
      "Test set: Average loss: 3.9970, Accuracy: 1418/5000 (28%)\n",
      "[epoch 32] loss: 0.0007529\n",
      "Test set: Average loss: 4.0575, Accuracy: 1421/5000 (28%)\n",
      "[epoch 33] loss: 0.0006603\n",
      "Test set: Average loss: 4.1150, Accuracy: 1414/5000 (28%)\n",
      "[epoch 34] loss: 0.0005883\n",
      "Test set: Average loss: 4.1693, Accuracy: 1405/5000 (28%)\n",
      "[epoch 35] loss: 0.0005307\n",
      "Test set: Average loss: 4.2204, Accuracy: 1398/5000 (28%)\n",
      "[epoch 36] loss: 0.0004840\n",
      "Test set: Average loss: 4.2684, Accuracy: 1396/5000 (28%)\n",
      "[epoch 37] loss: 0.0004457\n",
      "Test set: Average loss: 4.3134, Accuracy: 1392/5000 (28%)\n",
      "[epoch 38] loss: 0.0004135\n",
      "Test set: Average loss: 4.3553, Accuracy: 1386/5000 (28%)\n",
      "[epoch 39] loss: 0.0003860\n",
      "Test set: Average loss: 4.3944, Accuracy: 1381/5000 (28%)\n",
      "[epoch 40] loss: 0.0003623\n",
      "Test set: Average loss: 4.4308, Accuracy: 1378/5000 (28%)\n",
      "[epoch 41] loss: 0.0003411\n",
      "Test set: Average loss: 4.4646, Accuracy: 1377/5000 (28%)\n",
      "[epoch 42] loss: 0.0003226\n",
      "Test set: Average loss: 4.4959, Accuracy: 1370/5000 (27%)\n",
      "[epoch 43] loss: 0.0003059\n",
      "Test set: Average loss: 4.5249, Accuracy: 1376/5000 (28%)\n",
      "[epoch 44] loss: 0.0002909\n",
      "Test set: Average loss: 4.5518, Accuracy: 1378/5000 (28%)\n",
      "[epoch 45] loss: 0.0002771\n",
      "Test set: Average loss: 4.5767, Accuracy: 1374/5000 (27%)\n",
      "[epoch 46] loss: 0.0002646\n",
      "Test set: Average loss: 4.5997, Accuracy: 1373/5000 (27%)\n",
      "[epoch 47] loss: 0.0002531\n",
      "Test set: Average loss: 4.6211, Accuracy: 1374/5000 (27%)\n",
      "[epoch 48] loss: 0.0002427\n",
      "Test set: Average loss: 4.6408, Accuracy: 1374/5000 (27%)\n",
      "[epoch 49] loss: 0.0002330\n",
      "Test set: Average loss: 4.6591, Accuracy: 1379/5000 (28%)\n",
      "[epoch 50] loss: 0.0002241\n",
      "Test set: Average loss: 4.6760, Accuracy: 1378/5000 (28%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7277, Accuracy: 1483/5000 (30%)\n",
      "Test\n",
      "Test set: Average loss: 2.6919, Accuracy: 2972/10000 (30%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3069, Accuracy: 389/5000 (8%)\n",
      "[epoch 1] loss: 2.3058550\n",
      "Test set: Average loss: 2.2646, Accuracy: 1525/5000 (30%)\n",
      "[epoch 2] loss: 2.1756315\n",
      "Test set: Average loss: 2.2158, Accuracy: 1812/5000 (36%)\n",
      "[epoch 3] loss: 2.0108955\n",
      "Test set: Average loss: 2.1645, Accuracy: 1734/5000 (35%)\n",
      "[epoch 4] loss: 1.7885773\n",
      "Test set: Average loss: 2.1399, Accuracy: 1573/5000 (31%)\n",
      "[epoch 5] loss: 1.5308146\n",
      "Test set: Average loss: 2.1789, Accuracy: 1505/5000 (30%)\n",
      "[epoch 6] loss: 1.2837682\n",
      "Test set: Average loss: 2.2574, Accuracy: 1519/5000 (30%)\n",
      "[epoch 7] loss: 1.0610545\n",
      "Test set: Average loss: 2.3028, Accuracy: 1583/5000 (32%)\n",
      "[epoch 8] loss: 0.8470088\n",
      "Test set: Average loss: 2.3067, Accuracy: 1566/5000 (31%)\n",
      "[epoch 9] loss: 0.6404279\n",
      "Test set: Average loss: 2.3054, Accuracy: 1581/5000 (32%)\n",
      "[epoch 10] loss: 0.4555824\n",
      "Test set: Average loss: 2.3416, Accuracy: 1679/5000 (34%)\n",
      "[epoch 11] loss: 0.3103714\n",
      "Test set: Average loss: 2.4373, Accuracy: 1667/5000 (33%)\n",
      "[epoch 12] loss: 0.2150031\n",
      "Test set: Average loss: 2.5726, Accuracy: 1604/5000 (32%)\n",
      "[epoch 13] loss: 0.1460608\n",
      "Test set: Average loss: 2.7272, Accuracy: 1564/5000 (31%)\n",
      "[epoch 14] loss: 0.0943949\n",
      "Test set: Average loss: 2.8909, Accuracy: 1538/5000 (31%)\n",
      "[epoch 15] loss: 0.0606942\n",
      "Test set: Average loss: 3.0471, Accuracy: 1533/5000 (31%)\n",
      "[epoch 16] loss: 0.0393498\n",
      "Test set: Average loss: 3.1862, Accuracy: 1520/5000 (30%)\n",
      "[epoch 17] loss: 0.0254733\n",
      "Test set: Average loss: 3.3117, Accuracy: 1531/5000 (31%)\n",
      "[epoch 18] loss: 0.0164886\n",
      "Test set: Average loss: 3.4299, Accuracy: 1515/5000 (30%)\n",
      "[epoch 19] loss: 0.0108948\n",
      "Test set: Average loss: 3.5444, Accuracy: 1496/5000 (30%)\n",
      "[epoch 20] loss: 0.0074930\n",
      "Test set: Average loss: 3.6569, Accuracy: 1467/5000 (29%)\n",
      "[epoch 21] loss: 0.0053858\n",
      "Test set: Average loss: 3.7667, Accuracy: 1454/5000 (29%)\n",
      "[epoch 22] loss: 0.0040149\n",
      "Test set: Average loss: 3.8727, Accuracy: 1438/5000 (29%)\n",
      "[epoch 23] loss: 0.0030720\n",
      "Test set: Average loss: 3.9742, Accuracy: 1432/5000 (29%)\n",
      "[epoch 24] loss: 0.0023954\n",
      "Test set: Average loss: 4.0705, Accuracy: 1426/5000 (29%)\n",
      "[epoch 25] loss: 0.0018979\n",
      "Test set: Average loss: 4.1616, Accuracy: 1416/5000 (28%)\n",
      "[epoch 26] loss: 0.0015277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.2474, Accuracy: 1416/5000 (28%)\n",
      "[epoch 27] loss: 0.0012493\n",
      "Test set: Average loss: 4.3281, Accuracy: 1403/5000 (28%)\n",
      "[epoch 28] loss: 0.0010377\n",
      "Test set: Average loss: 4.4039, Accuracy: 1402/5000 (28%)\n",
      "[epoch 29] loss: 0.0008750\n",
      "Test set: Average loss: 4.4749, Accuracy: 1405/5000 (28%)\n",
      "[epoch 30] loss: 0.0007489\n",
      "Test set: Average loss: 4.5414, Accuracy: 1396/5000 (28%)\n",
      "[epoch 31] loss: 0.0006504\n",
      "Test set: Average loss: 4.6036, Accuracy: 1393/5000 (28%)\n",
      "[epoch 32] loss: 0.0005723\n",
      "Test set: Average loss: 4.6616, Accuracy: 1389/5000 (28%)\n",
      "[epoch 33] loss: 0.0005099\n",
      "Test set: Average loss: 4.7156, Accuracy: 1385/5000 (28%)\n",
      "[epoch 34] loss: 0.0004592\n",
      "Test set: Average loss: 4.7658, Accuracy: 1386/5000 (28%)\n",
      "[epoch 35] loss: 0.0004177\n",
      "Test set: Average loss: 4.8125, Accuracy: 1383/5000 (28%)\n",
      "[epoch 36] loss: 0.0003833\n",
      "Test set: Average loss: 4.8558, Accuracy: 1384/5000 (28%)\n",
      "[epoch 37] loss: 0.0003543\n",
      "Test set: Average loss: 4.8959, Accuracy: 1377/5000 (28%)\n",
      "[epoch 38] loss: 0.0003297\n",
      "Test set: Average loss: 4.9331, Accuracy: 1375/5000 (28%)\n",
      "[epoch 39] loss: 0.0003088\n",
      "Test set: Average loss: 4.9676, Accuracy: 1380/5000 (28%)\n",
      "[epoch 40] loss: 0.0002906\n",
      "Test set: Average loss: 4.9994, Accuracy: 1378/5000 (28%)\n",
      "[epoch 41] loss: 0.0002750\n",
      "Test set: Average loss: 5.0288, Accuracy: 1376/5000 (28%)\n",
      "[epoch 42] loss: 0.0002612\n",
      "Test set: Average loss: 5.0559, Accuracy: 1370/5000 (27%)\n",
      "[epoch 43] loss: 0.0002491\n",
      "Test set: Average loss: 5.0810, Accuracy: 1367/5000 (27%)\n",
      "[epoch 44] loss: 0.0002383\n",
      "Test set: Average loss: 5.1042, Accuracy: 1364/5000 (27%)\n",
      "[epoch 45] loss: 0.0002288\n",
      "Test set: Average loss: 5.1256, Accuracy: 1370/5000 (27%)\n",
      "[epoch 46] loss: 0.0002200\n",
      "Test set: Average loss: 5.1453, Accuracy: 1368/5000 (27%)\n",
      "[epoch 47] loss: 0.0002122\n",
      "Test set: Average loss: 5.1635, Accuracy: 1371/5000 (27%)\n",
      "[epoch 48] loss: 0.0002051\n",
      "Test set: Average loss: 5.1803, Accuracy: 1373/5000 (27%)\n",
      "[epoch 49] loss: 0.0001986\n",
      "Test set: Average loss: 5.1957, Accuracy: 1372/5000 (27%)\n",
      "[epoch 50] loss: 0.0001927\n",
      "Test set: Average loss: 5.2100, Accuracy: 1371/5000 (27%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2158, Accuracy: 1812/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 2.2183, Accuracy: 3666/10000 (37%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 512/5000 (10%)\n",
      "[epoch 1] loss: 2.3066971\n",
      "Test set: Average loss: 2.2708, Accuracy: 929/5000 (19%)\n",
      "[epoch 2] loss: 2.1739910\n",
      "Test set: Average loss: 2.2391, Accuracy: 1018/5000 (20%)\n",
      "[epoch 3] loss: 1.9915830\n",
      "Test set: Average loss: 2.2427, Accuracy: 856/5000 (17%)\n",
      "[epoch 4] loss: 1.7610570\n",
      "Test set: Average loss: 2.3647, Accuracy: 697/5000 (14%)\n",
      "[epoch 5] loss: 1.5505593\n",
      "Test set: Average loss: 2.5319, Accuracy: 665/5000 (13%)\n",
      "[epoch 6] loss: 1.3958472\n",
      "Test set: Average loss: 2.4732, Accuracy: 825/5000 (16%)\n",
      "[epoch 7] loss: 1.1666307\n",
      "Test set: Average loss: 2.3600, Accuracy: 959/5000 (19%)\n",
      "[epoch 8] loss: 0.9592628\n",
      "Test set: Average loss: 2.2915, Accuracy: 1041/5000 (21%)\n",
      "[epoch 9] loss: 0.7803648\n",
      "Test set: Average loss: 2.2617, Accuracy: 1101/5000 (22%)\n",
      "[epoch 10] loss: 0.5982916\n",
      "Test set: Average loss: 2.3089, Accuracy: 1154/5000 (23%)\n",
      "[epoch 11] loss: 0.4406383\n",
      "Test set: Average loss: 2.4589, Accuracy: 1144/5000 (23%)\n",
      "[epoch 12] loss: 0.3287313\n",
      "Test set: Average loss: 2.6727, Accuracy: 1099/5000 (22%)\n",
      "[epoch 13] loss: 0.2482035\n",
      "Test set: Average loss: 2.8873, Accuracy: 1087/5000 (22%)\n",
      "[epoch 14] loss: 0.1797265\n",
      "Test set: Average loss: 3.0783, Accuracy: 1080/5000 (22%)\n",
      "[epoch 15] loss: 0.1226405\n",
      "Test set: Average loss: 3.2544, Accuracy: 1094/5000 (22%)\n",
      "[epoch 16] loss: 0.0802313\n",
      "Test set: Average loss: 3.4325, Accuracy: 1078/5000 (22%)\n",
      "[epoch 17] loss: 0.0525214\n",
      "Test set: Average loss: 3.6201, Accuracy: 1093/5000 (22%)\n",
      "[epoch 18] loss: 0.0350973\n",
      "Test set: Average loss: 3.8166, Accuracy: 1101/5000 (22%)\n",
      "[epoch 19] loss: 0.0239819\n",
      "Test set: Average loss: 4.0204, Accuracy: 1083/5000 (22%)\n",
      "[epoch 20] loss: 0.0169083\n",
      "Test set: Average loss: 4.2293, Accuracy: 1057/5000 (21%)\n",
      "[epoch 21] loss: 0.0124300\n",
      "Test set: Average loss: 4.4390, Accuracy: 1034/5000 (21%)\n",
      "[epoch 22] loss: 0.0093662\n",
      "Test set: Average loss: 4.6444, Accuracy: 1018/5000 (20%)\n",
      "[epoch 23] loss: 0.0070463\n",
      "Test set: Average loss: 4.8416, Accuracy: 995/5000 (20%)\n",
      "[epoch 24] loss: 0.0052328\n",
      "Test set: Average loss: 5.0280, Accuracy: 978/5000 (20%)\n",
      "[epoch 25] loss: 0.0038680\n",
      "Test set: Average loss: 5.2025, Accuracy: 969/5000 (19%)\n",
      "[epoch 26] loss: 0.0028916\n",
      "Test set: Average loss: 5.3644, Accuracy: 958/5000 (19%)\n",
      "[epoch 27] loss: 0.0022224\n",
      "Test set: Average loss: 5.5137, Accuracy: 955/5000 (19%)\n",
      "[epoch 28] loss: 0.0017693\n",
      "Test set: Average loss: 5.6500, Accuracy: 939/5000 (19%)\n",
      "[epoch 29] loss: 0.0014597\n",
      "Test set: Average loss: 5.7737, Accuracy: 928/5000 (19%)\n",
      "[epoch 30] loss: 0.0012413\n",
      "Test set: Average loss: 5.8848, Accuracy: 926/5000 (19%)\n",
      "[epoch 31] loss: 0.0010810\n",
      "Test set: Average loss: 5.9839, Accuracy: 919/5000 (18%)\n",
      "[epoch 32] loss: 0.0009576\n",
      "Test set: Average loss: 6.0717, Accuracy: 911/5000 (18%)\n",
      "[epoch 33] loss: 0.0008588\n",
      "Test set: Average loss: 6.1487, Accuracy: 914/5000 (18%)\n",
      "[epoch 34] loss: 0.0007766\n",
      "Test set: Average loss: 6.2160, Accuracy: 909/5000 (18%)\n",
      "[epoch 35] loss: 0.0007061\n",
      "Test set: Average loss: 6.2743, Accuracy: 909/5000 (18%)\n",
      "[epoch 36] loss: 0.0006440\n",
      "Test set: Average loss: 6.3246, Accuracy: 911/5000 (18%)\n",
      "[epoch 37] loss: 0.0005885\n",
      "Test set: Average loss: 6.3677, Accuracy: 911/5000 (18%)\n",
      "[epoch 38] loss: 0.0005389\n",
      "Test set: Average loss: 6.4046, Accuracy: 911/5000 (18%)\n",
      "[epoch 39] loss: 0.0004942\n",
      "Test set: Average loss: 6.4360, Accuracy: 905/5000 (18%)\n",
      "[epoch 40] loss: 0.0004537\n",
      "Test set: Average loss: 6.4628, Accuracy: 905/5000 (18%)\n",
      "[epoch 41] loss: 0.0004175\n",
      "Test set: Average loss: 6.4855, Accuracy: 905/5000 (18%)\n",
      "[epoch 42] loss: 0.0003851\n",
      "Test set: Average loss: 6.5047, Accuracy: 905/5000 (18%)\n",
      "[epoch 43] loss: 0.0003560\n",
      "Test set: Average loss: 6.5211, Accuracy: 906/5000 (18%)\n",
      "[epoch 44] loss: 0.0003305\n",
      "Test set: Average loss: 6.5350, Accuracy: 903/5000 (18%)\n",
      "[epoch 45] loss: 0.0003079\n",
      "Test set: Average loss: 6.5468, Accuracy: 904/5000 (18%)\n",
      "[epoch 46] loss: 0.0002877\n",
      "Test set: Average loss: 6.5569, Accuracy: 909/5000 (18%)\n",
      "[epoch 47] loss: 0.0002700\n",
      "Test set: Average loss: 6.5656, Accuracy: 907/5000 (18%)\n",
      "[epoch 48] loss: 0.0002546\n",
      "Test set: Average loss: 6.5731, Accuracy: 911/5000 (18%)\n",
      "[epoch 49] loss: 0.0002410\n",
      "Test set: Average loss: 6.5796, Accuracy: 910/5000 (18%)\n",
      "[epoch 50] loss: 0.0002288\n",
      "Test set: Average loss: 6.5852, Accuracy: 910/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3089, Accuracy: 1154/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.3108, Accuracy: 2247/10000 (22%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3102, Accuracy: 282/5000 (6%)\n",
      "[epoch 1] loss: 2.2746611\n",
      "Test set: Average loss: 2.2317, Accuracy: 1349/5000 (27%)\n",
      "[epoch 2] loss: 2.0278753\n",
      "Test set: Average loss: 2.1791, Accuracy: 1103/5000 (22%)\n",
      "[epoch 3] loss: 1.7574052\n",
      "Test set: Average loss: 2.1722, Accuracy: 1168/5000 (23%)\n",
      "[epoch 4] loss: 1.4748606\n",
      "Test set: Average loss: 2.1186, Accuracy: 1359/5000 (27%)\n",
      "[epoch 5] loss: 1.2577625\n",
      "Test set: Average loss: 2.0412, Accuracy: 1527/5000 (31%)\n",
      "[epoch 6] loss: 0.9958137\n",
      "Test set: Average loss: 2.0125, Accuracy: 1531/5000 (31%)\n",
      "[epoch 7] loss: 0.7674837\n",
      "Test set: Average loss: 1.9438, Accuracy: 1625/5000 (32%)\n",
      "[epoch 8] loss: 0.5327537\n",
      "Test set: Average loss: 1.9878, Accuracy: 1618/5000 (32%)\n",
      "[epoch 9] loss: 0.3683085\n",
      "Test set: Average loss: 2.0001, Accuracy: 1709/5000 (34%)\n",
      "[epoch 10] loss: 0.2411636\n",
      "Test set: Average loss: 2.0877, Accuracy: 1735/5000 (35%)\n",
      "[epoch 11] loss: 0.1385869\n",
      "Test set: Average loss: 2.3103, Accuracy: 1628/5000 (33%)\n",
      "[epoch 12] loss: 0.0816223\n",
      "Test set: Average loss: 2.5139, Accuracy: 1637/5000 (33%)\n",
      "[epoch 13] loss: 0.0499771\n",
      "Test set: Average loss: 2.7080, Accuracy: 1621/5000 (32%)\n",
      "[epoch 14] loss: 0.0313218\n",
      "Test set: Average loss: 2.8262, Accuracy: 1608/5000 (32%)\n",
      "[epoch 15] loss: 0.0173008\n",
      "Test set: Average loss: 2.8866, Accuracy: 1621/5000 (32%)\n",
      "[epoch 16] loss: 0.0110898\n",
      "Test set: Average loss: 2.9538, Accuracy: 1643/5000 (33%)\n",
      "[epoch 17] loss: 0.0078681\n",
      "Test set: Average loss: 3.0318, Accuracy: 1604/5000 (32%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0055939\n",
      "Test set: Average loss: 3.1067, Accuracy: 1608/5000 (32%)\n",
      "[epoch 19] loss: 0.0049586\n",
      "Test set: Average loss: 3.1738, Accuracy: 1604/5000 (32%)\n",
      "[epoch 20] loss: 0.0037074\n",
      "Test set: Average loss: 3.2263, Accuracy: 1603/5000 (32%)\n",
      "[epoch 21] loss: 0.0031038\n",
      "Test set: Average loss: 3.2694, Accuracy: 1613/5000 (32%)\n",
      "[epoch 22] loss: 0.0026253\n",
      "Test set: Average loss: 3.3067, Accuracy: 1619/5000 (32%)\n",
      "[epoch 23] loss: 0.0020299\n",
      "Test set: Average loss: 3.3410, Accuracy: 1608/5000 (32%)\n",
      "[epoch 24] loss: 0.0017792\n",
      "Test set: Average loss: 3.3725, Accuracy: 1608/5000 (32%)\n",
      "[epoch 25] loss: 0.0015364\n",
      "Test set: Average loss: 3.4009, Accuracy: 1613/5000 (32%)\n",
      "[epoch 26] loss: 0.0013215\n",
      "Test set: Average loss: 3.4281, Accuracy: 1606/5000 (32%)\n",
      "[epoch 27] loss: 0.0012437\n",
      "Test set: Average loss: 3.4542, Accuracy: 1615/5000 (32%)\n",
      "[epoch 28] loss: 0.0011308\n",
      "Test set: Average loss: 3.4775, Accuracy: 1608/5000 (32%)\n",
      "[epoch 29] loss: 0.0010543\n",
      "Test set: Average loss: 3.4987, Accuracy: 1611/5000 (32%)\n",
      "[epoch 30] loss: 0.0010139\n",
      "Test set: Average loss: 3.5176, Accuracy: 1608/5000 (32%)\n",
      "[epoch 31] loss: 0.0009295\n",
      "Test set: Average loss: 3.5341, Accuracy: 1607/5000 (32%)\n",
      "[epoch 32] loss: 0.0008986\n",
      "Test set: Average loss: 3.5481, Accuracy: 1603/5000 (32%)\n",
      "[epoch 33] loss: 0.0008648\n",
      "Test set: Average loss: 3.5607, Accuracy: 1599/5000 (32%)\n",
      "[epoch 34] loss: 0.0008292\n",
      "Test set: Average loss: 3.5728, Accuracy: 1600/5000 (32%)\n",
      "[epoch 35] loss: 0.0008190\n",
      "Test set: Average loss: 3.5843, Accuracy: 1600/5000 (32%)\n",
      "[epoch 36] loss: 0.0007366\n",
      "Test set: Average loss: 3.5955, Accuracy: 1594/5000 (32%)\n",
      "[epoch 37] loss: 0.0007124\n",
      "Test set: Average loss: 3.6066, Accuracy: 1591/5000 (32%)\n",
      "[epoch 38] loss: 0.0007090\n",
      "Test set: Average loss: 3.6175, Accuracy: 1591/5000 (32%)\n",
      "[epoch 39] loss: 0.0006844\n",
      "Test set: Average loss: 3.6281, Accuracy: 1590/5000 (32%)\n",
      "[epoch 40] loss: 0.0006737\n",
      "Test set: Average loss: 3.6378, Accuracy: 1589/5000 (32%)\n",
      "[epoch 41] loss: 0.0006227\n",
      "Test set: Average loss: 3.6470, Accuracy: 1586/5000 (32%)\n",
      "[epoch 42] loss: 0.0006430\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.6557, Accuracy: 1587/5000 (32%)\n",
      "[epoch 43] loss: 0.0006375\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.6565, Accuracy: 1587/5000 (32%)\n",
      "[epoch 44] loss: 0.0006396\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.6652, Accuracy: 1584/5000 (32%)\n",
      "[epoch 45] loss: 0.0006455\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.6566, Accuracy: 1587/5000 (32%)\n",
      "[epoch 46] loss: 0.0006399\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.6566, Accuracy: 1587/5000 (32%)\n",
      "[epoch 47] loss: 0.0006484\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.6566, Accuracy: 1587/5000 (32%)\n",
      "[epoch 48] loss: 0.0006238\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.6566, Accuracy: 1587/5000 (32%)\n",
      "[epoch 49] loss: 0.0006430\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.6566, Accuracy: 1587/5000 (32%)\n",
      "[epoch 50] loss: 0.0006374\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.6566, Accuracy: 1587/5000 (32%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0877, Accuracy: 1735/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 2.0748, Accuracy: 3430/10000 (34%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3074, Accuracy: 210/5000 (4%)\n",
      "[epoch 1] loss: 2.2857567\n",
      "Test set: Average loss: 2.2181, Accuracy: 1488/5000 (30%)\n",
      "[epoch 2] loss: 2.0814520\n",
      "Test set: Average loss: 2.0878, Accuracy: 1429/5000 (29%)\n",
      "[epoch 3] loss: 1.8079116\n",
      "Test set: Average loss: 1.9836, Accuracy: 1434/5000 (29%)\n",
      "[epoch 4] loss: 1.4556241\n",
      "Test set: Average loss: 1.8627, Accuracy: 1766/5000 (35%)\n",
      "[epoch 5] loss: 1.1576809\n",
      "Test set: Average loss: 1.8112, Accuracy: 1842/5000 (37%)\n",
      "[epoch 6] loss: 0.8814553\n",
      "Test set: Average loss: 1.7731, Accuracy: 1896/5000 (38%)\n",
      "[epoch 7] loss: 0.7251724\n",
      "Test set: Average loss: 1.7960, Accuracy: 1924/5000 (38%)\n",
      "[epoch 8] loss: 0.5825945\n",
      "Test set: Average loss: 1.7765, Accuracy: 1989/5000 (40%)\n",
      "[epoch 9] loss: 0.4259793\n",
      "Test set: Average loss: 1.8247, Accuracy: 1976/5000 (40%)\n",
      "[epoch 10] loss: 0.3227762\n",
      "Test set: Average loss: 1.9420, Accuracy: 1922/5000 (38%)\n",
      "[epoch 11] loss: 0.2267112\n",
      "Test set: Average loss: 2.0721, Accuracy: 1891/5000 (38%)\n",
      "[epoch 12] loss: 0.1682111\n",
      "Test set: Average loss: 2.1344, Accuracy: 1848/5000 (37%)\n",
      "[epoch 13] loss: 0.0880298\n",
      "Test set: Average loss: 2.2066, Accuracy: 1844/5000 (37%)\n",
      "[epoch 14] loss: 0.0601889\n",
      "Test set: Average loss: 2.3098, Accuracy: 1812/5000 (36%)\n",
      "[epoch 15] loss: 0.0381927\n",
      "Test set: Average loss: 2.3987, Accuracy: 1826/5000 (37%)\n",
      "[epoch 16] loss: 0.0260556\n",
      "Test set: Average loss: 2.4639, Accuracy: 1847/5000 (37%)\n",
      "[epoch 17] loss: 0.0173807\n",
      "Test set: Average loss: 2.5175, Accuracy: 1859/5000 (37%)\n",
      "[epoch 18] loss: 0.0112052\n",
      "Test set: Average loss: 2.5730, Accuracy: 1873/5000 (37%)\n",
      "[epoch 19] loss: 0.0080970\n",
      "Test set: Average loss: 2.6314, Accuracy: 1888/5000 (38%)\n",
      "[epoch 20] loss: 0.0059295\n",
      "Test set: Average loss: 2.6911, Accuracy: 1878/5000 (38%)\n",
      "[epoch 21] loss: 0.0048681\n",
      "Test set: Average loss: 2.7487, Accuracy: 1866/5000 (37%)\n",
      "[epoch 22] loss: 0.0043259\n",
      "Test set: Average loss: 2.7972, Accuracy: 1865/5000 (37%)\n",
      "[epoch 23] loss: 0.0039174\n",
      "Test set: Average loss: 2.8377, Accuracy: 1865/5000 (37%)\n",
      "[epoch 24] loss: 0.0031503\n",
      "Test set: Average loss: 2.8686, Accuracy: 1850/5000 (37%)\n",
      "[epoch 25] loss: 0.0028720\n",
      "Test set: Average loss: 2.8927, Accuracy: 1855/5000 (37%)\n",
      "[epoch 26] loss: 0.0027434\n",
      "Test set: Average loss: 2.9114, Accuracy: 1854/5000 (37%)\n",
      "[epoch 27] loss: 0.0020666\n",
      "Test set: Average loss: 2.9252, Accuracy: 1856/5000 (37%)\n",
      "[epoch 28] loss: 0.0020083\n",
      "Test set: Average loss: 2.9367, Accuracy: 1860/5000 (37%)\n",
      "[epoch 29] loss: 0.0017807\n",
      "Test set: Average loss: 2.9459, Accuracy: 1869/5000 (37%)\n",
      "[epoch 30] loss: 0.0017066\n",
      "Test set: Average loss: 2.9548, Accuracy: 1877/5000 (38%)\n",
      "[epoch 31] loss: 0.0014925\n",
      "Test set: Average loss: 2.9633, Accuracy: 1879/5000 (38%)\n",
      "[epoch 32] loss: 0.0014973\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.9712, Accuracy: 1874/5000 (37%)\n",
      "[epoch 33] loss: 0.0013737\n",
      "Test set: Average loss: 2.9719, Accuracy: 1875/5000 (38%)\n",
      "[epoch 34] loss: 0.0013847\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9725, Accuracy: 1875/5000 (38%)\n",
      "[epoch 35] loss: 0.0013710\n",
      "Test set: Average loss: 2.9725, Accuracy: 1875/5000 (38%)\n",
      "[epoch 36] loss: 0.0013736\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 37] loss: 0.0013471\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 38] loss: 0.0013689\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 39] loss: 0.0013252\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 40] loss: 0.0013071\n",
      "Test set: Average loss: 2.9815, Accuracy: 1870/5000 (37%)\n",
      "[epoch 41] loss: 0.0014190\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 42] loss: 0.0013941\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 43] loss: 0.0014073\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 44] loss: 0.0014511\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 45] loss: 0.0013327\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 46] loss: 0.0013805\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 47] loss: 0.0013374\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 48] loss: 0.0013612\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 49] loss: 0.0013008\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "[epoch 50] loss: 0.0013095\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.9726, Accuracy: 1875/5000 (38%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7765, Accuracy: 1989/5000 (40%)\n",
      "Test\n",
      "Test set: Average loss: 1.7519, Accuracy: 3982/10000 (40%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 414/5000 (8%)\n",
      "[epoch 1] loss: 2.2646482\n",
      "Test set: Average loss: 2.2192, Accuracy: 1109/5000 (22%)\n",
      "[epoch 2] loss: 1.9539912\n",
      "Test set: Average loss: 2.2381, Accuracy: 918/5000 (18%)\n",
      "[epoch 3] loss: 1.7322221\n",
      "Test set: Average loss: 2.2176, Accuracy: 1098/5000 (22%)\n",
      "[epoch 4] loss: 1.3949410\n",
      "Test set: Average loss: 2.0866, Accuracy: 1402/5000 (28%)\n",
      "[epoch 5] loss: 1.2143279\n",
      "Test set: Average loss: 2.0440, Accuracy: 1501/5000 (30%)\n",
      "[epoch 6] loss: 0.9457705\n",
      "Test set: Average loss: 2.0613, Accuracy: 1560/5000 (31%)\n",
      "[epoch 7] loss: 0.7383943\n",
      "Test set: Average loss: 2.1632, Accuracy: 1529/5000 (31%)\n",
      "[epoch 8] loss: 0.5296417\n",
      "Test set: Average loss: 2.2477, Accuracy: 1529/5000 (31%)\n",
      "[epoch 9] loss: 0.3897677\n",
      "Test set: Average loss: 2.4002, Accuracy: 1466/5000 (29%)\n",
      "[epoch 10] loss: 0.2831708\n",
      "Test set: Average loss: 2.5763, Accuracy: 1458/5000 (29%)\n",
      "[epoch 11] loss: 0.1791308\n",
      "Test set: Average loss: 2.7904, Accuracy: 1471/5000 (29%)\n",
      "[epoch 12] loss: 0.1513066\n",
      "Test set: Average loss: 2.9303, Accuracy: 1466/5000 (29%)\n",
      "[epoch 13] loss: 0.0868260\n",
      "Test set: Average loss: 3.0651, Accuracy: 1460/5000 (29%)\n",
      "[epoch 14] loss: 0.0562716\n",
      "Test set: Average loss: 3.2066, Accuracy: 1443/5000 (29%)\n",
      "[epoch 15] loss: 0.0368312\n",
      "Test set: Average loss: 3.3129, Accuracy: 1436/5000 (29%)\n",
      "[epoch 16] loss: 0.0290069\n",
      "Test set: Average loss: 3.4035, Accuracy: 1455/5000 (29%)\n",
      "[epoch 17] loss: 0.0221441\n",
      "Test set: Average loss: 3.4919, Accuracy: 1460/5000 (29%)\n",
      "[epoch 18] loss: 0.0156557\n",
      "Test set: Average loss: 3.5905, Accuracy: 1470/5000 (29%)\n",
      "[epoch 19] loss: 0.0115948\n",
      "Test set: Average loss: 3.7007, Accuracy: 1457/5000 (29%)\n",
      "[epoch 20] loss: 0.0088827\n",
      "Test set: Average loss: 3.8205, Accuracy: 1454/5000 (29%)\n",
      "[epoch 21] loss: 0.0072932\n",
      "Test set: Average loss: 3.9339, Accuracy: 1435/5000 (29%)\n",
      "[epoch 22] loss: 0.0059170\n",
      "Test set: Average loss: 4.0326, Accuracy: 1415/5000 (28%)\n",
      "[epoch 23] loss: 0.0048172\n",
      "Test set: Average loss: 4.1155, Accuracy: 1402/5000 (28%)\n",
      "[epoch 24] loss: 0.0037932\n",
      "Test set: Average loss: 4.1889, Accuracy: 1395/5000 (28%)\n",
      "[epoch 25] loss: 0.0032851\n",
      "Test set: Average loss: 4.2494, Accuracy: 1392/5000 (28%)\n",
      "[epoch 26] loss: 0.0029736\n",
      "Test set: Average loss: 4.2938, Accuracy: 1387/5000 (28%)\n",
      "[epoch 27] loss: 0.0026664\n",
      "Test set: Average loss: 4.3204, Accuracy: 1380/5000 (28%)\n",
      "[epoch 28] loss: 0.0022946\n",
      "Test set: Average loss: 4.3344, Accuracy: 1376/5000 (28%)\n",
      "[epoch 29] loss: 0.0022960\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.3410, Accuracy: 1374/5000 (27%)\n",
      "[epoch 30] loss: 0.0019765\n",
      "Test set: Average loss: 4.3411, Accuracy: 1375/5000 (28%)\n",
      "[epoch 31] loss: 0.0019701\n",
      "Test set: Average loss: 4.3408, Accuracy: 1375/5000 (28%)\n",
      "[epoch 32] loss: 0.0020884\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.3403, Accuracy: 1375/5000 (28%)\n",
      "[epoch 33] loss: 0.0021692\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.3402, Accuracy: 1376/5000 (28%)\n",
      "[epoch 34] loss: 0.0019341\n",
      "Test set: Average loss: 4.3402, Accuracy: 1376/5000 (28%)\n",
      "[epoch 35] loss: 0.0018794\n",
      "Test set: Average loss: 4.3402, Accuracy: 1376/5000 (28%)\n",
      "[epoch 36] loss: 0.0019176\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 37] loss: 0.0021554\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 38] loss: 0.0020027\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 39] loss: 0.0019119\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 40] loss: 0.0018749\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 41] loss: 0.0020758\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 42] loss: 0.0019162\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 43] loss: 0.0020417\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 44] loss: 0.0021023\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 45] loss: 0.0019377\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 46] loss: 0.0018182\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 47] loss: 0.0023682\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 48] loss: 0.0022245\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 49] loss: 0.0018653\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "[epoch 50] loss: 0.0021089\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 4.3401, Accuracy: 1376/5000 (28%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0613, Accuracy: 1560/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.0526, Accuracy: 3041/10000 (30%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3119, Accuracy: 498/5000 (10%)\n",
      "[epoch 1] loss: 2.1967570\n",
      "Test set: Average loss: 2.1814, Accuracy: 1062/5000 (21%)\n",
      "[epoch 2] loss: 1.8804019\n",
      "Test set: Average loss: 2.2343, Accuracy: 1193/5000 (24%)\n",
      "[epoch 3] loss: 1.5358677\n",
      "Test set: Average loss: 2.0188, Accuracy: 1337/5000 (27%)\n",
      "[epoch 4] loss: 1.3822209\n",
      "Test set: Average loss: 1.9132, Accuracy: 1573/5000 (31%)\n",
      "[epoch 5] loss: 1.0888331\n",
      "Test set: Average loss: 1.8872, Accuracy: 1638/5000 (33%)\n",
      "[epoch 6] loss: 0.7948023\n",
      "Test set: Average loss: 1.9280, Accuracy: 1582/5000 (32%)\n",
      "[epoch 7] loss: 0.8214445\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8880, Accuracy: 1752/5000 (35%)\n",
      "[epoch 8] loss: 0.6580360\n",
      "Test set: Average loss: 1.8908, Accuracy: 1760/5000 (35%)\n",
      "[epoch 9] loss: 0.7886008\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8637, Accuracy: 1791/5000 (36%)\n",
      "[epoch 10] loss: 0.6167163\n",
      "Test set: Average loss: 1.8598, Accuracy: 1793/5000 (36%)\n",
      "[epoch 11] loss: 0.7110923\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8548, Accuracy: 1808/5000 (36%)\n",
      "[epoch 12] loss: 0.6698111\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8544, Accuracy: 1810/5000 (36%)\n",
      "[epoch 13] loss: 0.6059589\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 14] loss: 0.7816606\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 15] loss: 0.6152700\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 16] loss: 0.5984429\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 17] loss: 0.6503557\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 18] loss: 0.5721181\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 19] loss: 1.6128672\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 20] loss: 0.5715927\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 21] loss: 0.6813467\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 22] loss: 0.5776930\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 23] loss: 0.6115133\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 24] loss: 0.6306419\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 25] loss: 0.5863997\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 26] loss: 0.6462186\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 27] loss: 0.5989042\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 28] loss: 1.9641388\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 29] loss: 0.6016389\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 30] loss: 0.6643255\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 31] loss: 0.6119989\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 32] loss: 0.7230548\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 33] loss: 0.6175078\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 34] loss: 0.5830818\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 35] loss: 0.6904956\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 36] loss: 0.6171238\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 37] loss: 0.5760651\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 38] loss: 0.5740376\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 39] loss: 2.5229691\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 40] loss: 0.5592992\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 41] loss: 0.5759969\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 42] loss: 0.6533470\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 43] loss: 0.7513501\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 44] loss: 0.7061404\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 45] loss: 0.5669963\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 46] loss: 0.7186426\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 47] loss: 0.6189449\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 48] loss: 0.6358731\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 49] loss: 0.6607032\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "[epoch 50] loss: 0.6965143\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8543, Accuracy: 1810/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.7959, Accuracy: 3801/10000 (38%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3111, Accuracy: 324/5000 (6%)\n",
      "[epoch 1] loss: 2.1927580\n",
      "Test set: Average loss: 2.0672, Accuracy: 1641/5000 (33%)\n",
      "[epoch 2] loss: 2.1727029\n",
      "Test set: Average loss: 1.8899, Accuracy: 1666/5000 (33%)\n",
      "[epoch 3] loss: 1.5531459\n",
      "Test set: Average loss: 1.7654, Accuracy: 1917/5000 (38%)\n",
      "[epoch 4] loss: 1.4798748\n",
      "Test set: Average loss: 1.7659, Accuracy: 1857/5000 (37%)\n",
      "[epoch 5] loss: 1.2358230\n",
      "Test set: Average loss: 1.7392, Accuracy: 1965/5000 (39%)\n",
      "[epoch 6] loss: 1.0504585\n",
      "Test set: Average loss: 1.5917, Accuracy: 2212/5000 (44%)\n",
      "[epoch 7] loss: 0.9884334\n",
      "Test set: Average loss: 1.5796, Accuracy: 2249/5000 (45%)\n",
      "[epoch 8] loss: 0.6992014\n",
      "Test set: Average loss: 1.7349, Accuracy: 2063/5000 (41%)\n",
      "[epoch 9] loss: 0.6261940\n",
      "Test set: Average loss: 1.8298, Accuracy: 2025/5000 (40%)\n",
      "[epoch 10] loss: 0.7035817\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7057, Accuracy: 2141/5000 (43%)\n",
      "[epoch 11] loss: 0.3728867\n",
      "Test set: Average loss: 1.7191, Accuracy: 2124/5000 (42%)\n",
      "[epoch 12] loss: 0.3607169\n",
      "Test set: Average loss: 1.6948, Accuracy: 2176/5000 (44%)\n",
      "[epoch 13] loss: 0.3466094\n",
      "Test set: Average loss: 1.6576, Accuracy: 2230/5000 (45%)\n",
      "[epoch 14] loss: 0.3306776\n",
      "Test set: Average loss: 1.6241, Accuracy: 2269/5000 (45%)\n",
      "[epoch 15] loss: 0.2770004\n",
      "Test set: Average loss: 1.6130, Accuracy: 2308/5000 (46%)\n",
      "[epoch 16] loss: 0.2689935\n",
      "Test set: Average loss: 1.6126, Accuracy: 2320/5000 (46%)\n",
      "[epoch 17] loss: 0.2703103\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.6205, Accuracy: 2308/5000 (46%)\n",
      "[epoch 18] loss: 0.2773061\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.6214, Accuracy: 2308/5000 (46%)\n",
      "[epoch 19] loss: 0.2346397\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 20] loss: 0.2931141\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 21] loss: 0.2666243\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 22] loss: 0.2920101\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 23] loss: 0.3387782\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 24] loss: 0.2874938\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 25] loss: 0.2591490\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 26] loss: 0.3077767\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 27] loss: 0.2514541\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 28] loss: 0.2475246\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 29] loss: 0.3072757\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 30] loss: 0.2357292\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 31] loss: 0.2782130\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 32] loss: 0.2635345\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 33] loss: 0.2523970\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 34] loss: 0.3122954\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 35] loss: 0.2421206\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 36] loss: 0.3479204\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 37] loss: 0.2972672\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 38] loss: 0.2740450\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 39] loss: 0.2727514\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 40] loss: 0.3267356\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 41] loss: 0.2445712\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 42] loss: 0.3229664\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 43] loss: 0.3073272\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 44] loss: 0.3176435\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 45] loss: 0.2892804\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 46] loss: 0.2899673\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 47] loss: 0.2921437\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 48] loss: 0.2516135\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 49] loss: 0.2746583\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "[epoch 50] loss: 1.8074380\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.6215, Accuracy: 2307/5000 (46%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6126, Accuracy: 2320/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.5451, Accuracy: 4759/10000 (48%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3103, Accuracy: 575/5000 (12%)\n",
      "[epoch 1] loss: 2.1247317\n",
      "Test set: Average loss: 2.1910, Accuracy: 967/5000 (19%)\n",
      "[epoch 2] loss: 1.7725893\n",
      "Test set: Average loss: 2.1225, Accuracy: 1424/5000 (28%)\n",
      "[epoch 3] loss: 1.5578110\n",
      "Test set: Average loss: 2.0315, Accuracy: 1506/5000 (30%)\n",
      "[epoch 4] loss: 1.3501937\n",
      "Test set: Average loss: 1.9462, Accuracy: 1455/5000 (29%)\n",
      "[epoch 5] loss: 1.1091898\n",
      "Test set: Average loss: 1.8345, Accuracy: 1719/5000 (34%)\n",
      "[epoch 6] loss: 0.8972930\n",
      "Test set: Average loss: 1.9904, Accuracy: 1596/5000 (32%)\n",
      "[epoch 7] loss: 0.9774462\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8999, Accuracy: 1734/5000 (35%)\n",
      "[epoch 8] loss: 0.6626029\n",
      "Test set: Average loss: 1.9081, Accuracy: 1740/5000 (35%)\n",
      "[epoch 9] loss: 0.7223823\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8941, Accuracy: 1777/5000 (36%)\n",
      "[epoch 10] loss: 0.6244537\n",
      "Test set: Average loss: 1.8941, Accuracy: 1792/5000 (36%)\n",
      "[epoch 11] loss: 0.5834334\n",
      "Test set: Average loss: 1.8945, Accuracy: 1803/5000 (36%)\n",
      "[epoch 12] loss: 0.5418070\n",
      "Test set: Average loss: 1.8937, Accuracy: 1812/5000 (36%)\n",
      "[epoch 13] loss: 0.6091511\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1823/5000 (36%)\n",
      "[epoch 14] loss: 0.7002768\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 15] loss: 0.6378702\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 16] loss: 0.5890419\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 17] loss: 0.7898820\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 18] loss: 0.6148708\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 19] loss: 0.6395708\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 20] loss: 0.6738904\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 21] loss: 0.7466757\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 22] loss: 0.4996502\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 23] loss: 0.5842825\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 24] loss: 0.5669560\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 25] loss: 0.6929473\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 26] loss: 0.5601790\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 27] loss: 0.5601645\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 28] loss: 0.5665791\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 29] loss: 0.5367621\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 30] loss: 0.6208289\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 31] loss: 1.7822540\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 32] loss: 0.5937087\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 33] loss: 0.5255173\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 34] loss: 0.5115397\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 35] loss: 0.4944219\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 36] loss: 0.5298570\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 37] loss: 0.6719267\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 38] loss: 0.5119284\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 39] loss: 0.5853651\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 40] loss: 0.6770673\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.5750871\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 42] loss: 0.6725064\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 43] loss: 0.6584657\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 44] loss: 0.5413758\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 45] loss: 0.6288292\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 46] loss: 0.7521723\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 47] loss: 0.5805819\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 48] loss: 0.5858465\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 49] loss: 0.5821771\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "[epoch 50] loss: 0.6544931\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8935, Accuracy: 1825/5000 (36%)\n",
      "Test\n",
      "Test set: Average loss: 1.9089, Accuracy: 3645/10000 (36%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3054, Accuracy: 401/5000 (8%)\n",
      "[epoch 1] loss: 2.0970923\n",
      "Test set: Average loss: 1.7749, Accuracy: 2067/5000 (41%)\n",
      "[epoch 2] loss: 1.5724286\n",
      "Test set: Average loss: 1.5648, Accuracy: 2366/5000 (47%)\n",
      "[epoch 3] loss: 1.2263530\n",
      "Test set: Average loss: 1.6283, Accuracy: 2106/5000 (42%)\n",
      "[epoch 4] loss: 1.0782074\n",
      "Test set: Average loss: 1.5335, Accuracy: 2377/5000 (48%)\n",
      "[epoch 5] loss: 0.8824369\n",
      "Test set: Average loss: 1.5715, Accuracy: 2366/5000 (47%)\n",
      "[epoch 6] loss: 0.6728201\n",
      "Test set: Average loss: 1.5512, Accuracy: 2410/5000 (48%)\n",
      "[epoch 7] loss: 0.5467005\n",
      "Test set: Average loss: 1.5042, Accuracy: 2554/5000 (51%)\n",
      "[epoch 8] loss: 0.4072546\n",
      "Test set: Average loss: 1.6372, Accuracy: 2439/5000 (49%)\n",
      "[epoch 9] loss: 0.3006325\n",
      "Test set: Average loss: 1.7109, Accuracy: 2473/5000 (49%)\n",
      "[epoch 10] loss: 0.2331632\n",
      "Test set: Average loss: 1.9623, Accuracy: 2348/5000 (47%)\n",
      "[epoch 11] loss: 0.1591671\n",
      "Test set: Average loss: 1.8938, Accuracy: 2415/5000 (48%)\n",
      "[epoch 12] loss: 0.1310228\n",
      "Test set: Average loss: 1.9449, Accuracy: 2448/5000 (49%)\n",
      "[epoch 13] loss: 0.1032956\n",
      "Test set: Average loss: 2.1673, Accuracy: 2383/5000 (48%)\n",
      "[epoch 14] loss: 0.0643981\n",
      "Test set: Average loss: 2.1635, Accuracy: 2388/5000 (48%)\n",
      "[epoch 15] loss: 0.0370175\n",
      "Test set: Average loss: 2.1681, Accuracy: 2407/5000 (48%)\n",
      "[epoch 16] loss: 0.0245486\n",
      "Test set: Average loss: 2.2607, Accuracy: 2394/5000 (48%)\n",
      "[epoch 17] loss: 0.0164130\n",
      "Test set: Average loss: 2.2419, Accuracy: 2422/5000 (48%)\n",
      "[epoch 18] loss: 0.0121546\n",
      "Test set: Average loss: 2.2758, Accuracy: 2423/5000 (48%)\n",
      "[epoch 19] loss: 0.0097417\n",
      "Test set: Average loss: 2.3157, Accuracy: 2436/5000 (49%)\n",
      "[epoch 20] loss: 0.0081586\n",
      "Test set: Average loss: 2.3565, Accuracy: 2432/5000 (49%)\n",
      "[epoch 21] loss: 0.0070561\n",
      "Test set: Average loss: 2.3793, Accuracy: 2422/5000 (48%)\n",
      "[epoch 22] loss: 0.0062408\n",
      "Test set: Average loss: 2.4091, Accuracy: 2422/5000 (48%)\n",
      "[epoch 23] loss: 0.0057251\n",
      "Test set: Average loss: 2.4285, Accuracy: 2422/5000 (48%)\n",
      "[epoch 24] loss: 0.0052392\n",
      "Test set: Average loss: 2.4394, Accuracy: 2420/5000 (48%)\n",
      "[epoch 25] loss: 0.0048643\n",
      "Test set: Average loss: 2.4655, Accuracy: 2418/5000 (48%)\n",
      "[epoch 26] loss: 0.0044877\n",
      "Test set: Average loss: 2.4830, Accuracy: 2418/5000 (48%)\n",
      "[epoch 27] loss: 0.0042122\n",
      "Test set: Average loss: 2.4970, Accuracy: 2411/5000 (48%)\n",
      "[epoch 28] loss: 0.0039060\n",
      "Test set: Average loss: 2.5223, Accuracy: 2409/5000 (48%)\n",
      "[epoch 29] loss: 0.0036754\n",
      "Test set: Average loss: 2.5320, Accuracy: 2412/5000 (48%)\n",
      "[epoch 30] loss: 0.0034366\n",
      "Test set: Average loss: 2.5536, Accuracy: 2412/5000 (48%)\n",
      "[epoch 31] loss: 0.0031981\n",
      "Test set: Average loss: 2.5673, Accuracy: 2409/5000 (48%)\n",
      "[epoch 32] loss: 0.0030251\n",
      "Test set: Average loss: 2.5770, Accuracy: 2412/5000 (48%)\n",
      "[epoch 33] loss: 0.0028903\n",
      "Test set: Average loss: 2.5959, Accuracy: 2411/5000 (48%)\n",
      "[epoch 34] loss: 0.0027169\n",
      "Test set: Average loss: 2.6071, Accuracy: 2403/5000 (48%)\n",
      "[epoch 35] loss: 0.0025848\n",
      "Test set: Average loss: 2.6142, Accuracy: 2402/5000 (48%)\n",
      "[epoch 36] loss: 0.0024436\n",
      "Test set: Average loss: 2.6327, Accuracy: 2408/5000 (48%)\n",
      "[epoch 37] loss: 0.0023442\n",
      "Test set: Average loss: 2.6493, Accuracy: 2407/5000 (48%)\n",
      "[epoch 38] loss: 0.0022406\n",
      "Test set: Average loss: 2.6498, Accuracy: 2404/5000 (48%)\n",
      "[epoch 39] loss: 0.0021357\n",
      "Test set: Average loss: 2.6684, Accuracy: 2402/5000 (48%)\n",
      "[epoch 40] loss: 0.0020068\n",
      "Test set: Average loss: 2.6809, Accuracy: 2402/5000 (48%)\n",
      "[epoch 41] loss: 0.0019420\n",
      "Test set: Average loss: 2.6895, Accuracy: 2401/5000 (48%)\n",
      "[epoch 42] loss: 0.0018345\n",
      "Test set: Average loss: 2.7041, Accuracy: 2397/5000 (48%)\n",
      "[epoch 43] loss: 0.0017790\n",
      "Test set: Average loss: 2.7101, Accuracy: 2398/5000 (48%)\n",
      "[epoch 44] loss: 0.0017078\n",
      "Test set: Average loss: 2.7145, Accuracy: 2397/5000 (48%)\n",
      "[epoch 45] loss: 0.0016307\n",
      "Test set: Average loss: 2.7354, Accuracy: 2399/5000 (48%)\n",
      "[epoch 46] loss: 0.0015689\n",
      "Test set: Average loss: 2.7405, Accuracy: 2396/5000 (48%)\n",
      "[epoch 47] loss: 0.0015244\n",
      "Test set: Average loss: 2.7553, Accuracy: 2392/5000 (48%)\n",
      "[epoch 48] loss: 0.0014478\n",
      "Test set: Average loss: 2.7596, Accuracy: 2393/5000 (48%)\n",
      "[epoch 49] loss: 0.0014074\n",
      "Test set: Average loss: 2.7689, Accuracy: 2396/5000 (48%)\n",
      "[epoch 50] loss: 0.0013510\n",
      "Test set: Average loss: 2.7808, Accuracy: 2391/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5042, Accuracy: 2554/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.4876, Accuracy: 5120/10000 (51%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3128, Accuracy: 869/5000 (17%)\n",
      "[epoch 1] loss: 2.0508671\n",
      "Test set: Average loss: 1.7859, Accuracy: 1946/5000 (39%)\n",
      "[epoch 2] loss: 1.4246778\n",
      "Test set: Average loss: 1.4512, Accuracy: 2410/5000 (48%)\n",
      "[epoch 3] loss: 1.0596807\n",
      "Test set: Average loss: 1.3959, Accuracy: 2522/5000 (50%)\n",
      "[epoch 4] loss: 0.8006902\n",
      "Test set: Average loss: 1.3579, Accuracy: 2646/5000 (53%)\n",
      "[epoch 5] loss: 0.5921752\n",
      "Test set: Average loss: 1.6451, Accuracy: 2305/5000 (46%)\n",
      "[epoch 6] loss: 0.5364780\n",
      "Test set: Average loss: 1.5032, Accuracy: 2618/5000 (52%)\n",
      "[epoch 7] loss: 0.3837877\n",
      "Test set: Average loss: 1.6246, Accuracy: 2487/5000 (50%)\n",
      "[epoch 8] loss: 0.3275954\n",
      "Test set: Average loss: 1.6305, Accuracy: 2523/5000 (50%)\n",
      "[epoch 9] loss: 0.2254283\n",
      "Test set: Average loss: 1.6155, Accuracy: 2608/5000 (52%)\n",
      "[epoch 10] loss: 0.1610334\n",
      "Test set: Average loss: 1.6729, Accuracy: 2609/5000 (52%)\n",
      "[epoch 11] loss: 0.1088476\n",
      "Test set: Average loss: 1.7877, Accuracy: 2565/5000 (51%)\n",
      "[epoch 12] loss: 0.0923880\n",
      "Test set: Average loss: 1.9849, Accuracy: 2546/5000 (51%)\n",
      "[epoch 13] loss: 0.0697633\n",
      "Test set: Average loss: 1.9430, Accuracy: 2513/5000 (50%)\n",
      "[epoch 14] loss: 0.0479853\n",
      "Test set: Average loss: 2.0255, Accuracy: 2538/5000 (51%)\n",
      "[epoch 15] loss: 0.0344352\n",
      "Test set: Average loss: 2.0572, Accuracy: 2579/5000 (52%)\n",
      "[epoch 16] loss: 0.0176170\n",
      "Test set: Average loss: 2.0748, Accuracy: 2543/5000 (51%)\n",
      "[epoch 17] loss: 0.0125526\n",
      "Test set: Average loss: 2.1172, Accuracy: 2516/5000 (50%)\n",
      "[epoch 18] loss: 0.0098714\n",
      "Test set: Average loss: 2.1661, Accuracy: 2541/5000 (51%)\n",
      "[epoch 19] loss: 0.0082975\n",
      "Test set: Average loss: 2.1689, Accuracy: 2556/5000 (51%)\n",
      "[epoch 20] loss: 0.0067220\n",
      "Test set: Average loss: 2.1873, Accuracy: 2558/5000 (51%)\n",
      "[epoch 21] loss: 0.0058987\n",
      "Test set: Average loss: 2.2214, Accuracy: 2545/5000 (51%)\n",
      "[epoch 22] loss: 0.0052815\n",
      "Test set: Average loss: 2.2460, Accuracy: 2542/5000 (51%)\n",
      "[epoch 23] loss: 0.0047781\n",
      "Test set: Average loss: 2.2604, Accuracy: 2549/5000 (51%)\n",
      "[epoch 24] loss: 0.0044667\n",
      "Test set: Average loss: 2.2835, Accuracy: 2541/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25] loss: 0.0040933\n",
      "Test set: Average loss: 2.3032, Accuracy: 2535/5000 (51%)\n",
      "[epoch 26] loss: 0.0037656\n",
      "Test set: Average loss: 2.3141, Accuracy: 2538/5000 (51%)\n",
      "[epoch 27] loss: 0.0034954\n",
      "Test set: Average loss: 2.3377, Accuracy: 2531/5000 (51%)\n",
      "[epoch 28] loss: 0.0032810\n",
      "Test set: Average loss: 2.3553, Accuracy: 2533/5000 (51%)\n",
      "[epoch 29] loss: 0.0030977\n",
      "Test set: Average loss: 2.3671, Accuracy: 2532/5000 (51%)\n",
      "[epoch 30] loss: 0.0028542\n",
      "Test set: Average loss: 2.3804, Accuracy: 2528/5000 (51%)\n",
      "[epoch 31] loss: 0.0027169\n",
      "Test set: Average loss: 2.3897, Accuracy: 2535/5000 (51%)\n",
      "[epoch 32] loss: 0.0025798\n",
      "Test set: Average loss: 2.3998, Accuracy: 2540/5000 (51%)\n",
      "[epoch 33] loss: 0.0024280\n",
      "Test set: Average loss: 2.4207, Accuracy: 2533/5000 (51%)\n",
      "[epoch 34] loss: 0.0023105\n",
      "Test set: Average loss: 2.4385, Accuracy: 2527/5000 (51%)\n",
      "[epoch 35] loss: 0.0021837\n",
      "Test set: Average loss: 2.4428, Accuracy: 2531/5000 (51%)\n",
      "[epoch 36] loss: 0.0020753\n",
      "Test set: Average loss: 2.4525, Accuracy: 2525/5000 (50%)\n",
      "[epoch 37] loss: 0.0019844\n",
      "Test set: Average loss: 2.4635, Accuracy: 2530/5000 (51%)\n",
      "[epoch 38] loss: 0.0018821\n",
      "Test set: Average loss: 2.4784, Accuracy: 2531/5000 (51%)\n",
      "[epoch 39] loss: 0.0018271\n",
      "Test set: Average loss: 2.4909, Accuracy: 2526/5000 (51%)\n",
      "[epoch 40] loss: 0.0017253\n",
      "Test set: Average loss: 2.4968, Accuracy: 2523/5000 (50%)\n",
      "[epoch 41] loss: 0.0016619\n",
      "Test set: Average loss: 2.5088, Accuracy: 2522/5000 (50%)\n",
      "[epoch 42] loss: 0.0016032\n",
      "Test set: Average loss: 2.5192, Accuracy: 2519/5000 (50%)\n",
      "[epoch 43] loss: 0.0015181\n",
      "Test set: Average loss: 2.5305, Accuracy: 2522/5000 (50%)\n",
      "[epoch 44] loss: 0.0014673\n",
      "Test set: Average loss: 2.5391, Accuracy: 2521/5000 (50%)\n",
      "[epoch 45] loss: 0.0014174\n",
      "Test set: Average loss: 2.5491, Accuracy: 2522/5000 (50%)\n",
      "[epoch 46] loss: 0.0013573\n",
      "Test set: Average loss: 2.5565, Accuracy: 2521/5000 (50%)\n",
      "[epoch 47] loss: 0.0013029\n",
      "Test set: Average loss: 2.5648, Accuracy: 2520/5000 (50%)\n",
      "[epoch 48] loss: 0.0012529\n",
      "Test set: Average loss: 2.5753, Accuracy: 2524/5000 (50%)\n",
      "[epoch 49] loss: 0.0012079\n",
      "Test set: Average loss: 2.5831, Accuracy: 2518/5000 (50%)\n",
      "[epoch 50] loss: 0.0011693\n",
      "Test set: Average loss: 2.5900, Accuracy: 2518/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3579, Accuracy: 2646/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.3206, Accuracy: 5382/10000 (54%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3008, Accuracy: 700/5000 (14%)\n",
      "[epoch 1] loss: 2.0801474\n",
      "Test set: Average loss: 1.7816, Accuracy: 1914/5000 (38%)\n",
      "[epoch 2] loss: 1.5405627\n",
      "Test set: Average loss: 1.7096, Accuracy: 1956/5000 (39%)\n",
      "[epoch 3] loss: 1.2493855\n",
      "Test set: Average loss: 1.4647, Accuracy: 2463/5000 (49%)\n",
      "[epoch 4] loss: 0.9592106\n",
      "Test set: Average loss: 1.5842, Accuracy: 2359/5000 (47%)\n",
      "[epoch 5] loss: 0.8192719\n",
      "Test set: Average loss: 1.5065, Accuracy: 2542/5000 (51%)\n",
      "[epoch 6] loss: 0.6054028\n",
      "Test set: Average loss: 1.5662, Accuracy: 2493/5000 (50%)\n",
      "[epoch 7] loss: 0.4762405\n",
      "Test set: Average loss: 1.6415, Accuracy: 2496/5000 (50%)\n",
      "[epoch 8] loss: 0.3213442\n",
      "Test set: Average loss: 1.6845, Accuracy: 2490/5000 (50%)\n",
      "[epoch 9] loss: 0.2420012\n",
      "Test set: Average loss: 1.7260, Accuracy: 2524/5000 (50%)\n",
      "[epoch 10] loss: 0.1768837\n",
      "Test set: Average loss: 1.7894, Accuracy: 2556/5000 (51%)\n",
      "[epoch 11] loss: 0.1173288\n",
      "Test set: Average loss: 2.0365, Accuracy: 2412/5000 (48%)\n",
      "[epoch 12] loss: 0.0830836\n",
      "Test set: Average loss: 2.0064, Accuracy: 2466/5000 (49%)\n",
      "[epoch 13] loss: 0.0416031\n",
      "Test set: Average loss: 2.1645, Accuracy: 2458/5000 (49%)\n",
      "[epoch 14] loss: 0.0288775\n",
      "Test set: Average loss: 2.1813, Accuracy: 2459/5000 (49%)\n",
      "[epoch 15] loss: 0.0206748\n",
      "Test set: Average loss: 2.1929, Accuracy: 2465/5000 (49%)\n",
      "[epoch 16] loss: 0.0147993\n",
      "Test set: Average loss: 2.3177, Accuracy: 2435/5000 (49%)\n",
      "[epoch 17] loss: 0.0128274\n",
      "Test set: Average loss: 2.3327, Accuracy: 2458/5000 (49%)\n",
      "[epoch 18] loss: 0.0099641\n",
      "Test set: Average loss: 2.3155, Accuracy: 2468/5000 (49%)\n",
      "[epoch 19] loss: 0.0088003\n",
      "Test set: Average loss: 2.3523, Accuracy: 2460/5000 (49%)\n",
      "[epoch 20] loss: 0.0072069\n",
      "Test set: Average loss: 2.3955, Accuracy: 2455/5000 (49%)\n",
      "[epoch 21] loss: 0.0065133\n",
      "Test set: Average loss: 2.4221, Accuracy: 2457/5000 (49%)\n",
      "[epoch 22] loss: 0.0058475\n",
      "Test set: Average loss: 2.4332, Accuracy: 2448/5000 (49%)\n",
      "[epoch 23] loss: 0.0053648\n",
      "Test set: Average loss: 2.4537, Accuracy: 2453/5000 (49%)\n",
      "[epoch 24] loss: 0.0049573\n",
      "Test set: Average loss: 2.4752, Accuracy: 2461/5000 (49%)\n",
      "[epoch 25] loss: 0.0045275\n",
      "Test set: Average loss: 2.4978, Accuracy: 2453/5000 (49%)\n",
      "[epoch 26] loss: 0.0042298\n",
      "Test set: Average loss: 2.5094, Accuracy: 2455/5000 (49%)\n",
      "[epoch 27] loss: 0.0039250\n",
      "Test set: Average loss: 2.5294, Accuracy: 2454/5000 (49%)\n",
      "[epoch 28] loss: 0.0037003\n",
      "Test set: Average loss: 2.5425, Accuracy: 2450/5000 (49%)\n",
      "[epoch 29] loss: 0.0034728\n",
      "Test set: Average loss: 2.5641, Accuracy: 2459/5000 (49%)\n",
      "[epoch 30] loss: 0.0032522\n",
      "Test set: Average loss: 2.5770, Accuracy: 2459/5000 (49%)\n",
      "[epoch 31] loss: 0.0030438\n",
      "Test set: Average loss: 2.5889, Accuracy: 2451/5000 (49%)\n",
      "[epoch 32] loss: 0.0028612\n",
      "Test set: Average loss: 2.6011, Accuracy: 2454/5000 (49%)\n",
      "[epoch 33] loss: 0.0026901\n",
      "Test set: Average loss: 2.6201, Accuracy: 2449/5000 (49%)\n",
      "[epoch 34] loss: 0.0025500\n",
      "Test set: Average loss: 2.6336, Accuracy: 2448/5000 (49%)\n",
      "[epoch 35] loss: 0.0024328\n",
      "Test set: Average loss: 2.6453, Accuracy: 2454/5000 (49%)\n",
      "[epoch 36] loss: 0.0022985\n",
      "Test set: Average loss: 2.6546, Accuracy: 2447/5000 (49%)\n",
      "[epoch 37] loss: 0.0022096\n",
      "Test set: Average loss: 2.6677, Accuracy: 2445/5000 (49%)\n",
      "[epoch 38] loss: 0.0021112\n",
      "Test set: Average loss: 2.6784, Accuracy: 2449/5000 (49%)\n",
      "[epoch 39] loss: 0.0020124\n",
      "Test set: Average loss: 2.6895, Accuracy: 2447/5000 (49%)\n",
      "[epoch 40] loss: 0.0019122\n",
      "Test set: Average loss: 2.6999, Accuracy: 2445/5000 (49%)\n",
      "[epoch 41] loss: 0.0018374\n",
      "Test set: Average loss: 2.7088, Accuracy: 2448/5000 (49%)\n",
      "[epoch 42] loss: 0.0017562\n",
      "Test set: Average loss: 2.7216, Accuracy: 2442/5000 (49%)\n",
      "[epoch 43] loss: 0.0016876\n",
      "Test set: Average loss: 2.7327, Accuracy: 2447/5000 (49%)\n",
      "[epoch 44] loss: 0.0016200\n",
      "Test set: Average loss: 2.7394, Accuracy: 2446/5000 (49%)\n",
      "[epoch 45] loss: 0.0015481\n",
      "Test set: Average loss: 2.7526, Accuracy: 2438/5000 (49%)\n",
      "[epoch 46] loss: 0.0014959\n",
      "Test set: Average loss: 2.7632, Accuracy: 2442/5000 (49%)\n",
      "[epoch 47] loss: 0.0014294\n",
      "Test set: Average loss: 2.7697, Accuracy: 2441/5000 (49%)\n",
      "[epoch 48] loss: 0.0013802\n",
      "Test set: Average loss: 2.7755, Accuracy: 2444/5000 (49%)\n",
      "[epoch 49] loss: 0.0013290\n",
      "Test set: Average loss: 2.7892, Accuracy: 2442/5000 (49%)\n",
      "[epoch 50] loss: 0.0012905\n",
      "Test set: Average loss: 2.7961, Accuracy: 2444/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7894, Accuracy: 2556/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.7585, Accuracy: 5126/10000 (51%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3107, Accuracy: 160/5000 (3%)\n",
      "[epoch 1] loss: 1.8821807\n",
      "Test set: Average loss: 1.6037, Accuracy: 2063/5000 (41%)\n",
      "[epoch 2] loss: 1.2996363\n",
      "Test set: Average loss: 1.4210, Accuracy: 2509/5000 (50%)\n",
      "[epoch 3] loss: 1.0280296\n",
      "Test set: Average loss: 1.3221, Accuracy: 2779/5000 (56%)\n",
      "[epoch 4] loss: 0.8602281\n",
      "Test set: Average loss: 1.3512, Accuracy: 2691/5000 (54%)\n",
      "[epoch 5] loss: 0.6748881\n",
      "Test set: Average loss: 1.3762, Accuracy: 2722/5000 (54%)\n",
      "[epoch 6] loss: 0.5047526\n",
      "Test set: Average loss: 1.5327, Accuracy: 2620/5000 (52%)\n",
      "[epoch 7] loss: 0.3749573\n",
      "Test set: Average loss: 1.6376, Accuracy: 2639/5000 (53%)\n",
      "[epoch 8] loss: 0.3213130\n",
      "Test set: Average loss: 1.7740, Accuracy: 2577/5000 (52%)\n",
      "[epoch 9] loss: 0.2027612\n",
      "Test set: Average loss: 1.7718, Accuracy: 2650/5000 (53%)\n",
      "[epoch 10] loss: 0.1304980\n",
      "Test set: Average loss: 1.9704, Accuracy: 2541/5000 (51%)\n",
      "[epoch 11] loss: 0.0755958\n",
      "Test set: Average loss: 2.0757, Accuracy: 2601/5000 (52%)\n",
      "[epoch 12] loss: 0.0465442\n",
      "Test set: Average loss: 2.1959, Accuracy: 2546/5000 (51%)\n",
      "[epoch 13] loss: 0.0414360\n",
      "Test set: Average loss: 2.3105, Accuracy: 2571/5000 (51%)\n",
      "[epoch 14] loss: 0.0689721\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4193, Accuracy: 2518/5000 (50%)\n",
      "[epoch 15] loss: 0.0424133\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3249, Accuracy: 2584/5000 (52%)\n",
      "[epoch 16] loss: 0.0234129\n",
      "Test set: Average loss: 2.3206, Accuracy: 2582/5000 (52%)\n",
      "[epoch 17] loss: 0.0221947\n",
      "Test set: Average loss: 2.3153, Accuracy: 2580/5000 (52%)\n",
      "[epoch 18] loss: 0.0213166\n",
      "Test set: Average loss: 2.3107, Accuracy: 2590/5000 (52%)\n",
      "[epoch 19] loss: 0.0204052\n",
      "Test set: Average loss: 2.3074, Accuracy: 2598/5000 (52%)\n",
      "[epoch 20] loss: 0.0195626\n",
      "Test set: Average loss: 2.3044, Accuracy: 2604/5000 (52%)\n",
      "[epoch 21] loss: 0.0188164\n",
      "Test set: Average loss: 2.3019, Accuracy: 2608/5000 (52%)\n",
      "[epoch 22] loss: 0.0189291\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3001, Accuracy: 2604/5000 (52%)\n",
      "[epoch 23] loss: 0.0184476\n",
      "Test set: Average loss: 2.2999, Accuracy: 2604/5000 (52%)\n",
      "[epoch 24] loss: 0.0181720\n",
      "Test set: Average loss: 2.2998, Accuracy: 2606/5000 (52%)\n",
      "[epoch 25] loss: 0.0179149\n",
      "Test set: Average loss: 2.2996, Accuracy: 2606/5000 (52%)\n",
      "[epoch 26] loss: 0.0180838\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2606/5000 (52%)\n",
      "[epoch 27] loss: 0.0182614\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 28] loss: 0.0184446\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 29] loss: 0.0181684\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 30] loss: 0.0180151\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 31] loss: 0.0183433\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 32] loss: 0.0181116\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 33] loss: 0.0181075\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 34] loss: 0.0181211\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 35] loss: 0.0182370\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 36] loss: 0.0180998\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 37] loss: 0.0180242\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 38] loss: 0.0178300\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 39] loss: 0.0180735\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 40] loss: 0.0183217\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 41] loss: 0.0180124\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 42] loss: 0.0178905\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 43] loss: 0.0179329\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 44] loss: 0.0180752\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 45] loss: 0.0180390\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 46] loss: 0.0178832\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 47] loss: 0.0178972\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 48] loss: 0.0181268\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 49] loss: 0.0178923\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "[epoch 50] loss: 0.0180959\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.2994, Accuracy: 2605/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3221, Accuracy: 2779/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.2902, Accuracy: 5520/10000 (55%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3075, Accuracy: 270/5000 (5%)\n",
      "[epoch 1] loss: 1.7972407\n",
      "Test set: Average loss: 1.4686, Accuracy: 2475/5000 (50%)\n",
      "[epoch 2] loss: 1.1660713\n",
      "Test set: Average loss: 1.3799, Accuracy: 2564/5000 (51%)\n",
      "[epoch 3] loss: 0.9389753\n",
      "Test set: Average loss: 1.4004, Accuracy: 2554/5000 (51%)\n",
      "[epoch 4] loss: 0.7534183\n",
      "Test set: Average loss: 1.3602, Accuracy: 2705/5000 (54%)\n",
      "[epoch 5] loss: 0.5795625\n",
      "Test set: Average loss: 1.4084, Accuracy: 2761/5000 (55%)\n",
      "[epoch 6] loss: 0.4613866\n",
      "Test set: Average loss: 1.5327, Accuracy: 2654/5000 (53%)\n",
      "[epoch 7] loss: 0.3305268\n",
      "Test set: Average loss: 1.6165, Accuracy: 2630/5000 (53%)\n",
      "[epoch 8] loss: 0.2987772\n",
      "Test set: Average loss: 1.6869, Accuracy: 2665/5000 (53%)\n",
      "[epoch 9] loss: 0.1973351\n",
      "Test set: Average loss: 1.7607, Accuracy: 2651/5000 (53%)\n",
      "[epoch 10] loss: 0.1229326\n",
      "Test set: Average loss: 1.8515, Accuracy: 2618/5000 (52%)\n",
      "[epoch 11] loss: 0.0754845\n",
      "Test set: Average loss: 1.9917, Accuracy: 2679/5000 (54%)\n",
      "[epoch 12] loss: 0.0555109\n",
      "Test set: Average loss: 2.1056, Accuracy: 2635/5000 (53%)\n",
      "[epoch 13] loss: 0.0362599\n",
      "Test set: Average loss: 2.1481, Accuracy: 2616/5000 (52%)\n",
      "[epoch 14] loss: 0.0212933\n",
      "Test set: Average loss: 2.2275, Accuracy: 2660/5000 (53%)\n",
      "[epoch 15] loss: 0.0202512\n",
      "Test set: Average loss: 2.2383, Accuracy: 2620/5000 (52%)\n",
      "[epoch 16] loss: 0.0114478\n",
      "Test set: Average loss: 2.2660, Accuracy: 2645/5000 (53%)\n",
      "[epoch 17] loss: 0.0083749\n",
      "Test set: Average loss: 2.3204, Accuracy: 2637/5000 (53%)\n",
      "[epoch 18] loss: 0.0064348\n",
      "Test set: Average loss: 2.3370, Accuracy: 2650/5000 (53%)\n",
      "[epoch 19] loss: 0.0053245\n",
      "Test set: Average loss: 2.3663, Accuracy: 2646/5000 (53%)\n",
      "[epoch 20] loss: 0.0046181\n",
      "Test set: Average loss: 2.3882, Accuracy: 2649/5000 (53%)\n",
      "[epoch 21] loss: 0.0041326\n",
      "Test set: Average loss: 2.4135, Accuracy: 2653/5000 (53%)\n",
      "[epoch 22] loss: 0.0038369\n",
      "Test set: Average loss: 2.4347, Accuracy: 2655/5000 (53%)\n",
      "[epoch 23] loss: 0.0036477\n",
      "Test set: Average loss: 2.4564, Accuracy: 2657/5000 (53%)\n",
      "[epoch 24] loss: 0.0033238\n",
      "Test set: Average loss: 2.4768, Accuracy: 2648/5000 (53%)\n",
      "[epoch 25] loss: 0.0030150\n",
      "Test set: Average loss: 2.4942, Accuracy: 2646/5000 (53%)\n",
      "[epoch 26] loss: 0.0027476\n",
      "Test set: Average loss: 2.5166, Accuracy: 2653/5000 (53%)\n",
      "[epoch 27] loss: 0.0025186\n",
      "Test set: Average loss: 2.5297, Accuracy: 2644/5000 (53%)\n",
      "[epoch 28] loss: 0.0023274\n",
      "Test set: Average loss: 2.5495, Accuracy: 2650/5000 (53%)\n",
      "[epoch 29] loss: 0.0022062\n",
      "Test set: Average loss: 2.5676, Accuracy: 2650/5000 (53%)\n",
      "[epoch 30] loss: 0.0020733\n",
      "Test set: Average loss: 2.5799, Accuracy: 2646/5000 (53%)\n",
      "[epoch 31] loss: 0.0019309\n",
      "Test set: Average loss: 2.5950, Accuracy: 2647/5000 (53%)\n",
      "[epoch 32] loss: 0.0018513\n",
      "Test set: Average loss: 2.6079, Accuracy: 2654/5000 (53%)\n",
      "[epoch 33] loss: 0.0017189\n",
      "Test set: Average loss: 2.6225, Accuracy: 2647/5000 (53%)\n",
      "[epoch 34] loss: 0.0016396\n",
      "Test set: Average loss: 2.6358, Accuracy: 2649/5000 (53%)\n",
      "[epoch 35] loss: 0.0015644\n",
      "Test set: Average loss: 2.6486, Accuracy: 2647/5000 (53%)\n",
      "[epoch 36] loss: 0.0014819\n",
      "Test set: Average loss: 2.6615, Accuracy: 2643/5000 (53%)\n",
      "[epoch 37] loss: 0.0014093\n",
      "Test set: Average loss: 2.6750, Accuracy: 2650/5000 (53%)\n",
      "[epoch 38] loss: 0.0013488\n",
      "Test set: Average loss: 2.6866, Accuracy: 2657/5000 (53%)\n",
      "[epoch 39] loss: 0.0012845\n",
      "Test set: Average loss: 2.6965, Accuracy: 2646/5000 (53%)\n",
      "[epoch 40] loss: 0.0012216\n",
      "Test set: Average loss: 2.7068, Accuracy: 2647/5000 (53%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.0011648\n",
      "Test set: Average loss: 2.7200, Accuracy: 2649/5000 (53%)\n",
      "[epoch 42] loss: 0.0011122\n",
      "Test set: Average loss: 2.7321, Accuracy: 2651/5000 (53%)\n",
      "[epoch 43] loss: 0.0010572\n",
      "Test set: Average loss: 2.7421, Accuracy: 2646/5000 (53%)\n",
      "[epoch 44] loss: 0.0010254\n",
      "Test set: Average loss: 2.7528, Accuracy: 2653/5000 (53%)\n",
      "[epoch 45] loss: 0.0009777\n",
      "Test set: Average loss: 2.7623, Accuracy: 2646/5000 (53%)\n",
      "[epoch 46] loss: 0.0009399\n",
      "Test set: Average loss: 2.7713, Accuracy: 2649/5000 (53%)\n",
      "[epoch 47] loss: 0.0008953\n",
      "Test set: Average loss: 2.7807, Accuracy: 2646/5000 (53%)\n",
      "[epoch 48] loss: 0.0008718\n",
      "Test set: Average loss: 2.7914, Accuracy: 2652/5000 (53%)\n",
      "[epoch 49] loss: 0.0008424\n",
      "Test set: Average loss: 2.7999, Accuracy: 2644/5000 (53%)\n",
      "[epoch 50] loss: 0.0008073\n",
      "Test set: Average loss: 2.8098, Accuracy: 2648/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4084, Accuracy: 2761/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.3418, Accuracy: 5666/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3015, Accuracy: 383/5000 (8%)\n",
      "[epoch 1] loss: 1.8861000\n",
      "Test set: Average loss: 1.5363, Accuracy: 2350/5000 (47%)\n",
      "[epoch 2] loss: 1.3394939\n",
      "Test set: Average loss: 1.3835, Accuracy: 2552/5000 (51%)\n",
      "[epoch 3] loss: 1.0360610\n",
      "Test set: Average loss: 1.3756, Accuracy: 2606/5000 (52%)\n",
      "[epoch 4] loss: 0.8801136\n",
      "Test set: Average loss: 1.4584, Accuracy: 2583/5000 (52%)\n",
      "[epoch 5] loss: 0.7851219\n",
      "Test set: Average loss: 1.5592, Accuracy: 2535/5000 (51%)\n",
      "[epoch 6] loss: 0.6069774\n",
      "Test set: Average loss: 1.5823, Accuracy: 2567/5000 (51%)\n",
      "[epoch 7] loss: 0.4487992\n",
      "Test set: Average loss: 1.7216, Accuracy: 2559/5000 (51%)\n",
      "[epoch 8] loss: 0.3205880\n",
      "Test set: Average loss: 1.7163, Accuracy: 2610/5000 (52%)\n",
      "[epoch 9] loss: 0.1983034\n",
      "Test set: Average loss: 1.8868, Accuracy: 2524/5000 (50%)\n",
      "[epoch 10] loss: 0.1442558\n",
      "Test set: Average loss: 1.9735, Accuracy: 2528/5000 (51%)\n",
      "[epoch 11] loss: 0.0895230\n",
      "Test set: Average loss: 2.1183, Accuracy: 2472/5000 (49%)\n",
      "[epoch 12] loss: 0.0507110\n",
      "Test set: Average loss: 2.1789, Accuracy: 2525/5000 (50%)\n",
      "[epoch 13] loss: 0.0280230\n",
      "Test set: Average loss: 2.3087, Accuracy: 2506/5000 (50%)\n",
      "[epoch 14] loss: 0.0177924\n",
      "Test set: Average loss: 2.3502, Accuracy: 2519/5000 (50%)\n",
      "[epoch 15] loss: 0.0130670\n",
      "Test set: Average loss: 2.4090, Accuracy: 2523/5000 (50%)\n",
      "[epoch 16] loss: 0.0107328\n",
      "Test set: Average loss: 2.4582, Accuracy: 2513/5000 (50%)\n",
      "[epoch 17] loss: 0.0088258\n",
      "Test set: Average loss: 2.5042, Accuracy: 2520/5000 (50%)\n",
      "[epoch 18] loss: 0.0075361\n",
      "Test set: Average loss: 2.5384, Accuracy: 2527/5000 (51%)\n",
      "[epoch 19] loss: 0.0065951\n",
      "Test set: Average loss: 2.5787, Accuracy: 2517/5000 (50%)\n",
      "[epoch 20] loss: 0.0057411\n",
      "Test set: Average loss: 2.6018, Accuracy: 2520/5000 (50%)\n",
      "[epoch 21] loss: 0.0051891\n",
      "Test set: Average loss: 2.6301, Accuracy: 2518/5000 (50%)\n",
      "[epoch 22] loss: 0.0046149\n",
      "Test set: Average loss: 2.6623, Accuracy: 2521/5000 (50%)\n",
      "[epoch 23] loss: 0.0041403\n",
      "Test set: Average loss: 2.6831, Accuracy: 2510/5000 (50%)\n",
      "[epoch 24] loss: 0.0037867\n",
      "Test set: Average loss: 2.7109, Accuracy: 2520/5000 (50%)\n",
      "[epoch 25] loss: 0.0035372\n",
      "Test set: Average loss: 2.7333, Accuracy: 2503/5000 (50%)\n",
      "[epoch 26] loss: 0.0032392\n",
      "Test set: Average loss: 2.7555, Accuracy: 2512/5000 (50%)\n",
      "[epoch 27] loss: 0.0029945\n",
      "Test set: Average loss: 2.7735, Accuracy: 2518/5000 (50%)\n",
      "[epoch 28] loss: 0.0027552\n",
      "Test set: Average loss: 2.7982, Accuracy: 2516/5000 (50%)\n",
      "[epoch 29] loss: 0.0025982\n",
      "Test set: Average loss: 2.8071, Accuracy: 2508/5000 (50%)\n",
      "[epoch 30] loss: 0.0024017\n",
      "Test set: Average loss: 2.8327, Accuracy: 2515/5000 (50%)\n",
      "[epoch 31] loss: 0.0022629\n",
      "Test set: Average loss: 2.8491, Accuracy: 2513/5000 (50%)\n",
      "[epoch 32] loss: 0.0021121\n",
      "Test set: Average loss: 2.8637, Accuracy: 2514/5000 (50%)\n",
      "[epoch 33] loss: 0.0019979\n",
      "Test set: Average loss: 2.8824, Accuracy: 2502/5000 (50%)\n",
      "[epoch 34] loss: 0.0018632\n",
      "Test set: Average loss: 2.8950, Accuracy: 2510/5000 (50%)\n",
      "[epoch 35] loss: 0.0017743\n",
      "Test set: Average loss: 2.9135, Accuracy: 2510/5000 (50%)\n",
      "[epoch 36] loss: 0.0016868\n",
      "Test set: Average loss: 2.9276, Accuracy: 2510/5000 (50%)\n",
      "[epoch 37] loss: 0.0016047\n",
      "Test set: Average loss: 2.9426, Accuracy: 2510/5000 (50%)\n",
      "[epoch 38] loss: 0.0015275\n",
      "Test set: Average loss: 2.9553, Accuracy: 2505/5000 (50%)\n",
      "[epoch 39] loss: 0.0014271\n",
      "Test set: Average loss: 2.9700, Accuracy: 2502/5000 (50%)\n",
      "[epoch 40] loss: 0.0013699\n",
      "Test set: Average loss: 2.9848, Accuracy: 2503/5000 (50%)\n",
      "[epoch 41] loss: 0.0013009\n",
      "Test set: Average loss: 2.9930, Accuracy: 2501/5000 (50%)\n",
      "[epoch 42] loss: 0.0012443\n",
      "Test set: Average loss: 3.0068, Accuracy: 2508/5000 (50%)\n",
      "[epoch 43] loss: 0.0011980\n",
      "Test set: Average loss: 3.0222, Accuracy: 2499/5000 (50%)\n",
      "[epoch 44] loss: 0.0011321\n",
      "Test set: Average loss: 3.0310, Accuracy: 2502/5000 (50%)\n",
      "[epoch 45] loss: 0.0010878\n",
      "Test set: Average loss: 3.0415, Accuracy: 2499/5000 (50%)\n",
      "[epoch 46] loss: 0.0010402\n",
      "Test set: Average loss: 3.0534, Accuracy: 2500/5000 (50%)\n",
      "[epoch 47] loss: 0.0009886\n",
      "Test set: Average loss: 3.0656, Accuracy: 2501/5000 (50%)\n",
      "[epoch 48] loss: 0.0009577\n",
      "Test set: Average loss: 3.0781, Accuracy: 2501/5000 (50%)\n",
      "[epoch 49] loss: 0.0009199\n",
      "Test set: Average loss: 3.0859, Accuracy: 2508/5000 (50%)\n",
      "[epoch 50] loss: 0.0008798\n",
      "Test set: Average loss: 3.0970, Accuracy: 2495/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7163, Accuracy: 2610/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.6626, Accuracy: 5261/10000 (53%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3102, Accuracy: 405/5000 (8%)\n",
      "[epoch 1] loss: 1.7249177\n",
      "Test set: Average loss: 1.4562, Accuracy: 2359/5000 (47%)\n",
      "[epoch 2] loss: 1.2410467\n",
      "Test set: Average loss: 1.5119, Accuracy: 2288/5000 (46%)\n",
      "[epoch 3] loss: 1.0461220\n",
      "Test set: Average loss: 1.2897, Accuracy: 2790/5000 (56%)\n",
      "[epoch 4] loss: 0.8528488\n",
      "Test set: Average loss: 1.3338, Accuracy: 2736/5000 (55%)\n",
      "[epoch 5] loss: 0.7036015\n",
      "Test set: Average loss: 1.3976, Accuracy: 2738/5000 (55%)\n",
      "[epoch 6] loss: 0.5480246\n",
      "Test set: Average loss: 1.5039, Accuracy: 2738/5000 (55%)\n",
      "[epoch 7] loss: 0.4739281\n",
      "Test set: Average loss: 1.5815, Accuracy: 2714/5000 (54%)\n",
      "[epoch 8] loss: 0.3760486\n",
      "Test set: Average loss: 1.8031, Accuracy: 2631/5000 (53%)\n",
      "[epoch 9] loss: 0.2918651\n",
      "Test set: Average loss: 1.8735, Accuracy: 2684/5000 (54%)\n",
      "[epoch 10] loss: 0.2171351\n",
      "Test set: Average loss: 1.9929, Accuracy: 2648/5000 (53%)\n",
      "[epoch 11] loss: 0.1778725\n",
      "Test set: Average loss: 2.1091, Accuracy: 2574/5000 (51%)\n",
      "[epoch 12] loss: 0.1116946\n",
      "Test set: Average loss: 2.2846, Accuracy: 2555/5000 (51%)\n",
      "[epoch 13] loss: 0.0771631\n",
      "Test set: Average loss: 2.2522, Accuracy: 2619/5000 (52%)\n",
      "[epoch 14] loss: 0.0511070\n",
      "Test set: Average loss: 2.4426, Accuracy: 2577/5000 (52%)\n",
      "[epoch 15] loss: 0.0462911\n",
      "Test set: Average loss: 2.4962, Accuracy: 2575/5000 (52%)\n",
      "[epoch 16] loss: 0.0278084\n",
      "Test set: Average loss: 2.6233, Accuracy: 2580/5000 (52%)\n",
      "[epoch 17] loss: 0.0130086\n",
      "Test set: Average loss: 2.6123, Accuracy: 2618/5000 (52%)\n",
      "[epoch 18] loss: 0.0082346\n",
      "Test set: Average loss: 2.6890, Accuracy: 2643/5000 (53%)\n",
      "[epoch 19] loss: 0.0060950\n",
      "Test set: Average loss: 2.7237, Accuracy: 2633/5000 (53%)\n",
      "[epoch 20] loss: 0.0048662\n",
      "Test set: Average loss: 2.7499, Accuracy: 2638/5000 (53%)\n",
      "[epoch 21] loss: 0.0043368\n",
      "Test set: Average loss: 2.7809, Accuracy: 2634/5000 (53%)\n",
      "[epoch 22] loss: 0.0037481\n",
      "Test set: Average loss: 2.8135, Accuracy: 2630/5000 (53%)\n",
      "[epoch 23] loss: 0.0034337\n",
      "Test set: Average loss: 2.8327, Accuracy: 2641/5000 (53%)\n",
      "[epoch 24] loss: 0.0031154\n",
      "Test set: Average loss: 2.8709, Accuracy: 2632/5000 (53%)\n",
      "[epoch 25] loss: 0.0029757\n",
      "Test set: Average loss: 2.8819, Accuracy: 2637/5000 (53%)\n",
      "[epoch 26] loss: 0.0026316\n",
      "Test set: Average loss: 2.9041, Accuracy: 2637/5000 (53%)\n",
      "[epoch 27] loss: 0.0024732\n",
      "Test set: Average loss: 2.9268, Accuracy: 2637/5000 (53%)\n",
      "[epoch 28] loss: 0.0022951\n",
      "Test set: Average loss: 2.9453, Accuracy: 2631/5000 (53%)\n",
      "[epoch 29] loss: 0.0021174\n",
      "Test set: Average loss: 2.9665, Accuracy: 2632/5000 (53%)\n",
      "[epoch 30] loss: 0.0019393\n",
      "Test set: Average loss: 2.9890, Accuracy: 2631/5000 (53%)\n",
      "[epoch 31] loss: 0.0018124\n",
      "Test set: Average loss: 3.0047, Accuracy: 2635/5000 (53%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 32] loss: 0.0017293\n",
      "Test set: Average loss: 3.0445, Accuracy: 2626/5000 (53%)\n",
      "[epoch 33] loss: 0.0016196\n",
      "Test set: Average loss: 3.0362, Accuracy: 2631/5000 (53%)\n",
      "[epoch 34] loss: 0.0015374\n",
      "Test set: Average loss: 3.0556, Accuracy: 2632/5000 (53%)\n",
      "[epoch 35] loss: 0.0014684\n",
      "Test set: Average loss: 3.0720, Accuracy: 2628/5000 (53%)\n",
      "[epoch 36] loss: 0.0013829\n",
      "Test set: Average loss: 3.0878, Accuracy: 2632/5000 (53%)\n",
      "[epoch 37] loss: 0.0013228\n",
      "Test set: Average loss: 3.1003, Accuracy: 2632/5000 (53%)\n",
      "[epoch 38] loss: 0.0012500\n",
      "Test set: Average loss: 3.1187, Accuracy: 2629/5000 (53%)\n",
      "[epoch 39] loss: 0.0011705\n",
      "Test set: Average loss: 3.1327, Accuracy: 2629/5000 (53%)\n",
      "[epoch 40] loss: 0.0011239\n",
      "Test set: Average loss: 3.1468, Accuracy: 2626/5000 (53%)\n",
      "[epoch 41] loss: 0.0011002\n",
      "Test set: Average loss: 3.1612, Accuracy: 2632/5000 (53%)\n",
      "[epoch 42] loss: 0.0010227\n",
      "Test set: Average loss: 3.1942, Accuracy: 2616/5000 (52%)\n",
      "[epoch 43] loss: 0.0009912\n",
      "Test set: Average loss: 3.1885, Accuracy: 2622/5000 (52%)\n",
      "[epoch 44] loss: 0.0009336\n",
      "Test set: Average loss: 3.1999, Accuracy: 2622/5000 (52%)\n",
      "[epoch 45] loss: 0.0009059\n",
      "Test set: Average loss: 3.2109, Accuracy: 2619/5000 (52%)\n",
      "[epoch 46] loss: 0.0008569\n",
      "Test set: Average loss: 3.2260, Accuracy: 2620/5000 (52%)\n",
      "[epoch 47] loss: 0.0008209\n",
      "Test set: Average loss: 3.2366, Accuracy: 2620/5000 (52%)\n",
      "[epoch 48] loss: 0.0007995\n",
      "Test set: Average loss: 3.2489, Accuracy: 2621/5000 (52%)\n",
      "[epoch 49] loss: 0.0007650\n",
      "Test set: Average loss: 3.2609, Accuracy: 2615/5000 (52%)\n",
      "[epoch 50] loss: 0.0007306\n",
      "Test set: Average loss: 3.2725, Accuracy: 2614/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2897, Accuracy: 2790/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.2634, Accuracy: 5553/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2930, Accuracy: 887/5000 (18%)\n",
      "[epoch 1] loss: 1.6391171\n",
      "Test set: Average loss: 1.4800, Accuracy: 2328/5000 (47%)\n",
      "[epoch 2] loss: 1.0526822\n",
      "Test set: Average loss: 1.4150, Accuracy: 2535/5000 (51%)\n",
      "[epoch 3] loss: 0.8607440\n",
      "Test set: Average loss: 1.3464, Accuracy: 2721/5000 (54%)\n",
      "[epoch 4] loss: 0.6417609\n",
      "Test set: Average loss: 1.5080, Accuracy: 2628/5000 (53%)\n",
      "[epoch 5] loss: 0.5492776\n",
      "Test set: Average loss: 1.5567, Accuracy: 2718/5000 (54%)\n",
      "[epoch 6] loss: 0.4811483\n",
      "Test set: Average loss: 1.5778, Accuracy: 2722/5000 (54%)\n",
      "[epoch 7] loss: 0.3046874\n",
      "Test set: Average loss: 1.6734, Accuracy: 2679/5000 (54%)\n",
      "[epoch 8] loss: 0.2646223\n",
      "Test set: Average loss: 1.8190, Accuracy: 2672/5000 (53%)\n",
      "[epoch 9] loss: 0.1962634\n",
      "Test set: Average loss: 1.9609, Accuracy: 2644/5000 (53%)\n",
      "[epoch 10] loss: 0.1237681\n",
      "Test set: Average loss: 2.0418, Accuracy: 2683/5000 (54%)\n",
      "[epoch 11] loss: 0.1081079\n",
      "Test set: Average loss: 2.1846, Accuracy: 2674/5000 (53%)\n",
      "[epoch 12] loss: 0.0935044\n",
      "Test set: Average loss: 2.2559, Accuracy: 2669/5000 (53%)\n",
      "[epoch 13] loss: 0.0537646\n",
      "Test set: Average loss: 2.3603, Accuracy: 2610/5000 (52%)\n",
      "[epoch 14] loss: 0.0323381\n",
      "Test set: Average loss: 2.3760, Accuracy: 2669/5000 (53%)\n",
      "[epoch 15] loss: 0.0205173\n",
      "Test set: Average loss: 2.4649, Accuracy: 2659/5000 (53%)\n",
      "[epoch 16] loss: 0.0096382\n",
      "Test set: Average loss: 2.5116, Accuracy: 2675/5000 (54%)\n",
      "[epoch 17] loss: 0.0063094\n",
      "Test set: Average loss: 2.5313, Accuracy: 2683/5000 (54%)\n",
      "[epoch 18] loss: 0.0048809\n",
      "Test set: Average loss: 2.5647, Accuracy: 2674/5000 (53%)\n",
      "[epoch 19] loss: 0.0041730\n",
      "Test set: Average loss: 2.5908, Accuracy: 2669/5000 (53%)\n",
      "[epoch 20] loss: 0.0036227\n",
      "Test set: Average loss: 2.6225, Accuracy: 2671/5000 (53%)\n",
      "[epoch 21] loss: 0.0032880\n",
      "Test set: Average loss: 2.6473, Accuracy: 2665/5000 (53%)\n",
      "[epoch 22] loss: 0.0029587\n",
      "Test set: Average loss: 2.6721, Accuracy: 2656/5000 (53%)\n",
      "[epoch 23] loss: 0.0026944\n",
      "Test set: Average loss: 2.6983, Accuracy: 2666/5000 (53%)\n",
      "[epoch 24] loss: 0.0025077\n",
      "Test set: Average loss: 2.7201, Accuracy: 2660/5000 (53%)\n",
      "[epoch 25] loss: 0.0022941\n",
      "Test set: Average loss: 2.7362, Accuracy: 2667/5000 (53%)\n",
      "[epoch 26] loss: 0.0021084\n",
      "Test set: Average loss: 2.7571, Accuracy: 2656/5000 (53%)\n",
      "[epoch 27] loss: 0.0019777\n",
      "Test set: Average loss: 2.7754, Accuracy: 2659/5000 (53%)\n",
      "[epoch 28] loss: 0.0018187\n",
      "Test set: Average loss: 2.7953, Accuracy: 2670/5000 (53%)\n",
      "[epoch 29] loss: 0.0017120\n",
      "Test set: Average loss: 2.8095, Accuracy: 2655/5000 (53%)\n",
      "[epoch 30] loss: 0.0016025\n",
      "Test set: Average loss: 2.8296, Accuracy: 2667/5000 (53%)\n",
      "[epoch 31] loss: 0.0015157\n",
      "Test set: Average loss: 2.8427, Accuracy: 2666/5000 (53%)\n",
      "[epoch 32] loss: 0.0014243\n",
      "Test set: Average loss: 2.8610, Accuracy: 2668/5000 (53%)\n",
      "[epoch 33] loss: 0.0013451\n",
      "Test set: Average loss: 2.8770, Accuracy: 2661/5000 (53%)\n",
      "[epoch 34] loss: 0.0012870\n",
      "Test set: Average loss: 2.8870, Accuracy: 2655/5000 (53%)\n",
      "[epoch 35] loss: 0.0012171\n",
      "Test set: Average loss: 2.9048, Accuracy: 2659/5000 (53%)\n",
      "[epoch 36] loss: 0.0011467\n",
      "Test set: Average loss: 2.9175, Accuracy: 2659/5000 (53%)\n",
      "[epoch 37] loss: 0.0010765\n",
      "Test set: Average loss: 2.9319, Accuracy: 2663/5000 (53%)\n",
      "[epoch 38] loss: 0.0010302\n",
      "Test set: Average loss: 2.9439, Accuracy: 2663/5000 (53%)\n",
      "[epoch 39] loss: 0.0009687\n",
      "Test set: Average loss: 2.9583, Accuracy: 2660/5000 (53%)\n",
      "[epoch 40] loss: 0.0009427\n",
      "Test set: Average loss: 2.9699, Accuracy: 2664/5000 (53%)\n",
      "[epoch 41] loss: 0.0008994\n",
      "Test set: Average loss: 2.9809, Accuracy: 2662/5000 (53%)\n",
      "[epoch 42] loss: 0.0008570\n",
      "Test set: Average loss: 2.9937, Accuracy: 2663/5000 (53%)\n",
      "[epoch 43] loss: 0.0008389\n",
      "Test set: Average loss: 3.0024, Accuracy: 2666/5000 (53%)\n",
      "[epoch 44] loss: 0.0007955\n",
      "Test set: Average loss: 3.0181, Accuracy: 2665/5000 (53%)\n",
      "[epoch 45] loss: 0.0007585\n",
      "Test set: Average loss: 3.0255, Accuracy: 2661/5000 (53%)\n",
      "[epoch 46] loss: 0.0007370\n",
      "Test set: Average loss: 3.0370, Accuracy: 2669/5000 (53%)\n",
      "[epoch 47] loss: 0.0007060\n",
      "Test set: Average loss: 3.0486, Accuracy: 2658/5000 (53%)\n",
      "[epoch 48] loss: 0.0006679\n",
      "Test set: Average loss: 3.0584, Accuracy: 2668/5000 (53%)\n",
      "[epoch 49] loss: 0.0006406\n",
      "Test set: Average loss: 3.0666, Accuracy: 2663/5000 (53%)\n",
      "[epoch 50] loss: 0.0006157\n",
      "Test set: Average loss: 3.0796, Accuracy: 2668/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5778, Accuracy: 2722/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.5107, Accuracy: 5624/10000 (56%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 232/5000 (5%)\n",
      "[epoch 1] loss: 1.7681043\n",
      "Test set: Average loss: 1.4796, Accuracy: 2458/5000 (49%)\n",
      "[epoch 2] loss: 1.2275245\n",
      "Test set: Average loss: 1.3782, Accuracy: 2648/5000 (53%)\n",
      "[epoch 3] loss: 1.0460471\n",
      "Test set: Average loss: 1.3896, Accuracy: 2562/5000 (51%)\n",
      "[epoch 4] loss: 0.8997762\n",
      "Test set: Average loss: 1.4609, Accuracy: 2588/5000 (52%)\n",
      "[epoch 5] loss: 0.6837945\n",
      "Test set: Average loss: 1.4242, Accuracy: 2716/5000 (54%)\n",
      "[epoch 6] loss: 0.5678898\n",
      "Test set: Average loss: 1.5749, Accuracy: 2609/5000 (52%)\n",
      "[epoch 7] loss: 0.4645643\n",
      "Test set: Average loss: 1.7057, Accuracy: 2591/5000 (52%)\n",
      "[epoch 8] loss: 0.2943602\n",
      "Test set: Average loss: 1.8035, Accuracy: 2647/5000 (53%)\n",
      "[epoch 9] loss: 0.2937123\n",
      "Test set: Average loss: 1.9483, Accuracy: 2528/5000 (51%)\n",
      "[epoch 10] loss: 0.2740570\n",
      "Test set: Average loss: 2.2250, Accuracy: 2438/5000 (49%)\n",
      "[epoch 11] loss: 0.2168686\n",
      "Test set: Average loss: 2.2720, Accuracy: 2481/5000 (50%)\n",
      "[epoch 12] loss: 0.1677705\n",
      "Test set: Average loss: 2.3107, Accuracy: 2546/5000 (51%)\n",
      "[epoch 13] loss: 0.1023774\n",
      "Test set: Average loss: 2.4192, Accuracy: 2517/5000 (50%)\n",
      "[epoch 14] loss: 0.0491005\n",
      "Test set: Average loss: 2.5211, Accuracy: 2524/5000 (50%)\n",
      "[epoch 15] loss: 0.0268537\n",
      "Test set: Average loss: 2.5785, Accuracy: 2553/5000 (51%)\n",
      "[epoch 16] loss: 0.0137858\n",
      "Test set: Average loss: 2.6350, Accuracy: 2569/5000 (51%)\n",
      "[epoch 17] loss: 0.0092319\n",
      "Test set: Average loss: 2.6526, Accuracy: 2567/5000 (51%)\n",
      "[epoch 18] loss: 0.0069950\n",
      "Test set: Average loss: 2.7062, Accuracy: 2570/5000 (51%)\n",
      "[epoch 19] loss: 0.0060782\n",
      "Test set: Average loss: 2.7338, Accuracy: 2582/5000 (52%)\n",
      "[epoch 20] loss: 0.0054284\n",
      "Test set: Average loss: 2.7806, Accuracy: 2559/5000 (51%)\n",
      "[epoch 21] loss: 0.0047412\n",
      "Test set: Average loss: 2.8124, Accuracy: 2571/5000 (51%)\n",
      "[epoch 22] loss: 0.0042939\n",
      "Test set: Average loss: 2.8386, Accuracy: 2575/5000 (52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] loss: 0.0039214\n",
      "Test set: Average loss: 2.8774, Accuracy: 2580/5000 (52%)\n",
      "[epoch 24] loss: 0.0036243\n",
      "Test set: Average loss: 2.9100, Accuracy: 2563/5000 (51%)\n",
      "[epoch 25] loss: 0.0032668\n",
      "Test set: Average loss: 2.9137, Accuracy: 2575/5000 (52%)\n",
      "[epoch 26] loss: 0.0030159\n",
      "Test set: Average loss: 2.9361, Accuracy: 2574/5000 (51%)\n",
      "[epoch 27] loss: 0.0028316\n",
      "Test set: Average loss: 2.9626, Accuracy: 2569/5000 (51%)\n",
      "[epoch 28] loss: 0.0025812\n",
      "Test set: Average loss: 2.9829, Accuracy: 2582/5000 (52%)\n",
      "[epoch 29] loss: 0.0023973\n",
      "Test set: Average loss: 3.0020, Accuracy: 2574/5000 (51%)\n",
      "[epoch 30] loss: 0.0022141\n",
      "Test set: Average loss: 3.0209, Accuracy: 2577/5000 (52%)\n",
      "[epoch 31] loss: 0.0020834\n",
      "Test set: Average loss: 3.0390, Accuracy: 2573/5000 (51%)\n",
      "[epoch 32] loss: 0.0019573\n",
      "Test set: Average loss: 3.0633, Accuracy: 2577/5000 (52%)\n",
      "[epoch 33] loss: 0.0018316\n",
      "Test set: Average loss: 3.0759, Accuracy: 2574/5000 (51%)\n",
      "[epoch 34] loss: 0.0017347\n",
      "Test set: Average loss: 3.0915, Accuracy: 2573/5000 (51%)\n",
      "[epoch 35] loss: 0.0016634\n",
      "Test set: Average loss: 3.1084, Accuracy: 2571/5000 (51%)\n",
      "[epoch 36] loss: 0.0015577\n",
      "Test set: Average loss: 3.1294, Accuracy: 2565/5000 (51%)\n",
      "[epoch 37] loss: 0.0015070\n",
      "Test set: Average loss: 3.1363, Accuracy: 2572/5000 (51%)\n",
      "[epoch 38] loss: 0.0014124\n",
      "Test set: Average loss: 3.1598, Accuracy: 2569/5000 (51%)\n",
      "[epoch 39] loss: 0.0013340\n",
      "Test set: Average loss: 3.1710, Accuracy: 2563/5000 (51%)\n",
      "[epoch 40] loss: 0.0012613\n",
      "Test set: Average loss: 3.1860, Accuracy: 2561/5000 (51%)\n",
      "[epoch 41] loss: 0.0012058\n",
      "Test set: Average loss: 3.1982, Accuracy: 2561/5000 (51%)\n",
      "[epoch 42] loss: 0.0011460\n",
      "Test set: Average loss: 3.2144, Accuracy: 2561/5000 (51%)\n",
      "[epoch 43] loss: 0.0011101\n",
      "Test set: Average loss: 3.2265, Accuracy: 2551/5000 (51%)\n",
      "[epoch 44] loss: 0.0010417\n",
      "Test set: Average loss: 3.2409, Accuracy: 2561/5000 (51%)\n",
      "[epoch 45] loss: 0.0010131\n",
      "Test set: Average loss: 3.2528, Accuracy: 2560/5000 (51%)\n",
      "[epoch 46] loss: 0.0009679\n",
      "Test set: Average loss: 3.2666, Accuracy: 2553/5000 (51%)\n",
      "[epoch 47] loss: 0.0009246\n",
      "Test set: Average loss: 3.2815, Accuracy: 2564/5000 (51%)\n",
      "[epoch 48] loss: 0.0008701\n",
      "Test set: Average loss: 3.2934, Accuracy: 2554/5000 (51%)\n",
      "[epoch 49] loss: 0.0008485\n",
      "Test set: Average loss: 3.3038, Accuracy: 2557/5000 (51%)\n",
      "[epoch 50] loss: 0.0008136\n",
      "Test set: Average loss: 3.3168, Accuracy: 2560/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4242, Accuracy: 2716/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.3879, Accuracy: 5532/10000 (55%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3167, Accuracy: 307/5000 (6%)\n",
      "[epoch 1] loss: 1.6908103\n",
      "Test set: Average loss: 1.4236, Accuracy: 2564/5000 (51%)\n",
      "[epoch 2] loss: 1.1525641\n",
      "Test set: Average loss: 1.3778, Accuracy: 2588/5000 (52%)\n",
      "[epoch 3] loss: 1.0085017\n",
      "Test set: Average loss: 1.2726, Accuracy: 2783/5000 (56%)\n",
      "[epoch 4] loss: 0.8088916\n",
      "Test set: Average loss: 1.3213, Accuracy: 2779/5000 (56%)\n",
      "[epoch 5] loss: 0.6688834\n",
      "Test set: Average loss: 1.4191, Accuracy: 2752/5000 (55%)\n",
      "[epoch 6] loss: 0.6178229\n",
      "Test set: Average loss: 1.6045, Accuracy: 2662/5000 (53%)\n",
      "[epoch 7] loss: 0.4840909\n",
      "Test set: Average loss: 1.7413, Accuracy: 2615/5000 (52%)\n",
      "[epoch 8] loss: 0.4020176\n",
      "Test set: Average loss: 1.8372, Accuracy: 2601/5000 (52%)\n",
      "[epoch 9] loss: 0.3967567\n",
      "Test set: Average loss: 1.9817, Accuracy: 2581/5000 (52%)\n",
      "[epoch 10] loss: 0.2618186\n",
      "Test set: Average loss: 2.1268, Accuracy: 2569/5000 (51%)\n",
      "[epoch 11] loss: 0.2104949\n",
      "Test set: Average loss: 2.1960, Accuracy: 2551/5000 (51%)\n",
      "[epoch 12] loss: 0.1564352\n",
      "Test set: Average loss: 2.2610, Accuracy: 2637/5000 (53%)\n",
      "[epoch 13] loss: 0.1642452\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4367, Accuracy: 2501/5000 (50%)\n",
      "[epoch 14] loss: 0.0689500\n",
      "Test set: Average loss: 2.3780, Accuracy: 2592/5000 (52%)\n",
      "[epoch 15] loss: 0.0443014\n",
      "Test set: Average loss: 2.3534, Accuracy: 2624/5000 (52%)\n",
      "[epoch 16] loss: 0.0368463\n",
      "Test set: Average loss: 2.3574, Accuracy: 2632/5000 (53%)\n",
      "[epoch 17] loss: 0.0323491\n",
      "Test set: Average loss: 2.3671, Accuracy: 2638/5000 (53%)\n",
      "[epoch 18] loss: 0.0300533\n",
      "Test set: Average loss: 2.3775, Accuracy: 2643/5000 (53%)\n",
      "[epoch 19] loss: 0.0279305\n",
      "Test set: Average loss: 2.3862, Accuracy: 2648/5000 (53%)\n",
      "[epoch 20] loss: 0.0254231\n",
      "Test set: Average loss: 2.3981, Accuracy: 2652/5000 (53%)\n",
      "[epoch 21] loss: 0.0238358\n",
      "Test set: Average loss: 2.4100, Accuracy: 2651/5000 (53%)\n",
      "[epoch 22] loss: 0.0224251\n",
      "Test set: Average loss: 2.4217, Accuracy: 2654/5000 (53%)\n",
      "[epoch 23] loss: 0.0213357\n",
      "Test set: Average loss: 2.4336, Accuracy: 2653/5000 (53%)\n",
      "[epoch 24] loss: 0.0202095\n",
      "Test set: Average loss: 2.4473, Accuracy: 2652/5000 (53%)\n",
      "[epoch 25] loss: 0.0191071\n",
      "Test set: Average loss: 2.4585, Accuracy: 2652/5000 (53%)\n",
      "[epoch 26] loss: 0.0184739\n",
      "Test set: Average loss: 2.4703, Accuracy: 2650/5000 (53%)\n",
      "[epoch 27] loss: 0.0175614\n",
      "Test set: Average loss: 2.4802, Accuracy: 2660/5000 (53%)\n",
      "[epoch 28] loss: 0.0172269\n",
      "Test set: Average loss: 2.4941, Accuracy: 2651/5000 (53%)\n",
      "[epoch 29] loss: 0.0159207\n",
      "Test set: Average loss: 2.5053, Accuracy: 2650/5000 (53%)\n",
      "[epoch 30] loss: 0.0152572\n",
      "Test set: Average loss: 2.5156, Accuracy: 2653/5000 (53%)\n",
      "[epoch 31] loss: 0.0148337\n",
      "Test set: Average loss: 2.5277, Accuracy: 2652/5000 (53%)\n",
      "[epoch 32] loss: 0.0139113\n",
      "Test set: Average loss: 2.5389, Accuracy: 2647/5000 (53%)\n",
      "[epoch 33] loss: 0.0134124\n",
      "Test set: Average loss: 2.5493, Accuracy: 2648/5000 (53%)\n",
      "[epoch 34] loss: 0.0128958\n",
      "Test set: Average loss: 2.5611, Accuracy: 2651/5000 (53%)\n",
      "[epoch 35] loss: 0.0125784\n",
      "Test set: Average loss: 2.5728, Accuracy: 2646/5000 (53%)\n",
      "[epoch 36] loss: 0.0118932\n",
      "Test set: Average loss: 2.5833, Accuracy: 2648/5000 (53%)\n",
      "[epoch 37] loss: 0.0113724\n",
      "Test set: Average loss: 2.5931, Accuracy: 2652/5000 (53%)\n",
      "[epoch 38] loss: 0.0113635\n",
      "Test set: Average loss: 2.6040, Accuracy: 2646/5000 (53%)\n",
      "[epoch 39] loss: 0.0107979\n",
      "Test set: Average loss: 2.6136, Accuracy: 2653/5000 (53%)\n",
      "[epoch 40] loss: 0.0103316\n",
      "Test set: Average loss: 2.6235, Accuracy: 2654/5000 (53%)\n",
      "[epoch 41] loss: 0.4348406\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.6585, Accuracy: 2619/5000 (52%)\n",
      "[epoch 42] loss: 0.0170066\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.6924, Accuracy: 2585/5000 (52%)\n",
      "[epoch 43] loss: 0.0167384\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.6897, Accuracy: 2583/5000 (52%)\n",
      "[epoch 44] loss: 0.0163824\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.6895, Accuracy: 2583/5000 (52%)\n",
      "[epoch 45] loss: 0.0163146\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.6894, Accuracy: 2583/5000 (52%)\n",
      "[epoch 46] loss: 0.0162603\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.6894, Accuracy: 2583/5000 (52%)\n",
      "[epoch 47] loss: 0.0162185\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.6894, Accuracy: 2583/5000 (52%)\n",
      "[epoch 48] loss: 0.0163756\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.6894, Accuracy: 2583/5000 (52%)\n",
      "[epoch 49] loss: 0.0165266\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.6894, Accuracy: 2583/5000 (52%)\n",
      "[epoch 50] loss: 0.0163720\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.6894, Accuracy: 2583/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2726, Accuracy: 2783/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.2375, Accuracy: 5724/10000 (57%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 701/5000 (14%)\n",
      "[epoch 1] loss: 1.6359438\n",
      "Test set: Average loss: 1.5342, Accuracy: 2328/5000 (47%)\n",
      "[epoch 2] loss: 1.1811776\n",
      "Test set: Average loss: 1.2862, Accuracy: 2752/5000 (55%)\n",
      "[epoch 3] loss: 0.8938887\n",
      "Test set: Average loss: 1.3333, Accuracy: 2762/5000 (55%)\n",
      "[epoch 4] loss: 0.7301109\n",
      "Test set: Average loss: 1.3635, Accuracy: 2825/5000 (56%)\n",
      "[epoch 5] loss: 0.5832928\n",
      "Test set: Average loss: 1.4558, Accuracy: 2764/5000 (55%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.5507393\n",
      "Test set: Average loss: 1.6269, Accuracy: 2656/5000 (53%)\n",
      "[epoch 7] loss: 0.4530261\n",
      "Test set: Average loss: 1.6875, Accuracy: 2705/5000 (54%)\n",
      "[epoch 8] loss: 0.3231098\n",
      "Test set: Average loss: 1.7884, Accuracy: 2660/5000 (53%)\n",
      "[epoch 9] loss: 0.2485080\n",
      "Test set: Average loss: 1.9387, Accuracy: 2739/5000 (55%)\n",
      "[epoch 10] loss: 0.1708199\n",
      "Test set: Average loss: 2.1133, Accuracy: 2682/5000 (54%)\n",
      "[epoch 11] loss: 0.0962673\n",
      "Test set: Average loss: 2.1969, Accuracy: 2678/5000 (54%)\n",
      "[epoch 12] loss: 0.0650962\n",
      "Test set: Average loss: 2.3680, Accuracy: 2696/5000 (54%)\n",
      "[epoch 13] loss: 0.0673623\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4891, Accuracy: 2692/5000 (54%)\n",
      "[epoch 14] loss: 0.0257675\n",
      "Test set: Average loss: 2.4263, Accuracy: 2705/5000 (54%)\n",
      "[epoch 15] loss: 0.0186782\n",
      "Test set: Average loss: 2.4347, Accuracy: 2695/5000 (54%)\n",
      "[epoch 16] loss: 0.0162056\n",
      "Test set: Average loss: 2.4404, Accuracy: 2704/5000 (54%)\n",
      "[epoch 17] loss: 0.0151362\n",
      "Test set: Average loss: 2.4529, Accuracy: 2709/5000 (54%)\n",
      "[epoch 18] loss: 0.0141210\n",
      "Test set: Average loss: 2.4604, Accuracy: 2700/5000 (54%)\n",
      "[epoch 19] loss: 0.0134498\n",
      "Test set: Average loss: 2.4703, Accuracy: 2698/5000 (54%)\n",
      "[epoch 20] loss: 0.0129143\n",
      "Test set: Average loss: 2.4812, Accuracy: 2713/5000 (54%)\n",
      "[epoch 21] loss: 0.0124825\n",
      "Test set: Average loss: 2.4917, Accuracy: 2708/5000 (54%)\n",
      "[epoch 22] loss: 0.0119542\n",
      "Test set: Average loss: 2.4991, Accuracy: 2705/5000 (54%)\n",
      "[epoch 23] loss: 0.0113925\n",
      "Test set: Average loss: 2.5075, Accuracy: 2707/5000 (54%)\n",
      "[epoch 24] loss: 0.0108288\n",
      "Test set: Average loss: 2.5174, Accuracy: 2703/5000 (54%)\n",
      "[epoch 25] loss: 0.0107061\n",
      "Test set: Average loss: 2.5270, Accuracy: 2707/5000 (54%)\n",
      "[epoch 26] loss: 0.0103637\n",
      "Test set: Average loss: 2.5356, Accuracy: 2705/5000 (54%)\n",
      "[epoch 27] loss: 0.0097959\n",
      "Test set: Average loss: 2.5444, Accuracy: 2701/5000 (54%)\n",
      "[epoch 28] loss: 0.0100960\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5528, Accuracy: 2702/5000 (54%)\n",
      "[epoch 29] loss: 0.0092319\n",
      "Test set: Average loss: 2.5541, Accuracy: 2700/5000 (54%)\n",
      "[epoch 30] loss: 0.0093103\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5548, Accuracy: 2702/5000 (54%)\n",
      "[epoch 31] loss: 0.0092197\n",
      "Test set: Average loss: 2.5549, Accuracy: 2702/5000 (54%)\n",
      "[epoch 32] loss: 0.0091006\n",
      "Test set: Average loss: 2.5551, Accuracy: 2702/5000 (54%)\n",
      "[epoch 33] loss: 0.0092670\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2703/5000 (54%)\n",
      "[epoch 34] loss: 0.0089843\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 35] loss: 0.0089714\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 36] loss: 0.0096992\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 37] loss: 0.0092372\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 38] loss: 0.0090406\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 39] loss: 0.0091159\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 40] loss: 0.0091552\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 41] loss: 0.0090541\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 42] loss: 0.0093463\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 43] loss: 0.0091035\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 44] loss: 0.0091654\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 45] loss: 0.0091747\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 46] loss: 0.0091175\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 47] loss: 0.0092380\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 48] loss: 0.0092523\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 49] loss: 0.0091719\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 50] loss: 0.0090544\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.5552, Accuracy: 2702/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3635, Accuracy: 2825/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.3036, Accuracy: 5685/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2888, Accuracy: 745/5000 (15%)\n",
      "[epoch 1] loss: 1.7325214\n",
      "Test set: Average loss: 1.3969, Accuracy: 2551/5000 (51%)\n",
      "[epoch 2] loss: 1.2404327\n",
      "Test set: Average loss: 1.3361, Accuracy: 2678/5000 (54%)\n",
      "[epoch 3] loss: 1.0716105\n",
      "Test set: Average loss: 1.3348, Accuracy: 2684/5000 (54%)\n",
      "[epoch 4] loss: 0.8785734\n",
      "Test set: Average loss: 1.3817, Accuracy: 2709/5000 (54%)\n",
      "[epoch 5] loss: 0.7188652\n",
      "Test set: Average loss: 1.4362, Accuracy: 2749/5000 (55%)\n",
      "[epoch 6] loss: 0.6143268\n",
      "Test set: Average loss: 1.4758, Accuracy: 2720/5000 (54%)\n",
      "[epoch 7] loss: 0.5352626\n",
      "Test set: Average loss: 1.6968, Accuracy: 2607/5000 (52%)\n",
      "[epoch 8] loss: 0.4082569\n",
      "Test set: Average loss: 1.9970, Accuracy: 2528/5000 (51%)\n",
      "[epoch 9] loss: 0.4326741\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9818, Accuracy: 2528/5000 (51%)\n",
      "[epoch 10] loss: 0.2320769\n",
      "Test set: Average loss: 1.8458, Accuracy: 2671/5000 (53%)\n",
      "[epoch 11] loss: 0.1584278\n",
      "Test set: Average loss: 1.8558, Accuracy: 2686/5000 (54%)\n",
      "[epoch 12] loss: 0.1375634\n",
      "Test set: Average loss: 1.8722, Accuracy: 2682/5000 (54%)\n",
      "[epoch 13] loss: 0.1253928\n",
      "Test set: Average loss: 1.8937, Accuracy: 2680/5000 (54%)\n",
      "[epoch 14] loss: 0.1151985\n",
      "Test set: Average loss: 1.9166, Accuracy: 2677/5000 (54%)\n",
      "[epoch 15] loss: 0.1099894\n",
      "Test set: Average loss: 1.9446, Accuracy: 2669/5000 (53%)\n",
      "[epoch 16] loss: 0.0993381\n",
      "Test set: Average loss: 1.9669, Accuracy: 2663/5000 (53%)\n",
      "[epoch 17] loss: 0.0933832\n",
      "Test set: Average loss: 1.9830, Accuracy: 2669/5000 (53%)\n",
      "[epoch 18] loss: 0.0893738\n",
      "Test set: Average loss: 2.0110, Accuracy: 2664/5000 (53%)\n",
      "[epoch 19] loss: 0.0833010\n",
      "Test set: Average loss: 2.0308, Accuracy: 2651/5000 (53%)\n",
      "[epoch 20] loss: 0.0770447\n",
      "Test set: Average loss: 2.0542, Accuracy: 2654/5000 (53%)\n",
      "[epoch 21] loss: 0.0713985\n",
      "Test set: Average loss: 2.0735, Accuracy: 2640/5000 (53%)\n",
      "[epoch 22] loss: 0.0680463\n",
      "Test set: Average loss: 2.0988, Accuracy: 2635/5000 (53%)\n",
      "[epoch 23] loss: 0.0629645\n",
      "Test set: Average loss: 2.1160, Accuracy: 2641/5000 (53%)\n",
      "[epoch 24] loss: 0.0636833\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.1424, Accuracy: 2630/5000 (53%)\n",
      "[epoch 25] loss: 0.0552597\n",
      "Test set: Average loss: 2.1422, Accuracy: 2639/5000 (53%)\n",
      "[epoch 26] loss: 0.0560900\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.1425, Accuracy: 2642/5000 (53%)\n",
      "[epoch 27] loss: 0.0531659\n",
      "Test set: Average loss: 2.1428, Accuracy: 2645/5000 (53%)\n",
      "[epoch 28] loss: 0.0527077\n",
      "Test set: Average loss: 2.1430, Accuracy: 2646/5000 (53%)\n",
      "[epoch 29] loss: 0.0535812\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 30] loss: 0.0542642\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 31] loss: 0.0532389\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 32] loss: 0.0522721\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 33] loss: 0.0528134\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 34] loss: 0.0523772\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 35] loss: 0.0531128\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 36] loss: 0.0526515\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 37] loss: 0.0528962\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 38] loss: 0.0531870\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 39] loss: 0.0533283\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 40] loss: 0.0523676\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 41] loss: 0.0541877\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 42] loss: 0.0528305\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 43] loss: 0.0543430\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 44] loss: 0.0530063\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 45] loss: 0.0549262\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 46] loss: 0.0532096\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 47] loss: 0.0523126\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 48] loss: 0.0528289\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 49] loss: 0.0524851\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "[epoch 50] loss: 0.0523879\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.1433, Accuracy: 2644/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4362, Accuracy: 2749/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.3980, Accuracy: 5554/10000 (56%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3058, Accuracy: 562/5000 (11%)\n",
      "[epoch 1] loss: 1.4569414\n",
      "Test set: Average loss: 1.5547, Accuracy: 2363/5000 (47%)\n",
      "[epoch 2] loss: 1.1395099\n",
      "Test set: Average loss: 1.2756, Accuracy: 2792/5000 (56%)\n",
      "[epoch 3] loss: 1.0191854\n",
      "Test set: Average loss: 1.2478, Accuracy: 2819/5000 (56%)\n",
      "[epoch 4] loss: 0.9248550\n",
      "Test set: Average loss: 1.3539, Accuracy: 2768/5000 (55%)\n",
      "[epoch 5] loss: 0.8370902\n",
      "Test set: Average loss: 1.3241, Accuracy: 2848/5000 (57%)\n",
      "[epoch 6] loss: 0.7255468\n",
      "Test set: Average loss: 1.4783, Accuracy: 2707/5000 (54%)\n",
      "[epoch 7] loss: 0.6724819\n",
      "Test set: Average loss: 1.5322, Accuracy: 2789/5000 (56%)\n",
      "[epoch 8] loss: 0.6016740\n",
      "Test set: Average loss: 1.6729, Accuracy: 2684/5000 (54%)\n",
      "[epoch 9] loss: 0.5977677\n",
      "Test set: Average loss: 1.8872, Accuracy: 2523/5000 (50%)\n",
      "[epoch 10] loss: 0.5911591\n",
      "Test set: Average loss: 1.7889, Accuracy: 2700/5000 (54%)\n",
      "[epoch 11] loss: 0.5033753\n",
      "Test set: Average loss: 1.8402, Accuracy: 2662/5000 (53%)\n",
      "[epoch 12] loss: 0.4356422\n",
      "Test set: Average loss: 2.1053, Accuracy: 2575/5000 (52%)\n",
      "[epoch 13] loss: 0.5047939\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0337, Accuracy: 2626/5000 (53%)\n",
      "[epoch 14] loss: 0.2153850\n",
      "Test set: Average loss: 1.9587, Accuracy: 2737/5000 (55%)\n",
      "[epoch 15] loss: 0.1731430\n",
      "Test set: Average loss: 1.9753, Accuracy: 2743/5000 (55%)\n",
      "[epoch 16] loss: 0.1557516\n",
      "Test set: Average loss: 2.0018, Accuracy: 2738/5000 (55%)\n",
      "[epoch 17] loss: 0.1382231\n",
      "Test set: Average loss: 2.0350, Accuracy: 2741/5000 (55%)\n",
      "[epoch 18] loss: 0.1319238\n",
      "Test set: Average loss: 2.0601, Accuracy: 2745/5000 (55%)\n",
      "[epoch 19] loss: 0.1225055\n",
      "Test set: Average loss: 2.0919, Accuracy: 2745/5000 (55%)\n",
      "[epoch 20] loss: 0.1146907\n",
      "Test set: Average loss: 2.1230, Accuracy: 2720/5000 (54%)\n",
      "[epoch 21] loss: 0.1059780\n",
      "Test set: Average loss: 2.1587, Accuracy: 2720/5000 (54%)\n",
      "[epoch 22] loss: 0.1023423\n",
      "Test set: Average loss: 2.1967, Accuracy: 2716/5000 (54%)\n",
      "[epoch 23] loss: 0.1015434\n",
      "Test set: Average loss: 2.2193, Accuracy: 2722/5000 (54%)\n",
      "[epoch 24] loss: 0.0884278\n",
      "Test set: Average loss: 2.2494, Accuracy: 2716/5000 (54%)\n",
      "[epoch 25] loss: 0.0810391\n",
      "Test set: Average loss: 2.2788, Accuracy: 2719/5000 (54%)\n",
      "[epoch 26] loss: 0.0761317\n",
      "Test set: Average loss: 2.3190, Accuracy: 2724/5000 (54%)\n",
      "[epoch 27] loss: 0.0710564\n",
      "Test set: Average loss: 2.3512, Accuracy: 2712/5000 (54%)\n",
      "[epoch 28] loss: 0.0669506\n",
      "Test set: Average loss: 2.3832, Accuracy: 2712/5000 (54%)\n",
      "[epoch 29] loss: 0.0630486\n",
      "Test set: Average loss: 2.4229, Accuracy: 2697/5000 (54%)\n",
      "[epoch 30] loss: 0.0575188\n",
      "Test set: Average loss: 2.4550, Accuracy: 2698/5000 (54%)\n",
      "[epoch 31] loss: 0.0540670\n",
      "Test set: Average loss: 2.4917, Accuracy: 2700/5000 (54%)\n",
      "[epoch 32] loss: 0.0508871\n",
      "Test set: Average loss: 2.5282, Accuracy: 2708/5000 (54%)\n",
      "[epoch 33] loss: 0.2596577\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5623, Accuracy: 2691/5000 (54%)\n",
      "[epoch 34] loss: 0.0448534\n",
      "Test set: Average loss: 2.5600, Accuracy: 2688/5000 (54%)\n",
      "[epoch 35] loss: 0.1903118\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5587, Accuracy: 2698/5000 (54%)\n",
      "[epoch 36] loss: 0.0411043\n",
      "Test set: Average loss: 2.5592, Accuracy: 2696/5000 (54%)\n",
      "[epoch 37] loss: 0.0405587\n",
      "Test set: Average loss: 2.5590, Accuracy: 2697/5000 (54%)\n",
      "[epoch 38] loss: 0.0419764\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5589, Accuracy: 2701/5000 (54%)\n",
      "[epoch 39] loss: 0.0403624\n",
      "Test set: Average loss: 2.5590, Accuracy: 2701/5000 (54%)\n",
      "[epoch 40] loss: 0.0403497\n",
      "Test set: Average loss: 2.5590, Accuracy: 2702/5000 (54%)\n",
      "[epoch 41] loss: 0.0406922\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5748, Accuracy: 2700/5000 (54%)\n",
      "[epoch 42] loss: 0.0405022\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 43] loss: 0.0405452\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 44] loss: 0.0407956\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 45] loss: 0.0408654\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 46] loss: 0.0412680\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 47] loss: 0.0407146\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 48] loss: 0.0401990\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 49] loss: 0.0406331\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "[epoch 50] loss: 0.0402179\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5590, Accuracy: 2703/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3241, Accuracy: 2848/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.2687, Accuracy: 5777/10000 (58%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3067, Accuracy: 340/5000 (7%)\n",
      "[epoch 1] loss: 1.4333202\n",
      "Test set: Average loss: 1.2492, Accuracy: 2771/5000 (55%)\n",
      "[epoch 2] loss: 1.1550177\n",
      "Test set: Average loss: 1.3426, Accuracy: 2680/5000 (54%)\n",
      "[epoch 3] loss: 1.0233547\n",
      "Test set: Average loss: 1.3335, Accuracy: 2674/5000 (53%)\n",
      "[epoch 4] loss: 0.9506217\n",
      "Test set: Average loss: 1.2826, Accuracy: 2834/5000 (57%)\n",
      "[epoch 5] loss: 0.8973037\n",
      "Test set: Average loss: 1.3417, Accuracy: 2801/5000 (56%)\n",
      "[epoch 6] loss: 0.7469074\n",
      "Test set: Average loss: 1.4963, Accuracy: 2649/5000 (53%)\n",
      "[epoch 7] loss: 0.7646396\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6197, Accuracy: 2528/5000 (51%)\n",
      "[epoch 8] loss: 0.5108852\n",
      "Test set: Average loss: 1.4042, Accuracy: 2833/5000 (57%)\n",
      "[epoch 9] loss: 0.4068872\n",
      "Test set: Average loss: 1.4407, Accuracy: 2838/5000 (57%)\n",
      "[epoch 10] loss: 0.3662443\n",
      "Test set: Average loss: 1.4571, Accuracy: 2874/5000 (57%)\n",
      "[epoch 11] loss: 0.3516995\n",
      "Test set: Average loss: 1.4840, Accuracy: 2857/5000 (57%)\n",
      "[epoch 12] loss: 0.3421881\n",
      "Test set: Average loss: 1.5221, Accuracy: 2847/5000 (57%)\n",
      "[epoch 13] loss: 0.3182496\n",
      "Test set: Average loss: 1.5474, Accuracy: 2837/5000 (57%)\n",
      "[epoch 14] loss: 0.3035893\n",
      "Test set: Average loss: 1.5648, Accuracy: 2852/5000 (57%)\n",
      "[epoch 15] loss: 0.2918261\n",
      "Test set: Average loss: 1.5944, Accuracy: 2807/5000 (56%)\n",
      "[epoch 16] loss: 0.2764263\n",
      "Test set: Average loss: 1.6186, Accuracy: 2838/5000 (57%)\n",
      "[epoch 17] loss: 0.2686054\n",
      "Test set: Average loss: 1.6503, Accuracy: 2821/5000 (56%)\n",
      "[epoch 18] loss: 0.2582757\n",
      "Test set: Average loss: 1.6913, Accuracy: 2813/5000 (56%)\n",
      "[epoch 19] loss: 0.2394594\n",
      "Test set: Average loss: 1.7317, Accuracy: 2805/5000 (56%)\n",
      "[epoch 20] loss: 0.2341996\n",
      "Test set: Average loss: 1.7689, Accuracy: 2801/5000 (56%)\n",
      "[epoch 21] loss: 0.2236387\n",
      "Test set: Average loss: 1.7894, Accuracy: 2790/5000 (56%)\n",
      "[epoch 22] loss: 0.2105631\n",
      "Test set: Average loss: 1.8323, Accuracy: 2768/5000 (55%)\n",
      "[epoch 23] loss: 0.1982724\n",
      "Test set: Average loss: 1.8632, Accuracy: 2783/5000 (56%)\n",
      "[epoch 24] loss: 0.3484482\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8985, Accuracy: 2776/5000 (56%)\n",
      "[epoch 25] loss: 0.1679462\n",
      "Test set: Average loss: 1.8897, Accuracy: 2779/5000 (56%)\n",
      "[epoch 26] loss: 0.1611337\n",
      "Test set: Average loss: 1.8895, Accuracy: 2792/5000 (56%)\n",
      "[epoch 27] loss: 0.1611387\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8929, Accuracy: 2791/5000 (56%)\n",
      "[epoch 28] loss: 0.2883616\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2791/5000 (56%)\n",
      "[epoch 29] loss: 0.2864766\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 30] loss: 0.1582079\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 31] loss: 0.1698763\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 32] loss: 0.1577008\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 33] loss: 0.1574686\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 34] loss: 0.1562158\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 35] loss: 0.1579162\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 36] loss: 0.1573527\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 37] loss: 0.1587273\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 38] loss: 0.1586433\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 39] loss: 0.1562987\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 40] loss: 0.1605113\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 41] loss: 0.1566857\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 42] loss: 0.1565202\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 43] loss: 0.1627151\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 44] loss: 0.1564618\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 45] loss: 0.1565645\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 46] loss: 0.1568654\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 47] loss: 0.2987901\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 48] loss: 0.2698789\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 49] loss: 0.1572627\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "[epoch 50] loss: 0.1596480\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8933, Accuracy: 2790/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4571, Accuracy: 2874/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.3841, Accuracy: 5941/10000 (59%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2993, Accuracy: 667/5000 (13%)\n",
      "[epoch 1] loss: 1.4682782\n",
      "Test set: Average loss: 1.3271, Accuracy: 2660/5000 (53%)\n",
      "[epoch 2] loss: 1.1621586\n",
      "Test set: Average loss: 1.2284, Accuracy: 2853/5000 (57%)\n",
      "[epoch 3] loss: 1.0127109\n",
      "Test set: Average loss: 1.2641, Accuracy: 2842/5000 (57%)\n",
      "[epoch 4] loss: 0.9405728\n",
      "Test set: Average loss: 1.3084, Accuracy: 2752/5000 (55%)\n",
      "[epoch 5] loss: 0.8328959\n",
      "Test set: Average loss: 1.4562, Accuracy: 2682/5000 (54%)\n",
      "[epoch 6] loss: 0.8233665\n",
      "Test set: Average loss: 1.4782, Accuracy: 2660/5000 (53%)\n",
      "[epoch 7] loss: 0.7251905\n",
      "Test set: Average loss: 1.5187, Accuracy: 2692/5000 (54%)\n",
      "[epoch 8] loss: 0.6456913\n",
      "Test set: Average loss: 1.6579, Accuracy: 2545/5000 (51%)\n",
      "[epoch 9] loss: 0.6141446\n",
      "Test set: Average loss: 1.8207, Accuracy: 2548/5000 (51%)\n",
      "[epoch 10] loss: 0.5507010\n",
      "Test set: Average loss: 1.7962, Accuracy: 2646/5000 (53%)\n",
      "[epoch 11] loss: 0.5051617\n",
      "Test set: Average loss: 1.9896, Accuracy: 2495/5000 (50%)\n",
      "[epoch 12] loss: 0.4639296\n",
      "Test set: Average loss: 2.0796, Accuracy: 2534/5000 (51%)\n",
      "[epoch 13] loss: 0.4245194\n",
      "Test set: Average loss: 2.1394, Accuracy: 2571/5000 (51%)\n",
      "[epoch 14] loss: 0.4095870\n",
      "Test set: Average loss: 2.3431, Accuracy: 2529/5000 (51%)\n",
      "[epoch 15] loss: 0.4682992\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4599, Accuracy: 2370/5000 (47%)\n",
      "[epoch 16] loss: 0.2162765\n",
      "Test set: Average loss: 2.2234, Accuracy: 2540/5000 (51%)\n",
      "[epoch 17] loss: 0.1514472\n",
      "Test set: Average loss: 2.2569, Accuracy: 2552/5000 (51%)\n",
      "[epoch 18] loss: 0.1330813\n",
      "Test set: Average loss: 2.2853, Accuracy: 2547/5000 (51%)\n",
      "[epoch 19] loss: 0.1205888\n",
      "Test set: Average loss: 2.3207, Accuracy: 2545/5000 (51%)\n",
      "[epoch 20] loss: 0.1109228\n",
      "Test set: Average loss: 2.3447, Accuracy: 2561/5000 (51%)\n",
      "[epoch 21] loss: 0.1043536\n",
      "Test set: Average loss: 2.3769, Accuracy: 2563/5000 (51%)\n",
      "[epoch 22] loss: 0.0972123\n",
      "Test set: Average loss: 2.4025, Accuracy: 2559/5000 (51%)\n",
      "[epoch 23] loss: 0.0901532\n",
      "Test set: Average loss: 2.4427, Accuracy: 2559/5000 (51%)\n",
      "[epoch 24] loss: 0.0843280\n",
      "Test set: Average loss: 2.4745, Accuracy: 2554/5000 (51%)\n",
      "[epoch 25] loss: 0.0784893\n",
      "Test set: Average loss: 2.5132, Accuracy: 2552/5000 (51%)\n",
      "[epoch 26] loss: 0.0726710\n",
      "Test set: Average loss: 2.5456, Accuracy: 2546/5000 (51%)\n",
      "[epoch 27] loss: 0.2700119\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5937, Accuracy: 2532/5000 (51%)\n",
      "[epoch 28] loss: 0.0689613\n",
      "Test set: Average loss: 2.5846, Accuracy: 2542/5000 (51%)\n",
      "[epoch 29] loss: 0.0621409\n",
      "Test set: Average loss: 2.5792, Accuracy: 2534/5000 (51%)\n",
      "[epoch 30] loss: 0.0605537\n",
      "Test set: Average loss: 2.5788, Accuracy: 2545/5000 (51%)\n",
      "[epoch 31] loss: 0.0618850\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5805, Accuracy: 2546/5000 (51%)\n",
      "[epoch 32] loss: 0.0594969\n",
      "Test set: Average loss: 2.5807, Accuracy: 2547/5000 (51%)\n",
      "[epoch 33] loss: 0.0588159\n",
      "Test set: Average loss: 2.5810, Accuracy: 2547/5000 (51%)\n",
      "[epoch 34] loss: 0.0592420\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2547/5000 (51%)\n",
      "[epoch 35] loss: 0.0586949\n",
      "Test set: Average loss: 2.5814, Accuracy: 2547/5000 (51%)\n",
      "[epoch 36] loss: 0.0591485\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 37] loss: 0.0590054\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 38] loss: 0.2398178\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 39] loss: 0.0587030\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 40] loss: 0.0592711\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 41] loss: 0.0594001\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 42] loss: 0.0587371\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 43] loss: 0.0587903\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 44] loss: 0.0597893\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 45] loss: 0.0585772\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 46] loss: 0.2479654\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 47] loss: 0.0596896\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 48] loss: 0.0594568\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 49] loss: 0.0588536\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "[epoch 50] loss: 0.0586781\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5814, Accuracy: 2546/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2284, Accuracy: 2853/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.1838, Accuracy: 5846/10000 (58%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2994, Accuracy: 582/5000 (12%)\n",
      "[epoch 1] loss: 1.2837960\n",
      "Test set: Average loss: 1.3910, Accuracy: 2491/5000 (50%)\n",
      "[epoch 2] loss: 1.0732561\n",
      "Test set: Average loss: 1.2452, Accuracy: 2899/5000 (58%)\n",
      "[epoch 3] loss: 1.0179300\n",
      "Test set: Average loss: 1.3163, Accuracy: 2745/5000 (55%)\n",
      "[epoch 4] loss: 0.9352929\n",
      "Test set: Average loss: 1.2689, Accuracy: 2919/5000 (58%)\n",
      "[epoch 5] loss: 0.9212923\n",
      "Test set: Average loss: 1.3688, Accuracy: 2769/5000 (55%)\n",
      "[epoch 6] loss: 0.8651336\n",
      "Test set: Average loss: 1.3668, Accuracy: 2812/5000 (56%)\n",
      "[epoch 7] loss: 0.7999658\n",
      "Test set: Average loss: 1.3912, Accuracy: 2765/5000 (55%)\n",
      "[epoch 8] loss: 0.7778843\n",
      "Test set: Average loss: 1.4154, Accuracy: 2771/5000 (55%)\n",
      "[epoch 9] loss: 0.7688684\n",
      "Test set: Average loss: 1.4618, Accuracy: 2743/5000 (55%)\n",
      "[epoch 10] loss: 0.6861650\n",
      "Test set: Average loss: 1.4638, Accuracy: 2819/5000 (56%)\n",
      "[epoch 11] loss: 0.6906336\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5043, Accuracy: 2817/5000 (56%)\n",
      "[epoch 12] loss: 0.4719969\n",
      "Test set: Average loss: 1.4624, Accuracy: 2888/5000 (58%)\n",
      "[epoch 13] loss: 0.4175468\n",
      "Test set: Average loss: 1.4797, Accuracy: 2888/5000 (58%)\n",
      "[epoch 14] loss: 0.3954591\n",
      "Test set: Average loss: 1.5083, Accuracy: 2894/5000 (58%)\n",
      "[epoch 15] loss: 0.3800871\n",
      "Test set: Average loss: 1.5418, Accuracy: 2872/5000 (57%)\n",
      "[epoch 16] loss: 0.3679032\n",
      "Test set: Average loss: 1.5818, Accuracy: 2877/5000 (58%)\n",
      "[epoch 17] loss: 0.3560523\n",
      "Test set: Average loss: 1.6126, Accuracy: 2887/5000 (58%)\n",
      "[epoch 18] loss: 0.3464007\n",
      "Test set: Average loss: 1.6410, Accuracy: 2875/5000 (58%)\n",
      "[epoch 19] loss: 0.3365756\n",
      "Test set: Average loss: 1.6844, Accuracy: 2828/5000 (57%)\n",
      "[epoch 20] loss: 0.3276429\n",
      "Test set: Average loss: 1.7145, Accuracy: 2856/5000 (57%)\n",
      "[epoch 21] loss: 0.3178405\n",
      "Test set: Average loss: 1.7276, Accuracy: 2854/5000 (57%)\n",
      "[epoch 22] loss: 0.3075188\n",
      "Test set: Average loss: 1.7689, Accuracy: 2842/5000 (57%)\n",
      "[epoch 23] loss: 0.2972179\n",
      "Test set: Average loss: 1.8010, Accuracy: 2849/5000 (57%)\n",
      "[epoch 24] loss: 0.2912273\n",
      "Test set: Average loss: 1.8256, Accuracy: 2848/5000 (57%)\n",
      "[epoch 25] loss: 0.2822644\n",
      "Test set: Average loss: 1.8823, Accuracy: 2818/5000 (56%)\n",
      "[epoch 26] loss: 0.2716893\n",
      "Test set: Average loss: 1.9163, Accuracy: 2826/5000 (57%)\n",
      "[epoch 27] loss: 0.2658724\n",
      "Test set: Average loss: 1.9255, Accuracy: 2840/5000 (57%)\n",
      "[epoch 28] loss: 0.2578687\n",
      "Test set: Average loss: 1.9755, Accuracy: 2821/5000 (56%)\n",
      "[epoch 29] loss: 0.2515005\n",
      "Test set: Average loss: 2.0020, Accuracy: 2823/5000 (56%)\n",
      "[epoch 30] loss: 0.2410549\n",
      "Test set: Average loss: 2.0507, Accuracy: 2817/5000 (56%)\n",
      "[epoch 31] loss: 0.2359992\n",
      "Test set: Average loss: 2.0636, Accuracy: 2841/5000 (57%)\n",
      "[epoch 32] loss: 0.2244969\n",
      "Test set: Average loss: 2.1192, Accuracy: 2810/5000 (56%)\n",
      "[epoch 33] loss: 0.2171775\n",
      "Test set: Average loss: 2.1581, Accuracy: 2813/5000 (56%)\n",
      "[epoch 34] loss: 0.2126930\n",
      "Test set: Average loss: 2.2060, Accuracy: 2793/5000 (56%)\n",
      "[epoch 35] loss: 0.2074812\n",
      "Test set: Average loss: 2.2236, Accuracy: 2806/5000 (56%)\n",
      "[epoch 36] loss: 0.1981081\n",
      "Test set: Average loss: 2.2638, Accuracy: 2801/5000 (56%)\n",
      "[epoch 37] loss: 0.1900027\n",
      "Test set: Average loss: 2.2852, Accuracy: 2800/5000 (56%)\n",
      "[epoch 38] loss: 0.1894561\n",
      "Test set: Average loss: 2.3387, Accuracy: 2801/5000 (56%)\n",
      "[epoch 39] loss: 0.1785884\n",
      "Test set: Average loss: 2.3705, Accuracy: 2796/5000 (56%)\n",
      "[epoch 40] loss: 0.1689014\n",
      "Test set: Average loss: 2.4205, Accuracy: 2787/5000 (56%)\n",
      "[epoch 41] loss: 0.1631645\n",
      "Test set: Average loss: 2.4581, Accuracy: 2801/5000 (56%)\n",
      "[epoch 42] loss: 0.1571472\n",
      "Test set: Average loss: 2.4934, Accuracy: 2801/5000 (56%)\n",
      "[epoch 43] loss: 0.1506430\n",
      "Test set: Average loss: 2.5370, Accuracy: 2788/5000 (56%)\n",
      "[epoch 44] loss: 0.1432208\n",
      "Test set: Average loss: 2.5805, Accuracy: 2783/5000 (56%)\n",
      "[epoch 45] loss: 0.1395270\n",
      "Test set: Average loss: 2.6207, Accuracy: 2766/5000 (55%)\n",
      "[epoch 46] loss: 0.1353207\n",
      "Test set: Average loss: 2.6750, Accuracy: 2765/5000 (55%)\n",
      "[epoch 47] loss: 0.1321774\n",
      "Test set: Average loss: 2.7096, Accuracy: 2764/5000 (55%)\n",
      "[epoch 48] loss: 0.1244318\n",
      "Test set: Average loss: 2.7444, Accuracy: 2783/5000 (56%)\n",
      "[epoch 49] loss: 0.1160789\n",
      "Test set: Average loss: 2.7983, Accuracy: 2781/5000 (56%)\n",
      "[epoch 50] loss: 0.1159787\n",
      "Test set: Average loss: 2.8667, Accuracy: 2753/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2689, Accuracy: 2919/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.2227, Accuracy: 5945/10000 (59%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2905, Accuracy: 669/5000 (13%)\n",
      "[epoch 1] loss: 1.2967572\n",
      "Test set: Average loss: 1.2106, Accuracy: 2908/5000 (58%)\n",
      "[epoch 2] loss: 1.0942269\n",
      "Test set: Average loss: 1.2188, Accuracy: 2910/5000 (58%)\n",
      "[epoch 3] loss: 1.0302930\n",
      "Test set: Average loss: 1.2231, Accuracy: 2880/5000 (58%)\n",
      "[epoch 4] loss: 0.9416870\n",
      "Test set: Average loss: 1.2834, Accuracy: 2902/5000 (58%)\n",
      "[epoch 5] loss: 0.8949692\n",
      "Test set: Average loss: 1.2852, Accuracy: 2853/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.8768251\n",
      "Test set: Average loss: 1.3891, Accuracy: 2723/5000 (54%)\n",
      "[epoch 7] loss: 0.8552993\n",
      "Test set: Average loss: 1.5463, Accuracy: 2658/5000 (53%)\n",
      "[epoch 8] loss: 0.8414942\n",
      "Test set: Average loss: 1.3812, Accuracy: 2831/5000 (57%)\n",
      "[epoch 9] loss: 0.7497247\n",
      "Test set: Average loss: 1.4564, Accuracy: 2776/5000 (56%)\n",
      "[epoch 10] loss: 0.7425719\n",
      "Test set: Average loss: 1.4937, Accuracy: 2722/5000 (54%)\n",
      "[epoch 11] loss: 0.6833941\n",
      "Test set: Average loss: 1.6541, Accuracy: 2643/5000 (53%)\n",
      "[epoch 12] loss: 0.7205392\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5087, Accuracy: 2705/5000 (54%)\n",
      "[epoch 13] loss: 0.4654074\n",
      "Test set: Average loss: 1.4311, Accuracy: 2829/5000 (57%)\n",
      "[epoch 14] loss: 0.4169489\n",
      "Test set: Average loss: 1.4671, Accuracy: 2856/5000 (57%)\n",
      "[epoch 15] loss: 0.3965796\n",
      "Test set: Average loss: 1.4921, Accuracy: 2858/5000 (57%)\n",
      "[epoch 16] loss: 0.3854538\n",
      "Test set: Average loss: 1.5465, Accuracy: 2843/5000 (57%)\n",
      "[epoch 17] loss: 0.3668763\n",
      "Test set: Average loss: 1.5613, Accuracy: 2870/5000 (57%)\n",
      "[epoch 18] loss: 0.3581507\n",
      "Test set: Average loss: 1.5860, Accuracy: 2841/5000 (57%)\n",
      "[epoch 19] loss: 0.3485051\n",
      "Test set: Average loss: 1.6210, Accuracy: 2852/5000 (57%)\n",
      "[epoch 20] loss: 0.3367270\n",
      "Test set: Average loss: 1.6475, Accuracy: 2836/5000 (57%)\n",
      "[epoch 21] loss: 0.3247689\n",
      "Test set: Average loss: 1.6911, Accuracy: 2811/5000 (56%)\n",
      "[epoch 22] loss: 0.3174562\n",
      "Test set: Average loss: 1.7171, Accuracy: 2826/5000 (57%)\n",
      "[epoch 23] loss: 0.3044910\n",
      "Test set: Average loss: 1.7512, Accuracy: 2823/5000 (56%)\n",
      "[epoch 24] loss: 0.3001025\n",
      "Test set: Average loss: 1.7753, Accuracy: 2829/5000 (57%)\n",
      "[epoch 25] loss: 0.2967880\n",
      "Test set: Average loss: 1.8111, Accuracy: 2826/5000 (57%)\n",
      "[epoch 26] loss: 0.2841728\n",
      "Test set: Average loss: 1.8462, Accuracy: 2825/5000 (56%)\n",
      "[epoch 27] loss: 0.2715382\n",
      "Test set: Average loss: 1.8776, Accuracy: 2811/5000 (56%)\n",
      "[epoch 28] loss: 0.2670132\n",
      "Test set: Average loss: 1.9197, Accuracy: 2793/5000 (56%)\n",
      "[epoch 29] loss: 0.2585588\n",
      "Test set: Average loss: 1.9353, Accuracy: 2800/5000 (56%)\n",
      "[epoch 30] loss: 0.2473917\n",
      "Test set: Average loss: 1.9781, Accuracy: 2804/5000 (56%)\n",
      "[epoch 31] loss: 0.2413038\n",
      "Test set: Average loss: 2.0068, Accuracy: 2781/5000 (56%)\n",
      "[epoch 32] loss: 0.2330319\n",
      "Test set: Average loss: 2.0420, Accuracy: 2788/5000 (56%)\n",
      "[epoch 33] loss: 0.2249377\n",
      "Test set: Average loss: 2.0743, Accuracy: 2799/5000 (56%)\n",
      "[epoch 34] loss: 0.2189235\n",
      "Test set: Average loss: 2.1188, Accuracy: 2791/5000 (56%)\n",
      "[epoch 35] loss: 0.2116081\n",
      "Test set: Average loss: 2.1753, Accuracy: 2767/5000 (55%)\n",
      "[epoch 36] loss: 0.2023817\n",
      "Test set: Average loss: 2.1915, Accuracy: 2788/5000 (56%)\n",
      "[epoch 37] loss: 0.1969229\n",
      "Test set: Average loss: 2.2248, Accuracy: 2763/5000 (55%)\n",
      "[epoch 38] loss: 0.1905237\n",
      "Test set: Average loss: 2.2784, Accuracy: 2756/5000 (55%)\n",
      "[epoch 39] loss: 0.1825890\n",
      "Test set: Average loss: 2.3161, Accuracy: 2759/5000 (55%)\n",
      "[epoch 40] loss: 0.1755972\n",
      "Test set: Average loss: 2.3516, Accuracy: 2764/5000 (55%)\n",
      "[epoch 41] loss: 0.1694479\n",
      "Test set: Average loss: 2.3939, Accuracy: 2752/5000 (55%)\n",
      "[epoch 42] loss: 0.1624187\n",
      "Test set: Average loss: 2.4267, Accuracy: 2746/5000 (55%)\n",
      "[epoch 43] loss: 0.1552622\n",
      "Test set: Average loss: 2.4508, Accuracy: 2755/5000 (55%)\n",
      "[epoch 44] loss: 0.1513473\n",
      "Test set: Average loss: 2.5099, Accuracy: 2753/5000 (55%)\n",
      "[epoch 45] loss: 0.1447189\n",
      "Test set: Average loss: 2.5433, Accuracy: 2761/5000 (55%)\n",
      "[epoch 46] loss: 0.1398270\n",
      "Test set: Average loss: 2.5981, Accuracy: 2751/5000 (55%)\n",
      "[epoch 47] loss: 0.1330202\n",
      "Test set: Average loss: 2.6237, Accuracy: 2751/5000 (55%)\n",
      "[epoch 48] loss: 0.1324624\n",
      "Test set: Average loss: 2.6919, Accuracy: 2750/5000 (55%)\n",
      "[epoch 49] loss: 0.1227324\n",
      "Test set: Average loss: 2.7059, Accuracy: 2741/5000 (55%)\n",
      "[epoch 50] loss: 0.1182405\n",
      "Test set: Average loss: 2.7537, Accuracy: 2756/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2188, Accuracy: 2910/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.1707, Accuracy: 5937/10000 (59%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2944, Accuracy: 823/5000 (16%)\n",
      "[epoch 1] loss: 1.3105616\n",
      "Test set: Average loss: 1.3083, Accuracy: 2780/5000 (56%)\n",
      "[epoch 2] loss: 1.1336495\n",
      "Test set: Average loss: 1.1989, Accuracy: 2931/5000 (59%)\n",
      "[epoch 3] loss: 1.0258043\n",
      "Test set: Average loss: 1.2239, Accuracy: 2883/5000 (58%)\n",
      "[epoch 4] loss: 0.9566452\n",
      "Test set: Average loss: 1.3698, Accuracy: 2732/5000 (55%)\n",
      "[epoch 5] loss: 0.9302770\n",
      "Test set: Average loss: 1.3158, Accuracy: 2821/5000 (56%)\n",
      "[epoch 6] loss: 0.8638181\n",
      "Test set: Average loss: 1.3685, Accuracy: 2783/5000 (56%)\n",
      "[epoch 7] loss: 0.8478838\n",
      "Test set: Average loss: 1.4235, Accuracy: 2694/5000 (54%)\n",
      "[epoch 8] loss: 0.7991017\n",
      "Test set: Average loss: 1.3721, Accuracy: 2785/5000 (56%)\n",
      "[epoch 9] loss: 0.7563257\n",
      "Test set: Average loss: 1.4467, Accuracy: 2782/5000 (56%)\n",
      "[epoch 10] loss: 0.7496896\n",
      "Test set: Average loss: 1.4801, Accuracy: 2747/5000 (55%)\n",
      "[epoch 11] loss: 0.6999095\n",
      "Test set: Average loss: 1.6196, Accuracy: 2752/5000 (55%)\n",
      "[epoch 12] loss: 0.6829752\n",
      "Test set: Average loss: 1.5426, Accuracy: 2759/5000 (55%)\n",
      "[epoch 13] loss: 0.6636391\n",
      "Test set: Average loss: 1.6047, Accuracy: 2708/5000 (54%)\n",
      "[epoch 14] loss: 0.6340207\n",
      "Test set: Average loss: 1.6437, Accuracy: 2726/5000 (55%)\n",
      "[epoch 15] loss: 0.5955919\n",
      "Test set: Average loss: 1.7080, Accuracy: 2703/5000 (54%)\n",
      "[epoch 16] loss: 0.5433963\n",
      "Test set: Average loss: 1.7715, Accuracy: 2690/5000 (54%)\n",
      "[epoch 17] loss: 0.5966524\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8699, Accuracy: 2575/5000 (52%)\n",
      "[epoch 18] loss: 0.3708679\n",
      "Test set: Average loss: 1.6539, Accuracy: 2800/5000 (56%)\n",
      "[epoch 19] loss: 0.3015662\n",
      "Test set: Average loss: 1.6966, Accuracy: 2802/5000 (56%)\n",
      "[epoch 20] loss: 0.2831183\n",
      "Test set: Average loss: 1.7209, Accuracy: 2828/5000 (57%)\n",
      "[epoch 21] loss: 0.2666689\n",
      "Test set: Average loss: 1.7704, Accuracy: 2806/5000 (56%)\n",
      "[epoch 22] loss: 0.2542866\n",
      "Test set: Average loss: 1.8058, Accuracy: 2787/5000 (56%)\n",
      "[epoch 23] loss: 0.2464819\n",
      "Test set: Average loss: 1.8642, Accuracy: 2783/5000 (56%)\n",
      "[epoch 24] loss: 0.2374141\n",
      "Test set: Average loss: 1.8746, Accuracy: 2789/5000 (56%)\n",
      "[epoch 25] loss: 0.2263534\n",
      "Test set: Average loss: 1.9187, Accuracy: 2755/5000 (55%)\n",
      "[epoch 26] loss: 0.2183403\n",
      "Test set: Average loss: 1.9574, Accuracy: 2782/5000 (56%)\n",
      "[epoch 27] loss: 0.2103103\n",
      "Test set: Average loss: 1.9833, Accuracy: 2770/5000 (55%)\n",
      "[epoch 28] loss: 0.2618191\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0390, Accuracy: 2755/5000 (55%)\n",
      "[epoch 29] loss: 0.1837032\n",
      "Test set: Average loss: 2.0243, Accuracy: 2776/5000 (56%)\n",
      "[epoch 30] loss: 0.1795632\n",
      "Test set: Average loss: 2.0301, Accuracy: 2779/5000 (56%)\n",
      "[epoch 31] loss: 0.1807472\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0325, Accuracy: 2772/5000 (55%)\n",
      "[epoch 32] loss: 0.1761311\n",
      "Test set: Average loss: 2.0332, Accuracy: 2772/5000 (55%)\n",
      "[epoch 33] loss: 0.1774357\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0338, Accuracy: 2775/5000 (56%)\n",
      "[epoch 34] loss: 0.1766231\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 35] loss: 0.1758330\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 36] loss: 0.1759069\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 37] loss: 0.1757171\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 38] loss: 0.1764294\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 39] loss: 0.1762665\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 40] loss: 0.1781570\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 41] loss: 0.1755015\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 42] loss: 0.1758501\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-13.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 43] loss: 0.1755493\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 44] loss: 0.1754360\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 45] loss: 0.1764439\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 46] loss: 0.1758437\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 47] loss: 0.1753841\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 48] loss: 0.1763951\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 49] loss: 0.1774543\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "[epoch 50] loss: 0.1758448\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0339, Accuracy: 2776/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1989, Accuracy: 2931/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 1.1476, Accuracy: 5982/10000 (60%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3022, Accuracy: 501/5000 (10%)\n",
      "[epoch 1] loss: 1.2272605\n",
      "Test set: Average loss: 1.2251, Accuracy: 2893/5000 (58%)\n",
      "[epoch 2] loss: 1.1019229\n",
      "Test set: Average loss: 1.2130, Accuracy: 2907/5000 (58%)\n",
      "[epoch 3] loss: 1.0421408\n",
      "Test set: Average loss: 1.1768, Accuracy: 2996/5000 (60%)\n",
      "[epoch 4] loss: 0.9899658\n",
      "Test set: Average loss: 1.2206, Accuracy: 2928/5000 (59%)\n",
      "[epoch 5] loss: 0.9538197\n",
      "Test set: Average loss: 1.2395, Accuracy: 2980/5000 (60%)\n",
      "[epoch 6] loss: 0.9351514\n",
      "Test set: Average loss: 1.2602, Accuracy: 2911/5000 (58%)\n",
      "[epoch 7] loss: 0.9106044\n",
      "Test set: Average loss: 1.2460, Accuracy: 2933/5000 (59%)\n",
      "[epoch 8] loss: 0.8590367\n",
      "Test set: Average loss: 1.2477, Accuracy: 2935/5000 (59%)\n",
      "[epoch 9] loss: 0.8565870\n",
      "Test set: Average loss: 1.2727, Accuracy: 2910/5000 (58%)\n",
      "[epoch 10] loss: 0.8316723\n",
      "Test set: Average loss: 1.3446, Accuracy: 2872/5000 (57%)\n",
      "[epoch 11] loss: 0.8043659\n",
      "Test set: Average loss: 1.2577, Accuracy: 2961/5000 (59%)\n",
      "[epoch 12] loss: 0.7798042\n",
      "Test set: Average loss: 1.3577, Accuracy: 2921/5000 (58%)\n",
      "[epoch 13] loss: 0.7608306\n",
      "Test set: Average loss: 1.3846, Accuracy: 2951/5000 (59%)\n",
      "[epoch 14] loss: 0.7186217\n",
      "Test set: Average loss: 1.3592, Accuracy: 2875/5000 (58%)\n",
      "[epoch 15] loss: 0.6769069\n",
      "Test set: Average loss: 1.4081, Accuracy: 2879/5000 (58%)\n",
      "[epoch 16] loss: 0.6508335\n",
      "Test set: Average loss: 1.3666, Accuracy: 2925/5000 (58%)\n",
      "[epoch 17] loss: 0.6049937\n",
      "Test set: Average loss: 1.4109, Accuracy: 2926/5000 (59%)\n",
      "[epoch 18] loss: 0.5613086\n",
      "Test set: Average loss: 1.4604, Accuracy: 2903/5000 (58%)\n",
      "[epoch 19] loss: 0.5184222\n",
      "Test set: Average loss: 1.4767, Accuracy: 2916/5000 (58%)\n",
      "[epoch 20] loss: 0.4659299\n",
      "Test set: Average loss: 1.4970, Accuracy: 2933/5000 (59%)\n",
      "[epoch 21] loss: 0.4085254\n",
      "Test set: Average loss: 1.5653, Accuracy: 2944/5000 (59%)\n",
      "[epoch 22] loss: 0.3580484\n",
      "Test set: Average loss: 1.5936, Accuracy: 2911/5000 (58%)\n",
      "[epoch 23] loss: 0.3152476\n",
      "Test set: Average loss: 1.6314, Accuracy: 2915/5000 (58%)\n",
      "[epoch 24] loss: 0.2336783\n",
      "Test set: Average loss: 1.7331, Accuracy: 2922/5000 (58%)\n",
      "[epoch 25] loss: 0.1956083\n",
      "Test set: Average loss: 1.7854, Accuracy: 2900/5000 (58%)\n",
      "[epoch 26] loss: 0.1638807\n",
      "Test set: Average loss: 1.9449, Accuracy: 2874/5000 (57%)\n",
      "[epoch 27] loss: 0.1263277\n",
      "Test set: Average loss: 1.8974, Accuracy: 2931/5000 (59%)\n",
      "[epoch 28] loss: 0.1069486\n",
      "Test set: Average loss: 2.0023, Accuracy: 2940/5000 (59%)\n",
      "[epoch 29] loss: 0.0659041\n",
      "Test set: Average loss: 2.0786, Accuracy: 2937/5000 (59%)\n",
      "[epoch 30] loss: 0.0352295\n",
      "Test set: Average loss: 2.1309, Accuracy: 2922/5000 (58%)\n",
      "[epoch 31] loss: 0.0264693\n",
      "Test set: Average loss: 2.1866, Accuracy: 2966/5000 (59%)\n",
      "[epoch 32] loss: 0.0091222\n",
      "Test set: Average loss: 2.2507, Accuracy: 2968/5000 (59%)\n",
      "[epoch 33] loss: 0.0047342\n",
      "Test set: Average loss: 2.3000, Accuracy: 2981/5000 (60%)\n",
      "[epoch 34] loss: 0.0034520\n",
      "Test set: Average loss: 2.3488, Accuracy: 3000/5000 (60%)\n",
      "[epoch 35] loss: 0.0027816\n",
      "Test set: Average loss: 2.3971, Accuracy: 2993/5000 (60%)\n",
      "[epoch 36] loss: 0.0022895\n",
      "Test set: Average loss: 2.4461, Accuracy: 3001/5000 (60%)\n",
      "[epoch 37] loss: 0.0019034\n",
      "Test set: Average loss: 2.4869, Accuracy: 3005/5000 (60%)\n",
      "[epoch 38] loss: 0.0015856\n",
      "Test set: Average loss: 2.5350, Accuracy: 3005/5000 (60%)\n",
      "[epoch 39] loss: 0.0013248\n",
      "Test set: Average loss: 2.5810, Accuracy: 3010/5000 (60%)\n",
      "[epoch 40] loss: 0.0011093\n",
      "Test set: Average loss: 2.6332, Accuracy: 3012/5000 (60%)\n",
      "[epoch 41] loss: 0.0009340\n",
      "Test set: Average loss: 2.6830, Accuracy: 3011/5000 (60%)\n",
      "[epoch 42] loss: 0.0007776\n",
      "Test set: Average loss: 2.7279, Accuracy: 3004/5000 (60%)\n",
      "[epoch 43] loss: 0.0006460\n",
      "Test set: Average loss: 2.7690, Accuracy: 3006/5000 (60%)\n",
      "[epoch 44] loss: 0.0005409\n",
      "Test set: Average loss: 2.8189, Accuracy: 3012/5000 (60%)\n",
      "[epoch 45] loss: 0.0004518\n",
      "Test set: Average loss: 2.8655, Accuracy: 3012/5000 (60%)\n",
      "[epoch 46] loss: 0.0003777\n",
      "Test set: Average loss: 2.9253, Accuracy: 3008/5000 (60%)\n",
      "[epoch 47] loss: 0.0003149\n",
      "Test set: Average loss: 2.9625, Accuracy: 3010/5000 (60%)\n",
      "[epoch 48] loss: 0.0002603\n",
      "Test set: Average loss: 3.0075, Accuracy: 3013/5000 (60%)\n",
      "[epoch 49] loss: 0.0002148\n",
      "Test set: Average loss: 3.0656, Accuracy: 3012/5000 (60%)\n",
      "[epoch 50] loss: 0.0001785\n",
      "Test set: Average loss: 3.1131, Accuracy: 3009/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0075, Accuracy: 3013/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.9406, Accuracy: 6091/10000 (61%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3081, Accuracy: 403/5000 (8%)\n",
      "[epoch 1] loss: 1.2349383\n",
      "Test set: Average loss: 1.2989, Accuracy: 2746/5000 (55%)\n",
      "[epoch 2] loss: 1.0830546\n",
      "Test set: Average loss: 1.2615, Accuracy: 2760/5000 (55%)\n",
      "[epoch 3] loss: 1.0261608\n",
      "Test set: Average loss: 1.2369, Accuracy: 2876/5000 (58%)\n",
      "[epoch 4] loss: 0.9899695\n",
      "Test set: Average loss: 1.2481, Accuracy: 2905/5000 (58%)\n",
      "[epoch 5] loss: 0.9407942\n",
      "Test set: Average loss: 1.2980, Accuracy: 2754/5000 (55%)\n",
      "[epoch 6] loss: 0.9260285\n",
      "Test set: Average loss: 1.2125, Accuracy: 2913/5000 (58%)\n",
      "[epoch 7] loss: 0.8945393\n",
      "Test set: Average loss: 1.3013, Accuracy: 2815/5000 (56%)\n",
      "[epoch 8] loss: 0.8670268\n",
      "Test set: Average loss: 1.2328, Accuracy: 2949/5000 (59%)\n",
      "[epoch 9] loss: 0.8354158\n",
      "Test set: Average loss: 1.2602, Accuracy: 2918/5000 (58%)\n",
      "[epoch 10] loss: 0.8218617\n",
      "Test set: Average loss: 1.2552, Accuracy: 2934/5000 (59%)\n",
      "[epoch 11] loss: 0.7958822\n",
      "Test set: Average loss: 1.3209, Accuracy: 2865/5000 (57%)\n",
      "[epoch 12] loss: 0.7653714\n",
      "Test set: Average loss: 1.3489, Accuracy: 2876/5000 (58%)\n",
      "[epoch 13] loss: 0.7304265\n",
      "Test set: Average loss: 1.3508, Accuracy: 2834/5000 (57%)\n",
      "[epoch 14] loss: 0.6998337\n",
      "Test set: Average loss: 1.3402, Accuracy: 2871/5000 (57%)\n",
      "[epoch 15] loss: 0.6508747\n",
      "Test set: Average loss: 1.3867, Accuracy: 2925/5000 (58%)\n",
      "[epoch 16] loss: 0.6163904\n",
      "Test set: Average loss: 1.3726, Accuracy: 2916/5000 (58%)\n",
      "[epoch 17] loss: 0.5881893\n",
      "Test set: Average loss: 1.3974, Accuracy: 2895/5000 (58%)\n",
      "[epoch 18] loss: 0.5321958\n",
      "Test set: Average loss: 1.4688, Accuracy: 2903/5000 (58%)\n",
      "[epoch 19] loss: 0.4817815\n",
      "Test set: Average loss: 1.5471, Accuracy: 2862/5000 (57%)\n",
      "[epoch 20] loss: 0.4424254\n",
      "Test set: Average loss: 1.4639, Accuracy: 2898/5000 (58%)\n",
      "[epoch 21] loss: 0.3811650\n",
      "Test set: Average loss: 1.5218, Accuracy: 2925/5000 (58%)\n",
      "[epoch 22] loss: 0.3413012\n",
      "Test set: Average loss: 1.6100, Accuracy: 2894/5000 (58%)\n",
      "[epoch 23] loss: 0.2543375\n",
      "Test set: Average loss: 1.6168, Accuracy: 2895/5000 (58%)\n",
      "[epoch 24] loss: 0.2097682\n",
      "Test set: Average loss: 1.7231, Accuracy: 2901/5000 (58%)\n",
      "[epoch 25] loss: 0.1538444\n",
      "Test set: Average loss: 1.8366, Accuracy: 2920/5000 (58%)\n",
      "[epoch 26] loss: 0.1199208\n",
      "Test set: Average loss: 1.8680, Accuracy: 2894/5000 (58%)\n",
      "[epoch 27] loss: 0.1149228\n",
      "Test set: Average loss: 1.9542, Accuracy: 2879/5000 (58%)\n",
      "[epoch 28] loss: 0.1424823\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.9503, Accuracy: 2950/5000 (59%)\n",
      "[epoch 29] loss: 0.0399139\n",
      "Test set: Average loss: 1.9164, Accuracy: 2979/5000 (60%)\n",
      "[epoch 30] loss: 0.0246050\n",
      "Test set: Average loss: 1.9231, Accuracy: 2985/5000 (60%)\n",
      "[epoch 31] loss: 0.0201549\n",
      "Test set: Average loss: 1.9402, Accuracy: 2993/5000 (60%)\n",
      "[epoch 32] loss: 0.0174557\n",
      "Test set: Average loss: 1.9577, Accuracy: 3005/5000 (60%)\n",
      "[epoch 33] loss: 0.0154578\n",
      "Test set: Average loss: 1.9698, Accuracy: 3007/5000 (60%)\n",
      "[epoch 34] loss: 0.0138274\n",
      "Test set: Average loss: 1.9890, Accuracy: 3000/5000 (60%)\n",
      "[epoch 35] loss: 0.0124559\n",
      "Test set: Average loss: 2.0057, Accuracy: 2999/5000 (60%)\n",
      "[epoch 36] loss: 0.0112787\n",
      "Test set: Average loss: 2.0261, Accuracy: 3002/5000 (60%)\n",
      "[epoch 37] loss: 0.0101822\n",
      "Test set: Average loss: 2.0449, Accuracy: 2998/5000 (60%)\n",
      "[epoch 38] loss: 0.0092092\n",
      "Test set: Average loss: 2.0655, Accuracy: 2994/5000 (60%)\n",
      "[epoch 39] loss: 0.0083221\n",
      "Test set: Average loss: 2.0893, Accuracy: 3006/5000 (60%)\n",
      "[epoch 40] loss: 0.0074878\n",
      "Test set: Average loss: 2.1133, Accuracy: 2999/5000 (60%)\n",
      "[epoch 41] loss: 0.0067108\n",
      "Test set: Average loss: 2.1375, Accuracy: 3010/5000 (60%)\n",
      "[epoch 42] loss: 0.0060595\n",
      "Test set: Average loss: 2.1591, Accuracy: 3007/5000 (60%)\n",
      "[epoch 43] loss: 0.0054353\n",
      "Test set: Average loss: 2.1889, Accuracy: 3007/5000 (60%)\n",
      "[epoch 44] loss: 0.0048596\n",
      "Test set: Average loss: 2.2113, Accuracy: 3018/5000 (60%)\n",
      "[epoch 45] loss: 0.0043467\n",
      "Test set: Average loss: 2.2406, Accuracy: 3012/5000 (60%)\n",
      "[epoch 46] loss: 0.0038607\n",
      "Test set: Average loss: 2.2651, Accuracy: 3002/5000 (60%)\n",
      "[epoch 47] loss: 0.0034378\n",
      "Test set: Average loss: 2.2935, Accuracy: 3009/5000 (60%)\n",
      "[epoch 48] loss: 0.0030446\n",
      "Test set: Average loss: 2.3204, Accuracy: 3006/5000 (60%)\n",
      "[epoch 49] loss: 0.0026944\n",
      "Test set: Average loss: 2.3536, Accuracy: 3017/5000 (60%)\n",
      "[epoch 50] loss: 0.0023850\n",
      "Test set: Average loss: 2.3826, Accuracy: 3018/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3826, Accuracy: 3018/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.2950, Accuracy: 6183/10000 (62%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2980, Accuracy: 697/5000 (14%)\n",
      "[epoch 1] loss: 1.2621685\n",
      "Test set: Average loss: 1.1977, Accuracy: 2876/5000 (58%)\n",
      "[epoch 2] loss: 1.1040896\n",
      "Test set: Average loss: 1.2437, Accuracy: 2857/5000 (57%)\n",
      "[epoch 3] loss: 1.0575617\n",
      "Test set: Average loss: 1.2464, Accuracy: 2880/5000 (58%)\n",
      "[epoch 4] loss: 1.0087888\n",
      "Test set: Average loss: 1.2168, Accuracy: 2879/5000 (58%)\n",
      "[epoch 5] loss: 0.9801623\n",
      "Test set: Average loss: 1.1954, Accuracy: 2971/5000 (59%)\n",
      "[epoch 6] loss: 0.9482264\n",
      "Test set: Average loss: 1.3310, Accuracy: 2826/5000 (57%)\n",
      "[epoch 7] loss: 0.9197514\n",
      "Test set: Average loss: 1.1857, Accuracy: 3002/5000 (60%)\n",
      "[epoch 8] loss: 0.9150190\n",
      "Test set: Average loss: 1.2356, Accuracy: 2929/5000 (59%)\n",
      "[epoch 9] loss: 0.8925637\n",
      "Test set: Average loss: 1.3212, Accuracy: 2790/5000 (56%)\n",
      "[epoch 10] loss: 0.8571234\n",
      "Test set: Average loss: 1.2302, Accuracy: 2950/5000 (59%)\n",
      "[epoch 11] loss: 0.8341503\n",
      "Test set: Average loss: 1.2810, Accuracy: 2871/5000 (57%)\n",
      "[epoch 12] loss: 0.8039863\n",
      "Test set: Average loss: 1.2796, Accuracy: 2855/5000 (57%)\n",
      "[epoch 13] loss: 0.7839246\n",
      "Test set: Average loss: 1.2715, Accuracy: 2929/5000 (59%)\n",
      "[epoch 14] loss: 0.7451992\n",
      "Test set: Average loss: 1.3282, Accuracy: 2852/5000 (57%)\n",
      "[epoch 15] loss: 0.7118186\n",
      "Test set: Average loss: 1.3452, Accuracy: 2841/5000 (57%)\n",
      "[epoch 16] loss: 0.6768864\n",
      "Test set: Average loss: 1.4370, Accuracy: 2816/5000 (56%)\n",
      "[epoch 17] loss: 0.6485090\n",
      "Test set: Average loss: 1.4300, Accuracy: 2877/5000 (58%)\n",
      "[epoch 18] loss: 0.5892710\n",
      "Test set: Average loss: 1.4015, Accuracy: 2885/5000 (58%)\n",
      "[epoch 19] loss: 0.5165782\n",
      "Test set: Average loss: 1.4357, Accuracy: 2872/5000 (57%)\n",
      "[epoch 20] loss: 0.4841767\n",
      "Test set: Average loss: 1.4539, Accuracy: 2902/5000 (58%)\n",
      "[epoch 21] loss: 0.4141500\n",
      "Test set: Average loss: 1.5272, Accuracy: 2838/5000 (57%)\n",
      "[epoch 22] loss: 0.3601077\n",
      "Test set: Average loss: 1.5707, Accuracy: 2881/5000 (58%)\n",
      "[epoch 23] loss: 0.2952198\n",
      "Test set: Average loss: 1.6721, Accuracy: 2834/5000 (57%)\n",
      "[epoch 24] loss: 0.2586573\n",
      "Test set: Average loss: 1.7427, Accuracy: 2878/5000 (58%)\n",
      "[epoch 25] loss: 0.2008168\n",
      "Test set: Average loss: 1.7905, Accuracy: 2810/5000 (56%)\n",
      "[epoch 26] loss: 0.1687803\n",
      "Test set: Average loss: 1.8306, Accuracy: 2885/5000 (58%)\n",
      "[epoch 27] loss: 0.1432983\n",
      "Test set: Average loss: 1.8836, Accuracy: 2866/5000 (57%)\n",
      "[epoch 28] loss: 0.0685921\n",
      "Test set: Average loss: 1.9667, Accuracy: 2908/5000 (58%)\n",
      "[epoch 29] loss: 0.0422414\n",
      "Test set: Average loss: 2.0376, Accuracy: 2866/5000 (57%)\n",
      "[epoch 30] loss: 0.0256166\n",
      "Test set: Average loss: 2.0880, Accuracy: 2931/5000 (59%)\n",
      "[epoch 31] loss: 0.0105688\n",
      "Test set: Average loss: 2.1504, Accuracy: 2925/5000 (58%)\n",
      "[epoch 32] loss: 0.0063785\n",
      "Test set: Average loss: 2.2139, Accuracy: 2940/5000 (59%)\n",
      "[epoch 33] loss: 0.0046422\n",
      "Test set: Average loss: 2.2774, Accuracy: 2920/5000 (58%)\n",
      "[epoch 34] loss: 0.0036421\n",
      "Test set: Average loss: 2.3252, Accuracy: 2938/5000 (59%)\n",
      "[epoch 35] loss: 0.0029421\n",
      "Test set: Average loss: 2.3810, Accuracy: 2943/5000 (59%)\n",
      "[epoch 36] loss: 0.0024180\n",
      "Test set: Average loss: 2.4258, Accuracy: 2945/5000 (59%)\n",
      "[epoch 37] loss: 0.0019805\n",
      "Test set: Average loss: 2.4845, Accuracy: 2934/5000 (59%)\n",
      "[epoch 38] loss: 0.0016394\n",
      "Test set: Average loss: 2.5231, Accuracy: 2947/5000 (59%)\n",
      "[epoch 39] loss: 0.0013444\n",
      "Test set: Average loss: 2.5916, Accuracy: 2938/5000 (59%)\n",
      "[epoch 40] loss: 0.0011061\n",
      "Test set: Average loss: 2.6228, Accuracy: 2942/5000 (59%)\n",
      "[epoch 41] loss: 0.0009202\n",
      "Test set: Average loss: 2.6789, Accuracy: 2944/5000 (59%)\n",
      "[epoch 42] loss: 0.0007623\n",
      "Test set: Average loss: 2.7330, Accuracy: 2941/5000 (59%)\n",
      "[epoch 43] loss: 0.0006260\n",
      "Test set: Average loss: 2.7961, Accuracy: 2936/5000 (59%)\n",
      "[epoch 44] loss: 0.0005114\n",
      "Test set: Average loss: 2.8446, Accuracy: 2934/5000 (59%)\n",
      "[epoch 45] loss: 0.0004219\n",
      "Test set: Average loss: 2.8945, Accuracy: 2944/5000 (59%)\n",
      "[epoch 46] loss: 0.0003459\n",
      "Test set: Average loss: 2.9505, Accuracy: 2934/5000 (59%)\n",
      "[epoch 47] loss: 0.0002861\n",
      "Test set: Average loss: 3.0080, Accuracy: 2928/5000 (59%)\n",
      "[epoch 48] loss: 0.0002350\n",
      "Test set: Average loss: 3.0493, Accuracy: 2939/5000 (59%)\n",
      "[epoch 49] loss: 0.0001938\n",
      "Test set: Average loss: 3.1092, Accuracy: 2944/5000 (59%)\n",
      "[epoch 50] loss: 0.0001590\n",
      "Test set: Average loss: 3.1474, Accuracy: 2943/5000 (59%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1857, Accuracy: 3002/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 1.1308, Accuracy: 6188/10000 (62%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3066, Accuracy: 259/5000 (5%)\n",
      "[epoch 1] loss: 1.2159825\n",
      "Test set: Average loss: 1.2098, Accuracy: 2869/5000 (57%)\n",
      "[epoch 2] loss: 1.0927276\n",
      "Test set: Average loss: 1.1592, Accuracy: 2988/5000 (60%)\n",
      "[epoch 3] loss: 1.0350377\n",
      "Test set: Average loss: 1.1951, Accuracy: 2910/5000 (58%)\n",
      "[epoch 4] loss: 1.0055655\n",
      "Test set: Average loss: 1.2079, Accuracy: 2927/5000 (59%)\n",
      "[epoch 5] loss: 0.9790783\n",
      "Test set: Average loss: 1.1686, Accuracy: 2995/5000 (60%)\n",
      "[epoch 6] loss: 0.9527863\n",
      "Test set: Average loss: 1.2480, Accuracy: 2885/5000 (58%)\n",
      "[epoch 7] loss: 0.9209373\n",
      "Test set: Average loss: 1.1792, Accuracy: 2985/5000 (60%)\n",
      "[epoch 8] loss: 0.8959504\n",
      "Test set: Average loss: 1.1375, Accuracy: 3070/5000 (61%)\n",
      "[epoch 9] loss: 0.8723474\n",
      "Test set: Average loss: 1.1393, Accuracy: 3068/5000 (61%)\n",
      "[epoch 10] loss: 0.8304354\n",
      "Test set: Average loss: 1.1576, Accuracy: 3102/5000 (62%)\n",
      "[epoch 11] loss: 0.8235400\n",
      "Test set: Average loss: 1.1854, Accuracy: 3027/5000 (61%)\n",
      "[epoch 12] loss: 0.7703622\n",
      "Test set: Average loss: 1.1690, Accuracy: 3090/5000 (62%)\n",
      "[epoch 13] loss: 0.7364922\n",
      "Test set: Average loss: 1.2113, Accuracy: 3050/5000 (61%)\n",
      "[epoch 14] loss: 0.6929976\n",
      "Test set: Average loss: 1.2864, Accuracy: 3013/5000 (60%)\n",
      "[epoch 15] loss: 0.6451701\n",
      "Test set: Average loss: 1.2639, Accuracy: 3029/5000 (61%)\n",
      "[epoch 16] loss: 0.5989160\n",
      "Test set: Average loss: 1.3062, Accuracy: 3010/5000 (60%)\n",
      "[epoch 17] loss: 0.5494789\n",
      "Test set: Average loss: 1.3161, Accuracy: 3045/5000 (61%)\n",
      "[epoch 18] loss: 0.4945003\n",
      "Test set: Average loss: 1.3324, Accuracy: 3081/5000 (62%)\n",
      "[epoch 19] loss: 0.4219126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3755, Accuracy: 3072/5000 (61%)\n",
      "[epoch 20] loss: 0.3458257\n",
      "Test set: Average loss: 1.4590, Accuracy: 3037/5000 (61%)\n",
      "[epoch 21] loss: 0.3065528\n",
      "Test set: Average loss: 1.5270, Accuracy: 3015/5000 (60%)\n",
      "[epoch 22] loss: 0.2210184\n",
      "Test set: Average loss: 1.5258, Accuracy: 3085/5000 (62%)\n",
      "[epoch 23] loss: 0.1833101\n",
      "Test set: Average loss: 1.6758, Accuracy: 2977/5000 (60%)\n",
      "[epoch 24] loss: 0.1382976\n",
      "Test set: Average loss: 1.7963, Accuracy: 2983/5000 (60%)\n",
      "[epoch 25] loss: 0.0898698\n",
      "Test set: Average loss: 1.7645, Accuracy: 3073/5000 (61%)\n",
      "[epoch 26] loss: 0.1009071\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9363, Accuracy: 3014/5000 (60%)\n",
      "[epoch 27] loss: 0.0433209\n",
      "Test set: Average loss: 1.8050, Accuracy: 3103/5000 (62%)\n",
      "[epoch 28] loss: 0.0203607\n",
      "Test set: Average loss: 1.8095, Accuracy: 3110/5000 (62%)\n",
      "[epoch 29] loss: 0.0154477\n",
      "Test set: Average loss: 1.8154, Accuracy: 3122/5000 (62%)\n",
      "[epoch 30] loss: 0.0125646\n",
      "Test set: Average loss: 1.8303, Accuracy: 3131/5000 (63%)\n",
      "[epoch 31] loss: 0.0105925\n",
      "Test set: Average loss: 1.8445, Accuracy: 3133/5000 (63%)\n",
      "[epoch 32] loss: 0.0089987\n",
      "Test set: Average loss: 1.8630, Accuracy: 3149/5000 (63%)\n",
      "[epoch 33] loss: 0.0077006\n",
      "Test set: Average loss: 1.8789, Accuracy: 3149/5000 (63%)\n",
      "[epoch 34] loss: 0.0066041\n",
      "Test set: Average loss: 1.9007, Accuracy: 3152/5000 (63%)\n",
      "[epoch 35] loss: 0.0056825\n",
      "Test set: Average loss: 1.9259, Accuracy: 3168/5000 (63%)\n",
      "[epoch 36] loss: 0.0048533\n",
      "Test set: Average loss: 1.9444, Accuracy: 3160/5000 (63%)\n",
      "[epoch 37] loss: 0.0041306\n",
      "Test set: Average loss: 1.9709, Accuracy: 3170/5000 (63%)\n",
      "[epoch 38] loss: 0.0035211\n",
      "Test set: Average loss: 1.9999, Accuracy: 3166/5000 (63%)\n",
      "[epoch 39] loss: 0.0029763\n",
      "Test set: Average loss: 2.0300, Accuracy: 3172/5000 (63%)\n",
      "[epoch 40] loss: 0.0025051\n",
      "Test set: Average loss: 2.0611, Accuracy: 3163/5000 (63%)\n",
      "[epoch 41] loss: 0.0021084\n",
      "Test set: Average loss: 2.0927, Accuracy: 3166/5000 (63%)\n",
      "[epoch 42] loss: 0.0017621\n",
      "Test set: Average loss: 2.1207, Accuracy: 3173/5000 (63%)\n",
      "[epoch 43] loss: 0.0014651\n",
      "Test set: Average loss: 2.1566, Accuracy: 3172/5000 (63%)\n",
      "[epoch 44] loss: 0.0012137\n",
      "Test set: Average loss: 2.1912, Accuracy: 3160/5000 (63%)\n",
      "[epoch 45] loss: 0.0009971\n",
      "Test set: Average loss: 2.2350, Accuracy: 3173/5000 (63%)\n",
      "[epoch 46] loss: 0.0008250\n",
      "Test set: Average loss: 2.2676, Accuracy: 3162/5000 (63%)\n",
      "[epoch 47] loss: 0.0006741\n",
      "Test set: Average loss: 2.2985, Accuracy: 3174/5000 (63%)\n",
      "[epoch 48] loss: 0.0005487\n",
      "Test set: Average loss: 2.3373, Accuracy: 3172/5000 (63%)\n",
      "[epoch 49] loss: 0.0004486\n",
      "Test set: Average loss: 2.3753, Accuracy: 3170/5000 (63%)\n",
      "[epoch 50] loss: 0.0003646\n",
      "Test set: Average loss: 2.4240, Accuracy: 3163/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2985, Accuracy: 3174/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.1781, Accuracy: 6433/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3044, Accuracy: 583/5000 (12%)\n",
      "[epoch 1] loss: 1.2108728\n",
      "Test set: Average loss: 1.2383, Accuracy: 2806/5000 (56%)\n",
      "[epoch 2] loss: 1.0899887\n",
      "Test set: Average loss: 1.1749, Accuracy: 2918/5000 (58%)\n",
      "[epoch 3] loss: 1.0377499\n",
      "Test set: Average loss: 1.2426, Accuracy: 2870/5000 (57%)\n",
      "[epoch 4] loss: 1.0018416\n",
      "Test set: Average loss: 1.1844, Accuracy: 2942/5000 (59%)\n",
      "[epoch 5] loss: 0.9792979\n",
      "Test set: Average loss: 1.2618, Accuracy: 2812/5000 (56%)\n",
      "[epoch 6] loss: 0.9494024\n",
      "Test set: Average loss: 1.1482, Accuracy: 3046/5000 (61%)\n",
      "[epoch 7] loss: 0.9346606\n",
      "Test set: Average loss: 1.2396, Accuracy: 2821/5000 (56%)\n",
      "[epoch 8] loss: 0.8985597\n",
      "Test set: Average loss: 1.1803, Accuracy: 2983/5000 (60%)\n",
      "[epoch 9] loss: 0.8688420\n",
      "Test set: Average loss: 1.1721, Accuracy: 2972/5000 (59%)\n",
      "[epoch 10] loss: 0.8367050\n",
      "Test set: Average loss: 1.1939, Accuracy: 3014/5000 (60%)\n",
      "[epoch 11] loss: 0.8085434\n",
      "Test set: Average loss: 1.2577, Accuracy: 2916/5000 (58%)\n",
      "[epoch 12] loss: 0.7795623\n",
      "Test set: Average loss: 1.1915, Accuracy: 3022/5000 (60%)\n",
      "[epoch 13] loss: 0.7479397\n",
      "Test set: Average loss: 1.2219, Accuracy: 2991/5000 (60%)\n",
      "[epoch 14] loss: 0.7072732\n",
      "Test set: Average loss: 1.2227, Accuracy: 3046/5000 (61%)\n",
      "[epoch 15] loss: 0.6499876\n",
      "Test set: Average loss: 1.2404, Accuracy: 3055/5000 (61%)\n",
      "[epoch 16] loss: 0.6005819\n",
      "Test set: Average loss: 1.2575, Accuracy: 3055/5000 (61%)\n",
      "[epoch 17] loss: 0.5364995\n",
      "Test set: Average loss: 1.2788, Accuracy: 3061/5000 (61%)\n",
      "[epoch 18] loss: 0.4881026\n",
      "Test set: Average loss: 1.3441, Accuracy: 3023/5000 (60%)\n",
      "[epoch 19] loss: 0.4015090\n",
      "Test set: Average loss: 1.4555, Accuracy: 2968/5000 (59%)\n",
      "[epoch 20] loss: 0.3462325\n",
      "Test set: Average loss: 1.4081, Accuracy: 3058/5000 (61%)\n",
      "[epoch 21] loss: 0.2769199\n",
      "Test set: Average loss: 1.4515, Accuracy: 3074/5000 (61%)\n",
      "[epoch 22] loss: 0.2116549\n",
      "Test set: Average loss: 1.5667, Accuracy: 3049/5000 (61%)\n",
      "[epoch 23] loss: 0.1667635\n",
      "Test set: Average loss: 1.6357, Accuracy: 3044/5000 (61%)\n",
      "[epoch 24] loss: 0.1321848\n",
      "Test set: Average loss: 1.7036, Accuracy: 3025/5000 (60%)\n",
      "[epoch 25] loss: 0.0895008\n",
      "Test set: Average loss: 1.8033, Accuracy: 3062/5000 (61%)\n",
      "[epoch 26] loss: 0.0684905\n",
      "Test set: Average loss: 1.9167, Accuracy: 3032/5000 (61%)\n",
      "[epoch 27] loss: 0.1322817\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9207, Accuracy: 3015/5000 (60%)\n",
      "[epoch 28] loss: 0.0461325\n",
      "Test set: Average loss: 1.8179, Accuracy: 3107/5000 (62%)\n",
      "[epoch 29] loss: 0.0184451\n",
      "Test set: Average loss: 1.8275, Accuracy: 3107/5000 (62%)\n",
      "[epoch 30] loss: 0.0133447\n",
      "Test set: Average loss: 1.8426, Accuracy: 3127/5000 (63%)\n",
      "[epoch 31] loss: 0.0106519\n",
      "Test set: Average loss: 1.8598, Accuracy: 3129/5000 (63%)\n",
      "[epoch 32] loss: 0.0087558\n",
      "Test set: Average loss: 1.8784, Accuracy: 3138/5000 (63%)\n",
      "[epoch 33] loss: 0.0073528\n",
      "Test set: Average loss: 1.8927, Accuracy: 3136/5000 (63%)\n",
      "[epoch 34] loss: 0.0062322\n",
      "Test set: Average loss: 1.9125, Accuracy: 3142/5000 (63%)\n",
      "[epoch 35] loss: 0.0052757\n",
      "Test set: Average loss: 1.9337, Accuracy: 3143/5000 (63%)\n",
      "[epoch 36] loss: 0.0044978\n",
      "Test set: Average loss: 1.9594, Accuracy: 3143/5000 (63%)\n",
      "[epoch 37] loss: 0.0038189\n",
      "Test set: Average loss: 1.9833, Accuracy: 3140/5000 (63%)\n",
      "[epoch 38] loss: 0.0032375\n",
      "Test set: Average loss: 2.0114, Accuracy: 3141/5000 (63%)\n",
      "[epoch 39] loss: 0.0027444\n",
      "Test set: Average loss: 2.0326, Accuracy: 3136/5000 (63%)\n",
      "[epoch 40] loss: 0.0023214\n",
      "Test set: Average loss: 2.0600, Accuracy: 3133/5000 (63%)\n",
      "[epoch 41] loss: 0.0019526\n",
      "Test set: Average loss: 2.0924, Accuracy: 3135/5000 (63%)\n",
      "[epoch 42] loss: 0.0016361\n",
      "Test set: Average loss: 2.1228, Accuracy: 3145/5000 (63%)\n",
      "[epoch 43] loss: 0.0013631\n",
      "Test set: Average loss: 2.1565, Accuracy: 3141/5000 (63%)\n",
      "[epoch 44] loss: 0.0011311\n",
      "Test set: Average loss: 2.1901, Accuracy: 3139/5000 (63%)\n",
      "[epoch 45] loss: 0.0009378\n",
      "Test set: Average loss: 2.2235, Accuracy: 3145/5000 (63%)\n",
      "[epoch 46] loss: 0.0007712\n",
      "Test set: Average loss: 2.2657, Accuracy: 3150/5000 (63%)\n",
      "[epoch 47] loss: 0.0006345\n",
      "Test set: Average loss: 2.3054, Accuracy: 3157/5000 (63%)\n",
      "[epoch 48] loss: 0.0005188\n",
      "Test set: Average loss: 2.3393, Accuracy: 3140/5000 (63%)\n",
      "[epoch 49] loss: 0.0004238\n",
      "Test set: Average loss: 2.3765, Accuracy: 3143/5000 (63%)\n",
      "[epoch 50] loss: 0.0003444\n",
      "Test set: Average loss: 2.4169, Accuracy: 3150/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3054, Accuracy: 3157/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.2198, Accuracy: 6482/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2999, Accuracy: 607/5000 (12%)\n",
      "[epoch 1] loss: 1.2088775\n",
      "Test set: Average loss: 1.2772, Accuracy: 2763/5000 (55%)\n",
      "[epoch 2] loss: 1.0932700\n",
      "Test set: Average loss: 1.1816, Accuracy: 2939/5000 (59%)\n",
      "[epoch 3] loss: 1.0406101\n",
      "Test set: Average loss: 1.1528, Accuracy: 3020/5000 (60%)\n",
      "[epoch 4] loss: 0.9971857\n",
      "Test set: Average loss: 1.1463, Accuracy: 3014/5000 (60%)\n",
      "[epoch 5] loss: 0.9775116\n",
      "Test set: Average loss: 1.1597, Accuracy: 2974/5000 (59%)\n",
      "[epoch 6] loss: 0.9455685\n",
      "Test set: Average loss: 1.1721, Accuracy: 3015/5000 (60%)\n",
      "[epoch 7] loss: 0.9209626\n",
      "Test set: Average loss: 1.2569, Accuracy: 2928/5000 (59%)\n",
      "[epoch 8] loss: 0.9110292\n",
      "Test set: Average loss: 1.2049, Accuracy: 3010/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 0.8807069\n",
      "Test set: Average loss: 1.1587, Accuracy: 3044/5000 (61%)\n",
      "[epoch 10] loss: 0.8532133\n",
      "Test set: Average loss: 1.1576, Accuracy: 3072/5000 (61%)\n",
      "[epoch 11] loss: 0.8174056\n",
      "Test set: Average loss: 1.2117, Accuracy: 3040/5000 (61%)\n",
      "[epoch 12] loss: 0.7775286\n",
      "Test set: Average loss: 1.2019, Accuracy: 3030/5000 (61%)\n",
      "[epoch 13] loss: 0.7334440\n",
      "Test set: Average loss: 1.1903, Accuracy: 3057/5000 (61%)\n",
      "[epoch 14] loss: 0.6878932\n",
      "Test set: Average loss: 1.2383, Accuracy: 3012/5000 (60%)\n",
      "[epoch 15] loss: 0.6528123\n",
      "Test set: Average loss: 1.2388, Accuracy: 3078/5000 (62%)\n",
      "[epoch 16] loss: 0.6122807\n",
      "Test set: Average loss: 1.3014, Accuracy: 2994/5000 (60%)\n",
      "[epoch 17] loss: 0.5527043\n",
      "Test set: Average loss: 1.2661, Accuracy: 3052/5000 (61%)\n",
      "[epoch 18] loss: 0.4950798\n",
      "Test set: Average loss: 1.3505, Accuracy: 3037/5000 (61%)\n",
      "[epoch 19] loss: 0.4336506\n",
      "Test set: Average loss: 1.4352, Accuracy: 3036/5000 (61%)\n",
      "[epoch 20] loss: 0.3763011\n",
      "Test set: Average loss: 1.4337, Accuracy: 3050/5000 (61%)\n",
      "[epoch 21] loss: 0.2908422\n",
      "Test set: Average loss: 1.4955, Accuracy: 3043/5000 (61%)\n",
      "[epoch 22] loss: 0.2314759\n",
      "Test set: Average loss: 1.5587, Accuracy: 3050/5000 (61%)\n",
      "[epoch 23] loss: 0.1966838\n",
      "Test set: Average loss: 1.6143, Accuracy: 3016/5000 (60%)\n",
      "[epoch 24] loss: 0.1428169\n",
      "Test set: Average loss: 1.7123, Accuracy: 2993/5000 (60%)\n",
      "[epoch 25] loss: 0.1158199\n",
      "Test set: Average loss: 1.7257, Accuracy: 3113/5000 (62%)\n",
      "[epoch 26] loss: 0.0669186\n",
      "Test set: Average loss: 1.7967, Accuracy: 3089/5000 (62%)\n",
      "[epoch 27] loss: 0.1441481\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0701, Accuracy: 2847/5000 (57%)\n",
      "[epoch 28] loss: 0.0678756\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7891, Accuracy: 3103/5000 (62%)\n",
      "[epoch 29] loss: 0.0259802\n",
      "Test set: Average loss: 1.7897, Accuracy: 3106/5000 (62%)\n",
      "[epoch 30] loss: 0.0244862\n",
      "Test set: Average loss: 1.7918, Accuracy: 3108/5000 (62%)\n",
      "[epoch 31] loss: 0.0231283\n",
      "Test set: Average loss: 1.7949, Accuracy: 3107/5000 (62%)\n",
      "[epoch 32] loss: 0.0217528\n",
      "Test set: Average loss: 1.7975, Accuracy: 3112/5000 (62%)\n",
      "[epoch 33] loss: 0.0204093\n",
      "Test set: Average loss: 1.8016, Accuracy: 3111/5000 (62%)\n",
      "[epoch 34] loss: 0.0190932\n",
      "Test set: Average loss: 1.8050, Accuracy: 3107/5000 (62%)\n",
      "[epoch 35] loss: 0.0178396\n",
      "Test set: Average loss: 1.8088, Accuracy: 3117/5000 (62%)\n",
      "[epoch 36] loss: 0.0166624\n",
      "Test set: Average loss: 1.8127, Accuracy: 3116/5000 (62%)\n",
      "[epoch 37] loss: 0.0155191\n",
      "Test set: Average loss: 1.8182, Accuracy: 3121/5000 (62%)\n",
      "[epoch 38] loss: 0.0144895\n",
      "Test set: Average loss: 1.8223, Accuracy: 3115/5000 (62%)\n",
      "[epoch 39] loss: 0.0135259\n",
      "Test set: Average loss: 1.8268, Accuracy: 3124/5000 (62%)\n",
      "[epoch 40] loss: 0.0126345\n",
      "Test set: Average loss: 1.8316, Accuracy: 3129/5000 (63%)\n",
      "[epoch 41] loss: 0.0118207\n",
      "Test set: Average loss: 1.8389, Accuracy: 3127/5000 (63%)\n",
      "[epoch 42] loss: 0.0110878\n",
      "Test set: Average loss: 1.8434, Accuracy: 3127/5000 (63%)\n",
      "[epoch 43] loss: 0.0103978\n",
      "Test set: Average loss: 1.8488, Accuracy: 3128/5000 (63%)\n",
      "[epoch 44] loss: 0.0097579\n",
      "Test set: Average loss: 1.8558, Accuracy: 3129/5000 (63%)\n",
      "[epoch 45] loss: 0.0091898\n",
      "Test set: Average loss: 1.8624, Accuracy: 3132/5000 (63%)\n",
      "[epoch 46] loss: 0.0086567\n",
      "Test set: Average loss: 1.8670, Accuracy: 3127/5000 (63%)\n",
      "[epoch 47] loss: 0.0081690\n",
      "Test set: Average loss: 1.8741, Accuracy: 3129/5000 (63%)\n",
      "[epoch 48] loss: 0.0077061\n",
      "Test set: Average loss: 1.8794, Accuracy: 3131/5000 (63%)\n",
      "[epoch 49] loss: 0.0072859\n",
      "Test set: Average loss: 1.8849, Accuracy: 3128/5000 (63%)\n",
      "[epoch 50] loss: 0.0068948\n",
      "Test set: Average loss: 1.8924, Accuracy: 3127/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8624, Accuracy: 3132/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 1.7616, Accuracy: 6360/10000 (64%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3145, Accuracy: 317/5000 (6%)\n",
      "[epoch 1] loss: 1.1969543\n",
      "Test set: Average loss: 1.1568, Accuracy: 3031/5000 (61%)\n",
      "[epoch 2] loss: 1.0868584\n",
      "Test set: Average loss: 1.1840, Accuracy: 2918/5000 (58%)\n",
      "[epoch 3] loss: 1.0266397\n",
      "Test set: Average loss: 1.2478, Accuracy: 2903/5000 (58%)\n",
      "[epoch 4] loss: 0.9975444\n",
      "Test set: Average loss: 1.1206, Accuracy: 3089/5000 (62%)\n",
      "[epoch 5] loss: 0.9737362\n",
      "Test set: Average loss: 1.1121, Accuracy: 3080/5000 (62%)\n",
      "[epoch 6] loss: 0.9471824\n",
      "Test set: Average loss: 1.1313, Accuracy: 3077/5000 (62%)\n",
      "[epoch 7] loss: 0.9193036\n",
      "Test set: Average loss: 1.1137, Accuracy: 3104/5000 (62%)\n",
      "[epoch 8] loss: 0.8906735\n",
      "Test set: Average loss: 1.1767, Accuracy: 3052/5000 (61%)\n",
      "[epoch 9] loss: 0.8520853\n",
      "Test set: Average loss: 1.2059, Accuracy: 3035/5000 (61%)\n",
      "[epoch 10] loss: 0.8291871\n",
      "Test set: Average loss: 1.1421, Accuracy: 3060/5000 (61%)\n",
      "[epoch 11] loss: 0.7830056\n",
      "Test set: Average loss: 1.1894, Accuracy: 3062/5000 (61%)\n",
      "[epoch 12] loss: 0.7405426\n",
      "Test set: Average loss: 1.1769, Accuracy: 3105/5000 (62%)\n",
      "[epoch 13] loss: 0.7027754\n",
      "Test set: Average loss: 1.1577, Accuracy: 3117/5000 (62%)\n",
      "[epoch 14] loss: 0.6460864\n",
      "Test set: Average loss: 1.1763, Accuracy: 3141/5000 (63%)\n",
      "[epoch 15] loss: 0.5865140\n",
      "Test set: Average loss: 1.2329, Accuracy: 3106/5000 (62%)\n",
      "[epoch 16] loss: 0.5170204\n",
      "Test set: Average loss: 1.2208, Accuracy: 3144/5000 (63%)\n",
      "[epoch 17] loss: 0.4464756\n",
      "Test set: Average loss: 1.2473, Accuracy: 3187/5000 (64%)\n",
      "[epoch 18] loss: 0.3691619\n",
      "Test set: Average loss: 1.3355, Accuracy: 3127/5000 (63%)\n",
      "[epoch 19] loss: 0.3088387\n",
      "Test set: Average loss: 1.4014, Accuracy: 3156/5000 (63%)\n",
      "[epoch 20] loss: 0.2404899\n",
      "Test set: Average loss: 1.4540, Accuracy: 3094/5000 (62%)\n",
      "[epoch 21] loss: 0.1898809\n",
      "Test set: Average loss: 1.5640, Accuracy: 3144/5000 (63%)\n",
      "[epoch 22] loss: 0.1271301\n",
      "Test set: Average loss: 1.6447, Accuracy: 3155/5000 (63%)\n",
      "[epoch 23] loss: 0.1282352\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7433, Accuracy: 3106/5000 (62%)\n",
      "[epoch 24] loss: 0.0462638\n",
      "Test set: Average loss: 1.6343, Accuracy: 3218/5000 (64%)\n",
      "[epoch 25] loss: 0.0213565\n",
      "Test set: Average loss: 1.6475, Accuracy: 3224/5000 (64%)\n",
      "[epoch 26] loss: 0.0156514\n",
      "Test set: Average loss: 1.6601, Accuracy: 3217/5000 (64%)\n",
      "[epoch 27] loss: 0.0123315\n",
      "Test set: Average loss: 1.6830, Accuracy: 3225/5000 (64%)\n",
      "[epoch 28] loss: 0.0099411\n",
      "Test set: Average loss: 1.7051, Accuracy: 3246/5000 (65%)\n",
      "[epoch 29] loss: 0.0081095\n",
      "Test set: Average loss: 1.7271, Accuracy: 3238/5000 (65%)\n",
      "[epoch 30] loss: 0.0066202\n",
      "Test set: Average loss: 1.7590, Accuracy: 3254/5000 (65%)\n",
      "[epoch 31] loss: 0.0053898\n",
      "Test set: Average loss: 1.7880, Accuracy: 3238/5000 (65%)\n",
      "[epoch 32] loss: 0.0043675\n",
      "Test set: Average loss: 1.8144, Accuracy: 3246/5000 (65%)\n",
      "[epoch 33] loss: 0.0035074\n",
      "Test set: Average loss: 1.8561, Accuracy: 3246/5000 (65%)\n",
      "[epoch 34] loss: 0.0027973\n",
      "Test set: Average loss: 1.8893, Accuracy: 3251/5000 (65%)\n",
      "[epoch 35] loss: 0.0022190\n",
      "Test set: Average loss: 1.9292, Accuracy: 3259/5000 (65%)\n",
      "[epoch 36] loss: 0.0017493\n",
      "Test set: Average loss: 1.9737, Accuracy: 3258/5000 (65%)\n",
      "[epoch 37] loss: 0.0013674\n",
      "Test set: Average loss: 2.0106, Accuracy: 3264/5000 (65%)\n",
      "[epoch 38] loss: 0.0010623\n",
      "Test set: Average loss: 2.0579, Accuracy: 3266/5000 (65%)\n",
      "[epoch 39] loss: 0.0008227\n",
      "Test set: Average loss: 2.1009, Accuracy: 3272/5000 (65%)\n",
      "[epoch 40] loss: 0.0006343\n",
      "Test set: Average loss: 2.1445, Accuracy: 3269/5000 (65%)\n",
      "[epoch 41] loss: 0.0004865\n",
      "Test set: Average loss: 2.1910, Accuracy: 3264/5000 (65%)\n",
      "[epoch 42] loss: 0.0003732\n",
      "Test set: Average loss: 2.2381, Accuracy: 3276/5000 (66%)\n",
      "[epoch 43] loss: 0.0002826\n",
      "Test set: Average loss: 2.2856, Accuracy: 3262/5000 (65%)\n",
      "[epoch 44] loss: 0.0002153\n",
      "Test set: Average loss: 2.3372, Accuracy: 3272/5000 (65%)\n",
      "[epoch 45] loss: 0.0001629\n",
      "Test set: Average loss: 2.3853, Accuracy: 3265/5000 (65%)\n",
      "[epoch 46] loss: 0.0001235\n",
      "Test set: Average loss: 2.4377, Accuracy: 3271/5000 (65%)\n",
      "[epoch 47] loss: 0.0000932\n",
      "Test set: Average loss: 2.4844, Accuracy: 3280/5000 (66%)\n",
      "[epoch 48] loss: 0.0000698\n",
      "Test set: Average loss: 2.5352, Accuracy: 3281/5000 (66%)\n",
      "[epoch 49] loss: 0.0000527\n",
      "Test set: Average loss: 2.5888, Accuracy: 3269/5000 (65%)\n",
      "[epoch 50] loss: 0.0000394\n",
      "Test set: Average loss: 2.6338, Accuracy: 3276/5000 (66%)\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5352, Accuracy: 3281/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.3830, Accuracy: 6560/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3093, Accuracy: 265/5000 (5%)\n",
      "[epoch 1] loss: 1.1907520\n",
      "Test set: Average loss: 1.2280, Accuracy: 2868/5000 (57%)\n",
      "[epoch 2] loss: 1.0701252\n",
      "Test set: Average loss: 1.2089, Accuracy: 2848/5000 (57%)\n",
      "[epoch 3] loss: 1.0338359\n",
      "Test set: Average loss: 1.1348, Accuracy: 2990/5000 (60%)\n",
      "[epoch 4] loss: 0.9951345\n",
      "Test set: Average loss: 1.1148, Accuracy: 3069/5000 (61%)\n",
      "[epoch 5] loss: 0.9726244\n",
      "Test set: Average loss: 1.1645, Accuracy: 2981/5000 (60%)\n",
      "[epoch 6] loss: 0.9450652\n",
      "Test set: Average loss: 1.1061, Accuracy: 3119/5000 (62%)\n",
      "[epoch 7] loss: 0.9143583\n",
      "Test set: Average loss: 1.1038, Accuracy: 3112/5000 (62%)\n",
      "[epoch 8] loss: 0.8881080\n",
      "Test set: Average loss: 1.1095, Accuracy: 3074/5000 (61%)\n",
      "[epoch 9] loss: 0.8591706\n",
      "Test set: Average loss: 1.1074, Accuracy: 3071/5000 (61%)\n",
      "[epoch 10] loss: 0.8265533\n",
      "Test set: Average loss: 1.1170, Accuracy: 3111/5000 (62%)\n",
      "[epoch 11] loss: 0.7887968\n",
      "Test set: Average loss: 1.1374, Accuracy: 3109/5000 (62%)\n",
      "[epoch 12] loss: 0.7484425\n",
      "Test set: Average loss: 1.1532, Accuracy: 3056/5000 (61%)\n",
      "[epoch 13] loss: 0.7112990\n",
      "Test set: Average loss: 1.1811, Accuracy: 3126/5000 (63%)\n",
      "[epoch 14] loss: 0.6591059\n",
      "Test set: Average loss: 1.2045, Accuracy: 3058/5000 (61%)\n",
      "[epoch 15] loss: 0.6075102\n",
      "Test set: Average loss: 1.2651, Accuracy: 3044/5000 (61%)\n",
      "[epoch 16] loss: 0.5529227\n",
      "Test set: Average loss: 1.2227, Accuracy: 3157/5000 (63%)\n",
      "[epoch 17] loss: 0.4676943\n",
      "Test set: Average loss: 1.2842, Accuracy: 3163/5000 (63%)\n",
      "[epoch 18] loss: 0.3993074\n",
      "Test set: Average loss: 1.2418, Accuracy: 3195/5000 (64%)\n",
      "[epoch 19] loss: 0.3191532\n",
      "Test set: Average loss: 1.3828, Accuracy: 3119/5000 (62%)\n",
      "[epoch 20] loss: 0.2618518\n",
      "Test set: Average loss: 1.5046, Accuracy: 3060/5000 (61%)\n",
      "[epoch 21] loss: 0.1986371\n",
      "Test set: Average loss: 1.6014, Accuracy: 3086/5000 (62%)\n",
      "[epoch 22] loss: 0.1465407\n",
      "Test set: Average loss: 1.5979, Accuracy: 3139/5000 (63%)\n",
      "[epoch 23] loss: 0.1156916\n",
      "Test set: Average loss: 1.7266, Accuracy: 3102/5000 (62%)\n",
      "[epoch 24] loss: 0.1425639\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7082, Accuracy: 3152/5000 (63%)\n",
      "[epoch 25] loss: 0.0433785\n",
      "Test set: Average loss: 1.6512, Accuracy: 3216/5000 (64%)\n",
      "[epoch 26] loss: 0.0202118\n",
      "Test set: Average loss: 1.6620, Accuracy: 3236/5000 (65%)\n",
      "[epoch 27] loss: 0.0145965\n",
      "Test set: Average loss: 1.6788, Accuracy: 3242/5000 (65%)\n",
      "[epoch 28] loss: 0.0113794\n",
      "Test set: Average loss: 1.6961, Accuracy: 3237/5000 (65%)\n",
      "[epoch 29] loss: 0.0090726\n",
      "Test set: Average loss: 1.7148, Accuracy: 3256/5000 (65%)\n",
      "[epoch 30] loss: 0.0073703\n",
      "Test set: Average loss: 1.7409, Accuracy: 3245/5000 (65%)\n",
      "[epoch 31] loss: 0.0059607\n",
      "Test set: Average loss: 1.7609, Accuracy: 3256/5000 (65%)\n",
      "[epoch 32] loss: 0.0048232\n",
      "Test set: Average loss: 1.7947, Accuracy: 3261/5000 (65%)\n",
      "[epoch 33] loss: 0.0038816\n",
      "Test set: Average loss: 1.8230, Accuracy: 3258/5000 (65%)\n",
      "[epoch 34] loss: 0.0031146\n",
      "Test set: Average loss: 1.8523, Accuracy: 3255/5000 (65%)\n",
      "[epoch 35] loss: 0.0024751\n",
      "Test set: Average loss: 1.8856, Accuracy: 3259/5000 (65%)\n",
      "[epoch 36] loss: 0.0019635\n",
      "Test set: Average loss: 1.9263, Accuracy: 3249/5000 (65%)\n",
      "[epoch 37] loss: 0.0015464\n",
      "Test set: Average loss: 1.9582, Accuracy: 3260/5000 (65%)\n",
      "[epoch 38] loss: 0.0012047\n",
      "Test set: Average loss: 1.9955, Accuracy: 3259/5000 (65%)\n",
      "[epoch 39] loss: 0.0009392\n",
      "Test set: Average loss: 2.0356, Accuracy: 3262/5000 (65%)\n",
      "[epoch 40] loss: 0.0007259\n",
      "Test set: Average loss: 2.0762, Accuracy: 3267/5000 (65%)\n",
      "[epoch 41] loss: 0.0005600\n",
      "Test set: Average loss: 2.1198, Accuracy: 3271/5000 (65%)\n",
      "[epoch 42] loss: 0.0004304\n",
      "Test set: Average loss: 2.1621, Accuracy: 3273/5000 (65%)\n",
      "[epoch 43] loss: 0.0003297\n",
      "Test set: Average loss: 2.2100, Accuracy: 3271/5000 (65%)\n",
      "[epoch 44] loss: 0.0002511\n",
      "Test set: Average loss: 2.2569, Accuracy: 3271/5000 (65%)\n",
      "[epoch 45] loss: 0.0001905\n",
      "Test set: Average loss: 2.3090, Accuracy: 3277/5000 (66%)\n",
      "[epoch 46] loss: 0.0001446\n",
      "Test set: Average loss: 2.3492, Accuracy: 3272/5000 (65%)\n",
      "[epoch 47] loss: 0.0001096\n",
      "Test set: Average loss: 2.3943, Accuracy: 3274/5000 (65%)\n",
      "[epoch 48] loss: 0.0000823\n",
      "Test set: Average loss: 2.4472, Accuracy: 3276/5000 (66%)\n",
      "[epoch 49] loss: 0.0000622\n",
      "Test set: Average loss: 2.4996, Accuracy: 3272/5000 (65%)\n",
      "[epoch 50] loss: 0.0000465\n",
      "Test set: Average loss: 2.5419, Accuracy: 3280/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5419, Accuracy: 3280/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.4494, Accuracy: 6634/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3000, Accuracy: 348/5000 (7%)\n",
      "[epoch 1] loss: 1.1919516\n",
      "Test set: Average loss: 1.1939, Accuracy: 2885/5000 (58%)\n",
      "[epoch 2] loss: 1.0831151\n",
      "Test set: Average loss: 1.2386, Accuracy: 2870/5000 (57%)\n",
      "[epoch 3] loss: 1.0384962\n",
      "Test set: Average loss: 1.1359, Accuracy: 3009/5000 (60%)\n",
      "[epoch 4] loss: 1.0052246\n",
      "Test set: Average loss: 1.1754, Accuracy: 2965/5000 (59%)\n",
      "[epoch 5] loss: 0.9751236\n",
      "Test set: Average loss: 1.2209, Accuracy: 2906/5000 (58%)\n",
      "[epoch 6] loss: 0.9482178\n",
      "Test set: Average loss: 1.1460, Accuracy: 3062/5000 (61%)\n",
      "[epoch 7] loss: 0.9183671\n",
      "Test set: Average loss: 1.1235, Accuracy: 3053/5000 (61%)\n",
      "[epoch 8] loss: 0.8956511\n",
      "Test set: Average loss: 1.1304, Accuracy: 3103/5000 (62%)\n",
      "[epoch 9] loss: 0.8580158\n",
      "Test set: Average loss: 1.1261, Accuracy: 3071/5000 (61%)\n",
      "[epoch 10] loss: 0.8321065\n",
      "Test set: Average loss: 1.0996, Accuracy: 3143/5000 (63%)\n",
      "[epoch 11] loss: 0.8026407\n",
      "Test set: Average loss: 1.1754, Accuracy: 3052/5000 (61%)\n",
      "[epoch 12] loss: 0.7564765\n",
      "Test set: Average loss: 1.1585, Accuracy: 3089/5000 (62%)\n",
      "[epoch 13] loss: 0.7099999\n",
      "Test set: Average loss: 1.1458, Accuracy: 3153/5000 (63%)\n",
      "[epoch 14] loss: 0.6552993\n",
      "Test set: Average loss: 1.2340, Accuracy: 3062/5000 (61%)\n",
      "[epoch 15] loss: 0.6194912\n",
      "Test set: Average loss: 1.1904, Accuracy: 3119/5000 (62%)\n",
      "[epoch 16] loss: 0.5491025\n",
      "Test set: Average loss: 1.1986, Accuracy: 3142/5000 (63%)\n",
      "[epoch 17] loss: 0.4943138\n",
      "Test set: Average loss: 1.2276, Accuracy: 3143/5000 (63%)\n",
      "[epoch 18] loss: 0.4136558\n",
      "Test set: Average loss: 1.3297, Accuracy: 3118/5000 (62%)\n",
      "[epoch 19] loss: 0.3421484\n",
      "Test set: Average loss: 1.3889, Accuracy: 3147/5000 (63%)\n",
      "[epoch 20] loss: 0.2802114\n",
      "Test set: Average loss: 1.4111, Accuracy: 3119/5000 (62%)\n",
      "[epoch 21] loss: 0.2173131\n",
      "Test set: Average loss: 1.4810, Accuracy: 3137/5000 (63%)\n",
      "[epoch 22] loss: 0.1631434\n",
      "Test set: Average loss: 1.5743, Accuracy: 3124/5000 (62%)\n",
      "[epoch 23] loss: 0.1474828\n",
      "Test set: Average loss: 1.6330, Accuracy: 3118/5000 (62%)\n",
      "[epoch 24] loss: 0.0864016\n",
      "Test set: Average loss: 1.7492, Accuracy: 3124/5000 (62%)\n",
      "[epoch 25] loss: 0.0891666\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8472, Accuracy: 3075/5000 (62%)\n",
      "[epoch 26] loss: 0.0362876\n",
      "Test set: Average loss: 1.7530, Accuracy: 3189/5000 (64%)\n",
      "[epoch 27] loss: 0.0140216\n",
      "Test set: Average loss: 1.7614, Accuracy: 3193/5000 (64%)\n",
      "[epoch 28] loss: 0.0100554\n",
      "Test set: Average loss: 1.7722, Accuracy: 3201/5000 (64%)\n",
      "[epoch 29] loss: 0.0078541\n",
      "Test set: Average loss: 1.7950, Accuracy: 3221/5000 (64%)\n",
      "[epoch 30] loss: 0.0063162\n",
      "Test set: Average loss: 1.8088, Accuracy: 3220/5000 (64%)\n",
      "[epoch 31] loss: 0.0051533\n",
      "Test set: Average loss: 1.8309, Accuracy: 3220/5000 (64%)\n",
      "[epoch 32] loss: 0.0042131\n",
      "Test set: Average loss: 1.8547, Accuracy: 3211/5000 (64%)\n",
      "[epoch 33] loss: 0.0034458\n",
      "Test set: Average loss: 1.8754, Accuracy: 3213/5000 (64%)\n",
      "[epoch 34] loss: 0.0028053\n",
      "Test set: Average loss: 1.9002, Accuracy: 3224/5000 (64%)\n",
      "[epoch 35] loss: 0.0022665\n",
      "Test set: Average loss: 1.9378, Accuracy: 3223/5000 (64%)\n",
      "[epoch 36] loss: 0.0018163\n",
      "Test set: Average loss: 1.9658, Accuracy: 3223/5000 (64%)\n",
      "[epoch 37] loss: 0.0014486\n",
      "Test set: Average loss: 1.9945, Accuracy: 3226/5000 (65%)\n",
      "[epoch 38] loss: 0.0011448\n",
      "Test set: Average loss: 2.0413, Accuracy: 3232/5000 (65%)\n",
      "[epoch 39] loss: 0.0009006\n",
      "Test set: Average loss: 2.0795, Accuracy: 3237/5000 (65%)\n",
      "[epoch 40] loss: 0.0007030\n",
      "Test set: Average loss: 2.1115, Accuracy: 3238/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] loss: 0.0005456\n",
      "Test set: Average loss: 2.1578, Accuracy: 3237/5000 (65%)\n",
      "[epoch 42] loss: 0.0004215\n",
      "Test set: Average loss: 2.1959, Accuracy: 3243/5000 (65%)\n",
      "[epoch 43] loss: 0.0003251\n",
      "Test set: Average loss: 2.2389, Accuracy: 3228/5000 (65%)\n",
      "[epoch 44] loss: 0.0002488\n",
      "Test set: Average loss: 2.2859, Accuracy: 3232/5000 (65%)\n",
      "[epoch 45] loss: 0.0001898\n",
      "Test set: Average loss: 2.3300, Accuracy: 3247/5000 (65%)\n",
      "[epoch 46] loss: 0.0001436\n",
      "Test set: Average loss: 2.3809, Accuracy: 3240/5000 (65%)\n",
      "[epoch 47] loss: 0.0001096\n",
      "Test set: Average loss: 2.4223, Accuracy: 3240/5000 (65%)\n",
      "[epoch 48] loss: 0.0000830\n",
      "Test set: Average loss: 2.4768, Accuracy: 3238/5000 (65%)\n",
      "[epoch 49] loss: 0.0000626\n",
      "Test set: Average loss: 2.5159, Accuracy: 3244/5000 (65%)\n",
      "[epoch 50] loss: 0.0000470\n",
      "Test set: Average loss: 2.5746, Accuracy: 3248/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5746, Accuracy: 3248/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.4296, Accuracy: 6639/10000 (66%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2980, Accuracy: 442/5000 (9%)\n",
      "[epoch 1] loss: 1.1854038\n",
      "Test set: Average loss: 1.1663, Accuracy: 3013/5000 (60%)\n",
      "[epoch 2] loss: 1.0840855\n",
      "Test set: Average loss: 1.1278, Accuracy: 3037/5000 (61%)\n",
      "[epoch 3] loss: 1.0269029\n",
      "Test set: Average loss: 1.2011, Accuracy: 2908/5000 (58%)\n",
      "[epoch 4] loss: 1.0013311\n",
      "Test set: Average loss: 1.1578, Accuracy: 3008/5000 (60%)\n",
      "[epoch 5] loss: 0.9679098\n",
      "Test set: Average loss: 1.1395, Accuracy: 3049/5000 (61%)\n",
      "[epoch 6] loss: 0.9415007\n",
      "Test set: Average loss: 1.0827, Accuracy: 3138/5000 (63%)\n",
      "[epoch 7] loss: 0.9091575\n",
      "Test set: Average loss: 1.1048, Accuracy: 3120/5000 (62%)\n",
      "[epoch 8] loss: 0.8725901\n",
      "Test set: Average loss: 1.0657, Accuracy: 3156/5000 (63%)\n",
      "[epoch 9] loss: 0.8388975\n",
      "Test set: Average loss: 1.1045, Accuracy: 3112/5000 (62%)\n",
      "[epoch 10] loss: 0.8053782\n",
      "Test set: Average loss: 1.0717, Accuracy: 3206/5000 (64%)\n",
      "[epoch 11] loss: 0.7560822\n",
      "Test set: Average loss: 1.1719, Accuracy: 3113/5000 (62%)\n",
      "[epoch 12] loss: 0.7168066\n",
      "Test set: Average loss: 1.1059, Accuracy: 3175/5000 (64%)\n",
      "[epoch 13] loss: 0.6651032\n",
      "Test set: Average loss: 1.1536, Accuracy: 3179/5000 (64%)\n",
      "[epoch 14] loss: 0.6072141\n",
      "Test set: Average loss: 1.1358, Accuracy: 3241/5000 (65%)\n",
      "[epoch 15] loss: 0.5376044\n",
      "Test set: Average loss: 1.1831, Accuracy: 3231/5000 (65%)\n",
      "[epoch 16] loss: 0.4705682\n",
      "Test set: Average loss: 1.1997, Accuracy: 3208/5000 (64%)\n",
      "[epoch 17] loss: 0.3893849\n",
      "Test set: Average loss: 1.3174, Accuracy: 3175/5000 (64%)\n",
      "[epoch 18] loss: 0.3178038\n",
      "Test set: Average loss: 1.3610, Accuracy: 3198/5000 (64%)\n",
      "[epoch 19] loss: 0.2420277\n",
      "Test set: Average loss: 1.4281, Accuracy: 3207/5000 (64%)\n",
      "[epoch 20] loss: 0.1951212\n",
      "Test set: Average loss: 1.6303, Accuracy: 3107/5000 (62%)\n",
      "[epoch 21] loss: 0.1788657\n",
      "Test set: Average loss: 1.6485, Accuracy: 3138/5000 (63%)\n",
      "[epoch 22] loss: 0.1461020\n",
      "Test set: Average loss: 1.7137, Accuracy: 3169/5000 (63%)\n",
      "[epoch 23] loss: 0.0986262\n",
      "Test set: Average loss: 1.7543, Accuracy: 3215/5000 (64%)\n",
      "[epoch 24] loss: 0.1342579\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9350, Accuracy: 3043/5000 (61%)\n",
      "[epoch 25] loss: 0.0479251\n",
      "Test set: Average loss: 1.7276, Accuracy: 3238/5000 (65%)\n",
      "[epoch 26] loss: 0.0160429\n",
      "Test set: Average loss: 1.7375, Accuracy: 3262/5000 (65%)\n",
      "[epoch 27] loss: 0.0105515\n",
      "Test set: Average loss: 1.7489, Accuracy: 3273/5000 (65%)\n",
      "[epoch 28] loss: 0.0077922\n",
      "Test set: Average loss: 1.7638, Accuracy: 3285/5000 (66%)\n",
      "[epoch 29] loss: 0.0059508\n",
      "Test set: Average loss: 1.7832, Accuracy: 3293/5000 (66%)\n",
      "[epoch 30] loss: 0.0045646\n",
      "Test set: Average loss: 1.8036, Accuracy: 3300/5000 (66%)\n",
      "[epoch 31] loss: 0.0035248\n",
      "Test set: Average loss: 1.8361, Accuracy: 3294/5000 (66%)\n",
      "[epoch 32] loss: 0.0027170\n",
      "Test set: Average loss: 1.8616, Accuracy: 3308/5000 (66%)\n",
      "[epoch 33] loss: 0.0020650\n",
      "Test set: Average loss: 1.8979, Accuracy: 3307/5000 (66%)\n",
      "[epoch 34] loss: 0.0015662\n",
      "Test set: Average loss: 1.9277, Accuracy: 3299/5000 (66%)\n",
      "[epoch 35] loss: 0.0011703\n",
      "Test set: Average loss: 1.9703, Accuracy: 3299/5000 (66%)\n",
      "[epoch 36] loss: 0.0008729\n",
      "Test set: Average loss: 2.0048, Accuracy: 3301/5000 (66%)\n",
      "[epoch 37] loss: 0.0006444\n",
      "Test set: Average loss: 2.0547, Accuracy: 3300/5000 (66%)\n",
      "[epoch 38] loss: 0.0004741\n",
      "Test set: Average loss: 2.0940, Accuracy: 3311/5000 (66%)\n",
      "[epoch 39] loss: 0.0003453\n",
      "Test set: Average loss: 2.1396, Accuracy: 3303/5000 (66%)\n",
      "[epoch 40] loss: 0.0002512\n",
      "Test set: Average loss: 2.1860, Accuracy: 3301/5000 (66%)\n",
      "[epoch 41] loss: 0.0001816\n",
      "Test set: Average loss: 2.2308, Accuracy: 3302/5000 (66%)\n",
      "[epoch 42] loss: 0.0001310\n",
      "Test set: Average loss: 2.2832, Accuracy: 3301/5000 (66%)\n",
      "[epoch 43] loss: 0.0000939\n",
      "Test set: Average loss: 2.3396, Accuracy: 3311/5000 (66%)\n",
      "[epoch 44] loss: 0.0000671\n",
      "Test set: Average loss: 2.3935, Accuracy: 3315/5000 (66%)\n",
      "[epoch 45] loss: 0.0000478\n",
      "Test set: Average loss: 2.4399, Accuracy: 3315/5000 (66%)\n",
      "[epoch 46] loss: 0.0000340\n",
      "Test set: Average loss: 2.4932, Accuracy: 3316/5000 (66%)\n",
      "[epoch 47] loss: 0.0000240\n",
      "Test set: Average loss: 2.5487, Accuracy: 3326/5000 (67%)\n",
      "[epoch 48] loss: 0.0000171\n",
      "Test set: Average loss: 2.6085, Accuracy: 3324/5000 (66%)\n",
      "[epoch 49] loss: 0.0000120\n",
      "Test set: Average loss: 2.6661, Accuracy: 3323/5000 (66%)\n",
      "[epoch 50] loss: 0.0000085\n",
      "Test set: Average loss: 2.7497, Accuracy: 3310/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5487, Accuracy: 3326/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.4393, Accuracy: 6755/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 511/5000 (10%)\n",
      "[epoch 1] loss: 1.1889044\n",
      "Test set: Average loss: 1.1841, Accuracy: 2952/5000 (59%)\n",
      "[epoch 2] loss: 1.0824990\n",
      "Test set: Average loss: 1.1196, Accuracy: 3101/5000 (62%)\n",
      "[epoch 3] loss: 1.0390789\n",
      "Test set: Average loss: 1.1166, Accuracy: 3072/5000 (61%)\n",
      "[epoch 4] loss: 1.0040570\n",
      "Test set: Average loss: 1.1381, Accuracy: 3061/5000 (61%)\n",
      "[epoch 5] loss: 0.9768557\n",
      "Test set: Average loss: 1.1500, Accuracy: 3020/5000 (60%)\n",
      "[epoch 6] loss: 0.9479231\n",
      "Test set: Average loss: 1.0870, Accuracy: 3161/5000 (63%)\n",
      "[epoch 7] loss: 0.9167036\n",
      "Test set: Average loss: 1.0694, Accuracy: 3145/5000 (63%)\n",
      "[epoch 8] loss: 0.8846371\n",
      "Test set: Average loss: 1.0958, Accuracy: 3130/5000 (63%)\n",
      "[epoch 9] loss: 0.8480192\n",
      "Test set: Average loss: 1.0674, Accuracy: 3202/5000 (64%)\n",
      "[epoch 10] loss: 0.8016998\n",
      "Test set: Average loss: 1.1232, Accuracy: 3140/5000 (63%)\n",
      "[epoch 11] loss: 0.7709800\n",
      "Test set: Average loss: 1.1644, Accuracy: 3124/5000 (62%)\n",
      "[epoch 12] loss: 0.7124430\n",
      "Test set: Average loss: 1.0834, Accuracy: 3232/5000 (65%)\n",
      "[epoch 13] loss: 0.6644389\n",
      "Test set: Average loss: 1.1277, Accuracy: 3186/5000 (64%)\n",
      "[epoch 14] loss: 0.6076923\n",
      "Test set: Average loss: 1.1103, Accuracy: 3243/5000 (65%)\n",
      "[epoch 15] loss: 0.5385911\n",
      "Test set: Average loss: 1.1625, Accuracy: 3203/5000 (64%)\n",
      "[epoch 16] loss: 0.4678982\n",
      "Test set: Average loss: 1.1746, Accuracy: 3263/5000 (65%)\n",
      "[epoch 17] loss: 0.3890691\n",
      "Test set: Average loss: 1.2288, Accuracy: 3194/5000 (64%)\n",
      "[epoch 18] loss: 0.2990429\n",
      "Test set: Average loss: 1.3578, Accuracy: 3213/5000 (64%)\n",
      "[epoch 19] loss: 0.2346753\n",
      "Test set: Average loss: 1.3948, Accuracy: 3203/5000 (64%)\n",
      "[epoch 20] loss: 0.1919707\n",
      "Test set: Average loss: 1.5142, Accuracy: 3202/5000 (64%)\n",
      "[epoch 21] loss: 0.1537689\n",
      "Test set: Average loss: 1.6315, Accuracy: 3154/5000 (63%)\n",
      "[epoch 22] loss: 0.1291060\n",
      "Test set: Average loss: 1.7508, Accuracy: 3122/5000 (62%)\n",
      "[epoch 23] loss: 0.1215512\n",
      "Test set: Average loss: 1.8208, Accuracy: 3131/5000 (63%)\n",
      "[epoch 24] loss: 0.1128122\n",
      "Test set: Average loss: 1.8886, Accuracy: 3140/5000 (63%)\n",
      "[epoch 25] loss: 0.0976253\n",
      "Test set: Average loss: 1.9321, Accuracy: 3164/5000 (63%)\n",
      "[epoch 26] loss: 0.1328820\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9310, Accuracy: 3113/5000 (62%)\n",
      "[epoch 27] loss: 0.0409529\n",
      "Test set: Average loss: 1.8378, Accuracy: 3262/5000 (65%)\n",
      "[epoch 28] loss: 0.0121941\n",
      "Test set: Average loss: 1.8549, Accuracy: 3262/5000 (65%)\n",
      "[epoch 29] loss: 0.0079410\n",
      "Test set: Average loss: 1.8673, Accuracy: 3281/5000 (66%)\n",
      "[epoch 30] loss: 0.0058425\n",
      "Test set: Average loss: 1.8848, Accuracy: 3282/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0044336\n",
      "Test set: Average loss: 1.8974, Accuracy: 3286/5000 (66%)\n",
      "[epoch 32] loss: 0.0034019\n",
      "Test set: Average loss: 1.9177, Accuracy: 3297/5000 (66%)\n",
      "[epoch 33] loss: 0.0026180\n",
      "Test set: Average loss: 1.9426, Accuracy: 3305/5000 (66%)\n",
      "[epoch 34] loss: 0.0020067\n",
      "Test set: Average loss: 1.9629, Accuracy: 3315/5000 (66%)\n",
      "[epoch 35] loss: 0.0015283\n",
      "Test set: Average loss: 1.9960, Accuracy: 3318/5000 (66%)\n",
      "[epoch 36] loss: 0.0011645\n",
      "Test set: Average loss: 2.0237, Accuracy: 3331/5000 (67%)\n",
      "[epoch 37] loss: 0.0008728\n",
      "Test set: Average loss: 2.0558, Accuracy: 3330/5000 (67%)\n",
      "[epoch 38] loss: 0.0006496\n",
      "Test set: Average loss: 2.0932, Accuracy: 3329/5000 (67%)\n",
      "[epoch 39] loss: 0.0004828\n",
      "Test set: Average loss: 2.1276, Accuracy: 3336/5000 (67%)\n",
      "[epoch 40] loss: 0.0003532\n",
      "Test set: Average loss: 2.1712, Accuracy: 3342/5000 (67%)\n",
      "[epoch 41] loss: 0.0002579\n",
      "Test set: Average loss: 2.2122, Accuracy: 3342/5000 (67%)\n",
      "[epoch 42] loss: 0.0001865\n",
      "Test set: Average loss: 2.2551, Accuracy: 3352/5000 (67%)\n",
      "[epoch 43] loss: 0.0001346\n",
      "Test set: Average loss: 2.3075, Accuracy: 3339/5000 (67%)\n",
      "[epoch 44] loss: 0.0000969\n",
      "Test set: Average loss: 2.3477, Accuracy: 3332/5000 (67%)\n",
      "[epoch 45] loss: 0.0000692\n",
      "Test set: Average loss: 2.3901, Accuracy: 3343/5000 (67%)\n",
      "[epoch 46] loss: 0.0000494\n",
      "Test set: Average loss: 2.4392, Accuracy: 3339/5000 (67%)\n",
      "[epoch 47] loss: 0.0000351\n",
      "Test set: Average loss: 2.4906, Accuracy: 3336/5000 (67%)\n",
      "[epoch 48] loss: 0.0000248\n",
      "Test set: Average loss: 2.5395, Accuracy: 3332/5000 (67%)\n",
      "[epoch 49] loss: 0.0000176\n",
      "Test set: Average loss: 2.5935, Accuracy: 3336/5000 (67%)\n",
      "[epoch 50] loss: 0.0000124\n",
      "Test set: Average loss: 2.6444, Accuracy: 3335/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2551, Accuracy: 3352/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.1663, Accuracy: 6709/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3079, Accuracy: 603/5000 (12%)\n",
      "[epoch 1] loss: 1.1991831\n",
      "Test set: Average loss: 1.2442, Accuracy: 2877/5000 (58%)\n",
      "[epoch 2] loss: 1.0793525\n",
      "Test set: Average loss: 1.1257, Accuracy: 3033/5000 (61%)\n",
      "[epoch 3] loss: 1.0352601\n",
      "Test set: Average loss: 1.1130, Accuracy: 3059/5000 (61%)\n",
      "[epoch 4] loss: 1.0092078\n",
      "Test set: Average loss: 1.1497, Accuracy: 2990/5000 (60%)\n",
      "[epoch 5] loss: 0.9855754\n",
      "Test set: Average loss: 1.0942, Accuracy: 3087/5000 (62%)\n",
      "[epoch 6] loss: 0.9538833\n",
      "Test set: Average loss: 1.0823, Accuracy: 3112/5000 (62%)\n",
      "[epoch 7] loss: 0.9208590\n",
      "Test set: Average loss: 1.1619, Accuracy: 3007/5000 (60%)\n",
      "[epoch 8] loss: 0.8914455\n",
      "Test set: Average loss: 1.1333, Accuracy: 3052/5000 (61%)\n",
      "[epoch 9] loss: 0.8500061\n",
      "Test set: Average loss: 1.0888, Accuracy: 3109/5000 (62%)\n",
      "[epoch 10] loss: 0.8152957\n",
      "Test set: Average loss: 1.1226, Accuracy: 3131/5000 (63%)\n",
      "[epoch 11] loss: 0.7713678\n",
      "Test set: Average loss: 1.0873, Accuracy: 3183/5000 (64%)\n",
      "[epoch 12] loss: 0.7245095\n",
      "Test set: Average loss: 1.1020, Accuracy: 3203/5000 (64%)\n",
      "[epoch 13] loss: 0.6762301\n",
      "Test set: Average loss: 1.1052, Accuracy: 3174/5000 (63%)\n",
      "[epoch 14] loss: 0.6112966\n",
      "Test set: Average loss: 1.1587, Accuracy: 3179/5000 (64%)\n",
      "[epoch 15] loss: 0.5482295\n",
      "Test set: Average loss: 1.1673, Accuracy: 3201/5000 (64%)\n",
      "[epoch 16] loss: 0.4796550\n",
      "Test set: Average loss: 1.1793, Accuracy: 3242/5000 (65%)\n",
      "[epoch 17] loss: 0.4099033\n",
      "Test set: Average loss: 1.2589, Accuracy: 3171/5000 (63%)\n",
      "[epoch 18] loss: 0.3142143\n",
      "Test set: Average loss: 1.3630, Accuracy: 3196/5000 (64%)\n",
      "[epoch 19] loss: 0.2396235\n",
      "Test set: Average loss: 1.4334, Accuracy: 3211/5000 (64%)\n",
      "[epoch 20] loss: 0.1938396\n",
      "Test set: Average loss: 1.5019, Accuracy: 3195/5000 (64%)\n",
      "[epoch 21] loss: 0.1411976\n",
      "Test set: Average loss: 1.5731, Accuracy: 3227/5000 (65%)\n",
      "[epoch 22] loss: 0.1351733\n",
      "Test set: Average loss: 1.6957, Accuracy: 3176/5000 (64%)\n",
      "[epoch 23] loss: 0.1319485\n",
      "Test set: Average loss: 1.7581, Accuracy: 3162/5000 (63%)\n",
      "[epoch 24] loss: 0.0943627\n",
      "Test set: Average loss: 1.8970, Accuracy: 3110/5000 (62%)\n",
      "[epoch 25] loss: 0.1192756\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9116, Accuracy: 3137/5000 (63%)\n",
      "[epoch 26] loss: 0.0377196\n",
      "Test set: Average loss: 1.7332, Accuracy: 3258/5000 (65%)\n",
      "[epoch 27] loss: 0.0125248\n",
      "Test set: Average loss: 1.7506, Accuracy: 3268/5000 (65%)\n",
      "[epoch 28] loss: 0.0082208\n",
      "Test set: Average loss: 1.7666, Accuracy: 3276/5000 (66%)\n",
      "[epoch 29] loss: 0.0060510\n",
      "Test set: Average loss: 1.7897, Accuracy: 3275/5000 (66%)\n",
      "[epoch 30] loss: 0.0045902\n",
      "Test set: Average loss: 1.8109, Accuracy: 3290/5000 (66%)\n",
      "[epoch 31] loss: 0.0035446\n",
      "Test set: Average loss: 1.8356, Accuracy: 3289/5000 (66%)\n",
      "[epoch 32] loss: 0.0027308\n",
      "Test set: Average loss: 1.8599, Accuracy: 3301/5000 (66%)\n",
      "[epoch 33] loss: 0.0021066\n",
      "Test set: Average loss: 1.8908, Accuracy: 3282/5000 (66%)\n",
      "[epoch 34] loss: 0.0016051\n",
      "Test set: Average loss: 1.9240, Accuracy: 3288/5000 (66%)\n",
      "[epoch 35] loss: 0.0012127\n",
      "Test set: Average loss: 1.9643, Accuracy: 3282/5000 (66%)\n",
      "[epoch 36] loss: 0.0009130\n",
      "Test set: Average loss: 1.9972, Accuracy: 3284/5000 (66%)\n",
      "[epoch 37] loss: 0.0006820\n",
      "Test set: Average loss: 2.0408, Accuracy: 3285/5000 (66%)\n",
      "[epoch 38] loss: 0.0005031\n",
      "Test set: Average loss: 2.0787, Accuracy: 3297/5000 (66%)\n",
      "[epoch 39] loss: 0.0003707\n",
      "Test set: Average loss: 2.1217, Accuracy: 3291/5000 (66%)\n",
      "[epoch 40] loss: 0.0002701\n",
      "Test set: Average loss: 2.1722, Accuracy: 3297/5000 (66%)\n",
      "[epoch 41] loss: 0.0001958\n",
      "Test set: Average loss: 2.2157, Accuracy: 3287/5000 (66%)\n",
      "[epoch 42] loss: 0.0001415\n",
      "Test set: Average loss: 2.2652, Accuracy: 3291/5000 (66%)\n",
      "[epoch 43] loss: 0.0001019\n",
      "Test set: Average loss: 2.3224, Accuracy: 3293/5000 (66%)\n",
      "[epoch 44] loss: 0.0000729\n",
      "Test set: Average loss: 2.3730, Accuracy: 3302/5000 (66%)\n",
      "[epoch 45] loss: 0.0000520\n",
      "Test set: Average loss: 2.4190, Accuracy: 3300/5000 (66%)\n",
      "[epoch 46] loss: 0.0000369\n",
      "Test set: Average loss: 2.4741, Accuracy: 3303/5000 (66%)\n",
      "[epoch 47] loss: 0.0000262\n",
      "Test set: Average loss: 2.5372, Accuracy: 3298/5000 (66%)\n",
      "[epoch 48] loss: 0.0000186\n",
      "Test set: Average loss: 2.5802, Accuracy: 3300/5000 (66%)\n",
      "[epoch 49] loss: 0.0000131\n",
      "Test set: Average loss: 2.6406, Accuracy: 3297/5000 (66%)\n",
      "[epoch 50] loss: 0.0000092\n",
      "Test set: Average loss: 2.6935, Accuracy: 3296/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4741, Accuracy: 3303/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.3551, Accuracy: 6721/10000 (67%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 707/5000 (14%)\n",
      "[epoch 1] loss: 1.1844509\n",
      "Test set: Average loss: 1.1601, Accuracy: 2969/5000 (59%)\n",
      "[epoch 2] loss: 1.0722137\n",
      "Test set: Average loss: 1.1493, Accuracy: 3012/5000 (60%)\n",
      "[epoch 3] loss: 1.0295143\n",
      "Test set: Average loss: 1.1047, Accuracy: 3082/5000 (62%)\n",
      "[epoch 4] loss: 0.9983702\n",
      "Test set: Average loss: 1.1211, Accuracy: 3078/5000 (62%)\n",
      "[epoch 5] loss: 0.9641747\n",
      "Test set: Average loss: 1.0845, Accuracy: 3123/5000 (62%)\n",
      "[epoch 6] loss: 0.9303457\n",
      "Test set: Average loss: 1.0490, Accuracy: 3188/5000 (64%)\n",
      "[epoch 7] loss: 0.9007770\n",
      "Test set: Average loss: 1.0842, Accuracy: 3201/5000 (64%)\n",
      "[epoch 8] loss: 0.8677566\n",
      "Test set: Average loss: 1.0708, Accuracy: 3205/5000 (64%)\n",
      "[epoch 9] loss: 0.8289006\n",
      "Test set: Average loss: 1.0505, Accuracy: 3246/5000 (65%)\n",
      "[epoch 10] loss: 0.7913088\n",
      "Test set: Average loss: 1.0694, Accuracy: 3247/5000 (65%)\n",
      "[epoch 11] loss: 0.7382671\n",
      "Test set: Average loss: 1.0395, Accuracy: 3264/5000 (65%)\n",
      "[epoch 12] loss: 0.6915783\n",
      "Test set: Average loss: 1.0391, Accuracy: 3276/5000 (66%)\n",
      "[epoch 13] loss: 0.6342039\n",
      "Test set: Average loss: 1.1178, Accuracy: 3225/5000 (64%)\n",
      "[epoch 14] loss: 0.5700333\n",
      "Test set: Average loss: 1.1997, Accuracy: 3193/5000 (64%)\n",
      "[epoch 15] loss: 0.4890884\n",
      "Test set: Average loss: 1.2260, Accuracy: 3230/5000 (65%)\n",
      "[epoch 16] loss: 0.4163280\n",
      "Test set: Average loss: 1.1807, Accuracy: 3300/5000 (66%)\n",
      "[epoch 17] loss: 0.3319488\n",
      "Test set: Average loss: 1.2820, Accuracy: 3269/5000 (65%)\n",
      "[epoch 18] loss: 0.2725363\n",
      "Test set: Average loss: 1.3177, Accuracy: 3274/5000 (65%)\n",
      "[epoch 19] loss: 0.2008279\n",
      "Test set: Average loss: 1.4101, Accuracy: 3279/5000 (66%)\n",
      "[epoch 20] loss: 0.1705653\n",
      "Test set: Average loss: 1.5831, Accuracy: 3227/5000 (65%)\n",
      "[epoch 21] loss: 0.1601903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6428, Accuracy: 3234/5000 (65%)\n",
      "[epoch 22] loss: 0.1353704\n",
      "Test set: Average loss: 1.6881, Accuracy: 3266/5000 (65%)\n",
      "[epoch 23] loss: 0.1351358\n",
      "Test set: Average loss: 1.8397, Accuracy: 3135/5000 (63%)\n",
      "[epoch 24] loss: 0.1341805\n",
      "Test set: Average loss: 1.8594, Accuracy: 3169/5000 (63%)\n",
      "[epoch 25] loss: 0.1142721\n",
      "Test set: Average loss: 1.8171, Accuracy: 3247/5000 (65%)\n",
      "[epoch 26] loss: 0.0938150\n",
      "Test set: Average loss: 1.8891, Accuracy: 3226/5000 (65%)\n",
      "[epoch 27] loss: 0.1334842\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0290, Accuracy: 3137/5000 (63%)\n",
      "[epoch 28] loss: 0.0496456\n",
      "Test set: Average loss: 1.8335, Accuracy: 3287/5000 (66%)\n",
      "[epoch 29] loss: 0.0128706\n",
      "Test set: Average loss: 1.8363, Accuracy: 3306/5000 (66%)\n",
      "[epoch 30] loss: 0.0074311\n",
      "Test set: Average loss: 1.8543, Accuracy: 3303/5000 (66%)\n",
      "[epoch 31] loss: 0.0051420\n",
      "Test set: Average loss: 1.8679, Accuracy: 3296/5000 (66%)\n",
      "[epoch 32] loss: 0.0037059\n",
      "Test set: Average loss: 1.8890, Accuracy: 3308/5000 (66%)\n",
      "[epoch 33] loss: 0.0027104\n",
      "Test set: Average loss: 1.9130, Accuracy: 3314/5000 (66%)\n",
      "[epoch 34] loss: 0.0019805\n",
      "Test set: Average loss: 1.9411, Accuracy: 3314/5000 (66%)\n",
      "[epoch 35] loss: 0.0014334\n",
      "Test set: Average loss: 1.9710, Accuracy: 3309/5000 (66%)\n",
      "[epoch 36] loss: 0.0010279\n",
      "Test set: Average loss: 2.0034, Accuracy: 3327/5000 (67%)\n",
      "[epoch 37] loss: 0.0007275\n",
      "Test set: Average loss: 2.0338, Accuracy: 3338/5000 (67%)\n",
      "[epoch 38] loss: 0.0005134\n",
      "Test set: Average loss: 2.0785, Accuracy: 3349/5000 (67%)\n",
      "[epoch 39] loss: 0.0003572\n",
      "Test set: Average loss: 2.1184, Accuracy: 3347/5000 (67%)\n",
      "[epoch 40] loss: 0.0002463\n",
      "Test set: Average loss: 2.1691, Accuracy: 3350/5000 (67%)\n",
      "[epoch 41] loss: 0.0001692\n",
      "Test set: Average loss: 2.2134, Accuracy: 3337/5000 (67%)\n",
      "[epoch 42] loss: 0.0001156\n",
      "Test set: Average loss: 2.2662, Accuracy: 3343/5000 (67%)\n",
      "[epoch 43] loss: 0.0000782\n",
      "Test set: Average loss: 2.3183, Accuracy: 3339/5000 (67%)\n",
      "[epoch 44] loss: 0.0000527\n",
      "Test set: Average loss: 2.3708, Accuracy: 3339/5000 (67%)\n",
      "[epoch 45] loss: 0.0000354\n",
      "Test set: Average loss: 2.4186, Accuracy: 3340/5000 (67%)\n",
      "[epoch 46] loss: 0.0000238\n",
      "Test set: Average loss: 2.4791, Accuracy: 3352/5000 (67%)\n",
      "[epoch 47] loss: 0.0000159\n",
      "Test set: Average loss: 2.5391, Accuracy: 3344/5000 (67%)\n",
      "[epoch 48] loss: 0.0000106\n",
      "Test set: Average loss: 2.6004, Accuracy: 3341/5000 (67%)\n",
      "[epoch 49] loss: 0.0000070\n",
      "Test set: Average loss: 2.6541, Accuracy: 3333/5000 (67%)\n",
      "[epoch 50] loss: 0.0000046\n",
      "Test set: Average loss: 2.7132, Accuracy: 3341/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4791, Accuracy: 3352/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.4432, Accuracy: 6796/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3052, Accuracy: 278/5000 (6%)\n",
      "[epoch 1] loss: 1.1779996\n",
      "Test set: Average loss: 1.1772, Accuracy: 2934/5000 (59%)\n",
      "[epoch 2] loss: 1.0702979\n",
      "Test set: Average loss: 1.1747, Accuracy: 2958/5000 (59%)\n",
      "[epoch 3] loss: 1.0307009\n",
      "Test set: Average loss: 1.1989, Accuracy: 2950/5000 (59%)\n",
      "[epoch 4] loss: 1.0085011\n",
      "Test set: Average loss: 1.1406, Accuracy: 3039/5000 (61%)\n",
      "[epoch 5] loss: 0.9758006\n",
      "Test set: Average loss: 1.0670, Accuracy: 3148/5000 (63%)\n",
      "[epoch 6] loss: 0.9385407\n",
      "Test set: Average loss: 1.0328, Accuracy: 3231/5000 (65%)\n",
      "[epoch 7] loss: 0.8989568\n",
      "Test set: Average loss: 1.0776, Accuracy: 3171/5000 (63%)\n",
      "[epoch 8] loss: 0.8624545\n",
      "Test set: Average loss: 1.0828, Accuracy: 3147/5000 (63%)\n",
      "[epoch 9] loss: 0.8240042\n",
      "Test set: Average loss: 1.0609, Accuracy: 3168/5000 (63%)\n",
      "[epoch 10] loss: 0.7868868\n",
      "Test set: Average loss: 1.0814, Accuracy: 3199/5000 (64%)\n",
      "[epoch 11] loss: 0.7374045\n",
      "Test set: Average loss: 1.0916, Accuracy: 3194/5000 (64%)\n",
      "[epoch 12] loss: 0.6843256\n",
      "Test set: Average loss: 1.1238, Accuracy: 3182/5000 (64%)\n",
      "[epoch 13] loss: 0.6229651\n",
      "Test set: Average loss: 1.1037, Accuracy: 3215/5000 (64%)\n",
      "[epoch 14] loss: 0.5578550\n",
      "Test set: Average loss: 1.1126, Accuracy: 3222/5000 (64%)\n",
      "[epoch 15] loss: 0.4820590\n",
      "Test set: Average loss: 1.1686, Accuracy: 3247/5000 (65%)\n",
      "[epoch 16] loss: 0.3930786\n",
      "Test set: Average loss: 1.2237, Accuracy: 3248/5000 (65%)\n",
      "[epoch 17] loss: 0.3224074\n",
      "Test set: Average loss: 1.2913, Accuracy: 3247/5000 (65%)\n",
      "[epoch 18] loss: 0.2440730\n",
      "Test set: Average loss: 1.4126, Accuracy: 3214/5000 (64%)\n",
      "[epoch 19] loss: 0.1947924\n",
      "Test set: Average loss: 1.5235, Accuracy: 3176/5000 (64%)\n",
      "[epoch 20] loss: 0.1582767\n",
      "Test set: Average loss: 1.5249, Accuracy: 3233/5000 (65%)\n",
      "[epoch 21] loss: 0.1596667\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7206, Accuracy: 3179/5000 (64%)\n",
      "[epoch 22] loss: 0.0668887\n",
      "Test set: Average loss: 1.5631, Accuracy: 3279/5000 (66%)\n",
      "[epoch 23] loss: 0.0253472\n",
      "Test set: Average loss: 1.5713, Accuracy: 3282/5000 (66%)\n",
      "[epoch 24] loss: 0.0162013\n",
      "Test set: Average loss: 1.5969, Accuracy: 3292/5000 (66%)\n",
      "[epoch 25] loss: 0.0115585\n",
      "Test set: Average loss: 1.6165, Accuracy: 3285/5000 (66%)\n",
      "[epoch 26] loss: 0.0084321\n",
      "Test set: Average loss: 1.6467, Accuracy: 3304/5000 (66%)\n",
      "[epoch 27] loss: 0.0061969\n",
      "Test set: Average loss: 1.6723, Accuracy: 3299/5000 (66%)\n",
      "[epoch 28] loss: 0.0045225\n",
      "Test set: Average loss: 1.7145, Accuracy: 3308/5000 (66%)\n",
      "[epoch 29] loss: 0.0032996\n",
      "Test set: Average loss: 1.7507, Accuracy: 3309/5000 (66%)\n",
      "[epoch 30] loss: 0.0023786\n",
      "Test set: Average loss: 1.7938, Accuracy: 3319/5000 (66%)\n",
      "[epoch 31] loss: 0.0016855\n",
      "Test set: Average loss: 1.8421, Accuracy: 3311/5000 (66%)\n",
      "[epoch 32] loss: 0.0011961\n",
      "Test set: Average loss: 1.8947, Accuracy: 3331/5000 (67%)\n",
      "[epoch 33] loss: 0.0008410\n",
      "Test set: Average loss: 1.9406, Accuracy: 3333/5000 (67%)\n",
      "[epoch 34] loss: 0.0005904\n",
      "Test set: Average loss: 1.9956, Accuracy: 3333/5000 (67%)\n",
      "[epoch 35] loss: 0.0004093\n",
      "Test set: Average loss: 2.0510, Accuracy: 3330/5000 (67%)\n",
      "[epoch 36] loss: 0.0002827\n",
      "Test set: Average loss: 2.1073, Accuracy: 3334/5000 (67%)\n",
      "[epoch 37] loss: 0.0001941\n",
      "Test set: Average loss: 2.1659, Accuracy: 3330/5000 (67%)\n",
      "[epoch 38] loss: 0.0001329\n",
      "Test set: Average loss: 2.2256, Accuracy: 3327/5000 (67%)\n",
      "[epoch 39] loss: 0.0000905\n",
      "Test set: Average loss: 2.2942, Accuracy: 3343/5000 (67%)\n",
      "[epoch 40] loss: 0.0000617\n",
      "Test set: Average loss: 2.3530, Accuracy: 3331/5000 (67%)\n",
      "[epoch 41] loss: 0.0000417\n",
      "Test set: Average loss: 2.4114, Accuracy: 3339/5000 (67%)\n",
      "[epoch 42] loss: 0.0000281\n",
      "Test set: Average loss: 2.4781, Accuracy: 3331/5000 (67%)\n",
      "[epoch 43] loss: 0.0000188\n",
      "Test set: Average loss: 2.5423, Accuracy: 3341/5000 (67%)\n",
      "[epoch 44] loss: 0.0000126\n",
      "Test set: Average loss: 2.6123, Accuracy: 3337/5000 (67%)\n",
      "[epoch 45] loss: 0.0000084\n",
      "Test set: Average loss: 2.6679, Accuracy: 3337/5000 (67%)\n",
      "[epoch 46] loss: 0.0000056\n",
      "Test set: Average loss: 2.7376, Accuracy: 3338/5000 (67%)\n",
      "[epoch 47] loss: 0.0000037\n",
      "Test set: Average loss: 2.7945, Accuracy: 3337/5000 (67%)\n",
      "[epoch 48] loss: 0.0000025\n",
      "Test set: Average loss: 2.8588, Accuracy: 3332/5000 (67%)\n",
      "[epoch 49] loss: 0.0000016\n",
      "Test set: Average loss: 2.9193, Accuracy: 3330/5000 (67%)\n",
      "[epoch 50] loss: 0.0000011\n",
      "Test set: Average loss: 2.9654, Accuracy: 3341/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2942, Accuracy: 3343/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.1782, Accuracy: 6822/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3115, Accuracy: 238/5000 (5%)\n",
      "[epoch 1] loss: 1.1807154\n",
      "Test set: Average loss: 1.1642, Accuracy: 2943/5000 (59%)\n",
      "[epoch 2] loss: 1.0846834\n",
      "Test set: Average loss: 1.1428, Accuracy: 3045/5000 (61%)\n",
      "[epoch 3] loss: 1.0371654\n",
      "Test set: Average loss: 1.1616, Accuracy: 2996/5000 (60%)\n",
      "[epoch 4] loss: 1.0028995\n",
      "Test set: Average loss: 1.1131, Accuracy: 3074/5000 (61%)\n",
      "[epoch 5] loss: 0.9699502\n",
      "Test set: Average loss: 1.1181, Accuracy: 3003/5000 (60%)\n",
      "[epoch 6] loss: 0.9392964\n",
      "Test set: Average loss: 1.0803, Accuracy: 3120/5000 (62%)\n",
      "[epoch 7] loss: 0.9099813\n",
      "Test set: Average loss: 1.0675, Accuracy: 3185/5000 (64%)\n",
      "[epoch 8] loss: 0.8749836\n",
      "Test set: Average loss: 1.0973, Accuracy: 3135/5000 (63%)\n",
      "[epoch 9] loss: 0.8378801\n",
      "Test set: Average loss: 1.0649, Accuracy: 3199/5000 (64%)\n",
      "[epoch 10] loss: 0.7930709\n",
      "Test set: Average loss: 1.0741, Accuracy: 3206/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] loss: 0.7469133\n",
      "Test set: Average loss: 1.0543, Accuracy: 3269/5000 (65%)\n",
      "[epoch 12] loss: 0.6929779\n",
      "Test set: Average loss: 1.1413, Accuracy: 3149/5000 (63%)\n",
      "[epoch 13] loss: 0.6395784\n",
      "Test set: Average loss: 1.1983, Accuracy: 3176/5000 (64%)\n",
      "[epoch 14] loss: 0.5733712\n",
      "Test set: Average loss: 1.1282, Accuracy: 3229/5000 (65%)\n",
      "[epoch 15] loss: 0.4979061\n",
      "Test set: Average loss: 1.1551, Accuracy: 3261/5000 (65%)\n",
      "[epoch 16] loss: 0.4197518\n",
      "Test set: Average loss: 1.1633, Accuracy: 3269/5000 (65%)\n",
      "[epoch 17] loss: 0.3410590\n",
      "Test set: Average loss: 1.3429, Accuracy: 3206/5000 (64%)\n",
      "[epoch 18] loss: 0.2724401\n",
      "Test set: Average loss: 1.3708, Accuracy: 3250/5000 (65%)\n",
      "[epoch 19] loss: 0.2059767\n",
      "Test set: Average loss: 1.4845, Accuracy: 3249/5000 (65%)\n",
      "[epoch 20] loss: 0.1659108\n",
      "Test set: Average loss: 1.5206, Accuracy: 3249/5000 (65%)\n",
      "[epoch 21] loss: 0.1602145\n",
      "Test set: Average loss: 1.5761, Accuracy: 3229/5000 (65%)\n",
      "[epoch 22] loss: 0.1350338\n",
      "Test set: Average loss: 1.7288, Accuracy: 3233/5000 (65%)\n",
      "[epoch 23] loss: 0.1374176\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7583, Accuracy: 3219/5000 (64%)\n",
      "[epoch 24] loss: 0.0518184\n",
      "Test set: Average loss: 1.6441, Accuracy: 3285/5000 (66%)\n",
      "[epoch 25] loss: 0.0170499\n",
      "Test set: Average loss: 1.6565, Accuracy: 3307/5000 (66%)\n",
      "[epoch 26] loss: 0.0107329\n",
      "Test set: Average loss: 1.6774, Accuracy: 3313/5000 (66%)\n",
      "[epoch 27] loss: 0.0075867\n",
      "Test set: Average loss: 1.6939, Accuracy: 3320/5000 (66%)\n",
      "[epoch 28] loss: 0.0055415\n",
      "Test set: Average loss: 1.7197, Accuracy: 3310/5000 (66%)\n",
      "[epoch 29] loss: 0.0040741\n",
      "Test set: Average loss: 1.7539, Accuracy: 3329/5000 (67%)\n",
      "[epoch 30] loss: 0.0030008\n",
      "Test set: Average loss: 1.7772, Accuracy: 3320/5000 (66%)\n",
      "[epoch 31] loss: 0.0021700\n",
      "Test set: Average loss: 1.8199, Accuracy: 3329/5000 (67%)\n",
      "[epoch 32] loss: 0.0015579\n",
      "Test set: Average loss: 1.8595, Accuracy: 3314/5000 (66%)\n",
      "[epoch 33] loss: 0.0011091\n",
      "Test set: Average loss: 1.9079, Accuracy: 3333/5000 (67%)\n",
      "[epoch 34] loss: 0.0007854\n",
      "Test set: Average loss: 1.9517, Accuracy: 3330/5000 (67%)\n",
      "[epoch 35] loss: 0.0005455\n",
      "Test set: Average loss: 1.9990, Accuracy: 3330/5000 (67%)\n",
      "[epoch 36] loss: 0.0003774\n",
      "Test set: Average loss: 2.0530, Accuracy: 3350/5000 (67%)\n",
      "[epoch 37] loss: 0.0002603\n",
      "Test set: Average loss: 2.1074, Accuracy: 3339/5000 (67%)\n",
      "[epoch 38] loss: 0.0001789\n",
      "Test set: Average loss: 2.1576, Accuracy: 3346/5000 (67%)\n",
      "[epoch 39] loss: 0.0001219\n",
      "Test set: Average loss: 2.2170, Accuracy: 3346/5000 (67%)\n",
      "[epoch 40] loss: 0.0000826\n",
      "Test set: Average loss: 2.2713, Accuracy: 3353/5000 (67%)\n",
      "[epoch 41] loss: 0.0000558\n",
      "Test set: Average loss: 2.3265, Accuracy: 3345/5000 (67%)\n",
      "[epoch 42] loss: 0.0000374\n",
      "Test set: Average loss: 2.3923, Accuracy: 3356/5000 (67%)\n",
      "[epoch 43] loss: 0.0000251\n",
      "Test set: Average loss: 2.4455, Accuracy: 3363/5000 (67%)\n",
      "[epoch 44] loss: 0.0000168\n",
      "Test set: Average loss: 2.5122, Accuracy: 3356/5000 (67%)\n",
      "[epoch 45] loss: 0.0000112\n",
      "Test set: Average loss: 2.5754, Accuracy: 3353/5000 (67%)\n",
      "[epoch 46] loss: 0.0000074\n",
      "Test set: Average loss: 2.6306, Accuracy: 3354/5000 (67%)\n",
      "[epoch 47] loss: 0.0000049\n",
      "Test set: Average loss: 2.6877, Accuracy: 3351/5000 (67%)\n",
      "[epoch 48] loss: 0.0000033\n",
      "Test set: Average loss: 2.7467, Accuracy: 3378/5000 (68%)\n",
      "[epoch 49] loss: 0.0000021\n",
      "Test set: Average loss: 2.8133, Accuracy: 3338/5000 (67%)\n",
      "[epoch 50] loss: 0.0000014\n",
      "Test set: Average loss: 2.8597, Accuracy: 3363/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7467, Accuracy: 3378/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6264, Accuracy: 6882/10000 (69%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3098, Accuracy: 280/5000 (6%)\n",
      "[epoch 1] loss: 1.1641993\n",
      "Test set: Average loss: 1.1546, Accuracy: 2986/5000 (60%)\n",
      "[epoch 2] loss: 1.0692351\n",
      "Test set: Average loss: 1.1108, Accuracy: 3041/5000 (61%)\n",
      "[epoch 3] loss: 1.0293164\n",
      "Test set: Average loss: 1.1805, Accuracy: 2936/5000 (59%)\n",
      "[epoch 4] loss: 0.9908859\n",
      "Test set: Average loss: 1.1497, Accuracy: 3004/5000 (60%)\n",
      "[epoch 5] loss: 0.9568246\n",
      "Test set: Average loss: 1.0937, Accuracy: 3123/5000 (62%)\n",
      "[epoch 6] loss: 0.9296822\n",
      "Test set: Average loss: 1.0678, Accuracy: 3134/5000 (63%)\n",
      "[epoch 7] loss: 0.8941991\n",
      "Test set: Average loss: 1.0654, Accuracy: 3148/5000 (63%)\n",
      "[epoch 8] loss: 0.8543634\n",
      "Test set: Average loss: 1.0315, Accuracy: 3182/5000 (64%)\n",
      "[epoch 9] loss: 0.8033494\n",
      "Test set: Average loss: 1.0531, Accuracy: 3213/5000 (64%)\n",
      "[epoch 10] loss: 0.7672279\n",
      "Test set: Average loss: 1.0232, Accuracy: 3261/5000 (65%)\n",
      "[epoch 11] loss: 0.7128557\n",
      "Test set: Average loss: 1.0279, Accuracy: 3329/5000 (67%)\n",
      "[epoch 12] loss: 0.6604132\n",
      "Test set: Average loss: 1.0301, Accuracy: 3315/5000 (66%)\n",
      "[epoch 13] loss: 0.5949813\n",
      "Test set: Average loss: 1.0704, Accuracy: 3329/5000 (67%)\n",
      "[epoch 14] loss: 0.5217411\n",
      "Test set: Average loss: 1.1016, Accuracy: 3338/5000 (67%)\n",
      "[epoch 15] loss: 0.4525659\n",
      "Test set: Average loss: 1.1940, Accuracy: 3276/5000 (66%)\n",
      "[epoch 16] loss: 0.3720788\n",
      "Test set: Average loss: 1.2005, Accuracy: 3297/5000 (66%)\n",
      "[epoch 17] loss: 0.3067220\n",
      "Test set: Average loss: 1.2627, Accuracy: 3311/5000 (66%)\n",
      "[epoch 18] loss: 0.2457248\n",
      "Test set: Average loss: 1.3886, Accuracy: 3306/5000 (66%)\n",
      "[epoch 19] loss: 0.2094739\n",
      "Test set: Average loss: 1.4550, Accuracy: 3251/5000 (65%)\n",
      "[epoch 20] loss: 0.1739693\n",
      "Test set: Average loss: 1.5519, Accuracy: 3226/5000 (65%)\n",
      "[epoch 21] loss: 0.1623781\n",
      "Test set: Average loss: 1.5857, Accuracy: 3307/5000 (66%)\n",
      "[epoch 22] loss: 0.1450674\n",
      "Test set: Average loss: 1.6927, Accuracy: 3236/5000 (65%)\n",
      "[epoch 23] loss: 0.1469902\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7068, Accuracy: 3273/5000 (65%)\n",
      "[epoch 24] loss: 0.0498108\n",
      "Test set: Average loss: 1.6399, Accuracy: 3313/5000 (66%)\n",
      "[epoch 25] loss: 0.0164910\n",
      "Test set: Average loss: 1.6527, Accuracy: 3319/5000 (66%)\n",
      "[epoch 26] loss: 0.0100631\n",
      "Test set: Average loss: 1.6634, Accuracy: 3337/5000 (67%)\n",
      "[epoch 27] loss: 0.0068587\n",
      "Test set: Average loss: 1.6823, Accuracy: 3362/5000 (67%)\n",
      "[epoch 28] loss: 0.0048339\n",
      "Test set: Average loss: 1.7185, Accuracy: 3347/5000 (67%)\n",
      "[epoch 29] loss: 0.0033825\n",
      "Test set: Average loss: 1.7498, Accuracy: 3359/5000 (67%)\n",
      "[epoch 30] loss: 0.0023485\n",
      "Test set: Average loss: 1.7787, Accuracy: 3364/5000 (67%)\n",
      "[epoch 31] loss: 0.0016133\n",
      "Test set: Average loss: 1.8224, Accuracy: 3368/5000 (67%)\n",
      "[epoch 32] loss: 0.0010898\n",
      "Test set: Average loss: 1.8759, Accuracy: 3360/5000 (67%)\n",
      "[epoch 33] loss: 0.0007340\n",
      "Test set: Average loss: 1.9348, Accuracy: 3372/5000 (67%)\n",
      "[epoch 34] loss: 0.0004889\n",
      "Test set: Average loss: 1.9828, Accuracy: 3365/5000 (67%)\n",
      "[epoch 35] loss: 0.0003221\n",
      "Test set: Average loss: 2.0436, Accuracy: 3362/5000 (67%)\n",
      "[epoch 36] loss: 0.0002104\n",
      "Test set: Average loss: 2.1089, Accuracy: 3362/5000 (67%)\n",
      "[epoch 37] loss: 0.0001366\n",
      "Test set: Average loss: 2.1619, Accuracy: 3379/5000 (68%)\n",
      "[epoch 38] loss: 0.0000876\n",
      "Test set: Average loss: 2.2350, Accuracy: 3373/5000 (67%)\n",
      "[epoch 39] loss: 0.0000566\n",
      "Test set: Average loss: 2.2945, Accuracy: 3372/5000 (67%)\n",
      "[epoch 40] loss: 0.0000362\n",
      "Test set: Average loss: 2.3609, Accuracy: 3377/5000 (68%)\n",
      "[epoch 41] loss: 0.0000230\n",
      "Test set: Average loss: 2.4226, Accuracy: 3386/5000 (68%)\n",
      "[epoch 42] loss: 0.0000146\n",
      "Test set: Average loss: 2.4919, Accuracy: 3385/5000 (68%)\n",
      "[epoch 43] loss: 0.0000092\n",
      "Test set: Average loss: 2.5650, Accuracy: 3385/5000 (68%)\n",
      "[epoch 44] loss: 0.0000058\n",
      "Test set: Average loss: 2.6303, Accuracy: 3378/5000 (68%)\n",
      "[epoch 45] loss: 0.0000036\n",
      "Test set: Average loss: 2.7058, Accuracy: 3393/5000 (68%)\n",
      "[epoch 46] loss: 0.0000023\n",
      "Test set: Average loss: 2.7762, Accuracy: 3389/5000 (68%)\n",
      "[epoch 47] loss: 0.0000014\n",
      "Test set: Average loss: 2.8346, Accuracy: 3384/5000 (68%)\n",
      "[epoch 48] loss: 0.0000009\n",
      "Test set: Average loss: 2.8897, Accuracy: 3387/5000 (68%)\n",
      "[epoch 49] loss: 0.0000005\n",
      "Test set: Average loss: 2.9318, Accuracy: 3378/5000 (68%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 2.9392, Accuracy: 3378/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7058, Accuracy: 3393/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6136, Accuracy: 6869/10000 (69%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3060, Accuracy: 469/5000 (9%)\n",
      "[epoch 1] loss: 1.1667321\n",
      "Test set: Average loss: 1.1187, Accuracy: 3084/5000 (62%)\n",
      "[epoch 2] loss: 1.0654656\n",
      "Test set: Average loss: 1.1316, Accuracy: 3030/5000 (61%)\n",
      "[epoch 3] loss: 1.0245323\n",
      "Test set: Average loss: 1.0976, Accuracy: 3108/5000 (62%)\n",
      "[epoch 4] loss: 1.0000837\n",
      "Test set: Average loss: 1.1100, Accuracy: 3037/5000 (61%)\n",
      "[epoch 5] loss: 0.9588711\n",
      "Test set: Average loss: 1.0861, Accuracy: 3077/5000 (62%)\n",
      "[epoch 6] loss: 0.9227042\n",
      "Test set: Average loss: 1.0199, Accuracy: 3193/5000 (64%)\n",
      "[epoch 7] loss: 0.8908707\n",
      "Test set: Average loss: 1.0327, Accuracy: 3224/5000 (64%)\n",
      "[epoch 8] loss: 0.8538172\n",
      "Test set: Average loss: 1.0367, Accuracy: 3209/5000 (64%)\n",
      "[epoch 9] loss: 0.8168554\n",
      "Test set: Average loss: 1.0133, Accuracy: 3264/5000 (65%)\n",
      "[epoch 10] loss: 0.7710329\n",
      "Test set: Average loss: 1.0122, Accuracy: 3320/5000 (66%)\n",
      "[epoch 11] loss: 0.7221883\n",
      "Test set: Average loss: 1.0513, Accuracy: 3275/5000 (66%)\n",
      "[epoch 12] loss: 0.6635528\n",
      "Test set: Average loss: 1.0638, Accuracy: 3303/5000 (66%)\n",
      "[epoch 13] loss: 0.6028321\n",
      "Test set: Average loss: 1.0960, Accuracy: 3272/5000 (65%)\n",
      "[epoch 14] loss: 0.5188942\n",
      "Test set: Average loss: 1.1117, Accuracy: 3289/5000 (66%)\n",
      "[epoch 15] loss: 0.4420943\n",
      "Test set: Average loss: 1.1228, Accuracy: 3325/5000 (66%)\n",
      "[epoch 16] loss: 0.3669264\n",
      "Test set: Average loss: 1.1961, Accuracy: 3290/5000 (66%)\n",
      "[epoch 17] loss: 0.3016231\n",
      "Test set: Average loss: 1.2852, Accuracy: 3293/5000 (66%)\n",
      "[epoch 18] loss: 0.2372053\n",
      "Test set: Average loss: 1.3207, Accuracy: 3337/5000 (67%)\n",
      "[epoch 19] loss: 0.1992032\n",
      "Test set: Average loss: 1.5248, Accuracy: 3288/5000 (66%)\n",
      "[epoch 20] loss: 0.1731235\n",
      "Test set: Average loss: 1.5318, Accuracy: 3271/5000 (65%)\n",
      "[epoch 21] loss: 0.1667649\n",
      "Test set: Average loss: 1.6548, Accuracy: 3245/5000 (65%)\n",
      "[epoch 22] loss: 0.1562869\n",
      "Test set: Average loss: 1.6429, Accuracy: 3283/5000 (66%)\n",
      "[epoch 23] loss: 0.1460027\n",
      "Test set: Average loss: 1.7489, Accuracy: 3205/5000 (64%)\n",
      "[epoch 24] loss: 0.1240461\n",
      "Test set: Average loss: 1.7970, Accuracy: 3275/5000 (66%)\n",
      "[epoch 25] loss: 0.1459419\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9242, Accuracy: 3182/5000 (64%)\n",
      "[epoch 26] loss: 0.0679841\n",
      "Test set: Average loss: 1.7019, Accuracy: 3319/5000 (66%)\n",
      "[epoch 27] loss: 0.0181852\n",
      "Test set: Average loss: 1.7263, Accuracy: 3331/5000 (67%)\n",
      "[epoch 28] loss: 0.0099133\n",
      "Test set: Average loss: 1.7431, Accuracy: 3357/5000 (67%)\n",
      "[epoch 29] loss: 0.0065829\n",
      "Test set: Average loss: 1.7691, Accuracy: 3369/5000 (67%)\n",
      "[epoch 30] loss: 0.0045308\n",
      "Test set: Average loss: 1.7958, Accuracy: 3370/5000 (67%)\n",
      "[epoch 31] loss: 0.0031466\n",
      "Test set: Average loss: 1.8314, Accuracy: 3382/5000 (68%)\n",
      "[epoch 32] loss: 0.0021699\n",
      "Test set: Average loss: 1.8652, Accuracy: 3389/5000 (68%)\n",
      "[epoch 33] loss: 0.0014831\n",
      "Test set: Average loss: 1.9018, Accuracy: 3387/5000 (68%)\n",
      "[epoch 34] loss: 0.0010009\n",
      "Test set: Average loss: 1.9474, Accuracy: 3394/5000 (68%)\n",
      "[epoch 35] loss: 0.0006710\n",
      "Test set: Average loss: 2.0046, Accuracy: 3391/5000 (68%)\n",
      "[epoch 36] loss: 0.0004426\n",
      "Test set: Average loss: 2.0572, Accuracy: 3401/5000 (68%)\n",
      "[epoch 37] loss: 0.0002927\n",
      "Test set: Average loss: 2.1133, Accuracy: 3395/5000 (68%)\n",
      "[epoch 38] loss: 0.0001902\n",
      "Test set: Average loss: 2.1642, Accuracy: 3409/5000 (68%)\n",
      "[epoch 39] loss: 0.0001229\n",
      "Test set: Average loss: 2.2248, Accuracy: 3403/5000 (68%)\n",
      "[epoch 40] loss: 0.0000793\n",
      "Test set: Average loss: 2.2918, Accuracy: 3402/5000 (68%)\n",
      "[epoch 41] loss: 0.0000509\n",
      "Test set: Average loss: 2.3504, Accuracy: 3400/5000 (68%)\n",
      "[epoch 42] loss: 0.0000324\n",
      "Test set: Average loss: 2.4156, Accuracy: 3401/5000 (68%)\n",
      "[epoch 43] loss: 0.0000207\n",
      "Test set: Average loss: 2.4768, Accuracy: 3406/5000 (68%)\n",
      "[epoch 44] loss: 0.0000130\n",
      "Test set: Average loss: 2.5500, Accuracy: 3392/5000 (68%)\n",
      "[epoch 45] loss: 0.0000082\n",
      "Test set: Average loss: 2.6116, Accuracy: 3404/5000 (68%)\n",
      "[epoch 46] loss: 0.0000051\n",
      "Test set: Average loss: 2.6857, Accuracy: 3398/5000 (68%)\n",
      "[epoch 47] loss: 0.0000032\n",
      "Test set: Average loss: 2.7373, Accuracy: 3396/5000 (68%)\n",
      "[epoch 48] loss: 0.0000020\n",
      "Test set: Average loss: 2.8031, Accuracy: 3392/5000 (68%)\n",
      "[epoch 49] loss: 0.0000012\n",
      "Test set: Average loss: 2.8656, Accuracy: 3397/5000 (68%)\n",
      "[epoch 50] loss: 0.0000008\n",
      "Test set: Average loss: 2.9086, Accuracy: 3393/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1642, Accuracy: 3409/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.0722, Accuracy: 6890/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3048, Accuracy: 283/5000 (6%)\n",
      "[epoch 1] loss: 1.1662062\n",
      "Test set: Average loss: 1.1444, Accuracy: 2991/5000 (60%)\n",
      "[epoch 2] loss: 1.0701912\n",
      "Test set: Average loss: 1.1392, Accuracy: 3005/5000 (60%)\n",
      "[epoch 3] loss: 1.0242309\n",
      "Test set: Average loss: 1.1512, Accuracy: 3004/5000 (60%)\n",
      "[epoch 4] loss: 0.9945867\n",
      "Test set: Average loss: 1.0645, Accuracy: 3151/5000 (63%)\n",
      "[epoch 5] loss: 0.9675144\n",
      "Test set: Average loss: 1.0581, Accuracy: 3145/5000 (63%)\n",
      "[epoch 6] loss: 0.9312279\n",
      "Test set: Average loss: 1.0359, Accuracy: 3207/5000 (64%)\n",
      "[epoch 7] loss: 0.8978994\n",
      "Test set: Average loss: 1.0545, Accuracy: 3164/5000 (63%)\n",
      "[epoch 8] loss: 0.8563454\n",
      "Test set: Average loss: 1.0271, Accuracy: 3218/5000 (64%)\n",
      "[epoch 9] loss: 0.8252760\n",
      "Test set: Average loss: 1.0493, Accuracy: 3206/5000 (64%)\n",
      "[epoch 10] loss: 0.7803002\n",
      "Test set: Average loss: 1.0696, Accuracy: 3244/5000 (65%)\n",
      "[epoch 11] loss: 0.7377274\n",
      "Test set: Average loss: 1.0350, Accuracy: 3275/5000 (66%)\n",
      "[epoch 12] loss: 0.6774891\n",
      "Test set: Average loss: 1.0768, Accuracy: 3273/5000 (65%)\n",
      "[epoch 13] loss: 0.6115901\n",
      "Test set: Average loss: 1.0681, Accuracy: 3293/5000 (66%)\n",
      "[epoch 14] loss: 0.5398358\n",
      "Test set: Average loss: 1.0874, Accuracy: 3339/5000 (67%)\n",
      "[epoch 15] loss: 0.4663719\n",
      "Test set: Average loss: 1.1523, Accuracy: 3278/5000 (66%)\n",
      "[epoch 16] loss: 0.3907276\n",
      "Test set: Average loss: 1.2027, Accuracy: 3265/5000 (65%)\n",
      "[epoch 17] loss: 0.3180842\n",
      "Test set: Average loss: 1.2589, Accuracy: 3290/5000 (66%)\n",
      "[epoch 18] loss: 0.2535667\n",
      "Test set: Average loss: 1.3139, Accuracy: 3298/5000 (66%)\n",
      "[epoch 19] loss: 0.2092496\n",
      "Test set: Average loss: 1.4970, Accuracy: 3240/5000 (65%)\n",
      "[epoch 20] loss: 0.1753664\n",
      "Test set: Average loss: 1.5100, Accuracy: 3263/5000 (65%)\n",
      "[epoch 21] loss: 0.1711791\n",
      "Test set: Average loss: 1.5735, Accuracy: 3263/5000 (65%)\n",
      "[epoch 22] loss: 0.1537178\n",
      "Test set: Average loss: 1.6607, Accuracy: 3252/5000 (65%)\n",
      "[epoch 23] loss: 0.1451531\n",
      "Test set: Average loss: 1.7440, Accuracy: 3235/5000 (65%)\n",
      "[epoch 24] loss: 0.1395533\n",
      "Test set: Average loss: 1.7747, Accuracy: 3298/5000 (66%)\n",
      "[epoch 25] loss: 0.1306060\n",
      "Test set: Average loss: 1.8425, Accuracy: 3227/5000 (65%)\n",
      "[epoch 26] loss: 0.1566731\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7906, Accuracy: 3288/5000 (66%)\n",
      "[epoch 27] loss: 0.0428814\n",
      "Test set: Average loss: 1.7199, Accuracy: 3371/5000 (67%)\n",
      "[epoch 28] loss: 0.0138558\n",
      "Test set: Average loss: 1.7328, Accuracy: 3369/5000 (67%)\n",
      "[epoch 29] loss: 0.0081040\n",
      "Test set: Average loss: 1.7544, Accuracy: 3360/5000 (67%)\n",
      "[epoch 30] loss: 0.0055183\n",
      "Test set: Average loss: 1.7807, Accuracy: 3364/5000 (67%)\n",
      "[epoch 31] loss: 0.0038462\n",
      "Test set: Average loss: 1.8020, Accuracy: 3373/5000 (67%)\n",
      "[epoch 32] loss: 0.0027019\n",
      "Test set: Average loss: 1.8326, Accuracy: 3384/5000 (68%)\n",
      "[epoch 33] loss: 0.0018809\n",
      "Test set: Average loss: 1.8746, Accuracy: 3382/5000 (68%)\n",
      "[epoch 34] loss: 0.0012900\n",
      "Test set: Average loss: 1.9079, Accuracy: 3391/5000 (68%)\n",
      "[epoch 35] loss: 0.0008689\n",
      "Test set: Average loss: 1.9562, Accuracy: 3395/5000 (68%)\n",
      "[epoch 36] loss: 0.0005844\n",
      "Test set: Average loss: 2.0125, Accuracy: 3386/5000 (68%)\n",
      "[epoch 37] loss: 0.0003891\n",
      "Test set: Average loss: 2.0541, Accuracy: 3384/5000 (68%)\n",
      "[epoch 38] loss: 0.0002541\n",
      "Test set: Average loss: 2.1117, Accuracy: 3390/5000 (68%)\n",
      "[epoch 39] loss: 0.0001666\n",
      "Test set: Average loss: 2.1730, Accuracy: 3393/5000 (68%)\n",
      "[epoch 40] loss: 0.0001075\n",
      "Test set: Average loss: 2.2314, Accuracy: 3383/5000 (68%)\n",
      "[epoch 41] loss: 0.0000693\n",
      "Test set: Average loss: 2.2938, Accuracy: 3395/5000 (68%)\n",
      "[epoch 42] loss: 0.0000445\n",
      "Test set: Average loss: 2.3546, Accuracy: 3396/5000 (68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 43] loss: 0.0000285\n",
      "Test set: Average loss: 2.4207, Accuracy: 3402/5000 (68%)\n",
      "[epoch 44] loss: 0.0000181\n",
      "Test set: Average loss: 2.4945, Accuracy: 3395/5000 (68%)\n",
      "[epoch 45] loss: 0.0000115\n",
      "Test set: Average loss: 2.5506, Accuracy: 3401/5000 (68%)\n",
      "[epoch 46] loss: 0.0000072\n",
      "Test set: Average loss: 2.6319, Accuracy: 3408/5000 (68%)\n",
      "[epoch 47] loss: 0.0000045\n",
      "Test set: Average loss: 2.6893, Accuracy: 3415/5000 (68%)\n",
      "[epoch 48] loss: 0.0000028\n",
      "Test set: Average loss: 2.7570, Accuracy: 3408/5000 (68%)\n",
      "[epoch 49] loss: 0.0000018\n",
      "Test set: Average loss: 2.8185, Accuracy: 3403/5000 (68%)\n",
      "[epoch 50] loss: 0.0000011\n",
      "Test set: Average loss: 2.8807, Accuracy: 3396/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6893, Accuracy: 3415/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6056, Accuracy: 6844/10000 (68%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2969, Accuracy: 643/5000 (13%)\n",
      "[epoch 1] loss: 1.1645654\n",
      "Test set: Average loss: 1.1679, Accuracy: 2934/5000 (59%)\n",
      "[epoch 2] loss: 1.0693641\n",
      "Test set: Average loss: 1.1922, Accuracy: 2934/5000 (59%)\n",
      "[epoch 3] loss: 1.0213714\n",
      "Test set: Average loss: 1.1065, Accuracy: 3051/5000 (61%)\n",
      "[epoch 4] loss: 0.9923937\n",
      "Test set: Average loss: 1.1484, Accuracy: 3022/5000 (60%)\n",
      "[epoch 5] loss: 0.9494286\n",
      "Test set: Average loss: 1.0969, Accuracy: 3093/5000 (62%)\n",
      "[epoch 6] loss: 0.9130367\n",
      "Test set: Average loss: 1.0311, Accuracy: 3228/5000 (65%)\n",
      "[epoch 7] loss: 0.8733010\n",
      "Test set: Average loss: 1.0713, Accuracy: 3165/5000 (63%)\n",
      "[epoch 8] loss: 0.8367950\n",
      "Test set: Average loss: 1.0191, Accuracy: 3300/5000 (66%)\n",
      "[epoch 9] loss: 0.7880029\n",
      "Test set: Average loss: 1.0084, Accuracy: 3282/5000 (66%)\n",
      "[epoch 10] loss: 0.7342951\n",
      "Test set: Average loss: 1.0244, Accuracy: 3282/5000 (66%)\n",
      "[epoch 11] loss: 0.6808802\n",
      "Test set: Average loss: 1.0273, Accuracy: 3348/5000 (67%)\n",
      "[epoch 12] loss: 0.6192950\n",
      "Test set: Average loss: 1.0527, Accuracy: 3341/5000 (67%)\n",
      "[epoch 13] loss: 0.5474074\n",
      "Test set: Average loss: 1.0816, Accuracy: 3329/5000 (67%)\n",
      "[epoch 14] loss: 0.4766437\n",
      "Test set: Average loss: 1.1057, Accuracy: 3366/5000 (67%)\n",
      "[epoch 15] loss: 0.4116400\n",
      "Test set: Average loss: 1.2152, Accuracy: 3319/5000 (66%)\n",
      "[epoch 16] loss: 0.3324711\n",
      "Test set: Average loss: 1.2302, Accuracy: 3296/5000 (66%)\n",
      "[epoch 17] loss: 0.2778669\n",
      "Test set: Average loss: 1.3593, Accuracy: 3272/5000 (65%)\n",
      "[epoch 18] loss: 0.2314624\n",
      "Test set: Average loss: 1.4333, Accuracy: 3326/5000 (67%)\n",
      "[epoch 19] loss: 0.1990403\n",
      "Test set: Average loss: 1.5381, Accuracy: 3258/5000 (65%)\n",
      "[epoch 20] loss: 0.2003048\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5295, Accuracy: 3292/5000 (66%)\n",
      "[epoch 21] loss: 0.0744167\n",
      "Test set: Average loss: 1.4772, Accuracy: 3349/5000 (67%)\n",
      "[epoch 22] loss: 0.0315392\n",
      "Test set: Average loss: 1.4892, Accuracy: 3352/5000 (67%)\n",
      "[epoch 23] loss: 0.0192705\n",
      "Test set: Average loss: 1.5146, Accuracy: 3381/5000 (68%)\n",
      "[epoch 24] loss: 0.0127520\n",
      "Test set: Average loss: 1.5400, Accuracy: 3388/5000 (68%)\n",
      "[epoch 25] loss: 0.0086177\n",
      "Test set: Average loss: 1.5830, Accuracy: 3371/5000 (67%)\n",
      "[epoch 26] loss: 0.0058790\n",
      "Test set: Average loss: 1.6244, Accuracy: 3368/5000 (67%)\n",
      "[epoch 27] loss: 0.0039792\n",
      "Test set: Average loss: 1.6753, Accuracy: 3377/5000 (68%)\n",
      "[epoch 28] loss: 0.0026021\n",
      "Test set: Average loss: 1.7289, Accuracy: 3391/5000 (68%)\n",
      "[epoch 29] loss: 0.0017305\n",
      "Test set: Average loss: 1.7906, Accuracy: 3383/5000 (68%)\n",
      "[epoch 30] loss: 0.0011369\n",
      "Test set: Average loss: 1.8529, Accuracy: 3396/5000 (68%)\n",
      "[epoch 31] loss: 0.0007393\n",
      "Test set: Average loss: 1.9266, Accuracy: 3378/5000 (68%)\n",
      "[epoch 32] loss: 0.0004753\n",
      "Test set: Average loss: 1.9819, Accuracy: 3389/5000 (68%)\n",
      "[epoch 33] loss: 0.0003034\n",
      "Test set: Average loss: 2.0470, Accuracy: 3397/5000 (68%)\n",
      "[epoch 34] loss: 0.0001943\n",
      "Test set: Average loss: 2.1139, Accuracy: 3389/5000 (68%)\n",
      "[epoch 35] loss: 0.0001216\n",
      "Test set: Average loss: 2.1923, Accuracy: 3385/5000 (68%)\n",
      "[epoch 36] loss: 0.0000760\n",
      "Test set: Average loss: 2.2712, Accuracy: 3391/5000 (68%)\n",
      "[epoch 37] loss: 0.0000476\n",
      "Test set: Average loss: 2.3407, Accuracy: 3394/5000 (68%)\n",
      "[epoch 38] loss: 0.0000293\n",
      "Test set: Average loss: 2.4183, Accuracy: 3395/5000 (68%)\n",
      "[epoch 39] loss: 0.0000181\n",
      "Test set: Average loss: 2.5034, Accuracy: 3395/5000 (68%)\n",
      "[epoch 40] loss: 0.0000110\n",
      "Test set: Average loss: 2.5785, Accuracy: 3386/5000 (68%)\n",
      "[epoch 41] loss: 0.0000067\n",
      "Test set: Average loss: 2.6533, Accuracy: 3386/5000 (68%)\n",
      "[epoch 42] loss: 0.0000041\n",
      "Test set: Average loss: 2.7447, Accuracy: 3399/5000 (68%)\n",
      "[epoch 43] loss: 0.0000025\n",
      "Test set: Average loss: 2.8094, Accuracy: 3391/5000 (68%)\n",
      "[epoch 44] loss: 0.0000015\n",
      "Test set: Average loss: 2.8811, Accuracy: 3386/5000 (68%)\n",
      "[epoch 45] loss: 0.0000009\n",
      "Test set: Average loss: 2.9453, Accuracy: 3387/5000 (68%)\n",
      "[epoch 46] loss: 0.0000005\n",
      "Test set: Average loss: 2.9905, Accuracy: 3377/5000 (68%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 3.0099, Accuracy: 3385/5000 (68%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 3.0174, Accuracy: 3370/5000 (67%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0215, Accuracy: 3377/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0466, Accuracy: 3366/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7447, Accuracy: 3399/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.5124, Accuracy: 6975/10000 (70%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3107, Accuracy: 336/5000 (7%)\n",
      "[epoch 1] loss: 1.1720281\n",
      "Test set: Average loss: 1.1287, Accuracy: 3012/5000 (60%)\n",
      "[epoch 2] loss: 1.0671058\n",
      "Test set: Average loss: 1.1238, Accuracy: 3044/5000 (61%)\n",
      "[epoch 3] loss: 1.0276180\n",
      "Test set: Average loss: 1.1053, Accuracy: 3031/5000 (61%)\n",
      "[epoch 4] loss: 0.9940036\n",
      "Test set: Average loss: 1.0686, Accuracy: 3156/5000 (63%)\n",
      "[epoch 5] loss: 0.9539390\n",
      "Test set: Average loss: 1.0560, Accuracy: 3146/5000 (63%)\n",
      "[epoch 6] loss: 0.9181288\n",
      "Test set: Average loss: 1.0425, Accuracy: 3225/5000 (64%)\n",
      "[epoch 7] loss: 0.8877642\n",
      "Test set: Average loss: 1.0078, Accuracy: 3255/5000 (65%)\n",
      "[epoch 8] loss: 0.8448690\n",
      "Test set: Average loss: 1.0501, Accuracy: 3253/5000 (65%)\n",
      "[epoch 9] loss: 0.7971620\n",
      "Test set: Average loss: 1.0536, Accuracy: 3230/5000 (65%)\n",
      "[epoch 10] loss: 0.7521627\n",
      "Test set: Average loss: 1.0068, Accuracy: 3325/5000 (66%)\n",
      "[epoch 11] loss: 0.6960011\n",
      "Test set: Average loss: 1.0386, Accuracy: 3282/5000 (66%)\n",
      "[epoch 12] loss: 0.6259803\n",
      "Test set: Average loss: 1.0789, Accuracy: 3261/5000 (65%)\n",
      "[epoch 13] loss: 0.5625306\n",
      "Test set: Average loss: 1.0800, Accuracy: 3299/5000 (66%)\n",
      "[epoch 14] loss: 0.4919506\n",
      "Test set: Average loss: 1.1159, Accuracy: 3320/5000 (66%)\n",
      "[epoch 15] loss: 0.4195793\n",
      "Test set: Average loss: 1.2415, Accuracy: 3251/5000 (65%)\n",
      "[epoch 16] loss: 0.3484412\n",
      "Test set: Average loss: 1.2229, Accuracy: 3314/5000 (66%)\n",
      "[epoch 17] loss: 0.2856857\n",
      "Test set: Average loss: 1.2894, Accuracy: 3356/5000 (67%)\n",
      "[epoch 18] loss: 0.2323690\n",
      "Test set: Average loss: 1.3772, Accuracy: 3378/5000 (68%)\n",
      "[epoch 19] loss: 0.2038700\n",
      "Test set: Average loss: 1.4514, Accuracy: 3313/5000 (66%)\n",
      "[epoch 20] loss: 0.1877058\n",
      "Test set: Average loss: 1.5316, Accuracy: 3272/5000 (65%)\n",
      "[epoch 21] loss: 0.1735491\n",
      "Test set: Average loss: 1.5744, Accuracy: 3317/5000 (66%)\n",
      "[epoch 22] loss: 0.1776440\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5409, Accuracy: 3328/5000 (67%)\n",
      "[epoch 23] loss: 0.0552538\n",
      "Test set: Average loss: 1.4968, Accuracy: 3417/5000 (68%)\n",
      "[epoch 24] loss: 0.0212927\n",
      "Test set: Average loss: 1.5132, Accuracy: 3438/5000 (69%)\n",
      "[epoch 25] loss: 0.0126777\n",
      "Test set: Average loss: 1.5304, Accuracy: 3439/5000 (69%)\n",
      "[epoch 26] loss: 0.0082778\n",
      "Test set: Average loss: 1.5703, Accuracy: 3450/5000 (69%)\n",
      "[epoch 27] loss: 0.0056136\n",
      "Test set: Average loss: 1.5991, Accuracy: 3467/5000 (69%)\n",
      "[epoch 28] loss: 0.0037596\n",
      "Test set: Average loss: 1.6436, Accuracy: 3463/5000 (69%)\n",
      "[epoch 29] loss: 0.0024822\n",
      "Test set: Average loss: 1.6860, Accuracy: 3466/5000 (69%)\n",
      "[epoch 30] loss: 0.0016398\n",
      "Test set: Average loss: 1.7368, Accuracy: 3465/5000 (69%)\n",
      "[epoch 31] loss: 0.0010649\n",
      "Test set: Average loss: 1.7883, Accuracy: 3468/5000 (69%)\n",
      "[epoch 32] loss: 0.0006796\n",
      "Test set: Average loss: 1.8538, Accuracy: 3482/5000 (70%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] loss: 0.0004295\n",
      "Test set: Average loss: 1.9140, Accuracy: 3468/5000 (69%)\n",
      "[epoch 34] loss: 0.0002719\n",
      "Test set: Average loss: 1.9762, Accuracy: 3481/5000 (70%)\n",
      "[epoch 35] loss: 0.0001699\n",
      "Test set: Average loss: 2.0449, Accuracy: 3487/5000 (70%)\n",
      "[epoch 36] loss: 0.0001050\n",
      "Test set: Average loss: 2.1137, Accuracy: 3484/5000 (70%)\n",
      "[epoch 37] loss: 0.0000654\n",
      "Test set: Average loss: 2.1828, Accuracy: 3480/5000 (70%)\n",
      "[epoch 38] loss: 0.0000398\n",
      "Test set: Average loss: 2.2574, Accuracy: 3481/5000 (70%)\n",
      "[epoch 39] loss: 0.0000243\n",
      "Test set: Average loss: 2.3274, Accuracy: 3479/5000 (70%)\n",
      "[epoch 40] loss: 0.0000147\n",
      "Test set: Average loss: 2.3958, Accuracy: 3489/5000 (70%)\n",
      "[epoch 41] loss: 0.0000089\n",
      "Test set: Average loss: 2.4742, Accuracy: 3469/5000 (69%)\n",
      "[epoch 42] loss: 0.0000053\n",
      "Test set: Average loss: 2.5581, Accuracy: 3482/5000 (70%)\n",
      "[epoch 43] loss: 0.0000032\n",
      "Test set: Average loss: 2.6262, Accuracy: 3468/5000 (69%)\n",
      "[epoch 44] loss: 0.0000019\n",
      "Test set: Average loss: 2.7057, Accuracy: 3475/5000 (70%)\n",
      "[epoch 45] loss: 0.0000011\n",
      "Test set: Average loss: 2.7602, Accuracy: 3466/5000 (69%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Test set: Average loss: 2.8078, Accuracy: 3479/5000 (70%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 2.8366, Accuracy: 3465/5000 (69%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 2.8523, Accuracy: 3460/5000 (69%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.8550, Accuracy: 3461/5000 (69%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.8691, Accuracy: 3470/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3958, Accuracy: 3489/5000 (70%)\n",
      "Test\n",
      "Test set: Average loss: 2.4212, Accuracy: 6934/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3009, Accuracy: 828/5000 (17%)\n",
      "[epoch 1] loss: 1.1667890\n",
      "Test set: Average loss: 1.1658, Accuracy: 2969/5000 (59%)\n",
      "[epoch 2] loss: 1.0704164\n",
      "Test set: Average loss: 1.1639, Accuracy: 3007/5000 (60%)\n",
      "[epoch 3] loss: 1.0237465\n",
      "Test set: Average loss: 1.1126, Accuracy: 3081/5000 (62%)\n",
      "[epoch 4] loss: 0.9887027\n",
      "Test set: Average loss: 1.0492, Accuracy: 3163/5000 (63%)\n",
      "[epoch 5] loss: 0.9521620\n",
      "Test set: Average loss: 1.0811, Accuracy: 3171/5000 (63%)\n",
      "[epoch 6] loss: 0.9218204\n",
      "Test set: Average loss: 1.0577, Accuracy: 3195/5000 (64%)\n",
      "[epoch 7] loss: 0.8817732\n",
      "Test set: Average loss: 1.0740, Accuracy: 3184/5000 (64%)\n",
      "[epoch 8] loss: 0.8432648\n",
      "Test set: Average loss: 1.0110, Accuracy: 3287/5000 (66%)\n",
      "[epoch 9] loss: 0.8001960\n",
      "Test set: Average loss: 1.0464, Accuracy: 3247/5000 (65%)\n",
      "[epoch 10] loss: 0.7494943\n",
      "Test set: Average loss: 1.0114, Accuracy: 3290/5000 (66%)\n",
      "[epoch 11] loss: 0.6921702\n",
      "Test set: Average loss: 1.0798, Accuracy: 3236/5000 (65%)\n",
      "[epoch 12] loss: 0.6292063\n",
      "Test set: Average loss: 1.0644, Accuracy: 3298/5000 (66%)\n",
      "[epoch 13] loss: 0.5621850\n",
      "Test set: Average loss: 1.0433, Accuracy: 3307/5000 (66%)\n",
      "[epoch 14] loss: 0.4823281\n",
      "Test set: Average loss: 1.1316, Accuracy: 3298/5000 (66%)\n",
      "[epoch 15] loss: 0.4122029\n",
      "Test set: Average loss: 1.1755, Accuracy: 3317/5000 (66%)\n",
      "[epoch 16] loss: 0.3420766\n",
      "Test set: Average loss: 1.2004, Accuracy: 3361/5000 (67%)\n",
      "[epoch 17] loss: 0.2833579\n",
      "Test set: Average loss: 1.3210, Accuracy: 3268/5000 (65%)\n",
      "[epoch 18] loss: 0.2356467\n",
      "Test set: Average loss: 1.3844, Accuracy: 3316/5000 (66%)\n",
      "[epoch 19] loss: 0.2143119\n",
      "Test set: Average loss: 1.5244, Accuracy: 3246/5000 (65%)\n",
      "[epoch 20] loss: 0.2006040\n",
      "Test set: Average loss: 1.5064, Accuracy: 3312/5000 (66%)\n",
      "[epoch 21] loss: 0.1605685\n",
      "Test set: Average loss: 1.6077, Accuracy: 3287/5000 (66%)\n",
      "[epoch 22] loss: 0.1644884\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6624, Accuracy: 3325/5000 (66%)\n",
      "[epoch 23] loss: 0.0577284\n",
      "Test set: Average loss: 1.5759, Accuracy: 3389/5000 (68%)\n",
      "[epoch 24] loss: 0.0201500\n",
      "Test set: Average loss: 1.6010, Accuracy: 3420/5000 (68%)\n",
      "[epoch 25] loss: 0.0120477\n",
      "Test set: Average loss: 1.6208, Accuracy: 3419/5000 (68%)\n",
      "[epoch 26] loss: 0.0079328\n",
      "Test set: Average loss: 1.6550, Accuracy: 3421/5000 (68%)\n",
      "[epoch 27] loss: 0.0053104\n",
      "Test set: Average loss: 1.6896, Accuracy: 3431/5000 (69%)\n",
      "[epoch 28] loss: 0.0035624\n",
      "Test set: Average loss: 1.7291, Accuracy: 3438/5000 (69%)\n",
      "[epoch 29] loss: 0.0023509\n",
      "Test set: Average loss: 1.7750, Accuracy: 3441/5000 (69%)\n",
      "[epoch 30] loss: 0.0015460\n",
      "Test set: Average loss: 1.8246, Accuracy: 3448/5000 (69%)\n",
      "[epoch 31] loss: 0.0009912\n",
      "Test set: Average loss: 1.8836, Accuracy: 3452/5000 (69%)\n",
      "[epoch 32] loss: 0.0006365\n",
      "Test set: Average loss: 1.9488, Accuracy: 3450/5000 (69%)\n",
      "[epoch 33] loss: 0.0004034\n",
      "Test set: Average loss: 2.0075, Accuracy: 3445/5000 (69%)\n",
      "[epoch 34] loss: 0.0002531\n",
      "Test set: Average loss: 2.0731, Accuracy: 3470/5000 (69%)\n",
      "[epoch 35] loss: 0.0001583\n",
      "Test set: Average loss: 2.1462, Accuracy: 3453/5000 (69%)\n",
      "[epoch 36] loss: 0.0000980\n",
      "Test set: Average loss: 2.2073, Accuracy: 3470/5000 (69%)\n",
      "[epoch 37] loss: 0.0000604\n",
      "Test set: Average loss: 2.2837, Accuracy: 3474/5000 (69%)\n",
      "[epoch 38] loss: 0.0000369\n",
      "Test set: Average loss: 2.3609, Accuracy: 3473/5000 (69%)\n",
      "[epoch 39] loss: 0.0000225\n",
      "Test set: Average loss: 2.4373, Accuracy: 3469/5000 (69%)\n",
      "[epoch 40] loss: 0.0000136\n",
      "Test set: Average loss: 2.5032, Accuracy: 3476/5000 (70%)\n",
      "[epoch 41] loss: 0.0000082\n",
      "Test set: Average loss: 2.5821, Accuracy: 3467/5000 (69%)\n",
      "[epoch 42] loss: 0.0000049\n",
      "Test set: Average loss: 2.6607, Accuracy: 3476/5000 (70%)\n",
      "[epoch 43] loss: 0.0000029\n",
      "Test set: Average loss: 2.7328, Accuracy: 3469/5000 (69%)\n",
      "[epoch 44] loss: 0.0000018\n",
      "Test set: Average loss: 2.8075, Accuracy: 3455/5000 (69%)\n",
      "[epoch 45] loss: 0.0000010\n",
      "Test set: Average loss: 2.8704, Accuracy: 3464/5000 (69%)\n",
      "[epoch 46] loss: 0.0000006\n",
      "Test set: Average loss: 2.9085, Accuracy: 3460/5000 (69%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 2.9387, Accuracy: 3441/5000 (69%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 2.9510, Accuracy: 3455/5000 (69%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.9722, Accuracy: 3457/5000 (69%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.9710, Accuracy: 3435/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6607, Accuracy: 3476/5000 (70%)\n",
      "Test\n",
      "Test set: Average loss: 2.5541, Accuracy: 6917/10000 (69%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3059, Accuracy: 381/5000 (8%)\n",
      "[epoch 1] loss: 1.1617953\n",
      "Test set: Average loss: 1.1695, Accuracy: 2944/5000 (59%)\n",
      "[epoch 2] loss: 1.0654525\n",
      "Test set: Average loss: 1.1124, Accuracy: 3023/5000 (60%)\n",
      "[epoch 3] loss: 1.0272549\n",
      "Test set: Average loss: 1.1050, Accuracy: 3091/5000 (62%)\n",
      "[epoch 4] loss: 0.9859880\n",
      "Test set: Average loss: 1.1144, Accuracy: 3076/5000 (62%)\n",
      "[epoch 5] loss: 0.9448292\n",
      "Test set: Average loss: 1.0234, Accuracy: 3231/5000 (65%)\n",
      "[epoch 6] loss: 0.9055176\n",
      "Test set: Average loss: 1.0537, Accuracy: 3158/5000 (63%)\n",
      "[epoch 7] loss: 0.8718335\n",
      "Test set: Average loss: 0.9812, Accuracy: 3336/5000 (67%)\n",
      "[epoch 8] loss: 0.8206993\n",
      "Test set: Average loss: 0.9786, Accuracy: 3314/5000 (66%)\n",
      "[epoch 9] loss: 0.7710379\n",
      "Test set: Average loss: 0.9716, Accuracy: 3381/5000 (68%)\n",
      "[epoch 10] loss: 0.7178628\n",
      "Test set: Average loss: 0.9881, Accuracy: 3399/5000 (68%)\n",
      "[epoch 11] loss: 0.6634265\n",
      "Test set: Average loss: 1.0326, Accuracy: 3318/5000 (66%)\n",
      "[epoch 12] loss: 0.5972487\n",
      "Test set: Average loss: 1.0338, Accuracy: 3359/5000 (67%)\n",
      "[epoch 13] loss: 0.5330378\n",
      "Test set: Average loss: 1.1085, Accuracy: 3311/5000 (66%)\n",
      "[epoch 14] loss: 0.4676275\n",
      "Test set: Average loss: 1.1104, Accuracy: 3363/5000 (67%)\n",
      "[epoch 15] loss: 0.3948088\n",
      "Test set: Average loss: 1.1723, Accuracy: 3343/5000 (67%)\n",
      "[epoch 16] loss: 0.3364204\n",
      "Test set: Average loss: 1.2924, Accuracy: 3302/5000 (66%)\n",
      "[epoch 17] loss: 0.2867667\n",
      "Test set: Average loss: 1.3486, Accuracy: 3290/5000 (66%)\n",
      "[epoch 18] loss: 0.2362669\n",
      "Test set: Average loss: 1.4217, Accuracy: 3266/5000 (65%)\n",
      "[epoch 19] loss: 0.2279275\n",
      "Test set: Average loss: 1.4542, Accuracy: 3288/5000 (66%)\n",
      "[epoch 20] loss: 0.2072343\n",
      "Test set: Average loss: 1.4891, Accuracy: 3292/5000 (66%)\n",
      "[epoch 21] loss: 0.1849634\n",
      "Test set: Average loss: 1.6837, Accuracy: 3278/5000 (66%)\n",
      "[epoch 22] loss: 0.1966585\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6178, Accuracy: 3286/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] loss: 0.0667668\n",
      "Test set: Average loss: 1.5258, Accuracy: 3399/5000 (68%)\n",
      "[epoch 24] loss: 0.0252962\n",
      "Test set: Average loss: 1.5484, Accuracy: 3396/5000 (68%)\n",
      "[epoch 25] loss: 0.0143851\n",
      "Test set: Average loss: 1.5766, Accuracy: 3401/5000 (68%)\n",
      "[epoch 26] loss: 0.0091508\n",
      "Test set: Average loss: 1.6129, Accuracy: 3416/5000 (68%)\n",
      "[epoch 27] loss: 0.0059238\n",
      "Test set: Average loss: 1.6622, Accuracy: 3429/5000 (69%)\n",
      "[epoch 28] loss: 0.0038509\n",
      "Test set: Average loss: 1.7061, Accuracy: 3412/5000 (68%)\n",
      "[epoch 29] loss: 0.0024414\n",
      "Test set: Average loss: 1.7601, Accuracy: 3432/5000 (69%)\n",
      "[epoch 30] loss: 0.0015323\n",
      "Test set: Average loss: 1.8224, Accuracy: 3430/5000 (69%)\n",
      "[epoch 31] loss: 0.0009611\n",
      "Test set: Average loss: 1.8897, Accuracy: 3437/5000 (69%)\n",
      "[epoch 32] loss: 0.0005920\n",
      "Test set: Average loss: 1.9534, Accuracy: 3433/5000 (69%)\n",
      "[epoch 33] loss: 0.0003606\n",
      "Test set: Average loss: 2.0207, Accuracy: 3427/5000 (69%)\n",
      "[epoch 34] loss: 0.0002187\n",
      "Test set: Average loss: 2.0823, Accuracy: 3439/5000 (69%)\n",
      "[epoch 35] loss: 0.0001323\n",
      "Test set: Average loss: 2.1717, Accuracy: 3432/5000 (69%)\n",
      "[epoch 36] loss: 0.0000795\n",
      "Test set: Average loss: 2.2448, Accuracy: 3448/5000 (69%)\n",
      "[epoch 37] loss: 0.0000470\n",
      "Test set: Average loss: 2.3315, Accuracy: 3438/5000 (69%)\n",
      "[epoch 38] loss: 0.0000277\n",
      "Test set: Average loss: 2.4005, Accuracy: 3443/5000 (69%)\n",
      "[epoch 39] loss: 0.0000162\n",
      "Test set: Average loss: 2.4818, Accuracy: 3445/5000 (69%)\n",
      "[epoch 40] loss: 0.0000095\n",
      "Test set: Average loss: 2.5652, Accuracy: 3438/5000 (69%)\n",
      "[epoch 41] loss: 0.0000054\n",
      "Test set: Average loss: 2.6741, Accuracy: 3439/5000 (69%)\n",
      "[epoch 42] loss: 0.0000031\n",
      "Test set: Average loss: 2.7345, Accuracy: 3451/5000 (69%)\n",
      "[epoch 43] loss: 0.0000018\n",
      "Test set: Average loss: 2.8076, Accuracy: 3447/5000 (69%)\n",
      "[epoch 44] loss: 0.0000010\n",
      "Test set: Average loss: 2.8837, Accuracy: 3445/5000 (69%)\n",
      "[epoch 45] loss: 0.0000006\n",
      "Test set: Average loss: 2.9298, Accuracy: 3433/5000 (69%)\n",
      "[epoch 46] loss: 0.0000003\n",
      "Test set: Average loss: 2.9597, Accuracy: 3441/5000 (69%)\n",
      "[epoch 47] loss: 0.0000002\n",
      "Test set: Average loss: 2.9725, Accuracy: 3439/5000 (69%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 2.9846, Accuracy: 3445/5000 (69%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0011, Accuracy: 3423/5000 (68%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.0102, Accuracy: 3437/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7345, Accuracy: 3451/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.6377, Accuracy: 6958/10000 (70%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3017, Accuracy: 650/5000 (13%)\n",
      "[epoch 1] loss: 1.1567520\n",
      "Test set: Average loss: 1.1465, Accuracy: 2987/5000 (60%)\n",
      "[epoch 2] loss: 1.0647998\n",
      "Test set: Average loss: 1.1126, Accuracy: 3040/5000 (61%)\n",
      "[epoch 3] loss: 1.0178624\n",
      "Test set: Average loss: 1.1010, Accuracy: 3087/5000 (62%)\n",
      "[epoch 4] loss: 0.9828703\n",
      "Test set: Average loss: 1.0752, Accuracy: 3115/5000 (62%)\n",
      "[epoch 5] loss: 0.9447335\n",
      "Test set: Average loss: 1.0174, Accuracy: 3229/5000 (65%)\n",
      "[epoch 6] loss: 0.9020803\n",
      "Test set: Average loss: 1.0298, Accuracy: 3267/5000 (65%)\n",
      "[epoch 7] loss: 0.8657872\n",
      "Test set: Average loss: 1.0338, Accuracy: 3214/5000 (64%)\n",
      "[epoch 8] loss: 0.8268844\n",
      "Test set: Average loss: 1.0257, Accuracy: 3253/5000 (65%)\n",
      "[epoch 9] loss: 0.7756824\n",
      "Test set: Average loss: 0.9877, Accuracy: 3291/5000 (66%)\n",
      "[epoch 10] loss: 0.7232860\n",
      "Test set: Average loss: 0.9789, Accuracy: 3371/5000 (67%)\n",
      "[epoch 11] loss: 0.6615811\n",
      "Test set: Average loss: 0.9887, Accuracy: 3378/5000 (68%)\n",
      "[epoch 12] loss: 0.6011878\n",
      "Test set: Average loss: 1.0864, Accuracy: 3301/5000 (66%)\n",
      "[epoch 13] loss: 0.5319079\n",
      "Test set: Average loss: 1.0642, Accuracy: 3363/5000 (67%)\n",
      "[epoch 14] loss: 0.4640577\n",
      "Test set: Average loss: 1.0933, Accuracy: 3337/5000 (67%)\n",
      "[epoch 15] loss: 0.4038247\n",
      "Test set: Average loss: 1.1402, Accuracy: 3354/5000 (67%)\n",
      "[epoch 16] loss: 0.3433276\n",
      "Test set: Average loss: 1.3703, Accuracy: 3219/5000 (64%)\n",
      "[epoch 17] loss: 0.2868420\n",
      "Test set: Average loss: 1.2883, Accuracy: 3341/5000 (67%)\n",
      "[epoch 18] loss: 0.2489471\n",
      "Test set: Average loss: 1.3638, Accuracy: 3338/5000 (67%)\n",
      "[epoch 19] loss: 0.2222085\n",
      "Test set: Average loss: 1.4517, Accuracy: 3326/5000 (67%)\n",
      "[epoch 20] loss: 0.2143028\n",
      "Test set: Average loss: 1.5211, Accuracy: 3322/5000 (66%)\n",
      "[epoch 21] loss: 0.1927754\n",
      "Test set: Average loss: 1.5120, Accuracy: 3319/5000 (66%)\n",
      "[epoch 22] loss: 0.1832729\n",
      "Test set: Average loss: 1.7458, Accuracy: 3203/5000 (64%)\n",
      "[epoch 23] loss: 0.1747221\n",
      "Test set: Average loss: 1.6617, Accuracy: 3323/5000 (66%)\n",
      "[epoch 24] loss: 0.1760013\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7511, Accuracy: 3268/5000 (65%)\n",
      "[epoch 25] loss: 0.0713296\n",
      "Test set: Average loss: 1.6261, Accuracy: 3349/5000 (67%)\n",
      "[epoch 26] loss: 0.0242010\n",
      "Test set: Average loss: 1.6426, Accuracy: 3373/5000 (67%)\n",
      "[epoch 27] loss: 0.0129554\n",
      "Test set: Average loss: 1.6673, Accuracy: 3404/5000 (68%)\n",
      "[epoch 28] loss: 0.0080487\n",
      "Test set: Average loss: 1.7003, Accuracy: 3392/5000 (68%)\n",
      "[epoch 29] loss: 0.0051564\n",
      "Test set: Average loss: 1.7531, Accuracy: 3405/5000 (68%)\n",
      "[epoch 30] loss: 0.0033147\n",
      "Test set: Average loss: 1.7898, Accuracy: 3415/5000 (68%)\n",
      "[epoch 31] loss: 0.0020943\n",
      "Test set: Average loss: 1.8436, Accuracy: 3413/5000 (68%)\n",
      "[epoch 32] loss: 0.0013057\n",
      "Test set: Average loss: 1.9076, Accuracy: 3414/5000 (68%)\n",
      "[epoch 33] loss: 0.0008075\n",
      "Test set: Average loss: 1.9669, Accuracy: 3420/5000 (68%)\n",
      "[epoch 34] loss: 0.0004962\n",
      "Test set: Average loss: 2.0332, Accuracy: 3415/5000 (68%)\n",
      "[epoch 35] loss: 0.0002989\n",
      "Test set: Average loss: 2.1073, Accuracy: 3429/5000 (69%)\n",
      "[epoch 36] loss: 0.0001828\n",
      "Test set: Average loss: 2.1654, Accuracy: 3425/5000 (68%)\n",
      "[epoch 37] loss: 0.0001075\n",
      "Test set: Average loss: 2.2468, Accuracy: 3425/5000 (68%)\n",
      "[epoch 38] loss: 0.0000640\n",
      "Test set: Average loss: 2.3242, Accuracy: 3412/5000 (68%)\n",
      "[epoch 39] loss: 0.0000379\n",
      "Test set: Average loss: 2.3984, Accuracy: 3424/5000 (68%)\n",
      "[epoch 40] loss: 0.0000222\n",
      "Test set: Average loss: 2.4781, Accuracy: 3417/5000 (68%)\n",
      "[epoch 41] loss: 0.0000128\n",
      "Test set: Average loss: 2.5580, Accuracy: 3434/5000 (69%)\n",
      "[epoch 42] loss: 0.0000075\n",
      "Test set: Average loss: 2.6467, Accuracy: 3424/5000 (68%)\n",
      "[epoch 43] loss: 0.0000043\n",
      "Test set: Average loss: 2.7397, Accuracy: 3420/5000 (68%)\n",
      "[epoch 44] loss: 0.0000024\n",
      "Test set: Average loss: 2.8182, Accuracy: 3428/5000 (69%)\n",
      "[epoch 45] loss: 0.0000014\n",
      "Test set: Average loss: 2.8968, Accuracy: 3436/5000 (69%)\n",
      "[epoch 46] loss: 0.0000008\n",
      "Test set: Average loss: 2.9557, Accuracy: 3426/5000 (69%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 2.9824, Accuracy: 3430/5000 (69%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.0153, Accuracy: 3431/5000 (69%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0203, Accuracy: 3427/5000 (69%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0387, Accuracy: 3434/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8968, Accuracy: 3436/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.7697, Accuracy: 6913/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3155, Accuracy: 133/5000 (3%)\n",
      "[epoch 1] loss: 1.1624117\n",
      "Test set: Average loss: 1.2186, Accuracy: 2893/5000 (58%)\n",
      "[epoch 2] loss: 1.0669498\n",
      "Test set: Average loss: 1.0952, Accuracy: 3075/5000 (62%)\n",
      "[epoch 3] loss: 1.0200717\n",
      "Test set: Average loss: 1.1164, Accuracy: 3043/5000 (61%)\n",
      "[epoch 4] loss: 0.9758063\n",
      "Test set: Average loss: 1.0758, Accuracy: 3150/5000 (63%)\n",
      "[epoch 5] loss: 0.9430451\n",
      "Test set: Average loss: 1.1323, Accuracy: 3059/5000 (61%)\n",
      "[epoch 6] loss: 0.9013855\n",
      "Test set: Average loss: 1.0208, Accuracy: 3271/5000 (65%)\n",
      "[epoch 7] loss: 0.8628798\n",
      "Test set: Average loss: 1.0144, Accuracy: 3252/5000 (65%)\n",
      "[epoch 8] loss: 0.8231242\n",
      "Test set: Average loss: 1.0143, Accuracy: 3240/5000 (65%)\n",
      "[epoch 9] loss: 0.7763006\n",
      "Test set: Average loss: 1.0023, Accuracy: 3328/5000 (67%)\n",
      "[epoch 10] loss: 0.7224346\n",
      "Test set: Average loss: 1.0156, Accuracy: 3338/5000 (67%)\n",
      "[epoch 11] loss: 0.6600253\n",
      "Test set: Average loss: 0.9839, Accuracy: 3363/5000 (67%)\n",
      "[epoch 12] loss: 0.5899665\n",
      "Test set: Average loss: 1.0762, Accuracy: 3327/5000 (67%)\n",
      "[epoch 13] loss: 0.5291966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0754, Accuracy: 3343/5000 (67%)\n",
      "[epoch 14] loss: 0.4542731\n",
      "Test set: Average loss: 1.1330, Accuracy: 3334/5000 (67%)\n",
      "[epoch 15] loss: 0.3907823\n",
      "Test set: Average loss: 1.1556, Accuracy: 3332/5000 (67%)\n",
      "[epoch 16] loss: 0.3306141\n",
      "Test set: Average loss: 1.1748, Accuracy: 3380/5000 (68%)\n",
      "[epoch 17] loss: 0.2867362\n",
      "Test set: Average loss: 1.3531, Accuracy: 3296/5000 (66%)\n",
      "[epoch 18] loss: 0.2462284\n",
      "Test set: Average loss: 1.3550, Accuracy: 3329/5000 (67%)\n",
      "[epoch 19] loss: 0.2168716\n",
      "Test set: Average loss: 1.4711, Accuracy: 3281/5000 (66%)\n",
      "[epoch 20] loss: 0.2091541\n",
      "Test set: Average loss: 1.4987, Accuracy: 3302/5000 (66%)\n",
      "[epoch 21] loss: 0.1864722\n",
      "Test set: Average loss: 1.6107, Accuracy: 3287/5000 (66%)\n",
      "[epoch 22] loss: 0.1828960\n",
      "Test set: Average loss: 1.6056, Accuracy: 3315/5000 (66%)\n",
      "[epoch 23] loss: 0.1831578\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7778, Accuracy: 3221/5000 (64%)\n",
      "[epoch 24] loss: 0.0640309\n",
      "Test set: Average loss: 1.5992, Accuracy: 3362/5000 (67%)\n",
      "[epoch 25] loss: 0.0228414\n",
      "Test set: Average loss: 1.6072, Accuracy: 3394/5000 (68%)\n",
      "[epoch 26] loss: 0.0129034\n",
      "Test set: Average loss: 1.6259, Accuracy: 3420/5000 (68%)\n",
      "[epoch 27] loss: 0.0081299\n",
      "Test set: Average loss: 1.6640, Accuracy: 3409/5000 (68%)\n",
      "[epoch 28] loss: 0.0052147\n",
      "Test set: Average loss: 1.6902, Accuracy: 3435/5000 (69%)\n",
      "[epoch 29] loss: 0.0033885\n",
      "Test set: Average loss: 1.7363, Accuracy: 3417/5000 (68%)\n",
      "[epoch 30] loss: 0.0021413\n",
      "Test set: Average loss: 1.7845, Accuracy: 3415/5000 (68%)\n",
      "[epoch 31] loss: 0.0013425\n",
      "Test set: Average loss: 1.8377, Accuracy: 3429/5000 (69%)\n",
      "[epoch 32] loss: 0.0008325\n",
      "Test set: Average loss: 1.9089, Accuracy: 3424/5000 (68%)\n",
      "[epoch 33] loss: 0.0005102\n",
      "Test set: Average loss: 1.9765, Accuracy: 3427/5000 (69%)\n",
      "[epoch 34] loss: 0.0003087\n",
      "Test set: Average loss: 2.0359, Accuracy: 3429/5000 (69%)\n",
      "[epoch 35] loss: 0.0001851\n",
      "Test set: Average loss: 2.1121, Accuracy: 3428/5000 (69%)\n",
      "[epoch 36] loss: 0.0001114\n",
      "Test set: Average loss: 2.1924, Accuracy: 3441/5000 (69%)\n",
      "[epoch 37] loss: 0.0000658\n",
      "Test set: Average loss: 2.2598, Accuracy: 3438/5000 (69%)\n",
      "[epoch 38] loss: 0.0000387\n",
      "Test set: Average loss: 2.3409, Accuracy: 3417/5000 (68%)\n",
      "[epoch 39] loss: 0.0000227\n",
      "Test set: Average loss: 2.4214, Accuracy: 3431/5000 (69%)\n",
      "[epoch 40] loss: 0.0000131\n",
      "Test set: Average loss: 2.5098, Accuracy: 3434/5000 (69%)\n",
      "[epoch 41] loss: 0.0000076\n",
      "Test set: Average loss: 2.5848, Accuracy: 3426/5000 (69%)\n",
      "[epoch 42] loss: 0.0000044\n",
      "Test set: Average loss: 2.6733, Accuracy: 3428/5000 (69%)\n",
      "[epoch 43] loss: 0.0000025\n",
      "Test set: Average loss: 2.7581, Accuracy: 3443/5000 (69%)\n",
      "[epoch 44] loss: 0.0000014\n",
      "Test set: Average loss: 2.8419, Accuracy: 3438/5000 (69%)\n",
      "[epoch 45] loss: 0.0000008\n",
      "Test set: Average loss: 2.8895, Accuracy: 3437/5000 (69%)\n",
      "[epoch 46] loss: 0.0000005\n",
      "Test set: Average loss: 2.9382, Accuracy: 3426/5000 (69%)\n",
      "[epoch 47] loss: 0.0000003\n",
      "Test set: Average loss: 2.9558, Accuracy: 3438/5000 (69%)\n",
      "[epoch 48] loss: 0.0000002\n",
      "Test set: Average loss: 2.9722, Accuracy: 3425/5000 (68%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.9880, Accuracy: 3428/5000 (69%)\n",
      "[epoch 50] loss: 0.0000001\n",
      "Test set: Average loss: 3.0030, Accuracy: 3436/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7581, Accuracy: 3443/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.6888, Accuracy: 6985/10000 (70%)\n"
     ]
    }
   ],
   "source": [
    "# train the SimEc\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = SimilarityEncoder(cnn, 512, n_targets)\n",
    "model.fit(X, S, epochs=50, lr=0.0001, s_ll_reg=100., S_ll=S_ll, orth_reg=1.)\n",
    "print(check_similarity_match(model.predict(X[:n_targets]), S_ll, X_embed_is_S_approx=True))\n",
    "print(check_similarity_match(model.transform(X[:n_targets]), S_ll))\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.model.embedding_net.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_se_t1 = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_se_t1.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T18:10:04.922263Z",
     "start_time": "2019-07-24T15:15:25.358988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.0046220\n",
      "[epoch 2] loss: 0.0004711\n",
      "[epoch 3] loss: 0.0003020\n",
      "[epoch 4] loss: 0.0002519\n",
      "[epoch 5] loss: 0.0002275\n",
      "[epoch 6] loss: 0.0002145\n",
      "[epoch 7] loss: 0.0002051\n",
      "[epoch 8] loss: 0.0002005\n",
      "[epoch 9] loss: 0.0001930\n",
      "[epoch 10] loss: 0.0001919\n",
      "[epoch 11] loss: 0.0001876\n",
      "[epoch 12] loss: 0.0001858\n",
      "[epoch 13] loss: 0.0001834\n",
      "[epoch 14] loss: 0.0001829\n",
      "[epoch 15] loss: 0.0001809\n",
      "[epoch 16] loss: 0.0001790\n",
      "[epoch 17] loss: 0.0001786\n",
      "[epoch 18] loss: 0.0001772\n",
      "[epoch 19] loss: 0.0001793\n",
      "[epoch 20] loss: 0.0001950\n",
      "[epoch 21] loss: 0.0001842\n",
      "[epoch 22] loss: 0.0001774\n",
      "[epoch 23] loss: 0.0001740\n",
      "[epoch 24] loss: 0.0001726\n",
      "[epoch 25] loss: 0.0001713\n",
      "[epoch 26] loss: 0.0001700\n",
      "[epoch 27] loss: 0.0001693\n",
      "[epoch 28] loss: 0.0001686\n",
      "[epoch 29] loss: 0.0001682\n",
      "[epoch 30] loss: 0.0001674\n",
      "[epoch 31] loss: 0.0001672\n",
      "[epoch 32] loss: 0.0001665\n",
      "[epoch 33] loss: 0.0001661\n",
      "[epoch 34] loss: 0.0001657\n",
      "[epoch 35] loss: 0.0001653\n",
      "[epoch 36] loss: 0.0001649\n",
      "[epoch 37] loss: 0.0001646\n",
      "[epoch 38] loss: 0.0001643\n",
      "[epoch 39] loss: 0.0001640\n",
      "[epoch 40] loss: 0.0001638\n",
      "[epoch 41] loss: 0.0001633\n",
      "[epoch 42] loss: 0.0001632\n",
      "[epoch 43] loss: 0.0001629\n",
      "[epoch 44] loss: 0.0001627\n",
      "[epoch 45] loss: 0.0001622\n",
      "[epoch 46] loss: 0.0001623\n",
      "[epoch 47] loss: 0.0001621\n",
      "[epoch 48] loss: 0.0001618\n",
      "[epoch 49] loss: 0.0001618\n",
      "[epoch 50] loss: 0.0001615\n",
      "(0.0001604481978878747, 0.9305801844479616, 0.9524157024471986)\n",
      "(0.0002087660584315367, 0.9103976776791763, 0.9403760817998809)\n",
      "Took 903 sec to train.\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 499/5000 (10%)\n",
      "[epoch 1] loss: 2.3062241\n",
      "Test set: Average loss: 2.2947, Accuracy: 705/5000 (14%)\n",
      "[epoch 2] loss: 2.2116582\n",
      "Test set: Average loss: 2.2901, Accuracy: 593/5000 (12%)\n",
      "[epoch 3] loss: 2.0778034\n",
      "Test set: Average loss: 2.3224, Accuracy: 567/5000 (11%)\n",
      "[epoch 4] loss: 1.9026198\n",
      "Test set: Average loss: 2.4761, Accuracy: 601/5000 (12%)\n",
      "[epoch 5] loss: 1.7393852\n",
      "Test set: Average loss: 2.6106, Accuracy: 720/5000 (14%)\n",
      "[epoch 6] loss: 1.5694400\n",
      "Test set: Average loss: 2.6670, Accuracy: 760/5000 (15%)\n",
      "[epoch 7] loss: 1.3843726\n",
      "Test set: Average loss: 2.7236, Accuracy: 800/5000 (16%)\n",
      "[epoch 8] loss: 1.2281659\n",
      "Test set: Average loss: 2.7297, Accuracy: 817/5000 (16%)\n",
      "[epoch 9] loss: 1.0375637\n",
      "Test set: Average loss: 2.7417, Accuracy: 815/5000 (16%)\n",
      "[epoch 10] loss: 0.8520054\n",
      "Test set: Average loss: 2.8170, Accuracy: 821/5000 (16%)\n",
      "[epoch 11] loss: 0.7073625\n",
      "Test set: Average loss: 2.9421, Accuracy: 820/5000 (16%)\n",
      "[epoch 12] loss: 0.5674040\n",
      "Test set: Average loss: 3.1493, Accuracy: 775/5000 (16%)\n",
      "[epoch 13] loss: 0.4281922\n",
      "Test set: Average loss: 3.4695, Accuracy: 771/5000 (15%)\n",
      "[epoch 14] loss: 0.3063584\n",
      "Test set: Average loss: 3.8761, Accuracy: 772/5000 (15%)\n",
      "[epoch 15] loss: 0.2115021\n",
      "Test set: Average loss: 4.3156, Accuracy: 794/5000 (16%)\n",
      "[epoch 16] loss: 0.1459650\n",
      "Test set: Average loss: 4.7198, Accuracy: 797/5000 (16%)\n",
      "[epoch 17] loss: 0.1012032\n",
      "Test set: Average loss: 5.0498, Accuracy: 804/5000 (16%)\n",
      "[epoch 18] loss: 0.0649030\n",
      "Test set: Average loss: 5.3403, Accuracy: 791/5000 (16%)\n",
      "[epoch 19] loss: 0.0405789\n",
      "Test set: Average loss: 5.6327, Accuracy: 799/5000 (16%)\n",
      "[epoch 20] loss: 0.0276703\n",
      "Test set: Average loss: 5.9376, Accuracy: 792/5000 (16%)\n",
      "[epoch 21] loss: 0.0195967\n",
      "Test set: Average loss: 6.2519, Accuracy: 791/5000 (16%)\n",
      "[epoch 22] loss: 0.0135108\n",
      "Test set: Average loss: 6.5694, Accuracy: 787/5000 (16%)\n",
      "[epoch 23] loss: 0.0089789\n",
      "Test set: Average loss: 6.8829, Accuracy: 789/5000 (16%)\n",
      "[epoch 24] loss: 0.0059216\n",
      "Test set: Average loss: 7.1857, Accuracy: 797/5000 (16%)\n",
      "[epoch 25] loss: 0.0040030\n",
      "Test set: Average loss: 7.4721, Accuracy: 797/5000 (16%)\n",
      "[epoch 26] loss: 0.0028244\n",
      "Test set: Average loss: 7.7386, Accuracy: 786/5000 (16%)\n",
      "[epoch 27] loss: 0.0020933\n",
      "Test set: Average loss: 7.9834, Accuracy: 780/5000 (16%)\n",
      "[epoch 28] loss: 0.0016280\n",
      "Test set: Average loss: 8.2059, Accuracy: 775/5000 (16%)\n",
      "[epoch 29] loss: 0.0013235\n",
      "Test set: Average loss: 8.4063, Accuracy: 772/5000 (15%)\n",
      "[epoch 30] loss: 0.0011172\n",
      "Test set: Average loss: 8.5852, Accuracy: 769/5000 (15%)\n",
      "[epoch 31] loss: 0.0009728\n",
      "Test set: Average loss: 8.7436, Accuracy: 770/5000 (15%)\n",
      "[epoch 32] loss: 0.0008667\n",
      "Test set: Average loss: 8.8828, Accuracy: 768/5000 (15%)\n",
      "[epoch 33] loss: 0.0007835\n",
      "Test set: Average loss: 9.0041, Accuracy: 768/5000 (15%)\n",
      "[epoch 34] loss: 0.0007121\n",
      "Test set: Average loss: 9.1091, Accuracy: 762/5000 (15%)\n",
      "[epoch 35] loss: 0.0006467\n",
      "Test set: Average loss: 9.1993, Accuracy: 759/5000 (15%)\n",
      "[epoch 36] loss: 0.0005851\n",
      "Test set: Average loss: 9.2767, Accuracy: 760/5000 (15%)\n",
      "[epoch 37] loss: 0.0005271\n",
      "Test set: Average loss: 9.3428, Accuracy: 761/5000 (15%)\n",
      "[epoch 38] loss: 0.0004737\n",
      "Test set: Average loss: 9.3994, Accuracy: 763/5000 (15%)\n",
      "[epoch 39] loss: 0.0004260\n",
      "Test set: Average loss: 9.4480, Accuracy: 762/5000 (15%)\n",
      "[epoch 40] loss: 0.0003844\n",
      "Test set: Average loss: 9.4900, Accuracy: 759/5000 (15%)\n",
      "[epoch 41] loss: 0.0003489\n",
      "Test set: Average loss: 9.5263, Accuracy: 757/5000 (15%)\n",
      "[epoch 42] loss: 0.0003186\n",
      "Test set: Average loss: 9.5580, Accuracy: 757/5000 (15%)\n",
      "[epoch 43] loss: 0.0002930\n",
      "Test set: Average loss: 9.5857, Accuracy: 759/5000 (15%)\n",
      "[epoch 44] loss: 0.0002710\n",
      "Test set: Average loss: 9.6103, Accuracy: 763/5000 (15%)\n",
      "[epoch 45] loss: 0.0002522\n",
      "Test set: Average loss: 9.6320, Accuracy: 760/5000 (15%)\n",
      "[epoch 46] loss: 0.0002357\n",
      "Test set: Average loss: 9.6514, Accuracy: 758/5000 (15%)\n",
      "[epoch 47] loss: 0.0002214\n",
      "Test set: Average loss: 9.6688, Accuracy: 759/5000 (15%)\n",
      "[epoch 48] loss: 0.0002088\n",
      "Test set: Average loss: 9.6845, Accuracy: 759/5000 (15%)\n",
      "[epoch 49] loss: 0.0001975\n",
      "Test set: Average loss: 9.6987, Accuracy: 759/5000 (15%)\n",
      "[epoch 50] loss: 0.0001872\n",
      "Test set: Average loss: 9.7117, Accuracy: 759/5000 (15%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8170, Accuracy: 821/5000 (16%)\n",
      "Test\n",
      "Test set: Average loss: 2.7464, Accuracy: 1845/10000 (18%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3048, Accuracy: 324/5000 (6%)\n",
      "[epoch 1] loss: 2.3067505\n",
      "Test set: Average loss: 2.2932, Accuracy: 819/5000 (16%)\n",
      "[epoch 2] loss: 2.2185414\n",
      "Test set: Average loss: 2.2857, Accuracy: 766/5000 (15%)\n",
      "[epoch 3] loss: 2.0912490\n",
      "Test set: Average loss: 2.3082, Accuracy: 724/5000 (14%)\n",
      "[epoch 4] loss: 1.9190732\n",
      "Test set: Average loss: 2.4336, Accuracy: 729/5000 (15%)\n",
      "[epoch 5] loss: 1.7531095\n",
      "Test set: Average loss: 2.5622, Accuracy: 844/5000 (17%)\n",
      "[epoch 6] loss: 1.5852131\n",
      "Test set: Average loss: 2.6343, Accuracy: 959/5000 (19%)\n",
      "[epoch 7] loss: 1.4061345\n",
      "Test set: Average loss: 2.7138, Accuracy: 918/5000 (18%)\n",
      "[epoch 8] loss: 1.2415400\n",
      "Test set: Average loss: 2.7624, Accuracy: 930/5000 (19%)\n",
      "[epoch 9] loss: 1.0316734\n",
      "Test set: Average loss: 2.8321, Accuracy: 936/5000 (19%)\n",
      "[epoch 10] loss: 0.8303837\n",
      "Test set: Average loss: 2.9217, Accuracy: 986/5000 (20%)\n",
      "[epoch 11] loss: 0.6690907\n",
      "Test set: Average loss: 2.9983, Accuracy: 1031/5000 (21%)\n",
      "[epoch 12] loss: 0.5184100\n",
      "Test set: Average loss: 3.1173, Accuracy: 975/5000 (20%)\n",
      "[epoch 13] loss: 0.3936958\n",
      "Test set: Average loss: 3.3039, Accuracy: 963/5000 (19%)\n",
      "[epoch 14] loss: 0.2874946\n",
      "Test set: Average loss: 3.5476, Accuracy: 949/5000 (19%)\n",
      "[epoch 15] loss: 0.1984934\n",
      "Test set: Average loss: 3.8509, Accuracy: 947/5000 (19%)\n",
      "[epoch 16] loss: 0.1378620\n",
      "Test set: Average loss: 4.1883, Accuracy: 937/5000 (19%)\n",
      "[epoch 17] loss: 0.0985950\n",
      "Test set: Average loss: 4.5176, Accuracy: 911/5000 (18%)\n",
      "[epoch 18] loss: 0.0713247\n",
      "Test set: Average loss: 4.8153, Accuracy: 896/5000 (18%)\n",
      "[epoch 19] loss: 0.0515855\n",
      "Test set: Average loss: 5.0795, Accuracy: 896/5000 (18%)\n",
      "[epoch 20] loss: 0.0366258\n",
      "Test set: Average loss: 5.3193, Accuracy: 882/5000 (18%)\n",
      "[epoch 21] loss: 0.0254443\n",
      "Test set: Average loss: 5.5430, Accuracy: 871/5000 (17%)\n",
      "[epoch 22] loss: 0.0174453\n",
      "Test set: Average loss: 5.7544, Accuracy: 877/5000 (18%)\n",
      "[epoch 23] loss: 0.0119355\n",
      "Test set: Average loss: 5.9543, Accuracy: 862/5000 (17%)\n",
      "[epoch 24] loss: 0.0082662\n",
      "Test set: Average loss: 6.1418, Accuracy: 859/5000 (17%)\n",
      "[epoch 25] loss: 0.0058645\n",
      "Test set: Average loss: 6.3161, Accuracy: 863/5000 (17%)\n",
      "[epoch 26] loss: 0.0042850\n",
      "Test set: Average loss: 6.4766, Accuracy: 858/5000 (17%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27] loss: 0.0032226\n",
      "Test set: Average loss: 6.6232, Accuracy: 855/5000 (17%)\n",
      "[epoch 28] loss: 0.0024881\n",
      "Test set: Average loss: 6.7565, Accuracy: 863/5000 (17%)\n",
      "[epoch 29] loss: 0.0019659\n",
      "Test set: Average loss: 6.8770, Accuracy: 865/5000 (17%)\n",
      "[epoch 30] loss: 0.0015863\n",
      "Test set: Average loss: 6.9858, Accuracy: 853/5000 (17%)\n",
      "[epoch 31] loss: 0.0013050\n",
      "Test set: Average loss: 7.0838, Accuracy: 855/5000 (17%)\n",
      "[epoch 32] loss: 0.0010932\n",
      "Test set: Average loss: 7.1722, Accuracy: 852/5000 (17%)\n",
      "[epoch 33] loss: 0.0009317\n",
      "Test set: Average loss: 7.2518, Accuracy: 854/5000 (17%)\n",
      "[epoch 34] loss: 0.0008064\n",
      "Test set: Average loss: 7.3236, Accuracy: 851/5000 (17%)\n",
      "[epoch 35] loss: 0.0007081\n",
      "Test set: Average loss: 7.3885, Accuracy: 851/5000 (17%)\n",
      "[epoch 36] loss: 0.0006298\n",
      "Test set: Average loss: 7.4473, Accuracy: 847/5000 (17%)\n",
      "[epoch 37] loss: 0.0005664\n",
      "Test set: Average loss: 7.5004, Accuracy: 845/5000 (17%)\n",
      "[epoch 38] loss: 0.0005147\n",
      "Test set: Average loss: 7.5487, Accuracy: 845/5000 (17%)\n",
      "[epoch 39] loss: 0.0004717\n",
      "Test set: Average loss: 7.5926, Accuracy: 845/5000 (17%)\n",
      "[epoch 40] loss: 0.0004357\n",
      "Test set: Average loss: 7.6325, Accuracy: 840/5000 (17%)\n",
      "[epoch 41] loss: 0.0004049\n",
      "Test set: Average loss: 7.6689, Accuracy: 838/5000 (17%)\n",
      "[epoch 42] loss: 0.0003785\n",
      "Test set: Average loss: 7.7021, Accuracy: 843/5000 (17%)\n",
      "[epoch 43] loss: 0.0003552\n",
      "Test set: Average loss: 7.7324, Accuracy: 841/5000 (17%)\n",
      "[epoch 44] loss: 0.0003346\n",
      "Test set: Average loss: 7.7602, Accuracy: 841/5000 (17%)\n",
      "[epoch 45] loss: 0.0003162\n",
      "Test set: Average loss: 7.7856, Accuracy: 838/5000 (17%)\n",
      "[epoch 46] loss: 0.0002994\n",
      "Test set: Average loss: 7.8089, Accuracy: 840/5000 (17%)\n",
      "[epoch 47] loss: 0.0002843\n",
      "Test set: Average loss: 7.8303, Accuracy: 839/5000 (17%)\n",
      "[epoch 48] loss: 0.0002703\n",
      "Test set: Average loss: 7.8499, Accuracy: 839/5000 (17%)\n",
      "[epoch 49] loss: 0.0002576\n",
      "Test set: Average loss: 7.8680, Accuracy: 837/5000 (17%)\n",
      "[epoch 50] loss: 0.0002457\n",
      "Test set: Average loss: 7.8846, Accuracy: 835/5000 (17%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9983, Accuracy: 1031/5000 (21%)\n",
      "Test\n",
      "Test set: Average loss: 2.9917, Accuracy: 2051/10000 (21%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3054, Accuracy: 493/5000 (10%)\n",
      "[epoch 1] loss: 2.2994614\n",
      "Test set: Average loss: 2.2979, Accuracy: 525/5000 (10%)\n",
      "[epoch 2] loss: 2.2154000\n",
      "Test set: Average loss: 2.2983, Accuracy: 525/5000 (10%)\n",
      "[epoch 3] loss: 2.1003423\n",
      "Test set: Average loss: 2.3387, Accuracy: 525/5000 (10%)\n",
      "[epoch 4] loss: 1.9425446\n",
      "Test set: Average loss: 2.5406, Accuracy: 525/5000 (10%)\n",
      "[epoch 5] loss: 1.8207927\n",
      "Test set: Average loss: 2.7096, Accuracy: 531/5000 (11%)\n",
      "[epoch 6] loss: 1.7218261\n",
      "Test set: Average loss: 2.6508, Accuracy: 720/5000 (14%)\n",
      "[epoch 7] loss: 1.5402297\n",
      "Test set: Average loss: 2.5414, Accuracy: 862/5000 (17%)\n",
      "[epoch 8] loss: 1.3457267\n",
      "Test set: Average loss: 2.4488, Accuracy: 921/5000 (18%)\n",
      "[epoch 9] loss: 1.1425126\n",
      "Test set: Average loss: 2.4188, Accuracy: 947/5000 (19%)\n",
      "[epoch 10] loss: 0.9471791\n",
      "Test set: Average loss: 2.4905, Accuracy: 932/5000 (19%)\n",
      "[epoch 11] loss: 0.7695820\n",
      "Test set: Average loss: 2.6439, Accuracy: 924/5000 (18%)\n",
      "[epoch 12] loss: 0.5859632\n",
      "Test set: Average loss: 2.8815, Accuracy: 954/5000 (19%)\n",
      "[epoch 13] loss: 0.4140300\n",
      "Test set: Average loss: 3.2244, Accuracy: 935/5000 (19%)\n",
      "[epoch 14] loss: 0.2880290\n",
      "Test set: Average loss: 3.6239, Accuracy: 874/5000 (17%)\n",
      "[epoch 15] loss: 0.1943958\n",
      "Test set: Average loss: 4.0095, Accuracy: 852/5000 (17%)\n",
      "[epoch 16] loss: 0.1295785\n",
      "Test set: Average loss: 4.2898, Accuracy: 865/5000 (17%)\n",
      "[epoch 17] loss: 0.0798227\n",
      "Test set: Average loss: 4.5023, Accuracy: 880/5000 (18%)\n",
      "[epoch 18] loss: 0.0486833\n",
      "Test set: Average loss: 4.7058, Accuracy: 909/5000 (18%)\n",
      "[epoch 19] loss: 0.0314851\n",
      "Test set: Average loss: 4.9132, Accuracy: 919/5000 (18%)\n",
      "[epoch 20] loss: 0.0210228\n",
      "Test set: Average loss: 5.1197, Accuracy: 929/5000 (19%)\n",
      "[epoch 21] loss: 0.0140983\n",
      "Test set: Average loss: 5.3224, Accuracy: 920/5000 (18%)\n",
      "[epoch 22] loss: 0.0094499\n",
      "Test set: Average loss: 5.5205, Accuracy: 921/5000 (18%)\n",
      "[epoch 23] loss: 0.0063390\n",
      "Test set: Average loss: 5.7135, Accuracy: 924/5000 (18%)\n",
      "[epoch 24] loss: 0.0042672\n",
      "Test set: Average loss: 5.9000, Accuracy: 916/5000 (18%)\n",
      "[epoch 25] loss: 0.0029139\n",
      "Test set: Average loss: 6.0786, Accuracy: 919/5000 (18%)\n",
      "[epoch 26] loss: 0.0020596\n",
      "Test set: Average loss: 6.2477, Accuracy: 920/5000 (18%)\n",
      "[epoch 27] loss: 0.0015353\n",
      "Test set: Average loss: 6.4058, Accuracy: 918/5000 (18%)\n",
      "[epoch 28] loss: 0.0012185\n",
      "Test set: Average loss: 6.5518, Accuracy: 909/5000 (18%)\n",
      "[epoch 29] loss: 0.0010234\n",
      "Test set: Average loss: 6.6849, Accuracy: 903/5000 (18%)\n",
      "[epoch 30] loss: 0.0008927\n",
      "Test set: Average loss: 6.8047, Accuracy: 899/5000 (18%)\n",
      "[epoch 31] loss: 0.0007895\n",
      "Test set: Average loss: 6.9114, Accuracy: 890/5000 (18%)\n",
      "[epoch 32] loss: 0.0006942\n",
      "Test set: Average loss: 7.0059, Accuracy: 890/5000 (18%)\n",
      "[epoch 33] loss: 0.0006020\n",
      "Test set: Average loss: 7.0893, Accuracy: 885/5000 (18%)\n",
      "[epoch 34] loss: 0.0005153\n",
      "Test set: Average loss: 7.1732, Accuracy: 883/5000 (18%)\n",
      "[epoch 35] loss: 0.0004387\n",
      "Test set: Average loss: 7.2286, Accuracy: 886/5000 (18%)\n",
      "[epoch 36] loss: 0.0003742\n",
      "Test set: Average loss: 7.2871, Accuracy: 887/5000 (18%)\n",
      "[epoch 37] loss: 0.0003220\n",
      "Test set: Average loss: 7.3397, Accuracy: 887/5000 (18%)\n",
      "[epoch 38] loss: 0.0002805\n",
      "Test set: Average loss: 7.3872, Accuracy: 888/5000 (18%)\n",
      "[epoch 39] loss: 0.0002479\n",
      "Test set: Average loss: 7.4304, Accuracy: 889/5000 (18%)\n",
      "[epoch 40] loss: 0.0002218\n",
      "Test set: Average loss: 7.4697, Accuracy: 892/5000 (18%)\n",
      "[epoch 41] loss: 0.0002010\n",
      "Test set: Average loss: 7.5058, Accuracy: 893/5000 (18%)\n",
      "[epoch 42] loss: 0.0001839\n",
      "Test set: Average loss: 7.5389, Accuracy: 893/5000 (18%)\n",
      "[epoch 43] loss: 0.0001699\n",
      "Test set: Average loss: 7.5695, Accuracy: 895/5000 (18%)\n",
      "[epoch 44] loss: 0.0001581\n",
      "Test set: Average loss: 7.5978, Accuracy: 896/5000 (18%)\n",
      "[epoch 45] loss: 0.0001482\n",
      "Test set: Average loss: 7.6240, Accuracy: 898/5000 (18%)\n",
      "[epoch 46] loss: 0.0001394\n",
      "Test set: Average loss: 7.6484, Accuracy: 899/5000 (18%)\n",
      "[epoch 47] loss: 0.0001321\n",
      "Test set: Average loss: 7.6711, Accuracy: 900/5000 (18%)\n",
      "[epoch 48] loss: 0.0001255\n",
      "Test set: Average loss: 7.6922, Accuracy: 900/5000 (18%)\n",
      "[epoch 49] loss: 0.0001197\n",
      "Test set: Average loss: 7.7120, Accuracy: 902/5000 (18%)\n",
      "[epoch 50] loss: 0.0001147\n",
      "Test set: Average loss: 7.7305, Accuracy: 901/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8815, Accuracy: 954/5000 (19%)\n",
      "Test\n",
      "Test set: Average loss: 2.8847, Accuracy: 1862/10000 (19%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 534/5000 (11%)\n",
      "[epoch 1] loss: 2.2827041\n",
      "Test set: Average loss: 2.2750, Accuracy: 683/5000 (14%)\n",
      "[epoch 2] loss: 2.1422309\n",
      "Test set: Average loss: 2.2844, Accuracy: 725/5000 (14%)\n",
      "[epoch 3] loss: 1.8606342\n",
      "Test set: Average loss: 2.4471, Accuracy: 919/5000 (18%)\n",
      "[epoch 4] loss: 1.7745509\n",
      "Test set: Average loss: 2.5780, Accuracy: 1018/5000 (20%)\n",
      "[epoch 5] loss: 1.4546029\n",
      "Test set: Average loss: 2.4677, Accuracy: 1096/5000 (22%)\n",
      "[epoch 6] loss: 1.3327134\n",
      "Test set: Average loss: 2.4293, Accuracy: 1069/5000 (21%)\n",
      "[epoch 7] loss: 1.1224930\n",
      "Test set: Average loss: 2.4072, Accuracy: 1086/5000 (22%)\n",
      "[epoch 8] loss: 0.9372773\n",
      "Test set: Average loss: 2.4326, Accuracy: 1115/5000 (22%)\n",
      "[epoch 9] loss: 0.7352289\n",
      "Test set: Average loss: 2.6013, Accuracy: 1128/5000 (23%)\n",
      "[epoch 10] loss: 0.5440719\n",
      "Test set: Average loss: 2.8405, Accuracy: 1115/5000 (22%)\n",
      "[epoch 11] loss: 0.4479063\n",
      "Test set: Average loss: 3.0951, Accuracy: 1128/5000 (23%)\n",
      "[epoch 12] loss: 0.3533217\n",
      "Test set: Average loss: 3.2933, Accuracy: 1120/5000 (22%)\n",
      "[epoch 13] loss: 0.2240887\n",
      "Test set: Average loss: 3.4641, Accuracy: 1156/5000 (23%)\n",
      "[epoch 14] loss: 0.1614131\n",
      "Test set: Average loss: 3.6973, Accuracy: 1183/5000 (24%)\n",
      "[epoch 15] loss: 0.1036267\n",
      "Test set: Average loss: 3.9423, Accuracy: 1167/5000 (23%)\n",
      "[epoch 16] loss: 0.0612388\n",
      "Test set: Average loss: 4.1955, Accuracy: 1161/5000 (23%)\n",
      "[epoch 17] loss: 0.0382700\n",
      "Test set: Average loss: 4.4491, Accuracy: 1143/5000 (23%)\n",
      "[epoch 18] loss: 0.0302921\n",
      "Test set: Average loss: 4.5845, Accuracy: 1144/5000 (23%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] loss: 0.0170357\n",
      "Test set: Average loss: 4.6299, Accuracy: 1209/5000 (24%)\n",
      "[epoch 20] loss: 0.0112788\n",
      "Test set: Average loss: 4.6805, Accuracy: 1213/5000 (24%)\n",
      "[epoch 21] loss: 0.0090632\n",
      "Test set: Average loss: 4.7582, Accuracy: 1246/5000 (25%)\n",
      "[epoch 22] loss: 0.0081850\n",
      "Test set: Average loss: 4.8490, Accuracy: 1231/5000 (25%)\n",
      "[epoch 23] loss: 0.0059580\n",
      "Test set: Average loss: 4.9413, Accuracy: 1226/5000 (25%)\n",
      "[epoch 24] loss: 0.0046117\n",
      "Test set: Average loss: 5.0289, Accuracy: 1217/5000 (24%)\n",
      "[epoch 25] loss: 0.0039706\n",
      "Test set: Average loss: 5.1080, Accuracy: 1214/5000 (24%)\n",
      "[epoch 26] loss: 0.0034053\n",
      "Test set: Average loss: 5.1786, Accuracy: 1209/5000 (24%)\n",
      "[epoch 27] loss: 0.0024258\n",
      "Test set: Average loss: 5.2408, Accuracy: 1195/5000 (24%)\n",
      "[epoch 28] loss: 0.0024105\n",
      "Test set: Average loss: 5.2957, Accuracy: 1184/5000 (24%)\n",
      "[epoch 29] loss: 0.0019077\n",
      "Test set: Average loss: 5.3410, Accuracy: 1179/5000 (24%)\n",
      "[epoch 30] loss: 0.0017580\n",
      "Test set: Average loss: 5.3789, Accuracy: 1180/5000 (24%)\n",
      "[epoch 31] loss: 0.0018199\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.4105, Accuracy: 1172/5000 (23%)\n",
      "[epoch 32] loss: 0.0015818\n",
      "Test set: Average loss: 5.4129, Accuracy: 1174/5000 (23%)\n",
      "[epoch 33] loss: 0.0015983\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.4150, Accuracy: 1176/5000 (24%)\n",
      "[epoch 34] loss: 0.0015735\n",
      "Test set: Average loss: 5.4151, Accuracy: 1177/5000 (24%)\n",
      "[epoch 35] loss: 0.0015174\n",
      "Test set: Average loss: 5.4152, Accuracy: 1177/5000 (24%)\n",
      "[epoch 36] loss: 0.0014952\n",
      "Test set: Average loss: 5.4153, Accuracy: 1177/5000 (24%)\n",
      "[epoch 37] loss: 0.0016511\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 38] loss: 0.0015902\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 39] loss: 0.0015362\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 40] loss: 0.0015268\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 41] loss: 0.0014620\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 42] loss: 0.0015720\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 43] loss: 0.0015141\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 44] loss: 0.0016782\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 45] loss: 0.0015485\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 46] loss: 0.0015430\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 47] loss: 0.0015963\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 48] loss: 0.0016117\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 49] loss: 0.0015024\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "[epoch 50] loss: 0.0016451\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 5.4154, Accuracy: 1176/5000 (24%)\n",
      "Validation:\n",
      "Test set: Average loss: 4.7582, Accuracy: 1246/5000 (25%)\n",
      "Test\n",
      "Test set: Average loss: 4.7169, Accuracy: 2462/10000 (25%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 527/5000 (11%)\n",
      "[epoch 1] loss: 2.3171308\n",
      "Test set: Average loss: 2.2875, Accuracy: 570/5000 (11%)\n",
      "[epoch 2] loss: 2.1981722\n",
      "Test set: Average loss: 2.2649, Accuracy: 632/5000 (13%)\n",
      "[epoch 3] loss: 2.0578240\n",
      "Test set: Average loss: 2.2826, Accuracy: 724/5000 (14%)\n",
      "[epoch 4] loss: 1.8030075\n",
      "Test set: Average loss: 2.2495, Accuracy: 1063/5000 (21%)\n",
      "[epoch 5] loss: 1.5806578\n",
      "Test set: Average loss: 2.3150, Accuracy: 1032/5000 (21%)\n",
      "[epoch 6] loss: 1.4266162\n",
      "Test set: Average loss: 2.3651, Accuracy: 1094/5000 (22%)\n",
      "[epoch 7] loss: 1.2122998\n",
      "Test set: Average loss: 2.4301, Accuracy: 1099/5000 (22%)\n",
      "[epoch 8] loss: 1.0287301\n",
      "Test set: Average loss: 2.3719, Accuracy: 1197/5000 (24%)\n",
      "[epoch 9] loss: 0.8577332\n",
      "Test set: Average loss: 2.4302, Accuracy: 1208/5000 (24%)\n",
      "[epoch 10] loss: 0.6544004\n",
      "Test set: Average loss: 2.6524, Accuracy: 1188/5000 (24%)\n",
      "[epoch 11] loss: 0.5207252\n",
      "Test set: Average loss: 2.8009, Accuracy: 1197/5000 (24%)\n",
      "[epoch 12] loss: 0.4398980\n",
      "Test set: Average loss: 2.9510, Accuracy: 1155/5000 (23%)\n",
      "[epoch 13] loss: 0.2990177\n",
      "Test set: Average loss: 3.0517, Accuracy: 1108/5000 (22%)\n",
      "[epoch 14] loss: 0.2041959\n",
      "Test set: Average loss: 3.1901, Accuracy: 1108/5000 (22%)\n",
      "[epoch 15] loss: 0.1436499\n",
      "Test set: Average loss: 3.4327, Accuracy: 1128/5000 (23%)\n",
      "[epoch 16] loss: 0.1103251\n",
      "Test set: Average loss: 3.6221, Accuracy: 1144/5000 (23%)\n",
      "[epoch 17] loss: 0.0635524\n",
      "Test set: Average loss: 3.8037, Accuracy: 1131/5000 (23%)\n",
      "[epoch 18] loss: 0.0400558\n",
      "Test set: Average loss: 4.0029, Accuracy: 1135/5000 (23%)\n",
      "[epoch 19] loss: 0.0338222\n",
      "Test set: Average loss: 4.1847, Accuracy: 1130/5000 (23%)\n",
      "[epoch 20] loss: 0.0235550\n",
      "Test set: Average loss: 4.3403, Accuracy: 1105/5000 (22%)\n",
      "[epoch 21] loss: 0.0165256\n",
      "Test set: Average loss: 4.4843, Accuracy: 1090/5000 (22%)\n",
      "[epoch 22] loss: 0.0115782\n",
      "Test set: Average loss: 4.6215, Accuracy: 1071/5000 (21%)\n",
      "[epoch 23] loss: 0.0074211\n",
      "Test set: Average loss: 4.7488, Accuracy: 1072/5000 (21%)\n",
      "[epoch 24] loss: 0.0057601\n",
      "Test set: Average loss: 4.8654, Accuracy: 1050/5000 (21%)\n",
      "[epoch 25] loss: 0.0049498\n",
      "Test set: Average loss: 4.9677, Accuracy: 1038/5000 (21%)\n",
      "[epoch 26] loss: 0.0043581\n",
      "Test set: Average loss: 5.0555, Accuracy: 1021/5000 (20%)\n",
      "[epoch 27] loss: 0.0037702\n",
      "Test set: Average loss: 5.1257, Accuracy: 1015/5000 (20%)\n",
      "[epoch 28] loss: 0.0034744\n",
      "Test set: Average loss: 5.1791, Accuracy: 1020/5000 (20%)\n",
      "[epoch 29] loss: 0.0029539\n",
      "Test set: Average loss: 5.2160, Accuracy: 1016/5000 (20%)\n",
      "[epoch 30] loss: 0.0026262\n",
      "Test set: Average loss: 5.2431, Accuracy: 1021/5000 (20%)\n",
      "[epoch 31] loss: 0.0022257\n",
      "Test set: Average loss: 5.2623, Accuracy: 1027/5000 (21%)\n",
      "[epoch 32] loss: 0.0020738\n",
      "Test set: Average loss: 5.2782, Accuracy: 1029/5000 (21%)\n",
      "[epoch 33] loss: 0.0017354\n",
      "Test set: Average loss: 5.2924, Accuracy: 1028/5000 (21%)\n",
      "[epoch 34] loss: 0.0016758\n",
      "Test set: Average loss: 5.3053, Accuracy: 1024/5000 (20%)\n",
      "[epoch 35] loss: 0.0015410\n",
      "Test set: Average loss: 5.3174, Accuracy: 1036/5000 (21%)\n",
      "[epoch 36] loss: 0.0015029\n",
      "Test set: Average loss: 5.3282, Accuracy: 1038/5000 (21%)\n",
      "[epoch 37] loss: 0.0014281\n",
      "Test set: Average loss: 5.3387, Accuracy: 1048/5000 (21%)\n",
      "[epoch 38] loss: 0.0012645\n",
      "Test set: Average loss: 5.3487, Accuracy: 1049/5000 (21%)\n",
      "[epoch 39] loss: 0.0012922\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 5.3586, Accuracy: 1047/5000 (21%)\n",
      "[epoch 40] loss: 0.0012185\n",
      "Test set: Average loss: 5.3596, Accuracy: 1046/5000 (21%)\n",
      "[epoch 41] loss: 0.0012751\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 5.3607, Accuracy: 1046/5000 (21%)\n",
      "[epoch 42] loss: 0.0012532\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 43] loss: 0.0012480\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 44] loss: 0.0012156\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 45] loss: 0.0012324\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 46] loss: 0.0011136\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 47] loss: 0.0012058\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 48] loss: 0.0011898\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 49] loss: 0.0012445\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "[epoch 50] loss: 0.0012488\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 5.3608, Accuracy: 1046/5000 (21%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4302, Accuracy: 1208/5000 (24%)\n",
      "Test\n",
      "Test set: Average loss: 2.3928, Accuracy: 2484/10000 (25%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 449/5000 (9%)\n",
      "[epoch 1] loss: 2.2796789\n",
      "Test set: Average loss: 2.2746, Accuracy: 676/5000 (14%)\n",
      "[epoch 2] loss: 2.1206574\n",
      "Test set: Average loss: 2.3155, Accuracy: 661/5000 (13%)\n",
      "[epoch 3] loss: 1.8313761\n",
      "Test set: Average loss: 2.4265, Accuracy: 795/5000 (16%)\n",
      "[epoch 4] loss: 1.7032738\n",
      "Test set: Average loss: 2.3918, Accuracy: 975/5000 (20%)\n",
      "[epoch 5] loss: 1.5057659\n",
      "Test set: Average loss: 2.4193, Accuracy: 979/5000 (20%)\n",
      "[epoch 6] loss: 1.3003474\n",
      "Test set: Average loss: 2.4745, Accuracy: 1029/5000 (21%)\n",
      "[epoch 7] loss: 1.1101847\n",
      "Test set: Average loss: 2.4497, Accuracy: 1097/5000 (22%)\n",
      "[epoch 8] loss: 0.8891451\n",
      "Test set: Average loss: 2.5184, Accuracy: 1125/5000 (22%)\n",
      "[epoch 9] loss: 0.7132035\n",
      "Test set: Average loss: 2.7475, Accuracy: 1079/5000 (22%)\n",
      "[epoch 10] loss: 0.5207940\n",
      "Test set: Average loss: 3.0712, Accuracy: 1050/5000 (21%)\n",
      "[epoch 11] loss: 0.4390455\n",
      "Test set: Average loss: 3.0268, Accuracy: 1099/5000 (22%)\n",
      "[epoch 12] loss: 0.3066591\n",
      "Test set: Average loss: 3.0206, Accuracy: 1154/5000 (23%)\n",
      "[epoch 13] loss: 0.2325028\n",
      "Test set: Average loss: 3.1881, Accuracy: 1132/5000 (23%)\n",
      "[epoch 14] loss: 0.1983384\n",
      "Test set: Average loss: 3.4853, Accuracy: 1093/5000 (22%)\n",
      "[epoch 15] loss: 0.1445442\n",
      "Test set: Average loss: 3.8444, Accuracy: 1041/5000 (21%)\n",
      "[epoch 16] loss: 0.0932335\n",
      "Test set: Average loss: 4.1377, Accuracy: 1036/5000 (21%)\n",
      "[epoch 17] loss: 0.0953844\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.3468, Accuracy: 1040/5000 (21%)\n",
      "[epoch 18] loss: 0.0632827\n",
      "Test set: Average loss: 4.3462, Accuracy: 1040/5000 (21%)\n",
      "[epoch 19] loss: 0.0551327\n",
      "Test set: Average loss: 4.3251, Accuracy: 1057/5000 (21%)\n",
      "[epoch 20] loss: 0.0517082\n",
      "Test set: Average loss: 4.2984, Accuracy: 1066/5000 (21%)\n",
      "[epoch 21] loss: 0.0419353\n",
      "Test set: Average loss: 4.2683, Accuracy: 1074/5000 (21%)\n",
      "[epoch 22] loss: 0.0384146\n",
      "Test set: Average loss: 4.2406, Accuracy: 1063/5000 (21%)\n",
      "[epoch 23] loss: 0.0307991\n",
      "Test set: Average loss: 4.2187, Accuracy: 1065/5000 (21%)\n",
      "[epoch 24] loss: 0.0340840\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.2002, Accuracy: 1079/5000 (22%)\n",
      "[epoch 25] loss: 0.0322955\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.1989, Accuracy: 1078/5000 (22%)\n",
      "[epoch 26] loss: 0.0325818\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 27] loss: 0.0309932\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 28] loss: 0.0319835\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 29] loss: 0.0338965\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 30] loss: 0.0272025\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 31] loss: 0.0284549\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 32] loss: 0.0321259\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 33] loss: 0.0274708\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 34] loss: 0.0297231\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 35] loss: 0.0284755\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 36] loss: 0.0326511\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 37] loss: 0.0330109\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 38] loss: 0.0318941\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 39] loss: 0.0382658\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 40] loss: 0.0298656\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 41] loss: 0.0372474\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 42] loss: 0.0314882\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 43] loss: 0.0321760\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 44] loss: 0.0320807\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 45] loss: 0.0299303\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 46] loss: 0.0337606\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 47] loss: 0.0275555\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 48] loss: 0.0367417\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 49] loss: 0.0289342\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "[epoch 50] loss: 0.0319678\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 4.1988, Accuracy: 1078/5000 (22%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.0206, Accuracy: 1154/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.9625, Accuracy: 2251/10000 (23%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3008, Accuracy: 627/5000 (13%)\n",
      "[epoch 1] loss: 2.2937650\n",
      "Test set: Average loss: 2.2595, Accuracy: 672/5000 (13%)\n",
      "[epoch 2] loss: 2.0462889\n",
      "Test set: Average loss: 2.3205, Accuracy: 831/5000 (17%)\n",
      "[epoch 3] loss: 1.8524283\n",
      "Test set: Average loss: 2.2040, Accuracy: 1152/5000 (23%)\n",
      "[epoch 4] loss: 1.5904453\n",
      "Test set: Average loss: 2.3412, Accuracy: 1100/5000 (22%)\n",
      "[epoch 5] loss: 1.6830252\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4377, Accuracy: 997/5000 (20%)\n",
      "[epoch 6] loss: 1.3946379\n",
      "Test set: Average loss: 2.3860, Accuracy: 1054/5000 (21%)\n",
      "[epoch 7] loss: 1.3947858\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3441, Accuracy: 1096/5000 (22%)\n",
      "[epoch 8] loss: 1.3371824\n",
      "Test set: Average loss: 2.3421, Accuracy: 1112/5000 (22%)\n",
      "[epoch 9] loss: 1.1675340\n",
      "Test set: Average loss: 2.3402, Accuracy: 1113/5000 (22%)\n",
      "[epoch 10] loss: 1.3186944\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3392, Accuracy: 1119/5000 (22%)\n",
      "[epoch 11] loss: 1.3115346\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 12] loss: 1.3045692\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 13] loss: 1.2837341\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 14] loss: 1.3340791\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 15] loss: 1.3403592\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 16] loss: 1.3272743\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 17] loss: 1.3548774\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 18] loss: 1.3149621\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 19] loss: 1.3723938\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 20] loss: 1.3222989\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 21] loss: 1.2090841\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 22] loss: 1.3479761\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 23] loss: 1.2823671\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 24] loss: 1.3706070\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 25] loss: 1.3599115\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 26] loss: 1.2939816\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 27] loss: 1.3281454\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 28] loss: 1.2390711\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 29] loss: 1.4483262\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 30] loss: 1.3655193\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 31] loss: 1.2825798\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 32] loss: 1.3122408\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 33] loss: 1.3898693\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 34] loss: 1.2958296\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 35] loss: 1.3567643\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 36] loss: 1.4632942\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 37] loss: 1.1746373\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 38] loss: 1.3097223\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 39] loss: 2.5405381\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 40] loss: 1.3376648\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 41] loss: 1.3355252\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 42] loss: 1.3438965\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 43] loss: 1.2750969\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 44] loss: 1.2203082\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 45] loss: 1.2758814\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 46] loss: 1.2596768\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 47] loss: 1.2429342\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 48] loss: 1.3944220\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 49] loss: 1.2802806\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "[epoch 50] loss: 1.2964621\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 2.3391, Accuracy: 1120/5000 (22%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2040, Accuracy: 1152/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.1631, Accuracy: 2364/10000 (24%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3011, Accuracy: 722/5000 (14%)\n",
      "[epoch 1] loss: 2.2670782\n",
      "Test set: Average loss: 2.2219, Accuracy: 1080/5000 (22%)\n",
      "[epoch 2] loss: 2.0865282\n",
      "Test set: Average loss: 2.1558, Accuracy: 1201/5000 (24%)\n",
      "[epoch 3] loss: 1.7691150\n",
      "Test set: Average loss: 2.1403, Accuracy: 1140/5000 (23%)\n",
      "[epoch 4] loss: 1.6442318\n",
      "Test set: Average loss: 2.1255, Accuracy: 1153/5000 (23%)\n",
      "[epoch 5] loss: 1.3091215\n",
      "Test set: Average loss: 2.1953, Accuracy: 1316/5000 (26%)\n",
      "[epoch 6] loss: 1.3298089\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0686, Accuracy: 1513/5000 (30%)\n",
      "[epoch 7] loss: 1.8011380\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0590, Accuracy: 1535/5000 (31%)\n",
      "[epoch 8] loss: 1.0978442\n",
      "Test set: Average loss: 2.0568, Accuracy: 1534/5000 (31%)\n",
      "[epoch 9] loss: 1.1418172\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0548, Accuracy: 1534/5000 (31%)\n",
      "[epoch 10] loss: 1.0859076\n",
      "Test set: Average loss: 2.0546, Accuracy: 1535/5000 (31%)\n",
      "[epoch 11] loss: 1.0341826\n",
      "Test set: Average loss: 2.0544, Accuracy: 1536/5000 (31%)\n",
      "[epoch 12] loss: 2.1321909\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 13] loss: 1.0810700\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 14] loss: 1.1286653\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 15] loss: 1.0067834\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 16] loss: 1.0187551\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 17] loss: 1.1618320\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 18] loss: 1.0312504\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 19] loss: 1.1295177\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 20] loss: 1.1756538\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 21] loss: 1.1267995\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 22] loss: 1.0816958\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 23] loss: 1.0878182\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 24] loss: 1.0069055\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 25] loss: 1.0587448\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 26] loss: 1.9269958\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 27] loss: 1.1527358\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 28] loss: 0.9568482\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 29] loss: 1.9560093\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 30] loss: 1.2410207\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 31] loss: 1.1018119\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 32] loss: 1.1826162\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 33] loss: 1.0023976\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 34] loss: 1.0353404\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 35] loss: 2.2606307\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 36] loss: 1.1118570\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 37] loss: 1.0298028\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 38] loss: 1.0612141\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 39] loss: 1.2478714\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 40] loss: 1.1759731\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 41] loss: 1.1685588\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 42] loss: 1.1837215\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 43] loss: 1.2314719\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 44] loss: 1.0668636\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 45] loss: 1.1505638\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 46] loss: 1.0332097\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 47] loss: 1.1207300\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 48] loss: 1.1485898\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 49] loss: 1.2062866\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "[epoch 50] loss: 1.2974323\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.0542, Accuracy: 1535/5000 (31%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0544, Accuracy: 1536/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.0197, Accuracy: 3123/10000 (31%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 435/5000 (9%)\n",
      "[epoch 1] loss: 2.2499973\n",
      "Test set: Average loss: 2.3045, Accuracy: 534/5000 (11%)\n",
      "[epoch 2] loss: 2.0239286\n",
      "Test set: Average loss: 2.3850, Accuracy: 714/5000 (14%)\n",
      "[epoch 3] loss: 1.7907329\n",
      "Test set: Average loss: 2.3092, Accuracy: 976/5000 (20%)\n",
      "[epoch 4] loss: 1.7684970\n",
      "Test set: Average loss: 2.4454, Accuracy: 917/5000 (18%)\n",
      "[epoch 5] loss: 1.5934971\n",
      "Test set: Average loss: 2.3276, Accuracy: 1077/5000 (22%)\n",
      "[epoch 6] loss: 1.2093598\n",
      "Test set: Average loss: 2.3437, Accuracy: 1203/5000 (24%)\n",
      "[epoch 7] loss: 1.0403105\n",
      "Test set: Average loss: 2.4633, Accuracy: 1175/5000 (24%)\n",
      "[epoch 8] loss: 1.0611531\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5812, Accuracy: 1180/5000 (24%)\n",
      "[epoch 9] loss: 0.7898340\n",
      "Test set: Average loss: 2.5594, Accuracy: 1207/5000 (24%)\n",
      "[epoch 10] loss: 0.7646932\n",
      "Test set: Average loss: 2.5395, Accuracy: 1207/5000 (24%)\n",
      "[epoch 11] loss: 0.9194233\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5258, Accuracy: 1211/5000 (24%)\n",
      "[epoch 12] loss: 0.7661543\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5242, Accuracy: 1215/5000 (24%)\n",
      "[epoch 13] loss: 0.7373648\n",
      "Test set: Average loss: 2.5240, Accuracy: 1214/5000 (24%)\n",
      "[epoch 14] loss: 0.8472332\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 15] loss: 0.7109840\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 16] loss: 1.9437730\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 17] loss: 0.7134370\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 18] loss: 0.8546049\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 19] loss: 0.7419896\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 20] loss: 0.8633069\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 21] loss: 0.8708313\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 22] loss: 0.6635356\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 23] loss: 0.7165359\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 24] loss: 0.6689007\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 25] loss: 0.9143068\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 26] loss: 0.6938591\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 27] loss: 0.7837856\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 28] loss: 0.8034428\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 29] loss: 0.8002600\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 30] loss: 0.8501766\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 31] loss: 0.7222279\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 32] loss: 0.7351909\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 33] loss: 0.7408829\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 34] loss: 1.9559238\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 35] loss: 0.9797100\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 36] loss: 0.8348322\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 37] loss: 0.7133179\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 38] loss: 0.8409694\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 39] loss: 0.8649338\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 40] loss: 0.7600079\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 41] loss: 0.7607805\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 42] loss: 0.7340122\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 43] loss: 0.7973158\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 44] loss: 0.8409577\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 45] loss: 1.7556898\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 46] loss: 0.8097311\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 47] loss: 0.8261978\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 48] loss: 0.6772695\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 49] loss: 0.7969945\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "[epoch 50] loss: 0.7831676\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.5239, Accuracy: 1214/5000 (24%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5242, Accuracy: 1215/5000 (24%)\n",
      "Test\n",
      "Test set: Average loss: 2.5409, Accuracy: 2358/10000 (24%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 482/5000 (10%)\n",
      "[epoch 1] loss: 2.2397024\n",
      "Test set: Average loss: 2.1425, Accuracy: 900/5000 (18%)\n",
      "[epoch 2] loss: 1.9738688\n",
      "Test set: Average loss: 1.9652, Accuracy: 1513/5000 (30%)\n",
      "[epoch 3] loss: 1.7339133\n",
      "Test set: Average loss: 1.9030, Accuracy: 1478/5000 (30%)\n",
      "[epoch 4] loss: 1.4869446\n",
      "Test set: Average loss: 1.8382, Accuracy: 1769/5000 (35%)\n",
      "[epoch 5] loss: 1.3078177\n",
      "Test set: Average loss: 1.8502, Accuracy: 1755/5000 (35%)\n",
      "[epoch 6] loss: 1.1414536\n",
      "Test set: Average loss: 1.8535, Accuracy: 1895/5000 (38%)\n",
      "[epoch 7] loss: 0.9532788\n",
      "Test set: Average loss: 1.9108, Accuracy: 1819/5000 (36%)\n",
      "[epoch 8] loss: 0.8371360\n",
      "Test set: Average loss: 2.0198, Accuracy: 1798/5000 (36%)\n",
      "[epoch 9] loss: 0.6854458\n",
      "Test set: Average loss: 2.0689, Accuracy: 1804/5000 (36%)\n",
      "[epoch 10] loss: 0.5351706\n",
      "Test set: Average loss: 2.1256, Accuracy: 1827/5000 (37%)\n",
      "[epoch 11] loss: 0.3953089\n",
      "Test set: Average loss: 2.2662, Accuracy: 1856/5000 (37%)\n",
      "[epoch 12] loss: 0.2925888\n",
      "Test set: Average loss: 2.5093, Accuracy: 1772/5000 (35%)\n",
      "[epoch 13] loss: 0.2185135\n",
      "Test set: Average loss: 2.7430, Accuracy: 1771/5000 (35%)\n",
      "[epoch 14] loss: 0.1846917\n",
      "Test set: Average loss: 2.7232, Accuracy: 1774/5000 (35%)\n",
      "[epoch 15] loss: 0.1051229\n",
      "Test set: Average loss: 2.9485, Accuracy: 1782/5000 (36%)\n",
      "[epoch 16] loss: 0.0749648\n",
      "Test set: Average loss: 3.1512, Accuracy: 1722/5000 (34%)\n",
      "[epoch 17] loss: 0.0498891\n",
      "Test set: Average loss: 3.1171, Accuracy: 1768/5000 (35%)\n",
      "[epoch 18] loss: 0.0291074\n",
      "Test set: Average loss: 3.2503, Accuracy: 1741/5000 (35%)\n",
      "[epoch 19] loss: 0.0205836\n",
      "Test set: Average loss: 3.2867, Accuracy: 1787/5000 (36%)\n",
      "[epoch 20] loss: 0.0153744\n",
      "Test set: Average loss: 3.3965, Accuracy: 1745/5000 (35%)\n",
      "[epoch 21] loss: 0.0115956\n",
      "Test set: Average loss: 3.4495, Accuracy: 1751/5000 (35%)\n",
      "[epoch 22] loss: 0.0094582\n",
      "Test set: Average loss: 3.4601, Accuracy: 1770/5000 (35%)\n",
      "[epoch 23] loss: 0.0078788\n",
      "Test set: Average loss: 3.5529, Accuracy: 1745/5000 (35%)\n",
      "[epoch 24] loss: 0.0070853\n",
      "Test set: Average loss: 3.5777, Accuracy: 1768/5000 (35%)\n",
      "[epoch 25] loss: 0.0061922\n",
      "Test set: Average loss: 3.6057, Accuracy: 1762/5000 (35%)\n",
      "[epoch 26] loss: 0.0055107\n",
      "Test set: Average loss: 3.6571, Accuracy: 1750/5000 (35%)\n",
      "[epoch 27] loss: 0.0050260\n",
      "Test set: Average loss: 3.6665, Accuracy: 1757/5000 (35%)\n",
      "[epoch 28] loss: 0.0046588\n",
      "Test set: Average loss: 3.6936, Accuracy: 1760/5000 (35%)\n",
      "[epoch 29] loss: 0.0043022\n",
      "Test set: Average loss: 3.7086, Accuracy: 1762/5000 (35%)\n",
      "[epoch 30] loss: 0.0040071\n",
      "Test set: Average loss: 3.7393, Accuracy: 1759/5000 (35%)\n",
      "[epoch 31] loss: 0.0037033\n",
      "Test set: Average loss: 3.7715, Accuracy: 1755/5000 (35%)\n",
      "[epoch 32] loss: 0.0034678\n",
      "Test set: Average loss: 3.7909, Accuracy: 1755/5000 (35%)\n",
      "[epoch 33] loss: 0.0032602\n",
      "Test set: Average loss: 3.8107, Accuracy: 1755/5000 (35%)\n",
      "[epoch 34] loss: 0.0030727\n",
      "Test set: Average loss: 3.8363, Accuracy: 1754/5000 (35%)\n",
      "[epoch 35] loss: 0.0028995\n",
      "Test set: Average loss: 3.8552, Accuracy: 1752/5000 (35%)\n",
      "[epoch 36] loss: 0.0027275\n",
      "Test set: Average loss: 3.8685, Accuracy: 1752/5000 (35%)\n",
      "[epoch 37] loss: 0.0026164\n",
      "Test set: Average loss: 3.8903, Accuracy: 1751/5000 (35%)\n",
      "[epoch 38] loss: 0.0024600\n",
      "Test set: Average loss: 3.9139, Accuracy: 1754/5000 (35%)\n",
      "[epoch 39] loss: 0.0023337\n",
      "Test set: Average loss: 3.9286, Accuracy: 1749/5000 (35%)\n",
      "[epoch 40] loss: 0.0022299\n",
      "Test set: Average loss: 3.9429, Accuracy: 1751/5000 (35%)\n",
      "[epoch 41] loss: 0.0021128\n",
      "Test set: Average loss: 3.9630, Accuracy: 1749/5000 (35%)\n",
      "[epoch 42] loss: 0.0020076\n",
      "Test set: Average loss: 3.9670, Accuracy: 1763/5000 (35%)\n",
      "[epoch 43] loss: 0.0019138\n",
      "Test set: Average loss: 3.9849, Accuracy: 1764/5000 (35%)\n",
      "[epoch 44] loss: 0.0018450\n",
      "Test set: Average loss: 4.0031, Accuracy: 1768/5000 (35%)\n",
      "[epoch 45] loss: 0.0017682\n",
      "Test set: Average loss: 4.0200, Accuracy: 1762/5000 (35%)\n",
      "[epoch 46] loss: 0.0017179\n",
      "Test set: Average loss: 4.0397, Accuracy: 1752/5000 (35%)\n",
      "[epoch 47] loss: 0.0016257\n",
      "Test set: Average loss: 4.0529, Accuracy: 1756/5000 (35%)\n",
      "[epoch 48] loss: 0.0015749\n",
      "Test set: Average loss: 4.0555, Accuracy: 1762/5000 (35%)\n",
      "[epoch 49] loss: 0.0015195\n",
      "Test set: Average loss: 4.0734, Accuracy: 1757/5000 (35%)\n",
      "[epoch 50] loss: 0.0014501\n",
      "Test set: Average loss: 4.0896, Accuracy: 1755/5000 (35%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8535, Accuracy: 1895/5000 (38%)\n",
      "Test\n",
      "Test set: Average loss: 1.8481, Accuracy: 3786/10000 (38%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 456/5000 (9%)\n",
      "[epoch 1] loss: 2.2302919\n",
      "Test set: Average loss: 2.0539, Accuracy: 1460/5000 (29%)\n",
      "[epoch 2] loss: 1.8496218\n",
      "Test set: Average loss: 1.9281, Accuracy: 1494/5000 (30%)\n",
      "[epoch 3] loss: 1.6410903\n",
      "Test set: Average loss: 1.9622, Accuracy: 1625/5000 (32%)\n",
      "[epoch 4] loss: 1.4585467\n",
      "Test set: Average loss: 1.7689, Accuracy: 1818/5000 (36%)\n",
      "[epoch 5] loss: 1.1781199\n",
      "Test set: Average loss: 1.9470, Accuracy: 1757/5000 (35%)\n",
      "[epoch 6] loss: 0.9462880\n",
      "Test set: Average loss: 1.8805, Accuracy: 1934/5000 (39%)\n",
      "[epoch 7] loss: 0.8167664\n",
      "Test set: Average loss: 2.0219, Accuracy: 1894/5000 (38%)\n",
      "[epoch 8] loss: 0.7235496\n",
      "Test set: Average loss: 2.1771, Accuracy: 1788/5000 (36%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 0.6150771\n",
      "Test set: Average loss: 2.2134, Accuracy: 1883/5000 (38%)\n",
      "[epoch 10] loss: 0.4688181\n",
      "Test set: Average loss: 2.2416, Accuracy: 1956/5000 (39%)\n",
      "[epoch 11] loss: 0.3683440\n",
      "Test set: Average loss: 2.4658, Accuracy: 1834/5000 (37%)\n",
      "[epoch 12] loss: 0.2746635\n",
      "Test set: Average loss: 2.4360, Accuracy: 1889/5000 (38%)\n",
      "[epoch 13] loss: 0.2228677\n",
      "Test set: Average loss: 2.6201, Accuracy: 1867/5000 (37%)\n",
      "[epoch 14] loss: 0.1880078\n",
      "Test set: Average loss: 2.7522, Accuracy: 1845/5000 (37%)\n",
      "[epoch 15] loss: 0.1292660\n",
      "Test set: Average loss: 2.8555, Accuracy: 1908/5000 (38%)\n",
      "[epoch 16] loss: 0.0712127\n",
      "Test set: Average loss: 2.9281, Accuracy: 1838/5000 (37%)\n",
      "[epoch 17] loss: 0.0521869\n",
      "Test set: Average loss: 3.0212, Accuracy: 1920/5000 (38%)\n",
      "[epoch 18] loss: 0.0414844\n",
      "Test set: Average loss: 3.1345, Accuracy: 1856/5000 (37%)\n",
      "[epoch 19] loss: 0.0336079\n",
      "Test set: Average loss: 3.1956, Accuracy: 1908/5000 (38%)\n",
      "[epoch 20] loss: 0.0284848\n",
      "Test set: Average loss: 3.3256, Accuracy: 1854/5000 (37%)\n",
      "[epoch 21] loss: 0.0262749\n",
      "Test set: Average loss: 3.4085, Accuracy: 1881/5000 (38%)\n",
      "[epoch 22] loss: 0.0268707\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.4511, Accuracy: 1803/5000 (36%)\n",
      "[epoch 23] loss: 0.0194069\n",
      "Test set: Average loss: 3.4300, Accuracy: 1841/5000 (37%)\n",
      "[epoch 24] loss: 0.0130198\n",
      "Test set: Average loss: 3.4225, Accuracy: 1856/5000 (37%)\n",
      "[epoch 25] loss: 0.0109407\n",
      "Test set: Average loss: 3.4327, Accuracy: 1861/5000 (37%)\n",
      "[epoch 26] loss: 0.0104281\n",
      "Test set: Average loss: 3.4350, Accuracy: 1856/5000 (37%)\n",
      "[epoch 27] loss: 0.0099987\n",
      "Test set: Average loss: 3.4299, Accuracy: 1855/5000 (37%)\n",
      "[epoch 28] loss: 0.0098436\n",
      "Test set: Average loss: 3.4252, Accuracy: 1868/5000 (37%)\n",
      "[epoch 29] loss: 0.0094774\n",
      "Test set: Average loss: 3.4238, Accuracy: 1876/5000 (38%)\n",
      "[epoch 30] loss: 0.0094108\n",
      "Test set: Average loss: 3.4273, Accuracy: 1874/5000 (37%)\n",
      "[epoch 31] loss: 0.0092081\n",
      "Test set: Average loss: 3.4305, Accuracy: 1879/5000 (38%)\n",
      "[epoch 32] loss: 0.0090894\n",
      "Test set: Average loss: 3.4436, Accuracy: 1877/5000 (38%)\n",
      "[epoch 33] loss: 0.0088389\n",
      "Test set: Average loss: 3.4409, Accuracy: 1881/5000 (38%)\n",
      "[epoch 34] loss: 0.0087325\n",
      "Test set: Average loss: 3.4472, Accuracy: 1879/5000 (38%)\n",
      "[epoch 35] loss: 0.0086488\n",
      "Test set: Average loss: 3.4530, Accuracy: 1883/5000 (38%)\n",
      "[epoch 36] loss: 0.0084464\n",
      "Test set: Average loss: 3.4580, Accuracy: 1883/5000 (38%)\n",
      "[epoch 37] loss: 0.0083901\n",
      "Test set: Average loss: 3.4623, Accuracy: 1879/5000 (38%)\n",
      "[epoch 38] loss: 0.0082704\n",
      "Test set: Average loss: 3.4671, Accuracy: 1878/5000 (38%)\n",
      "[epoch 39] loss: 0.0081081\n",
      "Test set: Average loss: 3.4715, Accuracy: 1880/5000 (38%)\n",
      "[epoch 40] loss: 0.0081739\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.4775, Accuracy: 1879/5000 (38%)\n",
      "[epoch 41] loss: 0.0079660\n",
      "Test set: Average loss: 3.4781, Accuracy: 1880/5000 (38%)\n",
      "[epoch 42] loss: 0.0079085\n",
      "Test set: Average loss: 3.4783, Accuracy: 1880/5000 (38%)\n",
      "[epoch 43] loss: 0.0079470\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.4789, Accuracy: 1880/5000 (38%)\n",
      "[epoch 44] loss: 0.0079031\n",
      "Test set: Average loss: 3.4789, Accuracy: 1880/5000 (38%)\n",
      "[epoch 45] loss: 0.0078786\n",
      "Test set: Average loss: 3.4790, Accuracy: 1880/5000 (38%)\n",
      "[epoch 46] loss: 0.0079378\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.4790, Accuracy: 1880/5000 (38%)\n",
      "[epoch 47] loss: 0.0079643\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.4790, Accuracy: 1880/5000 (38%)\n",
      "[epoch 48] loss: 0.0078615\n",
      "Test set: Average loss: 3.4790, Accuracy: 1880/5000 (38%)\n",
      "[epoch 49] loss: 0.0079221\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.4790, Accuracy: 1880/5000 (38%)\n",
      "[epoch 50] loss: 0.0080103\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.4790, Accuracy: 1880/5000 (38%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2416, Accuracy: 1956/5000 (39%)\n",
      "Test\n",
      "Test set: Average loss: 2.2183, Accuracy: 3984/10000 (40%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 410/5000 (8%)\n",
      "[epoch 1] loss: 2.2698675\n",
      "Test set: Average loss: 2.2011, Accuracy: 1160/5000 (23%)\n",
      "[epoch 2] loss: 2.0205215\n",
      "Test set: Average loss: 1.9545, Accuracy: 1466/5000 (29%)\n",
      "[epoch 3] loss: 1.7797303\n",
      "Test set: Average loss: 1.9215, Accuracy: 1603/5000 (32%)\n",
      "[epoch 4] loss: 1.5907547\n",
      "Test set: Average loss: 1.8375, Accuracy: 1691/5000 (34%)\n",
      "[epoch 5] loss: 1.3493461\n",
      "Test set: Average loss: 1.8359, Accuracy: 1778/5000 (36%)\n",
      "[epoch 6] loss: 1.2304996\n",
      "Test set: Average loss: 2.0340, Accuracy: 1697/5000 (34%)\n",
      "[epoch 7] loss: 1.0501135\n",
      "Test set: Average loss: 1.8830, Accuracy: 1856/5000 (37%)\n",
      "[epoch 8] loss: 0.8476041\n",
      "Test set: Average loss: 1.9781, Accuracy: 1924/5000 (38%)\n",
      "[epoch 9] loss: 0.6748952\n",
      "Test set: Average loss: 1.9252, Accuracy: 2018/5000 (40%)\n",
      "[epoch 10] loss: 0.5477714\n",
      "Test set: Average loss: 2.1271, Accuracy: 1954/5000 (39%)\n",
      "[epoch 11] loss: 0.4899061\n",
      "Test set: Average loss: 2.3662, Accuracy: 1865/5000 (37%)\n",
      "[epoch 12] loss: 0.4404026\n",
      "Test set: Average loss: 2.2683, Accuracy: 1933/5000 (39%)\n",
      "[epoch 13] loss: 0.3155481\n",
      "Test set: Average loss: 2.5266, Accuracy: 1905/5000 (38%)\n",
      "[epoch 14] loss: 0.2634063\n",
      "Test set: Average loss: 2.5954, Accuracy: 1907/5000 (38%)\n",
      "[epoch 15] loss: 0.1789844\n",
      "Test set: Average loss: 2.5906, Accuracy: 1934/5000 (39%)\n",
      "[epoch 16] loss: 0.1077266\n",
      "Test set: Average loss: 2.8512, Accuracy: 1838/5000 (37%)\n",
      "[epoch 17] loss: 0.0751698\n",
      "Test set: Average loss: 2.8174, Accuracy: 1928/5000 (39%)\n",
      "[epoch 18] loss: 0.0500634\n",
      "Test set: Average loss: 2.8448, Accuracy: 1940/5000 (39%)\n",
      "[epoch 19] loss: 0.0371387\n",
      "Test set: Average loss: 2.9661, Accuracy: 1923/5000 (38%)\n",
      "[epoch 20] loss: 0.0261232\n",
      "Test set: Average loss: 3.0477, Accuracy: 1918/5000 (38%)\n",
      "[epoch 21] loss: 0.0202218\n",
      "Test set: Average loss: 3.1516, Accuracy: 1900/5000 (38%)\n",
      "[epoch 22] loss: 0.0176242\n",
      "Test set: Average loss: 3.2050, Accuracy: 1912/5000 (38%)\n",
      "[epoch 23] loss: 0.0127847\n",
      "Test set: Average loss: 3.2356, Accuracy: 1905/5000 (38%)\n",
      "[epoch 24] loss: 0.0112769\n",
      "Test set: Average loss: 3.2636, Accuracy: 1921/5000 (38%)\n",
      "[epoch 25] loss: 0.0094372\n",
      "Test set: Average loss: 3.3120, Accuracy: 1929/5000 (39%)\n",
      "[epoch 26] loss: 0.0084061\n",
      "Test set: Average loss: 3.3514, Accuracy: 1913/5000 (38%)\n",
      "[epoch 27] loss: 0.0079534\n",
      "Test set: Average loss: 3.3798, Accuracy: 1918/5000 (38%)\n",
      "[epoch 28] loss: 0.0069063\n",
      "Test set: Average loss: 3.4056, Accuracy: 1925/5000 (38%)\n",
      "[epoch 29] loss: 0.0062544\n",
      "Test set: Average loss: 3.4413, Accuracy: 1908/5000 (38%)\n",
      "[epoch 30] loss: 0.0057149\n",
      "Test set: Average loss: 3.4708, Accuracy: 1911/5000 (38%)\n",
      "[epoch 31] loss: 0.0052559\n",
      "Test set: Average loss: 3.4995, Accuracy: 1914/5000 (38%)\n",
      "[epoch 32] loss: 0.0047490\n",
      "Test set: Average loss: 3.5236, Accuracy: 1920/5000 (38%)\n",
      "[epoch 33] loss: 0.0044478\n",
      "Test set: Average loss: 3.5395, Accuracy: 1923/5000 (38%)\n",
      "[epoch 34] loss: 0.0041342\n",
      "Test set: Average loss: 3.5616, Accuracy: 1913/5000 (38%)\n",
      "[epoch 35] loss: 0.0038652\n",
      "Test set: Average loss: 3.5881, Accuracy: 1920/5000 (38%)\n",
      "[epoch 36] loss: 0.0036997\n",
      "Test set: Average loss: 3.6094, Accuracy: 1923/5000 (38%)\n",
      "[epoch 37] loss: 0.0034842\n",
      "Test set: Average loss: 3.6210, Accuracy: 1914/5000 (38%)\n",
      "[epoch 38] loss: 0.0032878\n",
      "Test set: Average loss: 3.6400, Accuracy: 1921/5000 (38%)\n",
      "[epoch 39] loss: 0.0031487\n",
      "Test set: Average loss: 3.6601, Accuracy: 1919/5000 (38%)\n",
      "[epoch 40] loss: 0.0029041\n",
      "Test set: Average loss: 3.6773, Accuracy: 1915/5000 (38%)\n",
      "[epoch 41] loss: 0.0027383\n",
      "Test set: Average loss: 3.6942, Accuracy: 1913/5000 (38%)\n",
      "[epoch 42] loss: 0.0025995\n",
      "Test set: Average loss: 3.7120, Accuracy: 1918/5000 (38%)\n",
      "[epoch 43] loss: 0.0024705\n",
      "Test set: Average loss: 3.7274, Accuracy: 1920/5000 (38%)\n",
      "[epoch 44] loss: 0.0023667\n",
      "Test set: Average loss: 3.7438, Accuracy: 1916/5000 (38%)\n",
      "[epoch 45] loss: 0.0022412\n",
      "Test set: Average loss: 3.7583, Accuracy: 1914/5000 (38%)\n",
      "[epoch 46] loss: 0.0021479\n",
      "Test set: Average loss: 3.7741, Accuracy: 1913/5000 (38%)\n",
      "[epoch 47] loss: 0.0020717\n",
      "Test set: Average loss: 3.7890, Accuracy: 1907/5000 (38%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 48] loss: 0.0019860\n",
      "Test set: Average loss: 3.7986, Accuracy: 1919/5000 (38%)\n",
      "[epoch 49] loss: 0.0018991\n",
      "Test set: Average loss: 3.8147, Accuracy: 1913/5000 (38%)\n",
      "[epoch 50] loss: 0.0018480\n",
      "Test set: Average loss: 3.8279, Accuracy: 1917/5000 (38%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9252, Accuracy: 2018/5000 (40%)\n",
      "Test\n",
      "Test set: Average loss: 1.9403, Accuracy: 3974/10000 (40%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 388/5000 (8%)\n",
      "[epoch 1] loss: 2.1174745\n",
      "Test set: Average loss: 1.9513, Accuracy: 1382/5000 (28%)\n",
      "[epoch 2] loss: 1.7523537\n",
      "Test set: Average loss: 1.7559, Accuracy: 1778/5000 (36%)\n",
      "[epoch 3] loss: 1.5209778\n",
      "Test set: Average loss: 1.6538, Accuracy: 2061/5000 (41%)\n",
      "[epoch 4] loss: 1.2889066\n",
      "Test set: Average loss: 1.6318, Accuracy: 2107/5000 (42%)\n",
      "[epoch 5] loss: 1.1627238\n",
      "Test set: Average loss: 1.7091, Accuracy: 2065/5000 (41%)\n",
      "[epoch 6] loss: 1.0331610\n",
      "Test set: Average loss: 1.6571, Accuracy: 2218/5000 (44%)\n",
      "[epoch 7] loss: 0.7945688\n",
      "Test set: Average loss: 1.7653, Accuracy: 2246/5000 (45%)\n",
      "[epoch 8] loss: 0.6112768\n",
      "Test set: Average loss: 1.9723, Accuracy: 2116/5000 (42%)\n",
      "[epoch 9] loss: 0.5589794\n",
      "Test set: Average loss: 2.0015, Accuracy: 2172/5000 (43%)\n",
      "[epoch 10] loss: 0.4405033\n",
      "Test set: Average loss: 2.1291, Accuracy: 2153/5000 (43%)\n",
      "[epoch 11] loss: 0.2897396\n",
      "Test set: Average loss: 2.3030, Accuracy: 2154/5000 (43%)\n",
      "[epoch 12] loss: 0.2088180\n",
      "Test set: Average loss: 2.4501, Accuracy: 2125/5000 (42%)\n",
      "[epoch 13] loss: 0.1346190\n",
      "Test set: Average loss: 2.6373, Accuracy: 2125/5000 (42%)\n",
      "[epoch 14] loss: 0.0752626\n",
      "Test set: Average loss: 2.7963, Accuracy: 2103/5000 (42%)\n",
      "[epoch 15] loss: 0.0489332\n",
      "Test set: Average loss: 2.8777, Accuracy: 2112/5000 (42%)\n",
      "[epoch 16] loss: 0.0381492\n",
      "Test set: Average loss: 3.0134, Accuracy: 2060/5000 (41%)\n",
      "[epoch 17] loss: 0.0325755\n",
      "Test set: Average loss: 3.0852, Accuracy: 2088/5000 (42%)\n",
      "[epoch 18] loss: 0.0266187\n",
      "Test set: Average loss: 3.1663, Accuracy: 2080/5000 (42%)\n",
      "[epoch 19] loss: 0.0192148\n",
      "Test set: Average loss: 3.2298, Accuracy: 2064/5000 (41%)\n",
      "[epoch 20] loss: 0.0122205\n",
      "Test set: Average loss: 3.3046, Accuracy: 2074/5000 (41%)\n",
      "[epoch 21] loss: 0.0084217\n",
      "Test set: Average loss: 3.3232, Accuracy: 2086/5000 (42%)\n",
      "[epoch 22] loss: 0.0065804\n",
      "Test set: Average loss: 3.3784, Accuracy: 2088/5000 (42%)\n",
      "[epoch 23] loss: 0.0056581\n",
      "Test set: Average loss: 3.4148, Accuracy: 2091/5000 (42%)\n",
      "[epoch 24] loss: 0.0050648\n",
      "Test set: Average loss: 3.4582, Accuracy: 2088/5000 (42%)\n",
      "[epoch 25] loss: 0.0045345\n",
      "Test set: Average loss: 3.4800, Accuracy: 2095/5000 (42%)\n",
      "[epoch 26] loss: 0.0041158\n",
      "Test set: Average loss: 3.5162, Accuracy: 2083/5000 (42%)\n",
      "[epoch 27] loss: 0.0038407\n",
      "Test set: Average loss: 3.5432, Accuracy: 2093/5000 (42%)\n",
      "[epoch 28] loss: 0.0035486\n",
      "Test set: Average loss: 3.5773, Accuracy: 2085/5000 (42%)\n",
      "[epoch 29] loss: 0.0032360\n",
      "Test set: Average loss: 3.6005, Accuracy: 2090/5000 (42%)\n",
      "[epoch 30] loss: 0.0029607\n",
      "Test set: Average loss: 3.6270, Accuracy: 2073/5000 (41%)\n",
      "[epoch 31] loss: 0.0027736\n",
      "Test set: Average loss: 3.6533, Accuracy: 2083/5000 (42%)\n",
      "[epoch 32] loss: 0.0026006\n",
      "Test set: Average loss: 3.6685, Accuracy: 2085/5000 (42%)\n",
      "[epoch 33] loss: 0.0024596\n",
      "Test set: Average loss: 3.6968, Accuracy: 2076/5000 (42%)\n",
      "[epoch 34] loss: 0.0023082\n",
      "Test set: Average loss: 3.7080, Accuracy: 2083/5000 (42%)\n",
      "[epoch 35] loss: 0.0021665\n",
      "Test set: Average loss: 3.7357, Accuracy: 2085/5000 (42%)\n",
      "[epoch 36] loss: 0.0020549\n",
      "Test set: Average loss: 3.7573, Accuracy: 2076/5000 (42%)\n",
      "[epoch 37] loss: 0.0019465\n",
      "Test set: Average loss: 3.7746, Accuracy: 2083/5000 (42%)\n",
      "[epoch 38] loss: 0.0018382\n",
      "Test set: Average loss: 3.7940, Accuracy: 2080/5000 (42%)\n",
      "[epoch 39] loss: 0.0017523\n",
      "Test set: Average loss: 3.8142, Accuracy: 2080/5000 (42%)\n",
      "[epoch 40] loss: 0.0016591\n",
      "Test set: Average loss: 3.8257, Accuracy: 2073/5000 (41%)\n",
      "[epoch 41] loss: 0.0016013\n",
      "Test set: Average loss: 3.8415, Accuracy: 2076/5000 (42%)\n",
      "[epoch 42] loss: 0.0015027\n",
      "Test set: Average loss: 3.8609, Accuracy: 2079/5000 (42%)\n",
      "[epoch 43] loss: 0.0014496\n",
      "Test set: Average loss: 3.8716, Accuracy: 2084/5000 (42%)\n",
      "[epoch 44] loss: 0.0013766\n",
      "Test set: Average loss: 3.8898, Accuracy: 2083/5000 (42%)\n",
      "[epoch 45] loss: 0.0013144\n",
      "Test set: Average loss: 3.9058, Accuracy: 2076/5000 (42%)\n",
      "[epoch 46] loss: 0.0012536\n",
      "Test set: Average loss: 3.9182, Accuracy: 2074/5000 (41%)\n",
      "[epoch 47] loss: 0.0012224\n",
      "Test set: Average loss: 3.9386, Accuracy: 2080/5000 (42%)\n",
      "[epoch 48] loss: 0.0011815\n",
      "Test set: Average loss: 3.9448, Accuracy: 2092/5000 (42%)\n",
      "[epoch 49] loss: 0.0011322\n",
      "Test set: Average loss: 3.9665, Accuracy: 2080/5000 (42%)\n",
      "[epoch 50] loss: 0.0010698\n",
      "Test set: Average loss: 3.9759, Accuracy: 2085/5000 (42%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7653, Accuracy: 2246/5000 (45%)\n",
      "Test\n",
      "Test set: Average loss: 1.7403, Accuracy: 4617/10000 (46%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3042, Accuracy: 491/5000 (10%)\n",
      "[epoch 1] loss: 2.0950200\n",
      "Test set: Average loss: 1.9510, Accuracy: 1419/5000 (28%)\n",
      "[epoch 2] loss: 1.6740841\n",
      "Test set: Average loss: 1.7493, Accuracy: 1798/5000 (36%)\n",
      "[epoch 3] loss: 1.3526780\n",
      "Test set: Average loss: 1.7301, Accuracy: 1886/5000 (38%)\n",
      "[epoch 4] loss: 1.1739187\n",
      "Test set: Average loss: 1.5965, Accuracy: 2180/5000 (44%)\n",
      "[epoch 5] loss: 1.0095010\n",
      "Test set: Average loss: 1.7204, Accuracy: 2115/5000 (42%)\n",
      "[epoch 6] loss: 0.8712009\n",
      "Test set: Average loss: 1.7054, Accuracy: 2139/5000 (43%)\n",
      "[epoch 7] loss: 0.6811169\n",
      "Test set: Average loss: 1.7712, Accuracy: 2159/5000 (43%)\n",
      "[epoch 8] loss: 0.5325004\n",
      "Test set: Average loss: 1.8965, Accuracy: 2151/5000 (43%)\n",
      "[epoch 9] loss: 0.4564697\n",
      "Test set: Average loss: 1.9851, Accuracy: 2156/5000 (43%)\n",
      "[epoch 10] loss: 0.4147433\n",
      "Test set: Average loss: 2.0883, Accuracy: 2190/5000 (44%)\n",
      "[epoch 11] loss: 0.2958291\n",
      "Test set: Average loss: 2.2235, Accuracy: 2109/5000 (42%)\n",
      "[epoch 12] loss: 0.2316746\n",
      "Test set: Average loss: 2.4122, Accuracy: 2091/5000 (42%)\n",
      "[epoch 13] loss: 0.1419294\n",
      "Test set: Average loss: 2.5903, Accuracy: 2115/5000 (42%)\n",
      "[epoch 14] loss: 0.1300079\n",
      "Test set: Average loss: 2.7942, Accuracy: 2030/5000 (41%)\n",
      "[epoch 15] loss: 0.1048905\n",
      "Test set: Average loss: 2.8096, Accuracy: 2069/5000 (41%)\n",
      "[epoch 16] loss: 0.0619628\n",
      "Test set: Average loss: 2.7543, Accuracy: 2168/5000 (43%)\n",
      "[epoch 17] loss: 0.0335349\n",
      "Test set: Average loss: 2.9327, Accuracy: 2154/5000 (43%)\n",
      "[epoch 18] loss: 0.0188609\n",
      "Test set: Average loss: 3.0218, Accuracy: 2150/5000 (43%)\n",
      "[epoch 19] loss: 0.0115369\n",
      "Test set: Average loss: 3.0345, Accuracy: 2158/5000 (43%)\n",
      "[epoch 20] loss: 0.0092237\n",
      "Test set: Average loss: 3.0977, Accuracy: 2142/5000 (43%)\n",
      "[epoch 21] loss: 0.0075501\n",
      "Test set: Average loss: 3.1514, Accuracy: 2151/5000 (43%)\n",
      "[epoch 22] loss: 0.0069307\n",
      "Test set: Average loss: 3.1930, Accuracy: 2147/5000 (43%)\n",
      "[epoch 23] loss: 0.0060398\n",
      "Test set: Average loss: 3.2391, Accuracy: 2145/5000 (43%)\n",
      "[epoch 24] loss: 0.0053001\n",
      "Test set: Average loss: 3.2734, Accuracy: 2132/5000 (43%)\n",
      "[epoch 25] loss: 0.0049264\n",
      "Test set: Average loss: 3.3047, Accuracy: 2140/5000 (43%)\n",
      "[epoch 26] loss: 0.0042839\n",
      "Test set: Average loss: 3.3427, Accuracy: 2132/5000 (43%)\n",
      "[epoch 27] loss: 0.0040143\n",
      "Test set: Average loss: 3.3648, Accuracy: 2143/5000 (43%)\n",
      "[epoch 28] loss: 0.0036831\n",
      "Test set: Average loss: 3.3932, Accuracy: 2135/5000 (43%)\n",
      "[epoch 29] loss: 0.0034480\n",
      "Test set: Average loss: 3.4178, Accuracy: 2142/5000 (43%)\n",
      "[epoch 30] loss: 0.0031449\n",
      "Test set: Average loss: 3.4489, Accuracy: 2124/5000 (42%)\n",
      "[epoch 31] loss: 0.0029535\n",
      "Test set: Average loss: 3.4696, Accuracy: 2129/5000 (43%)\n",
      "[epoch 32] loss: 0.0028257\n",
      "Test set: Average loss: 3.4901, Accuracy: 2131/5000 (43%)\n",
      "[epoch 33] loss: 0.0025616\n",
      "Test set: Average loss: 3.5132, Accuracy: 2134/5000 (43%)\n",
      "[epoch 34] loss: 0.0024295\n",
      "Test set: Average loss: 3.5351, Accuracy: 2127/5000 (43%)\n",
      "[epoch 35] loss: 0.0023071\n",
      "Test set: Average loss: 3.5532, Accuracy: 2126/5000 (43%)\n",
      "[epoch 36] loss: 0.0021539\n",
      "Test set: Average loss: 3.5734, Accuracy: 2128/5000 (43%)\n",
      "[epoch 37] loss: 0.0020579\n",
      "Test set: Average loss: 3.5940, Accuracy: 2126/5000 (43%)\n",
      "[epoch 38] loss: 0.0019229\n",
      "Test set: Average loss: 3.6082, Accuracy: 2133/5000 (43%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39] loss: 0.0018403\n",
      "Test set: Average loss: 3.6310, Accuracy: 2117/5000 (42%)\n",
      "[epoch 40] loss: 0.0017644\n",
      "Test set: Average loss: 3.6455, Accuracy: 2116/5000 (42%)\n",
      "[epoch 41] loss: 0.0016813\n",
      "Test set: Average loss: 3.6595, Accuracy: 2121/5000 (42%)\n",
      "[epoch 42] loss: 0.0016165\n",
      "Test set: Average loss: 3.6789, Accuracy: 2121/5000 (42%)\n",
      "[epoch 43] loss: 0.0015167\n",
      "Test set: Average loss: 3.6968, Accuracy: 2116/5000 (42%)\n",
      "[epoch 44] loss: 0.0014639\n",
      "Test set: Average loss: 3.7092, Accuracy: 2117/5000 (42%)\n",
      "[epoch 45] loss: 0.0013971\n",
      "Test set: Average loss: 3.7261, Accuracy: 2114/5000 (42%)\n",
      "[epoch 46] loss: 0.0013253\n",
      "Test set: Average loss: 3.7414, Accuracy: 2106/5000 (42%)\n",
      "[epoch 47] loss: 0.0012595\n",
      "Test set: Average loss: 3.7528, Accuracy: 2115/5000 (42%)\n",
      "[epoch 48] loss: 0.0012332\n",
      "Test set: Average loss: 3.7665, Accuracy: 2114/5000 (42%)\n",
      "[epoch 49] loss: 0.0011794\n",
      "Test set: Average loss: 3.7837, Accuracy: 2116/5000 (42%)\n",
      "[epoch 50] loss: 0.0011330\n",
      "Test set: Average loss: 3.7972, Accuracy: 2112/5000 (42%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0883, Accuracy: 2190/5000 (44%)\n",
      "Test\n",
      "Test set: Average loss: 2.0209, Accuracy: 4508/10000 (45%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 428/5000 (9%)\n",
      "[epoch 1] loss: 2.1907547\n",
      "Test set: Average loss: 1.9275, Accuracy: 1694/5000 (34%)\n",
      "[epoch 2] loss: 1.8200789\n",
      "Test set: Average loss: 1.7760, Accuracy: 1854/5000 (37%)\n",
      "[epoch 3] loss: 1.5620942\n",
      "Test set: Average loss: 1.6838, Accuracy: 2007/5000 (40%)\n",
      "[epoch 4] loss: 1.3807054\n",
      "Test set: Average loss: 1.6191, Accuracy: 2096/5000 (42%)\n",
      "[epoch 5] loss: 1.1591890\n",
      "Test set: Average loss: 1.6335, Accuracy: 2192/5000 (44%)\n",
      "[epoch 6] loss: 0.9684563\n",
      "Test set: Average loss: 1.7166, Accuracy: 2139/5000 (43%)\n",
      "[epoch 7] loss: 0.8040922\n",
      "Test set: Average loss: 1.8320, Accuracy: 2039/5000 (41%)\n",
      "[epoch 8] loss: 0.6418725\n",
      "Test set: Average loss: 1.9730, Accuracy: 2111/5000 (42%)\n",
      "[epoch 9] loss: 0.5609347\n",
      "Test set: Average loss: 2.1672, Accuracy: 1985/5000 (40%)\n",
      "[epoch 10] loss: 0.4162376\n",
      "Test set: Average loss: 2.0834, Accuracy: 2151/5000 (43%)\n",
      "[epoch 11] loss: 0.2941337\n",
      "Test set: Average loss: 2.2637, Accuracy: 2181/5000 (44%)\n",
      "[epoch 12] loss: 0.1924692\n",
      "Test set: Average loss: 2.4409, Accuracy: 2138/5000 (43%)\n",
      "[epoch 13] loss: 0.1390242\n",
      "Test set: Average loss: 2.6875, Accuracy: 2085/5000 (42%)\n",
      "[epoch 14] loss: 0.1007680\n",
      "Test set: Average loss: 2.7817, Accuracy: 2089/5000 (42%)\n",
      "[epoch 15] loss: 0.0885173\n",
      "Test set: Average loss: 2.8969, Accuracy: 2118/5000 (42%)\n",
      "[epoch 16] loss: 0.0738612\n",
      "Test set: Average loss: 3.0600, Accuracy: 2102/5000 (42%)\n",
      "[epoch 17] loss: 0.0922788\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.1044, Accuracy: 2061/5000 (41%)\n",
      "[epoch 18] loss: 0.0492304\n",
      "Test set: Average loss: 2.9826, Accuracy: 2116/5000 (42%)\n",
      "[epoch 19] loss: 0.0222033\n",
      "Test set: Average loss: 2.9675, Accuracy: 2129/5000 (43%)\n",
      "[epoch 20] loss: 0.0192818\n",
      "Test set: Average loss: 2.9889, Accuracy: 2125/5000 (42%)\n",
      "[epoch 21] loss: 0.0170613\n",
      "Test set: Average loss: 3.0079, Accuracy: 2122/5000 (42%)\n",
      "[epoch 22] loss: 0.0160873\n",
      "Test set: Average loss: 3.0223, Accuracy: 2120/5000 (42%)\n",
      "[epoch 23] loss: 0.0154642\n",
      "Test set: Average loss: 3.0352, Accuracy: 2121/5000 (42%)\n",
      "[epoch 24] loss: 0.0143767\n",
      "Test set: Average loss: 3.0447, Accuracy: 2120/5000 (42%)\n",
      "[epoch 25] loss: 0.0138940\n",
      "Test set: Average loss: 3.0542, Accuracy: 2127/5000 (43%)\n",
      "[epoch 26] loss: 0.0130940\n",
      "Test set: Average loss: 3.0659, Accuracy: 2124/5000 (42%)\n",
      "[epoch 27] loss: 0.0128176\n",
      "Test set: Average loss: 3.0769, Accuracy: 2121/5000 (42%)\n",
      "[epoch 28] loss: 0.0122119\n",
      "Test set: Average loss: 3.0862, Accuracy: 2123/5000 (42%)\n",
      "[epoch 29] loss: 0.0118603\n",
      "Test set: Average loss: 3.0944, Accuracy: 2127/5000 (43%)\n",
      "[epoch 30] loss: 0.0114058\n",
      "Test set: Average loss: 3.1067, Accuracy: 2131/5000 (43%)\n",
      "[epoch 31] loss: 0.0110283\n",
      "Test set: Average loss: 3.1175, Accuracy: 2127/5000 (43%)\n",
      "[epoch 32] loss: 0.0105565\n",
      "Test set: Average loss: 3.1247, Accuracy: 2119/5000 (42%)\n",
      "[epoch 33] loss: 0.0103108\n",
      "Test set: Average loss: 3.1337, Accuracy: 2117/5000 (42%)\n",
      "[epoch 34] loss: 0.0100588\n",
      "Test set: Average loss: 3.1436, Accuracy: 2120/5000 (42%)\n",
      "[epoch 35] loss: 0.0096866\n",
      "Test set: Average loss: 3.1524, Accuracy: 2115/5000 (42%)\n",
      "[epoch 36] loss: 0.0094186\n",
      "Test set: Average loss: 3.1614, Accuracy: 2120/5000 (42%)\n",
      "[epoch 37] loss: 0.0092535\n",
      "Test set: Average loss: 3.1713, Accuracy: 2118/5000 (42%)\n",
      "[epoch 38] loss: 0.0091104\n",
      "Test set: Average loss: 3.1798, Accuracy: 2108/5000 (42%)\n",
      "[epoch 39] loss: 0.0087737\n",
      "Test set: Average loss: 3.1879, Accuracy: 2115/5000 (42%)\n",
      "[epoch 40] loss: 0.0084860\n",
      "Test set: Average loss: 3.1965, Accuracy: 2117/5000 (42%)\n",
      "[epoch 41] loss: 0.0082970\n",
      "Test set: Average loss: 3.2048, Accuracy: 2119/5000 (42%)\n",
      "[epoch 42] loss: 0.0081662\n",
      "Test set: Average loss: 3.2134, Accuracy: 2115/5000 (42%)\n",
      "[epoch 43] loss: 0.0078663\n",
      "Test set: Average loss: 3.2215, Accuracy: 2112/5000 (42%)\n",
      "[epoch 44] loss: 0.0077884\n",
      "Test set: Average loss: 3.2293, Accuracy: 2114/5000 (42%)\n",
      "[epoch 45] loss: 0.0075103\n",
      "Test set: Average loss: 3.2378, Accuracy: 2116/5000 (42%)\n",
      "[epoch 46] loss: 0.0073418\n",
      "Test set: Average loss: 3.2458, Accuracy: 2113/5000 (42%)\n",
      "[epoch 47] loss: 0.0071838\n",
      "Test set: Average loss: 3.2538, Accuracy: 2114/5000 (42%)\n",
      "[epoch 48] loss: 0.0070434\n",
      "Test set: Average loss: 3.2613, Accuracy: 2114/5000 (42%)\n",
      "[epoch 49] loss: 0.0068998\n",
      "Test set: Average loss: 3.2698, Accuracy: 2113/5000 (42%)\n",
      "[epoch 50] loss: 0.0067709\n",
      "Test set: Average loss: 3.2764, Accuracy: 2113/5000 (42%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6335, Accuracy: 2192/5000 (44%)\n",
      "Test\n",
      "Test set: Average loss: 1.6287, Accuracy: 4382/10000 (44%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3030, Accuracy: 457/5000 (9%)\n",
      "[epoch 1] loss: 2.0767791\n",
      "Test set: Average loss: 1.9024, Accuracy: 1524/5000 (30%)\n",
      "[epoch 2] loss: 1.7057494\n",
      "Test set: Average loss: 1.7523, Accuracy: 1885/5000 (38%)\n",
      "[epoch 3] loss: 1.4585229\n",
      "Test set: Average loss: 1.6484, Accuracy: 2085/5000 (42%)\n",
      "[epoch 4] loss: 1.2969061\n",
      "Test set: Average loss: 1.5080, Accuracy: 2293/5000 (46%)\n",
      "[epoch 5] loss: 1.0977922\n",
      "Test set: Average loss: 1.6571, Accuracy: 2196/5000 (44%)\n",
      "[epoch 6] loss: 0.9609157\n",
      "Test set: Average loss: 1.6295, Accuracy: 2283/5000 (46%)\n",
      "[epoch 7] loss: 0.8192640\n",
      "Test set: Average loss: 1.7880, Accuracy: 2175/5000 (44%)\n",
      "[epoch 8] loss: 0.7453497\n",
      "Test set: Average loss: 1.7962, Accuracy: 2315/5000 (46%)\n",
      "[epoch 9] loss: 0.5569307\n",
      "Test set: Average loss: 2.0076, Accuracy: 2212/5000 (44%)\n",
      "[epoch 10] loss: 0.4685171\n",
      "Test set: Average loss: 2.0762, Accuracy: 2201/5000 (44%)\n",
      "[epoch 11] loss: 0.3604479\n",
      "Test set: Average loss: 2.2208, Accuracy: 2185/5000 (44%)\n",
      "[epoch 12] loss: 0.2426926\n",
      "Test set: Average loss: 2.3445, Accuracy: 2248/5000 (45%)\n",
      "[epoch 13] loss: 0.2102751\n",
      "Test set: Average loss: 2.4467, Accuracy: 2230/5000 (45%)\n",
      "[epoch 14] loss: 0.1294016\n",
      "Test set: Average loss: 2.6212, Accuracy: 2230/5000 (45%)\n",
      "[epoch 15] loss: 0.0823798\n",
      "Test set: Average loss: 2.9233, Accuracy: 2173/5000 (43%)\n",
      "[epoch 16] loss: 0.0688881\n",
      "Test set: Average loss: 2.9879, Accuracy: 2199/5000 (44%)\n",
      "[epoch 17] loss: 0.0553273\n",
      "Test set: Average loss: 3.0671, Accuracy: 2236/5000 (45%)\n",
      "[epoch 18] loss: 0.0446850\n",
      "Test set: Average loss: 3.2020, Accuracy: 2213/5000 (44%)\n",
      "[epoch 19] loss: 0.0336419\n",
      "Test set: Average loss: 3.3178, Accuracy: 2177/5000 (44%)\n",
      "[epoch 20] loss: 0.0365170\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.2917, Accuracy: 2182/5000 (44%)\n",
      "[epoch 21] loss: 0.0161377\n",
      "Test set: Average loss: 3.2772, Accuracy: 2189/5000 (44%)\n",
      "[epoch 22] loss: 0.0102675\n",
      "Test set: Average loss: 3.2844, Accuracy: 2187/5000 (44%)\n",
      "[epoch 23] loss: 0.0090750\n",
      "Test set: Average loss: 3.2887, Accuracy: 2195/5000 (44%)\n",
      "[epoch 24] loss: 0.0084319\n",
      "Test set: Average loss: 3.2971, Accuracy: 2195/5000 (44%)\n",
      "[epoch 25] loss: 0.0080321\n",
      "Test set: Average loss: 3.3033, Accuracy: 2199/5000 (44%)\n",
      "[epoch 26] loss: 0.0078422\n",
      "Test set: Average loss: 3.3120, Accuracy: 2201/5000 (44%)\n",
      "[epoch 27] loss: 0.0073928\n",
      "Test set: Average loss: 3.3189, Accuracy: 2201/5000 (44%)\n",
      "[epoch 28] loss: 0.0071653\n",
      "Test set: Average loss: 3.3281, Accuracy: 2201/5000 (44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] loss: 0.0069221\n",
      "Test set: Average loss: 3.3359, Accuracy: 2199/5000 (44%)\n",
      "[epoch 30] loss: 0.0066244\n",
      "Test set: Average loss: 3.3433, Accuracy: 2198/5000 (44%)\n",
      "[epoch 31] loss: 0.0065307\n",
      "Test set: Average loss: 3.3506, Accuracy: 2194/5000 (44%)\n",
      "[epoch 32] loss: 0.0063312\n",
      "Test set: Average loss: 3.3580, Accuracy: 2198/5000 (44%)\n",
      "[epoch 33] loss: 0.0061715\n",
      "Test set: Average loss: 3.3670, Accuracy: 2202/5000 (44%)\n",
      "[epoch 34] loss: 0.0059348\n",
      "Test set: Average loss: 3.3728, Accuracy: 2200/5000 (44%)\n",
      "[epoch 35] loss: 0.0057869\n",
      "Test set: Average loss: 3.3801, Accuracy: 2204/5000 (44%)\n",
      "[epoch 36] loss: 0.0057170\n",
      "Test set: Average loss: 3.3867, Accuracy: 2202/5000 (44%)\n",
      "[epoch 37] loss: 0.0055257\n",
      "Test set: Average loss: 3.3948, Accuracy: 2197/5000 (44%)\n",
      "[epoch 38] loss: 0.0055260\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.3991, Accuracy: 2206/5000 (44%)\n",
      "[epoch 39] loss: 0.0053856\n",
      "Test set: Average loss: 3.4000, Accuracy: 2204/5000 (44%)\n",
      "[epoch 40] loss: 0.0053713\n",
      "Test set: Average loss: 3.4008, Accuracy: 2204/5000 (44%)\n",
      "[epoch 41] loss: 0.0053427\n",
      "Test set: Average loss: 3.4015, Accuracy: 2203/5000 (44%)\n",
      "[epoch 42] loss: 0.0053735\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.4025, Accuracy: 2202/5000 (44%)\n",
      "[epoch 43] loss: 0.0052633\n",
      "Test set: Average loss: 3.4025, Accuracy: 2202/5000 (44%)\n",
      "[epoch 44] loss: 0.0052760\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "[epoch 45] loss: 0.0052654\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "[epoch 46] loss: 0.0052946\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "[epoch 47] loss: 0.0052376\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "[epoch 48] loss: 0.0053028\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "[epoch 49] loss: 0.0053352\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "[epoch 50] loss: 0.0053409\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.4026, Accuracy: 2202/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7962, Accuracy: 2315/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.7767, Accuracy: 4620/10000 (46%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 513/5000 (10%)\n",
      "[epoch 1] loss: 2.0072872\n",
      "Test set: Average loss: 1.8813, Accuracy: 1597/5000 (32%)\n",
      "[epoch 2] loss: 1.6244584\n",
      "Test set: Average loss: 1.6515, Accuracy: 2033/5000 (41%)\n",
      "[epoch 3] loss: 1.2650222\n",
      "Test set: Average loss: 1.6342, Accuracy: 2143/5000 (43%)\n",
      "[epoch 4] loss: 1.1650098\n",
      "Test set: Average loss: 1.5345, Accuracy: 2330/5000 (47%)\n",
      "[epoch 5] loss: 0.9054684\n",
      "Test set: Average loss: 1.5670, Accuracy: 2403/5000 (48%)\n",
      "[epoch 6] loss: 0.8050367\n",
      "Test set: Average loss: 1.6304, Accuracy: 2286/5000 (46%)\n",
      "[epoch 7] loss: 0.6571342\n",
      "Test set: Average loss: 1.7282, Accuracy: 2348/5000 (47%)\n",
      "[epoch 8] loss: 0.5205293\n",
      "Test set: Average loss: 1.9552, Accuracy: 2274/5000 (45%)\n",
      "[epoch 9] loss: 0.4496689\n",
      "Test set: Average loss: 2.1275, Accuracy: 2199/5000 (44%)\n",
      "[epoch 10] loss: 0.4685923\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1706, Accuracy: 2213/5000 (44%)\n",
      "[epoch 11] loss: 0.2748783\n",
      "Test set: Average loss: 2.0774, Accuracy: 2303/5000 (46%)\n",
      "[epoch 12] loss: 0.2015294\n",
      "Test set: Average loss: 2.0803, Accuracy: 2344/5000 (47%)\n",
      "[epoch 13] loss: 0.1689307\n",
      "Test set: Average loss: 2.0914, Accuracy: 2349/5000 (47%)\n",
      "[epoch 14] loss: 0.1554152\n",
      "Test set: Average loss: 2.1122, Accuracy: 2346/5000 (47%)\n",
      "[epoch 15] loss: 0.1467264\n",
      "Test set: Average loss: 2.1317, Accuracy: 2351/5000 (47%)\n",
      "[epoch 16] loss: 0.1357055\n",
      "Test set: Average loss: 2.1602, Accuracy: 2334/5000 (47%)\n",
      "[epoch 17] loss: 0.1266540\n",
      "Test set: Average loss: 2.1770, Accuracy: 2348/5000 (47%)\n",
      "[epoch 18] loss: 0.1170803\n",
      "Test set: Average loss: 2.2026, Accuracy: 2333/5000 (47%)\n",
      "[epoch 19] loss: 0.1118211\n",
      "Test set: Average loss: 2.2279, Accuracy: 2334/5000 (47%)\n",
      "[epoch 20] loss: 0.1061452\n",
      "Test set: Average loss: 2.2455, Accuracy: 2340/5000 (47%)\n",
      "[epoch 21] loss: 0.0996810\n",
      "Test set: Average loss: 2.2733, Accuracy: 2337/5000 (47%)\n",
      "[epoch 22] loss: 0.0947971\n",
      "Test set: Average loss: 2.2964, Accuracy: 2334/5000 (47%)\n",
      "[epoch 23] loss: 0.0890952\n",
      "Test set: Average loss: 2.3162, Accuracy: 2333/5000 (47%)\n",
      "[epoch 24] loss: 0.0844363\n",
      "Test set: Average loss: 2.3431, Accuracy: 2319/5000 (46%)\n",
      "[epoch 25] loss: 0.0803643\n",
      "Test set: Average loss: 2.3625, Accuracy: 2324/5000 (46%)\n",
      "[epoch 26] loss: 0.0764924\n",
      "Test set: Average loss: 2.3860, Accuracy: 2327/5000 (47%)\n",
      "[epoch 27] loss: 0.0709364\n",
      "Test set: Average loss: 2.4088, Accuracy: 2340/5000 (47%)\n",
      "[epoch 28] loss: 0.0666995\n",
      "Test set: Average loss: 2.4331, Accuracy: 2332/5000 (47%)\n",
      "[epoch 29] loss: 0.0641305\n",
      "Test set: Average loss: 2.4536, Accuracy: 2334/5000 (47%)\n",
      "[epoch 30] loss: 0.0605078\n",
      "Test set: Average loss: 2.4772, Accuracy: 2323/5000 (46%)\n",
      "[epoch 31] loss: 0.0561974\n",
      "Test set: Average loss: 2.5057, Accuracy: 2330/5000 (47%)\n",
      "[epoch 32] loss: 0.0528978\n",
      "Test set: Average loss: 2.5233, Accuracy: 2312/5000 (46%)\n",
      "[epoch 33] loss: 0.0510810\n",
      "Test set: Average loss: 2.5452, Accuracy: 2326/5000 (47%)\n",
      "[epoch 34] loss: 0.0473929\n",
      "Test set: Average loss: 2.5705, Accuracy: 2330/5000 (47%)\n",
      "[epoch 35] loss: 0.0441682\n",
      "Test set: Average loss: 2.5863, Accuracy: 2323/5000 (46%)\n",
      "[epoch 36] loss: 0.0420151\n",
      "Test set: Average loss: 2.6117, Accuracy: 2335/5000 (47%)\n",
      "[epoch 37] loss: 0.0400698\n",
      "Test set: Average loss: 2.6287, Accuracy: 2315/5000 (46%)\n",
      "[epoch 38] loss: 0.0369512\n",
      "Test set: Average loss: 2.6501, Accuracy: 2323/5000 (46%)\n",
      "[epoch 39] loss: 0.0351812\n",
      "Test set: Average loss: 2.6738, Accuracy: 2318/5000 (46%)\n",
      "[epoch 40] loss: 0.0332133\n",
      "Test set: Average loss: 2.6960, Accuracy: 2328/5000 (47%)\n",
      "[epoch 41] loss: 0.0312556\n",
      "Test set: Average loss: 2.7130, Accuracy: 2319/5000 (46%)\n",
      "[epoch 42] loss: 0.0296871\n",
      "Test set: Average loss: 2.7365, Accuracy: 2329/5000 (47%)\n",
      "[epoch 43] loss: 0.0284198\n",
      "Test set: Average loss: 2.7571, Accuracy: 2323/5000 (46%)\n",
      "[epoch 44] loss: 0.0265874\n",
      "Test set: Average loss: 2.7739, Accuracy: 2316/5000 (46%)\n",
      "[epoch 45] loss: 0.0256014\n",
      "Test set: Average loss: 2.7936, Accuracy: 2315/5000 (46%)\n",
      "[epoch 46] loss: 0.0244113\n",
      "Test set: Average loss: 2.8105, Accuracy: 2323/5000 (46%)\n",
      "[epoch 47] loss: 0.0231504\n",
      "Test set: Average loss: 2.8329, Accuracy: 2320/5000 (46%)\n",
      "[epoch 48] loss: 0.0218776\n",
      "Test set: Average loss: 2.8500, Accuracy: 2323/5000 (46%)\n",
      "[epoch 49] loss: 0.0211690\n",
      "Test set: Average loss: 2.8668, Accuracy: 2313/5000 (46%)\n",
      "[epoch 50] loss: 0.0201198\n",
      "Test set: Average loss: 2.8837, Accuracy: 2327/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5670, Accuracy: 2403/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 1.5524, Accuracy: 4861/10000 (49%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3044, Accuracy: 348/5000 (7%)\n",
      "[epoch 1] loss: 2.1148932\n",
      "Test set: Average loss: 1.9051, Accuracy: 1498/5000 (30%)\n",
      "[epoch 2] loss: 1.7391025\n",
      "Test set: Average loss: 1.8105, Accuracy: 1781/5000 (36%)\n",
      "[epoch 3] loss: 1.5744676\n",
      "Test set: Average loss: 1.6820, Accuracy: 1977/5000 (40%)\n",
      "[epoch 4] loss: 1.3483620\n",
      "Test set: Average loss: 1.5849, Accuracy: 2137/5000 (43%)\n",
      "[epoch 5] loss: 1.1061261\n",
      "Test set: Average loss: 1.5269, Accuracy: 2399/5000 (48%)\n",
      "[epoch 6] loss: 0.9644789\n",
      "Test set: Average loss: 1.6056, Accuracy: 2308/5000 (46%)\n",
      "[epoch 7] loss: 0.8058868\n",
      "Test set: Average loss: 1.7396, Accuracy: 2287/5000 (46%)\n",
      "[epoch 8] loss: 0.6762451\n",
      "Test set: Average loss: 1.7541, Accuracy: 2279/5000 (46%)\n",
      "[epoch 9] loss: 0.4816905\n",
      "Test set: Average loss: 2.0135, Accuracy: 2229/5000 (45%)\n",
      "[epoch 10] loss: 0.4426958\n",
      "Test set: Average loss: 2.1961, Accuracy: 2156/5000 (43%)\n",
      "[epoch 11] loss: 0.3435355\n",
      "Test set: Average loss: 2.2942, Accuracy: 2279/5000 (46%)\n",
      "[epoch 12] loss: 0.2536266\n",
      "Test set: Average loss: 2.5720, Accuracy: 2153/5000 (43%)\n",
      "[epoch 13] loss: 0.1918064\n",
      "Test set: Average loss: 2.6803, Accuracy: 2187/5000 (44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14] loss: 0.1816327\n",
      "Test set: Average loss: 2.8553, Accuracy: 2135/5000 (43%)\n",
      "[epoch 15] loss: 0.1617810\n",
      "Test set: Average loss: 2.8899, Accuracy: 2197/5000 (44%)\n",
      "[epoch 16] loss: 0.1303688\n",
      "Test set: Average loss: 3.1224, Accuracy: 2129/5000 (43%)\n",
      "[epoch 17] loss: 0.0821031\n",
      "Test set: Average loss: 3.0778, Accuracy: 2239/5000 (45%)\n",
      "[epoch 18] loss: 0.0732617\n",
      "Test set: Average loss: 3.3977, Accuracy: 2132/5000 (43%)\n",
      "[epoch 19] loss: 0.0546257\n",
      "Test set: Average loss: 3.4519, Accuracy: 2134/5000 (43%)\n",
      "[epoch 20] loss: 0.0298933\n",
      "Test set: Average loss: 3.5505, Accuracy: 2150/5000 (43%)\n",
      "[epoch 21] loss: 0.0338860\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.6339, Accuracy: 2128/5000 (43%)\n",
      "[epoch 22] loss: 0.0219076\n",
      "Test set: Average loss: 3.5031, Accuracy: 2174/5000 (43%)\n",
      "[epoch 23] loss: 0.0087770\n",
      "Test set: Average loss: 3.5019, Accuracy: 2190/5000 (44%)\n",
      "[epoch 24] loss: 0.0078223\n",
      "Test set: Average loss: 3.5064, Accuracy: 2193/5000 (44%)\n",
      "[epoch 25] loss: 0.0073018\n",
      "Test set: Average loss: 3.5117, Accuracy: 2201/5000 (44%)\n",
      "[epoch 26] loss: 0.0070069\n",
      "Test set: Average loss: 3.5169, Accuracy: 2196/5000 (44%)\n",
      "[epoch 27] loss: 0.0066833\n",
      "Test set: Average loss: 3.5231, Accuracy: 2200/5000 (44%)\n",
      "[epoch 28] loss: 0.0063651\n",
      "Test set: Average loss: 3.5254, Accuracy: 2201/5000 (44%)\n",
      "[epoch 29] loss: 0.0063380\n",
      "Test set: Average loss: 3.5307, Accuracy: 2197/5000 (44%)\n",
      "[epoch 30] loss: 0.0059558\n",
      "Test set: Average loss: 3.5358, Accuracy: 2200/5000 (44%)\n",
      "[epoch 31] loss: 0.0058699\n",
      "Test set: Average loss: 3.5405, Accuracy: 2202/5000 (44%)\n",
      "[epoch 32] loss: 0.0055811\n",
      "Test set: Average loss: 3.5444, Accuracy: 2200/5000 (44%)\n",
      "[epoch 33] loss: 0.0054684\n",
      "Test set: Average loss: 3.5491, Accuracy: 2204/5000 (44%)\n",
      "[epoch 34] loss: 0.0052616\n",
      "Test set: Average loss: 3.5555, Accuracy: 2201/5000 (44%)\n",
      "[epoch 35] loss: 0.0051677\n",
      "Test set: Average loss: 3.5609, Accuracy: 2203/5000 (44%)\n",
      "[epoch 36] loss: 0.0050260\n",
      "Test set: Average loss: 3.5652, Accuracy: 2203/5000 (44%)\n",
      "[epoch 37] loss: 0.0050628\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.5698, Accuracy: 2203/5000 (44%)\n",
      "[epoch 38] loss: 0.0047678\n",
      "Test set: Average loss: 3.5703, Accuracy: 2204/5000 (44%)\n",
      "[epoch 39] loss: 0.0047266\n",
      "Test set: Average loss: 3.5707, Accuracy: 2204/5000 (44%)\n",
      "[epoch 40] loss: 0.0047891\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.5713, Accuracy: 2205/5000 (44%)\n",
      "[epoch 41] loss: 0.0048029\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 42] loss: 0.0047980\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 43] loss: 0.0047300\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 44] loss: 0.0047378\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 45] loss: 0.0047592\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 46] loss: 0.0047451\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 47] loss: 0.0048276\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 48] loss: 0.0047180\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 49] loss: 0.0047610\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "[epoch 50] loss: 0.0047949\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.5714, Accuracy: 2205/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5269, Accuracy: 2399/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 1.5117, Accuracy: 4784/10000 (48%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3044, Accuracy: 459/5000 (9%)\n",
      "[epoch 1] loss: 2.0295168\n",
      "Test set: Average loss: 1.9730, Accuracy: 1578/5000 (32%)\n",
      "[epoch 2] loss: 1.6683313\n",
      "Test set: Average loss: 1.6503, Accuracy: 2059/5000 (41%)\n",
      "[epoch 3] loss: 1.3983179\n",
      "Test set: Average loss: 1.5590, Accuracy: 2214/5000 (44%)\n",
      "[epoch 4] loss: 1.1944980\n",
      "Test set: Average loss: 1.5019, Accuracy: 2348/5000 (47%)\n",
      "[epoch 5] loss: 1.0936913\n",
      "Test set: Average loss: 1.5331, Accuracy: 2341/5000 (47%)\n",
      "[epoch 6] loss: 0.9259476\n",
      "Test set: Average loss: 1.6151, Accuracy: 2281/5000 (46%)\n",
      "[epoch 7] loss: 0.8083185\n",
      "Test set: Average loss: 1.8789, Accuracy: 2136/5000 (43%)\n",
      "[epoch 8] loss: 0.7136823\n",
      "Test set: Average loss: 1.8398, Accuracy: 2247/5000 (45%)\n",
      "[epoch 9] loss: 0.5526378\n",
      "Test set: Average loss: 2.0272, Accuracy: 2317/5000 (46%)\n",
      "[epoch 10] loss: 0.4654481\n",
      "Test set: Average loss: 2.0763, Accuracy: 2325/5000 (46%)\n",
      "[epoch 11] loss: 0.4033088\n",
      "Test set: Average loss: 2.2200, Accuracy: 2237/5000 (45%)\n",
      "[epoch 12] loss: 0.3035763\n",
      "Test set: Average loss: 2.4805, Accuracy: 2226/5000 (45%)\n",
      "[epoch 13] loss: 0.2476092\n",
      "Test set: Average loss: 2.6188, Accuracy: 2234/5000 (45%)\n",
      "[epoch 14] loss: 0.1624173\n",
      "Test set: Average loss: 2.6672, Accuracy: 2263/5000 (45%)\n",
      "[epoch 15] loss: 0.1294214\n",
      "Test set: Average loss: 3.0033, Accuracy: 2156/5000 (43%)\n",
      "[epoch 16] loss: 0.1369110\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.0978, Accuracy: 2203/5000 (44%)\n",
      "[epoch 17] loss: 0.0647118\n",
      "Test set: Average loss: 3.0269, Accuracy: 2271/5000 (45%)\n",
      "[epoch 18] loss: 0.0372299\n",
      "Test set: Average loss: 3.0234, Accuracy: 2256/5000 (45%)\n",
      "[epoch 19] loss: 0.0313212\n",
      "Test set: Average loss: 3.0420, Accuracy: 2263/5000 (45%)\n",
      "[epoch 20] loss: 0.0277379\n",
      "Test set: Average loss: 3.0606, Accuracy: 2278/5000 (46%)\n",
      "[epoch 21] loss: 0.0251881\n",
      "Test set: Average loss: 3.0770, Accuracy: 2262/5000 (45%)\n",
      "[epoch 22] loss: 0.0231650\n",
      "Test set: Average loss: 3.0919, Accuracy: 2270/5000 (45%)\n",
      "[epoch 23] loss: 0.0217362\n",
      "Test set: Average loss: 3.1085, Accuracy: 2267/5000 (45%)\n",
      "[epoch 24] loss: 0.0202762\n",
      "Test set: Average loss: 3.1275, Accuracy: 2272/5000 (45%)\n",
      "[epoch 25] loss: 0.0191098\n",
      "Test set: Average loss: 3.1421, Accuracy: 2271/5000 (45%)\n",
      "[epoch 26] loss: 0.0182311\n",
      "Test set: Average loss: 3.1600, Accuracy: 2270/5000 (45%)\n",
      "[epoch 27] loss: 0.0174649\n",
      "Test set: Average loss: 3.1737, Accuracy: 2271/5000 (45%)\n",
      "[epoch 28] loss: 0.0168690\n",
      "Test set: Average loss: 3.1851, Accuracy: 2270/5000 (45%)\n",
      "[epoch 29] loss: 0.0161549\n",
      "Test set: Average loss: 3.2035, Accuracy: 2269/5000 (45%)\n",
      "[epoch 30] loss: 0.0162416\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.2163, Accuracy: 2266/5000 (45%)\n",
      "[epoch 31] loss: 0.0146970\n",
      "Test set: Average loss: 3.2164, Accuracy: 2268/5000 (45%)\n",
      "[epoch 32] loss: 0.0144708\n",
      "Test set: Average loss: 3.2176, Accuracy: 2265/5000 (45%)\n",
      "[epoch 33] loss: 0.0144182\n",
      "Test set: Average loss: 3.2194, Accuracy: 2267/5000 (45%)\n",
      "[epoch 34] loss: 0.0150306\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.2206, Accuracy: 2268/5000 (45%)\n",
      "[epoch 35] loss: 0.0143828\n",
      "Test set: Average loss: 3.2207, Accuracy: 2268/5000 (45%)\n",
      "[epoch 36] loss: 0.0142764\n",
      "Test set: Average loss: 3.2209, Accuracy: 2268/5000 (45%)\n",
      "[epoch 37] loss: 0.0143902\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 38] loss: 0.0144894\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 39] loss: 0.0148524\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 40] loss: 0.0143654\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 41] loss: 0.0147276\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 42] loss: 0.0140925\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 43] loss: 0.0142820\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 44] loss: 0.0143884\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 45] loss: 0.0141921\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 46] loss: 0.0143198\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 47] loss: 0.0140557\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 48] loss: 0.0147497\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 49] loss: 0.0144489\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "[epoch 50] loss: 0.0142613\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.2211, Accuracy: 2268/5000 (45%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5019, Accuracy: 2348/5000 (47%)\n",
      "Test\n",
      "Test set: Average loss: 1.4723, Accuracy: 4771/10000 (48%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3020, Accuracy: 501/5000 (10%)\n",
      "[epoch 1] loss: 1.9612057\n",
      "Test set: Average loss: 1.9008, Accuracy: 1789/5000 (36%)\n",
      "[epoch 2] loss: 1.5487749\n",
      "Test set: Average loss: 1.7077, Accuracy: 1885/5000 (38%)\n",
      "[epoch 3] loss: 1.4311454\n",
      "Test set: Average loss: 1.5646, Accuracy: 2181/5000 (44%)\n",
      "[epoch 4] loss: 1.1342771\n",
      "Test set: Average loss: 1.6763, Accuracy: 2208/5000 (44%)\n",
      "[epoch 5] loss: 1.0275820\n",
      "Test set: Average loss: 1.7088, Accuracy: 2153/5000 (43%)\n",
      "[epoch 6] loss: 0.8624114\n",
      "Test set: Average loss: 1.6569, Accuracy: 2294/5000 (46%)\n",
      "[epoch 7] loss: 0.7435110\n",
      "Test set: Average loss: 1.7220, Accuracy: 2374/5000 (47%)\n",
      "[epoch 8] loss: 0.6592009\n",
      "Test set: Average loss: 2.0638, Accuracy: 2130/5000 (43%)\n",
      "[epoch 9] loss: 0.6346997\n",
      "Test set: Average loss: 2.0036, Accuracy: 2273/5000 (45%)\n",
      "[epoch 10] loss: 0.5188649\n",
      "Test set: Average loss: 2.1217, Accuracy: 2245/5000 (45%)\n",
      "[epoch 11] loss: 0.3565949\n",
      "Test set: Average loss: 2.1466, Accuracy: 2294/5000 (46%)\n",
      "[epoch 12] loss: 0.2692922\n",
      "Test set: Average loss: 2.2555, Accuracy: 2349/5000 (47%)\n",
      "[epoch 13] loss: 0.1968373\n",
      "Test set: Average loss: 2.6039, Accuracy: 2158/5000 (43%)\n",
      "[epoch 14] loss: 0.1317490\n",
      "Test set: Average loss: 2.6120, Accuracy: 2308/5000 (46%)\n",
      "[epoch 15] loss: 0.1025869\n",
      "Test set: Average loss: 3.0438, Accuracy: 2104/5000 (42%)\n",
      "[epoch 16] loss: 0.0992992\n",
      "Test set: Average loss: 3.0815, Accuracy: 2163/5000 (43%)\n",
      "[epoch 17] loss: 0.0710673\n",
      "Test set: Average loss: 3.1503, Accuracy: 2244/5000 (45%)\n",
      "[epoch 18] loss: 0.1158501\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.2323, Accuracy: 2212/5000 (44%)\n",
      "[epoch 19] loss: 0.0439229\n",
      "Test set: Average loss: 3.1394, Accuracy: 2240/5000 (45%)\n",
      "[epoch 20] loss: 0.0196119\n",
      "Test set: Average loss: 3.1530, Accuracy: 2241/5000 (45%)\n",
      "[epoch 21] loss: 0.0159893\n",
      "Test set: Average loss: 3.1643, Accuracy: 2241/5000 (45%)\n",
      "[epoch 22] loss: 0.0145054\n",
      "Test set: Average loss: 3.1772, Accuracy: 2246/5000 (45%)\n",
      "[epoch 23] loss: 0.0137044\n",
      "Test set: Average loss: 3.1842, Accuracy: 2257/5000 (45%)\n",
      "[epoch 24] loss: 0.0129944\n",
      "Test set: Average loss: 3.1954, Accuracy: 2257/5000 (45%)\n",
      "[epoch 25] loss: 0.0117412\n",
      "Test set: Average loss: 3.2054, Accuracy: 2268/5000 (45%)\n",
      "[epoch 26] loss: 0.0110147\n",
      "Test set: Average loss: 3.2153, Accuracy: 2267/5000 (45%)\n",
      "[epoch 27] loss: 0.0104678\n",
      "Test set: Average loss: 3.2251, Accuracy: 2269/5000 (45%)\n",
      "[epoch 28] loss: 0.0099815\n",
      "Test set: Average loss: 3.2321, Accuracy: 2269/5000 (45%)\n",
      "[epoch 29] loss: 0.0094929\n",
      "Test set: Average loss: 3.2407, Accuracy: 2269/5000 (45%)\n",
      "[epoch 30] loss: 0.0089842\n",
      "Test set: Average loss: 3.2498, Accuracy: 2266/5000 (45%)\n",
      "[epoch 31] loss: 0.0087151\n",
      "Test set: Average loss: 3.2587, Accuracy: 2268/5000 (45%)\n",
      "[epoch 32] loss: 0.0083515\n",
      "Test set: Average loss: 3.2666, Accuracy: 2269/5000 (45%)\n",
      "[epoch 33] loss: 0.0083340\n",
      "Test set: Average loss: 3.2760, Accuracy: 2270/5000 (45%)\n",
      "[epoch 34] loss: 0.0078025\n",
      "Test set: Average loss: 3.2864, Accuracy: 2274/5000 (45%)\n",
      "[epoch 35] loss: 0.0075605\n",
      "Test set: Average loss: 3.2913, Accuracy: 2276/5000 (46%)\n",
      "[epoch 36] loss: 0.0073968\n",
      "Test set: Average loss: 3.3000, Accuracy: 2280/5000 (46%)\n",
      "[epoch 37] loss: 0.0071889\n",
      "Test set: Average loss: 3.3086, Accuracy: 2275/5000 (46%)\n",
      "[epoch 38] loss: 0.0068852\n",
      "Test set: Average loss: 3.3178, Accuracy: 2272/5000 (45%)\n",
      "[epoch 39] loss: 0.0065796\n",
      "Test set: Average loss: 3.3256, Accuracy: 2278/5000 (46%)\n",
      "[epoch 40] loss: 0.0064310\n",
      "Test set: Average loss: 3.3349, Accuracy: 2274/5000 (45%)\n",
      "[epoch 41] loss: 0.0062130\n",
      "Test set: Average loss: 3.3421, Accuracy: 2279/5000 (46%)\n",
      "[epoch 42] loss: 0.0061088\n",
      "Test set: Average loss: 3.3501, Accuracy: 2277/5000 (46%)\n",
      "[epoch 43] loss: 0.0059480\n",
      "Test set: Average loss: 3.3585, Accuracy: 2275/5000 (46%)\n",
      "[epoch 44] loss: 0.0059271\n",
      "Test set: Average loss: 3.3666, Accuracy: 2277/5000 (46%)\n",
      "[epoch 45] loss: 0.0055454\n",
      "Test set: Average loss: 3.3761, Accuracy: 2274/5000 (45%)\n",
      "[epoch 46] loss: 0.0055330\n",
      "Test set: Average loss: 3.3821, Accuracy: 2275/5000 (46%)\n",
      "[epoch 47] loss: 0.0052807\n",
      "Test set: Average loss: 3.3899, Accuracy: 2270/5000 (45%)\n",
      "[epoch 48] loss: 0.0051548\n",
      "Test set: Average loss: 3.3979, Accuracy: 2277/5000 (46%)\n",
      "[epoch 49] loss: 0.0051408\n",
      "Test set: Average loss: 3.4059, Accuracy: 2274/5000 (45%)\n",
      "[epoch 50] loss: 0.0049671\n",
      "Test set: Average loss: 3.4138, Accuracy: 2282/5000 (46%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7220, Accuracy: 2374/5000 (47%)\n",
      "Test\n",
      "Test set: Average loss: 1.7068, Accuracy: 4781/10000 (48%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 448/5000 (9%)\n",
      "[epoch 1] loss: 2.0290049\n",
      "Test set: Average loss: 1.8050, Accuracy: 2003/5000 (40%)\n",
      "[epoch 2] loss: 1.6054354\n",
      "Test set: Average loss: 1.6118, Accuracy: 2186/5000 (44%)\n",
      "[epoch 3] loss: 1.4070245\n",
      "Test set: Average loss: 1.5527, Accuracy: 2264/5000 (45%)\n",
      "[epoch 4] loss: 1.2094871\n",
      "Test set: Average loss: 1.6156, Accuracy: 2223/5000 (44%)\n",
      "[epoch 5] loss: 1.0814975\n",
      "Test set: Average loss: 1.5498, Accuracy: 2380/5000 (48%)\n",
      "[epoch 6] loss: 0.9354668\n",
      "Test set: Average loss: 1.6174, Accuracy: 2269/5000 (45%)\n",
      "[epoch 7] loss: 0.8090378\n",
      "Test set: Average loss: 1.7508, Accuracy: 2320/5000 (46%)\n",
      "[epoch 8] loss: 0.6844066\n",
      "Test set: Average loss: 1.8532, Accuracy: 2270/5000 (45%)\n",
      "[epoch 9] loss: 0.6003317\n",
      "Test set: Average loss: 1.9987, Accuracy: 2232/5000 (45%)\n",
      "[epoch 10] loss: 0.4488758\n",
      "Test set: Average loss: 2.1828, Accuracy: 2259/5000 (45%)\n",
      "[epoch 11] loss: 0.4133677\n",
      "Test set: Average loss: 2.2777, Accuracy: 2321/5000 (46%)\n",
      "[epoch 12] loss: 0.3860646\n",
      "Test set: Average loss: 2.4463, Accuracy: 2183/5000 (44%)\n",
      "[epoch 13] loss: 0.3758848\n",
      "Test set: Average loss: 2.5792, Accuracy: 2105/5000 (42%)\n",
      "[epoch 14] loss: 0.2448920\n",
      "Test set: Average loss: 2.7871, Accuracy: 2114/5000 (42%)\n",
      "[epoch 15] loss: 0.1768142\n",
      "Test set: Average loss: 2.8515, Accuracy: 2163/5000 (43%)\n",
      "[epoch 16] loss: 0.1239983\n",
      "Test set: Average loss: 3.0189, Accuracy: 2196/5000 (44%)\n",
      "[epoch 17] loss: 0.0839052\n",
      "Test set: Average loss: 3.1276, Accuracy: 2217/5000 (44%)\n",
      "[epoch 18] loss: 0.0649332\n",
      "Test set: Average loss: 3.2343, Accuracy: 2216/5000 (44%)\n",
      "[epoch 19] loss: 0.0546962\n",
      "Test set: Average loss: 3.4287, Accuracy: 2181/5000 (44%)\n",
      "[epoch 20] loss: 0.0424146\n",
      "Test set: Average loss: 3.5798, Accuracy: 2161/5000 (43%)\n",
      "[epoch 21] loss: 0.0386155\n",
      "Test set: Average loss: 3.6344, Accuracy: 2123/5000 (42%)\n",
      "[epoch 22] loss: 0.0495560\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.6753, Accuracy: 2163/5000 (43%)\n",
      "[epoch 23] loss: 0.0225617\n",
      "Test set: Average loss: 3.6184, Accuracy: 2203/5000 (44%)\n",
      "[epoch 24] loss: 0.0119354\n",
      "Test set: Average loss: 3.6128, Accuracy: 2198/5000 (44%)\n",
      "[epoch 25] loss: 0.0097372\n",
      "Test set: Average loss: 3.6177, Accuracy: 2212/5000 (44%)\n",
      "[epoch 26] loss: 0.0086207\n",
      "Test set: Average loss: 3.6206, Accuracy: 2206/5000 (44%)\n",
      "[epoch 27] loss: 0.0082616\n",
      "Test set: Average loss: 3.6280, Accuracy: 2202/5000 (44%)\n",
      "[epoch 28] loss: 0.0074910\n",
      "Test set: Average loss: 3.6337, Accuracy: 2206/5000 (44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] loss: 0.0070372\n",
      "Test set: Average loss: 3.6400, Accuracy: 2203/5000 (44%)\n",
      "[epoch 30] loss: 0.0068335\n",
      "Test set: Average loss: 3.6464, Accuracy: 2209/5000 (44%)\n",
      "[epoch 31] loss: 0.0066198\n",
      "Test set: Average loss: 3.6507, Accuracy: 2210/5000 (44%)\n",
      "[epoch 32] loss: 0.0061747\n",
      "Test set: Average loss: 3.6570, Accuracy: 2213/5000 (44%)\n",
      "[epoch 33] loss: 0.0059804\n",
      "Test set: Average loss: 3.6639, Accuracy: 2215/5000 (44%)\n",
      "[epoch 34] loss: 0.0058688\n",
      "Test set: Average loss: 3.6688, Accuracy: 2221/5000 (44%)\n",
      "[epoch 35] loss: 0.0054642\n",
      "Test set: Average loss: 3.6731, Accuracy: 2217/5000 (44%)\n",
      "[epoch 36] loss: 0.0054101\n",
      "Test set: Average loss: 3.6801, Accuracy: 2216/5000 (44%)\n",
      "[epoch 37] loss: 0.0051941\n",
      "Test set: Average loss: 3.6866, Accuracy: 2216/5000 (44%)\n",
      "[epoch 38] loss: 0.0050682\n",
      "Test set: Average loss: 3.6927, Accuracy: 2214/5000 (44%)\n",
      "[epoch 39] loss: 0.0049101\n",
      "Test set: Average loss: 3.6989, Accuracy: 2214/5000 (44%)\n",
      "[epoch 40] loss: 0.0047707\n",
      "Test set: Average loss: 3.7040, Accuracy: 2214/5000 (44%)\n",
      "[epoch 41] loss: 0.0046208\n",
      "Test set: Average loss: 3.7114, Accuracy: 2215/5000 (44%)\n",
      "[epoch 42] loss: 0.0044868\n",
      "Test set: Average loss: 3.7170, Accuracy: 2215/5000 (44%)\n",
      "[epoch 43] loss: 0.0043687\n",
      "Test set: Average loss: 3.7222, Accuracy: 2215/5000 (44%)\n",
      "[epoch 44] loss: 0.0043624\n",
      "Test set: Average loss: 3.7267, Accuracy: 2218/5000 (44%)\n",
      "[epoch 45] loss: 0.0042355\n",
      "Test set: Average loss: 3.7317, Accuracy: 2211/5000 (44%)\n",
      "[epoch 46] loss: 0.0041134\n",
      "Test set: Average loss: 3.7390, Accuracy: 2211/5000 (44%)\n",
      "[epoch 47] loss: 0.0039664\n",
      "Test set: Average loss: 3.7460, Accuracy: 2213/5000 (44%)\n",
      "[epoch 48] loss: 0.0039021\n",
      "Test set: Average loss: 3.7511, Accuracy: 2211/5000 (44%)\n",
      "[epoch 49] loss: 0.0038427\n",
      "Test set: Average loss: 3.7576, Accuracy: 2213/5000 (44%)\n",
      "[epoch 50] loss: 0.0037999\n",
      "Test set: Average loss: 3.7639, Accuracy: 2210/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5498, Accuracy: 2380/5000 (48%)\n",
      "Test\n",
      "Test set: Average loss: 1.5465, Accuracy: 4681/10000 (47%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 508/5000 (10%)\n",
      "[epoch 1] loss: 1.8170865\n",
      "Test set: Average loss: 1.6366, Accuracy: 2007/5000 (40%)\n",
      "[epoch 2] loss: 1.4369603\n",
      "Test set: Average loss: 1.4029, Accuracy: 2487/5000 (50%)\n",
      "[epoch 3] loss: 1.2364498\n",
      "Test set: Average loss: 1.5298, Accuracy: 2331/5000 (47%)\n",
      "[epoch 4] loss: 1.1780182\n",
      "Test set: Average loss: 1.6125, Accuracy: 2344/5000 (47%)\n",
      "[epoch 5] loss: 1.0969184\n",
      "Test set: Average loss: 1.4901, Accuracy: 2452/5000 (49%)\n",
      "[epoch 6] loss: 0.9712441\n",
      "Test set: Average loss: 1.5400, Accuracy: 2461/5000 (49%)\n",
      "[epoch 7] loss: 0.9169555\n",
      "Test set: Average loss: 1.4986, Accuracy: 2531/5000 (51%)\n",
      "[epoch 8] loss: 0.8583922\n",
      "Test set: Average loss: 1.6499, Accuracy: 2359/5000 (47%)\n",
      "[epoch 9] loss: 0.7699613\n",
      "Test set: Average loss: 1.5855, Accuracy: 2561/5000 (51%)\n",
      "[epoch 10] loss: 0.7702310\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6890, Accuracy: 2535/5000 (51%)\n",
      "[epoch 11] loss: 0.5558581\n",
      "Test set: Average loss: 1.6032, Accuracy: 2597/5000 (52%)\n",
      "[epoch 12] loss: 0.4284876\n",
      "Test set: Average loss: 1.6229, Accuracy: 2606/5000 (52%)\n",
      "[epoch 13] loss: 0.4049884\n",
      "Test set: Average loss: 1.6544, Accuracy: 2582/5000 (52%)\n",
      "[epoch 14] loss: 0.3849811\n",
      "Test set: Average loss: 1.6708, Accuracy: 2586/5000 (52%)\n",
      "[epoch 15] loss: 0.3615999\n",
      "Test set: Average loss: 1.6876, Accuracy: 2599/5000 (52%)\n",
      "[epoch 16] loss: 0.3517065\n",
      "Test set: Average loss: 1.7250, Accuracy: 2579/5000 (52%)\n",
      "[epoch 17] loss: 0.3364512\n",
      "Test set: Average loss: 1.7497, Accuracy: 2601/5000 (52%)\n",
      "[epoch 18] loss: 0.3232899\n",
      "Test set: Average loss: 1.7765, Accuracy: 2578/5000 (52%)\n",
      "[epoch 19] loss: 0.3106316\n",
      "Test set: Average loss: 1.8059, Accuracy: 2569/5000 (51%)\n",
      "[epoch 20] loss: 0.2973442\n",
      "Test set: Average loss: 1.8367, Accuracy: 2587/5000 (52%)\n",
      "[epoch 21] loss: 0.2869224\n",
      "Test set: Average loss: 1.8781, Accuracy: 2553/5000 (51%)\n",
      "[epoch 22] loss: 0.2775363\n",
      "Test set: Average loss: 1.9009, Accuracy: 2563/5000 (51%)\n",
      "[epoch 23] loss: 0.2672888\n",
      "Test set: Average loss: 1.9303, Accuracy: 2584/5000 (52%)\n",
      "[epoch 24] loss: 0.2545382\n",
      "Test set: Average loss: 1.9667, Accuracy: 2593/5000 (52%)\n",
      "[epoch 25] loss: 0.3657057\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0205, Accuracy: 2541/5000 (51%)\n",
      "[epoch 26] loss: 0.2269172\n",
      "Test set: Average loss: 1.9908, Accuracy: 2552/5000 (51%)\n",
      "[epoch 27] loss: 0.2171218\n",
      "Test set: Average loss: 1.9951, Accuracy: 2570/5000 (51%)\n",
      "[epoch 28] loss: 0.2148909\n",
      "Test set: Average loss: 2.0009, Accuracy: 2569/5000 (51%)\n",
      "[epoch 29] loss: 0.2133024\n",
      "Test set: Average loss: 2.0030, Accuracy: 2562/5000 (51%)\n",
      "[epoch 30] loss: 0.2116100\n",
      "Test set: Average loss: 2.0078, Accuracy: 2559/5000 (51%)\n",
      "[epoch 31] loss: 0.2115111\n",
      "Test set: Average loss: 2.0101, Accuracy: 2560/5000 (51%)\n",
      "[epoch 32] loss: 0.2172803\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0141, Accuracy: 2552/5000 (51%)\n",
      "[epoch 33] loss: 0.2115363\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0148, Accuracy: 2551/5000 (51%)\n",
      "[epoch 34] loss: 0.2067785\n",
      "Test set: Average loss: 2.0149, Accuracy: 2551/5000 (51%)\n",
      "[epoch 35] loss: 0.2077911\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0149, Accuracy: 2550/5000 (51%)\n",
      "[epoch 36] loss: 0.2122839\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 37] loss: 0.3013154\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 38] loss: 0.2100610\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 39] loss: 0.2091337\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 40] loss: 0.2079892\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 41] loss: 0.2070274\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 42] loss: 0.2080705\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 43] loss: 0.2096268\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 44] loss: 0.2066528\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 45] loss: 0.2117048\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 46] loss: 0.2075863\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 47] loss: 0.2099506\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 48] loss: 0.2075485\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 49] loss: 0.2092227\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "[epoch 50] loss: 0.2069712\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0150, Accuracy: 2550/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6229, Accuracy: 2606/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.5960, Accuracy: 5303/10000 (53%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 515/5000 (10%)\n",
      "[epoch 1] loss: 1.7668428\n",
      "Test set: Average loss: 1.4912, Accuracy: 2368/5000 (47%)\n",
      "[epoch 2] loss: 1.3813508\n",
      "Test set: Average loss: 1.5752, Accuracy: 2237/5000 (45%)\n",
      "[epoch 3] loss: 1.2036841\n",
      "Test set: Average loss: 1.4153, Accuracy: 2521/5000 (50%)\n",
      "[epoch 4] loss: 1.0884169\n",
      "Test set: Average loss: 1.6756, Accuracy: 2316/5000 (46%)\n",
      "[epoch 5] loss: 1.0448272\n",
      "Test set: Average loss: 1.5308, Accuracy: 2433/5000 (49%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.9112714\n",
      "Test set: Average loss: 1.5111, Accuracy: 2520/5000 (50%)\n",
      "[epoch 7] loss: 0.9249437\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6085, Accuracy: 2400/5000 (48%)\n",
      "[epoch 8] loss: 0.6714940\n",
      "Test set: Average loss: 1.4893, Accuracy: 2620/5000 (52%)\n",
      "[epoch 9] loss: 0.5263359\n",
      "Test set: Average loss: 1.5100, Accuracy: 2635/5000 (53%)\n",
      "[epoch 10] loss: 0.5009726\n",
      "Test set: Average loss: 1.5305, Accuracy: 2634/5000 (53%)\n",
      "[epoch 11] loss: 0.4850300\n",
      "Test set: Average loss: 1.5526, Accuracy: 2649/5000 (53%)\n",
      "[epoch 12] loss: 0.4608110\n",
      "Test set: Average loss: 1.5711, Accuracy: 2656/5000 (53%)\n",
      "[epoch 13] loss: 0.4500763\n",
      "Test set: Average loss: 1.5897, Accuracy: 2671/5000 (53%)\n",
      "[epoch 14] loss: 0.4358906\n",
      "Test set: Average loss: 1.6200, Accuracy: 2661/5000 (53%)\n",
      "[epoch 15] loss: 0.4105182\n",
      "Test set: Average loss: 1.6403, Accuracy: 2653/5000 (53%)\n",
      "[epoch 16] loss: 0.3952551\n",
      "Test set: Average loss: 1.6719, Accuracy: 2629/5000 (53%)\n",
      "[epoch 17] loss: 0.3926104\n",
      "Test set: Average loss: 1.7194, Accuracy: 2605/5000 (52%)\n",
      "[epoch 18] loss: 0.3683723\n",
      "Test set: Average loss: 1.7404, Accuracy: 2597/5000 (52%)\n",
      "[epoch 19] loss: 0.4311704\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7600, Accuracy: 2619/5000 (52%)\n",
      "[epoch 20] loss: 0.3269754\n",
      "Test set: Average loss: 1.7596, Accuracy: 2617/5000 (52%)\n",
      "[epoch 21] loss: 0.3192857\n",
      "Test set: Average loss: 1.7626, Accuracy: 2621/5000 (52%)\n",
      "[epoch 22] loss: 0.3147750\n",
      "Test set: Average loss: 1.7647, Accuracy: 2623/5000 (52%)\n",
      "[epoch 23] loss: 0.3141103\n",
      "Test set: Average loss: 1.7669, Accuracy: 2619/5000 (52%)\n",
      "[epoch 24] loss: 0.3147953\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7693, Accuracy: 2624/5000 (52%)\n",
      "[epoch 25] loss: 0.3169097\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7693, Accuracy: 2624/5000 (52%)\n",
      "[epoch 26] loss: 0.3091766\n",
      "Test set: Average loss: 1.7694, Accuracy: 2624/5000 (52%)\n",
      "[epoch 27] loss: 0.3082649\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 28] loss: 0.3106854\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 29] loss: 0.3095225\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 30] loss: 0.3197846\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 31] loss: 0.3124081\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 32] loss: 0.3129635\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 33] loss: 0.3108620\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 34] loss: 0.3122658\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 35] loss: 0.4324091\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 36] loss: 0.3127784\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 37] loss: 0.3101391\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 38] loss: 0.3087401\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 39] loss: 0.3186389\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 40] loss: 0.3114478\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 41] loss: 0.3168168\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 42] loss: 0.3086025\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 43] loss: 0.3132710\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 44] loss: 0.3094997\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 45] loss: 0.3108818\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 46] loss: 0.3087926\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 47] loss: 0.3126524\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 48] loss: 0.3131388\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 49] loss: 0.3095450\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "[epoch 50] loss: 0.3108321\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.7695, Accuracy: 2623/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5897, Accuracy: 2671/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.5232, Accuracy: 5451/10000 (55%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3029, Accuracy: 516/5000 (10%)\n",
      "[epoch 1] loss: 1.8225822\n",
      "Test set: Average loss: 1.5968, Accuracy: 2130/5000 (43%)\n",
      "[epoch 2] loss: 1.4951761\n",
      "Test set: Average loss: 1.3900, Accuracy: 2548/5000 (51%)\n",
      "[epoch 3] loss: 1.2904701\n",
      "Test set: Average loss: 1.3861, Accuracy: 2485/5000 (50%)\n",
      "[epoch 4] loss: 1.1626463\n",
      "Test set: Average loss: 1.4141, Accuracy: 2510/5000 (50%)\n",
      "[epoch 5] loss: 1.0680273\n",
      "Test set: Average loss: 1.5443, Accuracy: 2368/5000 (47%)\n",
      "[epoch 6] loss: 0.9805520\n",
      "Test set: Average loss: 1.5098, Accuracy: 2458/5000 (49%)\n",
      "[epoch 7] loss: 0.9162829\n",
      "Test set: Average loss: 1.5754, Accuracy: 2476/5000 (50%)\n",
      "[epoch 8] loss: 0.8967093\n",
      "Test set: Average loss: 1.5884, Accuracy: 2426/5000 (49%)\n",
      "[epoch 9] loss: 0.7818016\n",
      "Test set: Average loss: 1.7920, Accuracy: 2299/5000 (46%)\n",
      "[epoch 10] loss: 0.8591632\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7193, Accuracy: 2461/5000 (49%)\n",
      "[epoch 11] loss: 0.5211013\n",
      "Test set: Average loss: 1.6340, Accuracy: 2563/5000 (51%)\n",
      "[epoch 12] loss: 0.4365279\n",
      "Test set: Average loss: 1.6668, Accuracy: 2542/5000 (51%)\n",
      "[epoch 13] loss: 0.4095599\n",
      "Test set: Average loss: 1.6944, Accuracy: 2582/5000 (52%)\n",
      "[epoch 14] loss: 0.3922150\n",
      "Test set: Average loss: 1.7183, Accuracy: 2583/5000 (52%)\n",
      "[epoch 15] loss: 0.3734253\n",
      "Test set: Average loss: 1.7557, Accuracy: 2560/5000 (51%)\n",
      "[epoch 16] loss: 0.3584558\n",
      "Test set: Average loss: 1.7829, Accuracy: 2555/5000 (51%)\n",
      "[epoch 17] loss: 0.3444733\n",
      "Test set: Average loss: 1.8190, Accuracy: 2572/5000 (51%)\n",
      "[epoch 18] loss: 0.3317562\n",
      "Test set: Average loss: 1.8663, Accuracy: 2543/5000 (51%)\n",
      "[epoch 19] loss: 0.3191233\n",
      "Test set: Average loss: 1.8751, Accuracy: 2536/5000 (51%)\n",
      "[epoch 20] loss: 0.3120960\n",
      "Test set: Average loss: 1.9240, Accuracy: 2532/5000 (51%)\n",
      "[epoch 21] loss: 0.2993693\n",
      "Test set: Average loss: 1.9538, Accuracy: 2514/5000 (50%)\n",
      "[epoch 22] loss: 0.2780056\n",
      "Test set: Average loss: 1.9838, Accuracy: 2521/5000 (50%)\n",
      "[epoch 23] loss: 0.3727695\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0252, Accuracy: 2520/5000 (50%)\n",
      "[epoch 24] loss: 0.2530411\n",
      "Test set: Average loss: 2.0153, Accuracy: 2514/5000 (50%)\n",
      "[epoch 25] loss: 0.2433842\n",
      "Test set: Average loss: 2.0181, Accuracy: 2514/5000 (50%)\n",
      "[epoch 26] loss: 0.2397283\n",
      "Test set: Average loss: 2.0227, Accuracy: 2520/5000 (50%)\n",
      "[epoch 27] loss: 0.2394960\n",
      "Test set: Average loss: 2.0293, Accuracy: 2523/5000 (50%)\n",
      "[epoch 28] loss: 0.2358860\n",
      "Test set: Average loss: 2.0337, Accuracy: 2522/5000 (50%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] loss: 0.2354360\n",
      "Test set: Average loss: 2.0380, Accuracy: 2515/5000 (50%)\n",
      "[epoch 30] loss: 0.2355420\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0441, Accuracy: 2514/5000 (50%)\n",
      "[epoch 31] loss: 0.2316684\n",
      "Test set: Average loss: 2.0443, Accuracy: 2517/5000 (50%)\n",
      "[epoch 32] loss: 0.3738849\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2517/5000 (50%)\n",
      "[epoch 33] loss: 0.2342664\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 34] loss: 0.2328844\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 35] loss: 0.2308013\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 36] loss: 0.2318342\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 37] loss: 0.2315398\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 38] loss: 0.2300221\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 39] loss: 0.2334186\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 40] loss: 0.2319773\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 41] loss: 0.2352709\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 42] loss: 0.2330870\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 43] loss: 0.3734360\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 44] loss: 0.2310637\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 45] loss: 0.2318760\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0590, Accuracy: 2514/5000 (50%)\n",
      "[epoch 46] loss: 0.2306931\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 47] loss: 0.2307449\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 48] loss: 0.2314100\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 49] loss: 0.2301655\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "[epoch 50] loss: 0.2305630\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0448, Accuracy: 2518/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7183, Accuracy: 2583/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.6787, Accuracy: 5251/10000 (53%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3018, Accuracy: 536/5000 (11%)\n",
      "[epoch 1] loss: 1.6310434\n",
      "Test set: Average loss: 1.4497, Accuracy: 2480/5000 (50%)\n",
      "[epoch 2] loss: 1.2983721\n",
      "Test set: Average loss: 1.3263, Accuracy: 2658/5000 (53%)\n",
      "[epoch 3] loss: 1.1681598\n",
      "Test set: Average loss: 1.2896, Accuracy: 2787/5000 (56%)\n",
      "[epoch 4] loss: 1.0854289\n",
      "Test set: Average loss: 1.3466, Accuracy: 2656/5000 (53%)\n",
      "[epoch 5] loss: 1.0323415\n",
      "Test set: Average loss: 1.4609, Accuracy: 2528/5000 (51%)\n",
      "[epoch 6] loss: 0.9767373\n",
      "Test set: Average loss: 1.4237, Accuracy: 2602/5000 (52%)\n",
      "[epoch 7] loss: 0.9528240\n",
      "Test set: Average loss: 1.4687, Accuracy: 2566/5000 (51%)\n",
      "[epoch 8] loss: 0.9068122\n",
      "Test set: Average loss: 1.3940, Accuracy: 2715/5000 (54%)\n",
      "[epoch 9] loss: 0.8600848\n",
      "Test set: Average loss: 1.4694, Accuracy: 2649/5000 (53%)\n",
      "[epoch 10] loss: 0.8404201\n",
      "Test set: Average loss: 1.4556, Accuracy: 2611/5000 (52%)\n",
      "[epoch 11] loss: 0.8057844\n",
      "Test set: Average loss: 1.5780, Accuracy: 2631/5000 (53%)\n",
      "[epoch 12] loss: 0.7920602\n",
      "Test set: Average loss: 1.5328, Accuracy: 2629/5000 (53%)\n",
      "[epoch 13] loss: 0.7277130\n",
      "Test set: Average loss: 1.5727, Accuracy: 2628/5000 (53%)\n",
      "[epoch 14] loss: 0.7315952\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5467, Accuracy: 2679/5000 (54%)\n",
      "[epoch 15] loss: 0.4936467\n",
      "Test set: Average loss: 1.5109, Accuracy: 2741/5000 (55%)\n",
      "[epoch 16] loss: 0.4453271\n",
      "Test set: Average loss: 1.5625, Accuracy: 2750/5000 (55%)\n",
      "[epoch 17] loss: 0.4271298\n",
      "Test set: Average loss: 1.5965, Accuracy: 2734/5000 (55%)\n",
      "[epoch 18] loss: 0.4106683\n",
      "Test set: Average loss: 1.6258, Accuracy: 2744/5000 (55%)\n",
      "[epoch 19] loss: 0.3978414\n",
      "Test set: Average loss: 1.6587, Accuracy: 2726/5000 (55%)\n",
      "[epoch 20] loss: 0.3877681\n",
      "Test set: Average loss: 1.6883, Accuracy: 2748/5000 (55%)\n",
      "[epoch 21] loss: 0.3766474\n",
      "Test set: Average loss: 1.7223, Accuracy: 2747/5000 (55%)\n",
      "[epoch 22] loss: 0.3661684\n",
      "Test set: Average loss: 1.7566, Accuracy: 2727/5000 (55%)\n",
      "[epoch 23] loss: 0.3561034\n",
      "Test set: Average loss: 1.7861, Accuracy: 2741/5000 (55%)\n",
      "[epoch 24] loss: 0.3460149\n",
      "Test set: Average loss: 1.8215, Accuracy: 2724/5000 (54%)\n",
      "[epoch 25] loss: 0.3381193\n",
      "Test set: Average loss: 1.8404, Accuracy: 2733/5000 (55%)\n",
      "[epoch 26] loss: 0.3288093\n",
      "Test set: Average loss: 1.8899, Accuracy: 2712/5000 (54%)\n",
      "[epoch 27] loss: 0.3205853\n",
      "Test set: Average loss: 1.9175, Accuracy: 2714/5000 (54%)\n",
      "[epoch 28] loss: 0.3118138\n",
      "Test set: Average loss: 1.9558, Accuracy: 2707/5000 (54%)\n",
      "[epoch 29] loss: 0.3033298\n",
      "Test set: Average loss: 1.9826, Accuracy: 2705/5000 (54%)\n",
      "[epoch 30] loss: 0.2955866\n",
      "Test set: Average loss: 2.0226, Accuracy: 2710/5000 (54%)\n",
      "[epoch 31] loss: 0.2854976\n",
      "Test set: Average loss: 2.0563, Accuracy: 2708/5000 (54%)\n",
      "[epoch 32] loss: 0.2794780\n",
      "Test set: Average loss: 2.0869, Accuracy: 2689/5000 (54%)\n",
      "[epoch 33] loss: 0.2697581\n",
      "Test set: Average loss: 2.1210, Accuracy: 2710/5000 (54%)\n",
      "[epoch 34] loss: 0.2636807\n",
      "Test set: Average loss: 2.1666, Accuracy: 2692/5000 (54%)\n",
      "[epoch 35] loss: 0.2551283\n",
      "Test set: Average loss: 2.2108, Accuracy: 2698/5000 (54%)\n",
      "[epoch 36] loss: 0.2498602\n",
      "Test set: Average loss: 2.2426, Accuracy: 2696/5000 (54%)\n",
      "[epoch 37] loss: 0.2413120\n",
      "Test set: Average loss: 2.2742, Accuracy: 2692/5000 (54%)\n",
      "[epoch 38] loss: 0.2333533\n",
      "Test set: Average loss: 2.3120, Accuracy: 2660/5000 (53%)\n",
      "[epoch 39] loss: 0.2283090\n",
      "Test set: Average loss: 2.3451, Accuracy: 2648/5000 (53%)\n",
      "[epoch 40] loss: 0.2203162\n",
      "Test set: Average loss: 2.3891, Accuracy: 2691/5000 (54%)\n",
      "[epoch 41] loss: 0.2143299\n",
      "Test set: Average loss: 2.4253, Accuracy: 2671/5000 (53%)\n",
      "[epoch 42] loss: 0.2058823\n",
      "Test set: Average loss: 2.4765, Accuracy: 2662/5000 (53%)\n",
      "[epoch 43] loss: 0.2004368\n",
      "Test set: Average loss: 2.5064, Accuracy: 2660/5000 (53%)\n",
      "[epoch 44] loss: 0.1923784\n",
      "Test set: Average loss: 2.5621, Accuracy: 2656/5000 (53%)\n",
      "[epoch 45] loss: 0.1880411\n",
      "Test set: Average loss: 2.5761, Accuracy: 2663/5000 (53%)\n",
      "[epoch 46] loss: 0.1807883\n",
      "Test set: Average loss: 2.6289, Accuracy: 2655/5000 (53%)\n",
      "[epoch 47] loss: 0.1735515\n",
      "Test set: Average loss: 2.6798, Accuracy: 2647/5000 (53%)\n",
      "[epoch 48] loss: 0.1685495\n",
      "Test set: Average loss: 2.7190, Accuracy: 2658/5000 (53%)\n",
      "[epoch 49] loss: 0.1607640\n",
      "Test set: Average loss: 2.7689, Accuracy: 2636/5000 (53%)\n",
      "[epoch 50] loss: 0.1559204\n",
      "Test set: Average loss: 2.8145, Accuracy: 2635/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2896, Accuracy: 2787/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.2557, Accuracy: 5666/10000 (57%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 517/5000 (10%)\n",
      "[epoch 1] loss: 1.6586412\n",
      "Test set: Average loss: 1.4600, Accuracy: 2340/5000 (47%)\n",
      "[epoch 2] loss: 1.3031290\n",
      "Test set: Average loss: 1.3557, Accuracy: 2604/5000 (52%)\n",
      "[epoch 3] loss: 1.1733652\n",
      "Test set: Average loss: 1.5501, Accuracy: 2390/5000 (48%)\n",
      "[epoch 4] loss: 1.1502431\n",
      "Test set: Average loss: 1.3652, Accuracy: 2668/5000 (53%)\n",
      "[epoch 5] loss: 1.0214042\n",
      "Test set: Average loss: 1.3791, Accuracy: 2622/5000 (52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.9668877\n",
      "Test set: Average loss: 1.4476, Accuracy: 2609/5000 (52%)\n",
      "[epoch 7] loss: 0.9276199\n",
      "Test set: Average loss: 1.4665, Accuracy: 2619/5000 (52%)\n",
      "[epoch 8] loss: 0.9146127\n",
      "Test set: Average loss: 1.5182, Accuracy: 2585/5000 (52%)\n",
      "[epoch 9] loss: 0.8627147\n",
      "Test set: Average loss: 1.4823, Accuracy: 2599/5000 (52%)\n",
      "[epoch 10] loss: 0.8330985\n",
      "Test set: Average loss: 1.4997, Accuracy: 2597/5000 (52%)\n",
      "[epoch 11] loss: 0.8041991\n",
      "Test set: Average loss: 1.6077, Accuracy: 2558/5000 (51%)\n",
      "[epoch 12] loss: 0.7302567\n",
      "Test set: Average loss: 1.6734, Accuracy: 2516/5000 (50%)\n",
      "[epoch 13] loss: 0.7722592\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6134, Accuracy: 2589/5000 (52%)\n",
      "[epoch 14] loss: 0.5280551\n",
      "Test set: Average loss: 1.5407, Accuracy: 2709/5000 (54%)\n",
      "[epoch 15] loss: 0.4688451\n",
      "Test set: Average loss: 1.5719, Accuracy: 2702/5000 (54%)\n",
      "[epoch 16] loss: 0.4497731\n",
      "Test set: Average loss: 1.6107, Accuracy: 2700/5000 (54%)\n",
      "[epoch 17] loss: 0.4358985\n",
      "Test set: Average loss: 1.6468, Accuracy: 2693/5000 (54%)\n",
      "[epoch 18] loss: 0.4245023\n",
      "Test set: Average loss: 1.6958, Accuracy: 2672/5000 (53%)\n",
      "[epoch 19] loss: 0.4128381\n",
      "Test set: Average loss: 1.7115, Accuracy: 2675/5000 (54%)\n",
      "[epoch 20] loss: 0.4031171\n",
      "Test set: Average loss: 1.7502, Accuracy: 2690/5000 (54%)\n",
      "[epoch 21] loss: 0.3909488\n",
      "Test set: Average loss: 1.7853, Accuracy: 2658/5000 (53%)\n",
      "[epoch 22] loss: 0.3819864\n",
      "Test set: Average loss: 1.8078, Accuracy: 2657/5000 (53%)\n",
      "[epoch 23] loss: 0.3739992\n",
      "Test set: Average loss: 1.8487, Accuracy: 2661/5000 (53%)\n",
      "[epoch 24] loss: 0.3652401\n",
      "Test set: Average loss: 1.8806, Accuracy: 2661/5000 (53%)\n",
      "[epoch 25] loss: 0.3549259\n",
      "Test set: Average loss: 1.9088, Accuracy: 2645/5000 (53%)\n",
      "[epoch 26] loss: 0.3471889\n",
      "Test set: Average loss: 1.9357, Accuracy: 2643/5000 (53%)\n",
      "[epoch 27] loss: 0.3392570\n",
      "Test set: Average loss: 1.9743, Accuracy: 2649/5000 (53%)\n",
      "[epoch 28] loss: 0.3315753\n",
      "Test set: Average loss: 2.0219, Accuracy: 2631/5000 (53%)\n",
      "[epoch 29] loss: 0.3245169\n",
      "Test set: Average loss: 2.0383, Accuracy: 2651/5000 (53%)\n",
      "[epoch 30] loss: 0.3191256\n",
      "Test set: Average loss: 2.0858, Accuracy: 2618/5000 (52%)\n",
      "[epoch 31] loss: 0.3082409\n",
      "Test set: Average loss: 2.1111, Accuracy: 2606/5000 (52%)\n",
      "[epoch 32] loss: 0.3031244\n",
      "Test set: Average loss: 2.1410, Accuracy: 2623/5000 (52%)\n",
      "[epoch 33] loss: 0.2919613\n",
      "Test set: Average loss: 2.1731, Accuracy: 2613/5000 (52%)\n",
      "[epoch 34] loss: 0.2855726\n",
      "Test set: Average loss: 2.2176, Accuracy: 2595/5000 (52%)\n",
      "[epoch 35] loss: 0.2793528\n",
      "Test set: Average loss: 2.2479, Accuracy: 2638/5000 (53%)\n",
      "[epoch 36] loss: 0.2746904\n",
      "Test set: Average loss: 2.2981, Accuracy: 2613/5000 (52%)\n",
      "[epoch 37] loss: 0.2654798\n",
      "Test set: Average loss: 2.3161, Accuracy: 2597/5000 (52%)\n",
      "[epoch 38] loss: 0.2619547\n",
      "Test set: Average loss: 2.3596, Accuracy: 2596/5000 (52%)\n",
      "[epoch 39] loss: 0.2524119\n",
      "Test set: Average loss: 2.3864, Accuracy: 2602/5000 (52%)\n",
      "[epoch 40] loss: 0.2461678\n",
      "Test set: Average loss: 2.4272, Accuracy: 2568/5000 (51%)\n",
      "[epoch 41] loss: 0.2435901\n",
      "Test set: Average loss: 2.4729, Accuracy: 2596/5000 (52%)\n",
      "[epoch 42] loss: 0.2352579\n",
      "Test set: Average loss: 2.4974, Accuracy: 2586/5000 (52%)\n",
      "[epoch 43] loss: 0.2294041\n",
      "Test set: Average loss: 2.5343, Accuracy: 2597/5000 (52%)\n",
      "[epoch 44] loss: 0.2220163\n",
      "Test set: Average loss: 2.5762, Accuracy: 2579/5000 (52%)\n",
      "[epoch 45] loss: 0.2174079\n",
      "Test set: Average loss: 2.5902, Accuracy: 2563/5000 (51%)\n",
      "[epoch 46] loss: 0.2104360\n",
      "Test set: Average loss: 2.6375, Accuracy: 2573/5000 (51%)\n",
      "[epoch 47] loss: 0.2051437\n",
      "Test set: Average loss: 2.6946, Accuracy: 2591/5000 (52%)\n",
      "[epoch 48] loss: 0.1998316\n",
      "Test set: Average loss: 2.7215, Accuracy: 2576/5000 (52%)\n",
      "[epoch 49] loss: 0.1956434\n",
      "Test set: Average loss: 2.7688, Accuracy: 2580/5000 (52%)\n",
      "[epoch 50] loss: 0.1936071\n",
      "Test set: Average loss: 2.7878, Accuracy: 2582/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5407, Accuracy: 2709/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.4548, Accuracy: 5669/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 495/5000 (10%)\n",
      "[epoch 1] loss: 1.6294048\n",
      "Test set: Average loss: 1.4129, Accuracy: 2460/5000 (49%)\n",
      "[epoch 2] loss: 1.3313783\n",
      "Test set: Average loss: 1.3540, Accuracy: 2606/5000 (52%)\n",
      "[epoch 3] loss: 1.2274555\n",
      "Test set: Average loss: 1.3927, Accuracy: 2527/5000 (51%)\n",
      "[epoch 4] loss: 1.1195578\n",
      "Test set: Average loss: 1.3523, Accuracy: 2647/5000 (53%)\n",
      "[epoch 5] loss: 1.0695544\n",
      "Test set: Average loss: 1.3258, Accuracy: 2693/5000 (54%)\n",
      "[epoch 6] loss: 0.9994380\n",
      "Test set: Average loss: 1.4404, Accuracy: 2637/5000 (53%)\n",
      "[epoch 7] loss: 0.9673230\n",
      "Test set: Average loss: 1.3719, Accuracy: 2731/5000 (55%)\n",
      "[epoch 8] loss: 0.9056261\n",
      "Test set: Average loss: 1.3785, Accuracy: 2750/5000 (55%)\n",
      "[epoch 9] loss: 0.8837057\n",
      "Test set: Average loss: 1.4847, Accuracy: 2609/5000 (52%)\n",
      "[epoch 10] loss: 0.8542592\n",
      "Test set: Average loss: 1.5031, Accuracy: 2673/5000 (53%)\n",
      "[epoch 11] loss: 0.8387696\n",
      "Test set: Average loss: 1.6353, Accuracy: 2541/5000 (51%)\n",
      "[epoch 12] loss: 0.8026157\n",
      "Test set: Average loss: 1.5809, Accuracy: 2626/5000 (53%)\n",
      "[epoch 13] loss: 0.7839871\n",
      "Test set: Average loss: 1.5591, Accuracy: 2622/5000 (52%)\n",
      "[epoch 14] loss: 0.7239649\n",
      "Test set: Average loss: 1.6812, Accuracy: 2478/5000 (50%)\n",
      "[epoch 15] loss: 0.7251939\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6295, Accuracy: 2538/5000 (51%)\n",
      "[epoch 16] loss: 0.4931552\n",
      "Test set: Average loss: 1.5384, Accuracy: 2695/5000 (54%)\n",
      "[epoch 17] loss: 0.4326527\n",
      "Test set: Average loss: 1.5777, Accuracy: 2712/5000 (54%)\n",
      "[epoch 18] loss: 0.4128622\n",
      "Test set: Average loss: 1.6118, Accuracy: 2703/5000 (54%)\n",
      "[epoch 19] loss: 0.3982130\n",
      "Test set: Average loss: 1.6449, Accuracy: 2713/5000 (54%)\n",
      "[epoch 20] loss: 0.3863370\n",
      "Test set: Average loss: 1.6880, Accuracy: 2693/5000 (54%)\n",
      "[epoch 21] loss: 0.3779064\n",
      "Test set: Average loss: 1.7239, Accuracy: 2684/5000 (54%)\n",
      "[epoch 22] loss: 0.3679051\n",
      "Test set: Average loss: 1.7416, Accuracy: 2702/5000 (54%)\n",
      "[epoch 23] loss: 0.3554157\n",
      "Test set: Average loss: 1.7870, Accuracy: 2693/5000 (54%)\n",
      "[epoch 24] loss: 0.3488640\n",
      "Test set: Average loss: 1.8137, Accuracy: 2671/5000 (53%)\n",
      "[epoch 25] loss: 0.3406967\n",
      "Test set: Average loss: 1.8383, Accuracy: 2701/5000 (54%)\n",
      "[epoch 26] loss: 0.3297476\n",
      "Test set: Average loss: 1.8723, Accuracy: 2681/5000 (54%)\n",
      "[epoch 27] loss: 0.3219744\n",
      "Test set: Average loss: 1.9091, Accuracy: 2664/5000 (53%)\n",
      "[epoch 28] loss: 0.3108420\n",
      "Test set: Average loss: 1.9445, Accuracy: 2680/5000 (54%)\n",
      "[epoch 29] loss: 0.3059529\n",
      "Test set: Average loss: 1.9976, Accuracy: 2649/5000 (53%)\n",
      "[epoch 30] loss: 0.2990173\n",
      "Test set: Average loss: 1.9962, Accuracy: 2674/5000 (53%)\n",
      "[epoch 31] loss: 0.2941372\n",
      "Test set: Average loss: 2.0344, Accuracy: 2646/5000 (53%)\n",
      "[epoch 32] loss: 0.2823580\n",
      "Test set: Average loss: 2.0614, Accuracy: 2667/5000 (53%)\n",
      "[epoch 33] loss: 0.2752717\n",
      "Test set: Average loss: 2.1024, Accuracy: 2649/5000 (53%)\n",
      "[epoch 34] loss: 0.2672904\n",
      "Test set: Average loss: 2.1231, Accuracy: 2650/5000 (53%)\n",
      "[epoch 35] loss: 0.2582023\n",
      "Test set: Average loss: 2.1612, Accuracy: 2642/5000 (53%)\n",
      "[epoch 36] loss: 0.2535961\n",
      "Test set: Average loss: 2.1942, Accuracy: 2644/5000 (53%)\n",
      "[epoch 37] loss: 0.2513649\n",
      "Test set: Average loss: 2.2241, Accuracy: 2644/5000 (53%)\n",
      "[epoch 38] loss: 0.2390505\n",
      "Test set: Average loss: 2.2531, Accuracy: 2636/5000 (53%)\n",
      "[epoch 39] loss: 0.2307022\n",
      "Test set: Average loss: 2.2964, Accuracy: 2644/5000 (53%)\n",
      "[epoch 40] loss: 0.2253279\n",
      "Test set: Average loss: 2.3199, Accuracy: 2639/5000 (53%)\n",
      "[epoch 41] loss: 0.2213140\n",
      "Test set: Average loss: 2.3637, Accuracy: 2632/5000 (53%)\n",
      "[epoch 42] loss: 0.2143901\n",
      "Test set: Average loss: 2.4017, Accuracy: 2616/5000 (52%)\n",
      "[epoch 43] loss: 0.2098761\n",
      "Test set: Average loss: 2.4353, Accuracy: 2618/5000 (52%)\n",
      "[epoch 44] loss: 0.2024917\n",
      "Test set: Average loss: 2.4670, Accuracy: 2627/5000 (53%)\n",
      "[epoch 45] loss: 0.1998166\n",
      "Test set: Average loss: 2.5008, Accuracy: 2622/5000 (52%)\n",
      "[epoch 46] loss: 0.1870371\n",
      "Test set: Average loss: 2.5424, Accuracy: 2601/5000 (52%)\n",
      "[epoch 47] loss: 0.1819569\n",
      "Test set: Average loss: 2.5835, Accuracy: 2600/5000 (52%)\n",
      "[epoch 48] loss: 0.1777484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.6039, Accuracy: 2603/5000 (52%)\n",
      "[epoch 49] loss: 0.1695100\n",
      "Test set: Average loss: 2.6350, Accuracy: 2616/5000 (52%)\n",
      "[epoch 50] loss: 0.2642801\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.7077, Accuracy: 2581/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3785, Accuracy: 2750/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.3512, Accuracy: 5604/10000 (56%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3038, Accuracy: 426/5000 (9%)\n",
      "[epoch 1] loss: 1.4921930\n",
      "Test set: Average loss: 1.3790, Accuracy: 2588/5000 (52%)\n",
      "[epoch 2] loss: 1.2516219\n",
      "Test set: Average loss: 1.3112, Accuracy: 2655/5000 (53%)\n",
      "[epoch 3] loss: 1.1463255\n",
      "Test set: Average loss: 1.3139, Accuracy: 2736/5000 (55%)\n",
      "[epoch 4] loss: 1.0884192\n",
      "Test set: Average loss: 1.2650, Accuracy: 2772/5000 (55%)\n",
      "[epoch 5] loss: 1.0408898\n",
      "Test set: Average loss: 1.3029, Accuracy: 2707/5000 (54%)\n",
      "[epoch 6] loss: 1.0050410\n",
      "Test set: Average loss: 1.3211, Accuracy: 2723/5000 (54%)\n",
      "[epoch 7] loss: 0.9703741\n",
      "Test set: Average loss: 1.3274, Accuracy: 2726/5000 (55%)\n",
      "[epoch 8] loss: 0.9502315\n",
      "Test set: Average loss: 1.2739, Accuracy: 2833/5000 (57%)\n",
      "[epoch 9] loss: 0.9258966\n",
      "Test set: Average loss: 1.2888, Accuracy: 2793/5000 (56%)\n",
      "[epoch 10] loss: 0.8762675\n",
      "Test set: Average loss: 1.3477, Accuracy: 2749/5000 (55%)\n",
      "[epoch 11] loss: 0.8642259\n",
      "Test set: Average loss: 1.2826, Accuracy: 2861/5000 (57%)\n",
      "[epoch 12] loss: 0.8403871\n",
      "Test set: Average loss: 1.3336, Accuracy: 2753/5000 (55%)\n",
      "[epoch 13] loss: 0.8020815\n",
      "Test set: Average loss: 1.3706, Accuracy: 2786/5000 (56%)\n",
      "[epoch 14] loss: 0.7787212\n",
      "Test set: Average loss: 1.3728, Accuracy: 2754/5000 (55%)\n",
      "[epoch 15] loss: 0.7308612\n",
      "Test set: Average loss: 1.3975, Accuracy: 2740/5000 (55%)\n",
      "[epoch 16] loss: 0.7010107\n",
      "Test set: Average loss: 1.3468, Accuracy: 2830/5000 (57%)\n",
      "[epoch 17] loss: 0.6719739\n",
      "Test set: Average loss: 1.3887, Accuracy: 2766/5000 (55%)\n",
      "[epoch 18] loss: 0.6161157\n",
      "Test set: Average loss: 1.4439, Accuracy: 2778/5000 (56%)\n",
      "[epoch 19] loss: 0.5656340\n",
      "Test set: Average loss: 1.4898, Accuracy: 2771/5000 (55%)\n",
      "[epoch 20] loss: 0.5291717\n",
      "Test set: Average loss: 1.4970, Accuracy: 2785/5000 (56%)\n",
      "[epoch 21] loss: 0.4540290\n",
      "Test set: Average loss: 1.5657, Accuracy: 2801/5000 (56%)\n",
      "[epoch 22] loss: 0.4111367\n",
      "Test set: Average loss: 1.6572, Accuracy: 2714/5000 (54%)\n",
      "[epoch 23] loss: 0.3507104\n",
      "Test set: Average loss: 1.6848, Accuracy: 2817/5000 (56%)\n",
      "[epoch 24] loss: 0.2872016\n",
      "Test set: Average loss: 1.7822, Accuracy: 2829/5000 (57%)\n",
      "[epoch 25] loss: 0.2340861\n",
      "Test set: Average loss: 1.8179, Accuracy: 2819/5000 (56%)\n",
      "[epoch 26] loss: 0.2034938\n",
      "Test set: Average loss: 1.8665, Accuracy: 2780/5000 (56%)\n",
      "[epoch 27] loss: 0.1471932\n",
      "Test set: Average loss: 1.9338, Accuracy: 2808/5000 (56%)\n",
      "[epoch 28] loss: 0.1034616\n",
      "Test set: Average loss: 2.0618, Accuracy: 2777/5000 (56%)\n",
      "[epoch 29] loss: 0.0893754\n",
      "Test set: Average loss: 2.0613, Accuracy: 2817/5000 (56%)\n",
      "[epoch 30] loss: 0.1168702\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1564, Accuracy: 2774/5000 (55%)\n",
      "[epoch 31] loss: 0.0426744\n",
      "Test set: Average loss: 2.0840, Accuracy: 2864/5000 (57%)\n",
      "[epoch 32] loss: 0.0237250\n",
      "Test set: Average loss: 2.0992, Accuracy: 2874/5000 (57%)\n",
      "[epoch 33] loss: 0.0189757\n",
      "Test set: Average loss: 2.1227, Accuracy: 2868/5000 (57%)\n",
      "[epoch 34] loss: 0.0161889\n",
      "Test set: Average loss: 2.1381, Accuracy: 2869/5000 (57%)\n",
      "[epoch 35] loss: 0.0141949\n",
      "Test set: Average loss: 2.1580, Accuracy: 2874/5000 (57%)\n",
      "[epoch 36] loss: 0.0126458\n",
      "Test set: Average loss: 2.1797, Accuracy: 2865/5000 (57%)\n",
      "[epoch 37] loss: 0.0113139\n",
      "Test set: Average loss: 2.1982, Accuracy: 2878/5000 (58%)\n",
      "[epoch 38] loss: 0.0101869\n",
      "Test set: Average loss: 2.2177, Accuracy: 2873/5000 (57%)\n",
      "[epoch 39] loss: 0.0092073\n",
      "Test set: Average loss: 2.2388, Accuracy: 2872/5000 (57%)\n",
      "[epoch 40] loss: 0.0082993\n",
      "Test set: Average loss: 2.2620, Accuracy: 2874/5000 (57%)\n",
      "[epoch 41] loss: 0.0074850\n",
      "Test set: Average loss: 2.2892, Accuracy: 2877/5000 (58%)\n",
      "[epoch 42] loss: 0.0067644\n",
      "Test set: Average loss: 2.3093, Accuracy: 2870/5000 (57%)\n",
      "[epoch 43] loss: 0.0061084\n",
      "Test set: Average loss: 2.3352, Accuracy: 2868/5000 (57%)\n",
      "[epoch 44] loss: 0.0054857\n",
      "Test set: Average loss: 2.3645, Accuracy: 2885/5000 (58%)\n",
      "[epoch 45] loss: 0.0049323\n",
      "Test set: Average loss: 2.3844, Accuracy: 2869/5000 (57%)\n",
      "[epoch 46] loss: 0.0044262\n",
      "Test set: Average loss: 2.4164, Accuracy: 2863/5000 (57%)\n",
      "[epoch 47] loss: 0.0039675\n",
      "Test set: Average loss: 2.4464, Accuracy: 2867/5000 (57%)\n",
      "[epoch 48] loss: 0.0035461\n",
      "Test set: Average loss: 2.4781, Accuracy: 2867/5000 (57%)\n",
      "[epoch 49] loss: 0.0031645\n",
      "Test set: Average loss: 2.5010, Accuracy: 2865/5000 (57%)\n",
      "[epoch 50] loss: 0.0027910\n",
      "Test set: Average loss: 2.5341, Accuracy: 2868/5000 (57%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3645, Accuracy: 2885/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 2.3206, Accuracy: 5888/10000 (59%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3014, Accuracy: 575/5000 (12%)\n",
      "[epoch 1] loss: 1.5059750\n",
      "Test set: Average loss: 1.3826, Accuracy: 2539/5000 (51%)\n",
      "[epoch 2] loss: 1.2296672\n",
      "Test set: Average loss: 1.2834, Accuracy: 2733/5000 (55%)\n",
      "[epoch 3] loss: 1.1337710\n",
      "Test set: Average loss: 1.3469, Accuracy: 2716/5000 (54%)\n",
      "[epoch 4] loss: 1.0835393\n",
      "Test set: Average loss: 1.2658, Accuracy: 2844/5000 (57%)\n",
      "[epoch 5] loss: 1.0436663\n",
      "Test set: Average loss: 1.2311, Accuracy: 2834/5000 (57%)\n",
      "[epoch 6] loss: 0.9930189\n",
      "Test set: Average loss: 1.2817, Accuracy: 2794/5000 (56%)\n",
      "[epoch 7] loss: 0.9871063\n",
      "Test set: Average loss: 1.2910, Accuracy: 2765/5000 (55%)\n",
      "[epoch 8] loss: 0.9406113\n",
      "Test set: Average loss: 1.2971, Accuracy: 2838/5000 (57%)\n",
      "[epoch 9] loss: 0.9328233\n",
      "Test set: Average loss: 1.3384, Accuracy: 2752/5000 (55%)\n",
      "[epoch 10] loss: 0.8948595\n",
      "Test set: Average loss: 1.2548, Accuracy: 2856/5000 (57%)\n",
      "[epoch 11] loss: 0.8595446\n",
      "Test set: Average loss: 1.2775, Accuracy: 2873/5000 (57%)\n",
      "[epoch 12] loss: 0.8364260\n",
      "Test set: Average loss: 1.2993, Accuracy: 2872/5000 (57%)\n",
      "[epoch 13] loss: 0.8157683\n",
      "Test set: Average loss: 1.2995, Accuracy: 2869/5000 (57%)\n",
      "[epoch 14] loss: 0.7690101\n",
      "Test set: Average loss: 1.3442, Accuracy: 2868/5000 (57%)\n",
      "[epoch 15] loss: 0.7330376\n",
      "Test set: Average loss: 1.3074, Accuracy: 2887/5000 (58%)\n",
      "[epoch 16] loss: 0.6976830\n",
      "Test set: Average loss: 1.3281, Accuracy: 2900/5000 (58%)\n",
      "[epoch 17] loss: 0.6391208\n",
      "Test set: Average loss: 1.4065, Accuracy: 2848/5000 (57%)\n",
      "[epoch 18] loss: 0.6184349\n",
      "Test set: Average loss: 1.4732, Accuracy: 2805/5000 (56%)\n",
      "[epoch 19] loss: 0.5680341\n",
      "Test set: Average loss: 1.4573, Accuracy: 2889/5000 (58%)\n",
      "[epoch 20] loss: 0.4919640\n",
      "Test set: Average loss: 1.5548, Accuracy: 2815/5000 (56%)\n",
      "[epoch 21] loss: 0.4388399\n",
      "Test set: Average loss: 1.5243, Accuracy: 2829/5000 (57%)\n",
      "[epoch 22] loss: 0.3889227\n",
      "Test set: Average loss: 1.6316, Accuracy: 2839/5000 (57%)\n",
      "[epoch 23] loss: 0.3427569\n",
      "Test set: Average loss: 1.6285, Accuracy: 2876/5000 (58%)\n",
      "[epoch 24] loss: 0.2814160\n",
      "Test set: Average loss: 1.6559, Accuracy: 2864/5000 (57%)\n",
      "[epoch 25] loss: 0.2374411\n",
      "Test set: Average loss: 1.7666, Accuracy: 2826/5000 (57%)\n",
      "[epoch 26] loss: 0.1811358\n",
      "Test set: Average loss: 1.8211, Accuracy: 2893/5000 (58%)\n",
      "[epoch 27] loss: 0.1615165\n",
      "Test set: Average loss: 1.8892, Accuracy: 2817/5000 (56%)\n",
      "[epoch 28] loss: 0.0818355\n",
      "Test set: Average loss: 1.9409, Accuracy: 2896/5000 (58%)\n",
      "[epoch 29] loss: 0.0531185\n",
      "Test set: Average loss: 1.9897, Accuracy: 2912/5000 (58%)\n",
      "[epoch 30] loss: 0.0364539\n",
      "Test set: Average loss: 2.1182, Accuracy: 2910/5000 (58%)\n",
      "[epoch 31] loss: 0.2468249\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1718, Accuracy: 2731/5000 (55%)\n",
      "[epoch 32] loss: 0.1092186\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9408, Accuracy: 2922/5000 (58%)\n",
      "[epoch 33] loss: 0.0482278\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.9403, Accuracy: 2926/5000 (59%)\n",
      "[epoch 34] loss: 0.0457623\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0454488\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 36] loss: 0.0454622\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 37] loss: 0.0454142\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 38] loss: 0.0454459\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 39] loss: 0.0454339\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 40] loss: 0.0455068\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 41] loss: 0.0455026\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 42] loss: 0.0455148\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 43] loss: 0.0454560\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 44] loss: 0.0454448\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 45] loss: 0.0455017\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 46] loss: 0.0454406\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 47] loss: 0.0454386\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 48] loss: 0.0454571\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 49] loss: 0.0454661\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "[epoch 50] loss: 0.0454464\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.9405, Accuracy: 2924/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9403, Accuracy: 2926/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 1.8919, Accuracy: 5939/10000 (59%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 582/5000 (12%)\n",
      "[epoch 1] loss: 1.5408912\n",
      "Test set: Average loss: 1.4147, Accuracy: 2461/5000 (49%)\n",
      "[epoch 2] loss: 1.2648827\n",
      "Test set: Average loss: 1.2853, Accuracy: 2728/5000 (55%)\n",
      "[epoch 3] loss: 1.1785388\n",
      "Test set: Average loss: 1.2955, Accuracy: 2688/5000 (54%)\n",
      "[epoch 4] loss: 1.1171964\n",
      "Test set: Average loss: 1.2864, Accuracy: 2784/5000 (56%)\n",
      "[epoch 5] loss: 1.0699122\n",
      "Test set: Average loss: 1.2801, Accuracy: 2735/5000 (55%)\n",
      "[epoch 6] loss: 1.0437613\n",
      "Test set: Average loss: 1.2884, Accuracy: 2770/5000 (55%)\n",
      "[epoch 7] loss: 0.9925241\n",
      "Test set: Average loss: 1.2822, Accuracy: 2820/5000 (56%)\n",
      "[epoch 8] loss: 0.9632763\n",
      "Test set: Average loss: 1.2377, Accuracy: 2856/5000 (57%)\n",
      "[epoch 9] loss: 0.9477876\n",
      "Test set: Average loss: 1.3343, Accuracy: 2774/5000 (55%)\n",
      "[epoch 10] loss: 0.9223681\n",
      "Test set: Average loss: 1.3755, Accuracy: 2689/5000 (54%)\n",
      "[epoch 11] loss: 0.8770151\n",
      "Test set: Average loss: 1.3177, Accuracy: 2832/5000 (57%)\n",
      "[epoch 12] loss: 0.8670674\n",
      "Test set: Average loss: 1.2707, Accuracy: 2908/5000 (58%)\n",
      "[epoch 13] loss: 0.8334251\n",
      "Test set: Average loss: 1.3108, Accuracy: 2845/5000 (57%)\n",
      "[epoch 14] loss: 0.7753563\n",
      "Test set: Average loss: 1.3437, Accuracy: 2844/5000 (57%)\n",
      "[epoch 15] loss: 0.7371714\n",
      "Test set: Average loss: 1.3518, Accuracy: 2868/5000 (57%)\n",
      "[epoch 16] loss: 0.7139211\n",
      "Test set: Average loss: 1.4265, Accuracy: 2807/5000 (56%)\n",
      "[epoch 17] loss: 0.6577971\n",
      "Test set: Average loss: 1.4621, Accuracy: 2802/5000 (56%)\n",
      "[epoch 18] loss: 0.6205077\n",
      "Test set: Average loss: 1.4479, Accuracy: 2847/5000 (57%)\n",
      "[epoch 19] loss: 0.5575600\n",
      "Test set: Average loss: 1.4499, Accuracy: 2851/5000 (57%)\n",
      "[epoch 20] loss: 0.5038190\n",
      "Test set: Average loss: 1.5335, Accuracy: 2820/5000 (56%)\n",
      "[epoch 21] loss: 0.4490285\n",
      "Test set: Average loss: 1.5772, Accuracy: 2845/5000 (57%)\n",
      "[epoch 22] loss: 0.3894578\n",
      "Test set: Average loss: 1.6625, Accuracy: 2815/5000 (56%)\n",
      "[epoch 23] loss: 0.3524395\n",
      "Test set: Average loss: 1.7433, Accuracy: 2812/5000 (56%)\n",
      "[epoch 24] loss: 0.2625160\n",
      "Test set: Average loss: 1.7878, Accuracy: 2819/5000 (56%)\n",
      "[epoch 25] loss: 0.2150948\n",
      "Test set: Average loss: 1.8040, Accuracy: 2802/5000 (56%)\n",
      "[epoch 26] loss: 0.1804598\n",
      "Test set: Average loss: 1.9069, Accuracy: 2810/5000 (56%)\n",
      "[epoch 27] loss: 0.1280252\n",
      "Test set: Average loss: 1.9349, Accuracy: 2823/5000 (56%)\n",
      "[epoch 28] loss: 0.0688218\n",
      "Test set: Average loss: 2.0636, Accuracy: 2827/5000 (57%)\n",
      "[epoch 29] loss: 0.1082904\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1486, Accuracy: 2756/5000 (55%)\n",
      "[epoch 30] loss: 0.0365982\n",
      "Test set: Average loss: 2.0525, Accuracy: 2868/5000 (57%)\n",
      "[epoch 31] loss: 0.0227483\n",
      "Test set: Average loss: 2.0677, Accuracy: 2869/5000 (57%)\n",
      "[epoch 32] loss: 0.0190132\n",
      "Test set: Average loss: 2.0842, Accuracy: 2895/5000 (58%)\n",
      "[epoch 33] loss: 0.0165986\n",
      "Test set: Average loss: 2.1018, Accuracy: 2899/5000 (58%)\n",
      "[epoch 34] loss: 0.0146899\n",
      "Test set: Average loss: 2.1176, Accuracy: 2902/5000 (58%)\n",
      "[epoch 35] loss: 0.0132111\n",
      "Test set: Average loss: 2.1365, Accuracy: 2901/5000 (58%)\n",
      "[epoch 36] loss: 0.0119367\n",
      "Test set: Average loss: 2.1575, Accuracy: 2897/5000 (58%)\n",
      "[epoch 37] loss: 0.0108453\n",
      "Test set: Average loss: 2.1729, Accuracy: 2898/5000 (58%)\n",
      "[epoch 38] loss: 0.0098153\n",
      "Test set: Average loss: 2.1990, Accuracy: 2908/5000 (58%)\n",
      "[epoch 39] loss: 0.0089511\n",
      "Test set: Average loss: 2.2134, Accuracy: 2906/5000 (58%)\n",
      "[epoch 40] loss: 0.0081095\n",
      "Test set: Average loss: 2.2390, Accuracy: 2893/5000 (58%)\n",
      "[epoch 41] loss: 0.0073520\n",
      "Test set: Average loss: 2.2628, Accuracy: 2905/5000 (58%)\n",
      "[epoch 42] loss: 0.0066700\n",
      "Test set: Average loss: 2.2893, Accuracy: 2907/5000 (58%)\n",
      "[epoch 43] loss: 0.0060305\n",
      "Test set: Average loss: 2.3118, Accuracy: 2904/5000 (58%)\n",
      "[epoch 44] loss: 0.0054181\n",
      "Test set: Average loss: 2.3381, Accuracy: 2903/5000 (58%)\n",
      "[epoch 45] loss: 0.0048571\n",
      "Test set: Average loss: 2.3713, Accuracy: 2916/5000 (58%)\n",
      "[epoch 46] loss: 0.0043544\n",
      "Test set: Average loss: 2.3988, Accuracy: 2896/5000 (58%)\n",
      "[epoch 47] loss: 0.0038854\n",
      "Test set: Average loss: 2.4200, Accuracy: 2917/5000 (58%)\n",
      "[epoch 48] loss: 0.0034523\n",
      "Test set: Average loss: 2.4529, Accuracy: 2928/5000 (59%)\n",
      "[epoch 49] loss: 0.0030783\n",
      "Test set: Average loss: 2.4805, Accuracy: 2908/5000 (58%)\n",
      "[epoch 50] loss: 0.0027304\n",
      "Test set: Average loss: 2.5169, Accuracy: 2922/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4529, Accuracy: 2928/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 2.3345, Accuracy: 5991/10000 (60%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3035, Accuracy: 517/5000 (10%)\n",
      "[epoch 1] loss: 1.4243762\n",
      "Test set: Average loss: 1.2746, Accuracy: 2739/5000 (55%)\n",
      "[epoch 2] loss: 1.2018118\n",
      "Test set: Average loss: 1.2710, Accuracy: 2712/5000 (54%)\n",
      "[epoch 3] loss: 1.1184125\n",
      "Test set: Average loss: 1.2292, Accuracy: 2869/5000 (57%)\n",
      "[epoch 4] loss: 1.0788334\n",
      "Test set: Average loss: 1.3514, Accuracy: 2617/5000 (52%)\n",
      "[epoch 5] loss: 1.0463512\n",
      "Test set: Average loss: 1.1702, Accuracy: 2974/5000 (59%)\n",
      "[epoch 6] loss: 1.0084550\n",
      "Test set: Average loss: 1.1916, Accuracy: 2935/5000 (59%)\n",
      "[epoch 7] loss: 0.9813854\n",
      "Test set: Average loss: 1.1597, Accuracy: 2990/5000 (60%)\n",
      "[epoch 8] loss: 0.9442850\n",
      "Test set: Average loss: 1.2466, Accuracy: 2880/5000 (58%)\n",
      "[epoch 9] loss: 0.9276782\n",
      "Test set: Average loss: 1.1930, Accuracy: 2919/5000 (58%)\n",
      "[epoch 10] loss: 0.8923640\n",
      "Test set: Average loss: 1.1715, Accuracy: 2965/5000 (59%)\n",
      "[epoch 11] loss: 0.8584668\n",
      "Test set: Average loss: 1.1644, Accuracy: 3023/5000 (60%)\n",
      "[epoch 12] loss: 0.8228261\n",
      "Test set: Average loss: 1.2016, Accuracy: 2961/5000 (59%)\n",
      "[epoch 13] loss: 0.7820659\n",
      "Test set: Average loss: 1.1981, Accuracy: 3046/5000 (61%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14] loss: 0.7394423\n",
      "Test set: Average loss: 1.2516, Accuracy: 2979/5000 (60%)\n",
      "[epoch 15] loss: 0.6957958\n",
      "Test set: Average loss: 1.2511, Accuracy: 2953/5000 (59%)\n",
      "[epoch 16] loss: 0.6575450\n",
      "Test set: Average loss: 1.2358, Accuracy: 3052/5000 (61%)\n",
      "[epoch 17] loss: 0.5993034\n",
      "Test set: Average loss: 1.3088, Accuracy: 3023/5000 (60%)\n",
      "[epoch 18] loss: 0.5441050\n",
      "Test set: Average loss: 1.3471, Accuracy: 3001/5000 (60%)\n",
      "[epoch 19] loss: 0.4809720\n",
      "Test set: Average loss: 1.3672, Accuracy: 2978/5000 (60%)\n",
      "[epoch 20] loss: 0.4079790\n",
      "Test set: Average loss: 1.3868, Accuracy: 3039/5000 (61%)\n",
      "[epoch 21] loss: 0.3326457\n",
      "Test set: Average loss: 1.5591, Accuracy: 2964/5000 (59%)\n",
      "[epoch 22] loss: 0.2790687\n",
      "Test set: Average loss: 1.5399, Accuracy: 2984/5000 (60%)\n",
      "[epoch 23] loss: 0.2150497\n",
      "Test set: Average loss: 1.6675, Accuracy: 2939/5000 (59%)\n",
      "[epoch 24] loss: 0.1719430\n",
      "Test set: Average loss: 1.6775, Accuracy: 2997/5000 (60%)\n",
      "[epoch 25] loss: 0.1241899\n",
      "Test set: Average loss: 1.7087, Accuracy: 2985/5000 (60%)\n",
      "[epoch 26] loss: 0.0699993\n",
      "Test set: Average loss: 1.8117, Accuracy: 3066/5000 (61%)\n",
      "[epoch 27] loss: 0.1064846\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8799, Accuracy: 3005/5000 (60%)\n",
      "[epoch 28] loss: 0.0397463\n",
      "Test set: Average loss: 1.8153, Accuracy: 3070/5000 (61%)\n",
      "[epoch 29] loss: 0.0196137\n",
      "Test set: Average loss: 1.8291, Accuracy: 3089/5000 (62%)\n",
      "[epoch 30] loss: 0.0149258\n",
      "Test set: Average loss: 1.8451, Accuracy: 3102/5000 (62%)\n",
      "[epoch 31] loss: 0.0121553\n",
      "Test set: Average loss: 1.8584, Accuracy: 3095/5000 (62%)\n",
      "[epoch 32] loss: 0.0101887\n",
      "Test set: Average loss: 1.8791, Accuracy: 3102/5000 (62%)\n",
      "[epoch 33] loss: 0.0086232\n",
      "Test set: Average loss: 1.8944, Accuracy: 3101/5000 (62%)\n",
      "[epoch 34] loss: 0.0073899\n",
      "Test set: Average loss: 1.9150, Accuracy: 3109/5000 (62%)\n",
      "[epoch 35] loss: 0.0063350\n",
      "Test set: Average loss: 1.9327, Accuracy: 3120/5000 (62%)\n",
      "[epoch 36] loss: 0.0054295\n",
      "Test set: Average loss: 1.9569, Accuracy: 3110/5000 (62%)\n",
      "[epoch 37] loss: 0.0046383\n",
      "Test set: Average loss: 1.9828, Accuracy: 3121/5000 (62%)\n",
      "[epoch 38] loss: 0.0039536\n",
      "Test set: Average loss: 2.0121, Accuracy: 3125/5000 (62%)\n",
      "[epoch 39] loss: 0.0033644\n",
      "Test set: Average loss: 2.0411, Accuracy: 3121/5000 (62%)\n",
      "[epoch 40] loss: 0.0028351\n",
      "Test set: Average loss: 2.0722, Accuracy: 3124/5000 (62%)\n",
      "[epoch 41] loss: 0.0023928\n",
      "Test set: Average loss: 2.1009, Accuracy: 3118/5000 (62%)\n",
      "[epoch 42] loss: 0.0020007\n",
      "Test set: Average loss: 2.1347, Accuracy: 3111/5000 (62%)\n",
      "[epoch 43] loss: 0.0016727\n",
      "Test set: Average loss: 2.1686, Accuracy: 3125/5000 (62%)\n",
      "[epoch 44] loss: 0.0013862\n",
      "Test set: Average loss: 2.2015, Accuracy: 3110/5000 (62%)\n",
      "[epoch 45] loss: 0.0011518\n",
      "Test set: Average loss: 2.2498, Accuracy: 3109/5000 (62%)\n",
      "[epoch 46] loss: 0.0009476\n",
      "Test set: Average loss: 2.2796, Accuracy: 3110/5000 (62%)\n",
      "[epoch 47] loss: 0.0007778\n",
      "Test set: Average loss: 2.3199, Accuracy: 3108/5000 (62%)\n",
      "[epoch 48] loss: 0.0006357\n",
      "Test set: Average loss: 2.3557, Accuracy: 3111/5000 (62%)\n",
      "[epoch 49] loss: 0.0005195\n",
      "Test set: Average loss: 2.3979, Accuracy: 3119/5000 (62%)\n",
      "[epoch 50] loss: 0.0004230\n",
      "Test set: Average loss: 2.4314, Accuracy: 3108/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1686, Accuracy: 3125/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.1818, Accuracy: 6282/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 518/5000 (10%)\n",
      "[epoch 1] loss: 1.4568845\n",
      "Test set: Average loss: 1.5428, Accuracy: 2370/5000 (47%)\n",
      "[epoch 2] loss: 1.2056942\n",
      "Test set: Average loss: 1.2084, Accuracy: 2832/5000 (57%)\n",
      "[epoch 3] loss: 1.1378239\n",
      "Test set: Average loss: 1.2070, Accuracy: 2865/5000 (57%)\n",
      "[epoch 4] loss: 1.0765339\n",
      "Test set: Average loss: 1.1604, Accuracy: 2975/5000 (60%)\n",
      "[epoch 5] loss: 1.0403373\n",
      "Test set: Average loss: 1.2637, Accuracy: 2838/5000 (57%)\n",
      "[epoch 6] loss: 0.9981168\n",
      "Test set: Average loss: 1.2403, Accuracy: 2811/5000 (56%)\n",
      "[epoch 7] loss: 0.9759658\n",
      "Test set: Average loss: 1.2312, Accuracy: 2829/5000 (57%)\n",
      "[epoch 8] loss: 0.9416696\n",
      "Test set: Average loss: 1.2622, Accuracy: 2842/5000 (57%)\n",
      "[epoch 9] loss: 0.9002050\n",
      "Test set: Average loss: 1.1937, Accuracy: 2925/5000 (58%)\n",
      "[epoch 10] loss: 0.8839178\n",
      "Test set: Average loss: 1.1883, Accuracy: 2964/5000 (59%)\n",
      "[epoch 11] loss: 0.8424077\n",
      "Test set: Average loss: 1.2171, Accuracy: 2956/5000 (59%)\n",
      "[epoch 12] loss: 0.8153325\n",
      "Test set: Average loss: 1.2215, Accuracy: 2928/5000 (59%)\n",
      "[epoch 13] loss: 0.7762558\n",
      "Test set: Average loss: 1.2112, Accuracy: 2987/5000 (60%)\n",
      "[epoch 14] loss: 0.7422129\n",
      "Test set: Average loss: 1.1926, Accuracy: 3031/5000 (61%)\n",
      "[epoch 15] loss: 0.6937872\n",
      "Test set: Average loss: 1.1951, Accuracy: 3024/5000 (60%)\n",
      "[epoch 16] loss: 0.6259238\n",
      "Test set: Average loss: 1.2517, Accuracy: 2982/5000 (60%)\n",
      "[epoch 17] loss: 0.5816673\n",
      "Test set: Average loss: 1.3150, Accuracy: 2978/5000 (60%)\n",
      "[epoch 18] loss: 0.5280078\n",
      "Test set: Average loss: 1.3183, Accuracy: 2972/5000 (59%)\n",
      "[epoch 19] loss: 0.4690349\n",
      "Test set: Average loss: 1.3903, Accuracy: 2971/5000 (59%)\n",
      "[epoch 20] loss: 0.4147259\n",
      "Test set: Average loss: 1.4280, Accuracy: 2959/5000 (59%)\n",
      "[epoch 21] loss: 0.3370814\n",
      "Test set: Average loss: 1.4503, Accuracy: 3032/5000 (61%)\n",
      "[epoch 22] loss: 0.2701196\n",
      "Test set: Average loss: 1.5642, Accuracy: 3007/5000 (60%)\n",
      "[epoch 23] loss: 0.2125916\n",
      "Test set: Average loss: 1.5430, Accuracy: 3045/5000 (61%)\n",
      "[epoch 24] loss: 0.1734757\n",
      "Test set: Average loss: 1.7607, Accuracy: 2979/5000 (60%)\n",
      "[epoch 25] loss: 0.1137763\n",
      "Test set: Average loss: 1.7450, Accuracy: 3029/5000 (61%)\n",
      "[epoch 26] loss: 0.0651634\n",
      "Test set: Average loss: 1.8977, Accuracy: 2950/5000 (59%)\n",
      "[epoch 27] loss: 0.1368294\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9619, Accuracy: 2953/5000 (59%)\n",
      "[epoch 28] loss: 0.0527056\n",
      "Test set: Average loss: 1.8325, Accuracy: 3031/5000 (61%)\n",
      "[epoch 29] loss: 0.0237277\n",
      "Test set: Average loss: 1.8446, Accuracy: 3035/5000 (61%)\n",
      "[epoch 30] loss: 0.0173128\n",
      "Test set: Average loss: 1.8610, Accuracy: 3038/5000 (61%)\n",
      "[epoch 31] loss: 0.0137573\n",
      "Test set: Average loss: 1.8765, Accuracy: 3072/5000 (61%)\n",
      "[epoch 32] loss: 0.0113196\n",
      "Test set: Average loss: 1.8932, Accuracy: 3064/5000 (61%)\n",
      "[epoch 33] loss: 0.0095216\n",
      "Test set: Average loss: 1.9122, Accuracy: 3071/5000 (61%)\n",
      "[epoch 34] loss: 0.0080503\n",
      "Test set: Average loss: 1.9327, Accuracy: 3078/5000 (62%)\n",
      "[epoch 35] loss: 0.0068374\n",
      "Test set: Average loss: 1.9552, Accuracy: 3087/5000 (62%)\n",
      "[epoch 36] loss: 0.0058271\n",
      "Test set: Average loss: 1.9752, Accuracy: 3086/5000 (62%)\n",
      "[epoch 37] loss: 0.0049675\n",
      "Test set: Average loss: 2.0019, Accuracy: 3087/5000 (62%)\n",
      "[epoch 38] loss: 0.0042130\n",
      "Test set: Average loss: 2.0266, Accuracy: 3092/5000 (62%)\n",
      "[epoch 39] loss: 0.0035666\n",
      "Test set: Average loss: 2.0529, Accuracy: 3093/5000 (62%)\n",
      "[epoch 40] loss: 0.0030071\n",
      "Test set: Average loss: 2.0794, Accuracy: 3090/5000 (62%)\n",
      "[epoch 41] loss: 0.0025317\n",
      "Test set: Average loss: 2.1135, Accuracy: 3094/5000 (62%)\n",
      "[epoch 42] loss: 0.0021182\n",
      "Test set: Average loss: 2.1392, Accuracy: 3100/5000 (62%)\n",
      "[epoch 43] loss: 0.0017637\n",
      "Test set: Average loss: 2.1760, Accuracy: 3098/5000 (62%)\n",
      "[epoch 44] loss: 0.0014675\n",
      "Test set: Average loss: 2.2133, Accuracy: 3102/5000 (62%)\n",
      "[epoch 45] loss: 0.0012181\n",
      "Test set: Average loss: 2.2486, Accuracy: 3108/5000 (62%)\n",
      "[epoch 46] loss: 0.0010046\n",
      "Test set: Average loss: 2.2849, Accuracy: 3098/5000 (62%)\n",
      "[epoch 47] loss: 0.0008245\n",
      "Test set: Average loss: 2.3218, Accuracy: 3093/5000 (62%)\n",
      "[epoch 48] loss: 0.0006778\n",
      "Test set: Average loss: 2.3582, Accuracy: 3091/5000 (62%)\n",
      "[epoch 49] loss: 0.0005516\n",
      "Test set: Average loss: 2.3998, Accuracy: 3089/5000 (62%)\n",
      "[epoch 50] loss: 0.0004513\n",
      "Test set: Average loss: 2.4351, Accuracy: 3097/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2486, Accuracy: 3108/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.1667, Accuracy: 6338/10000 (63%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 1.4454667\n",
      "Test set: Average loss: 1.3419, Accuracy: 2542/5000 (51%)\n",
      "[epoch 2] loss: 1.2030104\n",
      "Test set: Average loss: 1.3043, Accuracy: 2659/5000 (53%)\n",
      "[epoch 3] loss: 1.1395687\n",
      "Test set: Average loss: 1.1891, Accuracy: 2886/5000 (58%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 1.0777144\n",
      "Test set: Average loss: 1.2583, Accuracy: 2795/5000 (56%)\n",
      "[epoch 5] loss: 1.0360381\n",
      "Test set: Average loss: 1.1683, Accuracy: 2933/5000 (59%)\n",
      "[epoch 6] loss: 1.0052871\n",
      "Test set: Average loss: 1.2571, Accuracy: 2858/5000 (57%)\n",
      "[epoch 7] loss: 0.9731643\n",
      "Test set: Average loss: 1.1720, Accuracy: 2980/5000 (60%)\n",
      "[epoch 8] loss: 0.9471110\n",
      "Test set: Average loss: 1.1579, Accuracy: 2957/5000 (59%)\n",
      "[epoch 9] loss: 0.9158756\n",
      "Test set: Average loss: 1.1686, Accuracy: 2975/5000 (60%)\n",
      "[epoch 10] loss: 0.8925338\n",
      "Test set: Average loss: 1.1781, Accuracy: 2980/5000 (60%)\n",
      "[epoch 11] loss: 0.8668986\n",
      "Test set: Average loss: 1.2100, Accuracy: 2933/5000 (59%)\n",
      "[epoch 12] loss: 0.8193792\n",
      "Test set: Average loss: 1.1876, Accuracy: 2999/5000 (60%)\n",
      "[epoch 13] loss: 0.7814900\n",
      "Test set: Average loss: 1.1823, Accuracy: 3015/5000 (60%)\n",
      "[epoch 14] loss: 0.7353413\n",
      "Test set: Average loss: 1.1971, Accuracy: 3019/5000 (60%)\n",
      "[epoch 15] loss: 0.6874860\n",
      "Test set: Average loss: 1.2711, Accuracy: 2975/5000 (60%)\n",
      "[epoch 16] loss: 0.6405826\n",
      "Test set: Average loss: 1.2853, Accuracy: 2937/5000 (59%)\n",
      "[epoch 17] loss: 0.5914597\n",
      "Test set: Average loss: 1.3344, Accuracy: 2923/5000 (58%)\n",
      "[epoch 18] loss: 0.5313833\n",
      "Test set: Average loss: 1.4079, Accuracy: 2926/5000 (59%)\n",
      "[epoch 19] loss: 0.4679959\n",
      "Test set: Average loss: 1.3411, Accuracy: 3049/5000 (61%)\n",
      "[epoch 20] loss: 0.3984435\n",
      "Test set: Average loss: 1.4519, Accuracy: 2931/5000 (59%)\n",
      "[epoch 21] loss: 0.3320427\n",
      "Test set: Average loss: 1.4873, Accuracy: 2992/5000 (60%)\n",
      "[epoch 22] loss: 0.2741003\n",
      "Test set: Average loss: 1.5161, Accuracy: 2979/5000 (60%)\n",
      "[epoch 23] loss: 0.2071708\n",
      "Test set: Average loss: 1.6149, Accuracy: 2997/5000 (60%)\n",
      "[epoch 24] loss: 0.1578106\n",
      "Test set: Average loss: 1.6927, Accuracy: 2987/5000 (60%)\n",
      "[epoch 25] loss: 0.1075595\n",
      "Test set: Average loss: 1.8324, Accuracy: 2933/5000 (59%)\n",
      "[epoch 26] loss: 0.1121821\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8693, Accuracy: 2965/5000 (59%)\n",
      "[epoch 27] loss: 0.0441837\n",
      "Test set: Average loss: 1.7622, Accuracy: 3088/5000 (62%)\n",
      "[epoch 28] loss: 0.0226351\n",
      "Test set: Average loss: 1.7880, Accuracy: 3063/5000 (61%)\n",
      "[epoch 29] loss: 0.0175284\n",
      "Test set: Average loss: 1.7845, Accuracy: 3081/5000 (62%)\n",
      "[epoch 30] loss: 0.0144386\n",
      "Test set: Average loss: 1.8030, Accuracy: 3074/5000 (61%)\n",
      "[epoch 31] loss: 0.0122486\n",
      "Test set: Average loss: 1.8176, Accuracy: 3080/5000 (62%)\n",
      "[epoch 32] loss: 0.0104884\n",
      "Test set: Average loss: 1.8361, Accuracy: 3079/5000 (62%)\n",
      "[epoch 33] loss: 0.0090631\n",
      "Test set: Average loss: 1.8561, Accuracy: 3079/5000 (62%)\n",
      "[epoch 34] loss: 0.0077912\n",
      "Test set: Average loss: 1.8822, Accuracy: 3089/5000 (62%)\n",
      "[epoch 35] loss: 0.0067131\n",
      "Test set: Average loss: 1.9046, Accuracy: 3085/5000 (62%)\n",
      "[epoch 36] loss: 0.0057397\n",
      "Test set: Average loss: 1.9253, Accuracy: 3078/5000 (62%)\n",
      "[epoch 37] loss: 0.0049153\n",
      "Test set: Average loss: 1.9560, Accuracy: 3087/5000 (62%)\n",
      "[epoch 38] loss: 0.0041598\n",
      "Test set: Average loss: 1.9851, Accuracy: 3087/5000 (62%)\n",
      "[epoch 39] loss: 0.0035212\n",
      "Test set: Average loss: 2.0155, Accuracy: 3088/5000 (62%)\n",
      "[epoch 40] loss: 0.0029548\n",
      "Test set: Average loss: 2.0454, Accuracy: 3103/5000 (62%)\n",
      "[epoch 41] loss: 0.0024734\n",
      "Test set: Average loss: 2.0827, Accuracy: 3085/5000 (62%)\n",
      "[epoch 42] loss: 0.0020646\n",
      "Test set: Average loss: 2.1152, Accuracy: 3093/5000 (62%)\n",
      "[epoch 43] loss: 0.0017115\n",
      "Test set: Average loss: 2.1538, Accuracy: 3095/5000 (62%)\n",
      "[epoch 44] loss: 0.0014225\n",
      "Test set: Average loss: 2.1884, Accuracy: 3095/5000 (62%)\n",
      "[epoch 45] loss: 0.0011577\n",
      "Test set: Average loss: 2.2296, Accuracy: 3089/5000 (62%)\n",
      "[epoch 46] loss: 0.0009501\n",
      "Test set: Average loss: 2.2701, Accuracy: 3106/5000 (62%)\n",
      "[epoch 47] loss: 0.0007746\n",
      "Test set: Average loss: 2.3060, Accuracy: 3114/5000 (62%)\n",
      "[epoch 48] loss: 0.0006343\n",
      "Test set: Average loss: 2.3482, Accuracy: 3111/5000 (62%)\n",
      "[epoch 49] loss: 0.0005146\n",
      "Test set: Average loss: 2.3901, Accuracy: 3109/5000 (62%)\n",
      "[epoch 50] loss: 0.0004165\n",
      "Test set: Average loss: 2.4322, Accuracy: 3107/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3060, Accuracy: 3114/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.3002, Accuracy: 6276/10000 (63%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3013, Accuracy: 505/5000 (10%)\n",
      "[epoch 1] loss: 1.3833932\n",
      "Test set: Average loss: 1.3049, Accuracy: 2666/5000 (53%)\n",
      "[epoch 2] loss: 1.1838199\n",
      "Test set: Average loss: 1.2387, Accuracy: 2794/5000 (56%)\n",
      "[epoch 3] loss: 1.1328750\n",
      "Test set: Average loss: 1.1749, Accuracy: 2882/5000 (58%)\n",
      "[epoch 4] loss: 1.0757198\n",
      "Test set: Average loss: 1.2041, Accuracy: 2857/5000 (57%)\n",
      "[epoch 5] loss: 1.0396136\n",
      "Test set: Average loss: 1.1545, Accuracy: 2980/5000 (60%)\n",
      "[epoch 6] loss: 1.0087819\n",
      "Test set: Average loss: 1.1448, Accuracy: 2953/5000 (59%)\n",
      "[epoch 7] loss: 0.9657199\n",
      "Test set: Average loss: 1.1353, Accuracy: 3007/5000 (60%)\n",
      "[epoch 8] loss: 0.9481757\n",
      "Test set: Average loss: 1.1498, Accuracy: 3003/5000 (60%)\n",
      "[epoch 9] loss: 0.9085646\n",
      "Test set: Average loss: 1.1484, Accuracy: 3030/5000 (61%)\n",
      "[epoch 10] loss: 0.8740296\n",
      "Test set: Average loss: 1.1434, Accuracy: 3063/5000 (61%)\n",
      "[epoch 11] loss: 0.8356096\n",
      "Test set: Average loss: 1.1156, Accuracy: 3089/5000 (62%)\n",
      "[epoch 12] loss: 0.8082162\n",
      "Test set: Average loss: 1.1461, Accuracy: 3071/5000 (61%)\n",
      "[epoch 13] loss: 0.7582905\n",
      "Test set: Average loss: 1.1333, Accuracy: 3042/5000 (61%)\n",
      "[epoch 14] loss: 0.7146886\n",
      "Test set: Average loss: 1.1632, Accuracy: 3051/5000 (61%)\n",
      "[epoch 15] loss: 0.6601676\n",
      "Test set: Average loss: 1.1702, Accuracy: 3122/5000 (62%)\n",
      "[epoch 16] loss: 0.6074374\n",
      "Test set: Average loss: 1.2151, Accuracy: 3069/5000 (61%)\n",
      "[epoch 17] loss: 0.5462717\n",
      "Test set: Average loss: 1.2956, Accuracy: 3096/5000 (62%)\n",
      "[epoch 18] loss: 0.4896969\n",
      "Test set: Average loss: 1.2632, Accuracy: 3106/5000 (62%)\n",
      "[epoch 19] loss: 0.3985034\n",
      "Test set: Average loss: 1.3379, Accuracy: 3135/5000 (63%)\n",
      "[epoch 20] loss: 0.3275121\n",
      "Test set: Average loss: 1.4204, Accuracy: 3119/5000 (62%)\n",
      "[epoch 21] loss: 0.2642953\n",
      "Test set: Average loss: 1.4431, Accuracy: 3075/5000 (62%)\n",
      "[epoch 22] loss: 0.2100423\n",
      "Test set: Average loss: 1.5187, Accuracy: 3097/5000 (62%)\n",
      "[epoch 23] loss: 0.1593863\n",
      "Test set: Average loss: 1.6447, Accuracy: 3083/5000 (62%)\n",
      "[epoch 24] loss: 0.1161189\n",
      "Test set: Average loss: 1.7083, Accuracy: 3063/5000 (61%)\n",
      "[epoch 25] loss: 0.1067174\n",
      "Test set: Average loss: 1.8680, Accuracy: 2940/5000 (59%)\n",
      "[epoch 26] loss: 0.1445735\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8274, Accuracy: 3045/5000 (61%)\n",
      "[epoch 27] loss: 0.0330040\n",
      "Test set: Average loss: 1.7540, Accuracy: 3131/5000 (63%)\n",
      "[epoch 28] loss: 0.0147661\n",
      "Test set: Average loss: 1.7756, Accuracy: 3145/5000 (63%)\n",
      "[epoch 29] loss: 0.0108452\n",
      "Test set: Average loss: 1.7863, Accuracy: 3152/5000 (63%)\n",
      "[epoch 30] loss: 0.0086279\n",
      "Test set: Average loss: 1.7998, Accuracy: 3156/5000 (63%)\n",
      "[epoch 31] loss: 0.0070245\n",
      "Test set: Average loss: 1.8191, Accuracy: 3176/5000 (64%)\n",
      "[epoch 32] loss: 0.0057772\n",
      "Test set: Average loss: 1.8407, Accuracy: 3164/5000 (63%)\n",
      "[epoch 33] loss: 0.0047669\n",
      "Test set: Average loss: 1.8616, Accuracy: 3180/5000 (64%)\n",
      "[epoch 34] loss: 0.0039128\n",
      "Test set: Average loss: 1.8848, Accuracy: 3182/5000 (64%)\n",
      "[epoch 35] loss: 0.0031995\n",
      "Test set: Average loss: 1.9065, Accuracy: 3182/5000 (64%)\n",
      "[epoch 36] loss: 0.0025831\n",
      "Test set: Average loss: 1.9370, Accuracy: 3180/5000 (64%)\n",
      "[epoch 37] loss: 0.0020759\n",
      "Test set: Average loss: 1.9706, Accuracy: 3189/5000 (64%)\n",
      "[epoch 38] loss: 0.0016594\n",
      "Test set: Average loss: 2.0030, Accuracy: 3194/5000 (64%)\n",
      "[epoch 39] loss: 0.0013164\n",
      "Test set: Average loss: 2.0381, Accuracy: 3192/5000 (64%)\n",
      "[epoch 40] loss: 0.0010332\n",
      "Test set: Average loss: 2.0800, Accuracy: 3190/5000 (64%)\n",
      "[epoch 41] loss: 0.0008094\n",
      "Test set: Average loss: 2.1083, Accuracy: 3203/5000 (64%)\n",
      "[epoch 42] loss: 0.0006292\n",
      "Test set: Average loss: 2.1488, Accuracy: 3201/5000 (64%)\n",
      "[epoch 43] loss: 0.0004871\n",
      "Test set: Average loss: 2.1927, Accuracy: 3201/5000 (64%)\n",
      "[epoch 44] loss: 0.0003759\n",
      "Test set: Average loss: 2.2399, Accuracy: 3202/5000 (64%)\n",
      "[epoch 45] loss: 0.0002884\n",
      "Test set: Average loss: 2.2810, Accuracy: 3201/5000 (64%)\n",
      "[epoch 46] loss: 0.0002214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3233, Accuracy: 3198/5000 (64%)\n",
      "[epoch 47] loss: 0.0001675\n",
      "Test set: Average loss: 2.3727, Accuracy: 3199/5000 (64%)\n",
      "[epoch 48] loss: 0.0001281\n",
      "Test set: Average loss: 2.4099, Accuracy: 3203/5000 (64%)\n",
      "[epoch 49] loss: 0.0000972\n",
      "Test set: Average loss: 2.4615, Accuracy: 3203/5000 (64%)\n",
      "[epoch 50] loss: 0.0000735\n",
      "Test set: Average loss: 2.5056, Accuracy: 3212/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5056, Accuracy: 3212/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.5255, Accuracy: 6445/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 490/5000 (10%)\n",
      "[epoch 1] loss: 1.3881583\n",
      "Test set: Average loss: 1.2375, Accuracy: 2777/5000 (56%)\n",
      "[epoch 2] loss: 1.1768016\n",
      "Test set: Average loss: 1.2373, Accuracy: 2819/5000 (56%)\n",
      "[epoch 3] loss: 1.1088812\n",
      "Test set: Average loss: 1.1724, Accuracy: 2946/5000 (59%)\n",
      "[epoch 4] loss: 1.0642860\n",
      "Test set: Average loss: 1.2061, Accuracy: 2828/5000 (57%)\n",
      "[epoch 5] loss: 1.0288284\n",
      "Test set: Average loss: 1.1502, Accuracy: 2939/5000 (59%)\n",
      "[epoch 6] loss: 0.9897403\n",
      "Test set: Average loss: 1.1328, Accuracy: 2996/5000 (60%)\n",
      "[epoch 7] loss: 0.9598227\n",
      "Test set: Average loss: 1.2000, Accuracy: 2960/5000 (59%)\n",
      "[epoch 8] loss: 0.9324615\n",
      "Test set: Average loss: 1.0800, Accuracy: 3132/5000 (63%)\n",
      "[epoch 9] loss: 0.9042912\n",
      "Test set: Average loss: 1.1415, Accuracy: 2994/5000 (60%)\n",
      "[epoch 10] loss: 0.8750321\n",
      "Test set: Average loss: 1.1583, Accuracy: 2979/5000 (60%)\n",
      "[epoch 11] loss: 0.8353058\n",
      "Test set: Average loss: 1.1274, Accuracy: 3027/5000 (61%)\n",
      "[epoch 12] loss: 0.7980504\n",
      "Test set: Average loss: 1.1904, Accuracy: 2976/5000 (60%)\n",
      "[epoch 13] loss: 0.7658753\n",
      "Test set: Average loss: 1.1731, Accuracy: 3040/5000 (61%)\n",
      "[epoch 14] loss: 0.7205534\n",
      "Test set: Average loss: 1.1811, Accuracy: 3027/5000 (61%)\n",
      "[epoch 15] loss: 0.6708649\n",
      "Test set: Average loss: 1.1963, Accuracy: 3082/5000 (62%)\n",
      "[epoch 16] loss: 0.6134927\n",
      "Test set: Average loss: 1.2056, Accuracy: 3102/5000 (62%)\n",
      "[epoch 17] loss: 0.5410752\n",
      "Test set: Average loss: 1.2085, Accuracy: 3105/5000 (62%)\n",
      "[epoch 18] loss: 0.4674503\n",
      "Test set: Average loss: 1.3470, Accuracy: 3040/5000 (61%)\n",
      "[epoch 19] loss: 0.4053762\n",
      "Test set: Average loss: 1.3409, Accuracy: 3046/5000 (61%)\n",
      "[epoch 20] loss: 0.3295150\n",
      "Test set: Average loss: 1.4219, Accuracy: 3060/5000 (61%)\n",
      "[epoch 21] loss: 0.2640560\n",
      "Test set: Average loss: 1.4192, Accuracy: 3111/5000 (62%)\n",
      "[epoch 22] loss: 0.2020811\n",
      "Test set: Average loss: 1.5431, Accuracy: 3077/5000 (62%)\n",
      "[epoch 23] loss: 0.1606152\n",
      "Test set: Average loss: 1.6054, Accuracy: 3109/5000 (62%)\n",
      "[epoch 24] loss: 0.1111263\n",
      "Test set: Average loss: 1.7185, Accuracy: 3087/5000 (62%)\n",
      "[epoch 25] loss: 0.1161155\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8408, Accuracy: 3010/5000 (60%)\n",
      "[epoch 26] loss: 0.0463282\n",
      "Test set: Average loss: 1.7040, Accuracy: 3119/5000 (62%)\n",
      "[epoch 27] loss: 0.0196691\n",
      "Test set: Average loss: 1.7108, Accuracy: 3130/5000 (63%)\n",
      "[epoch 28] loss: 0.0141366\n",
      "Test set: Average loss: 1.7311, Accuracy: 3116/5000 (62%)\n",
      "[epoch 29] loss: 0.0110248\n",
      "Test set: Average loss: 1.7415, Accuracy: 3130/5000 (63%)\n",
      "[epoch 30] loss: 0.0088702\n",
      "Test set: Average loss: 1.7628, Accuracy: 3160/5000 (63%)\n",
      "[epoch 31] loss: 0.0072225\n",
      "Test set: Average loss: 1.7876, Accuracy: 3150/5000 (63%)\n",
      "[epoch 32] loss: 0.0059251\n",
      "Test set: Average loss: 1.8072, Accuracy: 3163/5000 (63%)\n",
      "[epoch 33] loss: 0.0048259\n",
      "Test set: Average loss: 1.8350, Accuracy: 3172/5000 (63%)\n",
      "[epoch 34] loss: 0.0039261\n",
      "Test set: Average loss: 1.8638, Accuracy: 3168/5000 (63%)\n",
      "[epoch 35] loss: 0.0031708\n",
      "Test set: Average loss: 1.8962, Accuracy: 3178/5000 (64%)\n",
      "[epoch 36] loss: 0.0025436\n",
      "Test set: Average loss: 1.9303, Accuracy: 3183/5000 (64%)\n",
      "[epoch 37] loss: 0.0020237\n",
      "Test set: Average loss: 1.9648, Accuracy: 3180/5000 (64%)\n",
      "[epoch 38] loss: 0.0015993\n",
      "Test set: Average loss: 2.0006, Accuracy: 3181/5000 (64%)\n",
      "[epoch 39] loss: 0.0012559\n",
      "Test set: Average loss: 2.0415, Accuracy: 3181/5000 (64%)\n",
      "[epoch 40] loss: 0.0009848\n",
      "Test set: Average loss: 2.0828, Accuracy: 3198/5000 (64%)\n",
      "[epoch 41] loss: 0.0007691\n",
      "Test set: Average loss: 2.1257, Accuracy: 3188/5000 (64%)\n",
      "[epoch 42] loss: 0.0005955\n",
      "Test set: Average loss: 2.1667, Accuracy: 3187/5000 (64%)\n",
      "[epoch 43] loss: 0.0004607\n",
      "Test set: Average loss: 2.2046, Accuracy: 3199/5000 (64%)\n",
      "[epoch 44] loss: 0.0003527\n",
      "Test set: Average loss: 2.2547, Accuracy: 3207/5000 (64%)\n",
      "[epoch 45] loss: 0.0002702\n",
      "Test set: Average loss: 2.3005, Accuracy: 3204/5000 (64%)\n",
      "[epoch 46] loss: 0.0002066\n",
      "Test set: Average loss: 2.3461, Accuracy: 3197/5000 (64%)\n",
      "[epoch 47] loss: 0.0001574\n",
      "Test set: Average loss: 2.3962, Accuracy: 3198/5000 (64%)\n",
      "[epoch 48] loss: 0.0001196\n",
      "Test set: Average loss: 2.4467, Accuracy: 3184/5000 (64%)\n",
      "[epoch 49] loss: 0.0000902\n",
      "Test set: Average loss: 2.4979, Accuracy: 3193/5000 (64%)\n",
      "[epoch 50] loss: 0.0000685\n",
      "Test set: Average loss: 2.5500, Accuracy: 3204/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2547, Accuracy: 3207/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.2345, Accuracy: 6464/10000 (65%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 476/5000 (10%)\n",
      "[epoch 1] loss: 1.3686680\n",
      "Test set: Average loss: 1.2459, Accuracy: 2768/5000 (55%)\n",
      "[epoch 2] loss: 1.1846459\n",
      "Test set: Average loss: 1.1945, Accuracy: 2877/5000 (58%)\n",
      "[epoch 3] loss: 1.1221836\n",
      "Test set: Average loss: 1.2488, Accuracy: 2750/5000 (55%)\n",
      "[epoch 4] loss: 1.0798802\n",
      "Test set: Average loss: 1.2010, Accuracy: 2856/5000 (57%)\n",
      "[epoch 5] loss: 1.0290719\n",
      "Test set: Average loss: 1.1313, Accuracy: 2982/5000 (60%)\n",
      "[epoch 6] loss: 1.0072955\n",
      "Test set: Average loss: 1.1394, Accuracy: 2973/5000 (59%)\n",
      "[epoch 7] loss: 0.9698878\n",
      "Test set: Average loss: 1.1680, Accuracy: 2997/5000 (60%)\n",
      "[epoch 8] loss: 0.9324813\n",
      "Test set: Average loss: 1.2133, Accuracy: 2940/5000 (59%)\n",
      "[epoch 9] loss: 0.9251846\n",
      "Test set: Average loss: 1.1380, Accuracy: 2982/5000 (60%)\n",
      "[epoch 10] loss: 0.8723049\n",
      "Test set: Average loss: 1.1810, Accuracy: 2944/5000 (59%)\n",
      "[epoch 11] loss: 0.8504635\n",
      "Test set: Average loss: 1.1713, Accuracy: 3002/5000 (60%)\n",
      "[epoch 12] loss: 0.8109079\n",
      "Test set: Average loss: 1.1234, Accuracy: 3068/5000 (61%)\n",
      "[epoch 13] loss: 0.7602049\n",
      "Test set: Average loss: 1.1694, Accuracy: 3040/5000 (61%)\n",
      "[epoch 14] loss: 0.7269059\n",
      "Test set: Average loss: 1.1483, Accuracy: 3086/5000 (62%)\n",
      "[epoch 15] loss: 0.6786330\n",
      "Test set: Average loss: 1.2033, Accuracy: 3082/5000 (62%)\n",
      "[epoch 16] loss: 0.6189435\n",
      "Test set: Average loss: 1.3054, Accuracy: 3038/5000 (61%)\n",
      "[epoch 17] loss: 0.5639207\n",
      "Test set: Average loss: 1.2361, Accuracy: 3084/5000 (62%)\n",
      "[epoch 18] loss: 0.4970866\n",
      "Test set: Average loss: 1.3045, Accuracy: 3048/5000 (61%)\n",
      "[epoch 19] loss: 0.4264529\n",
      "Test set: Average loss: 1.3773, Accuracy: 3091/5000 (62%)\n",
      "[epoch 20] loss: 0.3515315\n",
      "Test set: Average loss: 1.4675, Accuracy: 2967/5000 (59%)\n",
      "[epoch 21] loss: 0.2837558\n",
      "Test set: Average loss: 1.4290, Accuracy: 3063/5000 (61%)\n",
      "[epoch 22] loss: 0.2069841\n",
      "Test set: Average loss: 1.5624, Accuracy: 3016/5000 (60%)\n",
      "[epoch 23] loss: 0.1836028\n",
      "Test set: Average loss: 1.6111, Accuracy: 3037/5000 (61%)\n",
      "[epoch 24] loss: 0.1145320\n",
      "Test set: Average loss: 1.8065, Accuracy: 3023/5000 (60%)\n",
      "[epoch 25] loss: 0.1230298\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7788, Accuracy: 3054/5000 (61%)\n",
      "[epoch 26] loss: 0.0494400\n",
      "Test set: Average loss: 1.7304, Accuracy: 3174/5000 (63%)\n",
      "[epoch 27] loss: 0.0216798\n",
      "Test set: Average loss: 1.7403, Accuracy: 3182/5000 (64%)\n",
      "[epoch 28] loss: 0.0156552\n",
      "Test set: Average loss: 1.7486, Accuracy: 3171/5000 (63%)\n",
      "[epoch 29] loss: 0.0122076\n",
      "Test set: Average loss: 1.7673, Accuracy: 3191/5000 (64%)\n",
      "[epoch 30] loss: 0.0098540\n",
      "Test set: Average loss: 1.7821, Accuracy: 3191/5000 (64%)\n",
      "[epoch 31] loss: 0.0080322\n",
      "Test set: Average loss: 1.8082, Accuracy: 3192/5000 (64%)\n",
      "[epoch 32] loss: 0.0065677\n",
      "Test set: Average loss: 1.8296, Accuracy: 3185/5000 (64%)\n",
      "[epoch 33] loss: 0.0053789\n",
      "Test set: Average loss: 1.8548, Accuracy: 3197/5000 (64%)\n",
      "[epoch 34] loss: 0.0043731\n",
      "Test set: Average loss: 1.8868, Accuracy: 3187/5000 (64%)\n",
      "[epoch 35] loss: 0.0035355\n",
      "Test set: Average loss: 1.9178, Accuracy: 3200/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 36] loss: 0.0028392\n",
      "Test set: Average loss: 1.9534, Accuracy: 3192/5000 (64%)\n",
      "[epoch 37] loss: 0.0022755\n",
      "Test set: Average loss: 1.9948, Accuracy: 3192/5000 (64%)\n",
      "[epoch 38] loss: 0.0018032\n",
      "Test set: Average loss: 2.0265, Accuracy: 3189/5000 (64%)\n",
      "[epoch 39] loss: 0.0014231\n",
      "Test set: Average loss: 2.0690, Accuracy: 3185/5000 (64%)\n",
      "[epoch 40] loss: 0.0011111\n",
      "Test set: Average loss: 2.1098, Accuracy: 3193/5000 (64%)\n",
      "[epoch 41] loss: 0.0008701\n",
      "Test set: Average loss: 2.1593, Accuracy: 3192/5000 (64%)\n",
      "[epoch 42] loss: 0.0006735\n",
      "Test set: Average loss: 2.1954, Accuracy: 3190/5000 (64%)\n",
      "[epoch 43] loss: 0.0005203\n",
      "Test set: Average loss: 2.2426, Accuracy: 3189/5000 (64%)\n",
      "[epoch 44] loss: 0.0004014\n",
      "Test set: Average loss: 2.2888, Accuracy: 3192/5000 (64%)\n",
      "[epoch 45] loss: 0.0003088\n",
      "Test set: Average loss: 2.3340, Accuracy: 3182/5000 (64%)\n",
      "[epoch 46] loss: 0.0002358\n",
      "Test set: Average loss: 2.3838, Accuracy: 3184/5000 (64%)\n",
      "[epoch 47] loss: 0.0001806\n",
      "Test set: Average loss: 2.4292, Accuracy: 3192/5000 (64%)\n",
      "[epoch 48] loss: 0.0001373\n",
      "Test set: Average loss: 2.4805, Accuracy: 3188/5000 (64%)\n",
      "[epoch 49] loss: 0.0001038\n",
      "Test set: Average loss: 2.5241, Accuracy: 3168/5000 (63%)\n",
      "[epoch 50] loss: 0.0000792\n",
      "Test set: Average loss: 2.5771, Accuracy: 3180/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9178, Accuracy: 3200/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 1.8884, Accuracy: 6358/10000 (64%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3046, Accuracy: 544/5000 (11%)\n",
      "[epoch 1] loss: 1.3601948\n",
      "Test set: Average loss: 1.3562, Accuracy: 2619/5000 (52%)\n",
      "[epoch 2] loss: 1.1640872\n",
      "Test set: Average loss: 1.2036, Accuracy: 2877/5000 (58%)\n",
      "[epoch 3] loss: 1.1001012\n",
      "Test set: Average loss: 1.1650, Accuracy: 2989/5000 (60%)\n",
      "[epoch 4] loss: 1.0510053\n",
      "Test set: Average loss: 1.1471, Accuracy: 3006/5000 (60%)\n",
      "[epoch 5] loss: 1.0144871\n",
      "Test set: Average loss: 1.1536, Accuracy: 2986/5000 (60%)\n",
      "[epoch 6] loss: 0.9870590\n",
      "Test set: Average loss: 1.1125, Accuracy: 3039/5000 (61%)\n",
      "[epoch 7] loss: 0.9558021\n",
      "Test set: Average loss: 1.1628, Accuracy: 2991/5000 (60%)\n",
      "[epoch 8] loss: 0.9184730\n",
      "Test set: Average loss: 1.1260, Accuracy: 3032/5000 (61%)\n",
      "[epoch 9] loss: 0.8764586\n",
      "Test set: Average loss: 1.0820, Accuracy: 3122/5000 (62%)\n",
      "[epoch 10] loss: 0.8501605\n",
      "Test set: Average loss: 1.0711, Accuracy: 3142/5000 (63%)\n",
      "[epoch 11] loss: 0.8068473\n",
      "Test set: Average loss: 1.0521, Accuracy: 3208/5000 (64%)\n",
      "[epoch 12] loss: 0.7654418\n",
      "Test set: Average loss: 1.1114, Accuracy: 3120/5000 (62%)\n",
      "[epoch 13] loss: 0.7165693\n",
      "Test set: Average loss: 1.1374, Accuracy: 3119/5000 (62%)\n",
      "[epoch 14] loss: 0.6604581\n",
      "Test set: Average loss: 1.1495, Accuracy: 3156/5000 (63%)\n",
      "[epoch 15] loss: 0.6019364\n",
      "Test set: Average loss: 1.1431, Accuracy: 3190/5000 (64%)\n",
      "[epoch 16] loss: 0.5349425\n",
      "Test set: Average loss: 1.1776, Accuracy: 3184/5000 (64%)\n",
      "[epoch 17] loss: 0.4607653\n",
      "Test set: Average loss: 1.2607, Accuracy: 3145/5000 (63%)\n",
      "[epoch 18] loss: 0.3833191\n",
      "Test set: Average loss: 1.3423, Accuracy: 3156/5000 (63%)\n",
      "[epoch 19] loss: 0.3139188\n",
      "Test set: Average loss: 1.3668, Accuracy: 3157/5000 (63%)\n",
      "[epoch 20] loss: 0.2420327\n",
      "Test set: Average loss: 1.4371, Accuracy: 3160/5000 (63%)\n",
      "[epoch 21] loss: 0.1916298\n",
      "Test set: Average loss: 1.5736, Accuracy: 3120/5000 (62%)\n",
      "[epoch 22] loss: 0.1396711\n",
      "Test set: Average loss: 1.6174, Accuracy: 3113/5000 (62%)\n",
      "[epoch 23] loss: 0.1385042\n",
      "Test set: Average loss: 1.7715, Accuracy: 3100/5000 (62%)\n",
      "[epoch 24] loss: 0.1546960\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8316, Accuracy: 3107/5000 (62%)\n",
      "[epoch 25] loss: 0.0516944\n",
      "Test set: Average loss: 1.6853, Accuracy: 3237/5000 (65%)\n",
      "[epoch 26] loss: 0.0193689\n",
      "Test set: Average loss: 1.7016, Accuracy: 3243/5000 (65%)\n",
      "[epoch 27] loss: 0.0129127\n",
      "Test set: Average loss: 1.7122, Accuracy: 3248/5000 (65%)\n",
      "[epoch 28] loss: 0.0096323\n",
      "Test set: Average loss: 1.7360, Accuracy: 3254/5000 (65%)\n",
      "[epoch 29] loss: 0.0073599\n",
      "Test set: Average loss: 1.7524, Accuracy: 3251/5000 (65%)\n",
      "[epoch 30] loss: 0.0057026\n",
      "Test set: Average loss: 1.7812, Accuracy: 3257/5000 (65%)\n",
      "[epoch 31] loss: 0.0044323\n",
      "Test set: Average loss: 1.8078, Accuracy: 3255/5000 (65%)\n",
      "[epoch 32] loss: 0.0034250\n",
      "Test set: Average loss: 1.8419, Accuracy: 3261/5000 (65%)\n",
      "[epoch 33] loss: 0.0026319\n",
      "Test set: Average loss: 1.8789, Accuracy: 3257/5000 (65%)\n",
      "[epoch 34] loss: 0.0020057\n",
      "Test set: Average loss: 1.9109, Accuracy: 3271/5000 (65%)\n",
      "[epoch 35] loss: 0.0015097\n",
      "Test set: Average loss: 1.9571, Accuracy: 3264/5000 (65%)\n",
      "[epoch 36] loss: 0.0011289\n",
      "Test set: Average loss: 1.9993, Accuracy: 3283/5000 (66%)\n",
      "[epoch 37] loss: 0.0008350\n",
      "Test set: Average loss: 2.0386, Accuracy: 3272/5000 (65%)\n",
      "[epoch 38] loss: 0.0006188\n",
      "Test set: Average loss: 2.0920, Accuracy: 3281/5000 (66%)\n",
      "[epoch 39] loss: 0.0004540\n",
      "Test set: Average loss: 2.1386, Accuracy: 3282/5000 (66%)\n",
      "[epoch 40] loss: 0.0003313\n",
      "Test set: Average loss: 2.1857, Accuracy: 3293/5000 (66%)\n",
      "[epoch 41] loss: 0.0002408\n",
      "Test set: Average loss: 2.2359, Accuracy: 3292/5000 (66%)\n",
      "[epoch 42] loss: 0.0001741\n",
      "Test set: Average loss: 2.2907, Accuracy: 3283/5000 (66%)\n",
      "[epoch 43] loss: 0.0001251\n",
      "Test set: Average loss: 2.3419, Accuracy: 3293/5000 (66%)\n",
      "[epoch 44] loss: 0.0000900\n",
      "Test set: Average loss: 2.3952, Accuracy: 3288/5000 (66%)\n",
      "[epoch 45] loss: 0.0000642\n",
      "Test set: Average loss: 2.4522, Accuracy: 3298/5000 (66%)\n",
      "[epoch 46] loss: 0.0000460\n",
      "Test set: Average loss: 2.5142, Accuracy: 3298/5000 (66%)\n",
      "[epoch 47] loss: 0.0000327\n",
      "Test set: Average loss: 2.5671, Accuracy: 3286/5000 (66%)\n",
      "[epoch 48] loss: 0.0000233\n",
      "Test set: Average loss: 2.6232, Accuracy: 3295/5000 (66%)\n",
      "[epoch 49] loss: 0.0000165\n",
      "Test set: Average loss: 2.6746, Accuracy: 3291/5000 (66%)\n",
      "[epoch 50] loss: 0.0000117\n",
      "Test set: Average loss: 2.7398, Accuracy: 3289/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5142, Accuracy: 3298/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.4053, Accuracy: 6601/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3021, Accuracy: 508/5000 (10%)\n",
      "[epoch 1] loss: 1.3734468\n",
      "Test set: Average loss: 1.2706, Accuracy: 2745/5000 (55%)\n",
      "[epoch 2] loss: 1.1708540\n",
      "Test set: Average loss: 1.1957, Accuracy: 2858/5000 (57%)\n",
      "[epoch 3] loss: 1.1007670\n",
      "Test set: Average loss: 1.1885, Accuracy: 2910/5000 (58%)\n",
      "[epoch 4] loss: 1.0676382\n",
      "Test set: Average loss: 1.1240, Accuracy: 3023/5000 (60%)\n",
      "[epoch 5] loss: 1.0257569\n",
      "Test set: Average loss: 1.1788, Accuracy: 2924/5000 (58%)\n",
      "[epoch 6] loss: 0.9882801\n",
      "Test set: Average loss: 1.1132, Accuracy: 3051/5000 (61%)\n",
      "[epoch 7] loss: 0.9559061\n",
      "Test set: Average loss: 1.1415, Accuracy: 3009/5000 (60%)\n",
      "[epoch 8] loss: 0.9281326\n",
      "Test set: Average loss: 1.1104, Accuracy: 3048/5000 (61%)\n",
      "[epoch 9] loss: 0.8898051\n",
      "Test set: Average loss: 1.0987, Accuracy: 3081/5000 (62%)\n",
      "[epoch 10] loss: 0.8566339\n",
      "Test set: Average loss: 1.1006, Accuracy: 3112/5000 (62%)\n",
      "[epoch 11] loss: 0.8094988\n",
      "Test set: Average loss: 1.0794, Accuracy: 3176/5000 (64%)\n",
      "[epoch 12] loss: 0.7629642\n",
      "Test set: Average loss: 1.1266, Accuracy: 3087/5000 (62%)\n",
      "[epoch 13] loss: 0.7175259\n",
      "Test set: Average loss: 1.1339, Accuracy: 3096/5000 (62%)\n",
      "[epoch 14] loss: 0.6607958\n",
      "Test set: Average loss: 1.1112, Accuracy: 3176/5000 (64%)\n",
      "[epoch 15] loss: 0.6020249\n",
      "Test set: Average loss: 1.1972, Accuracy: 3086/5000 (62%)\n",
      "[epoch 16] loss: 0.5390205\n",
      "Test set: Average loss: 1.2106, Accuracy: 3171/5000 (63%)\n",
      "[epoch 17] loss: 0.4606108\n",
      "Test set: Average loss: 1.2712, Accuracy: 3145/5000 (63%)\n",
      "[epoch 18] loss: 0.3964196\n",
      "Test set: Average loss: 1.3089, Accuracy: 3171/5000 (63%)\n",
      "[epoch 19] loss: 0.3017913\n",
      "Test set: Average loss: 1.4101, Accuracy: 3144/5000 (63%)\n",
      "[epoch 20] loss: 0.2330412\n",
      "Test set: Average loss: 1.4565, Accuracy: 3151/5000 (63%)\n",
      "[epoch 21] loss: 0.1788665\n",
      "Test set: Average loss: 1.5210, Accuracy: 3160/5000 (63%)\n",
      "[epoch 22] loss: 0.1508615\n",
      "Test set: Average loss: 1.6435, Accuracy: 3101/5000 (62%)\n",
      "[epoch 23] loss: 0.1442992\n",
      "Test set: Average loss: 1.7744, Accuracy: 3150/5000 (63%)\n",
      "[epoch 24] loss: 0.1316901\n",
      "Test set: Average loss: 1.7718, Accuracy: 3150/5000 (63%)\n",
      "[epoch 25] loss: 0.1267385\n",
      "Test set: Average loss: 1.8550, Accuracy: 3080/5000 (62%)\n",
      "[epoch 26] loss: 0.1057560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.9225, Accuracy: 3104/5000 (62%)\n",
      "[epoch 27] loss: 0.1047833\n",
      "Test set: Average loss: 2.0085, Accuracy: 3069/5000 (61%)\n",
      "[epoch 28] loss: 0.1045640\n",
      "Test set: Average loss: 2.0020, Accuracy: 3162/5000 (63%)\n",
      "[epoch 29] loss: 0.0861002\n",
      "Test set: Average loss: 1.9828, Accuracy: 3112/5000 (62%)\n",
      "[epoch 30] loss: 0.1239352\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0469, Accuracy: 3143/5000 (63%)\n",
      "[epoch 31] loss: 0.0289474\n",
      "Test set: Average loss: 1.9752, Accuracy: 3194/5000 (64%)\n",
      "[epoch 32] loss: 0.0089136\n",
      "Test set: Average loss: 1.9754, Accuracy: 3206/5000 (64%)\n",
      "[epoch 33] loss: 0.0058428\n",
      "Test set: Average loss: 1.9849, Accuracy: 3200/5000 (64%)\n",
      "[epoch 34] loss: 0.0043099\n",
      "Test set: Average loss: 1.9975, Accuracy: 3221/5000 (64%)\n",
      "[epoch 35] loss: 0.0032742\n",
      "Test set: Average loss: 2.0109, Accuracy: 3221/5000 (64%)\n",
      "[epoch 36] loss: 0.0025299\n",
      "Test set: Average loss: 2.0315, Accuracy: 3233/5000 (65%)\n",
      "[epoch 37] loss: 0.0019644\n",
      "Test set: Average loss: 2.0480, Accuracy: 3234/5000 (65%)\n",
      "[epoch 38] loss: 0.0015203\n",
      "Test set: Average loss: 2.0740, Accuracy: 3231/5000 (65%)\n",
      "[epoch 39] loss: 0.0011693\n",
      "Test set: Average loss: 2.1019, Accuracy: 3235/5000 (65%)\n",
      "[epoch 40] loss: 0.0008964\n",
      "Test set: Average loss: 2.1245, Accuracy: 3241/5000 (65%)\n",
      "[epoch 41] loss: 0.0006759\n",
      "Test set: Average loss: 2.1601, Accuracy: 3244/5000 (65%)\n",
      "[epoch 42] loss: 0.0005072\n",
      "Test set: Average loss: 2.1956, Accuracy: 3240/5000 (65%)\n",
      "[epoch 43] loss: 0.0003784\n",
      "Test set: Average loss: 2.2299, Accuracy: 3245/5000 (65%)\n",
      "[epoch 44] loss: 0.0002788\n",
      "Test set: Average loss: 2.2713, Accuracy: 3257/5000 (65%)\n",
      "[epoch 45] loss: 0.0002054\n",
      "Test set: Average loss: 2.3051, Accuracy: 3263/5000 (65%)\n",
      "[epoch 46] loss: 0.0001497\n",
      "Test set: Average loss: 2.3594, Accuracy: 3247/5000 (65%)\n",
      "[epoch 47] loss: 0.0001084\n",
      "Test set: Average loss: 2.3957, Accuracy: 3249/5000 (65%)\n",
      "[epoch 48] loss: 0.0000781\n",
      "Test set: Average loss: 2.4493, Accuracy: 3250/5000 (65%)\n",
      "[epoch 49] loss: 0.0000562\n",
      "Test set: Average loss: 2.4933, Accuracy: 3250/5000 (65%)\n",
      "[epoch 50] loss: 0.0000402\n",
      "Test set: Average loss: 2.5511, Accuracy: 3252/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3051, Accuracy: 3263/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.2673, Accuracy: 6611/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 483/5000 (10%)\n",
      "[epoch 1] loss: 1.3643306\n",
      "Test set: Average loss: 1.2604, Accuracy: 2761/5000 (55%)\n",
      "[epoch 2] loss: 1.1775503\n",
      "Test set: Average loss: 1.2336, Accuracy: 2886/5000 (58%)\n",
      "[epoch 3] loss: 1.1045254\n",
      "Test set: Average loss: 1.1566, Accuracy: 2956/5000 (59%)\n",
      "[epoch 4] loss: 1.0659256\n",
      "Test set: Average loss: 1.1559, Accuracy: 2965/5000 (59%)\n",
      "[epoch 5] loss: 1.0325001\n",
      "Test set: Average loss: 1.2554, Accuracy: 2809/5000 (56%)\n",
      "[epoch 6] loss: 0.9937891\n",
      "Test set: Average loss: 1.0736, Accuracy: 3126/5000 (63%)\n",
      "[epoch 7] loss: 0.9533497\n",
      "Test set: Average loss: 1.1842, Accuracy: 2974/5000 (59%)\n",
      "[epoch 8] loss: 0.9261303\n",
      "Test set: Average loss: 1.1547, Accuracy: 2993/5000 (60%)\n",
      "[epoch 9] loss: 0.8889678\n",
      "Test set: Average loss: 1.1556, Accuracy: 3032/5000 (61%)\n",
      "[epoch 10] loss: 0.8490059\n",
      "Test set: Average loss: 1.1007, Accuracy: 3153/5000 (63%)\n",
      "[epoch 11] loss: 0.8112261\n",
      "Test set: Average loss: 1.1239, Accuracy: 3106/5000 (62%)\n",
      "[epoch 12] loss: 0.7640579\n",
      "Test set: Average loss: 1.0980, Accuracy: 3140/5000 (63%)\n",
      "[epoch 13] loss: 0.7129793\n",
      "Test set: Average loss: 1.1267, Accuracy: 3170/5000 (63%)\n",
      "[epoch 14] loss: 0.6750887\n",
      "Test set: Average loss: 1.1385, Accuracy: 3146/5000 (63%)\n",
      "[epoch 15] loss: 0.5999744\n",
      "Test set: Average loss: 1.1601, Accuracy: 3135/5000 (63%)\n",
      "[epoch 16] loss: 0.5349641\n",
      "Test set: Average loss: 1.2456, Accuracy: 3099/5000 (62%)\n",
      "[epoch 17] loss: 0.4570277\n",
      "Test set: Average loss: 1.2940, Accuracy: 3099/5000 (62%)\n",
      "[epoch 18] loss: 0.3802496\n",
      "Test set: Average loss: 1.2809, Accuracy: 3146/5000 (63%)\n",
      "[epoch 19] loss: 0.3017328\n",
      "Test set: Average loss: 1.4306, Accuracy: 3121/5000 (62%)\n",
      "[epoch 20] loss: 0.2427840\n",
      "Test set: Average loss: 1.4509, Accuracy: 3146/5000 (63%)\n",
      "[epoch 21] loss: 0.1755454\n",
      "Test set: Average loss: 1.5396, Accuracy: 3113/5000 (62%)\n",
      "[epoch 22] loss: 0.1451806\n",
      "Test set: Average loss: 1.6283, Accuracy: 3153/5000 (63%)\n",
      "[epoch 23] loss: 0.1314106\n",
      "Test set: Average loss: 1.7474, Accuracy: 3154/5000 (63%)\n",
      "[epoch 24] loss: 0.1396657\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8454, Accuracy: 3062/5000 (61%)\n",
      "[epoch 25] loss: 0.0469074\n",
      "Test set: Average loss: 1.7412, Accuracy: 3191/5000 (64%)\n",
      "[epoch 26] loss: 0.0181615\n",
      "Test set: Average loss: 1.7460, Accuracy: 3201/5000 (64%)\n",
      "[epoch 27] loss: 0.0122353\n",
      "Test set: Average loss: 1.7628, Accuracy: 3216/5000 (64%)\n",
      "[epoch 28] loss: 0.0091410\n",
      "Test set: Average loss: 1.7818, Accuracy: 3212/5000 (64%)\n",
      "[epoch 29] loss: 0.0070149\n",
      "Test set: Average loss: 1.8018, Accuracy: 3221/5000 (64%)\n",
      "[epoch 30] loss: 0.0054471\n",
      "Test set: Average loss: 1.8294, Accuracy: 3228/5000 (65%)\n",
      "[epoch 31] loss: 0.0042305\n",
      "Test set: Average loss: 1.8578, Accuracy: 3233/5000 (65%)\n",
      "[epoch 32] loss: 0.0032543\n",
      "Test set: Average loss: 1.8905, Accuracy: 3242/5000 (65%)\n",
      "[epoch 33] loss: 0.0024927\n",
      "Test set: Average loss: 1.9294, Accuracy: 3249/5000 (65%)\n",
      "[epoch 34] loss: 0.0018884\n",
      "Test set: Average loss: 1.9595, Accuracy: 3236/5000 (65%)\n",
      "[epoch 35] loss: 0.0014195\n",
      "Test set: Average loss: 2.0112, Accuracy: 3249/5000 (65%)\n",
      "[epoch 36] loss: 0.0010676\n",
      "Test set: Average loss: 2.0443, Accuracy: 3254/5000 (65%)\n",
      "[epoch 37] loss: 0.0007873\n",
      "Test set: Average loss: 2.0926, Accuracy: 3249/5000 (65%)\n",
      "[epoch 38] loss: 0.0005809\n",
      "Test set: Average loss: 2.1317, Accuracy: 3252/5000 (65%)\n",
      "[epoch 39] loss: 0.0004257\n",
      "Test set: Average loss: 2.1892, Accuracy: 3262/5000 (65%)\n",
      "[epoch 40] loss: 0.0003113\n",
      "Test set: Average loss: 2.2314, Accuracy: 3265/5000 (65%)\n",
      "[epoch 41] loss: 0.0002261\n",
      "Test set: Average loss: 2.2815, Accuracy: 3255/5000 (65%)\n",
      "[epoch 42] loss: 0.0001626\n",
      "Test set: Average loss: 2.3361, Accuracy: 3276/5000 (66%)\n",
      "[epoch 43] loss: 0.0001173\n",
      "Test set: Average loss: 2.3928, Accuracy: 3263/5000 (65%)\n",
      "[epoch 44] loss: 0.0000844\n",
      "Test set: Average loss: 2.4463, Accuracy: 3266/5000 (65%)\n",
      "[epoch 45] loss: 0.0000600\n",
      "Test set: Average loss: 2.4974, Accuracy: 3271/5000 (65%)\n",
      "[epoch 46] loss: 0.0000430\n",
      "Test set: Average loss: 2.5566, Accuracy: 3267/5000 (65%)\n",
      "[epoch 47] loss: 0.0000305\n",
      "Test set: Average loss: 2.6130, Accuracy: 3260/5000 (65%)\n",
      "[epoch 48] loss: 0.0000217\n",
      "Test set: Average loss: 2.6698, Accuracy: 3253/5000 (65%)\n",
      "[epoch 49] loss: 0.0000154\n",
      "Test set: Average loss: 2.7269, Accuracy: 3256/5000 (65%)\n",
      "[epoch 50] loss: 0.0000109\n",
      "Test set: Average loss: 2.7798, Accuracy: 3266/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3361, Accuracy: 3276/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.2736, Accuracy: 6550/10000 (66%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3046, Accuracy: 504/5000 (10%)\n",
      "[epoch 1] loss: 1.3451011\n",
      "Test set: Average loss: 1.2372, Accuracy: 2796/5000 (56%)\n",
      "[epoch 2] loss: 1.1620896\n",
      "Test set: Average loss: 1.2132, Accuracy: 2908/5000 (58%)\n",
      "[epoch 3] loss: 1.1034607\n",
      "Test set: Average loss: 1.1639, Accuracy: 2997/5000 (60%)\n",
      "[epoch 4] loss: 1.0547283\n",
      "Test set: Average loss: 1.1943, Accuracy: 2898/5000 (58%)\n",
      "[epoch 5] loss: 1.0216353\n",
      "Test set: Average loss: 1.1261, Accuracy: 3054/5000 (61%)\n",
      "[epoch 6] loss: 0.9742702\n",
      "Test set: Average loss: 1.1560, Accuracy: 2989/5000 (60%)\n",
      "[epoch 7] loss: 0.9410465\n",
      "Test set: Average loss: 1.1264, Accuracy: 3045/5000 (61%)\n",
      "[epoch 8] loss: 0.9040891\n",
      "Test set: Average loss: 1.0791, Accuracy: 3158/5000 (63%)\n",
      "[epoch 9] loss: 0.8689247\n",
      "Test set: Average loss: 1.0957, Accuracy: 3101/5000 (62%)\n",
      "[epoch 10] loss: 0.8272852\n",
      "Test set: Average loss: 1.1167, Accuracy: 3121/5000 (62%)\n",
      "[epoch 11] loss: 0.7864053\n",
      "Test set: Average loss: 1.0559, Accuracy: 3199/5000 (64%)\n",
      "[epoch 12] loss: 0.7393898\n",
      "Test set: Average loss: 1.1125, Accuracy: 3172/5000 (63%)\n",
      "[epoch 13] loss: 0.6778109\n",
      "Test set: Average loss: 1.0917, Accuracy: 3207/5000 (64%)\n",
      "[epoch 14] loss: 0.6201088\n",
      "Test set: Average loss: 1.1937, Accuracy: 3129/5000 (63%)\n",
      "[epoch 15] loss: 0.5515886\n",
      "Test set: Average loss: 1.1904, Accuracy: 3185/5000 (64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 0.4813258\n",
      "Test set: Average loss: 1.2319, Accuracy: 3164/5000 (63%)\n",
      "[epoch 17] loss: 0.4109644\n",
      "Test set: Average loss: 1.2381, Accuracy: 3196/5000 (64%)\n",
      "[epoch 18] loss: 0.3219767\n",
      "Test set: Average loss: 1.2915, Accuracy: 3233/5000 (65%)\n",
      "[epoch 19] loss: 0.2608319\n",
      "Test set: Average loss: 1.3598, Accuracy: 3205/5000 (64%)\n",
      "[epoch 20] loss: 0.1990271\n",
      "Test set: Average loss: 1.4792, Accuracy: 3215/5000 (64%)\n",
      "[epoch 21] loss: 0.1722899\n",
      "Test set: Average loss: 1.5224, Accuracy: 3226/5000 (65%)\n",
      "[epoch 22] loss: 0.1601819\n",
      "Test set: Average loss: 1.6982, Accuracy: 3210/5000 (64%)\n",
      "[epoch 23] loss: 0.1510573\n",
      "Test set: Average loss: 1.7763, Accuracy: 3117/5000 (62%)\n",
      "[epoch 24] loss: 0.1584747\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8178, Accuracy: 3166/5000 (63%)\n",
      "[epoch 25] loss: 0.0466694\n",
      "Test set: Average loss: 1.6580, Accuracy: 3285/5000 (66%)\n",
      "[epoch 26] loss: 0.0172890\n",
      "Test set: Average loss: 1.6695, Accuracy: 3289/5000 (66%)\n",
      "[epoch 27] loss: 0.0111939\n",
      "Test set: Average loss: 1.6872, Accuracy: 3312/5000 (66%)\n",
      "[epoch 28] loss: 0.0079887\n",
      "Test set: Average loss: 1.7082, Accuracy: 3310/5000 (66%)\n",
      "[epoch 29] loss: 0.0059335\n",
      "Test set: Average loss: 1.7295, Accuracy: 3319/5000 (66%)\n",
      "[epoch 30] loss: 0.0044070\n",
      "Test set: Average loss: 1.7617, Accuracy: 3321/5000 (66%)\n",
      "[epoch 31] loss: 0.0032493\n",
      "Test set: Average loss: 1.7929, Accuracy: 3322/5000 (66%)\n",
      "[epoch 32] loss: 0.0023753\n",
      "Test set: Average loss: 1.8244, Accuracy: 3332/5000 (67%)\n",
      "[epoch 33] loss: 0.0017085\n",
      "Test set: Average loss: 1.8659, Accuracy: 3339/5000 (67%)\n",
      "[epoch 34] loss: 0.0012263\n",
      "Test set: Average loss: 1.9092, Accuracy: 3333/5000 (67%)\n",
      "[epoch 35] loss: 0.0008684\n",
      "Test set: Average loss: 1.9460, Accuracy: 3335/5000 (67%)\n",
      "[epoch 36] loss: 0.0006088\n",
      "Test set: Average loss: 1.9997, Accuracy: 3351/5000 (67%)\n",
      "[epoch 37] loss: 0.0004265\n",
      "Test set: Average loss: 2.0524, Accuracy: 3345/5000 (67%)\n",
      "[epoch 38] loss: 0.0002952\n",
      "Test set: Average loss: 2.0976, Accuracy: 3343/5000 (67%)\n",
      "[epoch 39] loss: 0.0002029\n",
      "Test set: Average loss: 2.1551, Accuracy: 3359/5000 (67%)\n",
      "[epoch 40] loss: 0.0001401\n",
      "Test set: Average loss: 2.2192, Accuracy: 3346/5000 (67%)\n",
      "[epoch 41] loss: 0.0000955\n",
      "Test set: Average loss: 2.2710, Accuracy: 3342/5000 (67%)\n",
      "[epoch 42] loss: 0.0000652\n",
      "Test set: Average loss: 2.3287, Accuracy: 3344/5000 (67%)\n",
      "[epoch 43] loss: 0.0000441\n",
      "Test set: Average loss: 2.3850, Accuracy: 3340/5000 (67%)\n",
      "[epoch 44] loss: 0.0000299\n",
      "Test set: Average loss: 2.4395, Accuracy: 3339/5000 (67%)\n",
      "[epoch 45] loss: 0.0000203\n",
      "Test set: Average loss: 2.5070, Accuracy: 3343/5000 (67%)\n",
      "[epoch 46] loss: 0.0000135\n",
      "Test set: Average loss: 2.5665, Accuracy: 3348/5000 (67%)\n",
      "[epoch 47] loss: 0.0000090\n",
      "Test set: Average loss: 2.6290, Accuracy: 3347/5000 (67%)\n",
      "[epoch 48] loss: 0.0000060\n",
      "Test set: Average loss: 2.6936, Accuracy: 3347/5000 (67%)\n",
      "[epoch 49] loss: 0.0000040\n",
      "Test set: Average loss: 2.7548, Accuracy: 3343/5000 (67%)\n",
      "[epoch 50] loss: 0.0000027\n",
      "Test set: Average loss: 2.8129, Accuracy: 3341/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1551, Accuracy: 3359/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.0869, Accuracy: 6749/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 550/5000 (11%)\n",
      "[epoch 1] loss: 1.3551911\n",
      "Test set: Average loss: 1.2473, Accuracy: 2724/5000 (54%)\n",
      "[epoch 2] loss: 1.1591667\n",
      "Test set: Average loss: 1.2210, Accuracy: 2801/5000 (56%)\n",
      "[epoch 3] loss: 1.0997607\n",
      "Test set: Average loss: 1.1766, Accuracy: 2944/5000 (59%)\n",
      "[epoch 4] loss: 1.0480676\n",
      "Test set: Average loss: 1.1532, Accuracy: 2988/5000 (60%)\n",
      "[epoch 5] loss: 1.0085541\n",
      "Test set: Average loss: 1.0879, Accuracy: 3079/5000 (62%)\n",
      "[epoch 6] loss: 0.9706660\n",
      "Test set: Average loss: 1.0752, Accuracy: 3093/5000 (62%)\n",
      "[epoch 7] loss: 0.9409623\n",
      "Test set: Average loss: 1.1008, Accuracy: 3090/5000 (62%)\n",
      "[epoch 8] loss: 0.9068566\n",
      "Test set: Average loss: 1.0467, Accuracy: 3165/5000 (63%)\n",
      "[epoch 9] loss: 0.8677016\n",
      "Test set: Average loss: 1.1161, Accuracy: 3101/5000 (62%)\n",
      "[epoch 10] loss: 0.8364393\n",
      "Test set: Average loss: 1.0542, Accuracy: 3211/5000 (64%)\n",
      "[epoch 11] loss: 0.7954998\n",
      "Test set: Average loss: 1.0775, Accuracy: 3202/5000 (64%)\n",
      "[epoch 12] loss: 0.7491892\n",
      "Test set: Average loss: 1.1092, Accuracy: 3158/5000 (63%)\n",
      "[epoch 13] loss: 0.6966612\n",
      "Test set: Average loss: 1.0577, Accuracy: 3244/5000 (65%)\n",
      "[epoch 14] loss: 0.6368127\n",
      "Test set: Average loss: 1.1735, Accuracy: 3120/5000 (62%)\n",
      "[epoch 15] loss: 0.5716907\n",
      "Test set: Average loss: 1.1607, Accuracy: 3189/5000 (64%)\n",
      "[epoch 16] loss: 0.4966393\n",
      "Test set: Average loss: 1.1984, Accuracy: 3157/5000 (63%)\n",
      "[epoch 17] loss: 0.4143977\n",
      "Test set: Average loss: 1.2258, Accuracy: 3219/5000 (64%)\n",
      "[epoch 18] loss: 0.3399131\n",
      "Test set: Average loss: 1.3253, Accuracy: 3195/5000 (64%)\n",
      "[epoch 19] loss: 0.2638676\n",
      "Test set: Average loss: 1.4376, Accuracy: 3172/5000 (63%)\n",
      "[epoch 20] loss: 0.2120728\n",
      "Test set: Average loss: 1.4976, Accuracy: 3166/5000 (63%)\n",
      "[epoch 21] loss: 0.1749726\n",
      "Test set: Average loss: 1.5823, Accuracy: 3176/5000 (64%)\n",
      "[epoch 22] loss: 0.1602831\n",
      "Test set: Average loss: 1.7042, Accuracy: 3120/5000 (62%)\n",
      "[epoch 23] loss: 0.1374601\n",
      "Test set: Average loss: 1.7275, Accuracy: 3181/5000 (64%)\n",
      "[epoch 24] loss: 0.1207608\n",
      "Test set: Average loss: 1.8621, Accuracy: 3149/5000 (63%)\n",
      "[epoch 25] loss: 0.1277177\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8755, Accuracy: 3185/5000 (64%)\n",
      "[epoch 26] loss: 0.0448574\n",
      "Test set: Average loss: 1.7861, Accuracy: 3248/5000 (65%)\n",
      "[epoch 27] loss: 0.0149214\n",
      "Test set: Average loss: 1.7931, Accuracy: 3261/5000 (65%)\n",
      "[epoch 28] loss: 0.0095272\n",
      "Test set: Average loss: 1.8064, Accuracy: 3261/5000 (65%)\n",
      "[epoch 29] loss: 0.0067651\n",
      "Test set: Average loss: 1.8257, Accuracy: 3285/5000 (66%)\n",
      "[epoch 30] loss: 0.0049671\n",
      "Test set: Average loss: 1.8469, Accuracy: 3289/5000 (66%)\n",
      "[epoch 31] loss: 0.0036454\n",
      "Test set: Average loss: 1.8746, Accuracy: 3285/5000 (66%)\n",
      "[epoch 32] loss: 0.0026687\n",
      "Test set: Average loss: 1.9042, Accuracy: 3291/5000 (66%)\n",
      "[epoch 33] loss: 0.0019417\n",
      "Test set: Average loss: 1.9404, Accuracy: 3290/5000 (66%)\n",
      "[epoch 34] loss: 0.0014007\n",
      "Test set: Average loss: 1.9828, Accuracy: 3292/5000 (66%)\n",
      "[epoch 35] loss: 0.0010032\n",
      "Test set: Average loss: 2.0215, Accuracy: 3293/5000 (66%)\n",
      "[epoch 36] loss: 0.0007084\n",
      "Test set: Average loss: 2.0690, Accuracy: 3296/5000 (66%)\n",
      "[epoch 37] loss: 0.0004970\n",
      "Test set: Average loss: 2.1160, Accuracy: 3290/5000 (66%)\n",
      "[epoch 38] loss: 0.0003494\n",
      "Test set: Average loss: 2.1714, Accuracy: 3302/5000 (66%)\n",
      "[epoch 39] loss: 0.0002415\n",
      "Test set: Average loss: 2.2268, Accuracy: 3298/5000 (66%)\n",
      "[epoch 40] loss: 0.0001659\n",
      "Test set: Average loss: 2.2763, Accuracy: 3303/5000 (66%)\n",
      "[epoch 41] loss: 0.0001139\n",
      "Test set: Average loss: 2.3364, Accuracy: 3302/5000 (66%)\n",
      "[epoch 42] loss: 0.0000778\n",
      "Test set: Average loss: 2.3905, Accuracy: 3305/5000 (66%)\n",
      "[epoch 43] loss: 0.0000527\n",
      "Test set: Average loss: 2.4563, Accuracy: 3300/5000 (66%)\n",
      "[epoch 44] loss: 0.0000359\n",
      "Test set: Average loss: 2.5171, Accuracy: 3288/5000 (66%)\n",
      "[epoch 45] loss: 0.0000242\n",
      "Test set: Average loss: 2.5816, Accuracy: 3289/5000 (66%)\n",
      "[epoch 46] loss: 0.0000162\n",
      "Test set: Average loss: 2.6466, Accuracy: 3310/5000 (66%)\n",
      "[epoch 47] loss: 0.0000109\n",
      "Test set: Average loss: 2.7070, Accuracy: 3300/5000 (66%)\n",
      "[epoch 48] loss: 0.0000073\n",
      "Test set: Average loss: 2.7690, Accuracy: 3308/5000 (66%)\n",
      "[epoch 49] loss: 0.0000049\n",
      "Test set: Average loss: 2.8334, Accuracy: 3306/5000 (66%)\n",
      "[epoch 50] loss: 0.0000032\n",
      "Test set: Average loss: 2.9037, Accuracy: 3293/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6466, Accuracy: 3310/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.5810, Accuracy: 6699/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3010, Accuracy: 520/5000 (10%)\n",
      "[epoch 1] loss: 1.3459482\n",
      "Test set: Average loss: 1.2540, Accuracy: 2770/5000 (55%)\n",
      "[epoch 2] loss: 1.1602801\n",
      "Test set: Average loss: 1.1724, Accuracy: 2917/5000 (58%)\n",
      "[epoch 3] loss: 1.1000279\n",
      "Test set: Average loss: 1.1571, Accuracy: 2936/5000 (59%)\n",
      "[epoch 4] loss: 1.0457324\n",
      "Test set: Average loss: 1.1012, Accuracy: 3045/5000 (61%)\n",
      "[epoch 5] loss: 1.0132085\n",
      "Test set: Average loss: 1.1125, Accuracy: 3022/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.9785415\n",
      "Test set: Average loss: 1.1257, Accuracy: 3036/5000 (61%)\n",
      "[epoch 7] loss: 0.9462890\n",
      "Test set: Average loss: 1.1609, Accuracy: 2989/5000 (60%)\n",
      "[epoch 8] loss: 0.9110113\n",
      "Test set: Average loss: 1.0786, Accuracy: 3104/5000 (62%)\n",
      "[epoch 9] loss: 0.8713597\n",
      "Test set: Average loss: 1.0709, Accuracy: 3107/5000 (62%)\n",
      "[epoch 10] loss: 0.8315276\n",
      "Test set: Average loss: 1.1259, Accuracy: 3090/5000 (62%)\n",
      "[epoch 11] loss: 0.7826066\n",
      "Test set: Average loss: 1.1221, Accuracy: 3115/5000 (62%)\n",
      "[epoch 12] loss: 0.7459944\n",
      "Test set: Average loss: 1.1120, Accuracy: 3122/5000 (62%)\n",
      "[epoch 13] loss: 0.6904158\n",
      "Test set: Average loss: 1.1309, Accuracy: 3129/5000 (63%)\n",
      "[epoch 14] loss: 0.6284663\n",
      "Test set: Average loss: 1.1123, Accuracy: 3206/5000 (64%)\n",
      "[epoch 15] loss: 0.5581560\n",
      "Test set: Average loss: 1.1962, Accuracy: 3179/5000 (64%)\n",
      "[epoch 16] loss: 0.4942400\n",
      "Test set: Average loss: 1.1886, Accuracy: 3191/5000 (64%)\n",
      "[epoch 17] loss: 0.4160166\n",
      "Test set: Average loss: 1.2684, Accuracy: 3187/5000 (64%)\n",
      "[epoch 18] loss: 0.3404410\n",
      "Test set: Average loss: 1.3070, Accuracy: 3215/5000 (64%)\n",
      "[epoch 19] loss: 0.2615091\n",
      "Test set: Average loss: 1.4516, Accuracy: 3137/5000 (63%)\n",
      "[epoch 20] loss: 0.2101041\n",
      "Test set: Average loss: 1.4525, Accuracy: 3192/5000 (64%)\n",
      "[epoch 21] loss: 0.1729262\n",
      "Test set: Average loss: 1.6510, Accuracy: 3143/5000 (63%)\n",
      "[epoch 22] loss: 0.1576965\n",
      "Test set: Average loss: 1.6545, Accuracy: 3136/5000 (63%)\n",
      "[epoch 23] loss: 0.1431727\n",
      "Test set: Average loss: 1.8407, Accuracy: 3030/5000 (61%)\n",
      "[epoch 24] loss: 0.1363507\n",
      "Test set: Average loss: 1.7841, Accuracy: 3156/5000 (63%)\n",
      "[epoch 25] loss: 0.1188873\n",
      "Test set: Average loss: 1.8493, Accuracy: 3152/5000 (63%)\n",
      "[epoch 26] loss: 0.1563352\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9104, Accuracy: 3169/5000 (63%)\n",
      "[epoch 27] loss: 0.0455601\n",
      "Test set: Average loss: 1.7982, Accuracy: 3235/5000 (65%)\n",
      "[epoch 28] loss: 0.0147994\n",
      "Test set: Average loss: 1.8086, Accuracy: 3269/5000 (65%)\n",
      "[epoch 29] loss: 0.0093486\n",
      "Test set: Average loss: 1.8151, Accuracy: 3280/5000 (66%)\n",
      "[epoch 30] loss: 0.0066206\n",
      "Test set: Average loss: 1.8308, Accuracy: 3281/5000 (66%)\n",
      "[epoch 31] loss: 0.0048274\n",
      "Test set: Average loss: 1.8486, Accuracy: 3284/5000 (66%)\n",
      "[epoch 32] loss: 0.0035514\n",
      "Test set: Average loss: 1.8709, Accuracy: 3286/5000 (66%)\n",
      "[epoch 33] loss: 0.0026216\n",
      "Test set: Average loss: 1.8993, Accuracy: 3281/5000 (66%)\n",
      "[epoch 34] loss: 0.0019125\n",
      "Test set: Average loss: 1.9276, Accuracy: 3297/5000 (66%)\n",
      "[epoch 35] loss: 0.0013804\n",
      "Test set: Average loss: 1.9626, Accuracy: 3292/5000 (66%)\n",
      "[epoch 36] loss: 0.0009882\n",
      "Test set: Average loss: 2.0031, Accuracy: 3299/5000 (66%)\n",
      "[epoch 37] loss: 0.0007003\n",
      "Test set: Average loss: 2.0459, Accuracy: 3294/5000 (66%)\n",
      "[epoch 38] loss: 0.0004903\n",
      "Test set: Average loss: 2.0884, Accuracy: 3297/5000 (66%)\n",
      "[epoch 39] loss: 0.0003422\n",
      "Test set: Average loss: 2.1421, Accuracy: 3301/5000 (66%)\n",
      "[epoch 40] loss: 0.0002360\n",
      "Test set: Average loss: 2.1823, Accuracy: 3309/5000 (66%)\n",
      "[epoch 41] loss: 0.0001629\n",
      "Test set: Average loss: 2.2346, Accuracy: 3307/5000 (66%)\n",
      "[epoch 42] loss: 0.0001118\n",
      "Test set: Average loss: 2.2948, Accuracy: 3315/5000 (66%)\n",
      "[epoch 43] loss: 0.0000763\n",
      "Test set: Average loss: 2.3458, Accuracy: 3328/5000 (67%)\n",
      "[epoch 44] loss: 0.0000516\n",
      "Test set: Average loss: 2.4071, Accuracy: 3331/5000 (67%)\n",
      "[epoch 45] loss: 0.0000349\n",
      "Test set: Average loss: 2.4690, Accuracy: 3321/5000 (66%)\n",
      "[epoch 46] loss: 0.0000236\n",
      "Test set: Average loss: 2.5217, Accuracy: 3317/5000 (66%)\n",
      "[epoch 47] loss: 0.0000158\n",
      "Test set: Average loss: 2.5918, Accuracy: 3322/5000 (66%)\n",
      "[epoch 48] loss: 0.0000106\n",
      "Test set: Average loss: 2.6486, Accuracy: 3321/5000 (66%)\n",
      "[epoch 49] loss: 0.0000071\n",
      "Test set: Average loss: 2.7172, Accuracy: 3322/5000 (66%)\n",
      "[epoch 50] loss: 0.0000047\n",
      "Test set: Average loss: 2.7710, Accuracy: 3323/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4071, Accuracy: 3331/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.4182, Accuracy: 6662/10000 (67%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3049, Accuracy: 421/5000 (8%)\n",
      "[epoch 1] loss: 1.3314369\n",
      "Test set: Average loss: 1.2179, Accuracy: 2860/5000 (57%)\n",
      "[epoch 2] loss: 1.1476219\n",
      "Test set: Average loss: 1.1734, Accuracy: 2935/5000 (59%)\n",
      "[epoch 3] loss: 1.0835030\n",
      "Test set: Average loss: 1.1289, Accuracy: 3045/5000 (61%)\n",
      "[epoch 4] loss: 1.0463915\n",
      "Test set: Average loss: 1.0921, Accuracy: 3068/5000 (61%)\n",
      "[epoch 5] loss: 1.0061470\n",
      "Test set: Average loss: 1.0862, Accuracy: 3112/5000 (62%)\n",
      "[epoch 6] loss: 0.9672500\n",
      "Test set: Average loss: 1.0691, Accuracy: 3122/5000 (62%)\n",
      "[epoch 7] loss: 0.9257726\n",
      "Test set: Average loss: 1.0689, Accuracy: 3149/5000 (63%)\n",
      "[epoch 8] loss: 0.8852606\n",
      "Test set: Average loss: 1.0722, Accuracy: 3114/5000 (62%)\n",
      "[epoch 9] loss: 0.8450938\n",
      "Test set: Average loss: 1.0469, Accuracy: 3200/5000 (64%)\n",
      "[epoch 10] loss: 0.8080272\n",
      "Test set: Average loss: 1.0425, Accuracy: 3244/5000 (65%)\n",
      "[epoch 11] loss: 0.7694589\n",
      "Test set: Average loss: 1.0261, Accuracy: 3246/5000 (65%)\n",
      "[epoch 12] loss: 0.7151165\n",
      "Test set: Average loss: 1.0987, Accuracy: 3218/5000 (64%)\n",
      "[epoch 13] loss: 0.6559495\n",
      "Test set: Average loss: 1.0505, Accuracy: 3293/5000 (66%)\n",
      "[epoch 14] loss: 0.5954947\n",
      "Test set: Average loss: 1.1220, Accuracy: 3243/5000 (65%)\n",
      "[epoch 15] loss: 0.5249704\n",
      "Test set: Average loss: 1.1151, Accuracy: 3285/5000 (66%)\n",
      "[epoch 16] loss: 0.4515924\n",
      "Test set: Average loss: 1.1694, Accuracy: 3255/5000 (65%)\n",
      "[epoch 17] loss: 0.3654354\n",
      "Test set: Average loss: 1.2101, Accuracy: 3261/5000 (65%)\n",
      "[epoch 18] loss: 0.3038566\n",
      "Test set: Average loss: 1.2991, Accuracy: 3284/5000 (66%)\n",
      "[epoch 19] loss: 0.2439360\n",
      "Test set: Average loss: 1.4220, Accuracy: 3229/5000 (65%)\n",
      "[epoch 20] loss: 0.2053555\n",
      "Test set: Average loss: 1.4663, Accuracy: 3246/5000 (65%)\n",
      "[epoch 21] loss: 0.1872867\n",
      "Test set: Average loss: 1.5525, Accuracy: 3262/5000 (65%)\n",
      "[epoch 22] loss: 0.1519928\n",
      "Test set: Average loss: 1.6123, Accuracy: 3261/5000 (65%)\n",
      "[epoch 23] loss: 0.1608113\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7122, Accuracy: 3210/5000 (64%)\n",
      "[epoch 24] loss: 0.0673341\n",
      "Test set: Average loss: 1.5503, Accuracy: 3343/5000 (67%)\n",
      "[epoch 25] loss: 0.0226126\n",
      "Test set: Average loss: 1.5707, Accuracy: 3352/5000 (67%)\n",
      "[epoch 26] loss: 0.0136268\n",
      "Test set: Average loss: 1.5926, Accuracy: 3371/5000 (67%)\n",
      "[epoch 27] loss: 0.0092920\n",
      "Test set: Average loss: 1.6219, Accuracy: 3372/5000 (67%)\n",
      "[epoch 28] loss: 0.0064949\n",
      "Test set: Average loss: 1.6502, Accuracy: 3378/5000 (68%)\n",
      "[epoch 29] loss: 0.0045591\n",
      "Test set: Average loss: 1.6825, Accuracy: 3382/5000 (68%)\n",
      "[epoch 30] loss: 0.0031842\n",
      "Test set: Average loss: 1.7203, Accuracy: 3400/5000 (68%)\n",
      "[epoch 31] loss: 0.0021939\n",
      "Test set: Average loss: 1.7663, Accuracy: 3404/5000 (68%)\n",
      "[epoch 32] loss: 0.0015086\n",
      "Test set: Average loss: 1.8150, Accuracy: 3399/5000 (68%)\n",
      "[epoch 33] loss: 0.0010197\n",
      "Test set: Average loss: 1.8659, Accuracy: 3399/5000 (68%)\n",
      "[epoch 34] loss: 0.0006844\n",
      "Test set: Average loss: 1.9231, Accuracy: 3399/5000 (68%)\n",
      "[epoch 35] loss: 0.0004571\n",
      "Test set: Average loss: 1.9765, Accuracy: 3393/5000 (68%)\n",
      "[epoch 36] loss: 0.0003039\n",
      "Test set: Average loss: 2.0300, Accuracy: 3392/5000 (68%)\n",
      "[epoch 37] loss: 0.0001983\n",
      "Test set: Average loss: 2.1068, Accuracy: 3395/5000 (68%)\n",
      "[epoch 38] loss: 0.0001309\n",
      "Test set: Average loss: 2.1628, Accuracy: 3395/5000 (68%)\n",
      "[epoch 39] loss: 0.0000853\n",
      "Test set: Average loss: 2.2317, Accuracy: 3392/5000 (68%)\n",
      "[epoch 40] loss: 0.0000548\n",
      "Test set: Average loss: 2.2988, Accuracy: 3389/5000 (68%)\n",
      "[epoch 41] loss: 0.0000352\n",
      "Test set: Average loss: 2.3572, Accuracy: 3394/5000 (68%)\n",
      "[epoch 42] loss: 0.0000227\n",
      "Test set: Average loss: 2.4262, Accuracy: 3395/5000 (68%)\n",
      "[epoch 43] loss: 0.0000145\n",
      "Test set: Average loss: 2.5029, Accuracy: 3388/5000 (68%)\n",
      "[epoch 44] loss: 0.0000092\n",
      "Test set: Average loss: 2.5708, Accuracy: 3396/5000 (68%)\n",
      "[epoch 45] loss: 0.0000058\n",
      "Test set: Average loss: 2.6294, Accuracy: 3383/5000 (68%)\n",
      "[epoch 46] loss: 0.0000037\n",
      "Test set: Average loss: 2.7003, Accuracy: 3393/5000 (68%)\n",
      "[epoch 47] loss: 0.0000023\n",
      "Test set: Average loss: 2.7729, Accuracy: 3384/5000 (68%)\n",
      "[epoch 48] loss: 0.0000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.8316, Accuracy: 3384/5000 (68%)\n",
      "[epoch 49] loss: 0.0000009\n",
      "Test set: Average loss: 2.8787, Accuracy: 3387/5000 (68%)\n",
      "[epoch 50] loss: 0.0000006\n",
      "Test set: Average loss: 2.9215, Accuracy: 3379/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7663, Accuracy: 3404/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.7702, Accuracy: 6758/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3046, Accuracy: 354/5000 (7%)\n",
      "[epoch 1] loss: 1.3147328\n",
      "Test set: Average loss: 1.2534, Accuracy: 2711/5000 (54%)\n",
      "[epoch 2] loss: 1.1467396\n",
      "Test set: Average loss: 1.1362, Accuracy: 2966/5000 (59%)\n",
      "[epoch 3] loss: 1.0892227\n",
      "Test set: Average loss: 1.2003, Accuracy: 2934/5000 (59%)\n",
      "[epoch 4] loss: 1.0426340\n",
      "Test set: Average loss: 1.1406, Accuracy: 2987/5000 (60%)\n",
      "[epoch 5] loss: 0.9996174\n",
      "Test set: Average loss: 1.1568, Accuracy: 3000/5000 (60%)\n",
      "[epoch 6] loss: 0.9708641\n",
      "Test set: Average loss: 1.0634, Accuracy: 3191/5000 (64%)\n",
      "[epoch 7] loss: 0.9260560\n",
      "Test set: Average loss: 1.1471, Accuracy: 3080/5000 (62%)\n",
      "[epoch 8] loss: 0.8916110\n",
      "Test set: Average loss: 1.0853, Accuracy: 3109/5000 (62%)\n",
      "[epoch 9] loss: 0.8506852\n",
      "Test set: Average loss: 1.0728, Accuracy: 3188/5000 (64%)\n",
      "[epoch 10] loss: 0.8139115\n",
      "Test set: Average loss: 1.0953, Accuracy: 3211/5000 (64%)\n",
      "[epoch 11] loss: 0.7646520\n",
      "Test set: Average loss: 1.1044, Accuracy: 3224/5000 (64%)\n",
      "[epoch 12] loss: 0.7184997\n",
      "Test set: Average loss: 1.1122, Accuracy: 3210/5000 (64%)\n",
      "[epoch 13] loss: 0.6627023\n",
      "Test set: Average loss: 1.0803, Accuracy: 3280/5000 (66%)\n",
      "[epoch 14] loss: 0.5890041\n",
      "Test set: Average loss: 1.1114, Accuracy: 3285/5000 (66%)\n",
      "[epoch 15] loss: 0.5239533\n",
      "Test set: Average loss: 1.2303, Accuracy: 3197/5000 (64%)\n",
      "[epoch 16] loss: 0.4436526\n",
      "Test set: Average loss: 1.2053, Accuracy: 3207/5000 (64%)\n",
      "[epoch 17] loss: 0.3679918\n",
      "Test set: Average loss: 1.2477, Accuracy: 3274/5000 (65%)\n",
      "[epoch 18] loss: 0.2977001\n",
      "Test set: Average loss: 1.3751, Accuracy: 3158/5000 (63%)\n",
      "[epoch 19] loss: 0.2452993\n",
      "Test set: Average loss: 1.4959, Accuracy: 3233/5000 (65%)\n",
      "[epoch 20] loss: 0.1957374\n",
      "Test set: Average loss: 1.5105, Accuracy: 3251/5000 (65%)\n",
      "[epoch 21] loss: 0.1901637\n",
      "Test set: Average loss: 1.6289, Accuracy: 3175/5000 (64%)\n",
      "[epoch 22] loss: 0.1714708\n",
      "Test set: Average loss: 1.7178, Accuracy: 3168/5000 (63%)\n",
      "[epoch 23] loss: 0.1440291\n",
      "Test set: Average loss: 1.7288, Accuracy: 3169/5000 (63%)\n",
      "[epoch 24] loss: 0.1490229\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8677, Accuracy: 3104/5000 (62%)\n",
      "[epoch 25] loss: 0.0519510\n",
      "Test set: Average loss: 1.6944, Accuracy: 3278/5000 (66%)\n",
      "[epoch 26] loss: 0.0175915\n",
      "Test set: Average loss: 1.7052, Accuracy: 3288/5000 (66%)\n",
      "[epoch 27] loss: 0.0106944\n",
      "Test set: Average loss: 1.7251, Accuracy: 3301/5000 (66%)\n",
      "[epoch 28] loss: 0.0073011\n",
      "Test set: Average loss: 1.7493, Accuracy: 3318/5000 (66%)\n",
      "[epoch 29] loss: 0.0051551\n",
      "Test set: Average loss: 1.7739, Accuracy: 3334/5000 (67%)\n",
      "[epoch 30] loss: 0.0036467\n",
      "Test set: Average loss: 1.8097, Accuracy: 3334/5000 (67%)\n",
      "[epoch 31] loss: 0.0025299\n",
      "Test set: Average loss: 1.8494, Accuracy: 3339/5000 (67%)\n",
      "[epoch 32] loss: 0.0017566\n",
      "Test set: Average loss: 1.8976, Accuracy: 3341/5000 (67%)\n",
      "[epoch 33] loss: 0.0011984\n",
      "Test set: Average loss: 1.9424, Accuracy: 3345/5000 (67%)\n",
      "[epoch 34] loss: 0.0008104\n",
      "Test set: Average loss: 1.9928, Accuracy: 3345/5000 (67%)\n",
      "[epoch 35] loss: 0.0005405\n",
      "Test set: Average loss: 2.0466, Accuracy: 3353/5000 (67%)\n",
      "[epoch 36] loss: 0.0003616\n",
      "Test set: Average loss: 2.1062, Accuracy: 3337/5000 (67%)\n",
      "[epoch 37] loss: 0.0002384\n",
      "Test set: Average loss: 2.1622, Accuracy: 3339/5000 (67%)\n",
      "[epoch 38] loss: 0.0001561\n",
      "Test set: Average loss: 2.2270, Accuracy: 3341/5000 (67%)\n",
      "[epoch 39] loss: 0.0001014\n",
      "Test set: Average loss: 2.2872, Accuracy: 3340/5000 (67%)\n",
      "[epoch 40] loss: 0.0000661\n",
      "Test set: Average loss: 2.3558, Accuracy: 3344/5000 (67%)\n",
      "[epoch 41] loss: 0.0000426\n",
      "Test set: Average loss: 2.4228, Accuracy: 3342/5000 (67%)\n",
      "[epoch 42] loss: 0.0000274\n",
      "Test set: Average loss: 2.4863, Accuracy: 3340/5000 (67%)\n",
      "[epoch 43] loss: 0.0000175\n",
      "Test set: Average loss: 2.5629, Accuracy: 3337/5000 (67%)\n",
      "[epoch 44] loss: 0.0000112\n",
      "Test set: Average loss: 2.6231, Accuracy: 3343/5000 (67%)\n",
      "[epoch 45] loss: 0.0000071\n",
      "Test set: Average loss: 2.7021, Accuracy: 3347/5000 (67%)\n",
      "[epoch 46] loss: 0.0000045\n",
      "Test set: Average loss: 2.7789, Accuracy: 3338/5000 (67%)\n",
      "[epoch 47] loss: 0.0000028\n",
      "Test set: Average loss: 2.8457, Accuracy: 3336/5000 (67%)\n",
      "[epoch 48] loss: 0.0000018\n",
      "Test set: Average loss: 2.8997, Accuracy: 3330/5000 (67%)\n",
      "[epoch 49] loss: 0.0000011\n",
      "Test set: Average loss: 2.9659, Accuracy: 3335/5000 (67%)\n",
      "[epoch 50] loss: 0.0000007\n",
      "Test set: Average loss: 3.0127, Accuracy: 3340/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0466, Accuracy: 3353/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.0239, Accuracy: 6679/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3047, Accuracy: 604/5000 (12%)\n",
      "[epoch 1] loss: 1.3274313\n",
      "Test set: Average loss: 1.2540, Accuracy: 2798/5000 (56%)\n",
      "[epoch 2] loss: 1.1449465\n",
      "Test set: Average loss: 1.2109, Accuracy: 2844/5000 (57%)\n",
      "[epoch 3] loss: 1.0783324\n",
      "Test set: Average loss: 1.1358, Accuracy: 3016/5000 (60%)\n",
      "[epoch 4] loss: 1.0404373\n",
      "Test set: Average loss: 1.0918, Accuracy: 3108/5000 (62%)\n",
      "[epoch 5] loss: 0.9961138\n",
      "Test set: Average loss: 1.1339, Accuracy: 3042/5000 (61%)\n",
      "[epoch 6] loss: 0.9639703\n",
      "Test set: Average loss: 1.0979, Accuracy: 3033/5000 (61%)\n",
      "[epoch 7] loss: 0.9226189\n",
      "Test set: Average loss: 1.0752, Accuracy: 3110/5000 (62%)\n",
      "[epoch 8] loss: 0.8885650\n",
      "Test set: Average loss: 1.0347, Accuracy: 3190/5000 (64%)\n",
      "[epoch 9] loss: 0.8492153\n",
      "Test set: Average loss: 1.0579, Accuracy: 3165/5000 (63%)\n",
      "[epoch 10] loss: 0.8107812\n",
      "Test set: Average loss: 1.1081, Accuracy: 3047/5000 (61%)\n",
      "[epoch 11] loss: 0.7676558\n",
      "Test set: Average loss: 1.0780, Accuracy: 3193/5000 (64%)\n",
      "[epoch 12] loss: 0.7152751\n",
      "Test set: Average loss: 1.0691, Accuracy: 3240/5000 (65%)\n",
      "[epoch 13] loss: 0.6533056\n",
      "Test set: Average loss: 1.0609, Accuracy: 3280/5000 (66%)\n",
      "[epoch 14] loss: 0.5852746\n",
      "Test set: Average loss: 1.1183, Accuracy: 3244/5000 (65%)\n",
      "[epoch 15] loss: 0.5226991\n",
      "Test set: Average loss: 1.1392, Accuracy: 3254/5000 (65%)\n",
      "[epoch 16] loss: 0.4350918\n",
      "Test set: Average loss: 1.2335, Accuracy: 3211/5000 (64%)\n",
      "[epoch 17] loss: 0.3660480\n",
      "Test set: Average loss: 1.2320, Accuracy: 3277/5000 (66%)\n",
      "[epoch 18] loss: 0.2896917\n",
      "Test set: Average loss: 1.3708, Accuracy: 3238/5000 (65%)\n",
      "[epoch 19] loss: 0.2381003\n",
      "Test set: Average loss: 1.4398, Accuracy: 3191/5000 (64%)\n",
      "[epoch 20] loss: 0.1987206\n",
      "Test set: Average loss: 1.5311, Accuracy: 3180/5000 (64%)\n",
      "[epoch 21] loss: 0.1673715\n",
      "Test set: Average loss: 1.6399, Accuracy: 3197/5000 (64%)\n",
      "[epoch 22] loss: 0.1589921\n",
      "Test set: Average loss: 1.6938, Accuracy: 3185/5000 (64%)\n",
      "[epoch 23] loss: 0.1642274\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8301, Accuracy: 3097/5000 (62%)\n",
      "[epoch 24] loss: 0.0590929\n",
      "Test set: Average loss: 1.6423, Accuracy: 3276/5000 (66%)\n",
      "[epoch 25] loss: 0.0202199\n",
      "Test set: Average loss: 1.6492, Accuracy: 3286/5000 (66%)\n",
      "[epoch 26] loss: 0.0123151\n",
      "Test set: Average loss: 1.6690, Accuracy: 3292/5000 (66%)\n",
      "[epoch 27] loss: 0.0084818\n",
      "Test set: Average loss: 1.6987, Accuracy: 3302/5000 (66%)\n",
      "[epoch 28] loss: 0.0059890\n",
      "Test set: Average loss: 1.7203, Accuracy: 3301/5000 (66%)\n",
      "[epoch 29] loss: 0.0042136\n",
      "Test set: Average loss: 1.7605, Accuracy: 3306/5000 (66%)\n",
      "[epoch 30] loss: 0.0029471\n",
      "Test set: Average loss: 1.8026, Accuracy: 3307/5000 (66%)\n",
      "[epoch 31] loss: 0.0020331\n",
      "Test set: Average loss: 1.8531, Accuracy: 3317/5000 (66%)\n",
      "[epoch 32] loss: 0.0013898\n",
      "Test set: Average loss: 1.8998, Accuracy: 3324/5000 (66%)\n",
      "[epoch 33] loss: 0.0009341\n",
      "Test set: Average loss: 1.9570, Accuracy: 3327/5000 (67%)\n",
      "[epoch 34] loss: 0.0006291\n",
      "Test set: Average loss: 2.0073, Accuracy: 3330/5000 (67%)\n",
      "[epoch 35] loss: 0.0004172\n",
      "Test set: Average loss: 2.0731, Accuracy: 3329/5000 (67%)\n",
      "[epoch 36] loss: 0.0002744\n",
      "Test set: Average loss: 2.1369, Accuracy: 3330/5000 (67%)\n",
      "[epoch 37] loss: 0.0001802\n",
      "Test set: Average loss: 2.2041, Accuracy: 3330/5000 (67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 38] loss: 0.0001179\n",
      "Test set: Average loss: 2.2754, Accuracy: 3326/5000 (67%)\n",
      "[epoch 39] loss: 0.0000766\n",
      "Test set: Average loss: 2.3350, Accuracy: 3330/5000 (67%)\n",
      "[epoch 40] loss: 0.0000492\n",
      "Test set: Average loss: 2.4147, Accuracy: 3325/5000 (66%)\n",
      "[epoch 41] loss: 0.0000318\n",
      "Test set: Average loss: 2.4813, Accuracy: 3315/5000 (66%)\n",
      "[epoch 42] loss: 0.0000202\n",
      "Test set: Average loss: 2.5515, Accuracy: 3327/5000 (67%)\n",
      "[epoch 43] loss: 0.0000129\n",
      "Test set: Average loss: 2.6335, Accuracy: 3309/5000 (66%)\n",
      "[epoch 44] loss: 0.0000082\n",
      "Test set: Average loss: 2.7002, Accuracy: 3321/5000 (66%)\n",
      "[epoch 45] loss: 0.0000052\n",
      "Test set: Average loss: 2.7697, Accuracy: 3319/5000 (66%)\n",
      "[epoch 46] loss: 0.0000033\n",
      "Test set: Average loss: 2.8440, Accuracy: 3322/5000 (66%)\n",
      "[epoch 47] loss: 0.0000021\n",
      "Test set: Average loss: 2.9140, Accuracy: 3313/5000 (66%)\n",
      "[epoch 48] loss: 0.0000013\n",
      "Test set: Average loss: 2.9811, Accuracy: 3306/5000 (66%)\n",
      "[epoch 49] loss: 0.0000008\n",
      "Test set: Average loss: 3.0355, Accuracy: 3317/5000 (66%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 3.0607, Accuracy: 3306/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3350, Accuracy: 3330/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.2458, Accuracy: 6765/10000 (68%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3022, Accuracy: 663/5000 (13%)\n",
      "[epoch 1] loss: 1.3037218\n",
      "Test set: Average loss: 1.2362, Accuracy: 2833/5000 (57%)\n",
      "[epoch 2] loss: 1.1225512\n",
      "Test set: Average loss: 1.1364, Accuracy: 2992/5000 (60%)\n",
      "[epoch 3] loss: 1.0666019\n",
      "Test set: Average loss: 1.1305, Accuracy: 2993/5000 (60%)\n",
      "[epoch 4] loss: 1.0192357\n",
      "Test set: Average loss: 1.0773, Accuracy: 3132/5000 (63%)\n",
      "[epoch 5] loss: 0.9802078\n",
      "Test set: Average loss: 1.1398, Accuracy: 2953/5000 (59%)\n",
      "[epoch 6] loss: 0.9404558\n",
      "Test set: Average loss: 1.0898, Accuracy: 3132/5000 (63%)\n",
      "[epoch 7] loss: 0.9028176\n",
      "Test set: Average loss: 1.0721, Accuracy: 3157/5000 (63%)\n",
      "[epoch 8] loss: 0.8630276\n",
      "Test set: Average loss: 1.0874, Accuracy: 3128/5000 (63%)\n",
      "[epoch 9] loss: 0.8270758\n",
      "Test set: Average loss: 0.9999, Accuracy: 3271/5000 (65%)\n",
      "[epoch 10] loss: 0.7830346\n",
      "Test set: Average loss: 1.0038, Accuracy: 3287/5000 (66%)\n",
      "[epoch 11] loss: 0.7323761\n",
      "Test set: Average loss: 1.0097, Accuracy: 3293/5000 (66%)\n",
      "[epoch 12] loss: 0.6769250\n",
      "Test set: Average loss: 1.0027, Accuracy: 3347/5000 (67%)\n",
      "[epoch 13] loss: 0.6166970\n",
      "Test set: Average loss: 1.0502, Accuracy: 3317/5000 (66%)\n",
      "[epoch 14] loss: 0.5469982\n",
      "Test set: Average loss: 1.0825, Accuracy: 3324/5000 (66%)\n",
      "[epoch 15] loss: 0.4669027\n",
      "Test set: Average loss: 1.1257, Accuracy: 3338/5000 (67%)\n",
      "[epoch 16] loss: 0.4000778\n",
      "Test set: Average loss: 1.2086, Accuracy: 3310/5000 (66%)\n",
      "[epoch 17] loss: 0.3237877\n",
      "Test set: Average loss: 1.3081, Accuracy: 3228/5000 (65%)\n",
      "[epoch 18] loss: 0.2777911\n",
      "Test set: Average loss: 1.3759, Accuracy: 3249/5000 (65%)\n",
      "[epoch 19] loss: 0.2325355\n",
      "Test set: Average loss: 1.4739, Accuracy: 3255/5000 (65%)\n",
      "[epoch 20] loss: 0.2191705\n",
      "Test set: Average loss: 1.5044, Accuracy: 3225/5000 (64%)\n",
      "[epoch 21] loss: 0.1865358\n",
      "Test set: Average loss: 1.6179, Accuracy: 3225/5000 (64%)\n",
      "[epoch 22] loss: 0.1728271\n",
      "Test set: Average loss: 1.6576, Accuracy: 3249/5000 (65%)\n",
      "[epoch 23] loss: 0.1693591\n",
      "Test set: Average loss: 1.7349, Accuracy: 3207/5000 (64%)\n",
      "[epoch 24] loss: 0.1533692\n",
      "Test set: Average loss: 1.8354, Accuracy: 3179/5000 (64%)\n",
      "[epoch 25] loss: 0.1670385\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7876, Accuracy: 3226/5000 (65%)\n",
      "[epoch 26] loss: 0.0514002\n",
      "Test set: Average loss: 1.7027, Accuracy: 3304/5000 (66%)\n",
      "[epoch 27] loss: 0.0170618\n",
      "Test set: Average loss: 1.7165, Accuracy: 3318/5000 (66%)\n",
      "[epoch 28] loss: 0.0099584\n",
      "Test set: Average loss: 1.7444, Accuracy: 3337/5000 (67%)\n",
      "[epoch 29] loss: 0.0065578\n",
      "Test set: Average loss: 1.7691, Accuracy: 3348/5000 (67%)\n",
      "[epoch 30] loss: 0.0044794\n",
      "Test set: Average loss: 1.8060, Accuracy: 3360/5000 (67%)\n",
      "[epoch 31] loss: 0.0030234\n",
      "Test set: Average loss: 1.8443, Accuracy: 3352/5000 (67%)\n",
      "[epoch 32] loss: 0.0019956\n",
      "Test set: Average loss: 1.8869, Accuracy: 3378/5000 (68%)\n",
      "[epoch 33] loss: 0.0013144\n",
      "Test set: Average loss: 1.9384, Accuracy: 3362/5000 (67%)\n",
      "[epoch 34] loss: 0.0008495\n",
      "Test set: Average loss: 2.0003, Accuracy: 3370/5000 (67%)\n",
      "[epoch 35] loss: 0.0005456\n",
      "Test set: Average loss: 2.0582, Accuracy: 3371/5000 (67%)\n",
      "[epoch 36] loss: 0.0003451\n",
      "Test set: Average loss: 2.1176, Accuracy: 3379/5000 (68%)\n",
      "[epoch 37] loss: 0.0002196\n",
      "Test set: Average loss: 2.1844, Accuracy: 3374/5000 (67%)\n",
      "[epoch 38] loss: 0.0001371\n",
      "Test set: Average loss: 2.2476, Accuracy: 3382/5000 (68%)\n",
      "[epoch 39] loss: 0.0000854\n",
      "Test set: Average loss: 2.3199, Accuracy: 3383/5000 (68%)\n",
      "[epoch 40] loss: 0.0000530\n",
      "Test set: Average loss: 2.3963, Accuracy: 3387/5000 (68%)\n",
      "[epoch 41] loss: 0.0000325\n",
      "Test set: Average loss: 2.4613, Accuracy: 3384/5000 (68%)\n",
      "[epoch 42] loss: 0.0000200\n",
      "Test set: Average loss: 2.5429, Accuracy: 3379/5000 (68%)\n",
      "[epoch 43] loss: 0.0000122\n",
      "Test set: Average loss: 2.6168, Accuracy: 3376/5000 (68%)\n",
      "[epoch 44] loss: 0.0000074\n",
      "Test set: Average loss: 2.6952, Accuracy: 3374/5000 (67%)\n",
      "[epoch 45] loss: 0.0000045\n",
      "Test set: Average loss: 2.7618, Accuracy: 3383/5000 (68%)\n",
      "[epoch 46] loss: 0.0000027\n",
      "Test set: Average loss: 2.8420, Accuracy: 3375/5000 (68%)\n",
      "[epoch 47] loss: 0.0000016\n",
      "Test set: Average loss: 2.9105, Accuracy: 3370/5000 (67%)\n",
      "[epoch 48] loss: 0.0000010\n",
      "Test set: Average loss: 2.9723, Accuracy: 3376/5000 (68%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 3.0199, Accuracy: 3359/5000 (67%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.0402, Accuracy: 3363/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3963, Accuracy: 3387/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.3037, Accuracy: 6766/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 625/5000 (12%)\n",
      "[epoch 1] loss: 1.2998745\n",
      "Test set: Average loss: 1.2340, Accuracy: 2794/5000 (56%)\n",
      "[epoch 2] loss: 1.1328574\n",
      "Test set: Average loss: 1.1686, Accuracy: 2941/5000 (59%)\n",
      "[epoch 3] loss: 1.0720547\n",
      "Test set: Average loss: 1.1205, Accuracy: 3009/5000 (60%)\n",
      "[epoch 4] loss: 1.0299791\n",
      "Test set: Average loss: 1.0761, Accuracy: 3109/5000 (62%)\n",
      "[epoch 5] loss: 0.9927946\n",
      "Test set: Average loss: 1.1255, Accuracy: 3022/5000 (60%)\n",
      "[epoch 6] loss: 0.9540388\n",
      "Test set: Average loss: 1.0875, Accuracy: 3109/5000 (62%)\n",
      "[epoch 7] loss: 0.9075776\n",
      "Test set: Average loss: 1.0446, Accuracy: 3200/5000 (64%)\n",
      "[epoch 8] loss: 0.8723417\n",
      "Test set: Average loss: 1.0246, Accuracy: 3218/5000 (64%)\n",
      "[epoch 9] loss: 0.8348458\n",
      "Test set: Average loss: 1.0256, Accuracy: 3246/5000 (65%)\n",
      "[epoch 10] loss: 0.7878907\n",
      "Test set: Average loss: 1.0270, Accuracy: 3254/5000 (65%)\n",
      "[epoch 11] loss: 0.7465014\n",
      "Test set: Average loss: 0.9998, Accuracy: 3316/5000 (66%)\n",
      "[epoch 12] loss: 0.6863362\n",
      "Test set: Average loss: 1.0140, Accuracy: 3317/5000 (66%)\n",
      "[epoch 13] loss: 0.6245369\n",
      "Test set: Average loss: 1.0372, Accuracy: 3309/5000 (66%)\n",
      "[epoch 14] loss: 0.5577758\n",
      "Test set: Average loss: 1.0745, Accuracy: 3346/5000 (67%)\n",
      "[epoch 15] loss: 0.4877678\n",
      "Test set: Average loss: 1.1045, Accuracy: 3294/5000 (66%)\n",
      "[epoch 16] loss: 0.4150121\n",
      "Test set: Average loss: 1.1364, Accuracy: 3317/5000 (66%)\n",
      "[epoch 17] loss: 0.3433291\n",
      "Test set: Average loss: 1.3196, Accuracy: 3246/5000 (65%)\n",
      "[epoch 18] loss: 0.2885337\n",
      "Test set: Average loss: 1.3316, Accuracy: 3257/5000 (65%)\n",
      "[epoch 19] loss: 0.2477755\n",
      "Test set: Average loss: 1.4613, Accuracy: 3232/5000 (65%)\n",
      "[epoch 20] loss: 0.2047135\n",
      "Test set: Average loss: 1.5285, Accuracy: 3232/5000 (65%)\n",
      "[epoch 21] loss: 0.1841408\n",
      "Test set: Average loss: 1.6003, Accuracy: 3210/5000 (64%)\n",
      "[epoch 22] loss: 0.1772155\n",
      "Test set: Average loss: 1.6761, Accuracy: 3181/5000 (64%)\n",
      "[epoch 23] loss: 0.1656896\n",
      "Test set: Average loss: 1.6745, Accuracy: 3232/5000 (65%)\n",
      "[epoch 24] loss: 0.1550816\n",
      "Test set: Average loss: 1.8762, Accuracy: 3155/5000 (63%)\n",
      "[epoch 25] loss: 0.1659104\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8602, Accuracy: 3176/5000 (64%)\n",
      "[epoch 26] loss: 0.0543975\n",
      "Test set: Average loss: 1.7184, Accuracy: 3293/5000 (66%)\n",
      "[epoch 27] loss: 0.0175897\n",
      "Test set: Average loss: 1.7324, Accuracy: 3300/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] loss: 0.0102378\n",
      "Test set: Average loss: 1.7568, Accuracy: 3314/5000 (66%)\n",
      "[epoch 29] loss: 0.0068296\n",
      "Test set: Average loss: 1.7781, Accuracy: 3321/5000 (66%)\n",
      "[epoch 30] loss: 0.0046266\n",
      "Test set: Average loss: 1.8035, Accuracy: 3330/5000 (67%)\n",
      "[epoch 31] loss: 0.0031058\n",
      "Test set: Average loss: 1.8452, Accuracy: 3335/5000 (67%)\n",
      "[epoch 32] loss: 0.0020624\n",
      "Test set: Average loss: 1.8975, Accuracy: 3350/5000 (67%)\n",
      "[epoch 33] loss: 0.0013601\n",
      "Test set: Average loss: 1.9368, Accuracy: 3331/5000 (67%)\n",
      "[epoch 34] loss: 0.0008839\n",
      "Test set: Average loss: 1.9917, Accuracy: 3344/5000 (67%)\n",
      "[epoch 35] loss: 0.0005637\n",
      "Test set: Average loss: 2.0512, Accuracy: 3341/5000 (67%)\n",
      "[epoch 36] loss: 0.0003626\n",
      "Test set: Average loss: 2.1084, Accuracy: 3347/5000 (67%)\n",
      "[epoch 37] loss: 0.0002298\n",
      "Test set: Average loss: 2.1700, Accuracy: 3334/5000 (67%)\n",
      "[epoch 38] loss: 0.0001452\n",
      "Test set: Average loss: 2.2301, Accuracy: 3345/5000 (67%)\n",
      "[epoch 39] loss: 0.0000894\n",
      "Test set: Average loss: 2.3012, Accuracy: 3346/5000 (67%)\n",
      "[epoch 40] loss: 0.0000560\n",
      "Test set: Average loss: 2.3691, Accuracy: 3352/5000 (67%)\n",
      "[epoch 41] loss: 0.0000344\n",
      "Test set: Average loss: 2.4423, Accuracy: 3360/5000 (67%)\n",
      "[epoch 42] loss: 0.0000212\n",
      "Test set: Average loss: 2.5149, Accuracy: 3359/5000 (67%)\n",
      "[epoch 43] loss: 0.0000129\n",
      "Test set: Average loss: 2.5920, Accuracy: 3339/5000 (67%)\n",
      "[epoch 44] loss: 0.0000079\n",
      "Test set: Average loss: 2.6601, Accuracy: 3350/5000 (67%)\n",
      "[epoch 45] loss: 0.0000048\n",
      "Test set: Average loss: 2.7350, Accuracy: 3343/5000 (67%)\n",
      "[epoch 46] loss: 0.0000029\n",
      "Test set: Average loss: 2.8076, Accuracy: 3345/5000 (67%)\n",
      "[epoch 47] loss: 0.0000017\n",
      "Test set: Average loss: 2.8746, Accuracy: 3350/5000 (67%)\n",
      "[epoch 48] loss: 0.0000010\n",
      "Test set: Average loss: 2.9415, Accuracy: 3344/5000 (67%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 2.9804, Accuracy: 3339/5000 (67%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 3.0030, Accuracy: 3346/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4423, Accuracy: 3360/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.3553, Accuracy: 6871/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 323/5000 (6%)\n",
      "[epoch 1] loss: 1.3045894\n",
      "Test set: Average loss: 1.2115, Accuracy: 2885/5000 (58%)\n",
      "[epoch 2] loss: 1.1290493\n",
      "Test set: Average loss: 1.1045, Accuracy: 3037/5000 (61%)\n",
      "[epoch 3] loss: 1.0664140\n",
      "Test set: Average loss: 1.1390, Accuracy: 2995/5000 (60%)\n",
      "[epoch 4] loss: 1.0262524\n",
      "Test set: Average loss: 1.1310, Accuracy: 3036/5000 (61%)\n",
      "[epoch 5] loss: 0.9798975\n",
      "Test set: Average loss: 1.0286, Accuracy: 3213/5000 (64%)\n",
      "[epoch 6] loss: 0.9447754\n",
      "Test set: Average loss: 1.0641, Accuracy: 3157/5000 (63%)\n",
      "[epoch 7] loss: 0.9043440\n",
      "Test set: Average loss: 1.0475, Accuracy: 3206/5000 (64%)\n",
      "[epoch 8] loss: 0.8718727\n",
      "Test set: Average loss: 1.0299, Accuracy: 3245/5000 (65%)\n",
      "[epoch 9] loss: 0.8332894\n",
      "Test set: Average loss: 1.0191, Accuracy: 3262/5000 (65%)\n",
      "[epoch 10] loss: 0.7871580\n",
      "Test set: Average loss: 1.0250, Accuracy: 3268/5000 (65%)\n",
      "[epoch 11] loss: 0.7405385\n",
      "Test set: Average loss: 1.0237, Accuracy: 3248/5000 (65%)\n",
      "[epoch 12] loss: 0.6827629\n",
      "Test set: Average loss: 1.0376, Accuracy: 3320/5000 (66%)\n",
      "[epoch 13] loss: 0.6214246\n",
      "Test set: Average loss: 1.1200, Accuracy: 3215/5000 (64%)\n",
      "[epoch 14] loss: 0.5556994\n",
      "Test set: Average loss: 1.1565, Accuracy: 3222/5000 (64%)\n",
      "[epoch 15] loss: 0.4838471\n",
      "Test set: Average loss: 1.1506, Accuracy: 3276/5000 (66%)\n",
      "[epoch 16] loss: 0.4085423\n",
      "Test set: Average loss: 1.1932, Accuracy: 3292/5000 (66%)\n",
      "[epoch 17] loss: 0.3353231\n",
      "Test set: Average loss: 1.2978, Accuracy: 3237/5000 (65%)\n",
      "[epoch 18] loss: 0.2804416\n",
      "Test set: Average loss: 1.3943, Accuracy: 3261/5000 (65%)\n",
      "[epoch 19] loss: 0.2312419\n",
      "Test set: Average loss: 1.5335, Accuracy: 3235/5000 (65%)\n",
      "[epoch 20] loss: 0.2193313\n",
      "Test set: Average loss: 1.4854, Accuracy: 3214/5000 (64%)\n",
      "[epoch 21] loss: 0.1734004\n",
      "Test set: Average loss: 1.6009, Accuracy: 3257/5000 (65%)\n",
      "[epoch 22] loss: 0.1747651\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6725, Accuracy: 3229/5000 (65%)\n",
      "[epoch 23] loss: 0.0611100\n",
      "Test set: Average loss: 1.5850, Accuracy: 3343/5000 (67%)\n",
      "[epoch 24] loss: 0.0234349\n",
      "Test set: Average loss: 1.5943, Accuracy: 3357/5000 (67%)\n",
      "[epoch 25] loss: 0.0142972\n",
      "Test set: Average loss: 1.6308, Accuracy: 3355/5000 (67%)\n",
      "[epoch 26] loss: 0.0095213\n",
      "Test set: Average loss: 1.6629, Accuracy: 3373/5000 (67%)\n",
      "[epoch 27] loss: 0.0064521\n",
      "Test set: Average loss: 1.7016, Accuracy: 3372/5000 (67%)\n",
      "[epoch 28] loss: 0.0043803\n",
      "Test set: Average loss: 1.7455, Accuracy: 3362/5000 (67%)\n",
      "[epoch 29] loss: 0.0029226\n",
      "Test set: Average loss: 1.7959, Accuracy: 3370/5000 (67%)\n",
      "[epoch 30] loss: 0.0019252\n",
      "Test set: Average loss: 1.8451, Accuracy: 3364/5000 (67%)\n",
      "[epoch 31] loss: 0.0012537\n",
      "Test set: Average loss: 1.9025, Accuracy: 3371/5000 (67%)\n",
      "[epoch 32] loss: 0.0008154\n",
      "Test set: Average loss: 1.9622, Accuracy: 3376/5000 (68%)\n",
      "[epoch 33] loss: 0.0005191\n",
      "Test set: Average loss: 2.0263, Accuracy: 3384/5000 (68%)\n",
      "[epoch 34] loss: 0.0003326\n",
      "Test set: Average loss: 2.0929, Accuracy: 3385/5000 (68%)\n",
      "[epoch 35] loss: 0.0002097\n",
      "Test set: Average loss: 2.1656, Accuracy: 3393/5000 (68%)\n",
      "[epoch 36] loss: 0.0001308\n",
      "Test set: Average loss: 2.2383, Accuracy: 3386/5000 (68%)\n",
      "[epoch 37] loss: 0.0000819\n",
      "Test set: Average loss: 2.3043, Accuracy: 3386/5000 (68%)\n",
      "[epoch 38] loss: 0.0000508\n",
      "Test set: Average loss: 2.3834, Accuracy: 3385/5000 (68%)\n",
      "[epoch 39] loss: 0.0000312\n",
      "Test set: Average loss: 2.4543, Accuracy: 3386/5000 (68%)\n",
      "[epoch 40] loss: 0.0000191\n",
      "Test set: Average loss: 2.5378, Accuracy: 3383/5000 (68%)\n",
      "[epoch 41] loss: 0.0000117\n",
      "Test set: Average loss: 2.6130, Accuracy: 3396/5000 (68%)\n",
      "[epoch 42] loss: 0.0000071\n",
      "Test set: Average loss: 2.7014, Accuracy: 3375/5000 (68%)\n",
      "[epoch 43] loss: 0.0000043\n",
      "Test set: Average loss: 2.7774, Accuracy: 3391/5000 (68%)\n",
      "[epoch 44] loss: 0.0000026\n",
      "Test set: Average loss: 2.8475, Accuracy: 3387/5000 (68%)\n",
      "[epoch 45] loss: 0.0000015\n",
      "Test set: Average loss: 2.9256, Accuracy: 3397/5000 (68%)\n",
      "[epoch 46] loss: 0.0000009\n",
      "Test set: Average loss: 2.9806, Accuracy: 3383/5000 (68%)\n",
      "[epoch 47] loss: 0.0000005\n",
      "Test set: Average loss: 3.0244, Accuracy: 3379/5000 (68%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 3.0353, Accuracy: 3386/5000 (68%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 3.0536, Accuracy: 3384/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0779, Accuracy: 3362/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9256, Accuracy: 3397/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.8615, Accuracy: 6810/10000 (68%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 404/5000 (8%)\n",
      "[epoch 1] loss: 1.2891990\n",
      "Test set: Average loss: 1.2777, Accuracy: 2719/5000 (54%)\n",
      "[epoch 2] loss: 1.1195662\n",
      "Test set: Average loss: 1.1109, Accuracy: 3031/5000 (61%)\n",
      "[epoch 3] loss: 1.0594925\n",
      "Test set: Average loss: 1.1573, Accuracy: 2950/5000 (59%)\n",
      "[epoch 4] loss: 1.0123114\n",
      "Test set: Average loss: 1.0819, Accuracy: 3091/5000 (62%)\n",
      "[epoch 5] loss: 0.9751096\n",
      "Test set: Average loss: 1.1483, Accuracy: 3006/5000 (60%)\n",
      "[epoch 6] loss: 0.9316617\n",
      "Test set: Average loss: 1.0282, Accuracy: 3214/5000 (64%)\n",
      "[epoch 7] loss: 0.8933604\n",
      "Test set: Average loss: 1.0504, Accuracy: 3164/5000 (63%)\n",
      "[epoch 8] loss: 0.8528583\n",
      "Test set: Average loss: 1.0163, Accuracy: 3229/5000 (65%)\n",
      "[epoch 9] loss: 0.8160123\n",
      "Test set: Average loss: 1.0965, Accuracy: 3173/5000 (63%)\n",
      "[epoch 10] loss: 0.7679543\n",
      "Test set: Average loss: 1.0282, Accuracy: 3248/5000 (65%)\n",
      "[epoch 11] loss: 0.7178202\n",
      "Test set: Average loss: 1.0341, Accuracy: 3243/5000 (65%)\n",
      "[epoch 12] loss: 0.6541265\n",
      "Test set: Average loss: 1.0760, Accuracy: 3296/5000 (66%)\n",
      "[epoch 13] loss: 0.5937654\n",
      "Test set: Average loss: 1.1088, Accuracy: 3270/5000 (65%)\n",
      "[epoch 14] loss: 0.5334560\n",
      "Test set: Average loss: 1.0988, Accuracy: 3303/5000 (66%)\n",
      "[epoch 15] loss: 0.4567343\n",
      "Test set: Average loss: 1.1731, Accuracy: 3267/5000 (65%)\n",
      "[epoch 16] loss: 0.3996051\n",
      "Test set: Average loss: 1.2592, Accuracy: 3267/5000 (65%)\n",
      "[epoch 17] loss: 0.3340760\n",
      "Test set: Average loss: 1.3797, Accuracy: 3220/5000 (64%)\n",
      "[epoch 18] loss: 0.2936223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4307, Accuracy: 3259/5000 (65%)\n",
      "[epoch 19] loss: 0.2465054\n",
      "Test set: Average loss: 1.4147, Accuracy: 3259/5000 (65%)\n",
      "[epoch 20] loss: 0.2250004\n",
      "Test set: Average loss: 1.5296, Accuracy: 3273/5000 (65%)\n",
      "[epoch 21] loss: 0.2164890\n",
      "Test set: Average loss: 1.5952, Accuracy: 3232/5000 (65%)\n",
      "[epoch 22] loss: 0.2048990\n",
      "Test set: Average loss: 1.5983, Accuracy: 3252/5000 (65%)\n",
      "[epoch 23] loss: 0.1827957\n",
      "Test set: Average loss: 1.7176, Accuracy: 3250/5000 (65%)\n",
      "[epoch 24] loss: 0.1838864\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7225, Accuracy: 3211/5000 (64%)\n",
      "[epoch 25] loss: 0.0660674\n",
      "Test set: Average loss: 1.6362, Accuracy: 3340/5000 (67%)\n",
      "[epoch 26] loss: 0.0232534\n",
      "Test set: Average loss: 1.6519, Accuracy: 3322/5000 (66%)\n",
      "[epoch 27] loss: 0.0132852\n",
      "Test set: Average loss: 1.6866, Accuracy: 3357/5000 (67%)\n",
      "[epoch 28] loss: 0.0085070\n",
      "Test set: Average loss: 1.7205, Accuracy: 3356/5000 (67%)\n",
      "[epoch 29] loss: 0.0055472\n",
      "Test set: Average loss: 1.7663, Accuracy: 3355/5000 (67%)\n",
      "[epoch 30] loss: 0.0036011\n",
      "Test set: Average loss: 1.8090, Accuracy: 3361/5000 (67%)\n",
      "[epoch 31] loss: 0.0023195\n",
      "Test set: Average loss: 1.8581, Accuracy: 3376/5000 (68%)\n",
      "[epoch 32] loss: 0.0014665\n",
      "Test set: Average loss: 1.9205, Accuracy: 3375/5000 (68%)\n",
      "[epoch 33] loss: 0.0009238\n",
      "Test set: Average loss: 1.9853, Accuracy: 3380/5000 (68%)\n",
      "[epoch 34] loss: 0.0005741\n",
      "Test set: Average loss: 2.0562, Accuracy: 3394/5000 (68%)\n",
      "[epoch 35] loss: 0.0003550\n",
      "Test set: Average loss: 2.1216, Accuracy: 3383/5000 (68%)\n",
      "[epoch 36] loss: 0.0002167\n",
      "Test set: Average loss: 2.1995, Accuracy: 3378/5000 (68%)\n",
      "[epoch 37] loss: 0.0001324\n",
      "Test set: Average loss: 2.2776, Accuracy: 3379/5000 (68%)\n",
      "[epoch 38] loss: 0.0000799\n",
      "Test set: Average loss: 2.3513, Accuracy: 3391/5000 (68%)\n",
      "[epoch 39] loss: 0.0000476\n",
      "Test set: Average loss: 2.4332, Accuracy: 3372/5000 (67%)\n",
      "[epoch 40] loss: 0.0000285\n",
      "Test set: Average loss: 2.5089, Accuracy: 3391/5000 (68%)\n",
      "[epoch 41] loss: 0.0000168\n",
      "Test set: Average loss: 2.5989, Accuracy: 3382/5000 (68%)\n",
      "[epoch 42] loss: 0.0000099\n",
      "Test set: Average loss: 2.6783, Accuracy: 3383/5000 (68%)\n",
      "[epoch 43] loss: 0.0000058\n",
      "Test set: Average loss: 2.7562, Accuracy: 3380/5000 (68%)\n",
      "[epoch 44] loss: 0.0000034\n",
      "Test set: Average loss: 2.8548, Accuracy: 3388/5000 (68%)\n",
      "[epoch 45] loss: 0.0000020\n",
      "Test set: Average loss: 2.9199, Accuracy: 3391/5000 (68%)\n",
      "[epoch 46] loss: 0.0000011\n",
      "Test set: Average loss: 3.0037, Accuracy: 3391/5000 (68%)\n",
      "[epoch 47] loss: 0.0000006\n",
      "Test set: Average loss: 3.0515, Accuracy: 3376/5000 (68%)\n",
      "[epoch 48] loss: 0.0000004\n",
      "Test set: Average loss: 3.0897, Accuracy: 3385/5000 (68%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.1118, Accuracy: 3379/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.1195, Accuracy: 3358/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0562, Accuracy: 3394/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.9308, Accuracy: 6840/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 416/5000 (8%)\n",
      "[epoch 1] loss: 1.2867419\n",
      "Test set: Average loss: 1.2069, Accuracy: 2858/5000 (57%)\n",
      "[epoch 2] loss: 1.1217268\n",
      "Test set: Average loss: 1.1280, Accuracy: 3023/5000 (60%)\n",
      "[epoch 3] loss: 1.0628638\n",
      "Test set: Average loss: 1.1046, Accuracy: 3034/5000 (61%)\n",
      "[epoch 4] loss: 1.0155842\n",
      "Test set: Average loss: 1.0669, Accuracy: 3156/5000 (63%)\n",
      "[epoch 5] loss: 0.9719635\n",
      "Test set: Average loss: 1.0571, Accuracy: 3148/5000 (63%)\n",
      "[epoch 6] loss: 0.9311466\n",
      "Test set: Average loss: 1.0327, Accuracy: 3197/5000 (64%)\n",
      "[epoch 7] loss: 0.8948969\n",
      "Test set: Average loss: 1.0218, Accuracy: 3231/5000 (65%)\n",
      "[epoch 8] loss: 0.8624693\n",
      "Test set: Average loss: 1.0249, Accuracy: 3234/5000 (65%)\n",
      "[epoch 9] loss: 0.8195972\n",
      "Test set: Average loss: 0.9990, Accuracy: 3270/5000 (65%)\n",
      "[epoch 10] loss: 0.7742178\n",
      "Test set: Average loss: 1.0232, Accuracy: 3308/5000 (66%)\n",
      "[epoch 11] loss: 0.7196657\n",
      "Test set: Average loss: 1.1006, Accuracy: 3216/5000 (64%)\n",
      "[epoch 12] loss: 0.6640400\n",
      "Test set: Average loss: 1.0263, Accuracy: 3310/5000 (66%)\n",
      "[epoch 13] loss: 0.5990252\n",
      "Test set: Average loss: 1.0881, Accuracy: 3249/5000 (65%)\n",
      "[epoch 14] loss: 0.5306518\n",
      "Test set: Average loss: 1.0622, Accuracy: 3340/5000 (67%)\n",
      "[epoch 15] loss: 0.4612576\n",
      "Test set: Average loss: 1.1349, Accuracy: 3316/5000 (66%)\n",
      "[epoch 16] loss: 0.4063651\n",
      "Test set: Average loss: 1.2380, Accuracy: 3250/5000 (65%)\n",
      "[epoch 17] loss: 0.3400639\n",
      "Test set: Average loss: 1.2486, Accuracy: 3247/5000 (65%)\n",
      "[epoch 18] loss: 0.2969061\n",
      "Test set: Average loss: 1.3246, Accuracy: 3353/5000 (67%)\n",
      "[epoch 19] loss: 0.2545658\n",
      "Test set: Average loss: 1.4188, Accuracy: 3315/5000 (66%)\n",
      "[epoch 20] loss: 0.2299543\n",
      "Test set: Average loss: 1.5229, Accuracy: 3282/5000 (66%)\n",
      "[epoch 21] loss: 0.2114286\n",
      "Test set: Average loss: 1.5498, Accuracy: 3250/5000 (65%)\n",
      "[epoch 22] loss: 0.1974512\n",
      "Test set: Average loss: 1.6121, Accuracy: 3276/5000 (66%)\n",
      "[epoch 23] loss: 0.1944356\n",
      "Test set: Average loss: 1.6191, Accuracy: 3285/5000 (66%)\n",
      "[epoch 24] loss: 0.1809287\n",
      "Test set: Average loss: 1.7545, Accuracy: 3186/5000 (64%)\n",
      "[epoch 25] loss: 0.1758634\n",
      "Test set: Average loss: 1.7217, Accuracy: 3284/5000 (66%)\n",
      "[epoch 26] loss: 0.1767028\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7984, Accuracy: 3249/5000 (65%)\n",
      "[epoch 27] loss: 0.0629711\n",
      "Test set: Average loss: 1.6780, Accuracy: 3359/5000 (67%)\n",
      "[epoch 28] loss: 0.0214217\n",
      "Test set: Average loss: 1.6962, Accuracy: 3360/5000 (67%)\n",
      "[epoch 29] loss: 0.0117366\n",
      "Test set: Average loss: 1.7179, Accuracy: 3382/5000 (68%)\n",
      "[epoch 30] loss: 0.0074041\n",
      "Test set: Average loss: 1.7489, Accuracy: 3374/5000 (67%)\n",
      "[epoch 31] loss: 0.0048127\n",
      "Test set: Average loss: 1.7878, Accuracy: 3400/5000 (68%)\n",
      "[epoch 32] loss: 0.0031406\n",
      "Test set: Average loss: 1.8363, Accuracy: 3397/5000 (68%)\n",
      "[epoch 33] loss: 0.0020033\n",
      "Test set: Average loss: 1.8748, Accuracy: 3397/5000 (68%)\n",
      "[epoch 34] loss: 0.0012622\n",
      "Test set: Average loss: 1.9398, Accuracy: 3401/5000 (68%)\n",
      "[epoch 35] loss: 0.0007957\n",
      "Test set: Average loss: 2.0019, Accuracy: 3406/5000 (68%)\n",
      "[epoch 36] loss: 0.0004902\n",
      "Test set: Average loss: 2.0682, Accuracy: 3398/5000 (68%)\n",
      "[epoch 37] loss: 0.0003024\n",
      "Test set: Average loss: 2.1297, Accuracy: 3402/5000 (68%)\n",
      "[epoch 38] loss: 0.0001830\n",
      "Test set: Average loss: 2.2059, Accuracy: 3405/5000 (68%)\n",
      "[epoch 39] loss: 0.0001118\n",
      "Test set: Average loss: 2.2796, Accuracy: 3392/5000 (68%)\n",
      "[epoch 40] loss: 0.0000670\n",
      "Test set: Average loss: 2.3523, Accuracy: 3406/5000 (68%)\n",
      "[epoch 41] loss: 0.0000398\n",
      "Test set: Average loss: 2.4359, Accuracy: 3411/5000 (68%)\n",
      "[epoch 42] loss: 0.0000235\n",
      "Test set: Average loss: 2.5089, Accuracy: 3402/5000 (68%)\n",
      "[epoch 43] loss: 0.0000139\n",
      "Test set: Average loss: 2.5919, Accuracy: 3405/5000 (68%)\n",
      "[epoch 44] loss: 0.0000082\n",
      "Test set: Average loss: 2.6729, Accuracy: 3400/5000 (68%)\n",
      "[epoch 45] loss: 0.0000048\n",
      "Test set: Average loss: 2.7489, Accuracy: 3424/5000 (68%)\n",
      "[epoch 46] loss: 0.0000027\n",
      "Test set: Average loss: 2.8321, Accuracy: 3421/5000 (68%)\n",
      "[epoch 47] loss: 0.0000016\n",
      "Test set: Average loss: 2.9094, Accuracy: 3430/5000 (69%)\n",
      "[epoch 48] loss: 0.0000009\n",
      "Test set: Average loss: 2.9751, Accuracy: 3421/5000 (68%)\n",
      "[epoch 49] loss: 0.0000005\n",
      "Test set: Average loss: 3.0127, Accuracy: 3415/5000 (68%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 3.0482, Accuracy: 3413/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9094, Accuracy: 3430/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.7682, Accuracy: 6897/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3033, Accuracy: 493/5000 (10%)\n",
      "[epoch 1] loss: 1.2844434\n",
      "Test set: Average loss: 1.2291, Accuracy: 2818/5000 (56%)\n",
      "[epoch 2] loss: 1.1185090\n",
      "Test set: Average loss: 1.1422, Accuracy: 2960/5000 (59%)\n",
      "[epoch 3] loss: 1.0645133\n",
      "Test set: Average loss: 1.0926, Accuracy: 3057/5000 (61%)\n",
      "[epoch 4] loss: 1.0240662\n",
      "Test set: Average loss: 1.0723, Accuracy: 3135/5000 (63%)\n",
      "[epoch 5] loss: 0.9828509\n",
      "Test set: Average loss: 1.0778, Accuracy: 3130/5000 (63%)\n",
      "[epoch 6] loss: 0.9414157\n",
      "Test set: Average loss: 1.0714, Accuracy: 3113/5000 (62%)\n",
      "[epoch 7] loss: 0.9004685\n",
      "Test set: Average loss: 1.0715, Accuracy: 3133/5000 (63%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 0.8696416\n",
      "Test set: Average loss: 1.0573, Accuracy: 3177/5000 (64%)\n",
      "[epoch 9] loss: 0.8299842\n",
      "Test set: Average loss: 1.0186, Accuracy: 3238/5000 (65%)\n",
      "[epoch 10] loss: 0.7798368\n",
      "Test set: Average loss: 0.9978, Accuracy: 3294/5000 (66%)\n",
      "[epoch 11] loss: 0.7304824\n",
      "Test set: Average loss: 1.0191, Accuracy: 3308/5000 (66%)\n",
      "[epoch 12] loss: 0.6742038\n",
      "Test set: Average loss: 1.0497, Accuracy: 3260/5000 (65%)\n",
      "[epoch 13] loss: 0.6129200\n",
      "Test set: Average loss: 1.0560, Accuracy: 3320/5000 (66%)\n",
      "[epoch 14] loss: 0.5491705\n",
      "Test set: Average loss: 1.1304, Accuracy: 3227/5000 (65%)\n",
      "[epoch 15] loss: 0.4805577\n",
      "Test set: Average loss: 1.1210, Accuracy: 3322/5000 (66%)\n",
      "[epoch 16] loss: 0.4114386\n",
      "Test set: Average loss: 1.1864, Accuracy: 3290/5000 (66%)\n",
      "[epoch 17] loss: 0.3474767\n",
      "Test set: Average loss: 1.2697, Accuracy: 3244/5000 (65%)\n",
      "[epoch 18] loss: 0.3009560\n",
      "Test set: Average loss: 1.3319, Accuracy: 3276/5000 (66%)\n",
      "[epoch 19] loss: 0.2493153\n",
      "Test set: Average loss: 1.3395, Accuracy: 3357/5000 (67%)\n",
      "[epoch 20] loss: 0.2288230\n",
      "Test set: Average loss: 1.5100, Accuracy: 3248/5000 (65%)\n",
      "[epoch 21] loss: 0.2155749\n",
      "Test set: Average loss: 1.5393, Accuracy: 3269/5000 (65%)\n",
      "[epoch 22] loss: 0.1884931\n",
      "Test set: Average loss: 1.6155, Accuracy: 3220/5000 (64%)\n",
      "[epoch 23] loss: 0.1915309\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6746, Accuracy: 3218/5000 (64%)\n",
      "[epoch 24] loss: 0.0703445\n",
      "Test set: Average loss: 1.5524, Accuracy: 3354/5000 (67%)\n",
      "[epoch 25] loss: 0.0275345\n",
      "Test set: Average loss: 1.5699, Accuracy: 3372/5000 (67%)\n",
      "[epoch 26] loss: 0.0156344\n",
      "Test set: Average loss: 1.5943, Accuracy: 3376/5000 (68%)\n",
      "[epoch 27] loss: 0.0100925\n",
      "Test set: Average loss: 1.6310, Accuracy: 3380/5000 (68%)\n",
      "[epoch 28] loss: 0.0065846\n",
      "Test set: Average loss: 1.6756, Accuracy: 3373/5000 (67%)\n",
      "[epoch 29] loss: 0.0042854\n",
      "Test set: Average loss: 1.7209, Accuracy: 3383/5000 (68%)\n",
      "[epoch 30] loss: 0.0028106\n",
      "Test set: Average loss: 1.7812, Accuracy: 3388/5000 (68%)\n",
      "[epoch 31] loss: 0.0017966\n",
      "Test set: Average loss: 1.8332, Accuracy: 3388/5000 (68%)\n",
      "[epoch 32] loss: 0.0011338\n",
      "Test set: Average loss: 1.9098, Accuracy: 3385/5000 (68%)\n",
      "[epoch 33] loss: 0.0007131\n",
      "Test set: Average loss: 1.9724, Accuracy: 3401/5000 (68%)\n",
      "[epoch 34] loss: 0.0004468\n",
      "Test set: Average loss: 2.0379, Accuracy: 3396/5000 (68%)\n",
      "[epoch 35] loss: 0.0002758\n",
      "Test set: Average loss: 2.1112, Accuracy: 3394/5000 (68%)\n",
      "[epoch 36] loss: 0.0001684\n",
      "Test set: Average loss: 2.1904, Accuracy: 3414/5000 (68%)\n",
      "[epoch 37] loss: 0.0001033\n",
      "Test set: Average loss: 2.2692, Accuracy: 3414/5000 (68%)\n",
      "[epoch 38] loss: 0.0000624\n",
      "Test set: Average loss: 2.3499, Accuracy: 3413/5000 (68%)\n",
      "[epoch 39] loss: 0.0002421\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3818, Accuracy: 3382/5000 (68%)\n",
      "[epoch 40] loss: 0.0000599\n",
      "Test set: Average loss: 2.3848, Accuracy: 3386/5000 (68%)\n",
      "[epoch 41] loss: 0.0000545\n",
      "Test set: Average loss: 2.3883, Accuracy: 3384/5000 (68%)\n",
      "[epoch 42] loss: 0.0000486\n",
      "Test set: Average loss: 2.3933, Accuracy: 3387/5000 (68%)\n",
      "[epoch 43] loss: 0.0000427\n",
      "Test set: Average loss: 2.3984, Accuracy: 3394/5000 (68%)\n",
      "[epoch 44] loss: 0.0000372\n",
      "Test set: Average loss: 2.4067, Accuracy: 3396/5000 (68%)\n",
      "[epoch 45] loss: 0.0000325\n",
      "Test set: Average loss: 2.4190, Accuracy: 3398/5000 (68%)\n",
      "[epoch 46] loss: 0.0000285\n",
      "Test set: Average loss: 2.4339, Accuracy: 3404/5000 (68%)\n",
      "[epoch 47] loss: 0.0000251\n",
      "Test set: Average loss: 2.4465, Accuracy: 3413/5000 (68%)\n",
      "[epoch 48] loss: 0.0000222\n",
      "Test set: Average loss: 2.4633, Accuracy: 3421/5000 (68%)\n",
      "[epoch 49] loss: 0.0000198\n",
      "Test set: Average loss: 2.4784, Accuracy: 3417/5000 (68%)\n",
      "[epoch 50] loss: 0.0000176\n",
      "Test set: Average loss: 2.4954, Accuracy: 3417/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4633, Accuracy: 3421/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.3734, Accuracy: 6882/10000 (69%)\n"
     ]
    }
   ],
   "source": [
    "# train the SimEc\n",
    "w = 0.95\n",
    "S = w*S_lin + (1.-w)*S_class\n",
    "S_ll = S[:n_targets, :]\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = SimilarityEncoder(cnn, 512, n_targets)\n",
    "model.fit(X, S, epochs=50, lr=0.0001, s_ll_reg=100., S_ll=S_ll, orth_reg=0.1)\n",
    "print(check_similarity_match(model.predict(X[:n_targets]), S_ll, X_embed_is_S_approx=True))\n",
    "print(check_similarity_match(model.transform(X[:n_targets]), S_ll))\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.model.embedding_net.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_se_t1_mix = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_se_t1_mix.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T21:04:58.329930Z",
     "start_time": "2019-07-24T18:10:04.924969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.0212869\n",
      "[epoch 2] loss: 0.0178506\n",
      "[epoch 3] loss: 0.0173304\n",
      "[epoch 4] loss: 0.0170199\n",
      "[epoch 5] loss: 0.0167998\n",
      "[epoch 6] loss: 0.0165886\n",
      "[epoch 7] loss: 0.0164149\n",
      "[epoch 8] loss: 0.0162663\n",
      "[epoch 9] loss: 0.0161405\n",
      "[epoch 10] loss: 0.0160343\n",
      "[epoch 11] loss: 0.0159257\n",
      "[epoch 12] loss: 0.0158190\n",
      "[epoch 13] loss: 0.0157384\n",
      "[epoch 14] loss: 0.0156508\n",
      "[epoch 15] loss: 0.0155637\n",
      "[epoch 16] loss: 0.0154621\n",
      "[epoch 17] loss: 0.0153636\n",
      "[epoch 18] loss: 0.0153789\n",
      "[epoch 19] loss: 0.0153846\n",
      "[epoch 20] loss: 0.0152942\n",
      "[epoch 21] loss: 0.0152669\n",
      "[epoch 22] loss: 0.0152116\n",
      "[epoch 23] loss: 0.0151483\n",
      "[epoch 24] loss: 0.0150844\n",
      "[epoch 25] loss: 0.0149888\n",
      "[epoch 26] loss: 0.0149111\n",
      "[epoch 27] loss: 0.0148627\n",
      "[epoch 28] loss: 0.0148186\n",
      "[epoch 29] loss: 0.0147908\n",
      "[epoch 30] loss: 0.0147568\n",
      "[epoch 31] loss: 0.0147276\n",
      "[epoch 32] loss: 0.0146978\n",
      "[epoch 33] loss: 0.0146763\n",
      "[epoch 34] loss: 0.0146659\n",
      "[epoch 35] loss: 0.0146224\n",
      "[epoch 36] loss: 0.0146036\n",
      "[epoch 37] loss: 0.0145765\n",
      "[epoch 38] loss: 0.0145584\n",
      "[epoch 39] loss: 0.0145403\n",
      "[epoch 40] loss: 0.0145084\n",
      "[epoch 41] loss: 0.0144937\n",
      "[epoch 42] loss: 0.0144799\n",
      "[epoch 43] loss: 0.0144530\n",
      "[epoch 44] loss: 0.0144408\n",
      "[epoch 45] loss: 0.0144107\n",
      "[epoch 46] loss: 0.0143780\n",
      "[epoch 47] loss: 0.0143602\n",
      "[epoch 48] loss: 0.0143298\n",
      "[epoch 49] loss: 0.0142989\n",
      "[epoch 50] loss: 0.0142470\n",
      "(0.014147536536525635, 0.4007734126932223, 0.49999242003432504)\n",
      "(7.6765932167559745, 0.07344989816742903, 0.3133401162174463)\n",
      "Took 905 sec to train.\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3069, Accuracy: 483/5000 (10%)\n",
      "[epoch 1] loss: 2.3005860\n",
      "Test set: Average loss: 2.2622, Accuracy: 987/5000 (20%)\n",
      "[epoch 2] loss: 2.1150408\n",
      "Test set: Average loss: 2.2201, Accuracy: 1091/5000 (22%)\n",
      "[epoch 3] loss: 1.8740859\n",
      "Test set: Average loss: 2.2155, Accuracy: 1035/5000 (21%)\n",
      "[epoch 4] loss: 1.6348549\n",
      "Test set: Average loss: 2.2726, Accuracy: 921/5000 (18%)\n",
      "[epoch 5] loss: 1.4486287\n",
      "Test set: Average loss: 2.3604, Accuracy: 869/5000 (17%)\n",
      "[epoch 6] loss: 1.2821312\n",
      "Test set: Average loss: 2.4748, Accuracy: 918/5000 (18%)\n",
      "[epoch 7] loss: 1.1510806\n",
      "Test set: Average loss: 2.4722, Accuracy: 1058/5000 (21%)\n",
      "[epoch 8] loss: 0.9797385\n",
      "Test set: Average loss: 2.4140, Accuracy: 1105/5000 (22%)\n",
      "[epoch 9] loss: 0.8223528\n",
      "Test set: Average loss: 2.3826, Accuracy: 1146/5000 (23%)\n",
      "[epoch 10] loss: 0.7107422\n",
      "Test set: Average loss: 2.3921, Accuracy: 1243/5000 (25%)\n",
      "[epoch 11] loss: 0.6036492\n",
      "Test set: Average loss: 2.4604, Accuracy: 1269/5000 (25%)\n",
      "[epoch 12] loss: 0.5058925\n",
      "Test set: Average loss: 2.5696, Accuracy: 1292/5000 (26%)\n",
      "[epoch 13] loss: 0.4195757\n",
      "Test set: Average loss: 2.6863, Accuracy: 1271/5000 (25%)\n",
      "[epoch 14] loss: 0.3377108\n",
      "Test set: Average loss: 2.8171, Accuracy: 1191/5000 (24%)\n",
      "[epoch 15] loss: 0.2680497\n",
      "Test set: Average loss: 2.9649, Accuracy: 1135/5000 (23%)\n",
      "[epoch 16] loss: 0.2113692\n",
      "Test set: Average loss: 3.1110, Accuracy: 1126/5000 (23%)\n",
      "[epoch 17] loss: 0.1601953\n",
      "Test set: Average loss: 3.2389, Accuracy: 1156/5000 (23%)\n",
      "[epoch 18] loss: 0.1151759\n",
      "Test set: Average loss: 3.3362, Accuracy: 1174/5000 (23%)\n",
      "[epoch 19] loss: 0.0784987\n",
      "Test set: Average loss: 3.4123, Accuracy: 1203/5000 (24%)\n",
      "[epoch 20] loss: 0.0507694\n",
      "Test set: Average loss: 3.4972, Accuracy: 1225/5000 (24%)\n",
      "[epoch 21] loss: 0.0332494\n",
      "Test set: Average loss: 3.6037, Accuracy: 1231/5000 (25%)\n",
      "[epoch 22] loss: 0.0225300\n",
      "Test set: Average loss: 3.7297, Accuracy: 1243/5000 (25%)\n",
      "[epoch 23] loss: 0.0157753\n",
      "Test set: Average loss: 3.8689, Accuracy: 1260/5000 (25%)\n",
      "[epoch 24] loss: 0.0112786\n",
      "Test set: Average loss: 4.0156, Accuracy: 1259/5000 (25%)\n",
      "[epoch 25] loss: 0.0081536\n",
      "Test set: Average loss: 4.1654, Accuracy: 1260/5000 (25%)\n",
      "[epoch 26] loss: 0.0060008\n",
      "Test set: Average loss: 4.3150, Accuracy: 1242/5000 (25%)\n",
      "[epoch 27] loss: 0.0045095\n",
      "Test set: Average loss: 4.4615, Accuracy: 1234/5000 (25%)\n",
      "[epoch 28] loss: 0.0034661\n",
      "Test set: Average loss: 4.6027, Accuracy: 1218/5000 (24%)\n",
      "[epoch 29] loss: 0.0027210\n",
      "Test set: Average loss: 4.7368, Accuracy: 1205/5000 (24%)\n",
      "[epoch 30] loss: 0.0021815\n",
      "Test set: Average loss: 4.8625, Accuracy: 1200/5000 (24%)\n",
      "[epoch 31] loss: 0.0017872\n",
      "Test set: Average loss: 4.9790, Accuracy: 1200/5000 (24%)\n",
      "[epoch 32] loss: 0.0014990\n",
      "Test set: Average loss: 5.0859, Accuracy: 1186/5000 (24%)\n",
      "[epoch 33] loss: 0.0012882\n",
      "Test set: Average loss: 5.1830, Accuracy: 1173/5000 (23%)\n",
      "[epoch 34] loss: 0.0011312\n",
      "Test set: Average loss: 5.2704, Accuracy: 1165/5000 (23%)\n",
      "[epoch 35] loss: 0.0010100\n",
      "Test set: Average loss: 5.3486, Accuracy: 1166/5000 (23%)\n",
      "[epoch 36] loss: 0.0009114\n",
      "Test set: Average loss: 5.4182, Accuracy: 1160/5000 (23%)\n",
      "[epoch 37] loss: 0.0008275\n",
      "Test set: Average loss: 5.4799, Accuracy: 1166/5000 (23%)\n",
      "[epoch 38] loss: 0.0007529\n",
      "Test set: Average loss: 5.5348, Accuracy: 1163/5000 (23%)\n",
      "[epoch 39] loss: 0.0006852\n",
      "Test set: Average loss: 5.5837, Accuracy: 1157/5000 (23%)\n",
      "[epoch 40] loss: 0.0006237\n",
      "Test set: Average loss: 5.6274, Accuracy: 1157/5000 (23%)\n",
      "[epoch 41] loss: 0.0005679\n",
      "Test set: Average loss: 5.6667, Accuracy: 1152/5000 (23%)\n",
      "[epoch 42] loss: 0.0005185\n",
      "Test set: Average loss: 5.7023, Accuracy: 1155/5000 (23%)\n",
      "[epoch 43] loss: 0.0004748\n",
      "Test set: Average loss: 5.7348, Accuracy: 1159/5000 (23%)\n",
      "[epoch 44] loss: 0.0004367\n",
      "Test set: Average loss: 5.7646, Accuracy: 1158/5000 (23%)\n",
      "[epoch 45] loss: 0.0004041\n",
      "Test set: Average loss: 5.7921, Accuracy: 1159/5000 (23%)\n",
      "[epoch 46] loss: 0.0003761\n",
      "Test set: Average loss: 5.8175, Accuracy: 1162/5000 (23%)\n",
      "[epoch 47] loss: 0.0003519\n",
      "Test set: Average loss: 5.8410, Accuracy: 1163/5000 (23%)\n",
      "[epoch 48] loss: 0.0003313\n",
      "Test set: Average loss: 5.8628, Accuracy: 1162/5000 (23%)\n",
      "[epoch 49] loss: 0.0003131\n",
      "Test set: Average loss: 5.8830, Accuracy: 1164/5000 (23%)\n",
      "[epoch 50] loss: 0.0002967\n",
      "Test set: Average loss: 5.9017, Accuracy: 1163/5000 (23%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5696, Accuracy: 1292/5000 (26%)\n",
      "Test\n",
      "Test set: Average loss: 2.4919, Accuracy: 2651/10000 (27%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2995, Accuracy: 756/5000 (15%)\n",
      "[epoch 1] loss: 2.2993658\n",
      "Test set: Average loss: 2.2603, Accuracy: 818/5000 (16%)\n",
      "[epoch 2] loss: 2.1511917\n",
      "Test set: Average loss: 2.2124, Accuracy: 914/5000 (18%)\n",
      "[epoch 3] loss: 1.9593567\n",
      "Test set: Average loss: 2.1690, Accuracy: 953/5000 (19%)\n",
      "[epoch 4] loss: 1.7212316\n",
      "Test set: Average loss: 2.1650, Accuracy: 987/5000 (20%)\n",
      "[epoch 5] loss: 1.4712479\n",
      "Test set: Average loss: 2.1897, Accuracy: 1112/5000 (22%)\n",
      "[epoch 6] loss: 1.2334030\n",
      "Test set: Average loss: 2.2298, Accuracy: 1242/5000 (25%)\n",
      "[epoch 7] loss: 1.0199432\n",
      "Test set: Average loss: 2.2741, Accuracy: 1351/5000 (27%)\n",
      "[epoch 8] loss: 0.8271016\n",
      "Test set: Average loss: 2.3071, Accuracy: 1420/5000 (28%)\n",
      "[epoch 9] loss: 0.6466587\n",
      "Test set: Average loss: 2.3382, Accuracy: 1475/5000 (30%)\n",
      "[epoch 10] loss: 0.4821973\n",
      "Test set: Average loss: 2.4086, Accuracy: 1460/5000 (29%)\n",
      "[epoch 11] loss: 0.3563716\n",
      "Test set: Average loss: 2.5317, Accuracy: 1426/5000 (29%)\n",
      "[epoch 12] loss: 0.2614447\n",
      "Test set: Average loss: 2.6705, Accuracy: 1380/5000 (28%)\n",
      "[epoch 13] loss: 0.1814380\n",
      "Test set: Average loss: 2.8178, Accuracy: 1326/5000 (27%)\n",
      "[epoch 14] loss: 0.1242033\n",
      "Test set: Average loss: 2.9725, Accuracy: 1282/5000 (26%)\n",
      "[epoch 15] loss: 0.0890725\n",
      "Test set: Average loss: 3.1290, Accuracy: 1255/5000 (25%)\n",
      "[epoch 16] loss: 0.0635997\n",
      "Test set: Average loss: 3.2815, Accuracy: 1243/5000 (25%)\n",
      "[epoch 17] loss: 0.0419415\n",
      "Test set: Average loss: 3.4327, Accuracy: 1258/5000 (25%)\n",
      "[epoch 18] loss: 0.0261435\n",
      "Test set: Average loss: 3.5859, Accuracy: 1227/5000 (25%)\n",
      "[epoch 19] loss: 0.0166445\n",
      "Test set: Average loss: 3.7395, Accuracy: 1224/5000 (24%)\n",
      "[epoch 20] loss: 0.0113212\n",
      "Test set: Average loss: 3.8898, Accuracy: 1201/5000 (24%)\n",
      "[epoch 21] loss: 0.0082252\n",
      "Test set: Average loss: 4.0340, Accuracy: 1191/5000 (24%)\n",
      "[epoch 22] loss: 0.0062713\n",
      "Test set: Average loss: 4.1703, Accuracy: 1200/5000 (24%)\n",
      "[epoch 23] loss: 0.0048949\n",
      "Test set: Average loss: 4.2980, Accuracy: 1193/5000 (24%)\n",
      "[epoch 24] loss: 0.0038439\n",
      "Test set: Average loss: 4.4163, Accuracy: 1192/5000 (24%)\n",
      "[epoch 25] loss: 0.0030114\n",
      "Test set: Average loss: 4.5252, Accuracy: 1188/5000 (24%)\n",
      "[epoch 26] loss: 0.0023561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.6248, Accuracy: 1183/5000 (24%)\n",
      "[epoch 27] loss: 0.0018529\n",
      "Test set: Average loss: 4.7154, Accuracy: 1182/5000 (24%)\n",
      "[epoch 28] loss: 0.0014742\n",
      "Test set: Average loss: 4.7976, Accuracy: 1172/5000 (23%)\n",
      "[epoch 29] loss: 0.0011892\n",
      "Test set: Average loss: 4.8720, Accuracy: 1171/5000 (23%)\n",
      "[epoch 30] loss: 0.0009751\n",
      "Test set: Average loss: 4.9395, Accuracy: 1162/5000 (23%)\n",
      "[epoch 31] loss: 0.0008130\n",
      "Test set: Average loss: 5.0008, Accuracy: 1159/5000 (23%)\n",
      "[epoch 32] loss: 0.0006893\n",
      "Test set: Average loss: 5.0566, Accuracy: 1156/5000 (23%)\n",
      "[epoch 33] loss: 0.0005944\n",
      "Test set: Average loss: 5.1077, Accuracy: 1154/5000 (23%)\n",
      "[epoch 34] loss: 0.0005204\n",
      "Test set: Average loss: 5.1546, Accuracy: 1156/5000 (23%)\n",
      "[epoch 35] loss: 0.0004621\n",
      "Test set: Average loss: 5.1978, Accuracy: 1155/5000 (23%)\n",
      "[epoch 36] loss: 0.0004153\n",
      "Test set: Average loss: 5.2377, Accuracy: 1147/5000 (23%)\n",
      "[epoch 37] loss: 0.0003772\n",
      "Test set: Average loss: 5.2746, Accuracy: 1143/5000 (23%)\n",
      "[epoch 38] loss: 0.0003458\n",
      "Test set: Average loss: 5.3090, Accuracy: 1143/5000 (23%)\n",
      "[epoch 39] loss: 0.0003193\n",
      "Test set: Average loss: 5.3409, Accuracy: 1143/5000 (23%)\n",
      "[epoch 40] loss: 0.0002966\n",
      "Test set: Average loss: 5.3707, Accuracy: 1139/5000 (23%)\n",
      "[epoch 41] loss: 0.0002771\n",
      "Test set: Average loss: 5.3984, Accuracy: 1140/5000 (23%)\n",
      "[epoch 42] loss: 0.0002600\n",
      "Test set: Average loss: 5.4243, Accuracy: 1141/5000 (23%)\n",
      "[epoch 43] loss: 0.0002450\n",
      "Test set: Average loss: 5.4484, Accuracy: 1145/5000 (23%)\n",
      "[epoch 44] loss: 0.0002316\n",
      "Test set: Average loss: 5.4710, Accuracy: 1141/5000 (23%)\n",
      "[epoch 45] loss: 0.0002194\n",
      "Test set: Average loss: 5.4922, Accuracy: 1141/5000 (23%)\n",
      "[epoch 46] loss: 0.0002085\n",
      "Test set: Average loss: 5.5120, Accuracy: 1140/5000 (23%)\n",
      "[epoch 47] loss: 0.0001987\n",
      "Test set: Average loss: 5.5305, Accuracy: 1138/5000 (23%)\n",
      "[epoch 48] loss: 0.0001898\n",
      "Test set: Average loss: 5.5479, Accuracy: 1136/5000 (23%)\n",
      "[epoch 49] loss: 0.0001817\n",
      "Test set: Average loss: 5.5642, Accuracy: 1136/5000 (23%)\n",
      "[epoch 50] loss: 0.0001744\n",
      "Test set: Average loss: 5.5794, Accuracy: 1136/5000 (23%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3382, Accuracy: 1475/5000 (30%)\n",
      "Test\n",
      "Test set: Average loss: 2.3487, Accuracy: 2995/10000 (30%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3127, Accuracy: 488/5000 (10%)\n",
      "[epoch 1] loss: 2.3101144\n",
      "Test set: Average loss: 2.2766, Accuracy: 855/5000 (17%)\n",
      "[epoch 2] loss: 2.1393833\n",
      "Test set: Average loss: 2.2679, Accuracy: 833/5000 (17%)\n",
      "[epoch 3] loss: 1.9281598\n",
      "Test set: Average loss: 2.3209, Accuracy: 751/5000 (15%)\n",
      "[epoch 4] loss: 1.6898866\n",
      "Test set: Average loss: 2.5073, Accuracy: 692/5000 (14%)\n",
      "[epoch 5] loss: 1.5153706\n",
      "Test set: Average loss: 2.6237, Accuracy: 805/5000 (16%)\n",
      "[epoch 6] loss: 1.3766567\n",
      "Test set: Average loss: 2.6015, Accuracy: 858/5000 (17%)\n",
      "[epoch 7] loss: 1.1974568\n",
      "Test set: Average loss: 2.5137, Accuracy: 845/5000 (17%)\n",
      "[epoch 8] loss: 0.9865951\n",
      "Test set: Average loss: 2.3943, Accuracy: 881/5000 (18%)\n",
      "[epoch 9] loss: 0.7896326\n",
      "Test set: Average loss: 2.2749, Accuracy: 1023/5000 (20%)\n",
      "[epoch 10] loss: 0.6188858\n",
      "Test set: Average loss: 2.2145, Accuracy: 1090/5000 (22%)\n",
      "[epoch 11] loss: 0.4754218\n",
      "Test set: Average loss: 2.2212, Accuracy: 1117/5000 (22%)\n",
      "[epoch 12] loss: 0.3483272\n",
      "Test set: Average loss: 2.2883, Accuracy: 1104/5000 (22%)\n",
      "[epoch 13] loss: 0.2440801\n",
      "Test set: Average loss: 2.3949, Accuracy: 1116/5000 (22%)\n",
      "[epoch 14] loss: 0.1655483\n",
      "Test set: Average loss: 2.5380, Accuracy: 1109/5000 (22%)\n",
      "[epoch 15] loss: 0.1106320\n",
      "Test set: Average loss: 2.7297, Accuracy: 1121/5000 (22%)\n",
      "[epoch 16] loss: 0.0735486\n",
      "Test set: Average loss: 2.9685, Accuracy: 1113/5000 (22%)\n",
      "[epoch 17] loss: 0.0479498\n",
      "Test set: Average loss: 3.2433, Accuracy: 1090/5000 (22%)\n",
      "[epoch 18] loss: 0.0304667\n",
      "Test set: Average loss: 3.5381, Accuracy: 1065/5000 (21%)\n",
      "[epoch 19] loss: 0.0193177\n",
      "Test set: Average loss: 3.8357, Accuracy: 1031/5000 (21%)\n",
      "[epoch 20] loss: 0.0124963\n",
      "Test set: Average loss: 4.1218, Accuracy: 1016/5000 (20%)\n",
      "[epoch 21] loss: 0.0082971\n",
      "Test set: Average loss: 4.3881, Accuracy: 999/5000 (20%)\n",
      "[epoch 22] loss: 0.0056831\n",
      "Test set: Average loss: 4.6303, Accuracy: 991/5000 (20%)\n",
      "[epoch 23] loss: 0.0039862\n",
      "Test set: Average loss: 4.8489, Accuracy: 985/5000 (20%)\n",
      "[epoch 24] loss: 0.0028613\n",
      "Test set: Average loss: 5.0457, Accuracy: 991/5000 (20%)\n",
      "[epoch 25] loss: 0.0021017\n",
      "Test set: Average loss: 5.2232, Accuracy: 990/5000 (20%)\n",
      "[epoch 26] loss: 0.0015838\n",
      "Test set: Average loss: 5.3838, Accuracy: 988/5000 (20%)\n",
      "[epoch 27] loss: 0.0012261\n",
      "Test set: Average loss: 5.5296, Accuracy: 992/5000 (20%)\n",
      "[epoch 28] loss: 0.0009750\n",
      "Test set: Average loss: 5.6625, Accuracy: 990/5000 (20%)\n",
      "[epoch 29] loss: 0.0007948\n",
      "Test set: Average loss: 5.7840, Accuracy: 989/5000 (20%)\n",
      "[epoch 30] loss: 0.0006637\n",
      "Test set: Average loss: 5.8956, Accuracy: 993/5000 (20%)\n",
      "[epoch 31] loss: 0.0005660\n",
      "Test set: Average loss: 5.9982, Accuracy: 994/5000 (20%)\n",
      "[epoch 32] loss: 0.0004916\n",
      "Test set: Average loss: 6.0929, Accuracy: 991/5000 (20%)\n",
      "[epoch 33] loss: 0.0004342\n",
      "Test set: Average loss: 6.1806, Accuracy: 992/5000 (20%)\n",
      "[epoch 34] loss: 0.0003885\n",
      "Test set: Average loss: 6.2618, Accuracy: 990/5000 (20%)\n",
      "[epoch 35] loss: 0.0003515\n",
      "Test set: Average loss: 6.3371, Accuracy: 986/5000 (20%)\n",
      "[epoch 36] loss: 0.0003212\n",
      "Test set: Average loss: 6.4072, Accuracy: 988/5000 (20%)\n",
      "[epoch 37] loss: 0.0002959\n",
      "Test set: Average loss: 6.4724, Accuracy: 984/5000 (20%)\n",
      "[epoch 38] loss: 0.0002745\n",
      "Test set: Average loss: 6.5331, Accuracy: 987/5000 (20%)\n",
      "[epoch 39] loss: 0.0002559\n",
      "Test set: Average loss: 6.5896, Accuracy: 988/5000 (20%)\n",
      "[epoch 40] loss: 0.0002399\n",
      "Test set: Average loss: 6.6423, Accuracy: 987/5000 (20%)\n",
      "[epoch 41] loss: 0.0002260\n",
      "Test set: Average loss: 6.6914, Accuracy: 986/5000 (20%)\n",
      "[epoch 42] loss: 0.0002139\n",
      "Test set: Average loss: 6.7371, Accuracy: 981/5000 (20%)\n",
      "[epoch 43] loss: 0.0002029\n",
      "Test set: Average loss: 6.7797, Accuracy: 980/5000 (20%)\n",
      "[epoch 44] loss: 0.0001933\n",
      "Test set: Average loss: 6.8193, Accuracy: 979/5000 (20%)\n",
      "[epoch 45] loss: 0.0001848\n",
      "Test set: Average loss: 6.8562, Accuracy: 977/5000 (20%)\n",
      "[epoch 46] loss: 0.0001771\n",
      "Test set: Average loss: 6.8904, Accuracy: 979/5000 (20%)\n",
      "[epoch 47] loss: 0.0001703\n",
      "Test set: Average loss: 6.9222, Accuracy: 979/5000 (20%)\n",
      "[epoch 48] loss: 0.0001641\n",
      "Test set: Average loss: 6.9516, Accuracy: 976/5000 (20%)\n",
      "[epoch 49] loss: 0.0001587\n",
      "Test set: Average loss: 6.9788, Accuracy: 973/5000 (19%)\n",
      "[epoch 50] loss: 0.0001536\n",
      "Test set: Average loss: 7.0040, Accuracy: 971/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7297, Accuracy: 1121/5000 (22%)\n",
      "Test\n",
      "Test set: Average loss: 2.7169, Accuracy: 2235/10000 (22%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3086, Accuracy: 576/5000 (12%)\n",
      "[epoch 1] loss: 2.2820839\n",
      "Test set: Average loss: 2.2199, Accuracy: 974/5000 (19%)\n",
      "[epoch 2] loss: 1.9881543\n",
      "Test set: Average loss: 2.1303, Accuracy: 1165/5000 (23%)\n",
      "[epoch 3] loss: 1.7162681\n",
      "Test set: Average loss: 2.1595, Accuracy: 1170/5000 (23%)\n",
      "[epoch 4] loss: 1.3888136\n",
      "Test set: Average loss: 2.2218, Accuracy: 1312/5000 (26%)\n",
      "[epoch 5] loss: 1.3001295\n",
      "Test set: Average loss: 2.2315, Accuracy: 1434/5000 (29%)\n",
      "[epoch 6] loss: 1.1434851\n",
      "Test set: Average loss: 2.1851, Accuracy: 1414/5000 (28%)\n",
      "[epoch 7] loss: 0.9689998\n",
      "Test set: Average loss: 2.0724, Accuracy: 1511/5000 (30%)\n",
      "[epoch 8] loss: 0.7350442\n",
      "Test set: Average loss: 2.0566, Accuracy: 1495/5000 (30%)\n",
      "[epoch 9] loss: 0.5499070\n",
      "Test set: Average loss: 2.0488, Accuracy: 1485/5000 (30%)\n",
      "[epoch 10] loss: 0.4738003\n",
      "Test set: Average loss: 2.1218, Accuracy: 1475/5000 (30%)\n",
      "[epoch 11] loss: 0.3095756\n",
      "Test set: Average loss: 2.2869, Accuracy: 1455/5000 (29%)\n",
      "[epoch 12] loss: 0.2470038\n",
      "Test set: Average loss: 2.4447, Accuracy: 1455/5000 (29%)\n",
      "[epoch 13] loss: 0.1739286\n",
      "Test set: Average loss: 2.5244, Accuracy: 1571/5000 (31%)\n",
      "[epoch 14] loss: 0.1068288\n",
      "Test set: Average loss: 2.7317, Accuracy: 1525/5000 (30%)\n",
      "[epoch 15] loss: 0.0878887\n",
      "Test set: Average loss: 2.9540, Accuracy: 1513/5000 (30%)\n",
      "[epoch 16] loss: 0.0496895\n",
      "Test set: Average loss: 3.1865, Accuracy: 1469/5000 (29%)\n",
      "[epoch 17] loss: 0.0343148\n",
      "Test set: Average loss: 3.3727, Accuracy: 1440/5000 (29%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0219974\n",
      "Test set: Average loss: 3.4521, Accuracy: 1468/5000 (29%)\n",
      "[epoch 19] loss: 0.0137816\n",
      "Test set: Average loss: 3.5279, Accuracy: 1493/5000 (30%)\n",
      "[epoch 20] loss: 0.0097916\n",
      "Test set: Average loss: 3.5978, Accuracy: 1506/5000 (30%)\n",
      "[epoch 21] loss: 0.0091119\n",
      "Test set: Average loss: 3.6548, Accuracy: 1514/5000 (30%)\n",
      "[epoch 22] loss: 0.0060411\n",
      "Test set: Average loss: 3.6982, Accuracy: 1509/5000 (30%)\n",
      "[epoch 23] loss: 0.0043359\n",
      "Test set: Average loss: 3.7417, Accuracy: 1511/5000 (30%)\n",
      "[epoch 24] loss: 0.0034246\n",
      "Test set: Average loss: 3.7864, Accuracy: 1514/5000 (30%)\n",
      "[epoch 25] loss: 0.0027662\n",
      "Test set: Average loss: 3.8350, Accuracy: 1496/5000 (30%)\n",
      "[epoch 26] loss: 0.0025652\n",
      "Test set: Average loss: 3.8811, Accuracy: 1482/5000 (30%)\n",
      "[epoch 27] loss: 0.0023771\n",
      "Test set: Average loss: 3.9218, Accuracy: 1471/5000 (29%)\n",
      "[epoch 28] loss: 0.0022559\n",
      "Test set: Average loss: 3.9563, Accuracy: 1476/5000 (30%)\n",
      "[epoch 29] loss: 0.0020007\n",
      "Test set: Average loss: 3.9824, Accuracy: 1467/5000 (29%)\n",
      "[epoch 30] loss: 0.0018883\n",
      "Test set: Average loss: 4.0028, Accuracy: 1476/5000 (30%)\n",
      "[epoch 31] loss: 0.0016482\n",
      "Test set: Average loss: 4.0180, Accuracy: 1476/5000 (30%)\n",
      "[epoch 32] loss: 0.0015371\n",
      "Test set: Average loss: 4.0292, Accuracy: 1490/5000 (30%)\n",
      "[epoch 33] loss: 0.0013902\n",
      "Test set: Average loss: 4.0389, Accuracy: 1492/5000 (30%)\n",
      "[epoch 34] loss: 0.0013365\n",
      "Test set: Average loss: 4.0481, Accuracy: 1497/5000 (30%)\n",
      "[epoch 35] loss: 0.0012889\n",
      "Test set: Average loss: 4.0571, Accuracy: 1494/5000 (30%)\n",
      "[epoch 36] loss: 0.0012063\n",
      "Test set: Average loss: 4.0662, Accuracy: 1491/5000 (30%)\n",
      "[epoch 37] loss: 0.0011739\n",
      "Test set: Average loss: 4.0743, Accuracy: 1491/5000 (30%)\n",
      "[epoch 38] loss: 0.0011737\n",
      "Test set: Average loss: 4.0817, Accuracy: 1492/5000 (30%)\n",
      "[epoch 39] loss: 0.0010754\n",
      "Test set: Average loss: 4.0884, Accuracy: 1496/5000 (30%)\n",
      "[epoch 40] loss: 0.0010678\n",
      "Test set: Average loss: 4.0948, Accuracy: 1496/5000 (30%)\n",
      "[epoch 41] loss: 0.0010347\n",
      "Test set: Average loss: 4.1015, Accuracy: 1495/5000 (30%)\n",
      "[epoch 42] loss: 0.0009886\n",
      "Test set: Average loss: 4.1088, Accuracy: 1495/5000 (30%)\n",
      "[epoch 43] loss: 0.0009498\n",
      "Test set: Average loss: 4.1161, Accuracy: 1496/5000 (30%)\n",
      "[epoch 44] loss: 0.0009438\n",
      "Test set: Average loss: 4.1244, Accuracy: 1495/5000 (30%)\n",
      "[epoch 45] loss: 0.0009253\n",
      "Test set: Average loss: 4.1325, Accuracy: 1498/5000 (30%)\n",
      "[epoch 46] loss: 0.0008638\n",
      "Test set: Average loss: 4.1404, Accuracy: 1498/5000 (30%)\n",
      "[epoch 47] loss: 0.0009211\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.1476, Accuracy: 1499/5000 (30%)\n",
      "[epoch 48] loss: 0.0009111\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.1483, Accuracy: 1499/5000 (30%)\n",
      "[epoch 49] loss: 0.0008440\n",
      "Test set: Average loss: 4.1484, Accuracy: 1499/5000 (30%)\n",
      "[epoch 50] loss: 0.0008647\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.1484, Accuracy: 1499/5000 (30%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5244, Accuracy: 1571/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.4687, Accuracy: 3164/10000 (32%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3058, Accuracy: 333/5000 (7%)\n",
      "[epoch 1] loss: 2.2872827\n",
      "Test set: Average loss: 2.2006, Accuracy: 1226/5000 (25%)\n",
      "[epoch 2] loss: 1.9946970\n",
      "Test set: Average loss: 2.1049, Accuracy: 1119/5000 (22%)\n",
      "[epoch 3] loss: 1.6528364\n",
      "Test set: Average loss: 2.0023, Accuracy: 1220/5000 (24%)\n",
      "[epoch 4] loss: 1.4270384\n",
      "Test set: Average loss: 1.9281, Accuracy: 1510/5000 (30%)\n",
      "[epoch 5] loss: 1.1996430\n",
      "Test set: Average loss: 1.8707, Accuracy: 1751/5000 (35%)\n",
      "[epoch 6] loss: 0.9691826\n",
      "Test set: Average loss: 1.9068, Accuracy: 1589/5000 (32%)\n",
      "[epoch 7] loss: 0.7465815\n",
      "Test set: Average loss: 1.9827, Accuracy: 1626/5000 (33%)\n",
      "[epoch 8] loss: 0.6335959\n",
      "Test set: Average loss: 2.0004, Accuracy: 1682/5000 (34%)\n",
      "[epoch 9] loss: 0.4864381\n",
      "Test set: Average loss: 2.0745, Accuracy: 1667/5000 (33%)\n",
      "[epoch 10] loss: 0.3443187\n",
      "Test set: Average loss: 2.1823, Accuracy: 1662/5000 (33%)\n",
      "[epoch 11] loss: 0.2565287\n",
      "Test set: Average loss: 2.2006, Accuracy: 1619/5000 (32%)\n",
      "[epoch 12] loss: 0.1526290\n",
      "Test set: Average loss: 2.2689, Accuracy: 1592/5000 (32%)\n",
      "[epoch 13] loss: 0.1102969\n",
      "Test set: Average loss: 2.3262, Accuracy: 1643/5000 (33%)\n",
      "[epoch 14] loss: 0.0760771\n",
      "Test set: Average loss: 2.4364, Accuracy: 1656/5000 (33%)\n",
      "[epoch 15] loss: 0.0478019\n",
      "Test set: Average loss: 2.5721, Accuracy: 1616/5000 (32%)\n",
      "[epoch 16] loss: 0.0270574\n",
      "Test set: Average loss: 2.7400, Accuracy: 1577/5000 (32%)\n",
      "[epoch 17] loss: 0.0178590\n",
      "Test set: Average loss: 2.9175, Accuracy: 1523/5000 (30%)\n",
      "[epoch 18] loss: 0.0140598\n",
      "Test set: Average loss: 3.0479, Accuracy: 1510/5000 (30%)\n",
      "[epoch 19] loss: 0.0116375\n",
      "Test set: Average loss: 3.1329, Accuracy: 1496/5000 (30%)\n",
      "[epoch 20] loss: 0.0089556\n",
      "Test set: Average loss: 3.1732, Accuracy: 1515/5000 (30%)\n",
      "[epoch 21] loss: 0.0068289\n",
      "Test set: Average loss: 3.1999, Accuracy: 1504/5000 (30%)\n",
      "[epoch 22] loss: 0.0050554\n",
      "Test set: Average loss: 3.2190, Accuracy: 1521/5000 (30%)\n",
      "[epoch 23] loss: 0.0042927\n",
      "Test set: Average loss: 3.2344, Accuracy: 1532/5000 (31%)\n",
      "[epoch 24] loss: 0.0034313\n",
      "Test set: Average loss: 3.2509, Accuracy: 1543/5000 (31%)\n",
      "[epoch 25] loss: 0.0030320\n",
      "Test set: Average loss: 3.2671, Accuracy: 1542/5000 (31%)\n",
      "[epoch 26] loss: 0.0025625\n",
      "Test set: Average loss: 3.2850, Accuracy: 1548/5000 (31%)\n",
      "[epoch 27] loss: 0.0022484\n",
      "Test set: Average loss: 3.3040, Accuracy: 1554/5000 (31%)\n",
      "[epoch 28] loss: 0.0020720\n",
      "Test set: Average loss: 3.3231, Accuracy: 1552/5000 (31%)\n",
      "[epoch 29] loss: 0.0018768\n",
      "Test set: Average loss: 3.3449, Accuracy: 1547/5000 (31%)\n",
      "[epoch 30] loss: 0.0018896\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.3657, Accuracy: 1547/5000 (31%)\n",
      "[epoch 31] loss: 0.0015503\n",
      "Test set: Average loss: 3.3677, Accuracy: 1547/5000 (31%)\n",
      "[epoch 32] loss: 0.0015755\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.3695, Accuracy: 1548/5000 (31%)\n",
      "[epoch 33] loss: 0.0015628\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 34] loss: 0.0015418\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 35] loss: 0.0015076\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 36] loss: 0.0016173\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 37] loss: 0.0016412\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 38] loss: 0.0016063\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 39] loss: 0.0015739\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 40] loss: 0.0016854\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 41] loss: 0.0016300\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 42] loss: 0.0015533\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 43] loss: 0.0016414\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 44] loss: 0.0015547\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 45] loss: 0.0016753\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 46] loss: 0.0017335\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 47] loss: 0.0016769\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 48] loss: 0.0015824\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 49] loss: 0.0016097\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "[epoch 50] loss: 0.0016065\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.3697, Accuracy: 1548/5000 (31%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8707, Accuracy: 1751/5000 (35%)\n",
      "Test\n",
      "Test set: Average loss: 1.8577, Accuracy: 3522/10000 (35%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3070, Accuracy: 340/5000 (7%)\n",
      "[epoch 1] loss: 2.2849089\n",
      "Test set: Average loss: 2.2440, Accuracy: 764/5000 (15%)\n",
      "[epoch 2] loss: 2.0730821\n",
      "Test set: Average loss: 2.2428, Accuracy: 865/5000 (17%)\n",
      "[epoch 3] loss: 1.7643590\n",
      "Test set: Average loss: 2.2675, Accuracy: 958/5000 (19%)\n",
      "[epoch 4] loss: 1.4916601\n",
      "Test set: Average loss: 2.1122, Accuracy: 1124/5000 (22%)\n",
      "[epoch 5] loss: 1.2007732\n",
      "Test set: Average loss: 2.0450, Accuracy: 1206/5000 (24%)\n",
      "[epoch 6] loss: 0.9480729\n",
      "Test set: Average loss: 2.0608, Accuracy: 1309/5000 (26%)\n",
      "[epoch 7] loss: 0.7588140\n",
      "Test set: Average loss: 2.1725, Accuracy: 1284/5000 (26%)\n",
      "[epoch 8] loss: 0.5760851\n",
      "Test set: Average loss: 2.2829, Accuracy: 1289/5000 (26%)\n",
      "[epoch 9] loss: 0.4051804\n",
      "Test set: Average loss: 2.4512, Accuracy: 1270/5000 (25%)\n",
      "[epoch 10] loss: 0.3284651\n",
      "Test set: Average loss: 2.4760, Accuracy: 1322/5000 (26%)\n",
      "[epoch 11] loss: 0.2212829\n",
      "Test set: Average loss: 2.6329, Accuracy: 1358/5000 (27%)\n",
      "[epoch 12] loss: 0.1675719\n",
      "Test set: Average loss: 2.8956, Accuracy: 1323/5000 (26%)\n",
      "[epoch 13] loss: 0.1023877\n",
      "Test set: Average loss: 3.1295, Accuracy: 1306/5000 (26%)\n",
      "[epoch 14] loss: 0.0802804\n",
      "Test set: Average loss: 3.2613, Accuracy: 1313/5000 (26%)\n",
      "[epoch 15] loss: 0.0614974\n",
      "Test set: Average loss: 3.3547, Accuracy: 1340/5000 (27%)\n",
      "[epoch 16] loss: 0.0363146\n",
      "Test set: Average loss: 3.4894, Accuracy: 1329/5000 (27%)\n",
      "[epoch 17] loss: 0.0301718\n",
      "Test set: Average loss: 3.6245, Accuracy: 1334/5000 (27%)\n",
      "[epoch 18] loss: 0.0177338\n",
      "Test set: Average loss: 3.7802, Accuracy: 1321/5000 (26%)\n",
      "[epoch 19] loss: 0.0134565\n",
      "Test set: Average loss: 3.9393, Accuracy: 1331/5000 (27%)\n",
      "[epoch 20] loss: 0.0109332\n",
      "Test set: Average loss: 4.0907, Accuracy: 1293/5000 (26%)\n",
      "[epoch 21] loss: 0.0073479\n",
      "Test set: Average loss: 4.2299, Accuracy: 1291/5000 (26%)\n",
      "[epoch 22] loss: 0.0055275\n",
      "Test set: Average loss: 4.3472, Accuracy: 1275/5000 (26%)\n",
      "[epoch 23] loss: 0.0047095\n",
      "Test set: Average loss: 4.4259, Accuracy: 1271/5000 (25%)\n",
      "[epoch 24] loss: 0.0041593\n",
      "Test set: Average loss: 4.4634, Accuracy: 1276/5000 (26%)\n",
      "[epoch 25] loss: 0.0034460\n",
      "Test set: Average loss: 4.4709, Accuracy: 1294/5000 (26%)\n",
      "[epoch 26] loss: 0.0028813\n",
      "Test set: Average loss: 4.4676, Accuracy: 1289/5000 (26%)\n",
      "[epoch 27] loss: 0.0024767\n",
      "Test set: Average loss: 4.4628, Accuracy: 1290/5000 (26%)\n",
      "[epoch 28] loss: 0.0021375\n",
      "Test set: Average loss: 4.4596, Accuracy: 1295/5000 (26%)\n",
      "[epoch 29] loss: 0.0018353\n",
      "Test set: Average loss: 4.4625, Accuracy: 1291/5000 (26%)\n",
      "[epoch 30] loss: 0.0017213\n",
      "Test set: Average loss: 4.4684, Accuracy: 1294/5000 (26%)\n",
      "[epoch 31] loss: 0.0016844\n",
      "Test set: Average loss: 4.4800, Accuracy: 1293/5000 (26%)\n",
      "[epoch 32] loss: 0.0016123\n",
      "Test set: Average loss: 4.4953, Accuracy: 1296/5000 (26%)\n",
      "[epoch 33] loss: 0.0013095\n",
      "Test set: Average loss: 4.5130, Accuracy: 1302/5000 (26%)\n",
      "[epoch 34] loss: 0.0013832\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.5311, Accuracy: 1306/5000 (26%)\n",
      "[epoch 35] loss: 0.0013620\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.5331, Accuracy: 1304/5000 (26%)\n",
      "[epoch 36] loss: 0.0013200\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 37] loss: 0.0012496\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 38] loss: 0.0013426\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 39] loss: 0.0013195\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 40] loss: 0.0013086\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 41] loss: 0.0012951\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 42] loss: 0.0013201\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 43] loss: 0.0012751\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 44] loss: 0.0012965\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 45] loss: 0.0012075\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 46] loss: 0.0014018\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 47] loss: 0.0013084\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 48] loss: 0.0012091\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 49] loss: 0.0012918\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "[epoch 50] loss: 0.0012858\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 4.5333, Accuracy: 1304/5000 (26%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6329, Accuracy: 1358/5000 (27%)\n",
      "Test\n",
      "Test set: Average loss: 2.6075, Accuracy: 2708/10000 (27%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 695/5000 (14%)\n",
      "[epoch 1] loss: 2.2930464\n",
      "Test set: Average loss: 2.1484, Accuracy: 948/5000 (19%)\n",
      "[epoch 2] loss: 1.8230378\n",
      "Test set: Average loss: 2.0630, Accuracy: 997/5000 (20%)\n",
      "[epoch 3] loss: 2.1335616\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9885, Accuracy: 1328/5000 (27%)\n",
      "[epoch 4] loss: 1.3936639\n",
      "Test set: Average loss: 1.9772, Accuracy: 1382/5000 (28%)\n",
      "[epoch 5] loss: 1.4165543\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9630, Accuracy: 1460/5000 (29%)\n",
      "[epoch 6] loss: 1.3733654\n",
      "Test set: Average loss: 1.9623, Accuracy: 1457/5000 (29%)\n",
      "[epoch 7] loss: 1.4696212\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 8] loss: 1.3978565\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 9] loss: 1.3969947\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 10] loss: 1.2981101\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 11] loss: 1.3500932\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 12] loss: 1.3106986\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 13] loss: 1.3862773\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 14] loss: 1.2561075\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 15] loss: 1.3942020\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 16] loss: 1.3095357\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 17] loss: 1.4225526\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 18] loss: 2.0028374\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 19] loss: 1.3773549\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 20] loss: 1.3685596\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 21] loss: 1.3112724\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 22] loss: 1.3479680\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 23] loss: 1.4032910\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 24] loss: 1.3652563\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 25] loss: 1.3903635\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 26] loss: 1.3524902\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 27] loss: 1.4318011\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 28] loss: 1.3896440\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 29] loss: 1.3318025\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 30] loss: 1.3751044\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 31] loss: 1.3767582\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 32] loss: 1.3455950\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 33] loss: 1.7463056\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 34] loss: 1.3213238\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 35] loss: 1.2721838\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 36] loss: 1.4475577\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 37] loss: 1.3399126\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 38] loss: 1.4190932\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 39] loss: 1.2011621\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 40] loss: 1.2737731\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 41] loss: 1.2856067\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 42] loss: 1.4578725\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 43] loss: 1.2823832\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 44] loss: 1.3836161\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 45] loss: 1.3434247\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 46] loss: 1.2696660\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 47] loss: 1.3511051\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 48] loss: 1.2982996\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 49] loss: 1.4718839\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "[epoch 50] loss: 1.4216558\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 1.9620, Accuracy: 1459/5000 (29%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9630, Accuracy: 1460/5000 (29%)\n",
      "Test\n",
      "Test set: Average loss: 1.9218, Accuracy: 2995/10000 (30%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3038, Accuracy: 94/5000 (2%)\n",
      "[epoch 1] loss: 2.2033722\n",
      "Test set: Average loss: 2.0924, Accuracy: 1416/5000 (28%)\n",
      "[epoch 2] loss: 1.8388750\n",
      "Test set: Average loss: 1.9873, Accuracy: 1413/5000 (28%)\n",
      "[epoch 3] loss: 1.5280072\n",
      "Test set: Average loss: 1.7927, Accuracy: 1727/5000 (35%)\n",
      "[epoch 4] loss: 1.2148720\n",
      "Test set: Average loss: 1.6865, Accuracy: 1961/5000 (39%)\n",
      "[epoch 5] loss: 1.0637543\n",
      "Test set: Average loss: 1.5912, Accuracy: 2152/5000 (43%)\n",
      "[epoch 6] loss: 0.9164189\n",
      "Test set: Average loss: 1.6126, Accuracy: 2130/5000 (43%)\n",
      "[epoch 7] loss: 0.8645197\n",
      "Test set: Average loss: 1.6665, Accuracy: 2103/5000 (42%)\n",
      "[epoch 8] loss: 0.6317677\n",
      "Test set: Average loss: 1.7613, Accuracy: 2073/5000 (41%)\n",
      "[epoch 9] loss: 0.6326022\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7111, Accuracy: 2115/5000 (42%)\n",
      "[epoch 10] loss: 1.9372944\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.6869, Accuracy: 2147/5000 (43%)\n",
      "[epoch 11] loss: 0.5097271\n",
      "Test set: Average loss: 1.6832, Accuracy: 2147/5000 (43%)\n",
      "[epoch 12] loss: 0.4349697\n",
      "Test set: Average loss: 1.6788, Accuracy: 2154/5000 (43%)\n",
      "[epoch 13] loss: 0.5311935\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.6747, Accuracy: 2152/5000 (43%)\n",
      "[epoch 14] loss: 0.4386515\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 15] loss: 0.7253204\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 16] loss: 0.6449722\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 17] loss: 0.4290478\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 18] loss: 0.5563691\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 19] loss: 0.5283190\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 20] loss: 0.4774077\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 21] loss: 0.4589444\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 22] loss: 0.4212867\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 23] loss: 0.5263570\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 24] loss: 0.5132473\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 25] loss: 0.5655320\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 26] loss: 0.4869730\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 27] loss: 0.4706370\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 28] loss: 0.5399080\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 29] loss: 0.4384174\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 30] loss: 0.5032522\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 31] loss: 0.5194887\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 32] loss: 0.4911220\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 33] loss: 0.4862685\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 34] loss: 0.4551170\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 35] loss: 0.5398415\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 36] loss: 0.4231691\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 37] loss: 0.4106402\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 38] loss: 0.5592861\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 39] loss: 0.5414583\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 40] loss: 0.4756373\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 41] loss: 0.5583429\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 42] loss: 0.5875830\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 43] loss: 0.4233477\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 44] loss: 0.5172506\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 45] loss: 0.4296293\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 46] loss: 0.4831017\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 47] loss: 0.5881879\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 48] loss: 1.7218426\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 49] loss: 0.4465902\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "[epoch 50] loss: 0.4646700\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.6743, Accuracy: 2152/5000 (43%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6788, Accuracy: 2154/5000 (43%)\n",
      "Test\n",
      "Test set: Average loss: 1.6580, Accuracy: 4364/10000 (44%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2894, Accuracy: 919/5000 (18%)\n",
      "[epoch 1] loss: 2.1246338\n",
      "Test set: Average loss: 2.2614, Accuracy: 738/5000 (15%)\n",
      "[epoch 2] loss: 1.8415686\n",
      "Test set: Average loss: 2.1547, Accuracy: 1101/5000 (22%)\n",
      "[epoch 3] loss: 1.5556252\n",
      "Test set: Average loss: 2.0870, Accuracy: 1361/5000 (27%)\n",
      "[epoch 4] loss: 1.4424081\n",
      "Test set: Average loss: 1.8924, Accuracy: 1572/5000 (31%)\n",
      "[epoch 5] loss: 1.0720450\n",
      "Test set: Average loss: 2.0018, Accuracy: 1459/5000 (29%)\n",
      "[epoch 6] loss: 1.1234594\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0074, Accuracy: 1559/5000 (31%)\n",
      "[epoch 7] loss: 0.8841648\n",
      "Test set: Average loss: 1.9977, Accuracy: 1567/5000 (31%)\n",
      "[epoch 8] loss: 0.8500013\n",
      "Test set: Average loss: 1.9734, Accuracy: 1603/5000 (32%)\n",
      "[epoch 9] loss: 0.9232539\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9481, Accuracy: 1647/5000 (33%)\n",
      "[epoch 10] loss: 0.8582976\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.9437, Accuracy: 1648/5000 (33%)\n",
      "[epoch 11] loss: 0.7333023\n",
      "Test set: Average loss: 1.9434, Accuracy: 1647/5000 (33%)\n",
      "[epoch 12] loss: 0.9366737\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 13] loss: 0.7463528\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 14] loss: 0.8080799\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 15] loss: 0.9556374\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 16] loss: 0.7968424\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 17] loss: 0.8089280\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 18] loss: 0.8126163\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 19] loss: 0.8738625\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 20] loss: 0.8448435\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 21] loss: 0.7821314\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 22] loss: 0.7799073\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 23] loss: 0.7694089\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 24] loss: 0.7368815\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 25] loss: 0.8779685\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 26] loss: 0.8560636\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 27] loss: 0.9009121\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 28] loss: 0.8282971\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 29] loss: 0.8409603\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 30] loss: 0.8191500\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 31] loss: 0.8663906\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 32] loss: 0.7033473\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 33] loss: 0.7981018\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 34] loss: 0.8523232\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 35] loss: 0.8258193\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 36] loss: 0.7703176\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] loss: 0.7898788\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 38] loss: 0.8055096\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 39] loss: 0.8342242\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 40] loss: 0.7650633\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 41] loss: 0.7009515\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 42] loss: 0.7626336\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 43] loss: 0.8341036\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 44] loss: 0.7152371\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 45] loss: 0.7558314\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 46] loss: 0.7501428\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 47] loss: 0.8113280\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 48] loss: 0.7980363\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 49] loss: 0.7550624\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "[epoch 50] loss: 0.8539009\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9430, Accuracy: 1648/5000 (33%)\n",
      "Test\n",
      "Test set: Average loss: 1.9414, Accuracy: 3376/10000 (34%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3008, Accuracy: 887/5000 (18%)\n",
      "[epoch 1] loss: 2.1088264\n",
      "Test set: Average loss: 1.8158, Accuracy: 1780/5000 (36%)\n",
      "[epoch 2] loss: 1.6312357\n",
      "Test set: Average loss: 1.6801, Accuracy: 2050/5000 (41%)\n",
      "[epoch 3] loss: 1.4296711\n",
      "Test set: Average loss: 1.6439, Accuracy: 2068/5000 (41%)\n",
      "[epoch 4] loss: 1.1893742\n",
      "Test set: Average loss: 1.4955, Accuracy: 2475/5000 (50%)\n",
      "[epoch 5] loss: 1.0264485\n",
      "Test set: Average loss: 1.4548, Accuracy: 2462/5000 (49%)\n",
      "[epoch 6] loss: 0.8065769\n",
      "Test set: Average loss: 1.5615, Accuracy: 2409/5000 (48%)\n",
      "[epoch 7] loss: 0.6387149\n",
      "Test set: Average loss: 1.5735, Accuracy: 2451/5000 (49%)\n",
      "[epoch 8] loss: 0.4877966\n",
      "Test set: Average loss: 1.6899, Accuracy: 2389/5000 (48%)\n",
      "[epoch 9] loss: 0.3503307\n",
      "Test set: Average loss: 1.5438, Accuracy: 2571/5000 (51%)\n",
      "[epoch 10] loss: 0.2499705\n",
      "Test set: Average loss: 1.8384, Accuracy: 2445/5000 (49%)\n",
      "[epoch 11] loss: 0.1855705\n",
      "Test set: Average loss: 1.7422, Accuracy: 2531/5000 (51%)\n",
      "[epoch 12] loss: 0.1440149\n",
      "Test set: Average loss: 2.2323, Accuracy: 2161/5000 (43%)\n",
      "[epoch 13] loss: 0.1165018\n",
      "Test set: Average loss: 2.0481, Accuracy: 2407/5000 (48%)\n",
      "[epoch 14] loss: 0.0712855\n",
      "Test set: Average loss: 1.9721, Accuracy: 2426/5000 (49%)\n",
      "[epoch 15] loss: 0.0645686\n",
      "Test set: Average loss: 2.2102, Accuracy: 2387/5000 (48%)\n",
      "[epoch 16] loss: 0.0349100\n",
      "Test set: Average loss: 2.1286, Accuracy: 2432/5000 (49%)\n",
      "[epoch 17] loss: 0.0248449\n",
      "Test set: Average loss: 2.2249, Accuracy: 2434/5000 (49%)\n",
      "[epoch 18] loss: 0.0159524\n",
      "Test set: Average loss: 2.3918, Accuracy: 2347/5000 (47%)\n",
      "[epoch 19] loss: 0.0112962\n",
      "Test set: Average loss: 2.2969, Accuracy: 2399/5000 (48%)\n",
      "[epoch 20] loss: 0.0089137\n",
      "Test set: Average loss: 2.2963, Accuracy: 2415/5000 (48%)\n",
      "[epoch 21] loss: 0.0072530\n",
      "Test set: Average loss: 2.3605, Accuracy: 2407/5000 (48%)\n",
      "[epoch 22] loss: 0.0062503\n",
      "Test set: Average loss: 2.3919, Accuracy: 2407/5000 (48%)\n",
      "[epoch 23] loss: 0.0055606\n",
      "Test set: Average loss: 2.4079, Accuracy: 2415/5000 (48%)\n",
      "[epoch 24] loss: 0.0050766\n",
      "Test set: Average loss: 2.4251, Accuracy: 2412/5000 (48%)\n",
      "[epoch 25] loss: 0.0046623\n",
      "Test set: Average loss: 2.4434, Accuracy: 2408/5000 (48%)\n",
      "[epoch 26] loss: 0.0042822\n",
      "Test set: Average loss: 2.4614, Accuracy: 2400/5000 (48%)\n",
      "[epoch 27] loss: 0.0040190\n",
      "Test set: Average loss: 2.4710, Accuracy: 2402/5000 (48%)\n",
      "[epoch 28] loss: 0.0036887\n",
      "Test set: Average loss: 2.4957, Accuracy: 2405/5000 (48%)\n",
      "[epoch 29] loss: 0.0034668\n",
      "Test set: Average loss: 2.5097, Accuracy: 2403/5000 (48%)\n",
      "[epoch 30] loss: 0.0032291\n",
      "Test set: Average loss: 2.5270, Accuracy: 2404/5000 (48%)\n",
      "[epoch 31] loss: 0.0030103\n",
      "Test set: Average loss: 2.5373, Accuracy: 2401/5000 (48%)\n",
      "[epoch 32] loss: 0.0028401\n",
      "Test set: Average loss: 2.5561, Accuracy: 2400/5000 (48%)\n",
      "[epoch 33] loss: 0.0027121\n",
      "Test set: Average loss: 2.5674, Accuracy: 2393/5000 (48%)\n",
      "[epoch 34] loss: 0.0025396\n",
      "Test set: Average loss: 2.5821, Accuracy: 2395/5000 (48%)\n",
      "[epoch 35] loss: 0.0024145\n",
      "Test set: Average loss: 2.5958, Accuracy: 2396/5000 (48%)\n",
      "[epoch 36] loss: 0.0022914\n",
      "Test set: Average loss: 2.6017, Accuracy: 2396/5000 (48%)\n",
      "[epoch 37] loss: 0.0022011\n",
      "Test set: Average loss: 2.6177, Accuracy: 2397/5000 (48%)\n",
      "[epoch 38] loss: 0.0020719\n",
      "Test set: Average loss: 2.6256, Accuracy: 2393/5000 (48%)\n",
      "[epoch 39] loss: 0.0019914\n",
      "Test set: Average loss: 2.6353, Accuracy: 2388/5000 (48%)\n",
      "[epoch 40] loss: 0.0018937\n",
      "Test set: Average loss: 2.6488, Accuracy: 2391/5000 (48%)\n",
      "[epoch 41] loss: 0.0018206\n",
      "Test set: Average loss: 2.6589, Accuracy: 2393/5000 (48%)\n",
      "[epoch 42] loss: 0.0017254\n",
      "Test set: Average loss: 2.6672, Accuracy: 2392/5000 (48%)\n",
      "[epoch 43] loss: 0.0016665\n",
      "Test set: Average loss: 2.6780, Accuracy: 2390/5000 (48%)\n",
      "[epoch 44] loss: 0.0015979\n",
      "Test set: Average loss: 2.6884, Accuracy: 2387/5000 (48%)\n",
      "[epoch 45] loss: 0.0015421\n",
      "Test set: Average loss: 2.6977, Accuracy: 2387/5000 (48%)\n",
      "[epoch 46] loss: 0.0014804\n",
      "Test set: Average loss: 2.7047, Accuracy: 2388/5000 (48%)\n",
      "[epoch 47] loss: 0.0014240\n",
      "Test set: Average loss: 2.7187, Accuracy: 2388/5000 (48%)\n",
      "[epoch 48] loss: 0.0013637\n",
      "Test set: Average loss: 2.7240, Accuracy: 2388/5000 (48%)\n",
      "[epoch 49] loss: 0.0013179\n",
      "Test set: Average loss: 2.7319, Accuracy: 2388/5000 (48%)\n",
      "[epoch 50] loss: 0.0012683\n",
      "Test set: Average loss: 2.7412, Accuracy: 2390/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5438, Accuracy: 2571/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.5008, Accuracy: 5303/10000 (53%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3194, Accuracy: 215/5000 (4%)\n",
      "[epoch 1] loss: 2.1147561\n",
      "Test set: Average loss: 1.8258, Accuracy: 1879/5000 (38%)\n",
      "[epoch 2] loss: 1.5072279\n",
      "Test set: Average loss: 1.5526, Accuracy: 2196/5000 (44%)\n",
      "[epoch 3] loss: 1.0794463\n",
      "Test set: Average loss: 1.5909, Accuracy: 2260/5000 (45%)\n",
      "[epoch 4] loss: 0.8747688\n",
      "Test set: Average loss: 1.5933, Accuracy: 2317/5000 (46%)\n",
      "[epoch 5] loss: 0.7102639\n",
      "Test set: Average loss: 1.4830, Accuracy: 2507/5000 (50%)\n",
      "[epoch 6] loss: 0.5021228\n",
      "Test set: Average loss: 1.5772, Accuracy: 2482/5000 (50%)\n",
      "[epoch 7] loss: 0.3906106\n",
      "Test set: Average loss: 1.5726, Accuracy: 2535/5000 (51%)\n",
      "[epoch 8] loss: 0.2950077\n",
      "Test set: Average loss: 1.7266, Accuracy: 2477/5000 (50%)\n",
      "[epoch 9] loss: 0.2436678\n",
      "Test set: Average loss: 1.9540, Accuracy: 2325/5000 (46%)\n",
      "[epoch 10] loss: 0.1833154\n",
      "Test set: Average loss: 1.7793, Accuracy: 2521/5000 (50%)\n",
      "[epoch 11] loss: 0.1300520\n",
      "Test set: Average loss: 1.8845, Accuracy: 2529/5000 (51%)\n",
      "[epoch 12] loss: 0.0913115\n",
      "Test set: Average loss: 1.9739, Accuracy: 2525/5000 (50%)\n",
      "[epoch 13] loss: 0.0564040\n",
      "Test set: Average loss: 2.0149, Accuracy: 2528/5000 (51%)\n",
      "[epoch 14] loss: 0.0427934\n",
      "Test set: Average loss: 2.0301, Accuracy: 2543/5000 (51%)\n",
      "[epoch 15] loss: 0.0335961\n",
      "Test set: Average loss: 2.2090, Accuracy: 2504/5000 (50%)\n",
      "[epoch 16] loss: 0.0258665\n",
      "Test set: Average loss: 2.2584, Accuracy: 2482/5000 (50%)\n",
      "[epoch 17] loss: 0.0166589\n",
      "Test set: Average loss: 2.3181, Accuracy: 2486/5000 (50%)\n",
      "[epoch 18] loss: 0.0136460\n",
      "Test set: Average loss: 2.3138, Accuracy: 2471/5000 (49%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] loss: 0.0102181\n",
      "Test set: Average loss: 2.3177, Accuracy: 2520/5000 (50%)\n",
      "[epoch 20] loss: 0.0082632\n",
      "Test set: Average loss: 2.3456, Accuracy: 2525/5000 (50%)\n",
      "[epoch 21] loss: 0.0070281\n",
      "Test set: Average loss: 2.3663, Accuracy: 2534/5000 (51%)\n",
      "[epoch 22] loss: 0.0062042\n",
      "Test set: Average loss: 2.4026, Accuracy: 2526/5000 (51%)\n",
      "[epoch 23] loss: 0.0054810\n",
      "Test set: Average loss: 2.4425, Accuracy: 2513/5000 (50%)\n",
      "[epoch 24] loss: 0.0049200\n",
      "Test set: Average loss: 2.4418, Accuracy: 2522/5000 (50%)\n",
      "[epoch 25] loss: 0.0045454\n",
      "Test set: Average loss: 2.4614, Accuracy: 2526/5000 (51%)\n",
      "[epoch 26] loss: 0.0042101\n",
      "Test set: Average loss: 2.4832, Accuracy: 2520/5000 (50%)\n",
      "[epoch 27] loss: 0.0039001\n",
      "Test set: Average loss: 2.5019, Accuracy: 2515/5000 (50%)\n",
      "[epoch 28] loss: 0.0036229\n",
      "Test set: Average loss: 2.5134, Accuracy: 2512/5000 (50%)\n",
      "[epoch 29] loss: 0.0033979\n",
      "Test set: Average loss: 2.5375, Accuracy: 2512/5000 (50%)\n",
      "[epoch 30] loss: 0.0031847\n",
      "Test set: Average loss: 2.5455, Accuracy: 2516/5000 (50%)\n",
      "[epoch 31] loss: 0.0029880\n",
      "Test set: Average loss: 2.5572, Accuracy: 2512/5000 (50%)\n",
      "[epoch 32] loss: 0.0028177\n",
      "Test set: Average loss: 2.5730, Accuracy: 2510/5000 (50%)\n",
      "[epoch 33] loss: 0.0026628\n",
      "Test set: Average loss: 2.5905, Accuracy: 2507/5000 (50%)\n",
      "[epoch 34] loss: 0.0025073\n",
      "Test set: Average loss: 2.6039, Accuracy: 2502/5000 (50%)\n",
      "[epoch 35] loss: 0.0023667\n",
      "Test set: Average loss: 2.6161, Accuracy: 2503/5000 (50%)\n",
      "[epoch 36] loss: 0.0022761\n",
      "Test set: Average loss: 2.6337, Accuracy: 2498/5000 (50%)\n",
      "[epoch 37] loss: 0.0021627\n",
      "Test set: Average loss: 2.6358, Accuracy: 2501/5000 (50%)\n",
      "[epoch 38] loss: 0.0020741\n",
      "Test set: Average loss: 2.6528, Accuracy: 2501/5000 (50%)\n",
      "[epoch 39] loss: 0.0019752\n",
      "Test set: Average loss: 2.6722, Accuracy: 2494/5000 (50%)\n",
      "[epoch 40] loss: 0.0018877\n",
      "Test set: Average loss: 2.6731, Accuracy: 2497/5000 (50%)\n",
      "[epoch 41] loss: 0.0017854\n",
      "Test set: Average loss: 2.6821, Accuracy: 2500/5000 (50%)\n",
      "[epoch 42] loss: 0.0016970\n",
      "Test set: Average loss: 2.7048, Accuracy: 2492/5000 (50%)\n",
      "[epoch 43] loss: 0.0016482\n",
      "Test set: Average loss: 2.7066, Accuracy: 2494/5000 (50%)\n",
      "[epoch 44] loss: 0.0015534\n",
      "Test set: Average loss: 2.7188, Accuracy: 2496/5000 (50%)\n",
      "[epoch 45] loss: 0.0014983\n",
      "Test set: Average loss: 2.7288, Accuracy: 2489/5000 (50%)\n",
      "[epoch 46] loss: 0.0014508\n",
      "Test set: Average loss: 2.7364, Accuracy: 2488/5000 (50%)\n",
      "[epoch 47] loss: 0.0013916\n",
      "Test set: Average loss: 2.7486, Accuracy: 2493/5000 (50%)\n",
      "[epoch 48] loss: 0.0013379\n",
      "Test set: Average loss: 2.7536, Accuracy: 2491/5000 (50%)\n",
      "[epoch 49] loss: 0.0012967\n",
      "Test set: Average loss: 2.7621, Accuracy: 2491/5000 (50%)\n",
      "[epoch 50] loss: 0.0012460\n",
      "Test set: Average loss: 2.7703, Accuracy: 2494/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0301, Accuracy: 2543/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.9736, Accuracy: 5116/10000 (51%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3285, Accuracy: 90/5000 (2%)\n",
      "[epoch 1] loss: 2.1969491\n",
      "Test set: Average loss: 1.9611, Accuracy: 1660/5000 (33%)\n",
      "[epoch 2] loss: 1.7057103\n",
      "Test set: Average loss: 1.6175, Accuracy: 2106/5000 (42%)\n",
      "[epoch 3] loss: 1.3088673\n",
      "Test set: Average loss: 1.5297, Accuracy: 2269/5000 (45%)\n",
      "[epoch 4] loss: 1.0486465\n",
      "Test set: Average loss: 1.4361, Accuracy: 2463/5000 (49%)\n",
      "[epoch 5] loss: 0.8427551\n",
      "Test set: Average loss: 1.4653, Accuracy: 2528/5000 (51%)\n",
      "[epoch 6] loss: 0.7326505\n",
      "Test set: Average loss: 1.6112, Accuracy: 2349/5000 (47%)\n",
      "[epoch 7] loss: 0.5021952\n",
      "Test set: Average loss: 1.5336, Accuracy: 2563/5000 (51%)\n",
      "[epoch 8] loss: 0.3884250\n",
      "Test set: Average loss: 1.7129, Accuracy: 2432/5000 (49%)\n",
      "[epoch 9] loss: 0.2546538\n",
      "Test set: Average loss: 1.7765, Accuracy: 2459/5000 (49%)\n",
      "[epoch 10] loss: 0.2135759\n",
      "Test set: Average loss: 1.8633, Accuracy: 2430/5000 (49%)\n",
      "[epoch 11] loss: 0.1397017\n",
      "Test set: Average loss: 1.9638, Accuracy: 2438/5000 (49%)\n",
      "[epoch 12] loss: 0.1046692\n",
      "Test set: Average loss: 2.0587, Accuracy: 2411/5000 (48%)\n",
      "[epoch 13] loss: 0.0649121\n",
      "Test set: Average loss: 2.0498, Accuracy: 2442/5000 (49%)\n",
      "[epoch 14] loss: 0.0509133\n",
      "Test set: Average loss: 2.1658, Accuracy: 2449/5000 (49%)\n",
      "[epoch 15] loss: 0.0323748\n",
      "Test set: Average loss: 2.2395, Accuracy: 2475/5000 (50%)\n",
      "[epoch 16] loss: 0.0235089\n",
      "Test set: Average loss: 2.2706, Accuracy: 2445/5000 (49%)\n",
      "[epoch 17] loss: 0.0137126\n",
      "Test set: Average loss: 2.3169, Accuracy: 2428/5000 (49%)\n",
      "[epoch 18] loss: 0.0113652\n",
      "Test set: Average loss: 2.3707, Accuracy: 2439/5000 (49%)\n",
      "[epoch 19] loss: 0.0083281\n",
      "Test set: Average loss: 2.3712, Accuracy: 2442/5000 (49%)\n",
      "[epoch 20] loss: 0.0066958\n",
      "Test set: Average loss: 2.3848, Accuracy: 2455/5000 (49%)\n",
      "[epoch 21] loss: 0.0060224\n",
      "Test set: Average loss: 2.4164, Accuracy: 2442/5000 (49%)\n",
      "[epoch 22] loss: 0.0052750\n",
      "Test set: Average loss: 2.4488, Accuracy: 2437/5000 (49%)\n",
      "[epoch 23] loss: 0.0047999\n",
      "Test set: Average loss: 2.4602, Accuracy: 2431/5000 (49%)\n",
      "[epoch 24] loss: 0.0043724\n",
      "Test set: Average loss: 2.4667, Accuracy: 2427/5000 (49%)\n",
      "[epoch 25] loss: 0.0040481\n",
      "Test set: Average loss: 2.4951, Accuracy: 2422/5000 (48%)\n",
      "[epoch 26] loss: 0.0037554\n",
      "Test set: Average loss: 2.5143, Accuracy: 2428/5000 (49%)\n",
      "[epoch 27] loss: 0.0035080\n",
      "Test set: Average loss: 2.5236, Accuracy: 2423/5000 (48%)\n",
      "[epoch 28] loss: 0.0032630\n",
      "Test set: Average loss: 2.5391, Accuracy: 2417/5000 (48%)\n",
      "[epoch 29] loss: 0.0030744\n",
      "Test set: Average loss: 2.5553, Accuracy: 2411/5000 (48%)\n",
      "[epoch 30] loss: 0.0029335\n",
      "Test set: Average loss: 2.5689, Accuracy: 2413/5000 (48%)\n",
      "[epoch 31] loss: 0.0027544\n",
      "Test set: Average loss: 2.5815, Accuracy: 2414/5000 (48%)\n",
      "[epoch 32] loss: 0.0025974\n",
      "Test set: Average loss: 2.5968, Accuracy: 2406/5000 (48%)\n",
      "[epoch 33] loss: 0.0024613\n",
      "Test set: Average loss: 2.6064, Accuracy: 2410/5000 (48%)\n",
      "[epoch 34] loss: 0.0023393\n",
      "Test set: Average loss: 2.6196, Accuracy: 2407/5000 (48%)\n",
      "[epoch 35] loss: 0.0022251\n",
      "Test set: Average loss: 2.6307, Accuracy: 2405/5000 (48%)\n",
      "[epoch 36] loss: 0.0021244\n",
      "Test set: Average loss: 2.6438, Accuracy: 2408/5000 (48%)\n",
      "[epoch 37] loss: 0.0020294\n",
      "Test set: Average loss: 2.6533, Accuracy: 2400/5000 (48%)\n",
      "[epoch 38] loss: 0.0019362\n",
      "Test set: Average loss: 2.6658, Accuracy: 2398/5000 (48%)\n",
      "[epoch 39] loss: 0.0018572\n",
      "Test set: Average loss: 2.6783, Accuracy: 2405/5000 (48%)\n",
      "[epoch 40] loss: 0.0017777\n",
      "Test set: Average loss: 2.6902, Accuracy: 2403/5000 (48%)\n",
      "[epoch 41] loss: 0.0017158\n",
      "Test set: Average loss: 2.6955, Accuracy: 2401/5000 (48%)\n",
      "[epoch 42] loss: 0.0016541\n",
      "Test set: Average loss: 2.7021, Accuracy: 2401/5000 (48%)\n",
      "[epoch 43] loss: 0.0015812\n",
      "Test set: Average loss: 2.7182, Accuracy: 2400/5000 (48%)\n",
      "[epoch 44] loss: 0.0015219\n",
      "Test set: Average loss: 2.7271, Accuracy: 2403/5000 (48%)\n",
      "[epoch 45] loss: 0.0014561\n",
      "Test set: Average loss: 2.7360, Accuracy: 2402/5000 (48%)\n",
      "[epoch 46] loss: 0.0014031\n",
      "Test set: Average loss: 2.7465, Accuracy: 2400/5000 (48%)\n",
      "[epoch 47] loss: 0.0013467\n",
      "Test set: Average loss: 2.7527, Accuracy: 2400/5000 (48%)\n",
      "[epoch 48] loss: 0.0013084\n",
      "Test set: Average loss: 2.7624, Accuracy: 2397/5000 (48%)\n",
      "[epoch 49] loss: 0.0012584\n",
      "Test set: Average loss: 2.7692, Accuracy: 2400/5000 (48%)\n",
      "[epoch 50] loss: 0.0012160\n",
      "Test set: Average loss: 2.7763, Accuracy: 2401/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5336, Accuracy: 2563/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.5020, Accuracy: 5161/10000 (52%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3184, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 1.8823551\n",
      "Test set: Average loss: 1.6611, Accuracy: 2012/5000 (40%)\n",
      "[epoch 2] loss: 1.4087876\n",
      "Test set: Average loss: 1.4638, Accuracy: 2392/5000 (48%)\n",
      "[epoch 3] loss: 1.1434982\n",
      "Test set: Average loss: 1.3510, Accuracy: 2579/5000 (52%)\n",
      "[epoch 4] loss: 0.8956335\n",
      "Test set: Average loss: 1.3180, Accuracy: 2705/5000 (54%)\n",
      "[epoch 5] loss: 0.7530483\n",
      "Test set: Average loss: 1.4929, Accuracy: 2612/5000 (52%)\n",
      "[epoch 6] loss: 0.5960269\n",
      "Test set: Average loss: 1.4803, Accuracy: 2640/5000 (53%)\n",
      "[epoch 7] loss: 0.4484889\n",
      "Test set: Average loss: 1.6136, Accuracy: 2610/5000 (52%)\n",
      "[epoch 8] loss: 0.3341450\n",
      "Test set: Average loss: 1.6434, Accuracy: 2642/5000 (53%)\n",
      "[epoch 9] loss: 0.2666906\n",
      "Test set: Average loss: 1.7926, Accuracy: 2586/5000 (52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 0.2097858\n",
      "Test set: Average loss: 1.8496, Accuracy: 2644/5000 (53%)\n",
      "[epoch 11] loss: 0.1127658\n",
      "Test set: Average loss: 1.9510, Accuracy: 2650/5000 (53%)\n",
      "[epoch 12] loss: 0.0860719\n",
      "Test set: Average loss: 2.0870, Accuracy: 2608/5000 (52%)\n",
      "[epoch 13] loss: 0.0656841\n",
      "Test set: Average loss: 2.0870, Accuracy: 2620/5000 (52%)\n",
      "[epoch 14] loss: 0.0453766\n",
      "Test set: Average loss: 2.1707, Accuracy: 2586/5000 (52%)\n",
      "[epoch 15] loss: 0.0281410\n",
      "Test set: Average loss: 2.2564, Accuracy: 2628/5000 (53%)\n",
      "[epoch 16] loss: 0.0177527\n",
      "Test set: Average loss: 2.3481, Accuracy: 2621/5000 (52%)\n",
      "[epoch 17] loss: 0.0111741\n",
      "Test set: Average loss: 2.3295, Accuracy: 2647/5000 (53%)\n",
      "[epoch 18] loss: 0.0084135\n",
      "Test set: Average loss: 2.4097, Accuracy: 2628/5000 (53%)\n",
      "[epoch 19] loss: 0.0067350\n",
      "Test set: Average loss: 2.3904, Accuracy: 2652/5000 (53%)\n",
      "[epoch 20] loss: 0.0057876\n",
      "Test set: Average loss: 2.4391, Accuracy: 2647/5000 (53%)\n",
      "[epoch 21] loss: 0.0050952\n",
      "Test set: Average loss: 2.4559, Accuracy: 2649/5000 (53%)\n",
      "[epoch 22] loss: 0.0045151\n",
      "Test set: Average loss: 2.4849, Accuracy: 2650/5000 (53%)\n",
      "[epoch 23] loss: 0.0042160\n",
      "Test set: Average loss: 2.5066, Accuracy: 2643/5000 (53%)\n",
      "[epoch 24] loss: 0.0038676\n",
      "Test set: Average loss: 2.5242, Accuracy: 2643/5000 (53%)\n",
      "[epoch 25] loss: 0.0034917\n",
      "Test set: Average loss: 2.5512, Accuracy: 2633/5000 (53%)\n",
      "[epoch 26] loss: 0.0032123\n",
      "Test set: Average loss: 2.5757, Accuracy: 2634/5000 (53%)\n",
      "[epoch 27] loss: 0.0030104\n",
      "Test set: Average loss: 2.5899, Accuracy: 2635/5000 (53%)\n",
      "[epoch 28] loss: 0.0027818\n",
      "Test set: Average loss: 2.6009, Accuracy: 2649/5000 (53%)\n",
      "[epoch 29] loss: 0.0026417\n",
      "Test set: Average loss: 2.6254, Accuracy: 2635/5000 (53%)\n",
      "[epoch 30] loss: 0.0024330\n",
      "Test set: Average loss: 2.6450, Accuracy: 2641/5000 (53%)\n",
      "[epoch 31] loss: 0.0023124\n",
      "Test set: Average loss: 2.6582, Accuracy: 2640/5000 (53%)\n",
      "[epoch 32] loss: 0.0021888\n",
      "Test set: Average loss: 2.6706, Accuracy: 2639/5000 (53%)\n",
      "[epoch 33] loss: 0.0020627\n",
      "Test set: Average loss: 2.6962, Accuracy: 2630/5000 (53%)\n",
      "[epoch 34] loss: 0.0019407\n",
      "Test set: Average loss: 2.6996, Accuracy: 2640/5000 (53%)\n",
      "[epoch 35] loss: 0.0018233\n",
      "Test set: Average loss: 2.7132, Accuracy: 2637/5000 (53%)\n",
      "[epoch 36] loss: 0.0017343\n",
      "Test set: Average loss: 2.7333, Accuracy: 2631/5000 (53%)\n",
      "[epoch 37] loss: 0.0016624\n",
      "Test set: Average loss: 2.7456, Accuracy: 2635/5000 (53%)\n",
      "[epoch 38] loss: 0.0015649\n",
      "Test set: Average loss: 2.7596, Accuracy: 2633/5000 (53%)\n",
      "[epoch 39] loss: 0.0014797\n",
      "Test set: Average loss: 2.7700, Accuracy: 2636/5000 (53%)\n",
      "[epoch 40] loss: 0.0014178\n",
      "Test set: Average loss: 2.7770, Accuracy: 2636/5000 (53%)\n",
      "[epoch 41] loss: 0.0013355\n",
      "Test set: Average loss: 2.7986, Accuracy: 2633/5000 (53%)\n",
      "[epoch 42] loss: 0.0012923\n",
      "Test set: Average loss: 2.8078, Accuracy: 2626/5000 (53%)\n",
      "[epoch 43] loss: 0.0012331\n",
      "Test set: Average loss: 2.8144, Accuracy: 2637/5000 (53%)\n",
      "[epoch 44] loss: 0.0011935\n",
      "Test set: Average loss: 2.8285, Accuracy: 2635/5000 (53%)\n",
      "[epoch 45] loss: 0.0011389\n",
      "Test set: Average loss: 2.8430, Accuracy: 2627/5000 (53%)\n",
      "[epoch 46] loss: 0.0010849\n",
      "Test set: Average loss: 2.8504, Accuracy: 2629/5000 (53%)\n",
      "[epoch 47] loss: 0.0010581\n",
      "Test set: Average loss: 2.8616, Accuracy: 2628/5000 (53%)\n",
      "[epoch 48] loss: 0.0010186\n",
      "Test set: Average loss: 2.8746, Accuracy: 2629/5000 (53%)\n",
      "[epoch 49] loss: 0.0009683\n",
      "Test set: Average loss: 2.8813, Accuracy: 2623/5000 (52%)\n",
      "[epoch 50] loss: 0.0009331\n",
      "Test set: Average loss: 2.8921, Accuracy: 2634/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3180, Accuracy: 2705/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.2867, Accuracy: 5587/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3082, Accuracy: 301/5000 (6%)\n",
      "[epoch 1] loss: 1.9396930\n",
      "Test set: Average loss: 1.6073, Accuracy: 2284/5000 (46%)\n",
      "[epoch 2] loss: 1.2946152\n",
      "Test set: Average loss: 1.4207, Accuracy: 2484/5000 (50%)\n",
      "[epoch 3] loss: 0.9821680\n",
      "Test set: Average loss: 1.3958, Accuracy: 2573/5000 (51%)\n",
      "[epoch 4] loss: 0.8364696\n",
      "Test set: Average loss: 1.3513, Accuracy: 2716/5000 (54%)\n",
      "[epoch 5] loss: 0.6150888\n",
      "Test set: Average loss: 1.3895, Accuracy: 2707/5000 (54%)\n",
      "[epoch 6] loss: 0.4784166\n",
      "Test set: Average loss: 1.4432, Accuracy: 2807/5000 (56%)\n",
      "[epoch 7] loss: 0.3877516\n",
      "Test set: Average loss: 1.6479, Accuracy: 2648/5000 (53%)\n",
      "[epoch 8] loss: 0.3125105\n",
      "Test set: Average loss: 1.7583, Accuracy: 2518/5000 (50%)\n",
      "[epoch 9] loss: 0.2384141\n",
      "Test set: Average loss: 1.8212, Accuracy: 2635/5000 (53%)\n",
      "[epoch 10] loss: 0.1667632\n",
      "Test set: Average loss: 1.8148, Accuracy: 2689/5000 (54%)\n",
      "[epoch 11] loss: 0.1166312\n",
      "Test set: Average loss: 1.9891, Accuracy: 2634/5000 (53%)\n",
      "[epoch 12] loss: 0.0708954\n",
      "Test set: Average loss: 2.1073, Accuracy: 2610/5000 (52%)\n",
      "[epoch 13] loss: 0.0417926\n",
      "Test set: Average loss: 2.0567, Accuracy: 2715/5000 (54%)\n",
      "[epoch 14] loss: 0.0227417\n",
      "Test set: Average loss: 2.1249, Accuracy: 2679/5000 (54%)\n",
      "[epoch 15] loss: 0.0170026\n",
      "Test set: Average loss: 2.2149, Accuracy: 2668/5000 (53%)\n",
      "[epoch 16] loss: 0.0115929\n",
      "Test set: Average loss: 2.2266, Accuracy: 2694/5000 (54%)\n",
      "[epoch 17] loss: 0.0087137\n",
      "Test set: Average loss: 2.2749, Accuracy: 2686/5000 (54%)\n",
      "[epoch 18] loss: 0.0073651\n",
      "Test set: Average loss: 2.3224, Accuracy: 2681/5000 (54%)\n",
      "[epoch 19] loss: 0.0065664\n",
      "Test set: Average loss: 2.3307, Accuracy: 2699/5000 (54%)\n",
      "[epoch 20] loss: 0.0056072\n",
      "Test set: Average loss: 2.3796, Accuracy: 2673/5000 (53%)\n",
      "[epoch 21] loss: 0.0049075\n",
      "Test set: Average loss: 2.3925, Accuracy: 2696/5000 (54%)\n",
      "[epoch 22] loss: 0.0045131\n",
      "Test set: Average loss: 2.4276, Accuracy: 2680/5000 (54%)\n",
      "[epoch 23] loss: 0.0040819\n",
      "Test set: Average loss: 2.4406, Accuracy: 2694/5000 (54%)\n",
      "[epoch 24] loss: 0.0038657\n",
      "Test set: Average loss: 2.4619, Accuracy: 2683/5000 (54%)\n",
      "[epoch 25] loss: 0.0035102\n",
      "Test set: Average loss: 2.4921, Accuracy: 2672/5000 (53%)\n",
      "[epoch 26] loss: 0.0031755\n",
      "Test set: Average loss: 2.5084, Accuracy: 2671/5000 (53%)\n",
      "[epoch 27] loss: 0.0028826\n",
      "Test set: Average loss: 2.5285, Accuracy: 2675/5000 (54%)\n",
      "[epoch 28] loss: 0.0026662\n",
      "Test set: Average loss: 2.5445, Accuracy: 2677/5000 (54%)\n",
      "[epoch 29] loss: 0.0025307\n",
      "Test set: Average loss: 2.5606, Accuracy: 2681/5000 (54%)\n",
      "[epoch 30] loss: 0.0024268\n",
      "Test set: Average loss: 2.5787, Accuracy: 2668/5000 (53%)\n",
      "[epoch 31] loss: 0.0021676\n",
      "Test set: Average loss: 2.5947, Accuracy: 2672/5000 (53%)\n",
      "[epoch 32] loss: 0.0020504\n",
      "Test set: Average loss: 2.6123, Accuracy: 2666/5000 (53%)\n",
      "[epoch 33] loss: 0.0019297\n",
      "Test set: Average loss: 2.6286, Accuracy: 2667/5000 (53%)\n",
      "[epoch 34] loss: 0.0018447\n",
      "Test set: Average loss: 2.6395, Accuracy: 2673/5000 (53%)\n",
      "[epoch 35] loss: 0.0017239\n",
      "Test set: Average loss: 2.6552, Accuracy: 2666/5000 (53%)\n",
      "[epoch 36] loss: 0.0016385\n",
      "Test set: Average loss: 2.6663, Accuracy: 2665/5000 (53%)\n",
      "[epoch 37] loss: 0.0015581\n",
      "Test set: Average loss: 2.6856, Accuracy: 2666/5000 (53%)\n",
      "[epoch 38] loss: 0.0014796\n",
      "Test set: Average loss: 2.6914, Accuracy: 2667/5000 (53%)\n",
      "[epoch 39] loss: 0.0014213\n",
      "Test set: Average loss: 2.7071, Accuracy: 2664/5000 (53%)\n",
      "[epoch 40] loss: 0.0013374\n",
      "Test set: Average loss: 2.7174, Accuracy: 2668/5000 (53%)\n",
      "[epoch 41] loss: 0.0012902\n",
      "Test set: Average loss: 2.7324, Accuracy: 2666/5000 (53%)\n",
      "[epoch 42] loss: 0.0012492\n",
      "Test set: Average loss: 2.7425, Accuracy: 2668/5000 (53%)\n",
      "[epoch 43] loss: 0.0011775\n",
      "Test set: Average loss: 2.7563, Accuracy: 2661/5000 (53%)\n",
      "[epoch 44] loss: 0.0011179\n",
      "Test set: Average loss: 2.7667, Accuracy: 2662/5000 (53%)\n",
      "[epoch 45] loss: 0.0010738\n",
      "Test set: Average loss: 2.7767, Accuracy: 2664/5000 (53%)\n",
      "[epoch 46] loss: 0.0010345\n",
      "Test set: Average loss: 2.7924, Accuracy: 2653/5000 (53%)\n",
      "[epoch 47] loss: 0.0009912\n",
      "Test set: Average loss: 2.7966, Accuracy: 2664/5000 (53%)\n",
      "[epoch 48] loss: 0.0009407\n",
      "Test set: Average loss: 2.8099, Accuracy: 2653/5000 (53%)\n",
      "[epoch 49] loss: 0.0009208\n",
      "Test set: Average loss: 2.8203, Accuracy: 2653/5000 (53%)\n",
      "[epoch 50] loss: 0.0008978\n",
      "Test set: Average loss: 2.8284, Accuracy: 2655/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4432, Accuracy: 2807/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.3946, Accuracy: 5664/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2894, Accuracy: 815/5000 (16%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.8993311\n",
      "Test set: Average loss: 1.6128, Accuracy: 2248/5000 (45%)\n",
      "[epoch 2] loss: 1.3923686\n",
      "Test set: Average loss: 1.4928, Accuracy: 2356/5000 (47%)\n",
      "[epoch 3] loss: 1.1429076\n",
      "Test set: Average loss: 1.4304, Accuracy: 2454/5000 (49%)\n",
      "[epoch 4] loss: 0.9204458\n",
      "Test set: Average loss: 1.4217, Accuracy: 2578/5000 (52%)\n",
      "[epoch 5] loss: 0.7938167\n",
      "Test set: Average loss: 1.4741, Accuracy: 2651/5000 (53%)\n",
      "[epoch 6] loss: 0.5655709\n",
      "Test set: Average loss: 1.5355, Accuracy: 2612/5000 (52%)\n",
      "[epoch 7] loss: 0.4448568\n",
      "Test set: Average loss: 1.6775, Accuracy: 2615/5000 (52%)\n",
      "[epoch 8] loss: 0.3801883\n",
      "Test set: Average loss: 1.7385, Accuracy: 2521/5000 (50%)\n",
      "[epoch 9] loss: 0.2425431\n",
      "Test set: Average loss: 1.8726, Accuracy: 2503/5000 (50%)\n",
      "[epoch 10] loss: 0.1766215\n",
      "Test set: Average loss: 1.9185, Accuracy: 2530/5000 (51%)\n",
      "[epoch 11] loss: 0.1346159\n",
      "Test set: Average loss: 2.0837, Accuracy: 2521/5000 (50%)\n",
      "[epoch 12] loss: 0.0956751\n",
      "Test set: Average loss: 2.1852, Accuracy: 2543/5000 (51%)\n",
      "[epoch 13] loss: 0.0588600\n",
      "Test set: Average loss: 2.2282, Accuracy: 2486/5000 (50%)\n",
      "[epoch 14] loss: 0.0367935\n",
      "Test set: Average loss: 2.2773, Accuracy: 2559/5000 (51%)\n",
      "[epoch 15] loss: 0.0199219\n",
      "Test set: Average loss: 2.3856, Accuracy: 2523/5000 (50%)\n",
      "[epoch 16] loss: 0.0131934\n",
      "Test set: Average loss: 2.4489, Accuracy: 2546/5000 (51%)\n",
      "[epoch 17] loss: 0.0119428\n",
      "Test set: Average loss: 2.4614, Accuracy: 2541/5000 (51%)\n",
      "[epoch 18] loss: 0.0082693\n",
      "Test set: Average loss: 2.4870, Accuracy: 2537/5000 (51%)\n",
      "[epoch 19] loss: 0.0063729\n",
      "Test set: Average loss: 2.5206, Accuracy: 2552/5000 (51%)\n",
      "[epoch 20] loss: 0.0057272\n",
      "Test set: Average loss: 2.5570, Accuracy: 2564/5000 (51%)\n",
      "[epoch 21] loss: 0.0051189\n",
      "Test set: Average loss: 2.5825, Accuracy: 2550/5000 (51%)\n",
      "[epoch 22] loss: 0.0045559\n",
      "Test set: Average loss: 2.6055, Accuracy: 2556/5000 (51%)\n",
      "[epoch 23] loss: 0.0040847\n",
      "Test set: Average loss: 2.6399, Accuracy: 2544/5000 (51%)\n",
      "[epoch 24] loss: 0.0037471\n",
      "Test set: Average loss: 2.6507, Accuracy: 2551/5000 (51%)\n",
      "[epoch 25] loss: 0.0034180\n",
      "Test set: Average loss: 2.6733, Accuracy: 2548/5000 (51%)\n",
      "[epoch 26] loss: 0.0031677\n",
      "Test set: Average loss: 2.6964, Accuracy: 2547/5000 (51%)\n",
      "[epoch 27] loss: 0.0029555\n",
      "Test set: Average loss: 2.7174, Accuracy: 2547/5000 (51%)\n",
      "[epoch 28] loss: 0.0027804\n",
      "Test set: Average loss: 2.7381, Accuracy: 2550/5000 (51%)\n",
      "[epoch 29] loss: 0.0025549\n",
      "Test set: Average loss: 2.7566, Accuracy: 2544/5000 (51%)\n",
      "[epoch 30] loss: 0.0024051\n",
      "Test set: Average loss: 2.7664, Accuracy: 2546/5000 (51%)\n",
      "[epoch 31] loss: 0.0022647\n",
      "Test set: Average loss: 2.7933, Accuracy: 2546/5000 (51%)\n",
      "[epoch 32] loss: 0.0021060\n",
      "Test set: Average loss: 2.8022, Accuracy: 2546/5000 (51%)\n",
      "[epoch 33] loss: 0.0019943\n",
      "Test set: Average loss: 2.8168, Accuracy: 2541/5000 (51%)\n",
      "[epoch 34] loss: 0.0018911\n",
      "Test set: Average loss: 2.8386, Accuracy: 2541/5000 (51%)\n",
      "[epoch 35] loss: 0.0017844\n",
      "Test set: Average loss: 2.8475, Accuracy: 2542/5000 (51%)\n",
      "[epoch 36] loss: 0.0017049\n",
      "Test set: Average loss: 2.8680, Accuracy: 2543/5000 (51%)\n",
      "[epoch 37] loss: 0.0016157\n",
      "Test set: Average loss: 2.8796, Accuracy: 2547/5000 (51%)\n",
      "[epoch 38] loss: 0.0015199\n",
      "Test set: Average loss: 2.8895, Accuracy: 2547/5000 (51%)\n",
      "[epoch 39] loss: 0.0014704\n",
      "Test set: Average loss: 2.9104, Accuracy: 2545/5000 (51%)\n",
      "[epoch 40] loss: 0.0013766\n",
      "Test set: Average loss: 2.9183, Accuracy: 2544/5000 (51%)\n",
      "[epoch 41] loss: 0.0013263\n",
      "Test set: Average loss: 2.9271, Accuracy: 2542/5000 (51%)\n",
      "[epoch 42] loss: 0.0012577\n",
      "Test set: Average loss: 2.9470, Accuracy: 2544/5000 (51%)\n",
      "[epoch 43] loss: 0.0011973\n",
      "Test set: Average loss: 2.9564, Accuracy: 2541/5000 (51%)\n",
      "[epoch 44] loss: 0.0011602\n",
      "Test set: Average loss: 2.9672, Accuracy: 2543/5000 (51%)\n",
      "[epoch 45] loss: 0.0011094\n",
      "Test set: Average loss: 2.9800, Accuracy: 2541/5000 (51%)\n",
      "[epoch 46] loss: 0.0010589\n",
      "Test set: Average loss: 2.9899, Accuracy: 2541/5000 (51%)\n",
      "[epoch 47] loss: 0.0010350\n",
      "Test set: Average loss: 2.9988, Accuracy: 2539/5000 (51%)\n",
      "[epoch 48] loss: 0.0009918\n",
      "Test set: Average loss: 3.0141, Accuracy: 2536/5000 (51%)\n",
      "[epoch 49] loss: 0.0009349\n",
      "Test set: Average loss: 3.0227, Accuracy: 2536/5000 (51%)\n",
      "[epoch 50] loss: 0.0009177\n",
      "Test set: Average loss: 3.0322, Accuracy: 2539/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4741, Accuracy: 2651/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.4515, Accuracy: 5372/10000 (54%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 616/5000 (12%)\n",
      "[epoch 1] loss: 1.7566555\n",
      "Test set: Average loss: 1.5454, Accuracy: 2230/5000 (45%)\n",
      "[epoch 2] loss: 1.2701883\n",
      "Test set: Average loss: 1.4228, Accuracy: 2561/5000 (51%)\n",
      "[epoch 3] loss: 1.0613982\n",
      "Test set: Average loss: 1.3078, Accuracy: 2748/5000 (55%)\n",
      "[epoch 4] loss: 0.8812529\n",
      "Test set: Average loss: 1.4029, Accuracy: 2682/5000 (54%)\n",
      "[epoch 5] loss: 0.7528608\n",
      "Test set: Average loss: 1.3277, Accuracy: 2784/5000 (56%)\n",
      "[epoch 6] loss: 0.6309880\n",
      "Test set: Average loss: 1.5331, Accuracy: 2620/5000 (52%)\n",
      "[epoch 7] loss: 0.4612399\n",
      "Test set: Average loss: 1.6238, Accuracy: 2616/5000 (52%)\n",
      "[epoch 8] loss: 0.3906948\n",
      "Test set: Average loss: 1.8727, Accuracy: 2516/5000 (50%)\n",
      "[epoch 9] loss: 0.3898200\n",
      "Test set: Average loss: 1.9157, Accuracy: 2506/5000 (50%)\n",
      "[epoch 10] loss: 0.2606871\n",
      "Test set: Average loss: 1.9898, Accuracy: 2610/5000 (52%)\n",
      "[epoch 11] loss: 0.2222445\n",
      "Test set: Average loss: 1.9781, Accuracy: 2619/5000 (52%)\n",
      "[epoch 12] loss: 0.1825662\n",
      "Test set: Average loss: 2.2840, Accuracy: 2495/5000 (50%)\n",
      "[epoch 13] loss: 0.1786484\n",
      "Test set: Average loss: 2.3011, Accuracy: 2498/5000 (50%)\n",
      "[epoch 14] loss: 0.1521302\n",
      "Test set: Average loss: 2.3593, Accuracy: 2526/5000 (51%)\n",
      "[epoch 15] loss: 0.0843449\n",
      "Test set: Average loss: 2.5229, Accuracy: 2481/5000 (50%)\n",
      "[epoch 16] loss: 0.0612728\n",
      "Test set: Average loss: 2.6263, Accuracy: 2572/5000 (51%)\n",
      "[epoch 17] loss: 0.0357082\n",
      "Test set: Average loss: 2.5644, Accuracy: 2606/5000 (52%)\n",
      "[epoch 18] loss: 0.0234661\n",
      "Test set: Average loss: 2.6571, Accuracy: 2593/5000 (52%)\n",
      "[epoch 19] loss: 0.0149531\n",
      "Test set: Average loss: 2.6421, Accuracy: 2616/5000 (52%)\n",
      "[epoch 20] loss: 0.0073081\n",
      "Test set: Average loss: 2.6686, Accuracy: 2628/5000 (53%)\n",
      "[epoch 21] loss: 0.0050641\n",
      "Test set: Average loss: 2.7026, Accuracy: 2641/5000 (53%)\n",
      "[epoch 22] loss: 0.0040966\n",
      "Test set: Average loss: 2.7357, Accuracy: 2637/5000 (53%)\n",
      "[epoch 23] loss: 0.0035402\n",
      "Test set: Average loss: 2.7589, Accuracy: 2631/5000 (53%)\n",
      "[epoch 24] loss: 0.0032039\n",
      "Test set: Average loss: 2.7898, Accuracy: 2626/5000 (53%)\n",
      "[epoch 25] loss: 0.0029452\n",
      "Test set: Average loss: 2.8095, Accuracy: 2629/5000 (53%)\n",
      "[epoch 26] loss: 0.0027101\n",
      "Test set: Average loss: 2.8236, Accuracy: 2635/5000 (53%)\n",
      "[epoch 27] loss: 0.0025407\n",
      "Test set: Average loss: 2.8501, Accuracy: 2628/5000 (53%)\n",
      "[epoch 28] loss: 0.0023369\n",
      "Test set: Average loss: 2.8624, Accuracy: 2629/5000 (53%)\n",
      "[epoch 29] loss: 0.0021663\n",
      "Test set: Average loss: 2.8872, Accuracy: 2620/5000 (52%)\n",
      "[epoch 30] loss: 0.0020442\n",
      "Test set: Average loss: 2.8979, Accuracy: 2629/5000 (53%)\n",
      "[epoch 31] loss: 0.0019349\n",
      "Test set: Average loss: 2.9196, Accuracy: 2619/5000 (52%)\n",
      "[epoch 32] loss: 0.0018008\n",
      "Test set: Average loss: 2.9338, Accuracy: 2620/5000 (52%)\n",
      "[epoch 33] loss: 0.0017012\n",
      "Test set: Average loss: 2.9498, Accuracy: 2622/5000 (52%)\n",
      "[epoch 34] loss: 0.0016413\n",
      "Test set: Average loss: 2.9651, Accuracy: 2623/5000 (52%)\n",
      "[epoch 35] loss: 0.0015552\n",
      "Test set: Average loss: 2.9788, Accuracy: 2621/5000 (52%)\n",
      "[epoch 36] loss: 0.0014739\n",
      "Test set: Average loss: 2.9971, Accuracy: 2619/5000 (52%)\n",
      "[epoch 37] loss: 0.0013945\n",
      "Test set: Average loss: 3.0047, Accuracy: 2625/5000 (52%)\n",
      "[epoch 38] loss: 0.0013067\n",
      "Test set: Average loss: 3.0244, Accuracy: 2627/5000 (53%)\n",
      "[epoch 39] loss: 0.0012353\n",
      "Test set: Average loss: 3.0357, Accuracy: 2625/5000 (52%)\n",
      "[epoch 40] loss: 0.0012020\n",
      "Test set: Average loss: 3.0522, Accuracy: 2622/5000 (52%)\n",
      "[epoch 41] loss: 0.0011210\n",
      "Test set: Average loss: 3.0629, Accuracy: 2623/5000 (52%)\n",
      "[epoch 42] loss: 0.0010973\n",
      "Test set: Average loss: 3.0762, Accuracy: 2618/5000 (52%)\n",
      "[epoch 43] loss: 0.0010419\n",
      "Test set: Average loss: 3.0873, Accuracy: 2621/5000 (52%)\n",
      "[epoch 44] loss: 0.0009937\n",
      "Test set: Average loss: 3.0990, Accuracy: 2624/5000 (52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] loss: 0.0009569\n",
      "Test set: Average loss: 3.1072, Accuracy: 2622/5000 (52%)\n",
      "[epoch 46] loss: 0.0009022\n",
      "Test set: Average loss: 3.1256, Accuracy: 2620/5000 (52%)\n",
      "[epoch 47] loss: 0.0008757\n",
      "Test set: Average loss: 3.1330, Accuracy: 2628/5000 (53%)\n",
      "[epoch 48] loss: 0.0008342\n",
      "Test set: Average loss: 3.1402, Accuracy: 2629/5000 (53%)\n",
      "[epoch 49] loss: 0.0008144\n",
      "Test set: Average loss: 3.1550, Accuracy: 2625/5000 (52%)\n",
      "[epoch 50] loss: 0.0007739\n",
      "Test set: Average loss: 3.1664, Accuracy: 2622/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3277, Accuracy: 2784/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.2911, Accuracy: 5777/10000 (58%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 429/5000 (9%)\n",
      "[epoch 1] loss: 1.6867872\n",
      "Test set: Average loss: 1.4107, Accuracy: 2532/5000 (51%)\n",
      "[epoch 2] loss: 1.1360538\n",
      "Test set: Average loss: 1.3888, Accuracy: 2559/5000 (51%)\n",
      "[epoch 3] loss: 0.9175340\n",
      "Test set: Average loss: 1.3624, Accuracy: 2681/5000 (54%)\n",
      "[epoch 4] loss: 0.7567871\n",
      "Test set: Average loss: 1.3263, Accuracy: 2795/5000 (56%)\n",
      "[epoch 5] loss: 0.5943182\n",
      "Test set: Average loss: 1.3882, Accuracy: 2802/5000 (56%)\n",
      "[epoch 6] loss: 0.4507370\n",
      "Test set: Average loss: 1.4543, Accuracy: 2784/5000 (56%)\n",
      "[epoch 7] loss: 0.3988088\n",
      "Test set: Average loss: 1.8069, Accuracy: 2510/5000 (50%)\n",
      "[epoch 8] loss: 0.2769527\n",
      "Test set: Average loss: 1.7922, Accuracy: 2672/5000 (53%)\n",
      "[epoch 9] loss: 0.1903566\n",
      "Test set: Average loss: 1.8705, Accuracy: 2680/5000 (54%)\n",
      "[epoch 10] loss: 0.1722113\n",
      "Test set: Average loss: 1.9433, Accuracy: 2635/5000 (53%)\n",
      "[epoch 11] loss: 0.1430996\n",
      "Test set: Average loss: 2.2451, Accuracy: 2533/5000 (51%)\n",
      "[epoch 12] loss: 0.1894234\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1339, Accuracy: 2612/5000 (52%)\n",
      "[epoch 13] loss: 0.0655278\n",
      "Test set: Average loss: 2.0754, Accuracy: 2640/5000 (53%)\n",
      "[epoch 14] loss: 0.0421827\n",
      "Test set: Average loss: 2.0792, Accuracy: 2651/5000 (53%)\n",
      "[epoch 15] loss: 0.0348874\n",
      "Test set: Average loss: 2.0842, Accuracy: 2664/5000 (53%)\n",
      "[epoch 16] loss: 0.0303763\n",
      "Test set: Average loss: 2.0967, Accuracy: 2665/5000 (53%)\n",
      "[epoch 17] loss: 0.0275076\n",
      "Test set: Average loss: 2.1068, Accuracy: 2666/5000 (53%)\n",
      "[epoch 18] loss: 0.0256597\n",
      "Test set: Average loss: 2.1227, Accuracy: 2664/5000 (53%)\n",
      "[epoch 19] loss: 0.0231398\n",
      "Test set: Average loss: 2.1300, Accuracy: 2668/5000 (53%)\n",
      "[epoch 20] loss: 0.0220477\n",
      "Test set: Average loss: 2.1428, Accuracy: 2659/5000 (53%)\n",
      "[epoch 21] loss: 0.0202071\n",
      "Test set: Average loss: 2.1543, Accuracy: 2662/5000 (53%)\n",
      "[epoch 22] loss: 0.0192501\n",
      "Test set: Average loss: 2.1646, Accuracy: 2669/5000 (53%)\n",
      "[epoch 23] loss: 0.0179627\n",
      "Test set: Average loss: 2.1786, Accuracy: 2665/5000 (53%)\n",
      "[epoch 24] loss: 0.0172243\n",
      "Test set: Average loss: 2.1857, Accuracy: 2667/5000 (53%)\n",
      "[epoch 25] loss: 0.0167607\n",
      "Test set: Average loss: 2.1948, Accuracy: 2666/5000 (53%)\n",
      "[epoch 26] loss: 0.0155800\n",
      "Test set: Average loss: 2.2090, Accuracy: 2669/5000 (53%)\n",
      "[epoch 27] loss: 0.0148808\n",
      "Test set: Average loss: 2.2173, Accuracy: 2674/5000 (53%)\n",
      "[epoch 28] loss: 0.0145341\n",
      "Test set: Average loss: 2.2271, Accuracy: 2667/5000 (53%)\n",
      "[epoch 29] loss: 0.0134811\n",
      "Test set: Average loss: 2.2395, Accuracy: 2665/5000 (53%)\n",
      "[epoch 30] loss: 0.0131737\n",
      "Test set: Average loss: 2.2484, Accuracy: 2666/5000 (53%)\n",
      "[epoch 31] loss: 0.0124430\n",
      "Test set: Average loss: 2.2586, Accuracy: 2665/5000 (53%)\n",
      "[epoch 32] loss: 0.0119551\n",
      "Test set: Average loss: 2.2656, Accuracy: 2662/5000 (53%)\n",
      "[epoch 33] loss: 0.0115079\n",
      "Test set: Average loss: 2.2732, Accuracy: 2661/5000 (53%)\n",
      "[epoch 34] loss: 0.0111770\n",
      "Test set: Average loss: 2.2836, Accuracy: 2662/5000 (53%)\n",
      "[epoch 35] loss: 0.0107583\n",
      "Test set: Average loss: 2.2918, Accuracy: 2653/5000 (53%)\n",
      "[epoch 36] loss: 0.0103686\n",
      "Test set: Average loss: 2.2997, Accuracy: 2658/5000 (53%)\n",
      "[epoch 37] loss: 0.0099974\n",
      "Test set: Average loss: 2.3111, Accuracy: 2648/5000 (53%)\n",
      "[epoch 38] loss: 0.0094752\n",
      "Test set: Average loss: 2.3196, Accuracy: 2650/5000 (53%)\n",
      "[epoch 39] loss: 0.0092737\n",
      "Test set: Average loss: 2.3286, Accuracy: 2648/5000 (53%)\n",
      "[epoch 40] loss: 0.0089888\n",
      "Test set: Average loss: 2.3347, Accuracy: 2651/5000 (53%)\n",
      "[epoch 41] loss: 0.0087637\n",
      "Test set: Average loss: 2.3450, Accuracy: 2648/5000 (53%)\n",
      "[epoch 42] loss: 0.0085335\n",
      "Test set: Average loss: 2.3514, Accuracy: 2650/5000 (53%)\n",
      "[epoch 43] loss: 0.0082935\n",
      "Test set: Average loss: 2.3613, Accuracy: 2642/5000 (53%)\n",
      "[epoch 44] loss: 0.0078967\n",
      "Test set: Average loss: 2.3714, Accuracy: 2649/5000 (53%)\n",
      "[epoch 45] loss: 0.0076423\n",
      "Test set: Average loss: 2.3780, Accuracy: 2650/5000 (53%)\n",
      "[epoch 46] loss: 0.0074113\n",
      "Test set: Average loss: 2.3857, Accuracy: 2650/5000 (53%)\n",
      "[epoch 47] loss: 0.0072319\n",
      "Test set: Average loss: 2.3937, Accuracy: 2652/5000 (53%)\n",
      "[epoch 48] loss: 0.0069619\n",
      "Test set: Average loss: 2.4015, Accuracy: 2650/5000 (53%)\n",
      "[epoch 49] loss: 0.0069982\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4085, Accuracy: 2652/5000 (53%)\n",
      "[epoch 50] loss: 0.0064921\n",
      "Test set: Average loss: 2.4094, Accuracy: 2653/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3882, Accuracy: 2802/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.3428, Accuracy: 5736/10000 (57%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2992, Accuracy: 473/5000 (9%)\n",
      "[epoch 1] loss: 1.8019118\n",
      "Test set: Average loss: 1.5247, Accuracy: 2261/5000 (45%)\n",
      "[epoch 2] loss: 1.2590215\n",
      "Test set: Average loss: 1.3177, Accuracy: 2684/5000 (54%)\n",
      "[epoch 3] loss: 1.0551930\n",
      "Test set: Average loss: 1.3204, Accuracy: 2706/5000 (54%)\n",
      "[epoch 4] loss: 0.9230952\n",
      "Test set: Average loss: 1.5142, Accuracy: 2542/5000 (51%)\n",
      "[epoch 5] loss: 0.8683554\n",
      "Test set: Average loss: 1.4301, Accuracy: 2648/5000 (53%)\n",
      "[epoch 6] loss: 0.6276586\n",
      "Test set: Average loss: 1.5090, Accuracy: 2614/5000 (52%)\n",
      "[epoch 7] loss: 0.4977203\n",
      "Test set: Average loss: 1.6297, Accuracy: 2584/5000 (52%)\n",
      "[epoch 8] loss: 0.3635514\n",
      "Test set: Average loss: 1.7270, Accuracy: 2590/5000 (52%)\n",
      "[epoch 9] loss: 0.2771121\n",
      "Test set: Average loss: 1.8142, Accuracy: 2634/5000 (53%)\n",
      "[epoch 10] loss: 0.2204612\n",
      "Test set: Average loss: 1.9304, Accuracy: 2546/5000 (51%)\n",
      "[epoch 11] loss: 0.1516920\n",
      "Test set: Average loss: 2.0963, Accuracy: 2561/5000 (51%)\n",
      "[epoch 12] loss: 0.1070015\n",
      "Test set: Average loss: 2.1440, Accuracy: 2605/5000 (52%)\n",
      "[epoch 13] loss: 0.0560321\n",
      "Test set: Average loss: 2.2559, Accuracy: 2571/5000 (51%)\n",
      "[epoch 14] loss: 0.0483064\n",
      "Test set: Average loss: 2.4324, Accuracy: 2557/5000 (51%)\n",
      "[epoch 15] loss: 0.0321534\n",
      "Test set: Average loss: 2.3854, Accuracy: 2577/5000 (52%)\n",
      "[epoch 16] loss: 0.0207781\n",
      "Test set: Average loss: 2.5041, Accuracy: 2553/5000 (51%)\n",
      "[epoch 17] loss: 0.0103889\n",
      "Test set: Average loss: 2.5381, Accuracy: 2575/5000 (52%)\n",
      "[epoch 18] loss: 0.0073045\n",
      "Test set: Average loss: 2.5808, Accuracy: 2590/5000 (52%)\n",
      "[epoch 19] loss: 0.0059968\n",
      "Test set: Average loss: 2.6110, Accuracy: 2577/5000 (52%)\n",
      "[epoch 20] loss: 0.0050147\n",
      "Test set: Average loss: 2.6398, Accuracy: 2582/5000 (52%)\n",
      "[epoch 21] loss: 0.0044524\n",
      "Test set: Average loss: 2.6691, Accuracy: 2580/5000 (52%)\n",
      "[epoch 22] loss: 0.0040369\n",
      "Test set: Average loss: 2.7046, Accuracy: 2576/5000 (52%)\n",
      "[epoch 23] loss: 0.0035334\n",
      "Test set: Average loss: 2.7331, Accuracy: 2581/5000 (52%)\n",
      "[epoch 24] loss: 0.0032791\n",
      "Test set: Average loss: 2.7572, Accuracy: 2580/5000 (52%)\n",
      "[epoch 25] loss: 0.0029922\n",
      "Test set: Average loss: 2.7754, Accuracy: 2589/5000 (52%)\n",
      "[epoch 26] loss: 0.0027479\n",
      "Test set: Average loss: 2.8013, Accuracy: 2578/5000 (52%)\n",
      "[epoch 27] loss: 0.0025402\n",
      "Test set: Average loss: 2.8237, Accuracy: 2571/5000 (51%)\n",
      "[epoch 28] loss: 0.0023539\n",
      "Test set: Average loss: 2.8496, Accuracy: 2571/5000 (51%)\n",
      "[epoch 29] loss: 0.0021613\n",
      "Test set: Average loss: 2.8679, Accuracy: 2569/5000 (51%)\n",
      "[epoch 30] loss: 0.0020460\n",
      "Test set: Average loss: 2.8897, Accuracy: 2571/5000 (51%)\n",
      "[epoch 31] loss: 0.0019658\n",
      "Test set: Average loss: 2.9117, Accuracy: 2573/5000 (51%)\n",
      "[epoch 32] loss: 0.0018320\n",
      "Test set: Average loss: 2.9233, Accuracy: 2579/5000 (52%)\n",
      "[epoch 33] loss: 0.0017071\n",
      "Test set: Average loss: 2.9443, Accuracy: 2573/5000 (51%)\n",
      "[epoch 34] loss: 0.0016040\n",
      "Test set: Average loss: 2.9626, Accuracy: 2574/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] loss: 0.0015393\n",
      "Test set: Average loss: 2.9787, Accuracy: 2569/5000 (51%)\n",
      "[epoch 36] loss: 0.0014723\n",
      "Test set: Average loss: 2.9952, Accuracy: 2571/5000 (51%)\n",
      "[epoch 37] loss: 0.0013854\n",
      "Test set: Average loss: 3.0076, Accuracy: 2574/5000 (51%)\n",
      "[epoch 38] loss: 0.0012824\n",
      "Test set: Average loss: 3.0283, Accuracy: 2574/5000 (51%)\n",
      "[epoch 39] loss: 0.0012156\n",
      "Test set: Average loss: 3.0383, Accuracy: 2566/5000 (51%)\n",
      "[epoch 40] loss: 0.0011869\n",
      "Test set: Average loss: 3.0575, Accuracy: 2570/5000 (51%)\n",
      "[epoch 41] loss: 0.0011116\n",
      "Test set: Average loss: 3.0701, Accuracy: 2569/5000 (51%)\n",
      "[epoch 42] loss: 0.0010609\n",
      "Test set: Average loss: 3.0840, Accuracy: 2573/5000 (51%)\n",
      "[epoch 43] loss: 0.0010379\n",
      "Test set: Average loss: 3.0977, Accuracy: 2565/5000 (51%)\n",
      "[epoch 44] loss: 0.0009626\n",
      "Test set: Average loss: 3.1126, Accuracy: 2568/5000 (51%)\n",
      "[epoch 45] loss: 0.0009237\n",
      "Test set: Average loss: 3.1232, Accuracy: 2570/5000 (51%)\n",
      "[epoch 46] loss: 0.0008752\n",
      "Test set: Average loss: 3.1372, Accuracy: 2569/5000 (51%)\n",
      "[epoch 47] loss: 0.0008473\n",
      "Test set: Average loss: 3.1508, Accuracy: 2564/5000 (51%)\n",
      "[epoch 48] loss: 0.0008157\n",
      "Test set: Average loss: 3.1611, Accuracy: 2567/5000 (51%)\n",
      "[epoch 49] loss: 0.0007964\n",
      "Test set: Average loss: 3.1718, Accuracy: 2565/5000 (51%)\n",
      "[epoch 50] loss: 0.0007540\n",
      "Test set: Average loss: 3.1860, Accuracy: 2572/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3204, Accuracy: 2706/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.2995, Accuracy: 5577/10000 (56%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2997, Accuracy: 826/5000 (17%)\n",
      "[epoch 1] loss: 1.7007994\n",
      "Test set: Average loss: 1.3926, Accuracy: 2552/5000 (51%)\n",
      "[epoch 2] loss: 1.1722235\n",
      "Test set: Average loss: 1.2885, Accuracy: 2804/5000 (56%)\n",
      "[epoch 3] loss: 0.9902758\n",
      "Test set: Average loss: 1.3153, Accuracy: 2756/5000 (55%)\n",
      "[epoch 4] loss: 0.8378079\n",
      "Test set: Average loss: 1.3615, Accuracy: 2779/5000 (56%)\n",
      "[epoch 5] loss: 0.7197987\n",
      "Test set: Average loss: 1.3973, Accuracy: 2784/5000 (56%)\n",
      "[epoch 6] loss: 0.6238953\n",
      "Test set: Average loss: 1.5545, Accuracy: 2659/5000 (53%)\n",
      "[epoch 7] loss: 0.5695068\n",
      "Test set: Average loss: 1.7168, Accuracy: 2653/5000 (53%)\n",
      "[epoch 8] loss: 0.4568943\n",
      "Test set: Average loss: 1.8333, Accuracy: 2624/5000 (52%)\n",
      "[epoch 9] loss: 0.3654686\n",
      "Test set: Average loss: 1.8565, Accuracy: 2661/5000 (53%)\n",
      "[epoch 10] loss: 0.2649365\n",
      "Test set: Average loss: 2.1127, Accuracy: 2564/5000 (51%)\n",
      "[epoch 11] loss: 0.1801544\n",
      "Test set: Average loss: 2.1992, Accuracy: 2641/5000 (53%)\n",
      "[epoch 12] loss: 0.1232917\n",
      "Test set: Average loss: 2.3214, Accuracy: 2598/5000 (52%)\n",
      "[epoch 13] loss: 0.1235947\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.6456, Accuracy: 2511/5000 (50%)\n",
      "[epoch 14] loss: 0.0795601\n",
      "Test set: Average loss: 2.4246, Accuracy: 2585/5000 (52%)\n",
      "[epoch 15] loss: 0.0337356\n",
      "Test set: Average loss: 2.4201, Accuracy: 2607/5000 (52%)\n",
      "[epoch 16] loss: 0.0294989\n",
      "Test set: Average loss: 2.4328, Accuracy: 2632/5000 (53%)\n",
      "[epoch 17] loss: 0.0272545\n",
      "Test set: Average loss: 2.4377, Accuracy: 2625/5000 (52%)\n",
      "[epoch 18] loss: 0.0239700\n",
      "Test set: Average loss: 2.4513, Accuracy: 2632/5000 (53%)\n",
      "[epoch 19] loss: 0.0221208\n",
      "Test set: Average loss: 2.4566, Accuracy: 2630/5000 (53%)\n",
      "[epoch 20] loss: 0.0208659\n",
      "Test set: Average loss: 2.4704, Accuracy: 2637/5000 (53%)\n",
      "[epoch 21] loss: 0.0195322\n",
      "Test set: Average loss: 2.4784, Accuracy: 2636/5000 (53%)\n",
      "[epoch 22] loss: 0.0187538\n",
      "Test set: Average loss: 2.4868, Accuracy: 2638/5000 (53%)\n",
      "[epoch 23] loss: 0.0176082\n",
      "Test set: Average loss: 2.5017, Accuracy: 2641/5000 (53%)\n",
      "[epoch 24] loss: 0.0170040\n",
      "Test set: Average loss: 2.5070, Accuracy: 2632/5000 (53%)\n",
      "[epoch 25] loss: 0.0161313\n",
      "Test set: Average loss: 2.5183, Accuracy: 2639/5000 (53%)\n",
      "[epoch 26] loss: 0.0155922\n",
      "Test set: Average loss: 2.5287, Accuracy: 2633/5000 (53%)\n",
      "[epoch 27] loss: 0.0146827\n",
      "Test set: Average loss: 2.5380, Accuracy: 2637/5000 (53%)\n",
      "[epoch 28] loss: 0.0144406\n",
      "Test set: Average loss: 2.5455, Accuracy: 2645/5000 (53%)\n",
      "[epoch 29] loss: 0.0136666\n",
      "Test set: Average loss: 2.5569, Accuracy: 2637/5000 (53%)\n",
      "[epoch 30] loss: 0.0131119\n",
      "Test set: Average loss: 2.5677, Accuracy: 2645/5000 (53%)\n",
      "[epoch 31] loss: 0.0132259\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5767, Accuracy: 2641/5000 (53%)\n",
      "[epoch 32] loss: 0.0121124\n",
      "Test set: Average loss: 2.5781, Accuracy: 2638/5000 (53%)\n",
      "[epoch 33] loss: 0.0120681\n",
      "Test set: Average loss: 2.5788, Accuracy: 2645/5000 (53%)\n",
      "[epoch 34] loss: 0.0120785\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5796, Accuracy: 2641/5000 (53%)\n",
      "[epoch 35] loss: 0.0118638\n",
      "Test set: Average loss: 2.5797, Accuracy: 2641/5000 (53%)\n",
      "[epoch 36] loss: 0.0121535\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 37] loss: 0.0118140\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 38] loss: 0.0118681\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 39] loss: 0.0118782\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 40] loss: 0.0121296\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 41] loss: 0.0121752\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 42] loss: 0.0119806\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 43] loss: 0.0118086\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 44] loss: 0.0120839\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 45] loss: 0.0119545\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 46] loss: 0.0120715\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 47] loss: 0.0117660\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 48] loss: 0.0119725\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 49] loss: 0.0119325\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "[epoch 50] loss: 0.0119111\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5798, Accuracy: 2641/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2885, Accuracy: 2804/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.2531, Accuracy: 5622/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3095, Accuracy: 181/5000 (4%)\n",
      "[epoch 1] loss: 1.6011590\n",
      "Test set: Average loss: 1.5081, Accuracy: 2205/5000 (44%)\n",
      "[epoch 2] loss: 1.0679771\n",
      "Test set: Average loss: 1.3025, Accuracy: 2740/5000 (55%)\n",
      "[epoch 3] loss: 0.9009731\n",
      "Test set: Average loss: 1.3528, Accuracy: 2773/5000 (55%)\n",
      "[epoch 4] loss: 0.8101050\n",
      "Test set: Average loss: 1.4753, Accuracy: 2599/5000 (52%)\n",
      "[epoch 5] loss: 0.6660126\n",
      "Test set: Average loss: 1.4823, Accuracy: 2712/5000 (54%)\n",
      "[epoch 6] loss: 0.5746136\n",
      "Test set: Average loss: 1.6478, Accuracy: 2624/5000 (52%)\n",
      "[epoch 7] loss: 0.4452525\n",
      "Test set: Average loss: 1.7238, Accuracy: 2658/5000 (53%)\n",
      "[epoch 8] loss: 0.3332990\n",
      "Test set: Average loss: 1.7996, Accuracy: 2629/5000 (53%)\n",
      "[epoch 9] loss: 0.2893762\n",
      "Test set: Average loss: 1.9599, Accuracy: 2562/5000 (51%)\n",
      "[epoch 10] loss: 0.1958224\n",
      "Test set: Average loss: 2.0448, Accuracy: 2612/5000 (52%)\n",
      "[epoch 11] loss: 0.1540999\n",
      "Test set: Average loss: 2.2118, Accuracy: 2580/5000 (52%)\n",
      "[epoch 12] loss: 0.1148567\n",
      "Test set: Average loss: 2.3633, Accuracy: 2582/5000 (52%)\n",
      "[epoch 13] loss: 0.1084656\n",
      "Test set: Average loss: 2.4363, Accuracy: 2576/5000 (52%)\n",
      "[epoch 14] loss: 0.0641422\n",
      "Test set: Average loss: 2.5892, Accuracy: 2535/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] loss: 0.0615517\n",
      "Test set: Average loss: 2.9818, Accuracy: 2389/5000 (48%)\n",
      "[epoch 16] loss: 0.0481615\n",
      "Test set: Average loss: 2.8787, Accuracy: 2492/5000 (50%)\n",
      "[epoch 17] loss: 0.0406683\n",
      "Test set: Average loss: 2.8490, Accuracy: 2580/5000 (52%)\n",
      "[epoch 18] loss: 0.0286342\n",
      "Test set: Average loss: 3.0863, Accuracy: 2502/5000 (50%)\n",
      "[epoch 19] loss: 0.0185001\n",
      "Test set: Average loss: 2.9747, Accuracy: 2546/5000 (51%)\n",
      "[epoch 20] loss: 0.0131512\n",
      "Test set: Average loss: 3.1170, Accuracy: 2526/5000 (51%)\n",
      "[epoch 21] loss: 0.0123704\n",
      "Test set: Average loss: 3.0794, Accuracy: 2518/5000 (50%)\n",
      "[epoch 22] loss: 0.0039491\n",
      "Test set: Average loss: 3.0705, Accuracy: 2580/5000 (52%)\n",
      "[epoch 23] loss: 0.0028249\n",
      "Test set: Average loss: 3.1097, Accuracy: 2550/5000 (51%)\n",
      "[epoch 24] loss: 0.0022555\n",
      "Test set: Average loss: 3.1240, Accuracy: 2574/5000 (51%)\n",
      "[epoch 25] loss: 0.0018950\n",
      "Test set: Average loss: 3.1498, Accuracy: 2560/5000 (51%)\n",
      "[epoch 26] loss: 0.0017521\n",
      "Test set: Average loss: 3.1752, Accuracy: 2564/5000 (51%)\n",
      "[epoch 27] loss: 0.0016763\n",
      "Test set: Average loss: 3.1937, Accuracy: 2555/5000 (51%)\n",
      "[epoch 28] loss: 0.0015264\n",
      "Test set: Average loss: 3.2076, Accuracy: 2562/5000 (51%)\n",
      "[epoch 29] loss: 0.0013725\n",
      "Test set: Average loss: 3.2292, Accuracy: 2568/5000 (51%)\n",
      "[epoch 30] loss: 0.0012941\n",
      "Test set: Average loss: 3.2444, Accuracy: 2561/5000 (51%)\n",
      "[epoch 31] loss: 0.0012202\n",
      "Test set: Average loss: 3.2611, Accuracy: 2551/5000 (51%)\n",
      "[epoch 32] loss: 0.0011180\n",
      "Test set: Average loss: 3.2749, Accuracy: 2559/5000 (51%)\n",
      "[epoch 33] loss: 0.0010648\n",
      "Test set: Average loss: 3.2909, Accuracy: 2556/5000 (51%)\n",
      "[epoch 34] loss: 0.0010029\n",
      "Test set: Average loss: 3.3026, Accuracy: 2555/5000 (51%)\n",
      "[epoch 35] loss: 0.0009705\n",
      "Test set: Average loss: 3.3171, Accuracy: 2558/5000 (51%)\n",
      "[epoch 36] loss: 0.0009198\n",
      "Test set: Average loss: 3.3323, Accuracy: 2559/5000 (51%)\n",
      "[epoch 37] loss: 0.0008557\n",
      "Test set: Average loss: 3.3436, Accuracy: 2560/5000 (51%)\n",
      "[epoch 38] loss: 0.0008212\n",
      "Test set: Average loss: 3.3568, Accuracy: 2554/5000 (51%)\n",
      "[epoch 39] loss: 0.0007947\n",
      "Test set: Average loss: 3.3702, Accuracy: 2558/5000 (51%)\n",
      "[epoch 40] loss: 0.0007541\n",
      "Test set: Average loss: 3.3826, Accuracy: 2556/5000 (51%)\n",
      "[epoch 41] loss: 0.0007362\n",
      "Test set: Average loss: 3.3925, Accuracy: 2558/5000 (51%)\n",
      "[epoch 42] loss: 0.0006983\n",
      "Test set: Average loss: 3.4054, Accuracy: 2554/5000 (51%)\n",
      "[epoch 43] loss: 0.0006725\n",
      "Test set: Average loss: 3.4187, Accuracy: 2550/5000 (51%)\n",
      "[epoch 44] loss: 0.0006443\n",
      "Test set: Average loss: 3.4285, Accuracy: 2552/5000 (51%)\n",
      "[epoch 45] loss: 0.0006237\n",
      "Test set: Average loss: 3.4386, Accuracy: 2548/5000 (51%)\n",
      "[epoch 46] loss: 0.0005924\n",
      "Test set: Average loss: 3.4504, Accuracy: 2556/5000 (51%)\n",
      "[epoch 47] loss: 0.0005682\n",
      "Test set: Average loss: 3.4620, Accuracy: 2552/5000 (51%)\n",
      "[epoch 48] loss: 0.0005542\n",
      "Test set: Average loss: 3.4743, Accuracy: 2551/5000 (51%)\n",
      "[epoch 49] loss: 0.0005257\n",
      "Test set: Average loss: 3.4859, Accuracy: 2551/5000 (51%)\n",
      "[epoch 50] loss: 0.0005160\n",
      "Test set: Average loss: 3.4935, Accuracy: 2551/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3528, Accuracy: 2773/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.3084, Accuracy: 5578/10000 (56%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2909, Accuracy: 1005/5000 (20%)\n",
      "[epoch 1] loss: 1.7571780\n",
      "Test set: Average loss: 1.4766, Accuracy: 2445/5000 (49%)\n",
      "[epoch 2] loss: 1.3190164\n",
      "Test set: Average loss: 1.3957, Accuracy: 2532/5000 (51%)\n",
      "[epoch 3] loss: 1.1170739\n",
      "Test set: Average loss: 1.3852, Accuracy: 2572/5000 (51%)\n",
      "[epoch 4] loss: 0.9937553\n",
      "Test set: Average loss: 1.3684, Accuracy: 2646/5000 (53%)\n",
      "[epoch 5] loss: 0.7992141\n",
      "Test set: Average loss: 1.4530, Accuracy: 2680/5000 (54%)\n",
      "[epoch 6] loss: 0.7871200\n",
      "Test set: Average loss: 1.5472, Accuracy: 2549/5000 (51%)\n",
      "[epoch 7] loss: 0.5737837\n",
      "Test set: Average loss: 1.7863, Accuracy: 2467/5000 (49%)\n",
      "[epoch 8] loss: 0.5269587\n",
      "Test set: Average loss: 1.7503, Accuracy: 2575/5000 (52%)\n",
      "[epoch 9] loss: 0.4307752\n",
      "Test set: Average loss: 1.8292, Accuracy: 2589/5000 (52%)\n",
      "[epoch 10] loss: 0.3541156\n",
      "Test set: Average loss: 1.9671, Accuracy: 2464/5000 (49%)\n",
      "[epoch 11] loss: 0.2270338\n",
      "Test set: Average loss: 2.1573, Accuracy: 2507/5000 (50%)\n",
      "[epoch 12] loss: 0.1776882\n",
      "Test set: Average loss: 2.3539, Accuracy: 2442/5000 (49%)\n",
      "[epoch 13] loss: 0.2405012\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.6030, Accuracy: 2398/5000 (48%)\n",
      "[epoch 14] loss: 0.1313508\n",
      "Test set: Average loss: 2.2831, Accuracy: 2554/5000 (51%)\n",
      "[epoch 15] loss: 0.0612125\n",
      "Test set: Average loss: 2.2750, Accuracy: 2576/5000 (52%)\n",
      "[epoch 16] loss: 0.0508169\n",
      "Test set: Average loss: 2.2888, Accuracy: 2571/5000 (51%)\n",
      "[epoch 17] loss: 0.0455689\n",
      "Test set: Average loss: 2.3047, Accuracy: 2582/5000 (52%)\n",
      "[epoch 18] loss: 0.0424992\n",
      "Test set: Average loss: 2.3237, Accuracy: 2584/5000 (52%)\n",
      "[epoch 19] loss: 0.0395529\n",
      "Test set: Average loss: 2.3350, Accuracy: 2583/5000 (52%)\n",
      "[epoch 20] loss: 0.0368539\n",
      "Test set: Average loss: 2.3491, Accuracy: 2592/5000 (52%)\n",
      "[epoch 21] loss: 0.0346939\n",
      "Test set: Average loss: 2.3669, Accuracy: 2580/5000 (52%)\n",
      "[epoch 22] loss: 0.0318469\n",
      "Test set: Average loss: 2.3808, Accuracy: 2587/5000 (52%)\n",
      "[epoch 23] loss: 0.0395834\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3979, Accuracy: 2578/5000 (52%)\n",
      "[epoch 24] loss: 0.0286491\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 25] loss: 0.0286555\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3995, Accuracy: 2580/5000 (52%)\n",
      "[epoch 26] loss: 0.0275594\n",
      "Test set: Average loss: 2.3996, Accuracy: 2580/5000 (52%)\n",
      "[epoch 27] loss: 0.0284618\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 28] loss: 0.0280497\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 29] loss: 0.0274897\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 30] loss: 0.0276798\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 31] loss: 0.0276521\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 32] loss: 0.0281635\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 33] loss: 0.0278658\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 34] loss: 0.0276247\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 35] loss: 0.0276985\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 36] loss: 0.0277484\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 37] loss: 0.0288005\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 38] loss: 0.0289240\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 39] loss: 0.0279867\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 40] loss: 0.0277471\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 41] loss: 0.0276700\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 42] loss: 0.0278434\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 43] loss: 0.0279743\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 44] loss: 0.0278310\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 45] loss: 0.0279648\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 46] loss: 0.0279462\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 47] loss: 0.0283523\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 48] loss: 0.0280403\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 49] loss: 0.0276038\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "[epoch 50] loss: 0.0275940\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3998, Accuracy: 2580/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4530, Accuracy: 2680/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.4044, Accuracy: 5482/10000 (55%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3014, Accuracy: 513/5000 (10%)\n",
      "[epoch 1] loss: 1.4864822\n",
      "Test set: Average loss: 1.4640, Accuracy: 2508/5000 (50%)\n",
      "[epoch 2] loss: 1.1551300\n",
      "Test set: Average loss: 1.2691, Accuracy: 2823/5000 (56%)\n",
      "[epoch 3] loss: 1.0883710\n",
      "Test set: Average loss: 1.2226, Accuracy: 2864/5000 (57%)\n",
      "[epoch 4] loss: 0.9134935\n",
      "Test set: Average loss: 1.3231, Accuracy: 2752/5000 (55%)\n",
      "[epoch 5] loss: 0.8784274\n",
      "Test set: Average loss: 1.4247, Accuracy: 2710/5000 (54%)\n",
      "[epoch 6] loss: 0.8211858\n",
      "Test set: Average loss: 1.3686, Accuracy: 2827/5000 (57%)\n",
      "[epoch 7] loss: 0.7186149\n",
      "Test set: Average loss: 1.4460, Accuracy: 2762/5000 (55%)\n",
      "[epoch 8] loss: 0.6531264\n",
      "Test set: Average loss: 1.6575, Accuracy: 2630/5000 (53%)\n",
      "[epoch 9] loss: 0.6081670\n",
      "Test set: Average loss: 1.6918, Accuracy: 2675/5000 (54%)\n",
      "[epoch 10] loss: 0.5475846\n",
      "Test set: Average loss: 1.9925, Accuracy: 2509/5000 (50%)\n",
      "[epoch 11] loss: 0.5573446\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8882, Accuracy: 2594/5000 (52%)\n",
      "[epoch 12] loss: 0.3110244\n",
      "Test set: Average loss: 1.7289, Accuracy: 2760/5000 (55%)\n",
      "[epoch 13] loss: 0.2418669\n",
      "Test set: Average loss: 1.7434, Accuracy: 2765/5000 (55%)\n",
      "[epoch 14] loss: 0.2167337\n",
      "Test set: Average loss: 1.7816, Accuracy: 2763/5000 (55%)\n",
      "[epoch 15] loss: 0.2049199\n",
      "Test set: Average loss: 1.7937, Accuracy: 2768/5000 (55%)\n",
      "[epoch 16] loss: 0.1901524\n",
      "Test set: Average loss: 1.8230, Accuracy: 2787/5000 (56%)\n",
      "[epoch 17] loss: 0.1811968\n",
      "Test set: Average loss: 1.8421, Accuracy: 2788/5000 (56%)\n",
      "[epoch 18] loss: 0.1703434\n",
      "Test set: Average loss: 1.8829, Accuracy: 2781/5000 (56%)\n",
      "[epoch 19] loss: 0.1617481\n",
      "Test set: Average loss: 1.9096, Accuracy: 2774/5000 (55%)\n",
      "[epoch 20] loss: 0.1520430\n",
      "Test set: Average loss: 1.9380, Accuracy: 2774/5000 (55%)\n",
      "[epoch 21] loss: 0.1514193\n",
      "Test set: Average loss: 1.9625, Accuracy: 2786/5000 (56%)\n",
      "[epoch 22] loss: 0.1594076\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0023, Accuracy: 2790/5000 (56%)\n",
      "[epoch 23] loss: 0.1229808\n",
      "Test set: Average loss: 1.9960, Accuracy: 2780/5000 (56%)\n",
      "[epoch 24] loss: 0.1204784\n",
      "Test set: Average loss: 1.9977, Accuracy: 2794/5000 (56%)\n",
      "[epoch 25] loss: 0.1170713\n",
      "Test set: Average loss: 2.0013, Accuracy: 2790/5000 (56%)\n",
      "[epoch 26] loss: 0.1184033\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0047, Accuracy: 2786/5000 (56%)\n",
      "[epoch 27] loss: 0.1148814\n",
      "Test set: Average loss: 2.0052, Accuracy: 2785/5000 (56%)\n",
      "[epoch 28] loss: 0.1148493\n",
      "Test set: Average loss: 2.0056, Accuracy: 2788/5000 (56%)\n",
      "[epoch 29] loss: 0.1150023\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0059, Accuracy: 2787/5000 (56%)\n",
      "[epoch 30] loss: 0.1142959\n",
      "Test set: Average loss: 2.0060, Accuracy: 2788/5000 (56%)\n",
      "[epoch 31] loss: 0.1140639\n",
      "Test set: Average loss: 2.0060, Accuracy: 2788/5000 (56%)\n",
      "[epoch 32] loss: 0.1136692\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 33] loss: 0.1144027\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 34] loss: 0.1135121\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 35] loss: 0.1136038\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 36] loss: 0.1143482\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 37] loss: 0.1139611\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 38] loss: 0.1281586\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 39] loss: 0.1136636\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 40] loss: 0.1145514\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 41] loss: 0.1132505\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 42] loss: 0.1145190\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 43] loss: 0.1139963\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 44] loss: 0.1134342\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 45] loss: 0.1152082\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 46] loss: 0.1154844\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 47] loss: 0.1140247\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 48] loss: 0.1151294\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 49] loss: 0.1136711\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "[epoch 50] loss: 0.1139877\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0061, Accuracy: 2787/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2226, Accuracy: 2864/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.1819, Accuracy: 5996/10000 (60%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3054, Accuracy: 403/5000 (8%)\n",
      "[epoch 1] loss: 1.4607422\n",
      "Test set: Average loss: 1.3316, Accuracy: 2708/5000 (54%)\n",
      "[epoch 2] loss: 1.1147468\n",
      "Test set: Average loss: 1.3072, Accuracy: 2764/5000 (55%)\n",
      "[epoch 3] loss: 1.0199070\n",
      "Test set: Average loss: 1.4447, Accuracy: 2563/5000 (51%)\n",
      "[epoch 4] loss: 0.9418255\n",
      "Test set: Average loss: 1.3161, Accuracy: 2775/5000 (56%)\n",
      "[epoch 5] loss: 0.7923364\n",
      "Test set: Average loss: 1.4205, Accuracy: 2734/5000 (55%)\n",
      "[epoch 6] loss: 0.8018413\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5726, Accuracy: 2609/5000 (52%)\n",
      "[epoch 7] loss: 0.5195490\n",
      "Test set: Average loss: 1.3320, Accuracy: 2929/5000 (59%)\n",
      "[epoch 8] loss: 0.4375839\n",
      "Test set: Average loss: 1.3348, Accuracy: 2943/5000 (59%)\n",
      "[epoch 9] loss: 0.4174105\n",
      "Test set: Average loss: 1.3486, Accuracy: 2942/5000 (59%)\n",
      "[epoch 10] loss: 0.4006015\n",
      "Test set: Average loss: 1.3752, Accuracy: 2940/5000 (59%)\n",
      "[epoch 11] loss: 0.3903898\n",
      "Test set: Average loss: 1.3979, Accuracy: 2906/5000 (58%)\n",
      "[epoch 12] loss: 0.3644972\n",
      "Test set: Average loss: 1.4165, Accuracy: 2931/5000 (59%)\n",
      "[epoch 13] loss: 0.3522176\n",
      "Test set: Average loss: 1.4422, Accuracy: 2929/5000 (59%)\n",
      "[epoch 14] loss: 0.3400315\n",
      "Test set: Average loss: 1.4674, Accuracy: 2916/5000 (58%)\n",
      "[epoch 15] loss: 0.3248846\n",
      "Test set: Average loss: 1.4953, Accuracy: 2905/5000 (58%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 0.3101294\n",
      "Test set: Average loss: 1.5176, Accuracy: 2917/5000 (58%)\n",
      "[epoch 17] loss: 0.3066812\n",
      "Test set: Average loss: 1.5479, Accuracy: 2884/5000 (58%)\n",
      "[epoch 18] loss: 0.2938339\n",
      "Test set: Average loss: 1.5723, Accuracy: 2872/5000 (57%)\n",
      "[epoch 19] loss: 0.2711112\n",
      "Test set: Average loss: 1.6042, Accuracy: 2866/5000 (57%)\n",
      "[epoch 20] loss: 0.2554359\n",
      "Test set: Average loss: 1.6354, Accuracy: 2864/5000 (57%)\n",
      "[epoch 21] loss: 0.2474213\n",
      "Test set: Average loss: 1.6642, Accuracy: 2855/5000 (57%)\n",
      "[epoch 22] loss: 0.2395923\n",
      "Test set: Average loss: 1.6888, Accuracy: 2869/5000 (57%)\n",
      "[epoch 23] loss: 0.2241495\n",
      "Test set: Average loss: 1.7251, Accuracy: 2819/5000 (56%)\n",
      "[epoch 24] loss: 0.2165975\n",
      "Test set: Average loss: 1.7586, Accuracy: 2840/5000 (57%)\n",
      "[epoch 25] loss: 0.2059961\n",
      "Test set: Average loss: 1.8060, Accuracy: 2829/5000 (57%)\n",
      "[epoch 26] loss: 0.1972919\n",
      "Test set: Average loss: 1.8291, Accuracy: 2847/5000 (57%)\n",
      "[epoch 27] loss: 0.1815652\n",
      "Test set: Average loss: 1.8575, Accuracy: 2817/5000 (56%)\n",
      "[epoch 28] loss: 0.1704267\n",
      "Test set: Average loss: 1.9047, Accuracy: 2810/5000 (56%)\n",
      "[epoch 29] loss: 0.1627395\n",
      "Test set: Average loss: 1.9411, Accuracy: 2805/5000 (56%)\n",
      "[epoch 30] loss: 0.1557300\n",
      "Test set: Average loss: 1.9703, Accuracy: 2801/5000 (56%)\n",
      "[epoch 31] loss: 0.1461500\n",
      "Test set: Average loss: 2.0034, Accuracy: 2812/5000 (56%)\n",
      "[epoch 32] loss: 0.1380145\n",
      "Test set: Average loss: 2.0489, Accuracy: 2795/5000 (56%)\n",
      "[epoch 33] loss: 0.1336896\n",
      "Test set: Average loss: 2.0792, Accuracy: 2783/5000 (56%)\n",
      "[epoch 34] loss: 0.1276370\n",
      "Test set: Average loss: 2.1163, Accuracy: 2790/5000 (56%)\n",
      "[epoch 35] loss: 0.1148538\n",
      "Test set: Average loss: 2.1539, Accuracy: 2799/5000 (56%)\n",
      "[epoch 36] loss: 0.1065960\n",
      "Test set: Average loss: 2.1845, Accuracy: 2789/5000 (56%)\n",
      "[epoch 37] loss: 0.1010474\n",
      "Test set: Average loss: 2.2358, Accuracy: 2778/5000 (56%)\n",
      "[epoch 38] loss: 0.0965083\n",
      "Test set: Average loss: 2.2700, Accuracy: 2785/5000 (56%)\n",
      "[epoch 39] loss: 0.0877780\n",
      "Test set: Average loss: 2.3143, Accuracy: 2773/5000 (55%)\n",
      "[epoch 40] loss: 0.0820213\n",
      "Test set: Average loss: 2.3660, Accuracy: 2747/5000 (55%)\n",
      "[epoch 41] loss: 0.0815589\n",
      "Test set: Average loss: 2.3952, Accuracy: 2756/5000 (55%)\n",
      "[epoch 42] loss: 0.0729421\n",
      "Test set: Average loss: 2.4393, Accuracy: 2754/5000 (55%)\n",
      "[epoch 43] loss: 0.0679199\n",
      "Test set: Average loss: 2.4692, Accuracy: 2754/5000 (55%)\n",
      "[epoch 44] loss: 0.0619307\n",
      "Test set: Average loss: 2.5037, Accuracy: 2756/5000 (55%)\n",
      "[epoch 45] loss: 0.0567285\n",
      "Test set: Average loss: 2.5480, Accuracy: 2762/5000 (55%)\n",
      "[epoch 46] loss: 0.0529595\n",
      "Test set: Average loss: 2.5748, Accuracy: 2749/5000 (55%)\n",
      "[epoch 47] loss: 0.2749585\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.6434, Accuracy: 2723/5000 (54%)\n",
      "[epoch 48] loss: 0.0550443\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.6200, Accuracy: 2739/5000 (55%)\n",
      "[epoch 49] loss: 0.0429772\n",
      "Test set: Average loss: 2.6198, Accuracy: 2745/5000 (55%)\n",
      "[epoch 50] loss: 0.0421675\n",
      "Test set: Average loss: 2.6198, Accuracy: 2744/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3348, Accuracy: 2943/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 1.3040, Accuracy: 6040/10000 (60%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3178, Accuracy: 93/5000 (2%)\n",
      "[epoch 1] loss: 1.5236169\n",
      "Test set: Average loss: 1.3316, Accuracy: 2706/5000 (54%)\n",
      "[epoch 2] loss: 1.1402827\n",
      "Test set: Average loss: 1.3564, Accuracy: 2672/5000 (53%)\n",
      "[epoch 3] loss: 1.0611727\n",
      "Test set: Average loss: 1.3331, Accuracy: 2758/5000 (55%)\n",
      "[epoch 4] loss: 0.9287960\n",
      "Test set: Average loss: 1.3827, Accuracy: 2693/5000 (54%)\n",
      "[epoch 5] loss: 0.8810257\n",
      "Test set: Average loss: 1.4001, Accuracy: 2712/5000 (54%)\n",
      "[epoch 6] loss: 0.8016392\n",
      "Test set: Average loss: 1.4416, Accuracy: 2730/5000 (55%)\n",
      "[epoch 7] loss: 0.7775460\n",
      "Test set: Average loss: 1.4648, Accuracy: 2745/5000 (55%)\n",
      "[epoch 8] loss: 0.6485023\n",
      "Test set: Average loss: 1.4970, Accuracy: 2779/5000 (56%)\n",
      "[epoch 9] loss: 0.6240086\n",
      "Test set: Average loss: 1.6918, Accuracy: 2641/5000 (53%)\n",
      "[epoch 10] loss: 0.5735139\n",
      "Test set: Average loss: 1.8641, Accuracy: 2631/5000 (53%)\n",
      "[epoch 11] loss: 0.5924848\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9325, Accuracy: 2533/5000 (51%)\n",
      "[epoch 12] loss: 0.3345182\n",
      "Test set: Average loss: 1.6964, Accuracy: 2760/5000 (55%)\n",
      "[epoch 13] loss: 0.2634511\n",
      "Test set: Average loss: 1.7141, Accuracy: 2791/5000 (56%)\n",
      "[epoch 14] loss: 0.2399826\n",
      "Test set: Average loss: 1.7289, Accuracy: 2785/5000 (56%)\n",
      "[epoch 15] loss: 0.2228668\n",
      "Test set: Average loss: 1.7566, Accuracy: 2799/5000 (56%)\n",
      "[epoch 16] loss: 0.2117277\n",
      "Test set: Average loss: 1.7731, Accuracy: 2797/5000 (56%)\n",
      "[epoch 17] loss: 0.2015586\n",
      "Test set: Average loss: 1.8145, Accuracy: 2776/5000 (56%)\n",
      "[epoch 18] loss: 0.1971363\n",
      "Test set: Average loss: 1.8402, Accuracy: 2795/5000 (56%)\n",
      "[epoch 19] loss: 0.1777941\n",
      "Test set: Average loss: 1.8631, Accuracy: 2785/5000 (56%)\n",
      "[epoch 20] loss: 0.1711853\n",
      "Test set: Average loss: 1.9038, Accuracy: 2763/5000 (55%)\n",
      "[epoch 21] loss: 0.1596730\n",
      "Test set: Average loss: 1.9409, Accuracy: 2778/5000 (56%)\n",
      "[epoch 22] loss: 0.1499230\n",
      "Test set: Average loss: 1.9681, Accuracy: 2776/5000 (56%)\n",
      "[epoch 23] loss: 0.1443258\n",
      "Test set: Average loss: 1.9993, Accuracy: 2769/5000 (55%)\n",
      "[epoch 24] loss: 0.1361082\n",
      "Test set: Average loss: 2.0278, Accuracy: 2759/5000 (55%)\n",
      "[epoch 25] loss: 0.1264959\n",
      "Test set: Average loss: 2.0671, Accuracy: 2767/5000 (55%)\n",
      "[epoch 26] loss: 0.1191418\n",
      "Test set: Average loss: 2.1090, Accuracy: 2739/5000 (55%)\n",
      "[epoch 27] loss: 0.1119779\n",
      "Test set: Average loss: 2.1504, Accuracy: 2758/5000 (55%)\n",
      "[epoch 28] loss: 0.1067526\n",
      "Test set: Average loss: 2.1759, Accuracy: 2749/5000 (55%)\n",
      "[epoch 29] loss: 0.1022562\n",
      "Test set: Average loss: 2.2196, Accuracy: 2735/5000 (55%)\n",
      "[epoch 30] loss: 0.0939019\n",
      "Test set: Average loss: 2.2495, Accuracy: 2745/5000 (55%)\n",
      "[epoch 31] loss: 0.0887871\n",
      "Test set: Average loss: 2.2913, Accuracy: 2734/5000 (55%)\n",
      "[epoch 32] loss: 0.0827515\n",
      "Test set: Average loss: 2.3389, Accuracy: 2736/5000 (55%)\n",
      "[epoch 33] loss: 0.0787770\n",
      "Test set: Average loss: 2.3646, Accuracy: 2737/5000 (55%)\n",
      "[epoch 34] loss: 0.0769113\n",
      "Test set: Average loss: 2.4003, Accuracy: 2716/5000 (54%)\n",
      "[epoch 35] loss: 0.0709744\n",
      "Test set: Average loss: 2.4210, Accuracy: 2733/5000 (55%)\n",
      "[epoch 36] loss: 0.0643922\n",
      "Test set: Average loss: 2.4697, Accuracy: 2718/5000 (54%)\n",
      "[epoch 37] loss: 0.0578694\n",
      "Test set: Average loss: 2.5144, Accuracy: 2708/5000 (54%)\n",
      "[epoch 38] loss: 0.0563988\n",
      "Test set: Average loss: 2.5466, Accuracy: 2716/5000 (54%)\n",
      "[epoch 39] loss: 0.0526793\n",
      "Test set: Average loss: 2.5761, Accuracy: 2704/5000 (54%)\n",
      "[epoch 40] loss: 0.0487202\n",
      "Test set: Average loss: 2.6128, Accuracy: 2708/5000 (54%)\n",
      "[epoch 41] loss: 0.0443764\n",
      "Test set: Average loss: 2.6648, Accuracy: 2693/5000 (54%)\n",
      "[epoch 42] loss: 0.0418871\n",
      "Test set: Average loss: 2.6919, Accuracy: 2702/5000 (54%)\n",
      "[epoch 43] loss: 0.0373636\n",
      "Test set: Average loss: 2.7355, Accuracy: 2703/5000 (54%)\n",
      "[epoch 44] loss: 0.0346824\n",
      "Test set: Average loss: 2.7696, Accuracy: 2701/5000 (54%)\n",
      "[epoch 45] loss: 0.0310694\n",
      "Test set: Average loss: 2.7931, Accuracy: 2692/5000 (54%)\n",
      "[epoch 46] loss: 0.0295461\n",
      "Test set: Average loss: 2.8383, Accuracy: 2693/5000 (54%)\n",
      "[epoch 47] loss: 0.0283198\n",
      "Test set: Average loss: 2.8677, Accuracy: 2700/5000 (54%)\n",
      "[epoch 48] loss: 0.0254234\n",
      "Test set: Average loss: 2.9037, Accuracy: 2700/5000 (54%)\n",
      "[epoch 49] loss: 0.0236030\n",
      "Test set: Average loss: 2.9334, Accuracy: 2694/5000 (54%)\n",
      "[epoch 50] loss: 0.0215187\n",
      "Test set: Average loss: 2.9708, Accuracy: 2687/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7566, Accuracy: 2799/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.7691, Accuracy: 5599/10000 (56%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2998, Accuracy: 608/5000 (12%)\n",
      "[epoch 1] loss: 1.3207602\n",
      "Test set: Average loss: 1.2758, Accuracy: 2805/5000 (56%)\n",
      "[epoch 2] loss: 1.1043059\n",
      "Test set: Average loss: 1.3132, Accuracy: 2712/5000 (54%)\n",
      "[epoch 3] loss: 1.0302878\n",
      "Test set: Average loss: 1.2825, Accuracy: 2830/5000 (57%)\n",
      "[epoch 4] loss: 0.9543391\n",
      "Test set: Average loss: 1.2879, Accuracy: 2834/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 0.9120078\n",
      "Test set: Average loss: 1.3668, Accuracy: 2735/5000 (55%)\n",
      "[epoch 6] loss: 0.8884452\n",
      "Test set: Average loss: 1.3062, Accuracy: 2874/5000 (57%)\n",
      "[epoch 7] loss: 0.8037715\n",
      "Test set: Average loss: 1.3954, Accuracy: 2810/5000 (56%)\n",
      "[epoch 8] loss: 0.7913685\n",
      "Test set: Average loss: 1.4111, Accuracy: 2789/5000 (56%)\n",
      "[epoch 9] loss: 0.7560288\n",
      "Test set: Average loss: 1.4152, Accuracy: 2784/5000 (56%)\n",
      "[epoch 10] loss: 0.7359562\n",
      "Test set: Average loss: 1.5118, Accuracy: 2747/5000 (55%)\n",
      "[epoch 11] loss: 0.7164264\n",
      "Test set: Average loss: 1.4791, Accuracy: 2761/5000 (55%)\n",
      "[epoch 12] loss: 0.6850907\n",
      "Test set: Average loss: 1.5152, Accuracy: 2784/5000 (56%)\n",
      "[epoch 13] loss: 0.6501547\n",
      "Test set: Average loss: 1.6337, Accuracy: 2725/5000 (54%)\n",
      "[epoch 14] loss: 0.6178790\n",
      "Test set: Average loss: 1.5675, Accuracy: 2778/5000 (56%)\n",
      "[epoch 15] loss: 0.6301985\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7098, Accuracy: 2631/5000 (53%)\n",
      "[epoch 16] loss: 0.4113010\n",
      "Test set: Average loss: 1.5219, Accuracy: 2835/5000 (57%)\n",
      "[epoch 17] loss: 0.3478711\n",
      "Test set: Average loss: 1.5613, Accuracy: 2830/5000 (57%)\n",
      "[epoch 18] loss: 0.3260990\n",
      "Test set: Average loss: 1.5890, Accuracy: 2833/5000 (57%)\n",
      "[epoch 19] loss: 0.3118396\n",
      "Test set: Average loss: 1.6305, Accuracy: 2846/5000 (57%)\n",
      "[epoch 20] loss: 0.2976732\n",
      "Test set: Average loss: 1.6591, Accuracy: 2836/5000 (57%)\n",
      "[epoch 21] loss: 0.2890138\n",
      "Test set: Average loss: 1.7073, Accuracy: 2820/5000 (56%)\n",
      "[epoch 22] loss: 0.2786894\n",
      "Test set: Average loss: 1.7284, Accuracy: 2818/5000 (56%)\n",
      "[epoch 23] loss: 0.2738185\n",
      "Test set: Average loss: 1.7586, Accuracy: 2834/5000 (57%)\n",
      "[epoch 24] loss: 0.2596332\n",
      "Test set: Average loss: 1.8015, Accuracy: 2825/5000 (56%)\n",
      "[epoch 25] loss: 0.2541506\n",
      "Test set: Average loss: 1.8395, Accuracy: 2817/5000 (56%)\n",
      "[epoch 26] loss: 0.2464952\n",
      "Test set: Average loss: 1.8610, Accuracy: 2820/5000 (56%)\n",
      "[epoch 27] loss: 0.2336859\n",
      "Test set: Average loss: 1.9061, Accuracy: 2800/5000 (56%)\n",
      "[epoch 28] loss: 0.2293955\n",
      "Test set: Average loss: 1.9404, Accuracy: 2815/5000 (56%)\n",
      "[epoch 29] loss: 0.2209958\n",
      "Test set: Average loss: 1.9759, Accuracy: 2790/5000 (56%)\n",
      "[epoch 30] loss: 0.2159836\n",
      "Test set: Average loss: 2.0148, Accuracy: 2800/5000 (56%)\n",
      "[epoch 31] loss: 0.2058579\n",
      "Test set: Average loss: 2.0551, Accuracy: 2781/5000 (56%)\n",
      "[epoch 32] loss: 0.1974193\n",
      "Test set: Average loss: 2.0886, Accuracy: 2789/5000 (56%)\n",
      "[epoch 33] loss: 0.1875186\n",
      "Test set: Average loss: 2.1278, Accuracy: 2799/5000 (56%)\n",
      "[epoch 34] loss: 0.1808349\n",
      "Test set: Average loss: 2.1710, Accuracy: 2795/5000 (56%)\n",
      "[epoch 35] loss: 0.1740125\n",
      "Test set: Average loss: 2.2167, Accuracy: 2781/5000 (56%)\n",
      "[epoch 36] loss: 0.1691771\n",
      "Test set: Average loss: 2.2486, Accuracy: 2772/5000 (55%)\n",
      "[epoch 37] loss: 0.1630087\n",
      "Test set: Average loss: 2.3015, Accuracy: 2760/5000 (55%)\n",
      "[epoch 38] loss: 0.1542556\n",
      "Test set: Average loss: 2.3325, Accuracy: 2782/5000 (56%)\n",
      "[epoch 39] loss: 0.1481636\n",
      "Test set: Average loss: 2.3796, Accuracy: 2777/5000 (56%)\n",
      "[epoch 40] loss: 0.1487151\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4340, Accuracy: 2765/5000 (55%)\n",
      "[epoch 41] loss: 0.1227084\n",
      "Test set: Average loss: 2.4221, Accuracy: 2774/5000 (55%)\n",
      "[epoch 42] loss: 0.1188327\n",
      "Test set: Average loss: 2.4259, Accuracy: 2776/5000 (56%)\n",
      "[epoch 43] loss: 0.1175737\n",
      "Test set: Average loss: 2.4299, Accuracy: 2777/5000 (56%)\n",
      "[epoch 44] loss: 0.1165702\n",
      "Test set: Average loss: 2.4343, Accuracy: 2774/5000 (55%)\n",
      "[epoch 45] loss: 0.1159116\n",
      "Test set: Average loss: 2.4401, Accuracy: 2777/5000 (56%)\n",
      "[epoch 46] loss: 0.1152329\n",
      "Test set: Average loss: 2.4469, Accuracy: 2775/5000 (56%)\n",
      "[epoch 47] loss: 0.1144639\n",
      "Test set: Average loss: 2.4513, Accuracy: 2774/5000 (55%)\n",
      "[epoch 48] loss: 0.1177090\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.4569, Accuracy: 2774/5000 (55%)\n",
      "[epoch 49] loss: 0.1122922\n",
      "Test set: Average loss: 2.4574, Accuracy: 2770/5000 (55%)\n",
      "[epoch 50] loss: 0.1123429\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.4580, Accuracy: 2764/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3062, Accuracy: 2874/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.2895, Accuracy: 5765/10000 (58%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2854, Accuracy: 778/5000 (16%)\n",
      "[epoch 1] loss: 1.3179433\n",
      "Test set: Average loss: 1.3262, Accuracy: 2698/5000 (54%)\n",
      "[epoch 2] loss: 1.0835271\n",
      "Test set: Average loss: 1.2419, Accuracy: 2890/5000 (58%)\n",
      "[epoch 3] loss: 1.0115526\n",
      "Test set: Average loss: 1.2941, Accuracy: 2815/5000 (56%)\n",
      "[epoch 4] loss: 0.9517726\n",
      "Test set: Average loss: 1.3548, Accuracy: 2721/5000 (54%)\n",
      "[epoch 5] loss: 0.9016424\n",
      "Test set: Average loss: 1.4106, Accuracy: 2656/5000 (53%)\n",
      "[epoch 6] loss: 0.8508062\n",
      "Test set: Average loss: 1.3443, Accuracy: 2844/5000 (57%)\n",
      "[epoch 7] loss: 0.8039119\n",
      "Test set: Average loss: 1.4308, Accuracy: 2760/5000 (55%)\n",
      "[epoch 8] loss: 0.7904977\n",
      "Test set: Average loss: 1.3859, Accuracy: 2826/5000 (57%)\n",
      "[epoch 9] loss: 0.7457032\n",
      "Test set: Average loss: 1.4028, Accuracy: 2872/5000 (57%)\n",
      "[epoch 10] loss: 0.6830731\n",
      "Test set: Average loss: 1.5499, Accuracy: 2734/5000 (55%)\n",
      "[epoch 11] loss: 0.6884038\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5020, Accuracy: 2760/5000 (55%)\n",
      "[epoch 12] loss: 0.4659970\n",
      "Test set: Average loss: 1.4292, Accuracy: 2918/5000 (58%)\n",
      "[epoch 13] loss: 0.4095825\n",
      "Test set: Average loss: 1.4539, Accuracy: 2898/5000 (58%)\n",
      "[epoch 14] loss: 0.3867436\n",
      "Test set: Average loss: 1.4894, Accuracy: 2892/5000 (58%)\n",
      "[epoch 15] loss: 0.3754687\n",
      "Test set: Average loss: 1.5116, Accuracy: 2919/5000 (58%)\n",
      "[epoch 16] loss: 0.3622328\n",
      "Test set: Average loss: 1.5418, Accuracy: 2920/5000 (58%)\n",
      "[epoch 17] loss: 0.3532744\n",
      "Test set: Average loss: 1.5765, Accuracy: 2916/5000 (58%)\n",
      "[epoch 18] loss: 0.3388869\n",
      "Test set: Average loss: 1.6077, Accuracy: 2920/5000 (58%)\n",
      "[epoch 19] loss: 0.3306741\n",
      "Test set: Average loss: 1.6390, Accuracy: 2899/5000 (58%)\n",
      "[epoch 20] loss: 0.3186952\n",
      "Test set: Average loss: 1.6715, Accuracy: 2877/5000 (58%)\n",
      "[epoch 21] loss: 0.3100886\n",
      "Test set: Average loss: 1.7110, Accuracy: 2885/5000 (58%)\n",
      "[epoch 22] loss: 0.3031193\n",
      "Test set: Average loss: 1.7293, Accuracy: 2898/5000 (58%)\n",
      "[epoch 23] loss: 0.2912236\n",
      "Test set: Average loss: 1.7657, Accuracy: 2886/5000 (58%)\n",
      "[epoch 24] loss: 0.2824010\n",
      "Test set: Average loss: 1.8058, Accuracy: 2864/5000 (57%)\n",
      "[epoch 25] loss: 0.2751898\n",
      "Test set: Average loss: 1.8313, Accuracy: 2868/5000 (57%)\n",
      "[epoch 26] loss: 0.2704868\n",
      "Test set: Average loss: 1.8619, Accuracy: 2858/5000 (57%)\n",
      "[epoch 27] loss: 0.2584193\n",
      "Test set: Average loss: 1.8944, Accuracy: 2849/5000 (57%)\n",
      "[epoch 28] loss: 0.2555160\n",
      "Test set: Average loss: 1.9199, Accuracy: 2873/5000 (57%)\n",
      "[epoch 29] loss: 0.2502037\n",
      "Test set: Average loss: 1.9597, Accuracy: 2852/5000 (57%)\n",
      "[epoch 30] loss: 0.2379222\n",
      "Test set: Average loss: 2.0014, Accuracy: 2837/5000 (57%)\n",
      "[epoch 31] loss: 0.2286798\n",
      "Test set: Average loss: 2.0331, Accuracy: 2851/5000 (57%)\n",
      "[epoch 32] loss: 0.2197067\n",
      "Test set: Average loss: 2.0803, Accuracy: 2829/5000 (57%)\n",
      "[epoch 33] loss: 0.2157806\n",
      "Test set: Average loss: 2.1017, Accuracy: 2854/5000 (57%)\n",
      "[epoch 34] loss: 0.2080800\n",
      "Test set: Average loss: 2.1389, Accuracy: 2830/5000 (57%)\n",
      "[epoch 35] loss: 0.2007447\n",
      "Test set: Average loss: 2.1691, Accuracy: 2846/5000 (57%)\n",
      "[epoch 36] loss: 0.1974187\n",
      "Test set: Average loss: 2.2257, Accuracy: 2833/5000 (57%)\n",
      "[epoch 37] loss: 0.1895632\n",
      "Test set: Average loss: 2.2531, Accuracy: 2815/5000 (56%)\n",
      "[epoch 38] loss: 0.1834472\n",
      "Test set: Average loss: 2.2948, Accuracy: 2825/5000 (56%)\n",
      "[epoch 39] loss: 0.1749784\n",
      "Test set: Average loss: 2.3231, Accuracy: 2805/5000 (56%)\n",
      "[epoch 40] loss: 0.1664777\n",
      "Test set: Average loss: 2.3684, Accuracy: 2809/5000 (56%)\n",
      "[epoch 41] loss: 0.1631709\n",
      "Test set: Average loss: 2.4029, Accuracy: 2808/5000 (56%)\n",
      "[epoch 42] loss: 0.1597832\n",
      "Test set: Average loss: 2.4422, Accuracy: 2808/5000 (56%)\n",
      "[epoch 43] loss: 0.1512278\n",
      "Test set: Average loss: 2.4910, Accuracy: 2798/5000 (56%)\n",
      "[epoch 44] loss: 0.1442844\n",
      "Test set: Average loss: 2.5430, Accuracy: 2793/5000 (56%)\n",
      "[epoch 45] loss: 0.1374129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5677, Accuracy: 2788/5000 (56%)\n",
      "[epoch 46] loss: 0.1334342\n",
      "Test set: Average loss: 2.6242, Accuracy: 2792/5000 (56%)\n",
      "[epoch 47] loss: 0.1311311\n",
      "Test set: Average loss: 2.6552, Accuracy: 2776/5000 (56%)\n",
      "[epoch 48] loss: 0.1231049\n",
      "Test set: Average loss: 2.7033, Accuracy: 2775/5000 (56%)\n",
      "[epoch 49] loss: 0.1172607\n",
      "Test set: Average loss: 2.7417, Accuracy: 2768/5000 (55%)\n",
      "[epoch 50] loss: 0.1128331\n",
      "Test set: Average loss: 2.7793, Accuracy: 2775/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6077, Accuracy: 2920/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.5655, Accuracy: 5907/10000 (59%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2913, Accuracy: 887/5000 (18%)\n",
      "[epoch 1] loss: 1.3391501\n",
      "Test set: Average loss: 1.3085, Accuracy: 2775/5000 (56%)\n",
      "[epoch 2] loss: 1.1143569\n",
      "Test set: Average loss: 1.1841, Accuracy: 2893/5000 (58%)\n",
      "[epoch 3] loss: 1.0468095\n",
      "Test set: Average loss: 1.2864, Accuracy: 2774/5000 (55%)\n",
      "[epoch 4] loss: 0.9803878\n",
      "Test set: Average loss: 1.3415, Accuracy: 2739/5000 (55%)\n",
      "[epoch 5] loss: 0.9184152\n",
      "Test set: Average loss: 1.3737, Accuracy: 2734/5000 (55%)\n",
      "[epoch 6] loss: 0.8949829\n",
      "Test set: Average loss: 1.3158, Accuracy: 2831/5000 (57%)\n",
      "[epoch 7] loss: 0.8341301\n",
      "Test set: Average loss: 1.3705, Accuracy: 2800/5000 (56%)\n",
      "[epoch 8] loss: 0.7976022\n",
      "Test set: Average loss: 1.4567, Accuracy: 2703/5000 (54%)\n",
      "[epoch 9] loss: 0.7810709\n",
      "Test set: Average loss: 1.5090, Accuracy: 2647/5000 (53%)\n",
      "[epoch 10] loss: 0.7698059\n",
      "Test set: Average loss: 1.4598, Accuracy: 2788/5000 (56%)\n",
      "[epoch 11] loss: 0.7538763\n",
      "Test set: Average loss: 1.4947, Accuracy: 2768/5000 (55%)\n",
      "[epoch 12] loss: 0.7053180\n",
      "Test set: Average loss: 1.4958, Accuracy: 2733/5000 (55%)\n",
      "[epoch 13] loss: 0.6754690\n",
      "Test set: Average loss: 1.5751, Accuracy: 2729/5000 (55%)\n",
      "[epoch 14] loss: 0.6138835\n",
      "Test set: Average loss: 1.6827, Accuracy: 2656/5000 (53%)\n",
      "[epoch 15] loss: 0.6078605\n",
      "Test set: Average loss: 1.6519, Accuracy: 2700/5000 (54%)\n",
      "[epoch 16] loss: 0.5946322\n",
      "Test set: Average loss: 1.6470, Accuracy: 2767/5000 (55%)\n",
      "[epoch 17] loss: 0.5858192\n",
      "Test set: Average loss: 1.7514, Accuracy: 2667/5000 (53%)\n",
      "[epoch 18] loss: 0.5705598\n",
      "Test set: Average loss: 1.7695, Accuracy: 2696/5000 (54%)\n",
      "[epoch 19] loss: 0.4981972\n",
      "Test set: Average loss: 1.8226, Accuracy: 2686/5000 (54%)\n",
      "[epoch 20] loss: 0.5058757\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8719, Accuracy: 2688/5000 (54%)\n",
      "[epoch 21] loss: 0.2738333\n",
      "Test set: Average loss: 1.7538, Accuracy: 2820/5000 (56%)\n",
      "[epoch 22] loss: 0.2295242\n",
      "Test set: Average loss: 1.7881, Accuracy: 2822/5000 (56%)\n",
      "[epoch 23] loss: 0.2134591\n",
      "Test set: Average loss: 1.8237, Accuracy: 2795/5000 (56%)\n",
      "[epoch 24] loss: 0.2007855\n",
      "Test set: Average loss: 1.8640, Accuracy: 2801/5000 (56%)\n",
      "[epoch 25] loss: 0.1932854\n",
      "Test set: Average loss: 1.8993, Accuracy: 2808/5000 (56%)\n",
      "[epoch 26] loss: 0.1824324\n",
      "Test set: Average loss: 1.9297, Accuracy: 2823/5000 (56%)\n",
      "[epoch 27] loss: 0.1748745\n",
      "Test set: Average loss: 1.9671, Accuracy: 2804/5000 (56%)\n",
      "[epoch 28] loss: 0.1676276\n",
      "Test set: Average loss: 2.0017, Accuracy: 2797/5000 (56%)\n",
      "[epoch 29] loss: 0.1623211\n",
      "Test set: Average loss: 2.0322, Accuracy: 2805/5000 (56%)\n",
      "[epoch 30] loss: 0.1531728\n",
      "Test set: Average loss: 2.0603, Accuracy: 2805/5000 (56%)\n",
      "[epoch 31] loss: 0.1457063\n",
      "Test set: Average loss: 2.1128, Accuracy: 2792/5000 (56%)\n",
      "[epoch 32] loss: 0.1404083\n",
      "Test set: Average loss: 2.1330, Accuracy: 2807/5000 (56%)\n",
      "[epoch 33] loss: 0.1329081\n",
      "Test set: Average loss: 2.1707, Accuracy: 2804/5000 (56%)\n",
      "[epoch 34] loss: 0.1296988\n",
      "Test set: Average loss: 2.2036, Accuracy: 2784/5000 (56%)\n",
      "[epoch 35] loss: 0.1202503\n",
      "Test set: Average loss: 2.2472, Accuracy: 2773/5000 (55%)\n",
      "[epoch 36] loss: 0.1161074\n",
      "Test set: Average loss: 2.2835, Accuracy: 2776/5000 (56%)\n",
      "[epoch 37] loss: 0.1112175\n",
      "Test set: Average loss: 2.3074, Accuracy: 2777/5000 (56%)\n",
      "[epoch 38] loss: 0.1049588\n",
      "Test set: Average loss: 2.3475, Accuracy: 2799/5000 (56%)\n",
      "[epoch 39] loss: 0.1892963\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3885, Accuracy: 2771/5000 (55%)\n",
      "[epoch 40] loss: 0.0862507\n",
      "Test set: Average loss: 2.3886, Accuracy: 2778/5000 (56%)\n",
      "[epoch 41] loss: 0.0830817\n",
      "Test set: Average loss: 2.3897, Accuracy: 2777/5000 (56%)\n",
      "[epoch 42] loss: 0.0819771\n",
      "Test set: Average loss: 2.3942, Accuracy: 2777/5000 (56%)\n",
      "[epoch 43] loss: 0.0810678\n",
      "Test set: Average loss: 2.3980, Accuracy: 2776/5000 (56%)\n",
      "[epoch 44] loss: 0.0807640\n",
      "Test set: Average loss: 2.4022, Accuracy: 2773/5000 (55%)\n",
      "[epoch 45] loss: 0.0804486\n",
      "Test set: Average loss: 2.4078, Accuracy: 2776/5000 (56%)\n",
      "[epoch 46] loss: 0.0796412\n",
      "Test set: Average loss: 2.4103, Accuracy: 2780/5000 (56%)\n",
      "[epoch 47] loss: 0.0791966\n",
      "Test set: Average loss: 2.4153, Accuracy: 2779/5000 (56%)\n",
      "[epoch 48] loss: 0.0783814\n",
      "Test set: Average loss: 2.4203, Accuracy: 2782/5000 (56%)\n",
      "[epoch 49] loss: 0.0779113\n",
      "Test set: Average loss: 2.4253, Accuracy: 2772/5000 (55%)\n",
      "[epoch 50] loss: 0.0774284\n",
      "Test set: Average loss: 2.4306, Accuracy: 2780/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1841, Accuracy: 2893/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.1366, Accuracy: 5977/10000 (60%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2872, Accuracy: 624/5000 (12%)\n",
      "[epoch 1] loss: 1.2489605\n",
      "Test set: Average loss: 1.2109, Accuracy: 2880/5000 (58%)\n",
      "[epoch 2] loss: 1.0905832\n",
      "Test set: Average loss: 1.2100, Accuracy: 2884/5000 (58%)\n",
      "[epoch 3] loss: 1.0331791\n",
      "Test set: Average loss: 1.1978, Accuracy: 2914/5000 (58%)\n",
      "[epoch 4] loss: 0.9857438\n",
      "Test set: Average loss: 1.2022, Accuracy: 2908/5000 (58%)\n",
      "[epoch 5] loss: 0.9541102\n",
      "Test set: Average loss: 1.2169, Accuracy: 2926/5000 (59%)\n",
      "[epoch 6] loss: 0.9331336\n",
      "Test set: Average loss: 1.1753, Accuracy: 2968/5000 (59%)\n",
      "[epoch 7] loss: 0.8897973\n",
      "Test set: Average loss: 1.2167, Accuracy: 2959/5000 (59%)\n",
      "[epoch 8] loss: 0.8752955\n",
      "Test set: Average loss: 1.2457, Accuracy: 2890/5000 (58%)\n",
      "[epoch 9] loss: 0.8406391\n",
      "Test set: Average loss: 1.2333, Accuracy: 2946/5000 (59%)\n",
      "[epoch 10] loss: 0.8184842\n",
      "Test set: Average loss: 1.3006, Accuracy: 2835/5000 (57%)\n",
      "[epoch 11] loss: 0.8103873\n",
      "Test set: Average loss: 1.2550, Accuracy: 2942/5000 (59%)\n",
      "[epoch 12] loss: 0.7808611\n",
      "Test set: Average loss: 1.3485, Accuracy: 2839/5000 (57%)\n",
      "[epoch 13] loss: 0.7453754\n",
      "Test set: Average loss: 1.3143, Accuracy: 2890/5000 (58%)\n",
      "[epoch 14] loss: 0.7164165\n",
      "Test set: Average loss: 1.2970, Accuracy: 2947/5000 (59%)\n",
      "[epoch 15] loss: 0.6806184\n",
      "Test set: Average loss: 1.3585, Accuracy: 2869/5000 (57%)\n",
      "[epoch 16] loss: 0.6420873\n",
      "Test set: Average loss: 1.3669, Accuracy: 2893/5000 (58%)\n",
      "[epoch 17] loss: 0.6206525\n",
      "Test set: Average loss: 1.4248, Accuracy: 2857/5000 (57%)\n",
      "[epoch 18] loss: 0.5638228\n",
      "Test set: Average loss: 1.4896, Accuracy: 2862/5000 (57%)\n",
      "[epoch 19] loss: 0.5146599\n",
      "Test set: Average loss: 1.4921, Accuracy: 2886/5000 (58%)\n",
      "[epoch 20] loss: 0.4811811\n",
      "Test set: Average loss: 1.4856, Accuracy: 2882/5000 (58%)\n",
      "[epoch 21] loss: 0.4430778\n",
      "Test set: Average loss: 1.4975, Accuracy: 2947/5000 (59%)\n",
      "[epoch 22] loss: 0.3594357\n",
      "Test set: Average loss: 1.5728, Accuracy: 2933/5000 (59%)\n",
      "[epoch 23] loss: 0.3143160\n",
      "Test set: Average loss: 1.6191, Accuracy: 2986/5000 (60%)\n",
      "[epoch 24] loss: 0.2556078\n",
      "Test set: Average loss: 1.6563, Accuracy: 2976/5000 (60%)\n",
      "[epoch 25] loss: 0.2150536\n",
      "Test set: Average loss: 1.7749, Accuracy: 2945/5000 (59%)\n",
      "[epoch 26] loss: 0.1908933\n",
      "Test set: Average loss: 1.7351, Accuracy: 2942/5000 (59%)\n",
      "[epoch 27] loss: 0.1439472\n",
      "Test set: Average loss: 1.8866, Accuracy: 2946/5000 (59%)\n",
      "[epoch 28] loss: 0.1017041\n",
      "Test set: Average loss: 1.9252, Accuracy: 2944/5000 (59%)\n",
      "[epoch 29] loss: 0.0658179\n",
      "Test set: Average loss: 2.0347, Accuracy: 2994/5000 (60%)\n",
      "[epoch 30] loss: 0.1316715\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1218, Accuracy: 2905/5000 (58%)\n",
      "[epoch 31] loss: 0.0618204\n",
      "Test set: Average loss: 1.9535, Accuracy: 3016/5000 (60%)\n",
      "[epoch 32] loss: 0.0274444\n",
      "Test set: Average loss: 1.9657, Accuracy: 3023/5000 (60%)\n",
      "[epoch 33] loss: 0.0208812\n",
      "Test set: Average loss: 1.9789, Accuracy: 3027/5000 (61%)\n",
      "[epoch 34] loss: 0.0171873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.9961, Accuracy: 3029/5000 (61%)\n",
      "[epoch 35] loss: 0.0147051\n",
      "Test set: Average loss: 2.0155, Accuracy: 3035/5000 (61%)\n",
      "[epoch 36] loss: 0.0128178\n",
      "Test set: Average loss: 2.0348, Accuracy: 3045/5000 (61%)\n",
      "[epoch 37] loss: 0.0112558\n",
      "Test set: Average loss: 2.0519, Accuracy: 3048/5000 (61%)\n",
      "[epoch 38] loss: 0.0099982\n",
      "Test set: Average loss: 2.0729, Accuracy: 3059/5000 (61%)\n",
      "[epoch 39] loss: 0.0088876\n",
      "Test set: Average loss: 2.0904, Accuracy: 3060/5000 (61%)\n",
      "[epoch 40] loss: 0.0079407\n",
      "Test set: Average loss: 2.1101, Accuracy: 3061/5000 (61%)\n",
      "[epoch 41] loss: 0.0070921\n",
      "Test set: Average loss: 2.1311, Accuracy: 3058/5000 (61%)\n",
      "[epoch 42] loss: 0.0063486\n",
      "Test set: Average loss: 2.1545, Accuracy: 3063/5000 (61%)\n",
      "[epoch 43] loss: 0.0056959\n",
      "Test set: Average loss: 2.1818, Accuracy: 3070/5000 (61%)\n",
      "[epoch 44] loss: 0.0050917\n",
      "Test set: Average loss: 2.2023, Accuracy: 3063/5000 (61%)\n",
      "[epoch 45] loss: 0.0045412\n",
      "Test set: Average loss: 2.2257, Accuracy: 3057/5000 (61%)\n",
      "[epoch 46] loss: 0.0040532\n",
      "Test set: Average loss: 2.2514, Accuracy: 3063/5000 (61%)\n",
      "[epoch 47] loss: 0.0036345\n",
      "Test set: Average loss: 2.2772, Accuracy: 3071/5000 (61%)\n",
      "[epoch 48] loss: 0.0032126\n",
      "Test set: Average loss: 2.3095, Accuracy: 3067/5000 (61%)\n",
      "[epoch 49] loss: 0.0028673\n",
      "Test set: Average loss: 2.3382, Accuracy: 3063/5000 (61%)\n",
      "[epoch 50] loss: 0.0025421\n",
      "Test set: Average loss: 2.3649, Accuracy: 3072/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3649, Accuracy: 3072/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.3214, Accuracy: 6091/10000 (61%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3108, Accuracy: 572/5000 (11%)\n",
      "[epoch 1] loss: 1.2477514\n",
      "Test set: Average loss: 1.2249, Accuracy: 2919/5000 (58%)\n",
      "[epoch 2] loss: 1.0895959\n",
      "Test set: Average loss: 1.2166, Accuracy: 2905/5000 (58%)\n",
      "[epoch 3] loss: 1.0329097\n",
      "Test set: Average loss: 1.1577, Accuracy: 2960/5000 (59%)\n",
      "[epoch 4] loss: 0.9770385\n",
      "Test set: Average loss: 1.1695, Accuracy: 2978/5000 (60%)\n",
      "[epoch 5] loss: 0.9621914\n",
      "Test set: Average loss: 1.3274, Accuracy: 2740/5000 (55%)\n",
      "[epoch 6] loss: 0.9276382\n",
      "Test set: Average loss: 1.1858, Accuracy: 2994/5000 (60%)\n",
      "[epoch 7] loss: 0.8989820\n",
      "Test set: Average loss: 1.2365, Accuracy: 2917/5000 (58%)\n",
      "[epoch 8] loss: 0.8689300\n",
      "Test set: Average loss: 1.2093, Accuracy: 2975/5000 (60%)\n",
      "[epoch 9] loss: 0.8478784\n",
      "Test set: Average loss: 1.2866, Accuracy: 2833/5000 (57%)\n",
      "[epoch 10] loss: 0.8172129\n",
      "Test set: Average loss: 1.2700, Accuracy: 2936/5000 (59%)\n",
      "[epoch 11] loss: 0.7840738\n",
      "Test set: Average loss: 1.2940, Accuracy: 2893/5000 (58%)\n",
      "[epoch 12] loss: 0.7710367\n",
      "Test set: Average loss: 1.2494, Accuracy: 2955/5000 (59%)\n",
      "[epoch 13] loss: 0.7346965\n",
      "Test set: Average loss: 1.3210, Accuracy: 2887/5000 (58%)\n",
      "[epoch 14] loss: 0.6860787\n",
      "Test set: Average loss: 1.2709, Accuracy: 2986/5000 (60%)\n",
      "[epoch 15] loss: 0.6673221\n",
      "Test set: Average loss: 1.3487, Accuracy: 2899/5000 (58%)\n",
      "[epoch 16] loss: 0.6168302\n",
      "Test set: Average loss: 1.3681, Accuracy: 2942/5000 (59%)\n",
      "[epoch 17] loss: 0.5688926\n",
      "Test set: Average loss: 1.3742, Accuracy: 2991/5000 (60%)\n",
      "[epoch 18] loss: 0.5269490\n",
      "Test set: Average loss: 1.4313, Accuracy: 2879/5000 (58%)\n",
      "[epoch 19] loss: 0.4896271\n",
      "Test set: Average loss: 1.4461, Accuracy: 2948/5000 (59%)\n",
      "[epoch 20] loss: 0.4281065\n",
      "Test set: Average loss: 1.4271, Accuracy: 2982/5000 (60%)\n",
      "[epoch 21] loss: 0.3841257\n",
      "Test set: Average loss: 1.5538, Accuracy: 2924/5000 (58%)\n",
      "[epoch 22] loss: 0.3246359\n",
      "Test set: Average loss: 1.5980, Accuracy: 2959/5000 (59%)\n",
      "[epoch 23] loss: 0.2721347\n",
      "Test set: Average loss: 1.6197, Accuracy: 2908/5000 (58%)\n",
      "[epoch 24] loss: 0.2285335\n",
      "Test set: Average loss: 1.6476, Accuracy: 2937/5000 (59%)\n",
      "[epoch 25] loss: 0.1848581\n",
      "Test set: Average loss: 1.8496, Accuracy: 2831/5000 (57%)\n",
      "[epoch 26] loss: 0.1462804\n",
      "Test set: Average loss: 1.8333, Accuracy: 2951/5000 (59%)\n",
      "[epoch 27] loss: 0.1084701\n",
      "Test set: Average loss: 1.8266, Accuracy: 2997/5000 (60%)\n",
      "[epoch 28] loss: 0.1132442\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9102, Accuracy: 2937/5000 (59%)\n",
      "[epoch 29] loss: 0.0358409\n",
      "Test set: Average loss: 1.8640, Accuracy: 3015/5000 (60%)\n",
      "[epoch 30] loss: 0.0217719\n",
      "Test set: Average loss: 1.8764, Accuracy: 3033/5000 (61%)\n",
      "[epoch 31] loss: 0.0182089\n",
      "Test set: Average loss: 1.8948, Accuracy: 3037/5000 (61%)\n",
      "[epoch 32] loss: 0.0159400\n",
      "Test set: Average loss: 1.9071, Accuracy: 3029/5000 (61%)\n",
      "[epoch 33] loss: 0.0142708\n",
      "Test set: Average loss: 1.9258, Accuracy: 3026/5000 (61%)\n",
      "[epoch 34] loss: 0.0128094\n",
      "Test set: Average loss: 1.9458, Accuracy: 3028/5000 (61%)\n",
      "[epoch 35] loss: 0.0116409\n",
      "Test set: Average loss: 1.9619, Accuracy: 3033/5000 (61%)\n",
      "[epoch 36] loss: 0.0105384\n",
      "Test set: Average loss: 1.9754, Accuracy: 3028/5000 (61%)\n",
      "[epoch 37] loss: 0.0095883\n",
      "Test set: Average loss: 1.9996, Accuracy: 3025/5000 (60%)\n",
      "[epoch 38] loss: 0.0086919\n",
      "Test set: Average loss: 2.0251, Accuracy: 3018/5000 (60%)\n",
      "[epoch 39] loss: 0.0079104\n",
      "Test set: Average loss: 2.0423, Accuracy: 3015/5000 (60%)\n",
      "[epoch 40] loss: 0.0071381\n",
      "Test set: Average loss: 2.0693, Accuracy: 3023/5000 (60%)\n",
      "[epoch 41] loss: 0.0064640\n",
      "Test set: Average loss: 2.0899, Accuracy: 3029/5000 (61%)\n",
      "[epoch 42] loss: 0.0058128\n",
      "Test set: Average loss: 2.1167, Accuracy: 3031/5000 (61%)\n",
      "[epoch 43] loss: 0.0052323\n",
      "Test set: Average loss: 2.1462, Accuracy: 3039/5000 (61%)\n",
      "[epoch 44] loss: 0.0047034\n",
      "Test set: Average loss: 2.1696, Accuracy: 3028/5000 (61%)\n",
      "[epoch 45] loss: 0.0042086\n",
      "Test set: Average loss: 2.1949, Accuracy: 3042/5000 (61%)\n",
      "[epoch 46] loss: 0.0037554\n",
      "Test set: Average loss: 2.2257, Accuracy: 3031/5000 (61%)\n",
      "[epoch 47] loss: 0.0033478\n",
      "Test set: Average loss: 2.2574, Accuracy: 3028/5000 (61%)\n",
      "[epoch 48] loss: 0.0029683\n",
      "Test set: Average loss: 2.2849, Accuracy: 3030/5000 (61%)\n",
      "[epoch 49] loss: 0.0026077\n",
      "Test set: Average loss: 2.3136, Accuracy: 3042/5000 (61%)\n",
      "[epoch 50] loss: 0.0023176\n",
      "Test set: Average loss: 2.3479, Accuracy: 3033/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3136, Accuracy: 3042/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.3231, Accuracy: 6123/10000 (61%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3053, Accuracy: 664/5000 (13%)\n",
      "[epoch 1] loss: 1.2861895\n",
      "Test set: Average loss: 1.2534, Accuracy: 2806/5000 (56%)\n",
      "[epoch 2] loss: 1.1287951\n",
      "Test set: Average loss: 1.2746, Accuracy: 2728/5000 (55%)\n",
      "[epoch 3] loss: 1.0749005\n",
      "Test set: Average loss: 1.1771, Accuracy: 2939/5000 (59%)\n",
      "[epoch 4] loss: 1.0170720\n",
      "Test set: Average loss: 1.2506, Accuracy: 2903/5000 (58%)\n",
      "[epoch 5] loss: 0.9897645\n",
      "Test set: Average loss: 1.1515, Accuracy: 3041/5000 (61%)\n",
      "[epoch 6] loss: 0.9591275\n",
      "Test set: Average loss: 1.2799, Accuracy: 2865/5000 (57%)\n",
      "[epoch 7] loss: 0.9348450\n",
      "Test set: Average loss: 1.2216, Accuracy: 2973/5000 (59%)\n",
      "[epoch 8] loss: 0.9100231\n",
      "Test set: Average loss: 1.2449, Accuracy: 2947/5000 (59%)\n",
      "[epoch 9] loss: 0.8796022\n",
      "Test set: Average loss: 1.1753, Accuracy: 2994/5000 (60%)\n",
      "[epoch 10] loss: 0.8559181\n",
      "Test set: Average loss: 1.3002, Accuracy: 2919/5000 (58%)\n",
      "[epoch 11] loss: 0.8228818\n",
      "Test set: Average loss: 1.2395, Accuracy: 2963/5000 (59%)\n",
      "[epoch 12] loss: 0.7946867\n",
      "Test set: Average loss: 1.2543, Accuracy: 2942/5000 (59%)\n",
      "[epoch 13] loss: 0.7803754\n",
      "Test set: Average loss: 1.3072, Accuracy: 2926/5000 (59%)\n",
      "[epoch 14] loss: 0.7286401\n",
      "Test set: Average loss: 1.3507, Accuracy: 2814/5000 (56%)\n",
      "[epoch 15] loss: 0.7034468\n",
      "Test set: Average loss: 1.3426, Accuracy: 2953/5000 (59%)\n",
      "[epoch 16] loss: 0.6636516\n",
      "Test set: Average loss: 1.3220, Accuracy: 2921/5000 (58%)\n",
      "[epoch 17] loss: 0.6291545\n",
      "Test set: Average loss: 1.3470, Accuracy: 2930/5000 (59%)\n",
      "[epoch 18] loss: 0.5799587\n",
      "Test set: Average loss: 1.4126, Accuracy: 2912/5000 (58%)\n",
      "[epoch 19] loss: 0.4923596\n",
      "Test set: Average loss: 1.4383, Accuracy: 2878/5000 (58%)\n",
      "[epoch 20] loss: 0.4590567\n",
      "Test set: Average loss: 1.4762, Accuracy: 2938/5000 (59%)\n",
      "[epoch 21] loss: 0.4187544\n",
      "Test set: Average loss: 1.5037, Accuracy: 2896/5000 (58%)\n",
      "[epoch 22] loss: 0.3569480\n",
      "Test set: Average loss: 1.5679, Accuracy: 2921/5000 (58%)\n",
      "[epoch 23] loss: 0.2905963\n",
      "Test set: Average loss: 1.6577, Accuracy: 2887/5000 (58%)\n",
      "[epoch 24] loss: 0.2287020\n",
      "Test set: Average loss: 1.7000, Accuracy: 2948/5000 (59%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25] loss: 0.2000124\n",
      "Test set: Average loss: 1.7613, Accuracy: 2945/5000 (59%)\n",
      "[epoch 26] loss: 0.1581408\n",
      "Test set: Average loss: 1.8770, Accuracy: 2930/5000 (59%)\n",
      "[epoch 27] loss: 0.1378101\n",
      "Test set: Average loss: 1.9006, Accuracy: 2909/5000 (58%)\n",
      "[epoch 28] loss: 0.0760422\n",
      "Test set: Average loss: 1.9305, Accuracy: 2975/5000 (60%)\n",
      "[epoch 29] loss: 0.0549132\n",
      "Test set: Average loss: 2.0250, Accuracy: 2961/5000 (59%)\n",
      "[epoch 30] loss: 0.0320304\n",
      "Test set: Average loss: 2.0783, Accuracy: 2970/5000 (59%)\n",
      "[epoch 31] loss: 0.0110236\n",
      "Test set: Average loss: 2.1325, Accuracy: 3008/5000 (60%)\n",
      "[epoch 32] loss: 0.0057731\n",
      "Test set: Average loss: 2.2055, Accuracy: 3039/5000 (61%)\n",
      "[epoch 33] loss: 0.0040540\n",
      "Test set: Average loss: 2.2536, Accuracy: 3036/5000 (61%)\n",
      "[epoch 34] loss: 0.0032199\n",
      "Test set: Average loss: 2.3145, Accuracy: 3036/5000 (61%)\n",
      "[epoch 35] loss: 0.0026354\n",
      "Test set: Average loss: 2.3591, Accuracy: 3031/5000 (61%)\n",
      "[epoch 36] loss: 0.0021562\n",
      "Test set: Average loss: 2.4094, Accuracy: 3037/5000 (61%)\n",
      "[epoch 37] loss: 0.0017859\n",
      "Test set: Average loss: 2.4624, Accuracy: 3030/5000 (61%)\n",
      "[epoch 38] loss: 0.0014881\n",
      "Test set: Average loss: 2.5134, Accuracy: 3043/5000 (61%)\n",
      "[epoch 39] loss: 0.0012379\n",
      "Test set: Average loss: 2.5474, Accuracy: 3029/5000 (61%)\n",
      "[epoch 40] loss: 0.0010325\n",
      "Test set: Average loss: 2.6046, Accuracy: 3033/5000 (61%)\n",
      "[epoch 41] loss: 0.0008615\n",
      "Test set: Average loss: 2.6516, Accuracy: 3035/5000 (61%)\n",
      "[epoch 42] loss: 0.0007174\n",
      "Test set: Average loss: 2.7019, Accuracy: 3050/5000 (61%)\n",
      "[epoch 43] loss: 0.0005969\n",
      "Test set: Average loss: 2.7509, Accuracy: 3044/5000 (61%)\n",
      "[epoch 44] loss: 0.0004948\n",
      "Test set: Average loss: 2.8057, Accuracy: 3039/5000 (61%)\n",
      "[epoch 45] loss: 0.0004131\n",
      "Test set: Average loss: 2.8500, Accuracy: 3045/5000 (61%)\n",
      "[epoch 46] loss: 0.0003432\n",
      "Test set: Average loss: 2.9017, Accuracy: 3060/5000 (61%)\n",
      "[epoch 47] loss: 0.0002819\n",
      "Test set: Average loss: 2.9466, Accuracy: 3037/5000 (61%)\n",
      "[epoch 48] loss: 0.0002332\n",
      "Test set: Average loss: 3.0139, Accuracy: 3037/5000 (61%)\n",
      "[epoch 49] loss: 0.0001934\n",
      "Test set: Average loss: 3.0549, Accuracy: 3034/5000 (61%)\n",
      "[epoch 50] loss: 0.0001600\n",
      "Test set: Average loss: 3.1089, Accuracy: 3035/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.9017, Accuracy: 3060/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.8252, Accuracy: 6166/10000 (62%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3198, Accuracy: 348/5000 (7%)\n",
      "[epoch 1] loss: 1.2319205\n",
      "Test set: Average loss: 1.1701, Accuracy: 2902/5000 (58%)\n",
      "[epoch 2] loss: 1.0837088\n",
      "Test set: Average loss: 1.1271, Accuracy: 3030/5000 (61%)\n",
      "[epoch 3] loss: 1.0408121\n",
      "Test set: Average loss: 1.1691, Accuracy: 2972/5000 (59%)\n",
      "[epoch 4] loss: 0.9960370\n",
      "Test set: Average loss: 1.1575, Accuracy: 2981/5000 (60%)\n",
      "[epoch 5] loss: 0.9676238\n",
      "Test set: Average loss: 1.1626, Accuracy: 2973/5000 (59%)\n",
      "[epoch 6] loss: 0.9530170\n",
      "Test set: Average loss: 1.1951, Accuracy: 2962/5000 (59%)\n",
      "[epoch 7] loss: 0.9125712\n",
      "Test set: Average loss: 1.1903, Accuracy: 2984/5000 (60%)\n",
      "[epoch 8] loss: 0.8930693\n",
      "Test set: Average loss: 1.2037, Accuracy: 2999/5000 (60%)\n",
      "[epoch 9] loss: 0.8601724\n",
      "Test set: Average loss: 1.1710, Accuracy: 3052/5000 (61%)\n",
      "[epoch 10] loss: 0.8276421\n",
      "Test set: Average loss: 1.1861, Accuracy: 2998/5000 (60%)\n",
      "[epoch 11] loss: 0.8100522\n",
      "Test set: Average loss: 1.1783, Accuracy: 2998/5000 (60%)\n",
      "[epoch 12] loss: 0.7840278\n",
      "Test set: Average loss: 1.1916, Accuracy: 3024/5000 (60%)\n",
      "[epoch 13] loss: 0.7362983\n",
      "Test set: Average loss: 1.1888, Accuracy: 3010/5000 (60%)\n",
      "[epoch 14] loss: 0.6919946\n",
      "Test set: Average loss: 1.2300, Accuracy: 3021/5000 (60%)\n",
      "[epoch 15] loss: 0.6428841\n",
      "Test set: Average loss: 1.2309, Accuracy: 3029/5000 (61%)\n",
      "[epoch 16] loss: 0.5954972\n",
      "Test set: Average loss: 1.2960, Accuracy: 3018/5000 (60%)\n",
      "[epoch 17] loss: 0.5516023\n",
      "Test set: Average loss: 1.2897, Accuracy: 2958/5000 (59%)\n",
      "[epoch 18] loss: 0.4780012\n",
      "Test set: Average loss: 1.3875, Accuracy: 2926/5000 (59%)\n",
      "[epoch 19] loss: 0.4377765\n",
      "Test set: Average loss: 1.4131, Accuracy: 2973/5000 (59%)\n",
      "[epoch 20] loss: 0.3665731\n",
      "Test set: Average loss: 1.4308, Accuracy: 3016/5000 (60%)\n",
      "[epoch 21] loss: 0.2938292\n",
      "Test set: Average loss: 1.4739, Accuracy: 3007/5000 (60%)\n",
      "[epoch 22] loss: 0.2420466\n",
      "Test set: Average loss: 1.5630, Accuracy: 3049/5000 (61%)\n",
      "[epoch 23] loss: 0.2024042\n",
      "Test set: Average loss: 1.6394, Accuracy: 3055/5000 (61%)\n",
      "[epoch 24] loss: 0.1499003\n",
      "Test set: Average loss: 1.7350, Accuracy: 2970/5000 (59%)\n",
      "[epoch 25] loss: 0.1418736\n",
      "Test set: Average loss: 1.7446, Accuracy: 3003/5000 (60%)\n",
      "[epoch 26] loss: 0.1102418\n",
      "Test set: Average loss: 1.8710, Accuracy: 2959/5000 (59%)\n",
      "[epoch 27] loss: 0.1020448\n",
      "Test set: Average loss: 1.9431, Accuracy: 2964/5000 (59%)\n",
      "[epoch 28] loss: 0.0531288\n",
      "Test set: Average loss: 1.9485, Accuracy: 3012/5000 (60%)\n",
      "[epoch 29] loss: 0.1523992\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2072, Accuracy: 2872/5000 (57%)\n",
      "[epoch 30] loss: 0.0816900\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.9132, Accuracy: 3039/5000 (61%)\n",
      "[epoch 31] loss: 0.0292480\n",
      "Test set: Average loss: 1.9153, Accuracy: 3047/5000 (61%)\n",
      "[epoch 32] loss: 0.0274778\n",
      "Test set: Average loss: 1.9168, Accuracy: 3048/5000 (61%)\n",
      "[epoch 33] loss: 0.0257491\n",
      "Test set: Average loss: 1.9183, Accuracy: 3050/5000 (61%)\n",
      "[epoch 34] loss: 0.0240858\n",
      "Test set: Average loss: 1.9206, Accuracy: 3051/5000 (61%)\n",
      "[epoch 35] loss: 0.0224400\n",
      "Test set: Average loss: 1.9228, Accuracy: 3053/5000 (61%)\n",
      "[epoch 36] loss: 0.0208434\n",
      "Test set: Average loss: 1.9244, Accuracy: 3054/5000 (61%)\n",
      "[epoch 37] loss: 0.0193280\n",
      "Test set: Average loss: 1.9274, Accuracy: 3060/5000 (61%)\n",
      "[epoch 38] loss: 0.0179243\n",
      "Test set: Average loss: 1.9307, Accuracy: 3061/5000 (61%)\n",
      "[epoch 39] loss: 0.0165873\n",
      "Test set: Average loss: 1.9335, Accuracy: 3072/5000 (61%)\n",
      "[epoch 40] loss: 0.0153798\n",
      "Test set: Average loss: 1.9393, Accuracy: 3064/5000 (61%)\n",
      "[epoch 41] loss: 0.0142718\n",
      "Test set: Average loss: 1.9444, Accuracy: 3073/5000 (61%)\n",
      "[epoch 42] loss: 0.0132343\n",
      "Test set: Average loss: 1.9497, Accuracy: 3063/5000 (61%)\n",
      "[epoch 43] loss: 0.0123003\n",
      "Test set: Average loss: 1.9532, Accuracy: 3067/5000 (61%)\n",
      "[epoch 44] loss: 0.0114401\n",
      "Test set: Average loss: 1.9574, Accuracy: 3070/5000 (61%)\n",
      "[epoch 45] loss: 0.0106536\n",
      "Test set: Average loss: 1.9628, Accuracy: 3068/5000 (61%)\n",
      "[epoch 46] loss: 0.0099465\n",
      "Test set: Average loss: 1.9705, Accuracy: 3059/5000 (61%)\n",
      "[epoch 47] loss: 0.0092838\n",
      "Test set: Average loss: 1.9746, Accuracy: 3068/5000 (61%)\n",
      "[epoch 48] loss: 0.0086834\n",
      "Test set: Average loss: 1.9814, Accuracy: 3063/5000 (61%)\n",
      "[epoch 49] loss: 0.0081225\n",
      "Test set: Average loss: 1.9876, Accuracy: 3058/5000 (61%)\n",
      "[epoch 50] loss: 0.0076150\n",
      "Test set: Average loss: 1.9934, Accuracy: 3061/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9444, Accuracy: 3073/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 1.9064, Accuracy: 6285/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3180, Accuracy: 96/5000 (2%)\n",
      "[epoch 1] loss: 1.2109897\n",
      "Test set: Average loss: 1.1556, Accuracy: 2987/5000 (60%)\n",
      "[epoch 2] loss: 1.0821430\n",
      "Test set: Average loss: 1.1170, Accuracy: 3041/5000 (61%)\n",
      "[epoch 3] loss: 1.0468133\n",
      "Test set: Average loss: 1.1317, Accuracy: 3026/5000 (61%)\n",
      "[epoch 4] loss: 1.0049512\n",
      "Test set: Average loss: 1.2313, Accuracy: 2894/5000 (58%)\n",
      "[epoch 5] loss: 0.9729112\n",
      "Test set: Average loss: 1.1310, Accuracy: 3029/5000 (61%)\n",
      "[epoch 6] loss: 0.9402231\n",
      "Test set: Average loss: 1.1708, Accuracy: 2969/5000 (59%)\n",
      "[epoch 7] loss: 0.9186263\n",
      "Test set: Average loss: 1.1493, Accuracy: 3007/5000 (60%)\n",
      "[epoch 8] loss: 0.9064449\n",
      "Test set: Average loss: 1.1908, Accuracy: 2942/5000 (59%)\n",
      "[epoch 9] loss: 0.8767914\n",
      "Test set: Average loss: 1.1862, Accuracy: 2914/5000 (58%)\n",
      "[epoch 10] loss: 0.8310251\n",
      "Test set: Average loss: 1.1944, Accuracy: 2994/5000 (60%)\n",
      "[epoch 11] loss: 0.8149017\n",
      "Test set: Average loss: 1.1818, Accuracy: 3033/5000 (61%)\n",
      "[epoch 12] loss: 0.7945266\n",
      "Test set: Average loss: 1.1310, Accuracy: 3108/5000 (62%)\n",
      "[epoch 13] loss: 0.7493077\n",
      "Test set: Average loss: 1.1785, Accuracy: 3039/5000 (61%)\n",
      "[epoch 14] loss: 0.7053813\n",
      "Test set: Average loss: 1.1991, Accuracy: 3022/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] loss: 0.6570017\n",
      "Test set: Average loss: 1.2408, Accuracy: 3039/5000 (61%)\n",
      "[epoch 16] loss: 0.6116957\n",
      "Test set: Average loss: 1.2408, Accuracy: 3047/5000 (61%)\n",
      "[epoch 17] loss: 0.5496950\n",
      "Test set: Average loss: 1.2523, Accuracy: 3095/5000 (62%)\n",
      "[epoch 18] loss: 0.4785774\n",
      "Test set: Average loss: 1.3279, Accuracy: 3032/5000 (61%)\n",
      "[epoch 19] loss: 0.4232701\n",
      "Test set: Average loss: 1.3103, Accuracy: 3099/5000 (62%)\n",
      "[epoch 20] loss: 0.3549000\n",
      "Test set: Average loss: 1.4176, Accuracy: 3025/5000 (60%)\n",
      "[epoch 21] loss: 0.3005431\n",
      "Test set: Average loss: 1.4788, Accuracy: 3025/5000 (60%)\n",
      "[epoch 22] loss: 0.2252546\n",
      "Test set: Average loss: 1.5581, Accuracy: 3005/5000 (60%)\n",
      "[epoch 23] loss: 0.2008204\n",
      "Test set: Average loss: 1.7590, Accuracy: 2925/5000 (58%)\n",
      "[epoch 24] loss: 0.1844233\n",
      "Test set: Average loss: 1.6226, Accuracy: 3061/5000 (61%)\n",
      "[epoch 25] loss: 0.1018395\n",
      "Test set: Average loss: 1.8214, Accuracy: 3024/5000 (60%)\n",
      "[epoch 26] loss: 0.0569170\n",
      "Test set: Average loss: 1.8053, Accuracy: 3071/5000 (61%)\n",
      "[epoch 27] loss: 0.0757161\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9099, Accuracy: 2985/5000 (60%)\n",
      "[epoch 28] loss: 0.0533716\n",
      "Test set: Average loss: 1.7866, Accuracy: 3110/5000 (62%)\n",
      "[epoch 29] loss: 0.0185354\n",
      "Test set: Average loss: 1.7974, Accuracy: 3119/5000 (62%)\n",
      "[epoch 30] loss: 0.0133962\n",
      "Test set: Average loss: 1.8138, Accuracy: 3128/5000 (63%)\n",
      "[epoch 31] loss: 0.0106503\n",
      "Test set: Average loss: 1.8325, Accuracy: 3131/5000 (63%)\n",
      "[epoch 32] loss: 0.0088169\n",
      "Test set: Average loss: 1.8527, Accuracy: 3129/5000 (63%)\n",
      "[epoch 33] loss: 0.0074199\n",
      "Test set: Average loss: 1.8688, Accuracy: 3135/5000 (63%)\n",
      "[epoch 34] loss: 0.0062853\n",
      "Test set: Average loss: 1.8910, Accuracy: 3134/5000 (63%)\n",
      "[epoch 35] loss: 0.0053972\n",
      "Test set: Average loss: 1.9096, Accuracy: 3142/5000 (63%)\n",
      "[epoch 36] loss: 0.0045942\n",
      "Test set: Average loss: 1.9377, Accuracy: 3147/5000 (63%)\n",
      "[epoch 37] loss: 0.0039400\n",
      "Test set: Average loss: 1.9591, Accuracy: 3148/5000 (63%)\n",
      "[epoch 38] loss: 0.0033724\n",
      "Test set: Average loss: 1.9824, Accuracy: 3156/5000 (63%)\n",
      "[epoch 39] loss: 0.0028681\n",
      "Test set: Average loss: 2.0108, Accuracy: 3152/5000 (63%)\n",
      "[epoch 40] loss: 0.0024353\n",
      "Test set: Average loss: 2.0395, Accuracy: 3150/5000 (63%)\n",
      "[epoch 41] loss: 0.0020608\n",
      "Test set: Average loss: 2.0699, Accuracy: 3158/5000 (63%)\n",
      "[epoch 42] loss: 0.0017257\n",
      "Test set: Average loss: 2.0990, Accuracy: 3164/5000 (63%)\n",
      "[epoch 43] loss: 0.0014418\n",
      "Test set: Average loss: 2.1429, Accuracy: 3159/5000 (63%)\n",
      "[epoch 44] loss: 0.0012179\n",
      "Test set: Average loss: 2.1676, Accuracy: 3167/5000 (63%)\n",
      "[epoch 45] loss: 0.0010037\n",
      "Test set: Average loss: 2.2123, Accuracy: 3171/5000 (63%)\n",
      "[epoch 46] loss: 0.0008310\n",
      "Test set: Average loss: 2.2449, Accuracy: 3165/5000 (63%)\n",
      "[epoch 47] loss: 0.0006846\n",
      "Test set: Average loss: 2.2868, Accuracy: 3174/5000 (63%)\n",
      "[epoch 48] loss: 0.0005628\n",
      "Test set: Average loss: 2.3235, Accuracy: 3173/5000 (63%)\n",
      "[epoch 49] loss: 0.0004594\n",
      "Test set: Average loss: 2.3674, Accuracy: 3173/5000 (63%)\n",
      "[epoch 50] loss: 0.0003741\n",
      "Test set: Average loss: 2.4052, Accuracy: 3175/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4052, Accuracy: 3175/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.3822, Accuracy: 6446/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3123, Accuracy: 40/5000 (1%)\n",
      "[epoch 1] loss: 1.2159254\n",
      "Test set: Average loss: 1.1554, Accuracy: 2980/5000 (60%)\n",
      "[epoch 2] loss: 1.0899588\n",
      "Test set: Average loss: 1.2184, Accuracy: 2805/5000 (56%)\n",
      "[epoch 3] loss: 1.0478274\n",
      "Test set: Average loss: 1.1625, Accuracy: 2964/5000 (59%)\n",
      "[epoch 4] loss: 1.0154915\n",
      "Test set: Average loss: 1.1842, Accuracy: 2962/5000 (59%)\n",
      "[epoch 5] loss: 0.9807596\n",
      "Test set: Average loss: 1.1447, Accuracy: 3011/5000 (60%)\n",
      "[epoch 6] loss: 0.9619173\n",
      "Test set: Average loss: 1.1625, Accuracy: 2966/5000 (59%)\n",
      "[epoch 7] loss: 0.9373254\n",
      "Test set: Average loss: 1.1355, Accuracy: 3057/5000 (61%)\n",
      "[epoch 8] loss: 0.9091917\n",
      "Test set: Average loss: 1.1624, Accuracy: 3017/5000 (60%)\n",
      "[epoch 9] loss: 0.8866675\n",
      "Test set: Average loss: 1.2006, Accuracy: 3015/5000 (60%)\n",
      "[epoch 10] loss: 0.8605145\n",
      "Test set: Average loss: 1.1651, Accuracy: 3022/5000 (60%)\n",
      "[epoch 11] loss: 0.8184140\n",
      "Test set: Average loss: 1.2394, Accuracy: 2959/5000 (59%)\n",
      "[epoch 12] loss: 0.7869865\n",
      "Test set: Average loss: 1.1410, Accuracy: 3108/5000 (62%)\n",
      "[epoch 13] loss: 0.7451136\n",
      "Test set: Average loss: 1.2389, Accuracy: 3014/5000 (60%)\n",
      "[epoch 14] loss: 0.7127806\n",
      "Test set: Average loss: 1.1697, Accuracy: 3080/5000 (62%)\n",
      "[epoch 15] loss: 0.6520211\n",
      "Test set: Average loss: 1.1972, Accuracy: 3089/5000 (62%)\n",
      "[epoch 16] loss: 0.6138890\n",
      "Test set: Average loss: 1.2770, Accuracy: 3016/5000 (60%)\n",
      "[epoch 17] loss: 0.5701415\n",
      "Test set: Average loss: 1.2045, Accuracy: 3083/5000 (62%)\n",
      "[epoch 18] loss: 0.4850567\n",
      "Test set: Average loss: 1.2567, Accuracy: 3077/5000 (62%)\n",
      "[epoch 19] loss: 0.4330393\n",
      "Test set: Average loss: 1.3452, Accuracy: 3053/5000 (61%)\n",
      "[epoch 20] loss: 0.3746264\n",
      "Test set: Average loss: 1.3629, Accuracy: 3067/5000 (61%)\n",
      "[epoch 21] loss: 0.3114751\n",
      "Test set: Average loss: 1.4167, Accuracy: 3106/5000 (62%)\n",
      "[epoch 22] loss: 0.2411258\n",
      "Test set: Average loss: 1.5018, Accuracy: 3026/5000 (61%)\n",
      "[epoch 23] loss: 0.2107755\n",
      "Test set: Average loss: 1.5888, Accuracy: 3101/5000 (62%)\n",
      "[epoch 24] loss: 0.1706523\n",
      "Test set: Average loss: 1.6834, Accuracy: 3011/5000 (60%)\n",
      "[epoch 25] loss: 0.1433589\n",
      "Test set: Average loss: 1.7309, Accuracy: 3025/5000 (60%)\n",
      "[epoch 26] loss: 0.1059867\n",
      "Test set: Average loss: 1.7798, Accuracy: 3045/5000 (61%)\n",
      "[epoch 27] loss: 0.1146571\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8882, Accuracy: 3041/5000 (61%)\n",
      "[epoch 28] loss: 0.0531158\n",
      "Test set: Average loss: 1.7565, Accuracy: 3120/5000 (62%)\n",
      "[epoch 29] loss: 0.0223608\n",
      "Test set: Average loss: 1.7649, Accuracy: 3126/5000 (63%)\n",
      "[epoch 30] loss: 0.0162096\n",
      "Test set: Average loss: 1.7793, Accuracy: 3120/5000 (62%)\n",
      "[epoch 31] loss: 0.0128230\n",
      "Test set: Average loss: 1.7937, Accuracy: 3139/5000 (63%)\n",
      "[epoch 32] loss: 0.0105671\n",
      "Test set: Average loss: 1.8105, Accuracy: 3134/5000 (63%)\n",
      "[epoch 33] loss: 0.0088939\n",
      "Test set: Average loss: 1.8279, Accuracy: 3131/5000 (63%)\n",
      "[epoch 34] loss: 0.0075196\n",
      "Test set: Average loss: 1.8666, Accuracy: 3130/5000 (63%)\n",
      "[epoch 35] loss: 0.0064318\n",
      "Test set: Average loss: 1.8687, Accuracy: 3142/5000 (63%)\n",
      "[epoch 36] loss: 0.0054998\n",
      "Test set: Average loss: 1.8900, Accuracy: 3145/5000 (63%)\n",
      "[epoch 37] loss: 0.0046887\n",
      "Test set: Average loss: 1.9161, Accuracy: 3142/5000 (63%)\n",
      "[epoch 38] loss: 0.0039924\n",
      "Test set: Average loss: 1.9397, Accuracy: 3155/5000 (63%)\n",
      "[epoch 39] loss: 0.0034003\n",
      "Test set: Average loss: 1.9627, Accuracy: 3150/5000 (63%)\n",
      "[epoch 40] loss: 0.0028740\n",
      "Test set: Average loss: 1.9929, Accuracy: 3152/5000 (63%)\n",
      "[epoch 41] loss: 0.0024207\n",
      "Test set: Average loss: 2.0233, Accuracy: 3164/5000 (63%)\n",
      "[epoch 42] loss: 0.0020369\n",
      "Test set: Average loss: 2.0565, Accuracy: 3169/5000 (63%)\n",
      "[epoch 43] loss: 0.0016956\n",
      "Test set: Average loss: 2.0837, Accuracy: 3160/5000 (63%)\n",
      "[epoch 44] loss: 0.0014127\n",
      "Test set: Average loss: 2.1186, Accuracy: 3175/5000 (64%)\n",
      "[epoch 45] loss: 0.0011717\n",
      "Test set: Average loss: 2.1550, Accuracy: 3178/5000 (64%)\n",
      "[epoch 46] loss: 0.0009665\n",
      "Test set: Average loss: 2.1952, Accuracy: 3171/5000 (63%)\n",
      "[epoch 47] loss: 0.0007962\n",
      "Test set: Average loss: 2.2194, Accuracy: 3182/5000 (64%)\n",
      "[epoch 48] loss: 0.0006525\n",
      "Test set: Average loss: 2.2635, Accuracy: 3170/5000 (63%)\n",
      "[epoch 49] loss: 0.0005332\n",
      "Test set: Average loss: 2.3010, Accuracy: 3174/5000 (63%)\n",
      "[epoch 50] loss: 0.0004358\n",
      "Test set: Average loss: 2.3424, Accuracy: 3176/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2194, Accuracy: 3182/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.1444, Accuracy: 6485/10000 (65%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2924, Accuracy: 727/5000 (15%)\n",
      "[epoch 1] loss: 1.2059580\n",
      "Test set: Average loss: 1.1766, Accuracy: 2929/5000 (59%)\n",
      "[epoch 2] loss: 1.0754443\n",
      "Test set: Average loss: 1.1230, Accuracy: 2979/5000 (60%)\n",
      "[epoch 3] loss: 1.0378186\n",
      "Test set: Average loss: 1.2164, Accuracy: 2860/5000 (57%)\n",
      "[epoch 4] loss: 1.0065243\n",
      "Test set: Average loss: 1.1451, Accuracy: 2986/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 0.9739652\n",
      "Test set: Average loss: 1.1017, Accuracy: 3105/5000 (62%)\n",
      "[epoch 6] loss: 0.9437647\n",
      "Test set: Average loss: 1.1155, Accuracy: 3081/5000 (62%)\n",
      "[epoch 7] loss: 0.9223048\n",
      "Test set: Average loss: 1.1373, Accuracy: 3043/5000 (61%)\n",
      "[epoch 8] loss: 0.8889326\n",
      "Test set: Average loss: 1.1167, Accuracy: 3098/5000 (62%)\n",
      "[epoch 9] loss: 0.8656629\n",
      "Test set: Average loss: 1.1277, Accuracy: 3086/5000 (62%)\n",
      "[epoch 10] loss: 0.8270784\n",
      "Test set: Average loss: 1.1183, Accuracy: 3090/5000 (62%)\n",
      "[epoch 11] loss: 0.8005257\n",
      "Test set: Average loss: 1.1249, Accuracy: 3076/5000 (62%)\n",
      "[epoch 12] loss: 0.7572392\n",
      "Test set: Average loss: 1.2055, Accuracy: 3032/5000 (61%)\n",
      "[epoch 13] loss: 0.7098783\n",
      "Test set: Average loss: 1.1308, Accuracy: 3152/5000 (63%)\n",
      "[epoch 14] loss: 0.6670007\n",
      "Test set: Average loss: 1.1541, Accuracy: 3150/5000 (63%)\n",
      "[epoch 15] loss: 0.6145844\n",
      "Test set: Average loss: 1.1248, Accuracy: 3173/5000 (63%)\n",
      "[epoch 16] loss: 0.5587955\n",
      "Test set: Average loss: 1.1801, Accuracy: 3119/5000 (62%)\n",
      "[epoch 17] loss: 0.4947717\n",
      "Test set: Average loss: 1.2306, Accuracy: 3097/5000 (62%)\n",
      "[epoch 18] loss: 0.4285977\n",
      "Test set: Average loss: 1.2782, Accuracy: 3128/5000 (63%)\n",
      "[epoch 19] loss: 0.3762646\n",
      "Test set: Average loss: 1.3446, Accuracy: 3139/5000 (63%)\n",
      "[epoch 20] loss: 0.2960889\n",
      "Test set: Average loss: 1.3722, Accuracy: 3162/5000 (63%)\n",
      "[epoch 21] loss: 0.2378874\n",
      "Test set: Average loss: 1.4188, Accuracy: 3186/5000 (64%)\n",
      "[epoch 22] loss: 0.1738843\n",
      "Test set: Average loss: 1.5276, Accuracy: 3119/5000 (62%)\n",
      "[epoch 23] loss: 0.1384138\n",
      "Test set: Average loss: 1.5834, Accuracy: 3125/5000 (62%)\n",
      "[epoch 24] loss: 0.1488587\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7271, Accuracy: 3034/5000 (61%)\n",
      "[epoch 25] loss: 0.0553795\n",
      "Test set: Average loss: 1.5921, Accuracy: 3203/5000 (64%)\n",
      "[epoch 26] loss: 0.0241539\n",
      "Test set: Average loss: 1.6085, Accuracy: 3200/5000 (64%)\n",
      "[epoch 27] loss: 0.0173989\n",
      "Test set: Average loss: 1.6303, Accuracy: 3216/5000 (64%)\n",
      "[epoch 28] loss: 0.0135760\n",
      "Test set: Average loss: 1.6471, Accuracy: 3215/5000 (64%)\n",
      "[epoch 29] loss: 0.0108936\n",
      "Test set: Average loss: 1.6653, Accuracy: 3212/5000 (64%)\n",
      "[epoch 30] loss: 0.0088847\n",
      "Test set: Average loss: 1.6822, Accuracy: 3207/5000 (64%)\n",
      "[epoch 31] loss: 0.0072741\n",
      "Test set: Average loss: 1.7119, Accuracy: 3222/5000 (64%)\n",
      "[epoch 32] loss: 0.0059234\n",
      "Test set: Average loss: 1.7360, Accuracy: 3222/5000 (64%)\n",
      "[epoch 33] loss: 0.0048104\n",
      "Test set: Average loss: 1.7702, Accuracy: 3226/5000 (65%)\n",
      "[epoch 34] loss: 0.0038745\n",
      "Test set: Average loss: 1.7948, Accuracy: 3219/5000 (64%)\n",
      "[epoch 35] loss: 0.0031111\n",
      "Test set: Average loss: 1.8340, Accuracy: 3236/5000 (65%)\n",
      "[epoch 36] loss: 0.0024761\n",
      "Test set: Average loss: 1.8642, Accuracy: 3241/5000 (65%)\n",
      "[epoch 37] loss: 0.0019706\n",
      "Test set: Average loss: 1.9114, Accuracy: 3247/5000 (65%)\n",
      "[epoch 38] loss: 0.0015470\n",
      "Test set: Average loss: 1.9428, Accuracy: 3246/5000 (65%)\n",
      "[epoch 39] loss: 0.0012112\n",
      "Test set: Average loss: 1.9832, Accuracy: 3251/5000 (65%)\n",
      "[epoch 40] loss: 0.0009499\n",
      "Test set: Average loss: 2.0254, Accuracy: 3240/5000 (65%)\n",
      "[epoch 41] loss: 0.0007387\n",
      "Test set: Average loss: 2.0597, Accuracy: 3256/5000 (65%)\n",
      "[epoch 42] loss: 0.0005705\n",
      "Test set: Average loss: 2.1138, Accuracy: 3252/5000 (65%)\n",
      "[epoch 43] loss: 0.0004410\n",
      "Test set: Average loss: 2.1531, Accuracy: 3249/5000 (65%)\n",
      "[epoch 44] loss: 0.0003384\n",
      "Test set: Average loss: 2.2028, Accuracy: 3254/5000 (65%)\n",
      "[epoch 45] loss: 0.0002594\n",
      "Test set: Average loss: 2.2488, Accuracy: 3260/5000 (65%)\n",
      "[epoch 46] loss: 0.0001978\n",
      "Test set: Average loss: 2.2951, Accuracy: 3245/5000 (65%)\n",
      "[epoch 47] loss: 0.0001516\n",
      "Test set: Average loss: 2.3343, Accuracy: 3251/5000 (65%)\n",
      "[epoch 48] loss: 0.0001150\n",
      "Test set: Average loss: 2.3828, Accuracy: 3255/5000 (65%)\n",
      "[epoch 49] loss: 0.0000872\n",
      "Test set: Average loss: 2.4277, Accuracy: 3264/5000 (65%)\n",
      "[epoch 50] loss: 0.0000659\n",
      "Test set: Average loss: 2.4773, Accuracy: 3257/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4277, Accuracy: 3264/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.4088, Accuracy: 6643/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3088, Accuracy: 527/5000 (11%)\n",
      "[epoch 1] loss: 1.1952241\n",
      "Test set: Average loss: 1.2012, Accuracy: 2842/5000 (57%)\n",
      "[epoch 2] loss: 1.0777272\n",
      "Test set: Average loss: 1.1599, Accuracy: 3002/5000 (60%)\n",
      "[epoch 3] loss: 1.0319353\n",
      "Test set: Average loss: 1.1528, Accuracy: 2963/5000 (59%)\n",
      "[epoch 4] loss: 1.0082690\n",
      "Test set: Average loss: 1.1595, Accuracy: 3012/5000 (60%)\n",
      "[epoch 5] loss: 0.9692292\n",
      "Test set: Average loss: 1.1657, Accuracy: 2958/5000 (59%)\n",
      "[epoch 6] loss: 0.9464460\n",
      "Test set: Average loss: 1.0924, Accuracy: 3086/5000 (62%)\n",
      "[epoch 7] loss: 0.9264495\n",
      "Test set: Average loss: 1.1639, Accuracy: 2953/5000 (59%)\n",
      "[epoch 8] loss: 0.9004584\n",
      "Test set: Average loss: 1.1030, Accuracy: 3074/5000 (61%)\n",
      "[epoch 9] loss: 0.8666459\n",
      "Test set: Average loss: 1.0635, Accuracy: 3158/5000 (63%)\n",
      "[epoch 10] loss: 0.8312143\n",
      "Test set: Average loss: 1.1122, Accuracy: 3110/5000 (62%)\n",
      "[epoch 11] loss: 0.7986025\n",
      "Test set: Average loss: 1.1252, Accuracy: 3086/5000 (62%)\n",
      "[epoch 12] loss: 0.7572070\n",
      "Test set: Average loss: 1.0922, Accuracy: 3157/5000 (63%)\n",
      "[epoch 13] loss: 0.7199000\n",
      "Test set: Average loss: 1.1444, Accuracy: 3128/5000 (63%)\n",
      "[epoch 14] loss: 0.6741797\n",
      "Test set: Average loss: 1.1257, Accuracy: 3170/5000 (63%)\n",
      "[epoch 15] loss: 0.6075926\n",
      "Test set: Average loss: 1.1661, Accuracy: 3160/5000 (63%)\n",
      "[epoch 16] loss: 0.5538585\n",
      "Test set: Average loss: 1.1988, Accuracy: 3142/5000 (63%)\n",
      "[epoch 17] loss: 0.4993754\n",
      "Test set: Average loss: 1.2522, Accuracy: 3155/5000 (63%)\n",
      "[epoch 18] loss: 0.4184761\n",
      "Test set: Average loss: 1.2668, Accuracy: 3175/5000 (64%)\n",
      "[epoch 19] loss: 0.3571895\n",
      "Test set: Average loss: 1.3774, Accuracy: 3107/5000 (62%)\n",
      "[epoch 20] loss: 0.2761094\n",
      "Test set: Average loss: 1.3671, Accuracy: 3167/5000 (63%)\n",
      "[epoch 21] loss: 0.2463630\n",
      "Test set: Average loss: 1.5642, Accuracy: 3070/5000 (61%)\n",
      "[epoch 22] loss: 0.1774245\n",
      "Test set: Average loss: 1.5319, Accuracy: 3192/5000 (64%)\n",
      "[epoch 23] loss: 0.1274273\n",
      "Test set: Average loss: 1.6616, Accuracy: 3132/5000 (63%)\n",
      "[epoch 24] loss: 0.1447131\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7037, Accuracy: 3096/5000 (62%)\n",
      "[epoch 25] loss: 0.0440233\n",
      "Test set: Average loss: 1.5949, Accuracy: 3220/5000 (64%)\n",
      "[epoch 26] loss: 0.0212272\n",
      "Test set: Average loss: 1.6094, Accuracy: 3231/5000 (65%)\n",
      "[epoch 27] loss: 0.0157044\n",
      "Test set: Average loss: 1.6291, Accuracy: 3241/5000 (65%)\n",
      "[epoch 28] loss: 0.0124228\n",
      "Test set: Average loss: 1.6451, Accuracy: 3253/5000 (65%)\n",
      "[epoch 29] loss: 0.0100954\n",
      "Test set: Average loss: 1.6712, Accuracy: 3256/5000 (65%)\n",
      "[epoch 30] loss: 0.0082850\n",
      "Test set: Average loss: 1.6860, Accuracy: 3262/5000 (65%)\n",
      "[epoch 31] loss: 0.0067738\n",
      "Test set: Average loss: 1.7142, Accuracy: 3276/5000 (66%)\n",
      "[epoch 32] loss: 0.0055180\n",
      "Test set: Average loss: 1.7382, Accuracy: 3287/5000 (66%)\n",
      "[epoch 33] loss: 0.0045040\n",
      "Test set: Average loss: 1.7720, Accuracy: 3278/5000 (66%)\n",
      "[epoch 34] loss: 0.0036345\n",
      "Test set: Average loss: 1.8010, Accuracy: 3277/5000 (66%)\n",
      "[epoch 35] loss: 0.0028976\n",
      "Test set: Average loss: 1.8415, Accuracy: 3270/5000 (65%)\n",
      "[epoch 36] loss: 0.0023103\n",
      "Test set: Average loss: 1.8737, Accuracy: 3268/5000 (65%)\n",
      "[epoch 37] loss: 0.0018335\n",
      "Test set: Average loss: 1.9097, Accuracy: 3289/5000 (66%)\n",
      "[epoch 38] loss: 0.0014383\n",
      "Test set: Average loss: 1.9473, Accuracy: 3275/5000 (66%)\n",
      "[epoch 39] loss: 0.0011299\n",
      "Test set: Average loss: 1.9885, Accuracy: 3285/5000 (66%)\n",
      "[epoch 40] loss: 0.0008772\n",
      "Test set: Average loss: 2.0324, Accuracy: 3277/5000 (66%)\n",
      "[epoch 41] loss: 0.0006825\n",
      "Test set: Average loss: 2.0698, Accuracy: 3278/5000 (66%)\n",
      "[epoch 42] loss: 0.0005291\n",
      "Test set: Average loss: 2.1120, Accuracy: 3269/5000 (65%)\n",
      "[epoch 43] loss: 0.0004029\n",
      "Test set: Average loss: 2.1579, Accuracy: 3275/5000 (66%)\n",
      "[epoch 44] loss: 0.0003120\n",
      "Test set: Average loss: 2.2005, Accuracy: 3284/5000 (66%)\n",
      "[epoch 45] loss: 0.0002386\n",
      "Test set: Average loss: 2.2497, Accuracy: 3282/5000 (66%)\n",
      "[epoch 46] loss: 0.0001808\n",
      "Test set: Average loss: 2.3006, Accuracy: 3275/5000 (66%)\n",
      "[epoch 47] loss: 0.0001385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3520, Accuracy: 3287/5000 (66%)\n",
      "[epoch 48] loss: 0.0001051\n",
      "Test set: Average loss: 2.3950, Accuracy: 3273/5000 (65%)\n",
      "[epoch 49] loss: 0.0000797\n",
      "Test set: Average loss: 2.4354, Accuracy: 3277/5000 (66%)\n",
      "[epoch 50] loss: 0.0000603\n",
      "Test set: Average loss: 2.4852, Accuracy: 3288/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9097, Accuracy: 3289/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.8824, Accuracy: 6650/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3228, Accuracy: 89/5000 (2%)\n",
      "[epoch 1] loss: 1.2148007\n",
      "Test set: Average loss: 1.2728, Accuracy: 2786/5000 (56%)\n",
      "[epoch 2] loss: 1.0915782\n",
      "Test set: Average loss: 1.1490, Accuracy: 2952/5000 (59%)\n",
      "[epoch 3] loss: 1.0438684\n",
      "Test set: Average loss: 1.1765, Accuracy: 2993/5000 (60%)\n",
      "[epoch 4] loss: 1.0090522\n",
      "Test set: Average loss: 1.1231, Accuracy: 3055/5000 (61%)\n",
      "[epoch 5] loss: 0.9728257\n",
      "Test set: Average loss: 1.1768, Accuracy: 2924/5000 (58%)\n",
      "[epoch 6] loss: 0.9532322\n",
      "Test set: Average loss: 1.1388, Accuracy: 3042/5000 (61%)\n",
      "[epoch 7] loss: 0.9177767\n",
      "Test set: Average loss: 1.0773, Accuracy: 3079/5000 (62%)\n",
      "[epoch 8] loss: 0.8962244\n",
      "Test set: Average loss: 1.1200, Accuracy: 3068/5000 (61%)\n",
      "[epoch 9] loss: 0.8591870\n",
      "Test set: Average loss: 1.1008, Accuracy: 3114/5000 (62%)\n",
      "[epoch 10] loss: 0.8285764\n",
      "Test set: Average loss: 1.1585, Accuracy: 3059/5000 (61%)\n",
      "[epoch 11] loss: 0.7953325\n",
      "Test set: Average loss: 1.1650, Accuracy: 3090/5000 (62%)\n",
      "[epoch 12] loss: 0.7507038\n",
      "Test set: Average loss: 1.1136, Accuracy: 3151/5000 (63%)\n",
      "[epoch 13] loss: 0.7119006\n",
      "Test set: Average loss: 1.1519, Accuracy: 3152/5000 (63%)\n",
      "[epoch 14] loss: 0.6683590\n",
      "Test set: Average loss: 1.1413, Accuracy: 3148/5000 (63%)\n",
      "[epoch 15] loss: 0.6075177\n",
      "Test set: Average loss: 1.2121, Accuracy: 3114/5000 (62%)\n",
      "[epoch 16] loss: 0.5529206\n",
      "Test set: Average loss: 1.2692, Accuracy: 3159/5000 (63%)\n",
      "[epoch 17] loss: 0.4851941\n",
      "Test set: Average loss: 1.2176, Accuracy: 3189/5000 (64%)\n",
      "[epoch 18] loss: 0.4112746\n",
      "Test set: Average loss: 1.2934, Accuracy: 3145/5000 (63%)\n",
      "[epoch 19] loss: 0.3488289\n",
      "Test set: Average loss: 1.3484, Accuracy: 3118/5000 (62%)\n",
      "[epoch 20] loss: 0.2860800\n",
      "Test set: Average loss: 1.3791, Accuracy: 3205/5000 (64%)\n",
      "[epoch 21] loss: 0.2303664\n",
      "Test set: Average loss: 1.4196, Accuracy: 3228/5000 (65%)\n",
      "[epoch 22] loss: 0.1690692\n",
      "Test set: Average loss: 1.5467, Accuracy: 3144/5000 (63%)\n",
      "[epoch 23] loss: 0.1449580\n",
      "Test set: Average loss: 1.6398, Accuracy: 3116/5000 (62%)\n",
      "[epoch 24] loss: 0.1207099\n",
      "Test set: Average loss: 1.7312, Accuracy: 3141/5000 (63%)\n",
      "[epoch 25] loss: 0.1050343\n",
      "Test set: Average loss: 1.8402, Accuracy: 3077/5000 (62%)\n",
      "[epoch 26] loss: 0.1322613\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8739, Accuracy: 3106/5000 (62%)\n",
      "[epoch 27] loss: 0.0432191\n",
      "Test set: Average loss: 1.7197, Accuracy: 3226/5000 (65%)\n",
      "[epoch 28] loss: 0.0163702\n",
      "Test set: Average loss: 1.7333, Accuracy: 3228/5000 (65%)\n",
      "[epoch 29] loss: 0.0113795\n",
      "Test set: Average loss: 1.7550, Accuracy: 3236/5000 (65%)\n",
      "[epoch 30] loss: 0.0087885\n",
      "Test set: Average loss: 1.7662, Accuracy: 3243/5000 (65%)\n",
      "[epoch 31] loss: 0.0069748\n",
      "Test set: Average loss: 1.7862, Accuracy: 3242/5000 (65%)\n",
      "[epoch 32] loss: 0.0056244\n",
      "Test set: Average loss: 1.8079, Accuracy: 3243/5000 (65%)\n",
      "[epoch 33] loss: 0.0045537\n",
      "Test set: Average loss: 1.8309, Accuracy: 3241/5000 (65%)\n",
      "[epoch 34] loss: 0.0036969\n",
      "Test set: Average loss: 1.8511, Accuracy: 3241/5000 (65%)\n",
      "[epoch 35] loss: 0.0029901\n",
      "Test set: Average loss: 1.8761, Accuracy: 3247/5000 (65%)\n",
      "[epoch 36] loss: 0.0024095\n",
      "Test set: Average loss: 1.9043, Accuracy: 3249/5000 (65%)\n",
      "[epoch 37] loss: 0.0019307\n",
      "Test set: Average loss: 1.9358, Accuracy: 3239/5000 (65%)\n",
      "[epoch 38] loss: 0.0015392\n",
      "Test set: Average loss: 1.9657, Accuracy: 3248/5000 (65%)\n",
      "[epoch 39] loss: 0.0012204\n",
      "Test set: Average loss: 1.9974, Accuracy: 3253/5000 (65%)\n",
      "[epoch 40] loss: 0.0009616\n",
      "Test set: Average loss: 2.0347, Accuracy: 3260/5000 (65%)\n",
      "[epoch 41] loss: 0.0007519\n",
      "Test set: Average loss: 2.0738, Accuracy: 3252/5000 (65%)\n",
      "[epoch 42] loss: 0.0005853\n",
      "Test set: Average loss: 2.1040, Accuracy: 3258/5000 (65%)\n",
      "[epoch 43] loss: 0.0004535\n",
      "Test set: Average loss: 2.1524, Accuracy: 3260/5000 (65%)\n",
      "[epoch 44] loss: 0.0003515\n",
      "Test set: Average loss: 2.1901, Accuracy: 3263/5000 (65%)\n",
      "[epoch 45] loss: 0.0002696\n",
      "Test set: Average loss: 2.2298, Accuracy: 3272/5000 (65%)\n",
      "[epoch 46] loss: 0.0002064\n",
      "Test set: Average loss: 2.2808, Accuracy: 3255/5000 (65%)\n",
      "[epoch 47] loss: 0.0001580\n",
      "Test set: Average loss: 2.3163, Accuracy: 3266/5000 (65%)\n",
      "[epoch 48] loss: 0.0001208\n",
      "Test set: Average loss: 2.3633, Accuracy: 3265/5000 (65%)\n",
      "[epoch 49] loss: 0.0000912\n",
      "Test set: Average loss: 2.4118, Accuracy: 3268/5000 (65%)\n",
      "[epoch 50] loss: 0.0000696\n",
      "Test set: Average loss: 2.4547, Accuracy: 3268/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2298, Accuracy: 3272/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.1546, Accuracy: 6677/10000 (67%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3012, Accuracy: 733/5000 (15%)\n",
      "[epoch 1] loss: 1.2020591\n",
      "Test set: Average loss: 1.2132, Accuracy: 2857/5000 (57%)\n",
      "[epoch 2] loss: 1.0773038\n",
      "Test set: Average loss: 1.1721, Accuracy: 2919/5000 (58%)\n",
      "[epoch 3] loss: 1.0366679\n",
      "Test set: Average loss: 1.1086, Accuracy: 3085/5000 (62%)\n",
      "[epoch 4] loss: 0.9986479\n",
      "Test set: Average loss: 1.1279, Accuracy: 3032/5000 (61%)\n",
      "[epoch 5] loss: 0.9756288\n",
      "Test set: Average loss: 1.1026, Accuracy: 3072/5000 (61%)\n",
      "[epoch 6] loss: 0.9422047\n",
      "Test set: Average loss: 1.1026, Accuracy: 3080/5000 (62%)\n",
      "[epoch 7] loss: 0.9193911\n",
      "Test set: Average loss: 1.1365, Accuracy: 3014/5000 (60%)\n",
      "[epoch 8] loss: 0.8792493\n",
      "Test set: Average loss: 1.1119, Accuracy: 3076/5000 (62%)\n",
      "[epoch 9] loss: 0.8501098\n",
      "Test set: Average loss: 1.1213, Accuracy: 3060/5000 (61%)\n",
      "[epoch 10] loss: 0.8098694\n",
      "Test set: Average loss: 1.0937, Accuracy: 3159/5000 (63%)\n",
      "[epoch 11] loss: 0.7763107\n",
      "Test set: Average loss: 1.0930, Accuracy: 3125/5000 (62%)\n",
      "[epoch 12] loss: 0.7208578\n",
      "Test set: Average loss: 1.0973, Accuracy: 3164/5000 (63%)\n",
      "[epoch 13] loss: 0.6712061\n",
      "Test set: Average loss: 1.1426, Accuracy: 3151/5000 (63%)\n",
      "[epoch 14] loss: 0.6232702\n",
      "Test set: Average loss: 1.1469, Accuracy: 3177/5000 (64%)\n",
      "[epoch 15] loss: 0.5607548\n",
      "Test set: Average loss: 1.2351, Accuracy: 3119/5000 (62%)\n",
      "[epoch 16] loss: 0.5031809\n",
      "Test set: Average loss: 1.2859, Accuracy: 3092/5000 (62%)\n",
      "[epoch 17] loss: 0.4427412\n",
      "Test set: Average loss: 1.2442, Accuracy: 3174/5000 (63%)\n",
      "[epoch 18] loss: 0.3417555\n",
      "Test set: Average loss: 1.3289, Accuracy: 3196/5000 (64%)\n",
      "[epoch 19] loss: 0.2828906\n",
      "Test set: Average loss: 1.3636, Accuracy: 3162/5000 (63%)\n",
      "[epoch 20] loss: 0.2234741\n",
      "Test set: Average loss: 1.4581, Accuracy: 3192/5000 (64%)\n",
      "[epoch 21] loss: 0.1705898\n",
      "Test set: Average loss: 1.4840, Accuracy: 3202/5000 (64%)\n",
      "[epoch 22] loss: 0.1500172\n",
      "Test set: Average loss: 1.6064, Accuracy: 3187/5000 (64%)\n",
      "[epoch 23] loss: 0.1451935\n",
      "Test set: Average loss: 1.7522, Accuracy: 3120/5000 (62%)\n",
      "[epoch 24] loss: 0.1341961\n",
      "Test set: Average loss: 1.7620, Accuracy: 3171/5000 (63%)\n",
      "[epoch 25] loss: 0.1223557\n",
      "Test set: Average loss: 1.7989, Accuracy: 3128/5000 (63%)\n",
      "[epoch 26] loss: 0.0771630\n",
      "Test set: Average loss: 1.8777, Accuracy: 3152/5000 (63%)\n",
      "[epoch 27] loss: 0.1515572\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9068, Accuracy: 3148/5000 (63%)\n",
      "[epoch 28] loss: 0.0395805\n",
      "Test set: Average loss: 1.7671, Accuracy: 3237/5000 (65%)\n",
      "[epoch 29] loss: 0.0132238\n",
      "Test set: Average loss: 1.7800, Accuracy: 3241/5000 (65%)\n",
      "[epoch 30] loss: 0.0086017\n",
      "Test set: Average loss: 1.7926, Accuracy: 3258/5000 (65%)\n",
      "[epoch 31] loss: 0.0063291\n",
      "Test set: Average loss: 1.8075, Accuracy: 3269/5000 (65%)\n",
      "[epoch 32] loss: 0.0048037\n",
      "Test set: Average loss: 1.8278, Accuracy: 3272/5000 (65%)\n",
      "[epoch 33] loss: 0.0037048\n",
      "Test set: Average loss: 1.8449, Accuracy: 3269/5000 (65%)\n",
      "[epoch 34] loss: 0.0028511\n",
      "Test set: Average loss: 1.8692, Accuracy: 3286/5000 (66%)\n",
      "[epoch 35] loss: 0.0021972\n",
      "Test set: Average loss: 1.8972, Accuracy: 3284/5000 (66%)\n",
      "[epoch 36] loss: 0.0016700\n",
      "Test set: Average loss: 1.9249, Accuracy: 3297/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] loss: 0.0012676\n",
      "Test set: Average loss: 1.9573, Accuracy: 3296/5000 (66%)\n",
      "[epoch 38] loss: 0.0009538\n",
      "Test set: Average loss: 1.9965, Accuracy: 3291/5000 (66%)\n",
      "[epoch 39] loss: 0.0007125\n",
      "Test set: Average loss: 2.0323, Accuracy: 3280/5000 (66%)\n",
      "[epoch 40] loss: 0.0005280\n",
      "Test set: Average loss: 2.0713, Accuracy: 3299/5000 (66%)\n",
      "[epoch 41] loss: 0.0003894\n",
      "Test set: Average loss: 2.1120, Accuracy: 3290/5000 (66%)\n",
      "[epoch 42] loss: 0.0002852\n",
      "Test set: Average loss: 2.1601, Accuracy: 3304/5000 (66%)\n",
      "[epoch 43] loss: 0.0002080\n",
      "Test set: Average loss: 2.1978, Accuracy: 3287/5000 (66%)\n",
      "[epoch 44] loss: 0.0001510\n",
      "Test set: Average loss: 2.2433, Accuracy: 3293/5000 (66%)\n",
      "[epoch 45] loss: 0.0001086\n",
      "Test set: Average loss: 2.2961, Accuracy: 3293/5000 (66%)\n",
      "[epoch 46] loss: 0.0000783\n",
      "Test set: Average loss: 2.3427, Accuracy: 3295/5000 (66%)\n",
      "[epoch 47] loss: 0.0000561\n",
      "Test set: Average loss: 2.3880, Accuracy: 3283/5000 (66%)\n",
      "[epoch 48] loss: 0.0000402\n",
      "Test set: Average loss: 2.4435, Accuracy: 3294/5000 (66%)\n",
      "[epoch 49] loss: 0.0000286\n",
      "Test set: Average loss: 2.4939, Accuracy: 3299/5000 (66%)\n",
      "[epoch 50] loss: 0.0000203\n",
      "Test set: Average loss: 2.5444, Accuracy: 3302/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1601, Accuracy: 3304/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.1490, Accuracy: 6698/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3094, Accuracy: 296/5000 (6%)\n",
      "[epoch 1] loss: 1.1856862\n",
      "Test set: Average loss: 1.1708, Accuracy: 2982/5000 (60%)\n",
      "[epoch 2] loss: 1.0844573\n",
      "Test set: Average loss: 1.0993, Accuracy: 3056/5000 (61%)\n",
      "[epoch 3] loss: 1.0310091\n",
      "Test set: Average loss: 1.1263, Accuracy: 3005/5000 (60%)\n",
      "[epoch 4] loss: 1.0044218\n",
      "Test set: Average loss: 1.1150, Accuracy: 3006/5000 (60%)\n",
      "[epoch 5] loss: 0.9757698\n",
      "Test set: Average loss: 1.1323, Accuracy: 3058/5000 (61%)\n",
      "[epoch 6] loss: 0.9502343\n",
      "Test set: Average loss: 1.1532, Accuracy: 3000/5000 (60%)\n",
      "[epoch 7] loss: 0.9175095\n",
      "Test set: Average loss: 1.1095, Accuracy: 3038/5000 (61%)\n",
      "[epoch 8] loss: 0.8948364\n",
      "Test set: Average loss: 1.0781, Accuracy: 3142/5000 (63%)\n",
      "[epoch 9] loss: 0.8628200\n",
      "Test set: Average loss: 1.0730, Accuracy: 3166/5000 (63%)\n",
      "[epoch 10] loss: 0.8197016\n",
      "Test set: Average loss: 1.0744, Accuracy: 3151/5000 (63%)\n",
      "[epoch 11] loss: 0.7743812\n",
      "Test set: Average loss: 1.1059, Accuracy: 3138/5000 (63%)\n",
      "[epoch 12] loss: 0.7455009\n",
      "Test set: Average loss: 1.1142, Accuracy: 3141/5000 (63%)\n",
      "[epoch 13] loss: 0.6972580\n",
      "Test set: Average loss: 1.0789, Accuracy: 3201/5000 (64%)\n",
      "[epoch 14] loss: 0.6297468\n",
      "Test set: Average loss: 1.1043, Accuracy: 3213/5000 (64%)\n",
      "[epoch 15] loss: 0.5817156\n",
      "Test set: Average loss: 1.1760, Accuracy: 3144/5000 (63%)\n",
      "[epoch 16] loss: 0.5176655\n",
      "Test set: Average loss: 1.1523, Accuracy: 3240/5000 (65%)\n",
      "[epoch 17] loss: 0.4465328\n",
      "Test set: Average loss: 1.2092, Accuracy: 3181/5000 (64%)\n",
      "[epoch 18] loss: 0.3798453\n",
      "Test set: Average loss: 1.3022, Accuracy: 3167/5000 (63%)\n",
      "[epoch 19] loss: 0.2934538\n",
      "Test set: Average loss: 1.3837, Accuracy: 3149/5000 (63%)\n",
      "[epoch 20] loss: 0.2314257\n",
      "Test set: Average loss: 1.3685, Accuracy: 3220/5000 (64%)\n",
      "[epoch 21] loss: 0.1887452\n",
      "Test set: Average loss: 1.4433, Accuracy: 3217/5000 (64%)\n",
      "[epoch 22] loss: 0.1695294\n",
      "Test set: Average loss: 1.6304, Accuracy: 3119/5000 (62%)\n",
      "[epoch 23] loss: 0.1392227\n",
      "Test set: Average loss: 1.6671, Accuracy: 3180/5000 (64%)\n",
      "[epoch 24] loss: 0.1385618\n",
      "Test set: Average loss: 1.7766, Accuracy: 3146/5000 (63%)\n",
      "[epoch 25] loss: 0.1102703\n",
      "Test set: Average loss: 1.8626, Accuracy: 3121/5000 (62%)\n",
      "[epoch 26] loss: 0.0986644\n",
      "Test set: Average loss: 2.0105, Accuracy: 3121/5000 (62%)\n",
      "[epoch 27] loss: 0.1580908\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8564, Accuracy: 3172/5000 (63%)\n",
      "[epoch 28] loss: 0.0367425\n",
      "Test set: Average loss: 1.7431, Accuracy: 3263/5000 (65%)\n",
      "[epoch 29] loss: 0.0128575\n",
      "Test set: Average loss: 1.7556, Accuracy: 3275/5000 (66%)\n",
      "[epoch 30] loss: 0.0085045\n",
      "Test set: Average loss: 1.7722, Accuracy: 3269/5000 (65%)\n",
      "[epoch 31] loss: 0.0062550\n",
      "Test set: Average loss: 1.7900, Accuracy: 3277/5000 (66%)\n",
      "[epoch 32] loss: 0.0047988\n",
      "Test set: Average loss: 1.8127, Accuracy: 3284/5000 (66%)\n",
      "[epoch 33] loss: 0.0037104\n",
      "Test set: Average loss: 1.8312, Accuracy: 3276/5000 (66%)\n",
      "[epoch 34] loss: 0.0028727\n",
      "Test set: Average loss: 1.8539, Accuracy: 3287/5000 (66%)\n",
      "[epoch 35] loss: 0.0022075\n",
      "Test set: Average loss: 1.8838, Accuracy: 3289/5000 (66%)\n",
      "[epoch 36] loss: 0.0016936\n",
      "Test set: Average loss: 1.9076, Accuracy: 3285/5000 (66%)\n",
      "[epoch 37] loss: 0.0012863\n",
      "Test set: Average loss: 1.9436, Accuracy: 3299/5000 (66%)\n",
      "[epoch 38] loss: 0.0009675\n",
      "Test set: Average loss: 1.9774, Accuracy: 3303/5000 (66%)\n",
      "[epoch 39] loss: 0.0007184\n",
      "Test set: Average loss: 2.0093, Accuracy: 3304/5000 (66%)\n",
      "[epoch 40] loss: 0.0005322\n",
      "Test set: Average loss: 2.0438, Accuracy: 3303/5000 (66%)\n",
      "[epoch 41] loss: 0.0003915\n",
      "Test set: Average loss: 2.0888, Accuracy: 3299/5000 (66%)\n",
      "[epoch 42] loss: 0.0002866\n",
      "Test set: Average loss: 2.1342, Accuracy: 3297/5000 (66%)\n",
      "[epoch 43] loss: 0.0002077\n",
      "Test set: Average loss: 2.1728, Accuracy: 3292/5000 (66%)\n",
      "[epoch 44] loss: 0.0001507\n",
      "Test set: Average loss: 2.2222, Accuracy: 3296/5000 (66%)\n",
      "[epoch 45] loss: 0.0001082\n",
      "Test set: Average loss: 2.2694, Accuracy: 3301/5000 (66%)\n",
      "[epoch 46] loss: 0.0000779\n",
      "Test set: Average loss: 2.3166, Accuracy: 3303/5000 (66%)\n",
      "[epoch 47] loss: 0.0000558\n",
      "Test set: Average loss: 2.3641, Accuracy: 3302/5000 (66%)\n",
      "[epoch 48] loss: 0.0000397\n",
      "Test set: Average loss: 2.4198, Accuracy: 3299/5000 (66%)\n",
      "[epoch 49] loss: 0.0000283\n",
      "Test set: Average loss: 2.4694, Accuracy: 3307/5000 (66%)\n",
      "[epoch 50] loss: 0.0000201\n",
      "Test set: Average loss: 2.5240, Accuracy: 3302/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4694, Accuracy: 3307/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.4447, Accuracy: 6778/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3149, Accuracy: 140/5000 (3%)\n",
      "[epoch 1] loss: 1.1918238\n",
      "Test set: Average loss: 1.2320, Accuracy: 2920/5000 (58%)\n",
      "[epoch 2] loss: 1.0861130\n",
      "Test set: Average loss: 1.1915, Accuracy: 2881/5000 (58%)\n",
      "[epoch 3] loss: 1.0435688\n",
      "Test set: Average loss: 1.1050, Accuracy: 3064/5000 (61%)\n",
      "[epoch 4] loss: 1.0050706\n",
      "Test set: Average loss: 1.1170, Accuracy: 3046/5000 (61%)\n",
      "[epoch 5] loss: 0.9702584\n",
      "Test set: Average loss: 1.0840, Accuracy: 3151/5000 (63%)\n",
      "[epoch 6] loss: 0.9401331\n",
      "Test set: Average loss: 1.0673, Accuracy: 3134/5000 (63%)\n",
      "[epoch 7] loss: 0.9126815\n",
      "Test set: Average loss: 1.0878, Accuracy: 3086/5000 (62%)\n",
      "[epoch 8] loss: 0.8841930\n",
      "Test set: Average loss: 1.1028, Accuracy: 3130/5000 (63%)\n",
      "[epoch 9] loss: 0.8553407\n",
      "Test set: Average loss: 1.1087, Accuracy: 3095/5000 (62%)\n",
      "[epoch 10] loss: 0.7983007\n",
      "Test set: Average loss: 1.0500, Accuracy: 3219/5000 (64%)\n",
      "[epoch 11] loss: 0.7673192\n",
      "Test set: Average loss: 1.0509, Accuracy: 3253/5000 (65%)\n",
      "[epoch 12] loss: 0.7225881\n",
      "Test set: Average loss: 1.0931, Accuracy: 3187/5000 (64%)\n",
      "[epoch 13] loss: 0.6716096\n",
      "Test set: Average loss: 1.1107, Accuracy: 3206/5000 (64%)\n",
      "[epoch 14] loss: 0.6119254\n",
      "Test set: Average loss: 1.1292, Accuracy: 3216/5000 (64%)\n",
      "[epoch 15] loss: 0.5507013\n",
      "Test set: Average loss: 1.1233, Accuracy: 3213/5000 (64%)\n",
      "[epoch 16] loss: 0.4818732\n",
      "Test set: Average loss: 1.2247, Accuracy: 3147/5000 (63%)\n",
      "[epoch 17] loss: 0.4132685\n",
      "Test set: Average loss: 1.2448, Accuracy: 3197/5000 (64%)\n",
      "[epoch 18] loss: 0.3413461\n",
      "Test set: Average loss: 1.3333, Accuracy: 3146/5000 (63%)\n",
      "[epoch 19] loss: 0.2849173\n",
      "Test set: Average loss: 1.3754, Accuracy: 3226/5000 (65%)\n",
      "[epoch 20] loss: 0.2139449\n",
      "Test set: Average loss: 1.4003, Accuracy: 3210/5000 (64%)\n",
      "[epoch 21] loss: 0.1711484\n",
      "Test set: Average loss: 1.4783, Accuracy: 3220/5000 (64%)\n",
      "[epoch 22] loss: 0.1600983\n",
      "Test set: Average loss: 1.5444, Accuracy: 3233/5000 (65%)\n",
      "[epoch 23] loss: 0.1205916\n",
      "Test set: Average loss: 1.6283, Accuracy: 3180/5000 (64%)\n",
      "[epoch 24] loss: 0.1386226\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7297, Accuracy: 3210/5000 (64%)\n",
      "[epoch 25] loss: 0.0444030\n",
      "Test set: Average loss: 1.6229, Accuracy: 3280/5000 (66%)\n",
      "[epoch 26] loss: 0.0164091\n",
      "Test set: Average loss: 1.6309, Accuracy: 3280/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27] loss: 0.0110900\n",
      "Test set: Average loss: 1.6505, Accuracy: 3308/5000 (66%)\n",
      "[epoch 28] loss: 0.0082475\n",
      "Test set: Average loss: 1.6633, Accuracy: 3301/5000 (66%)\n",
      "[epoch 29] loss: 0.0063427\n",
      "Test set: Average loss: 1.6878, Accuracy: 3294/5000 (66%)\n",
      "[epoch 30] loss: 0.0049535\n",
      "Test set: Average loss: 1.7144, Accuracy: 3305/5000 (66%)\n",
      "[epoch 31] loss: 0.0038508\n",
      "Test set: Average loss: 1.7380, Accuracy: 3301/5000 (66%)\n",
      "[epoch 32] loss: 0.0029595\n",
      "Test set: Average loss: 1.7694, Accuracy: 3312/5000 (66%)\n",
      "[epoch 33] loss: 0.0022699\n",
      "Test set: Average loss: 1.8046, Accuracy: 3300/5000 (66%)\n",
      "[epoch 34] loss: 0.0017367\n",
      "Test set: Average loss: 1.8386, Accuracy: 3315/5000 (66%)\n",
      "[epoch 35] loss: 0.0013102\n",
      "Test set: Average loss: 1.8861, Accuracy: 3322/5000 (66%)\n",
      "[epoch 36] loss: 0.0009856\n",
      "Test set: Average loss: 1.9261, Accuracy: 3317/5000 (66%)\n",
      "[epoch 37] loss: 0.0007241\n",
      "Test set: Average loss: 1.9673, Accuracy: 3302/5000 (66%)\n",
      "[epoch 38] loss: 0.0005361\n",
      "Test set: Average loss: 2.0076, Accuracy: 3318/5000 (66%)\n",
      "[epoch 39] loss: 0.0003936\n",
      "Test set: Average loss: 2.0577, Accuracy: 3322/5000 (66%)\n",
      "[epoch 40] loss: 0.0002868\n",
      "Test set: Average loss: 2.1074, Accuracy: 3324/5000 (66%)\n",
      "[epoch 41] loss: 0.0002088\n",
      "Test set: Average loss: 2.1479, Accuracy: 3310/5000 (66%)\n",
      "[epoch 42] loss: 0.0001511\n",
      "Test set: Average loss: 2.2095, Accuracy: 3325/5000 (66%)\n",
      "[epoch 43] loss: 0.0001090\n",
      "Test set: Average loss: 2.2552, Accuracy: 3327/5000 (67%)\n",
      "[epoch 44] loss: 0.0000784\n",
      "Test set: Average loss: 2.3030, Accuracy: 3320/5000 (66%)\n",
      "[epoch 45] loss: 0.0000561\n",
      "Test set: Average loss: 2.3619, Accuracy: 3313/5000 (66%)\n",
      "[epoch 46] loss: 0.0000403\n",
      "Test set: Average loss: 2.4144, Accuracy: 3332/5000 (67%)\n",
      "[epoch 47] loss: 0.0000284\n",
      "Test set: Average loss: 2.4676, Accuracy: 3324/5000 (66%)\n",
      "[epoch 48] loss: 0.0000204\n",
      "Test set: Average loss: 2.5159, Accuracy: 3314/5000 (66%)\n",
      "[epoch 49] loss: 0.0000144\n",
      "Test set: Average loss: 2.5745, Accuracy: 3323/5000 (66%)\n",
      "[epoch 50] loss: 0.0000102\n",
      "Test set: Average loss: 2.6395, Accuracy: 3324/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4144, Accuracy: 3332/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.2960, Accuracy: 6793/10000 (68%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3213, Accuracy: 56/5000 (1%)\n",
      "[epoch 1] loss: 1.1685300\n",
      "Test set: Average loss: 1.1679, Accuracy: 2975/5000 (60%)\n",
      "[epoch 2] loss: 1.0705670\n",
      "Test set: Average loss: 1.1262, Accuracy: 3039/5000 (61%)\n",
      "[epoch 3] loss: 1.0343714\n",
      "Test set: Average loss: 1.1778, Accuracy: 2937/5000 (59%)\n",
      "[epoch 4] loss: 0.9968851\n",
      "Test set: Average loss: 1.0891, Accuracy: 3088/5000 (62%)\n",
      "[epoch 5] loss: 0.9716970\n",
      "Test set: Average loss: 1.1057, Accuracy: 3047/5000 (61%)\n",
      "[epoch 6] loss: 0.9364190\n",
      "Test set: Average loss: 1.0850, Accuracy: 3116/5000 (62%)\n",
      "[epoch 7] loss: 0.9059330\n",
      "Test set: Average loss: 1.0523, Accuracy: 3140/5000 (63%)\n",
      "[epoch 8] loss: 0.8729471\n",
      "Test set: Average loss: 1.0835, Accuracy: 3152/5000 (63%)\n",
      "[epoch 9] loss: 0.8364833\n",
      "Test set: Average loss: 1.1205, Accuracy: 3109/5000 (62%)\n",
      "[epoch 10] loss: 0.8057708\n",
      "Test set: Average loss: 1.0626, Accuracy: 3203/5000 (64%)\n",
      "[epoch 11] loss: 0.7567276\n",
      "Test set: Average loss: 1.0859, Accuracy: 3188/5000 (64%)\n",
      "[epoch 12] loss: 0.7076600\n",
      "Test set: Average loss: 1.0919, Accuracy: 3208/5000 (64%)\n",
      "[epoch 13] loss: 0.6596155\n",
      "Test set: Average loss: 1.0791, Accuracy: 3258/5000 (65%)\n",
      "[epoch 14] loss: 0.5991835\n",
      "Test set: Average loss: 1.0897, Accuracy: 3258/5000 (65%)\n",
      "[epoch 15] loss: 0.5285159\n",
      "Test set: Average loss: 1.1048, Accuracy: 3311/5000 (66%)\n",
      "[epoch 16] loss: 0.4551714\n",
      "Test set: Average loss: 1.1971, Accuracy: 3243/5000 (65%)\n",
      "[epoch 17] loss: 0.3813061\n",
      "Test set: Average loss: 1.2222, Accuracy: 3248/5000 (65%)\n",
      "[epoch 18] loss: 0.3133048\n",
      "Test set: Average loss: 1.3299, Accuracy: 3202/5000 (64%)\n",
      "[epoch 19] loss: 0.2415871\n",
      "Test set: Average loss: 1.3679, Accuracy: 3281/5000 (66%)\n",
      "[epoch 20] loss: 0.2092600\n",
      "Test set: Average loss: 1.5283, Accuracy: 3170/5000 (63%)\n",
      "[epoch 21] loss: 0.1652256\n",
      "Test set: Average loss: 1.6381, Accuracy: 3157/5000 (63%)\n",
      "[epoch 22] loss: 0.1636745\n",
      "Test set: Average loss: 1.6223, Accuracy: 3225/5000 (64%)\n",
      "[epoch 23] loss: 0.1399492\n",
      "Test set: Average loss: 1.7327, Accuracy: 3212/5000 (64%)\n",
      "[epoch 24] loss: 0.1361988\n",
      "Test set: Average loss: 1.7833, Accuracy: 3144/5000 (63%)\n",
      "[epoch 25] loss: 0.1319022\n",
      "Test set: Average loss: 1.8964, Accuracy: 3177/5000 (64%)\n",
      "[epoch 26] loss: 0.1143596\n",
      "Test set: Average loss: 1.8774, Accuracy: 3204/5000 (64%)\n",
      "[epoch 27] loss: 0.1292353\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9271, Accuracy: 3160/5000 (63%)\n",
      "[epoch 28] loss: 0.0410571\n",
      "Test set: Average loss: 1.7908, Accuracy: 3266/5000 (65%)\n",
      "[epoch 29] loss: 0.0122649\n",
      "Test set: Average loss: 1.8030, Accuracy: 3281/5000 (66%)\n",
      "[epoch 30] loss: 0.0075325\n",
      "Test set: Average loss: 1.8165, Accuracy: 3291/5000 (66%)\n",
      "[epoch 31] loss: 0.0053246\n",
      "Test set: Average loss: 1.8370, Accuracy: 3283/5000 (66%)\n",
      "[epoch 32] loss: 0.0039020\n",
      "Test set: Average loss: 1.8583, Accuracy: 3287/5000 (66%)\n",
      "[epoch 33] loss: 0.0028732\n",
      "Test set: Average loss: 1.8880, Accuracy: 3284/5000 (66%)\n",
      "[epoch 34] loss: 0.0021088\n",
      "Test set: Average loss: 1.9134, Accuracy: 3301/5000 (66%)\n",
      "[epoch 35] loss: 0.0015303\n",
      "Test set: Average loss: 1.9450, Accuracy: 3308/5000 (66%)\n",
      "[epoch 36] loss: 0.0011076\n",
      "Test set: Average loss: 1.9920, Accuracy: 3310/5000 (66%)\n",
      "[epoch 37] loss: 0.0007929\n",
      "Test set: Average loss: 2.0317, Accuracy: 3304/5000 (66%)\n",
      "[epoch 38] loss: 0.0005601\n",
      "Test set: Average loss: 2.0759, Accuracy: 3304/5000 (66%)\n",
      "[epoch 39] loss: 0.0003934\n",
      "Test set: Average loss: 2.1169, Accuracy: 3323/5000 (66%)\n",
      "[epoch 40] loss: 0.0002740\n",
      "Test set: Average loss: 2.1677, Accuracy: 3322/5000 (66%)\n",
      "[epoch 41] loss: 0.0001895\n",
      "Test set: Average loss: 2.2153, Accuracy: 3320/5000 (66%)\n",
      "[epoch 42] loss: 0.0001304\n",
      "Test set: Average loss: 2.2749, Accuracy: 3322/5000 (66%)\n",
      "[epoch 43] loss: 0.0000891\n",
      "Test set: Average loss: 2.3279, Accuracy: 3328/5000 (67%)\n",
      "[epoch 44] loss: 0.0000606\n",
      "Test set: Average loss: 2.3789, Accuracy: 3338/5000 (67%)\n",
      "[epoch 45] loss: 0.0000412\n",
      "Test set: Average loss: 2.4324, Accuracy: 3331/5000 (67%)\n",
      "[epoch 46] loss: 0.0000278\n",
      "Test set: Average loss: 2.4927, Accuracy: 3334/5000 (67%)\n",
      "[epoch 47] loss: 0.0000187\n",
      "Test set: Average loss: 2.5536, Accuracy: 3330/5000 (67%)\n",
      "[epoch 48] loss: 0.0000125\n",
      "Test set: Average loss: 2.6142, Accuracy: 3328/5000 (67%)\n",
      "[epoch 49] loss: 0.0000084\n",
      "Test set: Average loss: 2.6750, Accuracy: 3332/5000 (67%)\n",
      "[epoch 50] loss: 0.0000056\n",
      "Test set: Average loss: 2.7365, Accuracy: 3337/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3789, Accuracy: 3338/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.2873, Accuracy: 6771/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2921, Accuracy: 810/5000 (16%)\n",
      "[epoch 1] loss: 1.1720339\n",
      "Test set: Average loss: 1.2398, Accuracy: 2844/5000 (57%)\n",
      "[epoch 2] loss: 1.0776708\n",
      "Test set: Average loss: 1.1751, Accuracy: 2934/5000 (59%)\n",
      "[epoch 3] loss: 1.0324732\n",
      "Test set: Average loss: 1.1755, Accuracy: 2942/5000 (59%)\n",
      "[epoch 4] loss: 0.9976886\n",
      "Test set: Average loss: 1.1276, Accuracy: 3065/5000 (61%)\n",
      "[epoch 5] loss: 0.9625750\n",
      "Test set: Average loss: 1.0850, Accuracy: 3117/5000 (62%)\n",
      "[epoch 6] loss: 0.9367604\n",
      "Test set: Average loss: 1.0763, Accuracy: 3113/5000 (62%)\n",
      "[epoch 7] loss: 0.9093934\n",
      "Test set: Average loss: 1.0522, Accuracy: 3136/5000 (63%)\n",
      "[epoch 8] loss: 0.8757121\n",
      "Test set: Average loss: 1.0943, Accuracy: 3123/5000 (62%)\n",
      "[epoch 9] loss: 0.8365004\n",
      "Test set: Average loss: 1.0526, Accuracy: 3205/5000 (64%)\n",
      "[epoch 10] loss: 0.7983332\n",
      "Test set: Average loss: 1.0414, Accuracy: 3233/5000 (65%)\n",
      "[epoch 11] loss: 0.7560177\n",
      "Test set: Average loss: 1.0313, Accuracy: 3277/5000 (66%)\n",
      "[epoch 12] loss: 0.7143178\n",
      "Test set: Average loss: 1.0587, Accuracy: 3251/5000 (65%)\n",
      "[epoch 13] loss: 0.6611840\n",
      "Test set: Average loss: 1.0810, Accuracy: 3242/5000 (65%)\n",
      "[epoch 14] loss: 0.6051618\n",
      "Test set: Average loss: 1.1412, Accuracy: 3187/5000 (64%)\n",
      "[epoch 15] loss: 0.5398106\n",
      "Test set: Average loss: 1.1280, Accuracy: 3236/5000 (65%)\n",
      "[epoch 16] loss: 0.4736975\n",
      "Test set: Average loss: 1.1431, Accuracy: 3229/5000 (65%)\n",
      "[epoch 17] loss: 0.3966210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.2727, Accuracy: 3211/5000 (64%)\n",
      "[epoch 18] loss: 0.3207957\n",
      "Test set: Average loss: 1.3024, Accuracy: 3187/5000 (64%)\n",
      "[epoch 19] loss: 0.2555984\n",
      "Test set: Average loss: 1.4445, Accuracy: 3152/5000 (63%)\n",
      "[epoch 20] loss: 0.2132095\n",
      "Test set: Average loss: 1.4433, Accuracy: 3191/5000 (64%)\n",
      "[epoch 21] loss: 0.1954669\n",
      "Test set: Average loss: 1.5671, Accuracy: 3190/5000 (64%)\n",
      "[epoch 22] loss: 0.1571785\n",
      "Test set: Average loss: 1.6041, Accuracy: 3229/5000 (65%)\n",
      "[epoch 23] loss: 0.1383203\n",
      "Test set: Average loss: 1.6905, Accuracy: 3230/5000 (65%)\n",
      "[epoch 24] loss: 0.1632593\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7512, Accuracy: 3167/5000 (63%)\n",
      "[epoch 25] loss: 0.0462886\n",
      "Test set: Average loss: 1.6312, Accuracy: 3265/5000 (65%)\n",
      "[epoch 26] loss: 0.0180949\n",
      "Test set: Average loss: 1.6395, Accuracy: 3293/5000 (66%)\n",
      "[epoch 27] loss: 0.0116048\n",
      "Test set: Average loss: 1.6606, Accuracy: 3288/5000 (66%)\n",
      "[epoch 28] loss: 0.0082690\n",
      "Test set: Average loss: 1.6858, Accuracy: 3295/5000 (66%)\n",
      "[epoch 29] loss: 0.0060815\n",
      "Test set: Average loss: 1.7085, Accuracy: 3309/5000 (66%)\n",
      "[epoch 30] loss: 0.0044967\n",
      "Test set: Average loss: 1.7395, Accuracy: 3301/5000 (66%)\n",
      "[epoch 31] loss: 0.0032989\n",
      "Test set: Average loss: 1.7711, Accuracy: 3306/5000 (66%)\n",
      "[epoch 32] loss: 0.0024038\n",
      "Test set: Average loss: 1.8092, Accuracy: 3305/5000 (66%)\n",
      "[epoch 33] loss: 0.0017311\n",
      "Test set: Average loss: 1.8504, Accuracy: 3313/5000 (66%)\n",
      "[epoch 34] loss: 0.0012411\n",
      "Test set: Average loss: 1.8899, Accuracy: 3313/5000 (66%)\n",
      "[epoch 35] loss: 0.0008789\n",
      "Test set: Average loss: 1.9442, Accuracy: 3316/5000 (66%)\n",
      "[epoch 36] loss: 0.0006163\n",
      "Test set: Average loss: 1.9860, Accuracy: 3317/5000 (66%)\n",
      "[epoch 37] loss: 0.0004305\n",
      "Test set: Average loss: 2.0442, Accuracy: 3309/5000 (66%)\n",
      "[epoch 38] loss: 0.0002993\n",
      "Test set: Average loss: 2.1033, Accuracy: 3316/5000 (66%)\n",
      "[epoch 39] loss: 0.0002065\n",
      "Test set: Average loss: 2.1502, Accuracy: 3319/5000 (66%)\n",
      "[epoch 40] loss: 0.0001422\n",
      "Test set: Average loss: 2.2040, Accuracy: 3322/5000 (66%)\n",
      "[epoch 41] loss: 0.0000970\n",
      "Test set: Average loss: 2.2703, Accuracy: 3322/5000 (66%)\n",
      "[epoch 42] loss: 0.0000666\n",
      "Test set: Average loss: 2.3229, Accuracy: 3310/5000 (66%)\n",
      "[epoch 43] loss: 0.0000451\n",
      "Test set: Average loss: 2.3841, Accuracy: 3315/5000 (66%)\n",
      "[epoch 44] loss: 0.0000307\n",
      "Test set: Average loss: 2.4458, Accuracy: 3319/5000 (66%)\n",
      "[epoch 45] loss: 0.0000205\n",
      "Test set: Average loss: 2.5068, Accuracy: 3316/5000 (66%)\n",
      "[epoch 46] loss: 0.0000138\n",
      "Test set: Average loss: 2.5725, Accuracy: 3314/5000 (66%)\n",
      "[epoch 47] loss: 0.0000094\n",
      "Test set: Average loss: 2.6400, Accuracy: 3316/5000 (66%)\n",
      "[epoch 48] loss: 0.0000062\n",
      "Test set: Average loss: 2.6987, Accuracy: 3320/5000 (66%)\n",
      "[epoch 49] loss: 0.0000042\n",
      "Test set: Average loss: 2.7616, Accuracy: 3301/5000 (66%)\n",
      "[epoch 50] loss: 0.0000028\n",
      "Test set: Average loss: 2.8285, Accuracy: 3301/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2703, Accuracy: 3322/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.1552, Accuracy: 6866/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3217, Accuracy: 66/5000 (1%)\n",
      "[epoch 1] loss: 1.1940795\n",
      "Test set: Average loss: 1.1761, Accuracy: 2920/5000 (58%)\n",
      "[epoch 2] loss: 1.0784897\n",
      "Test set: Average loss: 1.1551, Accuracy: 3005/5000 (60%)\n",
      "[epoch 3] loss: 1.0415118\n",
      "Test set: Average loss: 1.1170, Accuracy: 3036/5000 (61%)\n",
      "[epoch 4] loss: 1.0018191\n",
      "Test set: Average loss: 1.0731, Accuracy: 3153/5000 (63%)\n",
      "[epoch 5] loss: 0.9680916\n",
      "Test set: Average loss: 1.1025, Accuracy: 3089/5000 (62%)\n",
      "[epoch 6] loss: 0.9440368\n",
      "Test set: Average loss: 1.0728, Accuracy: 3106/5000 (62%)\n",
      "[epoch 7] loss: 0.9076165\n",
      "Test set: Average loss: 1.0888, Accuracy: 3121/5000 (62%)\n",
      "[epoch 8] loss: 0.8763094\n",
      "Test set: Average loss: 1.0500, Accuracy: 3175/5000 (64%)\n",
      "[epoch 9] loss: 0.8296891\n",
      "Test set: Average loss: 1.0393, Accuracy: 3233/5000 (65%)\n",
      "[epoch 10] loss: 0.7858606\n",
      "Test set: Average loss: 1.1061, Accuracy: 3122/5000 (62%)\n",
      "[epoch 11] loss: 0.7541799\n",
      "Test set: Average loss: 1.1339, Accuracy: 3188/5000 (64%)\n",
      "[epoch 12] loss: 0.7020175\n",
      "Test set: Average loss: 1.0528, Accuracy: 3283/5000 (66%)\n",
      "[epoch 13] loss: 0.6461185\n",
      "Test set: Average loss: 1.0803, Accuracy: 3293/5000 (66%)\n",
      "[epoch 14] loss: 0.5949491\n",
      "Test set: Average loss: 1.1212, Accuracy: 3283/5000 (66%)\n",
      "[epoch 15] loss: 0.5265987\n",
      "Test set: Average loss: 1.1427, Accuracy: 3225/5000 (64%)\n",
      "[epoch 16] loss: 0.4613261\n",
      "Test set: Average loss: 1.1565, Accuracy: 3251/5000 (65%)\n",
      "[epoch 17] loss: 0.3802312\n",
      "Test set: Average loss: 1.2250, Accuracy: 3283/5000 (66%)\n",
      "[epoch 18] loss: 0.3148266\n",
      "Test set: Average loss: 1.3613, Accuracy: 3226/5000 (65%)\n",
      "[epoch 19] loss: 0.2451654\n",
      "Test set: Average loss: 1.3608, Accuracy: 3209/5000 (64%)\n",
      "[epoch 20] loss: 0.2087131\n",
      "Test set: Average loss: 1.4791, Accuracy: 3251/5000 (65%)\n",
      "[epoch 21] loss: 0.1710148\n",
      "Test set: Average loss: 1.6207, Accuracy: 3219/5000 (64%)\n",
      "[epoch 22] loss: 0.1732796\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6016, Accuracy: 3206/5000 (64%)\n",
      "[epoch 23] loss: 0.0675388\n",
      "Test set: Average loss: 1.5014, Accuracy: 3322/5000 (66%)\n",
      "[epoch 24] loss: 0.0268419\n",
      "Test set: Average loss: 1.5149, Accuracy: 3331/5000 (67%)\n",
      "[epoch 25] loss: 0.0172343\n",
      "Test set: Average loss: 1.5382, Accuracy: 3335/5000 (67%)\n",
      "[epoch 26] loss: 0.0121724\n",
      "Test set: Average loss: 1.5654, Accuracy: 3343/5000 (67%)\n",
      "[epoch 27] loss: 0.0089180\n",
      "Test set: Average loss: 1.5959, Accuracy: 3322/5000 (66%)\n",
      "[epoch 28] loss: 0.0066041\n",
      "Test set: Average loss: 1.6308, Accuracy: 3339/5000 (67%)\n",
      "[epoch 29] loss: 0.0048143\n",
      "Test set: Average loss: 1.6622, Accuracy: 3343/5000 (67%)\n",
      "[epoch 30] loss: 0.0035061\n",
      "Test set: Average loss: 1.7003, Accuracy: 3339/5000 (67%)\n",
      "[epoch 31] loss: 0.0025170\n",
      "Test set: Average loss: 1.7470, Accuracy: 3344/5000 (67%)\n",
      "[epoch 32] loss: 0.0018051\n",
      "Test set: Average loss: 1.7941, Accuracy: 3343/5000 (67%)\n",
      "[epoch 33] loss: 0.0012887\n",
      "Test set: Average loss: 1.8520, Accuracy: 3344/5000 (67%)\n",
      "[epoch 34] loss: 0.0008982\n",
      "Test set: Average loss: 1.8947, Accuracy: 3347/5000 (67%)\n",
      "[epoch 35] loss: 0.0006315\n",
      "Test set: Average loss: 1.9515, Accuracy: 3353/5000 (67%)\n",
      "[epoch 36] loss: 0.0004412\n",
      "Test set: Average loss: 2.0091, Accuracy: 3354/5000 (67%)\n",
      "[epoch 37] loss: 0.0003053\n",
      "Test set: Average loss: 2.0663, Accuracy: 3366/5000 (67%)\n",
      "[epoch 38] loss: 0.0002102\n",
      "Test set: Average loss: 2.1229, Accuracy: 3358/5000 (67%)\n",
      "[epoch 39] loss: 0.0001445\n",
      "Test set: Average loss: 2.1790, Accuracy: 3365/5000 (67%)\n",
      "[epoch 40] loss: 0.0000985\n",
      "Test set: Average loss: 2.2408, Accuracy: 3361/5000 (67%)\n",
      "[epoch 41] loss: 0.0000671\n",
      "Test set: Average loss: 2.3000, Accuracy: 3372/5000 (67%)\n",
      "[epoch 42] loss: 0.0000455\n",
      "Test set: Average loss: 2.3612, Accuracy: 3356/5000 (67%)\n",
      "[epoch 43] loss: 0.0000309\n",
      "Test set: Average loss: 2.4197, Accuracy: 3366/5000 (67%)\n",
      "[epoch 44] loss: 0.0000208\n",
      "Test set: Average loss: 2.4871, Accuracy: 3364/5000 (67%)\n",
      "[epoch 45] loss: 0.0000139\n",
      "Test set: Average loss: 2.5537, Accuracy: 3370/5000 (67%)\n",
      "[epoch 46] loss: 0.0000094\n",
      "Test set: Average loss: 2.6144, Accuracy: 3375/5000 (68%)\n",
      "[epoch 47] loss: 0.0000062\n",
      "Test set: Average loss: 2.6775, Accuracy: 3372/5000 (67%)\n",
      "[epoch 48] loss: 0.0000042\n",
      "Test set: Average loss: 2.7469, Accuracy: 3364/5000 (67%)\n",
      "[epoch 49] loss: 0.0000028\n",
      "Test set: Average loss: 2.8115, Accuracy: 3369/5000 (67%)\n",
      "[epoch 50] loss: 0.0000018\n",
      "Test set: Average loss: 2.8723, Accuracy: 3359/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6144, Accuracy: 3375/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.5115, Accuracy: 6868/10000 (69%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2971, Accuracy: 682/5000 (14%)\n",
      "[epoch 1] loss: 1.1643180\n",
      "Test set: Average loss: 1.1594, Accuracy: 3001/5000 (60%)\n",
      "[epoch 2] loss: 1.0722477\n",
      "Test set: Average loss: 1.0623, Accuracy: 3119/5000 (62%)\n",
      "[epoch 3] loss: 1.0285853\n",
      "Test set: Average loss: 1.1125, Accuracy: 3084/5000 (62%)\n",
      "[epoch 4] loss: 0.9835769\n",
      "Test set: Average loss: 1.0541, Accuracy: 3157/5000 (63%)\n",
      "[epoch 5] loss: 0.9631987\n",
      "Test set: Average loss: 1.1310, Accuracy: 3120/5000 (62%)\n",
      "[epoch 6] loss: 0.9246587\n",
      "Test set: Average loss: 1.0811, Accuracy: 3123/5000 (62%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 0.8901825\n",
      "Test set: Average loss: 1.0335, Accuracy: 3176/5000 (64%)\n",
      "[epoch 8] loss: 0.8525471\n",
      "Test set: Average loss: 1.0150, Accuracy: 3246/5000 (65%)\n",
      "[epoch 9] loss: 0.8060799\n",
      "Test set: Average loss: 1.0348, Accuracy: 3278/5000 (66%)\n",
      "[epoch 10] loss: 0.7728787\n",
      "Test set: Average loss: 1.0098, Accuracy: 3262/5000 (65%)\n",
      "[epoch 11] loss: 0.7213630\n",
      "Test set: Average loss: 1.0388, Accuracy: 3266/5000 (65%)\n",
      "[epoch 12] loss: 0.6711809\n",
      "Test set: Average loss: 1.0244, Accuracy: 3292/5000 (66%)\n",
      "[epoch 13] loss: 0.6113543\n",
      "Test set: Average loss: 1.0454, Accuracy: 3303/5000 (66%)\n",
      "[epoch 14] loss: 0.5486338\n",
      "Test set: Average loss: 1.1042, Accuracy: 3280/5000 (66%)\n",
      "[epoch 15] loss: 0.4729168\n",
      "Test set: Average loss: 1.1277, Accuracy: 3353/5000 (67%)\n",
      "[epoch 16] loss: 0.4116965\n",
      "Test set: Average loss: 1.1582, Accuracy: 3309/5000 (66%)\n",
      "[epoch 17] loss: 0.3403639\n",
      "Test set: Average loss: 1.2198, Accuracy: 3299/5000 (66%)\n",
      "[epoch 18] loss: 0.2809695\n",
      "Test set: Average loss: 1.2822, Accuracy: 3322/5000 (66%)\n",
      "[epoch 19] loss: 0.2313568\n",
      "Test set: Average loss: 1.3601, Accuracy: 3333/5000 (67%)\n",
      "[epoch 20] loss: 0.1928953\n",
      "Test set: Average loss: 1.5231, Accuracy: 3291/5000 (66%)\n",
      "[epoch 21] loss: 0.1740499\n",
      "Test set: Average loss: 1.5007, Accuracy: 3275/5000 (66%)\n",
      "[epoch 22] loss: 0.1672365\n",
      "Test set: Average loss: 1.5793, Accuracy: 3278/5000 (66%)\n",
      "[epoch 23] loss: 0.1566365\n",
      "Test set: Average loss: 1.6293, Accuracy: 3286/5000 (66%)\n",
      "[epoch 24] loss: 0.1468550\n",
      "Test set: Average loss: 1.7103, Accuracy: 3257/5000 (65%)\n",
      "[epoch 25] loss: 0.1379528\n",
      "Test set: Average loss: 1.7953, Accuracy: 3257/5000 (65%)\n",
      "[epoch 26] loss: 0.1410537\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8609, Accuracy: 3244/5000 (65%)\n",
      "[epoch 27] loss: 0.0454695\n",
      "Test set: Average loss: 1.7086, Accuracy: 3339/5000 (67%)\n",
      "[epoch 28] loss: 0.0140835\n",
      "Test set: Average loss: 1.7212, Accuracy: 3382/5000 (68%)\n",
      "[epoch 29] loss: 0.0084159\n",
      "Test set: Average loss: 1.7377, Accuracy: 3383/5000 (68%)\n",
      "[epoch 30] loss: 0.0057569\n",
      "Test set: Average loss: 1.7556, Accuracy: 3394/5000 (68%)\n",
      "[epoch 31] loss: 0.0040678\n",
      "Test set: Average loss: 1.7796, Accuracy: 3403/5000 (68%)\n",
      "[epoch 32] loss: 0.0028631\n",
      "Test set: Average loss: 1.8124, Accuracy: 3399/5000 (68%)\n",
      "[epoch 33] loss: 0.0020014\n",
      "Test set: Average loss: 1.8477, Accuracy: 3402/5000 (68%)\n",
      "[epoch 34] loss: 0.0013879\n",
      "Test set: Average loss: 1.8964, Accuracy: 3400/5000 (68%)\n",
      "[epoch 35] loss: 0.0009502\n",
      "Test set: Average loss: 1.9302, Accuracy: 3405/5000 (68%)\n",
      "[epoch 36] loss: 0.0006415\n",
      "Test set: Average loss: 1.9732, Accuracy: 3413/5000 (68%)\n",
      "[epoch 37] loss: 0.0004316\n",
      "Test set: Average loss: 2.0397, Accuracy: 3411/5000 (68%)\n",
      "[epoch 38] loss: 0.0002843\n",
      "Test set: Average loss: 2.0911, Accuracy: 3424/5000 (68%)\n",
      "[epoch 39] loss: 0.0001867\n",
      "Test set: Average loss: 2.1492, Accuracy: 3400/5000 (68%)\n",
      "[epoch 40] loss: 0.0001230\n",
      "Test set: Average loss: 2.2021, Accuracy: 3401/5000 (68%)\n",
      "[epoch 41] loss: 0.0000799\n",
      "Test set: Average loss: 2.2654, Accuracy: 3410/5000 (68%)\n",
      "[epoch 42] loss: 0.0000515\n",
      "Test set: Average loss: 2.3324, Accuracy: 3405/5000 (68%)\n",
      "[epoch 43] loss: 0.0000332\n",
      "Test set: Average loss: 2.3879, Accuracy: 3414/5000 (68%)\n",
      "[epoch 44] loss: 0.0000215\n",
      "Test set: Average loss: 2.4615, Accuracy: 3407/5000 (68%)\n",
      "[epoch 45] loss: 0.0000137\n",
      "Test set: Average loss: 2.5262, Accuracy: 3396/5000 (68%)\n",
      "[epoch 46] loss: 0.0000087\n",
      "Test set: Average loss: 2.5978, Accuracy: 3409/5000 (68%)\n",
      "[epoch 47] loss: 0.0000055\n",
      "Test set: Average loss: 2.6623, Accuracy: 3408/5000 (68%)\n",
      "[epoch 48] loss: 0.0000035\n",
      "Test set: Average loss: 2.7261, Accuracy: 3395/5000 (68%)\n",
      "[epoch 49] loss: 0.0000022\n",
      "Test set: Average loss: 2.7915, Accuracy: 3403/5000 (68%)\n",
      "[epoch 50] loss: 0.0000014\n",
      "Test set: Average loss: 2.8557, Accuracy: 3409/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0911, Accuracy: 3424/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.0725, Accuracy: 6842/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2846, Accuracy: 481/5000 (10%)\n",
      "[epoch 1] loss: 1.1804803\n",
      "Test set: Average loss: 1.2174, Accuracy: 2883/5000 (58%)\n",
      "[epoch 2] loss: 1.0703291\n",
      "Test set: Average loss: 1.0976, Accuracy: 3109/5000 (62%)\n",
      "[epoch 3] loss: 1.0333388\n",
      "Test set: Average loss: 1.1167, Accuracy: 3069/5000 (61%)\n",
      "[epoch 4] loss: 0.9954749\n",
      "Test set: Average loss: 1.0648, Accuracy: 3127/5000 (63%)\n",
      "[epoch 5] loss: 0.9695268\n",
      "Test set: Average loss: 1.0653, Accuracy: 3127/5000 (63%)\n",
      "[epoch 6] loss: 0.9329931\n",
      "Test set: Average loss: 1.0150, Accuracy: 3223/5000 (64%)\n",
      "[epoch 7] loss: 0.9029681\n",
      "Test set: Average loss: 1.0456, Accuracy: 3142/5000 (63%)\n",
      "[epoch 8] loss: 0.8553804\n",
      "Test set: Average loss: 1.0682, Accuracy: 3177/5000 (64%)\n",
      "[epoch 9] loss: 0.8274190\n",
      "Test set: Average loss: 1.0433, Accuracy: 3196/5000 (64%)\n",
      "[epoch 10] loss: 0.7719438\n",
      "Test set: Average loss: 1.0164, Accuracy: 3283/5000 (66%)\n",
      "[epoch 11] loss: 0.7426575\n",
      "Test set: Average loss: 1.0147, Accuracy: 3296/5000 (66%)\n",
      "[epoch 12] loss: 0.6826506\n",
      "Test set: Average loss: 1.0473, Accuracy: 3253/5000 (65%)\n",
      "[epoch 13] loss: 0.6286751\n",
      "Test set: Average loss: 1.0662, Accuracy: 3296/5000 (66%)\n",
      "[epoch 14] loss: 0.5719051\n",
      "Test set: Average loss: 1.1004, Accuracy: 3260/5000 (65%)\n",
      "[epoch 15] loss: 0.4997385\n",
      "Test set: Average loss: 1.1343, Accuracy: 3284/5000 (66%)\n",
      "[epoch 16] loss: 0.4306921\n",
      "Test set: Average loss: 1.2592, Accuracy: 3178/5000 (64%)\n",
      "[epoch 17] loss: 0.3590547\n",
      "Test set: Average loss: 1.2675, Accuracy: 3245/5000 (65%)\n",
      "[epoch 18] loss: 0.2994546\n",
      "Test set: Average loss: 1.3545, Accuracy: 3252/5000 (65%)\n",
      "[epoch 19] loss: 0.2411772\n",
      "Test set: Average loss: 1.3859, Accuracy: 3268/5000 (65%)\n",
      "[epoch 20] loss: 0.2072922\n",
      "Test set: Average loss: 1.4954, Accuracy: 3199/5000 (64%)\n",
      "[epoch 21] loss: 0.1755199\n",
      "Test set: Average loss: 1.6241, Accuracy: 3154/5000 (63%)\n",
      "[epoch 22] loss: 0.1639036\n",
      "Test set: Average loss: 1.6014, Accuracy: 3231/5000 (65%)\n",
      "[epoch 23] loss: 0.1455355\n",
      "Test set: Average loss: 1.7586, Accuracy: 3183/5000 (64%)\n",
      "[epoch 24] loss: 0.1608345\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7911, Accuracy: 3208/5000 (64%)\n",
      "[epoch 25] loss: 0.0589544\n",
      "Test set: Average loss: 1.6225, Accuracy: 3321/5000 (66%)\n",
      "[epoch 26] loss: 0.0197982\n",
      "Test set: Average loss: 1.6257, Accuracy: 3326/5000 (67%)\n",
      "[epoch 27] loss: 0.0119890\n",
      "Test set: Average loss: 1.6421, Accuracy: 3333/5000 (67%)\n",
      "[epoch 28] loss: 0.0081872\n",
      "Test set: Average loss: 1.6700, Accuracy: 3340/5000 (67%)\n",
      "[epoch 29] loss: 0.0057604\n",
      "Test set: Average loss: 1.7001, Accuracy: 3342/5000 (67%)\n",
      "[epoch 30] loss: 0.0040453\n",
      "Test set: Average loss: 1.7324, Accuracy: 3351/5000 (67%)\n",
      "[epoch 31] loss: 0.0028088\n",
      "Test set: Average loss: 1.7782, Accuracy: 3348/5000 (67%)\n",
      "[epoch 32] loss: 0.0019401\n",
      "Test set: Average loss: 1.8137, Accuracy: 3356/5000 (67%)\n",
      "[epoch 33] loss: 0.0013160\n",
      "Test set: Average loss: 1.8846, Accuracy: 3344/5000 (67%)\n",
      "[epoch 34] loss: 0.0008910\n",
      "Test set: Average loss: 1.9132, Accuracy: 3357/5000 (67%)\n",
      "[epoch 35] loss: 0.0005989\n",
      "Test set: Average loss: 1.9761, Accuracy: 3353/5000 (67%)\n",
      "[epoch 36] loss: 0.0003966\n",
      "Test set: Average loss: 2.0280, Accuracy: 3349/5000 (67%)\n",
      "[epoch 37] loss: 0.0002621\n",
      "Test set: Average loss: 2.0923, Accuracy: 3346/5000 (67%)\n",
      "[epoch 38] loss: 0.0001725\n",
      "Test set: Average loss: 2.1447, Accuracy: 3354/5000 (67%)\n",
      "[epoch 39] loss: 0.0001131\n",
      "Test set: Average loss: 2.2180, Accuracy: 3354/5000 (67%)\n",
      "[epoch 40] loss: 0.0000729\n",
      "Test set: Average loss: 2.2766, Accuracy: 3339/5000 (67%)\n",
      "[epoch 41] loss: 0.0000471\n",
      "Test set: Average loss: 2.3461, Accuracy: 3351/5000 (67%)\n",
      "[epoch 42] loss: 0.0000305\n",
      "Test set: Average loss: 2.4113, Accuracy: 3356/5000 (67%)\n",
      "[epoch 43] loss: 0.0000195\n",
      "Test set: Average loss: 2.4800, Accuracy: 3362/5000 (67%)\n",
      "[epoch 44] loss: 0.0000124\n",
      "Test set: Average loss: 2.5527, Accuracy: 3376/5000 (68%)\n",
      "[epoch 45] loss: 0.0000080\n",
      "Test set: Average loss: 2.6190, Accuracy: 3365/5000 (67%)\n",
      "[epoch 46] loss: 0.0000050\n",
      "Test set: Average loss: 2.6835, Accuracy: 3368/5000 (67%)\n",
      "[epoch 47] loss: 0.0000032\n",
      "Test set: Average loss: 2.7521, Accuracy: 3375/5000 (68%)\n",
      "[epoch 48] loss: 0.0000020\n",
      "Test set: Average loss: 2.8219, Accuracy: 3379/5000 (68%)\n",
      "[epoch 49] loss: 0.0000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.8888, Accuracy: 3367/5000 (67%)\n",
      "[epoch 50] loss: 0.0000008\n",
      "Test set: Average loss: 2.9305, Accuracy: 3372/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8219, Accuracy: 3379/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6897, Accuracy: 6905/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3258, Accuracy: 70/5000 (1%)\n",
      "[epoch 1] loss: 1.1698943\n",
      "Test set: Average loss: 1.1531, Accuracy: 2927/5000 (59%)\n",
      "[epoch 2] loss: 1.0728538\n",
      "Test set: Average loss: 1.1256, Accuracy: 3025/5000 (60%)\n",
      "[epoch 3] loss: 1.0293848\n",
      "Test set: Average loss: 1.1107, Accuracy: 3085/5000 (62%)\n",
      "[epoch 4] loss: 0.9865739\n",
      "Test set: Average loss: 1.0656, Accuracy: 3116/5000 (62%)\n",
      "[epoch 5] loss: 0.9597758\n",
      "Test set: Average loss: 1.1015, Accuracy: 3119/5000 (62%)\n",
      "[epoch 6] loss: 0.9252427\n",
      "Test set: Average loss: 1.0546, Accuracy: 3161/5000 (63%)\n",
      "[epoch 7] loss: 0.8904488\n",
      "Test set: Average loss: 1.0632, Accuracy: 3148/5000 (63%)\n",
      "[epoch 8] loss: 0.8530730\n",
      "Test set: Average loss: 1.0504, Accuracy: 3198/5000 (64%)\n",
      "[epoch 9] loss: 0.8163148\n",
      "Test set: Average loss: 1.0398, Accuracy: 3243/5000 (65%)\n",
      "[epoch 10] loss: 0.7724283\n",
      "Test set: Average loss: 1.0222, Accuracy: 3263/5000 (65%)\n",
      "[epoch 11] loss: 0.7181715\n",
      "Test set: Average loss: 1.0015, Accuracy: 3310/5000 (66%)\n",
      "[epoch 12] loss: 0.6671608\n",
      "Test set: Average loss: 1.0649, Accuracy: 3236/5000 (65%)\n",
      "[epoch 13] loss: 0.6089352\n",
      "Test set: Average loss: 1.0857, Accuracy: 3267/5000 (65%)\n",
      "[epoch 14] loss: 0.5421017\n",
      "Test set: Average loss: 1.1064, Accuracy: 3269/5000 (65%)\n",
      "[epoch 15] loss: 0.4749585\n",
      "Test set: Average loss: 1.1455, Accuracy: 3257/5000 (65%)\n",
      "[epoch 16] loss: 0.4103955\n",
      "Test set: Average loss: 1.2104, Accuracy: 3253/5000 (65%)\n",
      "[epoch 17] loss: 0.3331409\n",
      "Test set: Average loss: 1.2409, Accuracy: 3307/5000 (66%)\n",
      "[epoch 18] loss: 0.2809163\n",
      "Test set: Average loss: 1.2656, Accuracy: 3310/5000 (66%)\n",
      "[epoch 19] loss: 0.2220620\n",
      "Test set: Average loss: 1.4568, Accuracy: 3222/5000 (64%)\n",
      "[epoch 20] loss: 0.1946907\n",
      "Test set: Average loss: 1.5159, Accuracy: 3256/5000 (65%)\n",
      "[epoch 21] loss: 0.1820237\n",
      "Test set: Average loss: 1.6583, Accuracy: 3246/5000 (65%)\n",
      "[epoch 22] loss: 0.1531997\n",
      "Test set: Average loss: 1.7276, Accuracy: 3203/5000 (64%)\n",
      "[epoch 23] loss: 0.1572218\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7158, Accuracy: 3264/5000 (65%)\n",
      "[epoch 24] loss: 0.0590751\n",
      "Test set: Average loss: 1.5936, Accuracy: 3364/5000 (67%)\n",
      "[epoch 25] loss: 0.0204536\n",
      "Test set: Average loss: 1.6115, Accuracy: 3367/5000 (67%)\n",
      "[epoch 26] loss: 0.0123641\n",
      "Test set: Average loss: 1.6300, Accuracy: 3385/5000 (68%)\n",
      "[epoch 27] loss: 0.0084763\n",
      "Test set: Average loss: 1.6586, Accuracy: 3376/5000 (68%)\n",
      "[epoch 28] loss: 0.0059565\n",
      "Test set: Average loss: 1.6861, Accuracy: 3385/5000 (68%)\n",
      "[epoch 29] loss: 0.0041916\n",
      "Test set: Average loss: 1.7210, Accuracy: 3394/5000 (68%)\n",
      "[epoch 30] loss: 0.0029299\n",
      "Test set: Average loss: 1.7602, Accuracy: 3376/5000 (68%)\n",
      "[epoch 31] loss: 0.0020139\n",
      "Test set: Average loss: 1.8102, Accuracy: 3394/5000 (68%)\n",
      "[epoch 32] loss: 0.0013806\n",
      "Test set: Average loss: 1.8575, Accuracy: 3395/5000 (68%)\n",
      "[epoch 33] loss: 0.0009341\n",
      "Test set: Average loss: 1.9015, Accuracy: 3398/5000 (68%)\n",
      "[epoch 34] loss: 0.0006227\n",
      "Test set: Average loss: 1.9590, Accuracy: 3392/5000 (68%)\n",
      "[epoch 35] loss: 0.0004176\n",
      "Test set: Average loss: 2.0179, Accuracy: 3407/5000 (68%)\n",
      "[epoch 36] loss: 0.0002743\n",
      "Test set: Average loss: 2.0838, Accuracy: 3402/5000 (68%)\n",
      "[epoch 37] loss: 0.0001805\n",
      "Test set: Average loss: 2.1430, Accuracy: 3411/5000 (68%)\n",
      "[epoch 38] loss: 0.0001176\n",
      "Test set: Average loss: 2.2047, Accuracy: 3424/5000 (68%)\n",
      "[epoch 39] loss: 0.0000768\n",
      "Test set: Average loss: 2.2702, Accuracy: 3428/5000 (69%)\n",
      "[epoch 40] loss: 0.0000495\n",
      "Test set: Average loss: 2.3380, Accuracy: 3425/5000 (68%)\n",
      "[epoch 41] loss: 0.0000317\n",
      "Test set: Average loss: 2.4084, Accuracy: 3412/5000 (68%)\n",
      "[epoch 42] loss: 0.0000204\n",
      "Test set: Average loss: 2.4746, Accuracy: 3426/5000 (69%)\n",
      "[epoch 43] loss: 0.0000129\n",
      "Test set: Average loss: 2.5421, Accuracy: 3424/5000 (68%)\n",
      "[epoch 44] loss: 0.0000083\n",
      "Test set: Average loss: 2.6123, Accuracy: 3411/5000 (68%)\n",
      "[epoch 45] loss: 0.0000052\n",
      "Test set: Average loss: 2.6846, Accuracy: 3419/5000 (68%)\n",
      "[epoch 46] loss: 0.0000033\n",
      "Test set: Average loss: 2.7565, Accuracy: 3424/5000 (68%)\n",
      "[epoch 47] loss: 0.0000021\n",
      "Test set: Average loss: 2.8243, Accuracy: 3422/5000 (68%)\n",
      "[epoch 48] loss: 0.0000013\n",
      "Test set: Average loss: 2.8925, Accuracy: 3426/5000 (69%)\n",
      "[epoch 49] loss: 0.0000008\n",
      "Test set: Average loss: 2.9412, Accuracy: 3417/5000 (68%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 2.9716, Accuracy: 3414/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2702, Accuracy: 3428/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.1800, Accuracy: 6882/10000 (69%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3144, Accuracy: 120/5000 (2%)\n",
      "[epoch 1] loss: 1.1682733\n",
      "Test set: Average loss: 1.1139, Accuracy: 3047/5000 (61%)\n",
      "[epoch 2] loss: 1.0670697\n",
      "Test set: Average loss: 1.1033, Accuracy: 3052/5000 (61%)\n",
      "[epoch 3] loss: 1.0201849\n",
      "Test set: Average loss: 1.0884, Accuracy: 3069/5000 (61%)\n",
      "[epoch 4] loss: 0.9810146\n",
      "Test set: Average loss: 1.1060, Accuracy: 3018/5000 (60%)\n",
      "[epoch 5] loss: 0.9528957\n",
      "Test set: Average loss: 1.0566, Accuracy: 3159/5000 (63%)\n",
      "[epoch 6] loss: 0.9069691\n",
      "Test set: Average loss: 1.0610, Accuracy: 3133/5000 (63%)\n",
      "[epoch 7] loss: 0.8781661\n",
      "Test set: Average loss: 1.0125, Accuracy: 3271/5000 (65%)\n",
      "[epoch 8] loss: 0.8374292\n",
      "Test set: Average loss: 1.0417, Accuracy: 3256/5000 (65%)\n",
      "[epoch 9] loss: 0.7923637\n",
      "Test set: Average loss: 1.0071, Accuracy: 3284/5000 (66%)\n",
      "[epoch 10] loss: 0.7519521\n",
      "Test set: Average loss: 1.0261, Accuracy: 3273/5000 (65%)\n",
      "[epoch 11] loss: 0.7066162\n",
      "Test set: Average loss: 1.0561, Accuracy: 3233/5000 (65%)\n",
      "[epoch 12] loss: 0.6450246\n",
      "Test set: Average loss: 1.0359, Accuracy: 3306/5000 (66%)\n",
      "[epoch 13] loss: 0.5861044\n",
      "Test set: Average loss: 1.0397, Accuracy: 3359/5000 (67%)\n",
      "[epoch 14] loss: 0.5259507\n",
      "Test set: Average loss: 1.0785, Accuracy: 3303/5000 (66%)\n",
      "[epoch 15] loss: 0.4553606\n",
      "Test set: Average loss: 1.1442, Accuracy: 3294/5000 (66%)\n",
      "[epoch 16] loss: 0.3921148\n",
      "Test set: Average loss: 1.1909, Accuracy: 3319/5000 (66%)\n",
      "[epoch 17] loss: 0.3359581\n",
      "Test set: Average loss: 1.2606, Accuracy: 3320/5000 (66%)\n",
      "[epoch 18] loss: 0.2788468\n",
      "Test set: Average loss: 1.3199, Accuracy: 3285/5000 (66%)\n",
      "[epoch 19] loss: 0.2479354\n",
      "Test set: Average loss: 1.3769, Accuracy: 3253/5000 (65%)\n",
      "[epoch 20] loss: 0.2176103\n",
      "Test set: Average loss: 1.4441, Accuracy: 3276/5000 (66%)\n",
      "[epoch 21] loss: 0.2015461\n",
      "Test set: Average loss: 1.6004, Accuracy: 3273/5000 (65%)\n",
      "[epoch 22] loss: 0.1802248\n",
      "Test set: Average loss: 1.5292, Accuracy: 3290/5000 (66%)\n",
      "[epoch 23] loss: 0.1842087\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6412, Accuracy: 3271/5000 (65%)\n",
      "[epoch 24] loss: 0.0652421\n",
      "Test set: Average loss: 1.5188, Accuracy: 3357/5000 (67%)\n",
      "[epoch 25] loss: 0.0242517\n",
      "Test set: Average loss: 1.5377, Accuracy: 3369/5000 (67%)\n",
      "[epoch 26] loss: 0.0146100\n",
      "Test set: Average loss: 1.5612, Accuracy: 3377/5000 (68%)\n",
      "[epoch 27] loss: 0.0097032\n",
      "Test set: Average loss: 1.5819, Accuracy: 3391/5000 (68%)\n",
      "[epoch 28] loss: 0.0065811\n",
      "Test set: Average loss: 1.6216, Accuracy: 3379/5000 (68%)\n",
      "[epoch 29] loss: 0.0044703\n",
      "Test set: Average loss: 1.6653, Accuracy: 3383/5000 (68%)\n",
      "[epoch 30] loss: 0.0030120\n",
      "Test set: Average loss: 1.7005, Accuracy: 3402/5000 (68%)\n",
      "[epoch 31] loss: 0.0020096\n",
      "Test set: Average loss: 1.7514, Accuracy: 3417/5000 (68%)\n",
      "[epoch 32] loss: 0.0013286\n",
      "Test set: Average loss: 1.8016, Accuracy: 3418/5000 (68%)\n",
      "[epoch 33] loss: 0.0008678\n",
      "Test set: Average loss: 1.8540, Accuracy: 3417/5000 (68%)\n",
      "[epoch 34] loss: 0.0005633\n",
      "Test set: Average loss: 1.9063, Accuracy: 3432/5000 (69%)\n",
      "[epoch 35] loss: 0.0003640\n",
      "Test set: Average loss: 1.9673, Accuracy: 3439/5000 (69%)\n",
      "[epoch 36] loss: 0.0002335\n",
      "Test set: Average loss: 2.0248, Accuracy: 3429/5000 (69%)\n",
      "[epoch 37] loss: 0.0001481\n",
      "Test set: Average loss: 2.0892, Accuracy: 3430/5000 (69%)\n",
      "[epoch 38] loss: 0.0000932\n",
      "Test set: Average loss: 2.1586, Accuracy: 3424/5000 (68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39] loss: 0.0000586\n",
      "Test set: Average loss: 2.2233, Accuracy: 3445/5000 (69%)\n",
      "[epoch 40] loss: 0.0000366\n",
      "Test set: Average loss: 2.2947, Accuracy: 3439/5000 (69%)\n",
      "[epoch 41] loss: 0.0000227\n",
      "Test set: Average loss: 2.3684, Accuracy: 3431/5000 (69%)\n",
      "[epoch 42] loss: 0.0000141\n",
      "Test set: Average loss: 2.4333, Accuracy: 3430/5000 (69%)\n",
      "[epoch 43] loss: 0.0000086\n",
      "Test set: Average loss: 2.5076, Accuracy: 3446/5000 (69%)\n",
      "[epoch 44] loss: 0.0000053\n",
      "Test set: Average loss: 2.5849, Accuracy: 3435/5000 (69%)\n",
      "[epoch 45] loss: 0.0000032\n",
      "Test set: Average loss: 2.6487, Accuracy: 3433/5000 (69%)\n",
      "[epoch 46] loss: 0.0000019\n",
      "Test set: Average loss: 2.7176, Accuracy: 3426/5000 (69%)\n",
      "[epoch 47] loss: 0.0000012\n",
      "Test set: Average loss: 2.7837, Accuracy: 3432/5000 (69%)\n",
      "[epoch 48] loss: 0.0000007\n",
      "Test set: Average loss: 2.8280, Accuracy: 3422/5000 (68%)\n",
      "[epoch 49] loss: 0.0000004\n",
      "Test set: Average loss: 2.8454, Accuracy: 3422/5000 (68%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 2.8594, Accuracy: 3426/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5076, Accuracy: 3446/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.5002, Accuracy: 6955/10000 (70%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2838, Accuracy: 581/5000 (12%)\n",
      "[epoch 1] loss: 1.1746363\n",
      "Test set: Average loss: 1.1970, Accuracy: 2908/5000 (58%)\n",
      "[epoch 2] loss: 1.0673376\n",
      "Test set: Average loss: 1.0940, Accuracy: 3096/5000 (62%)\n",
      "[epoch 3] loss: 1.0320047\n",
      "Test set: Average loss: 1.0851, Accuracy: 3078/5000 (62%)\n",
      "[epoch 4] loss: 0.9878786\n",
      "Test set: Average loss: 1.0874, Accuracy: 3093/5000 (62%)\n",
      "[epoch 5] loss: 0.9539148\n",
      "Test set: Average loss: 1.0391, Accuracy: 3175/5000 (64%)\n",
      "[epoch 6] loss: 0.9201485\n",
      "Test set: Average loss: 1.0619, Accuracy: 3164/5000 (63%)\n",
      "[epoch 7] loss: 0.8763659\n",
      "Test set: Average loss: 1.0736, Accuracy: 3135/5000 (63%)\n",
      "[epoch 8] loss: 0.8418445\n",
      "Test set: Average loss: 1.0659, Accuracy: 3191/5000 (64%)\n",
      "[epoch 9] loss: 0.7965363\n",
      "Test set: Average loss: 1.0744, Accuracy: 3191/5000 (64%)\n",
      "[epoch 10] loss: 0.7663924\n",
      "Test set: Average loss: 0.9677, Accuracy: 3334/5000 (67%)\n",
      "[epoch 11] loss: 0.7111543\n",
      "Test set: Average loss: 1.0322, Accuracy: 3274/5000 (65%)\n",
      "[epoch 12] loss: 0.6561274\n",
      "Test set: Average loss: 1.0017, Accuracy: 3316/5000 (66%)\n",
      "[epoch 13] loss: 0.5891601\n",
      "Test set: Average loss: 1.0488, Accuracy: 3321/5000 (66%)\n",
      "[epoch 14] loss: 0.5260602\n",
      "Test set: Average loss: 1.1011, Accuracy: 3272/5000 (65%)\n",
      "[epoch 15] loss: 0.4653513\n",
      "Test set: Average loss: 1.1577, Accuracy: 3258/5000 (65%)\n",
      "[epoch 16] loss: 0.3878405\n",
      "Test set: Average loss: 1.1712, Accuracy: 3305/5000 (66%)\n",
      "[epoch 17] loss: 0.3216189\n",
      "Test set: Average loss: 1.2891, Accuracy: 3257/5000 (65%)\n",
      "[epoch 18] loss: 0.2791187\n",
      "Test set: Average loss: 1.3471, Accuracy: 3266/5000 (65%)\n",
      "[epoch 19] loss: 0.2445183\n",
      "Test set: Average loss: 1.3740, Accuracy: 3293/5000 (66%)\n",
      "[epoch 20] loss: 0.2123117\n",
      "Test set: Average loss: 1.3970, Accuracy: 3331/5000 (67%)\n",
      "[epoch 21] loss: 0.1843070\n",
      "Test set: Average loss: 1.5027, Accuracy: 3253/5000 (65%)\n",
      "[epoch 22] loss: 0.1884594\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5652, Accuracy: 3262/5000 (65%)\n",
      "[epoch 23] loss: 0.0644153\n",
      "Test set: Average loss: 1.4578, Accuracy: 3364/5000 (67%)\n",
      "[epoch 24] loss: 0.0259979\n",
      "Test set: Average loss: 1.4816, Accuracy: 3392/5000 (68%)\n",
      "[epoch 25] loss: 0.0156986\n",
      "Test set: Average loss: 1.5039, Accuracy: 3395/5000 (68%)\n",
      "[epoch 26] loss: 0.0104364\n",
      "Test set: Average loss: 1.5415, Accuracy: 3400/5000 (68%)\n",
      "[epoch 27] loss: 0.0071242\n",
      "Test set: Average loss: 1.5667, Accuracy: 3390/5000 (68%)\n",
      "[epoch 28] loss: 0.0048333\n",
      "Test set: Average loss: 1.6188, Accuracy: 3393/5000 (68%)\n",
      "[epoch 29] loss: 0.0032423\n",
      "Test set: Average loss: 1.6613, Accuracy: 3382/5000 (68%)\n",
      "[epoch 30] loss: 0.0022000\n",
      "Test set: Average loss: 1.7087, Accuracy: 3387/5000 (68%)\n",
      "[epoch 31] loss: 0.0014302\n",
      "Test set: Average loss: 1.7603, Accuracy: 3394/5000 (68%)\n",
      "[epoch 32] loss: 0.0009341\n",
      "Test set: Average loss: 1.8134, Accuracy: 3397/5000 (68%)\n",
      "[epoch 33] loss: 0.0006104\n",
      "Test set: Average loss: 1.8822, Accuracy: 3395/5000 (68%)\n",
      "[epoch 34] loss: 0.0003950\n",
      "Test set: Average loss: 1.9438, Accuracy: 3399/5000 (68%)\n",
      "[epoch 35] loss: 0.0002515\n",
      "Test set: Average loss: 2.0081, Accuracy: 3397/5000 (68%)\n",
      "[epoch 36] loss: 0.0001596\n",
      "Test set: Average loss: 2.0683, Accuracy: 3409/5000 (68%)\n",
      "[epoch 37] loss: 0.0001015\n",
      "Test set: Average loss: 2.1416, Accuracy: 3415/5000 (68%)\n",
      "[epoch 38] loss: 0.0000637\n",
      "Test set: Average loss: 2.2024, Accuracy: 3404/5000 (68%)\n",
      "[epoch 39] loss: 0.0000399\n",
      "Test set: Average loss: 2.2773, Accuracy: 3404/5000 (68%)\n",
      "[epoch 40] loss: 0.0000247\n",
      "Test set: Average loss: 2.3385, Accuracy: 3416/5000 (68%)\n",
      "[epoch 41] loss: 0.0000152\n",
      "Test set: Average loss: 2.4098, Accuracy: 3422/5000 (68%)\n",
      "[epoch 42] loss: 0.0000094\n",
      "Test set: Average loss: 2.4889, Accuracy: 3414/5000 (68%)\n",
      "[epoch 43] loss: 0.0000058\n",
      "Test set: Average loss: 2.5682, Accuracy: 3408/5000 (68%)\n",
      "[epoch 44] loss: 0.0000035\n",
      "Test set: Average loss: 2.6350, Accuracy: 3412/5000 (68%)\n",
      "[epoch 45] loss: 0.0000021\n",
      "Test set: Average loss: 2.7105, Accuracy: 3402/5000 (68%)\n",
      "[epoch 46] loss: 0.0000013\n",
      "Test set: Average loss: 2.7783, Accuracy: 3402/5000 (68%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 2.8207, Accuracy: 3400/5000 (68%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 2.8647, Accuracy: 3409/5000 (68%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 2.8805, Accuracy: 3388/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.8932, Accuracy: 3404/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4098, Accuracy: 3422/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.3461, Accuracy: 6983/10000 (70%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3006, Accuracy: 504/5000 (10%)\n",
      "[epoch 1] loss: 1.1673206\n",
      "Test set: Average loss: 1.0880, Accuracy: 3087/5000 (62%)\n",
      "[epoch 2] loss: 1.0680244\n",
      "Test set: Average loss: 1.0999, Accuracy: 3076/5000 (62%)\n",
      "[epoch 3] loss: 1.0287113\n",
      "Test set: Average loss: 1.0606, Accuracy: 3103/5000 (62%)\n",
      "[epoch 4] loss: 0.9878896\n",
      "Test set: Average loss: 1.1556, Accuracy: 3032/5000 (61%)\n",
      "[epoch 5] loss: 0.9524324\n",
      "Test set: Average loss: 1.0439, Accuracy: 3160/5000 (63%)\n",
      "[epoch 6] loss: 0.9156585\n",
      "Test set: Average loss: 1.0162, Accuracy: 3253/5000 (65%)\n",
      "[epoch 7] loss: 0.8763462\n",
      "Test set: Average loss: 1.0597, Accuracy: 3152/5000 (63%)\n",
      "[epoch 8] loss: 0.8365987\n",
      "Test set: Average loss: 1.0086, Accuracy: 3248/5000 (65%)\n",
      "[epoch 9] loss: 0.7954983\n",
      "Test set: Average loss: 1.0480, Accuracy: 3201/5000 (64%)\n",
      "[epoch 10] loss: 0.7548354\n",
      "Test set: Average loss: 1.0425, Accuracy: 3231/5000 (65%)\n",
      "[epoch 11] loss: 0.7065764\n",
      "Test set: Average loss: 1.0191, Accuracy: 3330/5000 (67%)\n",
      "[epoch 12] loss: 0.6530527\n",
      "Test set: Average loss: 1.0791, Accuracy: 3278/5000 (66%)\n",
      "[epoch 13] loss: 0.5880512\n",
      "Test set: Average loss: 1.0070, Accuracy: 3372/5000 (67%)\n",
      "[epoch 14] loss: 0.5190345\n",
      "Test set: Average loss: 1.0949, Accuracy: 3311/5000 (66%)\n",
      "[epoch 15] loss: 0.4546339\n",
      "Test set: Average loss: 1.1386, Accuracy: 3340/5000 (67%)\n",
      "[epoch 16] loss: 0.3939844\n",
      "Test set: Average loss: 1.1807, Accuracy: 3326/5000 (67%)\n",
      "[epoch 17] loss: 0.3306263\n",
      "Test set: Average loss: 1.2454, Accuracy: 3334/5000 (67%)\n",
      "[epoch 18] loss: 0.2780371\n",
      "Test set: Average loss: 1.3084, Accuracy: 3282/5000 (66%)\n",
      "[epoch 19] loss: 0.2358527\n",
      "Test set: Average loss: 1.4440, Accuracy: 3284/5000 (66%)\n",
      "[epoch 20] loss: 0.2182647\n",
      "Test set: Average loss: 1.4687, Accuracy: 3264/5000 (65%)\n",
      "[epoch 21] loss: 0.1830915\n",
      "Test set: Average loss: 1.6288, Accuracy: 3207/5000 (64%)\n",
      "[epoch 22] loss: 0.1935965\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6391, Accuracy: 3279/5000 (66%)\n",
      "[epoch 23] loss: 0.0662958\n",
      "Test set: Average loss: 1.5082, Accuracy: 3371/5000 (67%)\n",
      "[epoch 24] loss: 0.0265380\n",
      "Test set: Average loss: 1.5280, Accuracy: 3378/5000 (68%)\n",
      "[epoch 25] loss: 0.0160024\n",
      "Test set: Average loss: 1.5460, Accuracy: 3384/5000 (68%)\n",
      "[epoch 26] loss: 0.0105208\n",
      "Test set: Average loss: 1.5827, Accuracy: 3405/5000 (68%)\n",
      "[epoch 27] loss: 0.0071498\n",
      "Test set: Average loss: 1.6141, Accuracy: 3432/5000 (69%)\n",
      "[epoch 28] loss: 0.0048895\n",
      "Test set: Average loss: 1.6524, Accuracy: 3419/5000 (68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] loss: 0.0032838\n",
      "Test set: Average loss: 1.7049, Accuracy: 3425/5000 (68%)\n",
      "[epoch 30] loss: 0.0021774\n",
      "Test set: Average loss: 1.7577, Accuracy: 3435/5000 (69%)\n",
      "[epoch 31] loss: 0.0014561\n",
      "Test set: Average loss: 1.8089, Accuracy: 3440/5000 (69%)\n",
      "[epoch 32] loss: 0.0009447\n",
      "Test set: Average loss: 1.8710, Accuracy: 3426/5000 (69%)\n",
      "[epoch 33] loss: 0.0006175\n",
      "Test set: Average loss: 1.9315, Accuracy: 3421/5000 (68%)\n",
      "[epoch 34] loss: 0.0003979\n",
      "Test set: Average loss: 1.9963, Accuracy: 3424/5000 (68%)\n",
      "[epoch 35] loss: 0.0002545\n",
      "Test set: Average loss: 2.0720, Accuracy: 3429/5000 (69%)\n",
      "[epoch 36] loss: 0.0001617\n",
      "Test set: Average loss: 2.1366, Accuracy: 3426/5000 (69%)\n",
      "[epoch 37] loss: 0.0001024\n",
      "Test set: Average loss: 2.2088, Accuracy: 3426/5000 (69%)\n",
      "[epoch 38] loss: 0.0000643\n",
      "Test set: Average loss: 2.2785, Accuracy: 3430/5000 (69%)\n",
      "[epoch 39] loss: 0.0000404\n",
      "Test set: Average loss: 2.3514, Accuracy: 3421/5000 (68%)\n",
      "[epoch 40] loss: 0.0000248\n",
      "Test set: Average loss: 2.4308, Accuracy: 3439/5000 (69%)\n",
      "[epoch 41] loss: 0.0000155\n",
      "Test set: Average loss: 2.5060, Accuracy: 3447/5000 (69%)\n",
      "[epoch 42] loss: 0.0000095\n",
      "Test set: Average loss: 2.5791, Accuracy: 3441/5000 (69%)\n",
      "[epoch 43] loss: 0.0000058\n",
      "Test set: Average loss: 2.6662, Accuracy: 3447/5000 (69%)\n",
      "[epoch 44] loss: 0.0000036\n",
      "Test set: Average loss: 2.7397, Accuracy: 3434/5000 (69%)\n",
      "[epoch 45] loss: 0.0000022\n",
      "Test set: Average loss: 2.8099, Accuracy: 3441/5000 (69%)\n",
      "[epoch 46] loss: 0.0000013\n",
      "Test set: Average loss: 2.8873, Accuracy: 3442/5000 (69%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 2.9364, Accuracy: 3446/5000 (69%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 2.9667, Accuracy: 3432/5000 (69%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 2.9952, Accuracy: 3428/5000 (69%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0012, Accuracy: 3440/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6662, Accuracy: 3447/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.5025, Accuracy: 6961/10000 (70%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3226, Accuracy: 222/5000 (4%)\n",
      "[epoch 1] loss: 1.1544424\n",
      "Test set: Average loss: 1.1245, Accuracy: 3022/5000 (60%)\n",
      "[epoch 2] loss: 1.0640608\n",
      "Test set: Average loss: 1.0722, Accuracy: 3105/5000 (62%)\n",
      "[epoch 3] loss: 1.0210709\n",
      "Test set: Average loss: 1.0796, Accuracy: 3148/5000 (63%)\n",
      "[epoch 4] loss: 0.9803352\n",
      "Test set: Average loss: 1.1037, Accuracy: 3085/5000 (62%)\n",
      "[epoch 5] loss: 0.9424651\n",
      "Test set: Average loss: 1.0579, Accuracy: 3142/5000 (63%)\n",
      "[epoch 6] loss: 0.9016145\n",
      "Test set: Average loss: 0.9969, Accuracy: 3260/5000 (65%)\n",
      "[epoch 7] loss: 0.8682224\n",
      "Test set: Average loss: 0.9882, Accuracy: 3269/5000 (65%)\n",
      "[epoch 8] loss: 0.8290680\n",
      "Test set: Average loss: 1.0235, Accuracy: 3247/5000 (65%)\n",
      "[epoch 9] loss: 0.7848594\n",
      "Test set: Average loss: 0.9799, Accuracy: 3303/5000 (66%)\n",
      "[epoch 10] loss: 0.7363199\n",
      "Test set: Average loss: 1.0032, Accuracy: 3300/5000 (66%)\n",
      "[epoch 11] loss: 0.6862768\n",
      "Test set: Average loss: 0.9953, Accuracy: 3406/5000 (68%)\n",
      "[epoch 12] loss: 0.6318433\n",
      "Test set: Average loss: 0.9958, Accuracy: 3407/5000 (68%)\n",
      "[epoch 13] loss: 0.5799090\n",
      "Test set: Average loss: 1.0232, Accuracy: 3361/5000 (67%)\n",
      "[epoch 14] loss: 0.5093239\n",
      "Test set: Average loss: 1.0509, Accuracy: 3346/5000 (67%)\n",
      "[epoch 15] loss: 0.4592033\n",
      "Test set: Average loss: 1.0849, Accuracy: 3365/5000 (67%)\n",
      "[epoch 16] loss: 0.3871075\n",
      "Test set: Average loss: 1.2998, Accuracy: 3220/5000 (64%)\n",
      "[epoch 17] loss: 0.3378946\n",
      "Test set: Average loss: 1.2318, Accuracy: 3324/5000 (66%)\n",
      "[epoch 18] loss: 0.2932326\n",
      "Test set: Average loss: 1.2558, Accuracy: 3338/5000 (67%)\n",
      "[epoch 19] loss: 0.2563213\n",
      "Test set: Average loss: 1.3640, Accuracy: 3321/5000 (66%)\n",
      "[epoch 20] loss: 0.2404898\n",
      "Test set: Average loss: 1.4367, Accuracy: 3282/5000 (66%)\n",
      "[epoch 21] loss: 0.2061942\n",
      "Test set: Average loss: 1.5058, Accuracy: 3226/5000 (65%)\n",
      "[epoch 22] loss: 0.2157786\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5415, Accuracy: 3266/5000 (65%)\n",
      "[epoch 23] loss: 0.0777667\n",
      "Test set: Average loss: 1.4148, Accuracy: 3398/5000 (68%)\n",
      "[epoch 24] loss: 0.0318240\n",
      "Test set: Average loss: 1.4364, Accuracy: 3416/5000 (68%)\n",
      "[epoch 25] loss: 0.0189427\n",
      "Test set: Average loss: 1.4490, Accuracy: 3426/5000 (69%)\n",
      "[epoch 26] loss: 0.0122859\n",
      "Test set: Average loss: 1.4763, Accuracy: 3453/5000 (69%)\n",
      "[epoch 27] loss: 0.0081125\n",
      "Test set: Average loss: 1.5187, Accuracy: 3453/5000 (69%)\n",
      "[epoch 28] loss: 0.0053410\n",
      "Test set: Average loss: 1.5581, Accuracy: 3449/5000 (69%)\n",
      "[epoch 29] loss: 0.0034799\n",
      "Test set: Average loss: 1.6058, Accuracy: 3444/5000 (69%)\n",
      "[epoch 30] loss: 0.0022645\n",
      "Test set: Average loss: 1.6668, Accuracy: 3444/5000 (69%)\n",
      "[epoch 31] loss: 0.0014463\n",
      "Test set: Average loss: 1.7171, Accuracy: 3453/5000 (69%)\n",
      "[epoch 32] loss: 0.0009189\n",
      "Test set: Average loss: 1.7822, Accuracy: 3455/5000 (69%)\n",
      "[epoch 33] loss: 0.0005799\n",
      "Test set: Average loss: 1.8369, Accuracy: 3464/5000 (69%)\n",
      "[epoch 34] loss: 0.0003618\n",
      "Test set: Average loss: 1.9132, Accuracy: 3461/5000 (69%)\n",
      "[epoch 35] loss: 0.0002233\n",
      "Test set: Average loss: 1.9810, Accuracy: 3458/5000 (69%)\n",
      "[epoch 36] loss: 0.0001385\n",
      "Test set: Average loss: 2.0475, Accuracy: 3459/5000 (69%)\n",
      "[epoch 37] loss: 0.0000840\n",
      "Test set: Average loss: 2.1197, Accuracy: 3462/5000 (69%)\n",
      "[epoch 38] loss: 0.0000509\n",
      "Test set: Average loss: 2.2072, Accuracy: 3464/5000 (69%)\n",
      "[epoch 39] loss: 0.0000309\n",
      "Test set: Average loss: 2.2752, Accuracy: 3453/5000 (69%)\n",
      "[epoch 40] loss: 0.0000184\n",
      "Test set: Average loss: 2.3555, Accuracy: 3468/5000 (69%)\n",
      "[epoch 41] loss: 0.0000111\n",
      "Test set: Average loss: 2.4353, Accuracy: 3458/5000 (69%)\n",
      "[epoch 42] loss: 0.0000065\n",
      "Test set: Average loss: 2.5190, Accuracy: 3469/5000 (69%)\n",
      "[epoch 43] loss: 0.0000039\n",
      "Test set: Average loss: 2.5916, Accuracy: 3464/5000 (69%)\n",
      "[epoch 44] loss: 0.0000022\n",
      "Test set: Average loss: 2.6616, Accuracy: 3448/5000 (69%)\n",
      "[epoch 45] loss: 0.0000013\n",
      "Test set: Average loss: 2.7309, Accuracy: 3448/5000 (69%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Test set: Average loss: 2.7848, Accuracy: 3457/5000 (69%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 2.8314, Accuracy: 3454/5000 (69%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 2.8501, Accuracy: 3445/5000 (69%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.8654, Accuracy: 3446/5000 (69%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.8922, Accuracy: 3448/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5190, Accuracy: 3469/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.4338, Accuracy: 7080/10000 (71%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2817, Accuracy: 679/5000 (14%)\n",
      "[epoch 1] loss: 1.1546932\n",
      "Test set: Average loss: 1.0839, Accuracy: 3079/5000 (62%)\n",
      "[epoch 2] loss: 1.0630398\n",
      "Test set: Average loss: 1.1647, Accuracy: 2971/5000 (59%)\n",
      "[epoch 3] loss: 1.0136248\n",
      "Test set: Average loss: 1.1352, Accuracy: 3031/5000 (61%)\n",
      "[epoch 4] loss: 0.9776970\n",
      "Test set: Average loss: 1.0360, Accuracy: 3167/5000 (63%)\n",
      "[epoch 5] loss: 0.9429777\n",
      "Test set: Average loss: 1.0692, Accuracy: 3151/5000 (63%)\n",
      "[epoch 6] loss: 0.9040061\n",
      "Test set: Average loss: 1.0066, Accuracy: 3241/5000 (65%)\n",
      "[epoch 7] loss: 0.8716620\n",
      "Test set: Average loss: 0.9686, Accuracy: 3303/5000 (66%)\n",
      "[epoch 8] loss: 0.8320404\n",
      "Test set: Average loss: 1.0193, Accuracy: 3239/5000 (65%)\n",
      "[epoch 9] loss: 0.7862351\n",
      "Test set: Average loss: 1.0495, Accuracy: 3244/5000 (65%)\n",
      "[epoch 10] loss: 0.7418090\n",
      "Test set: Average loss: 0.9958, Accuracy: 3291/5000 (66%)\n",
      "[epoch 11] loss: 0.6905084\n",
      "Test set: Average loss: 1.0083, Accuracy: 3319/5000 (66%)\n",
      "[epoch 12] loss: 0.6332037\n",
      "Test set: Average loss: 1.0438, Accuracy: 3287/5000 (66%)\n",
      "[epoch 13] loss: 0.5763568\n",
      "Test set: Average loss: 0.9920, Accuracy: 3406/5000 (68%)\n",
      "[epoch 14] loss: 0.5127629\n",
      "Test set: Average loss: 1.0607, Accuracy: 3386/5000 (68%)\n",
      "[epoch 15] loss: 0.4535594\n",
      "Test set: Average loss: 1.1086, Accuracy: 3343/5000 (67%)\n",
      "[epoch 16] loss: 0.3950472\n",
      "Test set: Average loss: 1.2167, Accuracy: 3316/5000 (66%)\n",
      "[epoch 17] loss: 0.3410465\n",
      "Test set: Average loss: 1.2692, Accuracy: 3329/5000 (67%)\n",
      "[epoch 18] loss: 0.2983572\n",
      "Test set: Average loss: 1.2278, Accuracy: 3340/5000 (67%)\n",
      "[epoch 19] loss: 0.2612710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3810, Accuracy: 3279/5000 (66%)\n",
      "[epoch 20] loss: 0.2319540\n",
      "Test set: Average loss: 1.4674, Accuracy: 3256/5000 (65%)\n",
      "[epoch 21] loss: 0.2166144\n",
      "Test set: Average loss: 1.4324, Accuracy: 3293/5000 (66%)\n",
      "[epoch 22] loss: 0.2180239\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6011, Accuracy: 3296/5000 (66%)\n",
      "[epoch 23] loss: 0.0810489\n",
      "Test set: Average loss: 1.4503, Accuracy: 3415/5000 (68%)\n",
      "[epoch 24] loss: 0.0336200\n",
      "Test set: Average loss: 1.4706, Accuracy: 3417/5000 (68%)\n",
      "[epoch 25] loss: 0.0200033\n",
      "Test set: Average loss: 1.5008, Accuracy: 3422/5000 (68%)\n",
      "[epoch 26] loss: 0.0130380\n",
      "Test set: Average loss: 1.5322, Accuracy: 3411/5000 (68%)\n",
      "[epoch 27] loss: 0.0084933\n",
      "Test set: Average loss: 1.5625, Accuracy: 3424/5000 (68%)\n",
      "[epoch 28] loss: 0.0057385\n",
      "Test set: Average loss: 1.6082, Accuracy: 3441/5000 (69%)\n",
      "[epoch 29] loss: 0.0036987\n",
      "Test set: Average loss: 1.6595, Accuracy: 3438/5000 (69%)\n",
      "[epoch 30] loss: 0.0024432\n",
      "Test set: Average loss: 1.7152, Accuracy: 3435/5000 (69%)\n",
      "[epoch 31] loss: 0.0015612\n",
      "Test set: Average loss: 1.7839, Accuracy: 3455/5000 (69%)\n",
      "[epoch 32] loss: 0.0010038\n",
      "Test set: Average loss: 1.8321, Accuracy: 3453/5000 (69%)\n",
      "[epoch 33] loss: 0.0006373\n",
      "Test set: Average loss: 1.9051, Accuracy: 3443/5000 (69%)\n",
      "[epoch 34] loss: 0.0003960\n",
      "Test set: Average loss: 1.9770, Accuracy: 3437/5000 (69%)\n",
      "[epoch 35] loss: 0.0002482\n",
      "Test set: Average loss: 2.0388, Accuracy: 3447/5000 (69%)\n",
      "[epoch 36] loss: 0.0001534\n",
      "Test set: Average loss: 2.1227, Accuracy: 3446/5000 (69%)\n",
      "[epoch 37] loss: 0.0000942\n",
      "Test set: Average loss: 2.1905, Accuracy: 3453/5000 (69%)\n",
      "[epoch 38] loss: 0.0000575\n",
      "Test set: Average loss: 2.2701, Accuracy: 3448/5000 (69%)\n",
      "[epoch 39] loss: 0.0000346\n",
      "Test set: Average loss: 2.3461, Accuracy: 3454/5000 (69%)\n",
      "[epoch 40] loss: 0.0000209\n",
      "Test set: Average loss: 2.4306, Accuracy: 3443/5000 (69%)\n",
      "[epoch 41] loss: 0.0000125\n",
      "Test set: Average loss: 2.5048, Accuracy: 3430/5000 (69%)\n",
      "[epoch 42] loss: 0.0000075\n",
      "Test set: Average loss: 2.6019, Accuracy: 3432/5000 (69%)\n",
      "[epoch 43] loss: 0.0000045\n",
      "Test set: Average loss: 2.6718, Accuracy: 3439/5000 (69%)\n",
      "[epoch 44] loss: 0.0000026\n",
      "Test set: Average loss: 2.7546, Accuracy: 3447/5000 (69%)\n",
      "[epoch 45] loss: 0.0000015\n",
      "Test set: Average loss: 2.8211, Accuracy: 3432/5000 (69%)\n",
      "[epoch 46] loss: 0.0000009\n",
      "Test set: Average loss: 2.8857, Accuracy: 3438/5000 (69%)\n",
      "[epoch 47] loss: 0.0000005\n",
      "Test set: Average loss: 2.9361, Accuracy: 3424/5000 (68%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 2.9569, Accuracy: 3420/5000 (68%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.9708, Accuracy: 3429/5000 (69%)\n",
      "[epoch 50] loss: 0.0008282\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9424, Accuracy: 3419/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7839, Accuracy: 3455/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 1.6548, Accuracy: 7000/10000 (70%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2917, Accuracy: 619/5000 (12%)\n",
      "[epoch 1] loss: 1.1611231\n",
      "Test set: Average loss: 1.1768, Accuracy: 2939/5000 (59%)\n",
      "[epoch 2] loss: 1.0641503\n",
      "Test set: Average loss: 1.0947, Accuracy: 3054/5000 (61%)\n",
      "[epoch 3] loss: 1.0145134\n",
      "Test set: Average loss: 1.0548, Accuracy: 3172/5000 (63%)\n",
      "[epoch 4] loss: 0.9782492\n",
      "Test set: Average loss: 1.0466, Accuracy: 3138/5000 (63%)\n",
      "[epoch 5] loss: 0.9382631\n",
      "Test set: Average loss: 1.0439, Accuracy: 3226/5000 (65%)\n",
      "[epoch 6] loss: 0.9069179\n",
      "Test set: Average loss: 1.0156, Accuracy: 3241/5000 (65%)\n",
      "[epoch 7] loss: 0.8608357\n",
      "Test set: Average loss: 1.0060, Accuracy: 3311/5000 (66%)\n",
      "[epoch 8] loss: 0.8206071\n",
      "Test set: Average loss: 0.9530, Accuracy: 3350/5000 (67%)\n",
      "[epoch 9] loss: 0.7828707\n",
      "Test set: Average loss: 0.9859, Accuracy: 3290/5000 (66%)\n",
      "[epoch 10] loss: 0.7341552\n",
      "Test set: Average loss: 1.0201, Accuracy: 3270/5000 (65%)\n",
      "[epoch 11] loss: 0.6851401\n",
      "Test set: Average loss: 1.0089, Accuracy: 3319/5000 (66%)\n",
      "[epoch 12] loss: 0.6214938\n",
      "Test set: Average loss: 1.0329, Accuracy: 3329/5000 (67%)\n",
      "[epoch 13] loss: 0.5580723\n",
      "Test set: Average loss: 1.0813, Accuracy: 3329/5000 (67%)\n",
      "[epoch 14] loss: 0.4987130\n",
      "Test set: Average loss: 1.0977, Accuracy: 3320/5000 (66%)\n",
      "[epoch 15] loss: 0.4358698\n",
      "Test set: Average loss: 1.1399, Accuracy: 3301/5000 (66%)\n",
      "[epoch 16] loss: 0.3825125\n",
      "Test set: Average loss: 1.2257, Accuracy: 3316/5000 (66%)\n",
      "[epoch 17] loss: 0.3265501\n",
      "Test set: Average loss: 1.2510, Accuracy: 3305/5000 (66%)\n",
      "[epoch 18] loss: 0.2953863\n",
      "Test set: Average loss: 1.3279, Accuracy: 3295/5000 (66%)\n",
      "[epoch 19] loss: 0.2566438\n",
      "Test set: Average loss: 1.3641, Accuracy: 3356/5000 (67%)\n",
      "[epoch 20] loss: 0.2272823\n",
      "Test set: Average loss: 1.4479, Accuracy: 3267/5000 (65%)\n",
      "[epoch 21] loss: 0.2226782\n",
      "Test set: Average loss: 1.4887, Accuracy: 3287/5000 (66%)\n",
      "[epoch 22] loss: 0.1950292\n",
      "Test set: Average loss: 1.5811, Accuracy: 3281/5000 (66%)\n",
      "[epoch 23] loss: 0.1928672\n",
      "Test set: Average loss: 1.5911, Accuracy: 3292/5000 (66%)\n",
      "[epoch 24] loss: 0.1839904\n",
      "Test set: Average loss: 1.6805, Accuracy: 3264/5000 (65%)\n",
      "[epoch 25] loss: 0.1860870\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7105, Accuracy: 3258/5000 (65%)\n",
      "[epoch 26] loss: 0.0635827\n",
      "Test set: Average loss: 1.5778, Accuracy: 3373/5000 (67%)\n",
      "[epoch 27] loss: 0.0230271\n",
      "Test set: Average loss: 1.5985, Accuracy: 3393/5000 (68%)\n",
      "[epoch 28] loss: 0.0127918\n",
      "Test set: Average loss: 1.6199, Accuracy: 3410/5000 (68%)\n",
      "[epoch 29] loss: 0.0082172\n",
      "Test set: Average loss: 1.6506, Accuracy: 3414/5000 (68%)\n",
      "[epoch 30] loss: 0.0052881\n",
      "Test set: Average loss: 1.6846, Accuracy: 3419/5000 (68%)\n",
      "[epoch 31] loss: 0.0034671\n",
      "Test set: Average loss: 1.7339, Accuracy: 3427/5000 (69%)\n",
      "[epoch 32] loss: 0.0022104\n",
      "Test set: Average loss: 1.7803, Accuracy: 3438/5000 (69%)\n",
      "[epoch 33] loss: 0.0014100\n",
      "Test set: Average loss: 1.8263, Accuracy: 3447/5000 (69%)\n",
      "[epoch 34] loss: 0.0008835\n",
      "Test set: Average loss: 1.8817, Accuracy: 3446/5000 (69%)\n",
      "[epoch 35] loss: 0.0005533\n",
      "Test set: Average loss: 1.9405, Accuracy: 3457/5000 (69%)\n",
      "[epoch 36] loss: 0.0003415\n",
      "Test set: Average loss: 2.0079, Accuracy: 3455/5000 (69%)\n",
      "[epoch 37] loss: 0.0002083\n",
      "Test set: Average loss: 2.0758, Accuracy: 3446/5000 (69%)\n",
      "[epoch 38] loss: 0.0001275\n",
      "Test set: Average loss: 2.1376, Accuracy: 3467/5000 (69%)\n",
      "[epoch 39] loss: 0.0000773\n",
      "Test set: Average loss: 2.2117, Accuracy: 3466/5000 (69%)\n",
      "[epoch 40] loss: 0.0000464\n",
      "Test set: Average loss: 2.2901, Accuracy: 3463/5000 (69%)\n",
      "[epoch 41] loss: 0.0000280\n",
      "Test set: Average loss: 2.3575, Accuracy: 3459/5000 (69%)\n",
      "[epoch 42] loss: 0.0000166\n",
      "Test set: Average loss: 2.4433, Accuracy: 3463/5000 (69%)\n",
      "[epoch 43] loss: 0.0000098\n",
      "Test set: Average loss: 2.5063, Accuracy: 3453/5000 (69%)\n",
      "[epoch 44] loss: 0.0000059\n",
      "Test set: Average loss: 2.5884, Accuracy: 3462/5000 (69%)\n",
      "[epoch 45] loss: 0.0000033\n",
      "Test set: Average loss: 2.6698, Accuracy: 3460/5000 (69%)\n",
      "[epoch 46] loss: 0.0000020\n",
      "Test set: Average loss: 2.7354, Accuracy: 3462/5000 (69%)\n",
      "[epoch 47] loss: 0.0000011\n",
      "Test set: Average loss: 2.8130, Accuracy: 3454/5000 (69%)\n",
      "[epoch 48] loss: 0.0000006\n",
      "Test set: Average loss: 2.8598, Accuracy: 3445/5000 (69%)\n",
      "[epoch 49] loss: 0.0000004\n",
      "Test set: Average loss: 2.8930, Accuracy: 3439/5000 (69%)\n",
      "[epoch 50] loss: 0.0000003\n",
      "Test set: Average loss: 2.9041, Accuracy: 3447/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1376, Accuracy: 3467/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.0693, Accuracy: 7007/10000 (70%)\n"
     ]
    }
   ],
   "source": [
    "# train the SimEc\n",
    "w = 0.5\n",
    "S = w*S_lin + (1.-w)*S_class\n",
    "S_ll = S[:n_targets, :]\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = SimilarityEncoder(cnn, 512, n_targets)\n",
    "model.fit(X, S, epochs=50, lr=0.0001, s_ll_reg=100., S_ll=S_ll, orth_reg=0.1)\n",
    "print(check_similarity_match(model.predict(X[:n_targets]), S_ll, X_embed_is_S_approx=True))\n",
    "print(check_similarity_match(model.transform(X[:n_targets]), S_ll))\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.model.embedding_net.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_se_t1_mix5 = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_se_t1_mix5.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T23:59:53.594772Z",
     "start_time": "2019-07-24T21:04:58.333718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.0103360\n",
      "[epoch 2] loss: 0.0067707\n",
      "[epoch 3] loss: 0.0063620\n",
      "[epoch 4] loss: 0.0061616\n",
      "[epoch 5] loss: 0.0060465\n",
      "[epoch 6] loss: 0.0059630\n",
      "[epoch 7] loss: 0.0059066\n",
      "[epoch 8] loss: 0.0058611\n",
      "[epoch 9] loss: 0.0058208\n",
      "[epoch 10] loss: 0.0057794\n",
      "[epoch 11] loss: 0.0057469\n",
      "[epoch 12] loss: 0.0057210\n",
      "[epoch 13] loss: 0.0056944\n",
      "[epoch 14] loss: 0.0056668\n",
      "[epoch 15] loss: 0.0056407\n",
      "[epoch 16] loss: 0.0056166\n",
      "[epoch 17] loss: 0.0055997\n",
      "[epoch 18] loss: 0.0055890\n",
      "[epoch 19] loss: 0.0056346\n",
      "[epoch 20] loss: 0.0055563\n",
      "[epoch 21] loss: 0.0055257\n",
      "[epoch 22] loss: 0.0055018\n",
      "[epoch 23] loss: 0.0054815\n",
      "[epoch 24] loss: 0.0054630\n",
      "[epoch 25] loss: 0.0054495\n",
      "[epoch 26] loss: 0.0054373\n",
      "[epoch 27] loss: 0.0054262\n",
      "[epoch 28] loss: 0.0054173\n",
      "[epoch 29] loss: 0.0054056\n",
      "[epoch 30] loss: 0.0053994\n",
      "[epoch 31] loss: 0.0053888\n",
      "[epoch 32] loss: 0.0053791\n",
      "[epoch 33] loss: 0.0053698\n",
      "[epoch 34] loss: 0.0053628\n",
      "[epoch 35] loss: 0.0053548\n",
      "[epoch 36] loss: 0.0053539\n",
      "[epoch 37] loss: 0.0053410\n",
      "[epoch 38] loss: 0.0053394\n",
      "[epoch 39] loss: 0.0053320\n",
      "[epoch 40] loss: 0.0053242\n",
      "[epoch 41] loss: 0.0053182\n",
      "[epoch 42] loss: 0.0053132\n",
      "[epoch 43] loss: 0.0053112\n",
      "[epoch 44] loss: 0.0053058\n",
      "[epoch 45] loss: 0.0052970\n",
      "[epoch 46] loss: 0.0052971\n",
      "[epoch 47] loss: 0.0052914\n",
      "[epoch 48] loss: 0.0052858\n",
      "[epoch 49] loss: 0.0052805\n",
      "[epoch 50] loss: 0.0052771\n",
      "(0.005252798738865568, 0.45366755096456496, 0.6795726917255167)\n",
      "(0.007475174965735936, 0.25927413328123944, 0.6235065908121007)\n",
      "Took 908 sec to train.\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 407/5000 (8%)\n",
      "[epoch 1] loss: 2.3049459\n",
      "Test set: Average loss: 2.2727, Accuracy: 755/5000 (15%)\n",
      "[epoch 2] loss: 2.1786909\n",
      "Test set: Average loss: 2.2371, Accuracy: 766/5000 (15%)\n",
      "[epoch 3] loss: 1.9940410\n",
      "Test set: Average loss: 2.2189, Accuracy: 785/5000 (16%)\n",
      "[epoch 4] loss: 1.7824392\n",
      "Test set: Average loss: 2.2497, Accuracy: 843/5000 (17%)\n",
      "[epoch 5] loss: 1.6007249\n",
      "Test set: Average loss: 2.2903, Accuracy: 856/5000 (17%)\n",
      "[epoch 6] loss: 1.4105052\n",
      "Test set: Average loss: 2.4255, Accuracy: 855/5000 (17%)\n",
      "[epoch 7] loss: 1.2930884\n",
      "Test set: Average loss: 2.4756, Accuracy: 997/5000 (20%)\n",
      "[epoch 8] loss: 1.1546346\n",
      "Test set: Average loss: 2.4646, Accuracy: 970/5000 (19%)\n",
      "[epoch 9] loss: 0.9982197\n",
      "Test set: Average loss: 2.4533, Accuracy: 980/5000 (20%)\n",
      "[epoch 10] loss: 0.8555684\n",
      "Test set: Average loss: 2.4731, Accuracy: 1055/5000 (21%)\n",
      "[epoch 11] loss: 0.7332930\n",
      "Test set: Average loss: 2.5348, Accuracy: 1131/5000 (23%)\n",
      "[epoch 12] loss: 0.6104696\n",
      "Test set: Average loss: 2.6571, Accuracy: 1141/5000 (23%)\n",
      "[epoch 13] loss: 0.5069295\n",
      "Test set: Average loss: 2.7951, Accuracy: 1166/5000 (23%)\n",
      "[epoch 14] loss: 0.4054492\n",
      "Test set: Average loss: 2.9729, Accuracy: 1114/5000 (22%)\n",
      "[epoch 15] loss: 0.3243534\n",
      "Test set: Average loss: 3.1982, Accuracy: 1060/5000 (21%)\n",
      "[epoch 16] loss: 0.2636199\n",
      "Test set: Average loss: 3.4425, Accuracy: 1054/5000 (21%)\n",
      "[epoch 17] loss: 0.2107236\n",
      "Test set: Average loss: 3.6899, Accuracy: 1037/5000 (21%)\n",
      "[epoch 18] loss: 0.1677662\n",
      "Test set: Average loss: 3.9100, Accuracy: 1035/5000 (21%)\n",
      "[epoch 19] loss: 0.1324735\n",
      "Test set: Average loss: 4.0793, Accuracy: 1041/5000 (21%)\n",
      "[epoch 20] loss: 0.0996735\n",
      "Test set: Average loss: 4.2226, Accuracy: 1041/5000 (21%)\n",
      "[epoch 21] loss: 0.0745254\n",
      "Test set: Average loss: 4.3643, Accuracy: 1047/5000 (21%)\n",
      "[epoch 22] loss: 0.0548669\n",
      "Test set: Average loss: 4.5118, Accuracy: 1065/5000 (21%)\n",
      "[epoch 23] loss: 0.0386421\n",
      "Test set: Average loss: 4.6655, Accuracy: 1082/5000 (22%)\n",
      "[epoch 24] loss: 0.0272009\n",
      "Test set: Average loss: 4.8157, Accuracy: 1076/5000 (22%)\n",
      "[epoch 25] loss: 0.0190305\n",
      "Test set: Average loss: 4.9580, Accuracy: 1084/5000 (22%)\n",
      "[epoch 26] loss: 0.0132561\n",
      "Test set: Average loss: 5.0934, Accuracy: 1087/5000 (22%)\n",
      "[epoch 27] loss: 0.0095424\n",
      "Test set: Average loss: 5.2210, Accuracy: 1066/5000 (21%)\n",
      "[epoch 28] loss: 0.0071328\n",
      "Test set: Average loss: 5.3383, Accuracy: 1062/5000 (21%)\n",
      "[epoch 29] loss: 0.0054184\n",
      "Test set: Average loss: 5.4439, Accuracy: 1065/5000 (21%)\n",
      "[epoch 30] loss: 0.0041178\n",
      "Test set: Average loss: 5.5392, Accuracy: 1067/5000 (21%)\n",
      "[epoch 31] loss: 0.0031319\n",
      "Test set: Average loss: 5.6263, Accuracy: 1064/5000 (21%)\n",
      "[epoch 32] loss: 0.0024104\n",
      "Test set: Average loss: 5.7072, Accuracy: 1053/5000 (21%)\n",
      "[epoch 33] loss: 0.0019014\n",
      "Test set: Average loss: 5.7832, Accuracy: 1059/5000 (21%)\n",
      "[epoch 34] loss: 0.0015463\n",
      "Test set: Average loss: 5.8552, Accuracy: 1063/5000 (21%)\n",
      "[epoch 35] loss: 0.0012990\n",
      "Test set: Average loss: 5.9235, Accuracy: 1051/5000 (21%)\n",
      "[epoch 36] loss: 0.0011235\n",
      "Test set: Average loss: 5.9883, Accuracy: 1047/5000 (21%)\n",
      "[epoch 37] loss: 0.0009941\n",
      "Test set: Average loss: 6.0497, Accuracy: 1046/5000 (21%)\n",
      "[epoch 38] loss: 0.0008942\n",
      "Test set: Average loss: 6.1078, Accuracy: 1040/5000 (21%)\n",
      "[epoch 39] loss: 0.0008129\n",
      "Test set: Average loss: 6.1625, Accuracy: 1036/5000 (21%)\n",
      "[epoch 40] loss: 0.0007437\n",
      "Test set: Average loss: 6.2139, Accuracy: 1032/5000 (21%)\n",
      "[epoch 41] loss: 0.0006826\n",
      "Test set: Average loss: 6.2621, Accuracy: 1034/5000 (21%)\n",
      "[epoch 42] loss: 0.0006273\n",
      "Test set: Average loss: 6.3073, Accuracy: 1040/5000 (21%)\n",
      "[epoch 43] loss: 0.0005777\n",
      "Test set: Average loss: 6.3496, Accuracy: 1033/5000 (21%)\n",
      "[epoch 44] loss: 0.0005321\n",
      "Test set: Average loss: 6.3890, Accuracy: 1033/5000 (21%)\n",
      "[epoch 45] loss: 0.0004906\n",
      "Test set: Average loss: 6.4258, Accuracy: 1033/5000 (21%)\n",
      "[epoch 46] loss: 0.0004531\n",
      "Test set: Average loss: 6.4601, Accuracy: 1031/5000 (21%)\n",
      "[epoch 47] loss: 0.0004195\n",
      "Test set: Average loss: 6.4920, Accuracy: 1034/5000 (21%)\n",
      "[epoch 48] loss: 0.0003896\n",
      "Test set: Average loss: 6.5217, Accuracy: 1032/5000 (21%)\n",
      "[epoch 49] loss: 0.0003631\n",
      "Test set: Average loss: 6.5492, Accuracy: 1037/5000 (21%)\n",
      "[epoch 50] loss: 0.0003398\n",
      "Test set: Average loss: 6.5746, Accuracy: 1038/5000 (21%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7951, Accuracy: 1166/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.6932, Accuracy: 2415/10000 (24%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 169/5000 (3%)\n",
      "[epoch 1] loss: 2.2989264\n",
      "Test set: Average loss: 2.2739, Accuracy: 1113/5000 (22%)\n",
      "[epoch 2] loss: 2.1807122\n",
      "Test set: Average loss: 2.2457, Accuracy: 1006/5000 (20%)\n",
      "[epoch 3] loss: 2.0106859\n",
      "Test set: Average loss: 2.2506, Accuracy: 883/5000 (18%)\n",
      "[epoch 4] loss: 1.7916576\n",
      "Test set: Average loss: 2.3513, Accuracy: 921/5000 (18%)\n",
      "[epoch 5] loss: 1.5892049\n",
      "Test set: Average loss: 2.4020, Accuracy: 1184/5000 (24%)\n",
      "[epoch 6] loss: 1.3728315\n",
      "Test set: Average loss: 2.4134, Accuracy: 1308/5000 (26%)\n",
      "[epoch 7] loss: 1.1735697\n",
      "Test set: Average loss: 2.4439, Accuracy: 1320/5000 (26%)\n",
      "[epoch 8] loss: 0.9852502\n",
      "Test set: Average loss: 2.4727, Accuracy: 1328/5000 (27%)\n",
      "[epoch 9] loss: 0.7780645\n",
      "Test set: Average loss: 2.5379, Accuracy: 1341/5000 (27%)\n",
      "[epoch 10] loss: 0.5927407\n",
      "Test set: Average loss: 2.6480, Accuracy: 1278/5000 (26%)\n",
      "[epoch 11] loss: 0.4473237\n",
      "Test set: Average loss: 2.7625, Accuracy: 1247/5000 (25%)\n",
      "[epoch 12] loss: 0.3273193\n",
      "Test set: Average loss: 2.8727, Accuracy: 1254/5000 (25%)\n",
      "[epoch 13] loss: 0.2314743\n",
      "Test set: Average loss: 3.0021, Accuracy: 1241/5000 (25%)\n",
      "[epoch 14] loss: 0.1663366\n",
      "Test set: Average loss: 3.1610, Accuracy: 1250/5000 (25%)\n",
      "[epoch 15] loss: 0.1190225\n",
      "Test set: Average loss: 3.3554, Accuracy: 1254/5000 (25%)\n",
      "[epoch 16] loss: 0.0872605\n",
      "Test set: Average loss: 3.5693, Accuracy: 1215/5000 (24%)\n",
      "[epoch 17] loss: 0.0664974\n",
      "Test set: Average loss: 3.7795, Accuracy: 1200/5000 (24%)\n",
      "[epoch 18] loss: 0.0488967\n",
      "Test set: Average loss: 3.9837, Accuracy: 1173/5000 (23%)\n",
      "[epoch 19] loss: 0.0341029\n",
      "Test set: Average loss: 4.1866, Accuracy: 1129/5000 (23%)\n",
      "[epoch 20] loss: 0.0238219\n",
      "Test set: Average loss: 4.3846, Accuracy: 1117/5000 (22%)\n",
      "[epoch 21] loss: 0.0172852\n",
      "Test set: Average loss: 4.5693, Accuracy: 1100/5000 (22%)\n",
      "[epoch 22] loss: 0.0127652\n",
      "Test set: Average loss: 4.7359, Accuracy: 1101/5000 (22%)\n",
      "[epoch 23] loss: 0.0092865\n",
      "Test set: Average loss: 4.8856, Accuracy: 1087/5000 (22%)\n",
      "[epoch 24] loss: 0.0065979\n",
      "Test set: Average loss: 5.0227, Accuracy: 1080/5000 (22%)\n",
      "[epoch 25] loss: 0.0046362\n",
      "Test set: Average loss: 5.1517, Accuracy: 1076/5000 (22%)\n",
      "[epoch 26] loss: 0.0032940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 5.2758, Accuracy: 1078/5000 (22%)\n",
      "[epoch 27] loss: 0.0024082\n",
      "Test set: Average loss: 5.3959, Accuracy: 1081/5000 (22%)\n",
      "[epoch 28] loss: 0.0018307\n",
      "Test set: Average loss: 5.5119, Accuracy: 1088/5000 (22%)\n",
      "[epoch 29] loss: 0.0014474\n",
      "Test set: Average loss: 5.6224, Accuracy: 1086/5000 (22%)\n",
      "[epoch 30] loss: 0.0011831\n",
      "Test set: Average loss: 5.7264, Accuracy: 1091/5000 (22%)\n",
      "[epoch 31] loss: 0.0009904\n",
      "Test set: Average loss: 5.8227, Accuracy: 1090/5000 (22%)\n",
      "[epoch 32] loss: 0.0008411\n",
      "Test set: Average loss: 5.9110, Accuracy: 1095/5000 (22%)\n",
      "[epoch 33] loss: 0.0007206\n",
      "Test set: Average loss: 5.9910, Accuracy: 1103/5000 (22%)\n",
      "[epoch 34] loss: 0.0006220\n",
      "Test set: Average loss: 6.0630, Accuracy: 1101/5000 (22%)\n",
      "[epoch 35] loss: 0.0005415\n",
      "Test set: Average loss: 6.1272, Accuracy: 1103/5000 (22%)\n",
      "[epoch 36] loss: 0.0004766\n",
      "Test set: Average loss: 6.1841, Accuracy: 1106/5000 (22%)\n",
      "[epoch 37] loss: 0.0004244\n",
      "Test set: Average loss: 6.2343, Accuracy: 1111/5000 (22%)\n",
      "[epoch 38] loss: 0.0003823\n",
      "Test set: Average loss: 6.2783, Accuracy: 1118/5000 (22%)\n",
      "[epoch 39] loss: 0.0003479\n",
      "Test set: Average loss: 6.3165, Accuracy: 1113/5000 (22%)\n",
      "[epoch 40] loss: 0.0003191\n",
      "Test set: Average loss: 6.3496, Accuracy: 1110/5000 (22%)\n",
      "[epoch 41] loss: 0.0002945\n",
      "Test set: Average loss: 6.3781, Accuracy: 1109/5000 (22%)\n",
      "[epoch 42] loss: 0.0002732\n",
      "Test set: Average loss: 6.4026, Accuracy: 1108/5000 (22%)\n",
      "[epoch 43] loss: 0.0002541\n",
      "Test set: Average loss: 6.4236, Accuracy: 1112/5000 (22%)\n",
      "[epoch 44] loss: 0.0002372\n",
      "Test set: Average loss: 6.4417, Accuracy: 1115/5000 (22%)\n",
      "[epoch 45] loss: 0.0002225\n",
      "Test set: Average loss: 6.4573, Accuracy: 1119/5000 (22%)\n",
      "[epoch 46] loss: 0.0002094\n",
      "Test set: Average loss: 6.4709, Accuracy: 1122/5000 (22%)\n",
      "[epoch 47] loss: 0.0001981\n",
      "Test set: Average loss: 6.4828, Accuracy: 1122/5000 (22%)\n",
      "[epoch 48] loss: 0.0001882\n",
      "Test set: Average loss: 6.4933, Accuracy: 1121/5000 (22%)\n",
      "[epoch 49] loss: 0.0001793\n",
      "Test set: Average loss: 6.5027, Accuracy: 1121/5000 (22%)\n",
      "[epoch 50] loss: 0.0001718\n",
      "Test set: Average loss: 6.5111, Accuracy: 1118/5000 (22%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5379, Accuracy: 1341/5000 (27%)\n",
      "Test\n",
      "Test set: Average loss: 2.5500, Accuracy: 2685/10000 (27%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3012, Accuracy: 494/5000 (10%)\n",
      "[epoch 1] loss: 2.3013549\n",
      "Test set: Average loss: 2.2782, Accuracy: 828/5000 (17%)\n",
      "[epoch 2] loss: 2.1953833\n",
      "Test set: Average loss: 2.2565, Accuracy: 700/5000 (14%)\n",
      "[epoch 3] loss: 2.0383272\n",
      "Test set: Average loss: 2.2777, Accuracy: 536/5000 (11%)\n",
      "[epoch 4] loss: 1.8345402\n",
      "Test set: Average loss: 2.4824, Accuracy: 526/5000 (11%)\n",
      "[epoch 5] loss: 1.7011861\n",
      "Test set: Average loss: 2.5678, Accuracy: 562/5000 (11%)\n",
      "[epoch 6] loss: 1.5609852\n",
      "Test set: Average loss: 2.5024, Accuracy: 769/5000 (15%)\n",
      "[epoch 7] loss: 1.3971449\n",
      "Test set: Average loss: 2.4298, Accuracy: 851/5000 (17%)\n",
      "[epoch 8] loss: 1.2470413\n",
      "Test set: Average loss: 2.3425, Accuracy: 919/5000 (18%)\n",
      "[epoch 9] loss: 1.0586493\n",
      "Test set: Average loss: 2.3048, Accuracy: 970/5000 (19%)\n",
      "[epoch 10] loss: 0.8833774\n",
      "Test set: Average loss: 2.3064, Accuracy: 1042/5000 (21%)\n",
      "[epoch 11] loss: 0.7255440\n",
      "Test set: Average loss: 2.3021, Accuracy: 1130/5000 (23%)\n",
      "[epoch 12] loss: 0.5609527\n",
      "Test set: Average loss: 2.3375, Accuracy: 1173/5000 (23%)\n",
      "[epoch 13] loss: 0.4125735\n",
      "Test set: Average loss: 2.4617, Accuracy: 1170/5000 (23%)\n",
      "[epoch 14] loss: 0.2974978\n",
      "Test set: Average loss: 2.6426, Accuracy: 1156/5000 (23%)\n",
      "[epoch 15] loss: 0.2002317\n",
      "Test set: Average loss: 2.8590, Accuracy: 1132/5000 (23%)\n",
      "[epoch 16] loss: 0.1265094\n",
      "Test set: Average loss: 3.1123, Accuracy: 1117/5000 (22%)\n",
      "[epoch 17] loss: 0.0797337\n",
      "Test set: Average loss: 3.3855, Accuracy: 1094/5000 (22%)\n",
      "[epoch 18] loss: 0.0507786\n",
      "Test set: Average loss: 3.6628, Accuracy: 1082/5000 (22%)\n",
      "[epoch 19] loss: 0.0330132\n",
      "Test set: Average loss: 3.9368, Accuracy: 1073/5000 (21%)\n",
      "[epoch 20] loss: 0.0223344\n",
      "Test set: Average loss: 4.2011, Accuracy: 1069/5000 (21%)\n",
      "[epoch 21] loss: 0.0152967\n",
      "Test set: Average loss: 4.4529, Accuracy: 1056/5000 (21%)\n",
      "[epoch 22] loss: 0.0104039\n",
      "Test set: Average loss: 4.6933, Accuracy: 1037/5000 (21%)\n",
      "[epoch 23] loss: 0.0071689\n",
      "Test set: Average loss: 4.9236, Accuracy: 1035/5000 (21%)\n",
      "[epoch 24] loss: 0.0051006\n",
      "Test set: Average loss: 5.1434, Accuracy: 1027/5000 (21%)\n",
      "[epoch 25] loss: 0.0037556\n",
      "Test set: Average loss: 5.3521, Accuracy: 1015/5000 (20%)\n",
      "[epoch 26] loss: 0.0028420\n",
      "Test set: Average loss: 5.5489, Accuracy: 1001/5000 (20%)\n",
      "[epoch 27] loss: 0.0021978\n",
      "Test set: Average loss: 5.7426, Accuracy: 999/5000 (20%)\n",
      "[epoch 28] loss: 0.0017330\n",
      "Test set: Average loss: 5.9036, Accuracy: 992/5000 (20%)\n",
      "[epoch 29] loss: 0.0013926\n",
      "Test set: Average loss: 6.0612, Accuracy: 988/5000 (20%)\n",
      "[epoch 30] loss: 0.0011421\n",
      "Test set: Average loss: 6.2057, Accuracy: 986/5000 (20%)\n",
      "[epoch 31] loss: 0.0009551\n",
      "Test set: Average loss: 6.3376, Accuracy: 981/5000 (20%)\n",
      "[epoch 32] loss: 0.0008132\n",
      "Test set: Average loss: 6.4575, Accuracy: 972/5000 (19%)\n",
      "[epoch 33] loss: 0.0007040\n",
      "Test set: Average loss: 6.5660, Accuracy: 967/5000 (19%)\n",
      "[epoch 34] loss: 0.0006181\n",
      "Test set: Average loss: 6.6638, Accuracy: 959/5000 (19%)\n",
      "[epoch 35] loss: 0.0005492\n",
      "Test set: Average loss: 6.7517, Accuracy: 958/5000 (19%)\n",
      "[epoch 36] loss: 0.0004926\n",
      "Test set: Average loss: 6.8305, Accuracy: 956/5000 (19%)\n",
      "[epoch 37] loss: 0.0004455\n",
      "Test set: Average loss: 6.9008, Accuracy: 953/5000 (19%)\n",
      "[epoch 38] loss: 0.0004057\n",
      "Test set: Average loss: 6.9634, Accuracy: 952/5000 (19%)\n",
      "[epoch 39] loss: 0.0003715\n",
      "Test set: Average loss: 7.0190, Accuracy: 951/5000 (19%)\n",
      "[epoch 40] loss: 0.0003418\n",
      "Test set: Average loss: 7.0683, Accuracy: 950/5000 (19%)\n",
      "[epoch 41] loss: 0.0003162\n",
      "Test set: Average loss: 7.1119, Accuracy: 952/5000 (19%)\n",
      "[epoch 42] loss: 0.0002937\n",
      "Test set: Average loss: 7.1504, Accuracy: 948/5000 (19%)\n",
      "[epoch 43] loss: 0.0002737\n",
      "Test set: Average loss: 7.1844, Accuracy: 943/5000 (19%)\n",
      "[epoch 44] loss: 0.0002563\n",
      "Test set: Average loss: 7.2143, Accuracy: 945/5000 (19%)\n",
      "[epoch 45] loss: 0.0002409\n",
      "Test set: Average loss: 7.2405, Accuracy: 944/5000 (19%)\n",
      "[epoch 46] loss: 0.0002272\n",
      "Test set: Average loss: 7.2635, Accuracy: 948/5000 (19%)\n",
      "[epoch 47] loss: 0.0002151\n",
      "Test set: Average loss: 7.2836, Accuracy: 951/5000 (19%)\n",
      "[epoch 48] loss: 0.0002042\n",
      "Test set: Average loss: 7.3012, Accuracy: 946/5000 (19%)\n",
      "[epoch 49] loss: 0.0001945\n",
      "Test set: Average loss: 7.3165, Accuracy: 947/5000 (19%)\n",
      "[epoch 50] loss: 0.0001859\n",
      "Test set: Average loss: 7.3299, Accuracy: 949/5000 (19%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3375, Accuracy: 1173/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.3475, Accuracy: 2335/10000 (23%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3011, Accuracy: 495/5000 (10%)\n",
      "[epoch 1] loss: 2.2805605\n",
      "Test set: Average loss: 2.2597, Accuracy: 1152/5000 (23%)\n",
      "[epoch 2] loss: 2.0826756\n",
      "Test set: Average loss: 2.2689, Accuracy: 827/5000 (17%)\n",
      "[epoch 3] loss: 1.8247291\n",
      "Test set: Average loss: 2.3190, Accuracy: 984/5000 (20%)\n",
      "[epoch 4] loss: 1.7139303\n",
      "Test set: Average loss: 2.2418, Accuracy: 1331/5000 (27%)\n",
      "[epoch 5] loss: 1.4834460\n",
      "Test set: Average loss: 2.2692, Accuracy: 1359/5000 (27%)\n",
      "[epoch 6] loss: 1.3575854\n",
      "Test set: Average loss: 2.2045, Accuracy: 1364/5000 (27%)\n",
      "[epoch 7] loss: 1.1291942\n",
      "Test set: Average loss: 2.1216, Accuracy: 1543/5000 (31%)\n",
      "[epoch 8] loss: 0.9073184\n",
      "Test set: Average loss: 2.0314, Accuracy: 1614/5000 (32%)\n",
      "[epoch 9] loss: 0.7983124\n",
      "Test set: Average loss: 1.9946, Accuracy: 1583/5000 (32%)\n",
      "[epoch 10] loss: 0.6321414\n",
      "Test set: Average loss: 2.1140, Accuracy: 1545/5000 (31%)\n",
      "[epoch 11] loss: 0.4967618\n",
      "Test set: Average loss: 2.3014, Accuracy: 1489/5000 (30%)\n",
      "[epoch 12] loss: 0.3919546\n",
      "Test set: Average loss: 2.2650, Accuracy: 1495/5000 (30%)\n",
      "[epoch 13] loss: 0.2890335\n",
      "Test set: Average loss: 2.2047, Accuracy: 1555/5000 (31%)\n",
      "[epoch 14] loss: 0.2291266\n",
      "Test set: Average loss: 2.2247, Accuracy: 1586/5000 (32%)\n",
      "[epoch 15] loss: 0.1754039\n",
      "Test set: Average loss: 2.4953, Accuracy: 1529/5000 (31%)\n",
      "[epoch 16] loss: 0.1082583\n",
      "Test set: Average loss: 2.5920, Accuracy: 1497/5000 (30%)\n",
      "[epoch 17] loss: 0.0640977\n",
      "Test set: Average loss: 2.7678, Accuracy: 1441/5000 (29%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0656708\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.9165, Accuracy: 1424/5000 (28%)\n",
      "[epoch 19] loss: 0.0391523\n",
      "Test set: Average loss: 2.9228, Accuracy: 1424/5000 (28%)\n",
      "[epoch 20] loss: 0.0397039\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.9223, Accuracy: 1436/5000 (29%)\n",
      "[epoch 21] loss: 0.0343455\n",
      "Test set: Average loss: 2.9219, Accuracy: 1441/5000 (29%)\n",
      "[epoch 22] loss: 0.0375640\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.9211, Accuracy: 1442/5000 (29%)\n",
      "[epoch 23] loss: 0.0382562\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 24] loss: 0.0320561\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 25] loss: 0.0324809\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 26] loss: 0.0338473\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 27] loss: 0.0383352\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 28] loss: 0.0375497\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 29] loss: 0.0329654\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 30] loss: 0.0328484\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 31] loss: 0.0341371\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 32] loss: 0.0333463\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 33] loss: 0.0351767\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 34] loss: 0.0326524\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 35] loss: 0.0366558\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 36] loss: 0.0353116\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 37] loss: 0.0340320\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 38] loss: 0.0356454\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 39] loss: 0.0309093\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 40] loss: 0.0330213\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 41] loss: 0.0373224\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 42] loss: 0.0333893\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 43] loss: 0.0331534\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 44] loss: 0.0324875\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.9207, Accuracy: 1440/5000 (29%)\n",
      "[epoch 45] loss: 0.0327810\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 46] loss: 0.0338777\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 47] loss: 0.0343728\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 48] loss: 0.0336179\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 49] loss: 0.0322585\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "[epoch 50] loss: 0.0338200\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.9209, Accuracy: 1442/5000 (29%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0314, Accuracy: 1614/5000 (32%)\n",
      "Test\n",
      "Test set: Average loss: 1.9978, Accuracy: 3352/10000 (34%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3052, Accuracy: 483/5000 (10%)\n",
      "[epoch 1] loss: 2.2899022\n",
      "Test set: Average loss: 2.2370, Accuracy: 1394/5000 (28%)\n",
      "[epoch 2] loss: 2.1374776\n",
      "Test set: Average loss: 2.1369, Accuracy: 1252/5000 (25%)\n",
      "[epoch 3] loss: 1.7992856\n",
      "Test set: Average loss: 2.0584, Accuracy: 1196/5000 (24%)\n",
      "[epoch 4] loss: 1.5927955\n",
      "Test set: Average loss: 2.0469, Accuracy: 1279/5000 (26%)\n",
      "[epoch 5] loss: 1.3252915\n",
      "Test set: Average loss: 1.9966, Accuracy: 1462/5000 (29%)\n",
      "[epoch 6] loss: 1.2154739\n",
      "Test set: Average loss: 1.9424, Accuracy: 1443/5000 (29%)\n",
      "[epoch 7] loss: 0.9886903\n",
      "Test set: Average loss: 1.9423, Accuracy: 1554/5000 (31%)\n",
      "[epoch 8] loss: 0.8762445\n",
      "Test set: Average loss: 1.9762, Accuracy: 1482/5000 (30%)\n",
      "[epoch 9] loss: 0.6466374\n",
      "Test set: Average loss: 2.0477, Accuracy: 1551/5000 (31%)\n",
      "[epoch 10] loss: 0.5875659\n",
      "Test set: Average loss: 2.1602, Accuracy: 1555/5000 (31%)\n",
      "[epoch 11] loss: 0.3962234\n",
      "Test set: Average loss: 2.2019, Accuracy: 1565/5000 (31%)\n",
      "[epoch 12] loss: 0.3003027\n",
      "Test set: Average loss: 2.2991, Accuracy: 1511/5000 (30%)\n",
      "[epoch 13] loss: 0.2287152\n",
      "Test set: Average loss: 2.4969, Accuracy: 1463/5000 (29%)\n",
      "[epoch 14] loss: 0.1877182\n",
      "Test set: Average loss: 2.6748, Accuracy: 1454/5000 (29%)\n",
      "[epoch 15] loss: 0.1285776\n",
      "Test set: Average loss: 2.7279, Accuracy: 1529/5000 (31%)\n",
      "[epoch 16] loss: 0.0716430\n",
      "Test set: Average loss: 2.7648, Accuracy: 1559/5000 (31%)\n",
      "[epoch 17] loss: 0.0517553\n",
      "Test set: Average loss: 2.8449, Accuracy: 1566/5000 (31%)\n",
      "[epoch 18] loss: 0.0434025\n",
      "Test set: Average loss: 2.9409, Accuracy: 1541/5000 (31%)\n",
      "[epoch 19] loss: 0.0341561\n",
      "Test set: Average loss: 3.0071, Accuracy: 1523/5000 (30%)\n",
      "[epoch 20] loss: 0.0193248\n",
      "Test set: Average loss: 3.0971, Accuracy: 1476/5000 (30%)\n",
      "[epoch 21] loss: 0.0131262\n",
      "Test set: Average loss: 3.2117, Accuracy: 1437/5000 (29%)\n",
      "[epoch 22] loss: 0.0102235\n",
      "Test set: Average loss: 3.3195, Accuracy: 1411/5000 (28%)\n",
      "[epoch 23] loss: 0.0102443\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.4018, Accuracy: 1429/5000 (29%)\n",
      "[epoch 24] loss: 0.0081715\n",
      "Test set: Average loss: 3.4064, Accuracy: 1426/5000 (29%)\n",
      "[epoch 25] loss: 0.0076277\n",
      "Test set: Average loss: 3.4081, Accuracy: 1425/5000 (28%)\n",
      "[epoch 26] loss: 0.0088345\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.4079, Accuracy: 1428/5000 (29%)\n",
      "[epoch 27] loss: 0.0078205\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.4076, Accuracy: 1428/5000 (29%)\n",
      "[epoch 28] loss: 0.0069423\n",
      "Test set: Average loss: 3.4076, Accuracy: 1428/5000 (29%)\n",
      "[epoch 29] loss: 0.0082288\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 30] loss: 0.0070957\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 31] loss: 0.0072661\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 32] loss: 0.0074721\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 33] loss: 0.0074398\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 34] loss: 0.0077739\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 35] loss: 0.0075908\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 36] loss: 0.0074436\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 37] loss: 0.0082435\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 38] loss: 0.0070545\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 39] loss: 0.0075694\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 40] loss: 0.0074211\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 41] loss: 0.0073495\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 42] loss: 0.0073218\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 43] loss: 0.0081694\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 44] loss: 0.0079822\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 45] loss: 0.0077795\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 46] loss: 0.0075450\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 47] loss: 0.0074144\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 48] loss: 0.0082058\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 49] loss: 0.0075328\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "[epoch 50] loss: 0.0072629\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 3.4075, Accuracy: 1428/5000 (29%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8449, Accuracy: 1566/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 2.7967, Accuracy: 3153/10000 (32%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3055, Accuracy: 518/5000 (10%)\n",
      "[epoch 1] loss: 2.2623165\n",
      "Test set: Average loss: 2.2541, Accuracy: 775/5000 (16%)\n",
      "[epoch 2] loss: 2.0587239\n",
      "Test set: Average loss: 2.2592, Accuracy: 681/5000 (14%)\n",
      "[epoch 3] loss: 1.8678570\n",
      "Test set: Average loss: 2.2883, Accuracy: 904/5000 (18%)\n",
      "[epoch 4] loss: 1.6655517\n",
      "Test set: Average loss: 2.2009, Accuracy: 1192/5000 (24%)\n",
      "[epoch 5] loss: 1.4555093\n",
      "Test set: Average loss: 2.0982, Accuracy: 1439/5000 (29%)\n",
      "[epoch 6] loss: 1.2279803\n",
      "Test set: Average loss: 2.1205, Accuracy: 1316/5000 (26%)\n",
      "[epoch 7] loss: 1.0699781\n",
      "Test set: Average loss: 2.1152, Accuracy: 1314/5000 (26%)\n",
      "[epoch 8] loss: 0.9495987\n",
      "Test set: Average loss: 2.1709, Accuracy: 1304/5000 (26%)\n",
      "[epoch 9] loss: 0.6823781\n",
      "Test set: Average loss: 2.2641, Accuracy: 1271/5000 (25%)\n",
      "[epoch 10] loss: 0.5174855\n",
      "Test set: Average loss: 2.3941, Accuracy: 1252/5000 (25%)\n",
      "[epoch 11] loss: 0.4151879\n",
      "Test set: Average loss: 2.5580, Accuracy: 1239/5000 (25%)\n",
      "[epoch 12] loss: 0.2857208\n",
      "Test set: Average loss: 2.5965, Accuracy: 1304/5000 (26%)\n",
      "[epoch 13] loss: 0.1988575\n",
      "Test set: Average loss: 2.7085, Accuracy: 1368/5000 (27%)\n",
      "[epoch 14] loss: 0.1262388\n",
      "Test set: Average loss: 2.8753, Accuracy: 1377/5000 (28%)\n",
      "[epoch 15] loss: 0.0855414\n",
      "Test set: Average loss: 3.0466, Accuracy: 1373/5000 (27%)\n",
      "[epoch 16] loss: 0.0595051\n",
      "Test set: Average loss: 3.2684, Accuracy: 1392/5000 (28%)\n",
      "[epoch 17] loss: 0.0378184\n",
      "Test set: Average loss: 3.5186, Accuracy: 1355/5000 (27%)\n",
      "[epoch 18] loss: 0.0384538\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 3.7078, Accuracy: 1318/5000 (26%)\n",
      "[epoch 19] loss: 0.0244069\n",
      "Test set: Average loss: 3.7142, Accuracy: 1326/5000 (27%)\n",
      "[epoch 20] loss: 0.0218775\n",
      "Test set: Average loss: 3.7163, Accuracy: 1329/5000 (27%)\n",
      "[epoch 21] loss: 0.0200245\n",
      "Test set: Average loss: 3.7168, Accuracy: 1337/5000 (27%)\n",
      "[epoch 22] loss: 0.0194947\n",
      "Test set: Average loss: 3.7168, Accuracy: 1336/5000 (27%)\n",
      "[epoch 23] loss: 0.0178996\n",
      "Test set: Average loss: 3.7175, Accuracy: 1335/5000 (27%)\n",
      "[epoch 24] loss: 0.0163443\n",
      "Test set: Average loss: 3.7186, Accuracy: 1328/5000 (27%)\n",
      "[epoch 25] loss: 0.0179013\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.7200, Accuracy: 1326/5000 (27%)\n",
      "[epoch 26] loss: 0.0152048\n",
      "Test set: Average loss: 3.7199, Accuracy: 1328/5000 (27%)\n",
      "[epoch 27] loss: 0.0179996\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 3.7197, Accuracy: 1328/5000 (27%)\n",
      "[epoch 28] loss: 0.0155119\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 29] loss: 0.0164032\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 30] loss: 0.0159003\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 31] loss: 0.0177792\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 32] loss: 0.0171103\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 33] loss: 0.0171669\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 34] loss: 0.0171289\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 35] loss: 0.0162605\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 36] loss: 0.0156255\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 37] loss: 0.0173133\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 38] loss: 0.0157166\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 39] loss: 0.0172089\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 40] loss: 0.0150937\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 41] loss: 0.0169069\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 42] loss: 0.0145824\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 43] loss: 0.0182152\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 44] loss: 0.0158282\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 45] loss: 0.0170278\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 46] loss: 0.0155389\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 47] loss: 0.0176935\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 48] loss: 0.0174505\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "[epoch 49] loss: 0.0157280\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.0153904\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 3.7196, Accuracy: 1328/5000 (27%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0982, Accuracy: 1439/5000 (29%)\n",
      "Test\n",
      "Test set: Average loss: 2.0823, Accuracy: 2914/10000 (29%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3009, Accuracy: 387/5000 (8%)\n",
      "[epoch 1] loss: 2.2666499\n",
      "Test set: Average loss: 2.1779, Accuracy: 1056/5000 (21%)\n",
      "[epoch 2] loss: 2.1322131\n",
      "Test set: Average loss: 2.2251, Accuracy: 1040/5000 (21%)\n",
      "[epoch 3] loss: 1.6766056\n",
      "Test set: Average loss: 2.0394, Accuracy: 1301/5000 (26%)\n",
      "[epoch 4] loss: 1.5589453\n",
      "Test set: Average loss: 2.0796, Accuracy: 1293/5000 (26%)\n",
      "[epoch 5] loss: 1.3608569\n",
      "Test set: Average loss: 2.0817, Accuracy: 1453/5000 (29%)\n",
      "[epoch 6] loss: 1.2773711\n",
      "Test set: Average loss: 2.1663, Accuracy: 1317/5000 (26%)\n",
      "[epoch 7] loss: 1.1812974\n",
      "Test set: Average loss: 2.2173, Accuracy: 1357/5000 (27%)\n",
      "[epoch 8] loss: 0.8805692\n",
      "Test set: Average loss: 2.1066, Accuracy: 1566/5000 (31%)\n",
      "[epoch 9] loss: 0.8680549\n",
      "Test set: Average loss: 2.0825, Accuracy: 1581/5000 (32%)\n",
      "[epoch 10] loss: 0.6740480\n",
      "Test set: Average loss: 2.4036, Accuracy: 1544/5000 (31%)\n",
      "[epoch 11] loss: 0.7371777\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3422, Accuracy: 1591/5000 (32%)\n",
      "[epoch 12] loss: 0.7197967\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3132, Accuracy: 1598/5000 (32%)\n",
      "[epoch 13] loss: 0.5237999\n",
      "Test set: Average loss: 2.3075, Accuracy: 1602/5000 (32%)\n",
      "[epoch 14] loss: 0.5420809\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.3018, Accuracy: 1603/5000 (32%)\n",
      "[epoch 15] loss: 0.6749016\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.3011, Accuracy: 1604/5000 (32%)\n",
      "[epoch 16] loss: 0.5642991\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 17] loss: 0.5590751\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 18] loss: 0.6103880\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 19] loss: 0.5564709\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 20] loss: 0.5208949\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 21] loss: 0.6580981\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 22] loss: 0.6250200\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 23] loss: 0.5671183\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 24] loss: 0.5088520\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 25] loss: 2.0377809\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 26] loss: 0.5057476\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 27] loss: 0.5186789\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 28] loss: 0.5641192\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 29] loss: 0.5043002\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 30] loss: 0.5846904\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 31] loss: 0.5296574\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 32] loss: 0.5814216\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 33] loss: 0.6628976\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 34] loss: 0.5676806\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 35] loss: 0.5814028\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 36] loss: 0.4851438\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 37] loss: 0.6300810\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 38] loss: 0.5906097\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 39] loss: 1.9263057\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 40] loss: 0.5402375\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 41] loss: 0.5259729\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 42] loss: 0.5182392\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 43] loss: 1.9421154\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 44] loss: 0.4935313\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 45] loss: 0.5570572\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 46] loss: 0.4740767\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 47] loss: 0.6004450\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 48] loss: 0.5730121\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 49] loss: 0.4707336\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "[epoch 50] loss: 0.5234033\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3010, Accuracy: 1604/5000 (32%)\n",
      "Test\n",
      "Test set: Average loss: 2.2381, Accuracy: 3298/10000 (33%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3050, Accuracy: 563/5000 (11%)\n",
      "[epoch 1] loss: 2.2861685\n",
      "Test set: Average loss: 2.1601, Accuracy: 1363/5000 (27%)\n",
      "[epoch 2] loss: 1.9246109\n",
      "Test set: Average loss: 2.0032, Accuracy: 1351/5000 (27%)\n",
      "[epoch 3] loss: 2.1377094\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8276, Accuracy: 1773/5000 (35%)\n",
      "[epoch 4] loss: 1.3993412\n",
      "Test set: Average loss: 1.8171, Accuracy: 1805/5000 (36%)\n",
      "[epoch 5] loss: 1.3494638\n",
      "Test set: Average loss: 1.8015, Accuracy: 1853/5000 (37%)\n",
      "[epoch 6] loss: 1.3878586\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7875, Accuracy: 1868/5000 (37%)\n",
      "[epoch 7] loss: 1.5447682\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7861, Accuracy: 1866/5000 (37%)\n",
      "[epoch 8] loss: 1.3120291\n",
      "Test set: Average loss: 1.7859, Accuracy: 1868/5000 (37%)\n",
      "[epoch 9] loss: 1.2387376\n",
      "Test set: Average loss: 1.7857, Accuracy: 1870/5000 (37%)\n",
      "[epoch 10] loss: 1.3008952\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 11] loss: 1.3971052\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 12] loss: 1.4207643\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] loss: 1.3435699\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 14] loss: 1.4245422\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 15] loss: 2.0503059\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 16] loss: 1.9393636\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 17] loss: 2.0101638\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 18] loss: 1.3108086\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 19] loss: 1.3591329\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 20] loss: 1.4060794\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 21] loss: 1.4028519\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 22] loss: 1.2930821\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 23] loss: 1.3968436\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 24] loss: 1.4255988\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 25] loss: 1.4129963\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 26] loss: 1.3245645\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 27] loss: 1.2370440\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 28] loss: 1.3304380\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 29] loss: 1.3677068\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 30] loss: 1.3273935\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 31] loss: 1.3720059\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 32] loss: 1.3714495\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 33] loss: 1.2502008\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 34] loss: 1.3262018\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 35] loss: 1.3016384\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 36] loss: 1.4397758\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 37] loss: 1.2900233\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 38] loss: 1.8007835\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 39] loss: 1.3463276\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 40] loss: 1.3259723\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 41] loss: 1.2808883\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 42] loss: 1.3234430\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 43] loss: 1.4001352\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 44] loss: 1.4790878\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 45] loss: 1.3116552\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 46] loss: 1.4042890\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 47] loss: 1.3395842\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 48] loss: 1.4239298\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 49] loss: 2.0394908\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "[epoch 50] loss: 1.4583054\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7855, Accuracy: 1870/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 1.7643, Accuracy: 3818/10000 (38%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 352/5000 (7%)\n",
      "[epoch 1] loss: 2.2883056\n",
      "Test set: Average loss: 2.2207, Accuracy: 833/5000 (17%)\n",
      "[epoch 2] loss: 1.9127188\n",
      "Test set: Average loss: 2.2923, Accuracy: 911/5000 (18%)\n",
      "[epoch 3] loss: 1.7226940\n",
      "Test set: Average loss: 2.1349, Accuracy: 1272/5000 (25%)\n",
      "[epoch 4] loss: 1.7476476\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0604, Accuracy: 1339/5000 (27%)\n",
      "[epoch 5] loss: 1.4774180\n",
      "Test set: Average loss: 2.0371, Accuracy: 1360/5000 (27%)\n",
      "[epoch 6] loss: 1.4073960\n",
      "Test set: Average loss: 1.9872, Accuracy: 1440/5000 (29%)\n",
      "[epoch 7] loss: 1.3192867\n",
      "Test set: Average loss: 1.9516, Accuracy: 1456/5000 (29%)\n",
      "[epoch 8] loss: 1.2763095\n",
      "Test set: Average loss: 1.9247, Accuracy: 1491/5000 (30%)\n",
      "[epoch 9] loss: 1.2675055\n",
      "Test set: Average loss: 1.9079, Accuracy: 1523/5000 (30%)\n",
      "[epoch 10] loss: 1.5615353\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8989, Accuracy: 1525/5000 (30%)\n",
      "[epoch 11] loss: 1.1925501\n",
      "Test set: Average loss: 1.8985, Accuracy: 1527/5000 (31%)\n",
      "[epoch 12] loss: 1.1330526\n",
      "Test set: Average loss: 1.8974, Accuracy: 1529/5000 (31%)\n",
      "[epoch 13] loss: 1.2948619\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1525/5000 (30%)\n",
      "[epoch 14] loss: 1.3287213\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 15] loss: 1.2009519\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 16] loss: 1.2144466\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 17] loss: 1.4276973\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 18] loss: 1.2772789\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 19] loss: 1.1644952\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 20] loss: 1.1635891\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 21] loss: 1.2527038\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22] loss: 1.1062441\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 23] loss: 1.2267102\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 24] loss: 1.1753308\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 25] loss: 1.3643541\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 26] loss: 1.1156972\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 27] loss: 1.2499268\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 28] loss: 1.2552148\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 29] loss: 1.2774146\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 30] loss: 1.1491317\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 31] loss: 1.2326750\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 32] loss: 1.2050061\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 33] loss: 1.1293478\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 34] loss: 1.3524383\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 35] loss: 1.2269532\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 36] loss: 1.1657525\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 37] loss: 1.2304593\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 38] loss: 1.2157600\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 39] loss: 1.3227279\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 40] loss: 1.2592344\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 41] loss: 1.0801422\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 42] loss: 1.3137787\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 43] loss: 1.3504558\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 44] loss: 1.2007835\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 45] loss: 1.1606871\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 46] loss: 1.4102871\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 47] loss: 1.3877897\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 48] loss: 1.2413202\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 49] loss: 1.2244179\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "[epoch 50] loss: 1.1550689\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 1.8973, Accuracy: 1526/5000 (31%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8974, Accuracy: 1529/5000 (31%)\n",
      "Test\n",
      "Test set: Average loss: 1.8865, Accuracy: 3143/10000 (31%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 556/5000 (11%)\n",
      "[epoch 1] loss: 2.1602281\n",
      "Test set: Average loss: 1.9681, Accuracy: 1329/5000 (27%)\n",
      "[epoch 2] loss: 1.7425587\n",
      "Test set: Average loss: 1.6997, Accuracy: 2236/5000 (45%)\n",
      "[epoch 3] loss: 1.4174335\n",
      "Test set: Average loss: 1.5633, Accuracy: 2201/5000 (44%)\n",
      "[epoch 4] loss: 1.2248681\n",
      "Test set: Average loss: 1.5173, Accuracy: 2328/5000 (47%)\n",
      "[epoch 5] loss: 1.0137306\n",
      "Test set: Average loss: 1.4353, Accuracy: 2462/5000 (49%)\n",
      "[epoch 6] loss: 0.8763354\n",
      "Test set: Average loss: 1.4631, Accuracy: 2449/5000 (49%)\n",
      "[epoch 7] loss: 0.6681684\n",
      "Test set: Average loss: 1.7977, Accuracy: 2149/5000 (43%)\n",
      "[epoch 8] loss: 0.6068950\n",
      "Test set: Average loss: 1.6994, Accuracy: 2296/5000 (46%)\n",
      "[epoch 9] loss: 0.4593647\n",
      "Test set: Average loss: 1.7295, Accuracy: 2308/5000 (46%)\n",
      "[epoch 10] loss: 0.3354034\n",
      "Test set: Average loss: 1.8414, Accuracy: 2267/5000 (45%)\n",
      "[epoch 11] loss: 0.2530891\n",
      "Test set: Average loss: 1.9735, Accuracy: 2203/5000 (44%)\n",
      "[epoch 12] loss: 0.1909105\n",
      "Test set: Average loss: 2.1230, Accuracy: 2235/5000 (45%)\n",
      "[epoch 13] loss: 0.1369122\n",
      "Test set: Average loss: 2.1309, Accuracy: 2244/5000 (45%)\n",
      "[epoch 14] loss: 0.0908750\n",
      "Test set: Average loss: 2.0725, Accuracy: 2375/5000 (48%)\n",
      "[epoch 15] loss: 0.0598296\n",
      "Test set: Average loss: 2.2138, Accuracy: 2253/5000 (45%)\n",
      "[epoch 16] loss: 0.0369254\n",
      "Test set: Average loss: 2.1643, Accuracy: 2344/5000 (47%)\n",
      "[epoch 17] loss: 0.0472251\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2749, Accuracy: 2304/5000 (46%)\n",
      "[epoch 18] loss: 0.0238075\n",
      "Test set: Average loss: 2.2260, Accuracy: 2317/5000 (46%)\n",
      "[epoch 19] loss: 0.0199447\n",
      "Test set: Average loss: 2.2422, Accuracy: 2318/5000 (46%)\n",
      "[epoch 20] loss: 0.0181924\n",
      "Test set: Average loss: 2.2204, Accuracy: 2341/5000 (47%)\n",
      "[epoch 21] loss: 0.0162210\n",
      "Test set: Average loss: 2.2038, Accuracy: 2356/5000 (47%)\n",
      "[epoch 22] loss: 0.0153416\n",
      "Test set: Average loss: 2.2020, Accuracy: 2341/5000 (47%)\n",
      "[epoch 23] loss: 0.0149675\n",
      "Test set: Average loss: 2.2050, Accuracy: 2350/5000 (47%)\n",
      "[epoch 24] loss: 0.0146931\n",
      "Test set: Average loss: 2.2121, Accuracy: 2337/5000 (47%)\n",
      "[epoch 25] loss: 0.0143351\n",
      "Test set: Average loss: 2.2189, Accuracy: 2340/5000 (47%)\n",
      "[epoch 26] loss: 0.0139114\n",
      "Test set: Average loss: 2.2274, Accuracy: 2347/5000 (47%)\n",
      "[epoch 27] loss: 0.0136836\n",
      "Test set: Average loss: 2.2308, Accuracy: 2344/5000 (47%)\n",
      "[epoch 28] loss: 0.0133361\n",
      "Test set: Average loss: 2.2345, Accuracy: 2342/5000 (47%)\n",
      "[epoch 29] loss: 0.0130671\n",
      "Test set: Average loss: 2.2371, Accuracy: 2342/5000 (47%)\n",
      "[epoch 30] loss: 0.0130826\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.2443, Accuracy: 2337/5000 (47%)\n",
      "[epoch 31] loss: 0.0126950\n",
      "Test set: Average loss: 2.2446, Accuracy: 2336/5000 (47%)\n",
      "[epoch 32] loss: 0.0126440\n",
      "Test set: Average loss: 2.2450, Accuracy: 2337/5000 (47%)\n",
      "[epoch 33] loss: 0.0125311\n",
      "Test set: Average loss: 2.2455, Accuracy: 2337/5000 (47%)\n",
      "[epoch 34] loss: 0.0125185\n",
      "Test set: Average loss: 2.2459, Accuracy: 2337/5000 (47%)\n",
      "[epoch 35] loss: 0.0125885\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.2464, Accuracy: 2338/5000 (47%)\n",
      "[epoch 36] loss: 0.0127401\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 37] loss: 0.0126095\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 38] loss: 0.0125627\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 39] loss: 0.0125210\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 40] loss: 0.0125624\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 41] loss: 0.0125246\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 42] loss: 0.0125102\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 43] loss: 0.0125184\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 44] loss: 0.0124856\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 45] loss: 0.0125196\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 46] loss: 0.0124903\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 47] loss: 0.0126284\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 48] loss: 0.0124961\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 49] loss: 0.0125676\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "[epoch 50] loss: 0.0124501\n",
      "Test set: Average loss: 2.2465, Accuracy: 2338/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4353, Accuracy: 2462/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 1.4014, Accuracy: 5098/10000 (51%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 522/5000 (10%)\n",
      "[epoch 1] loss: 2.1158891\n",
      "Test set: Average loss: 1.8744, Accuracy: 1804/5000 (36%)\n",
      "[epoch 2] loss: 1.5275815\n",
      "Test set: Average loss: 1.6280, Accuracy: 2183/5000 (44%)\n",
      "[epoch 3] loss: 1.2190074\n",
      "Test set: Average loss: 1.5550, Accuracy: 2212/5000 (44%)\n",
      "[epoch 4] loss: 0.9361018\n",
      "Test set: Average loss: 1.5718, Accuracy: 2249/5000 (45%)\n",
      "[epoch 5] loss: 0.7726276\n",
      "Test set: Average loss: 1.5139, Accuracy: 2395/5000 (48%)\n",
      "[epoch 6] loss: 0.6144833\n",
      "Test set: Average loss: 1.5673, Accuracy: 2397/5000 (48%)\n",
      "[epoch 7] loss: 0.5624352\n",
      "Test set: Average loss: 1.6718, Accuracy: 2445/5000 (49%)\n",
      "[epoch 8] loss: 0.4148526\n",
      "Test set: Average loss: 1.8594, Accuracy: 2239/5000 (45%)\n",
      "[epoch 9] loss: 0.3877480\n",
      "Test set: Average loss: 1.8161, Accuracy: 2346/5000 (47%)\n",
      "[epoch 10] loss: 0.2518034\n",
      "Test set: Average loss: 1.7759, Accuracy: 2435/5000 (49%)\n",
      "[epoch 11] loss: 0.2011686\n",
      "Test set: Average loss: 1.8697, Accuracy: 2445/5000 (49%)\n",
      "[epoch 12] loss: 0.1610242\n",
      "Test set: Average loss: 2.2394, Accuracy: 2155/5000 (43%)\n",
      "[epoch 13] loss: 0.1285739\n",
      "Test set: Average loss: 2.1080, Accuracy: 2349/5000 (47%)\n",
      "[epoch 14] loss: 0.0982165\n",
      "Test set: Average loss: 2.1488, Accuracy: 2375/5000 (48%)\n",
      "[epoch 15] loss: 0.0714343\n",
      "Test set: Average loss: 2.1765, Accuracy: 2393/5000 (48%)\n",
      "[epoch 16] loss: 0.0563571\n",
      "Test set: Average loss: 2.3149, Accuracy: 2335/5000 (47%)\n",
      "[epoch 17] loss: 0.0283206\n",
      "Test set: Average loss: 2.3398, Accuracy: 2380/5000 (48%)\n",
      "[epoch 18] loss: 0.0205337\n",
      "Test set: Average loss: 2.4019, Accuracy: 2337/5000 (47%)\n",
      "[epoch 19] loss: 0.0138025\n",
      "Test set: Average loss: 2.4346, Accuracy: 2337/5000 (47%)\n",
      "[epoch 20] loss: 0.0107430\n",
      "Test set: Average loss: 2.4425, Accuracy: 2355/5000 (47%)\n",
      "[epoch 21] loss: 0.0090199\n",
      "Test set: Average loss: 2.4985, Accuracy: 2352/5000 (47%)\n",
      "[epoch 22] loss: 0.0077738\n",
      "Test set: Average loss: 2.5339, Accuracy: 2360/5000 (47%)\n",
      "[epoch 23] loss: 0.0068252\n",
      "Test set: Average loss: 2.5408, Accuracy: 2357/5000 (47%)\n",
      "[epoch 24] loss: 0.0062505\n",
      "Test set: Average loss: 2.5654, Accuracy: 2354/5000 (47%)\n",
      "[epoch 25] loss: 0.0056250\n",
      "Test set: Average loss: 2.5883, Accuracy: 2356/5000 (47%)\n",
      "[epoch 26] loss: 0.0053050\n",
      "Test set: Average loss: 2.6167, Accuracy: 2354/5000 (47%)\n",
      "[epoch 27] loss: 0.0048698\n",
      "Test set: Average loss: 2.6394, Accuracy: 2349/5000 (47%)\n",
      "[epoch 28] loss: 0.0045296\n",
      "Test set: Average loss: 2.6545, Accuracy: 2344/5000 (47%)\n",
      "[epoch 29] loss: 0.0041999\n",
      "Test set: Average loss: 2.6840, Accuracy: 2357/5000 (47%)\n",
      "[epoch 30] loss: 0.0039523\n",
      "Test set: Average loss: 2.6985, Accuracy: 2349/5000 (47%)\n",
      "[epoch 31] loss: 0.0037273\n",
      "Test set: Average loss: 2.7067, Accuracy: 2353/5000 (47%)\n",
      "[epoch 32] loss: 0.0035180\n",
      "Test set: Average loss: 2.7268, Accuracy: 2346/5000 (47%)\n",
      "[epoch 33] loss: 0.0032768\n",
      "Test set: Average loss: 2.7429, Accuracy: 2349/5000 (47%)\n",
      "[epoch 34] loss: 0.0031271\n",
      "Test set: Average loss: 2.7547, Accuracy: 2350/5000 (47%)\n",
      "[epoch 35] loss: 0.0029534\n",
      "Test set: Average loss: 2.7783, Accuracy: 2350/5000 (47%)\n",
      "[epoch 36] loss: 0.0028649\n",
      "Test set: Average loss: 2.7899, Accuracy: 2357/5000 (47%)\n",
      "[epoch 37] loss: 0.0026711\n",
      "Test set: Average loss: 2.8018, Accuracy: 2348/5000 (47%)\n",
      "[epoch 38] loss: 0.0025652\n",
      "Test set: Average loss: 2.8126, Accuracy: 2342/5000 (47%)\n",
      "[epoch 39] loss: 0.0024357\n",
      "Test set: Average loss: 2.8250, Accuracy: 2353/5000 (47%)\n",
      "[epoch 40] loss: 0.0023373\n",
      "Test set: Average loss: 2.8445, Accuracy: 2339/5000 (47%)\n",
      "[epoch 41] loss: 0.0022307\n",
      "Test set: Average loss: 2.8578, Accuracy: 2336/5000 (47%)\n",
      "[epoch 42] loss: 0.0021207\n",
      "Test set: Average loss: 2.8650, Accuracy: 2351/5000 (47%)\n",
      "[epoch 43] loss: 0.0020382\n",
      "Test set: Average loss: 2.8754, Accuracy: 2341/5000 (47%)\n",
      "[epoch 44] loss: 0.0019538\n",
      "Test set: Average loss: 2.8903, Accuracy: 2338/5000 (47%)\n",
      "[epoch 45] loss: 0.0018680\n",
      "Test set: Average loss: 2.8997, Accuracy: 2330/5000 (47%)\n",
      "[epoch 46] loss: 0.0018030\n",
      "Test set: Average loss: 2.9152, Accuracy: 2346/5000 (47%)\n",
      "[epoch 47] loss: 0.0017265\n",
      "Test set: Average loss: 2.9223, Accuracy: 2338/5000 (47%)\n",
      "[epoch 48] loss: 0.0016598\n",
      "Test set: Average loss: 2.9310, Accuracy: 2335/5000 (47%)\n",
      "[epoch 49] loss: 0.0015927\n",
      "Test set: Average loss: 2.9441, Accuracy: 2337/5000 (47%)\n",
      "[epoch 50] loss: 0.0015517\n",
      "Test set: Average loss: 2.9548, Accuracy: 2348/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8697, Accuracy: 2445/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 1.8219, Accuracy: 4963/10000 (50%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 508/5000 (10%)\n",
      "[epoch 1] loss: 2.2029165\n",
      "Test set: Average loss: 1.9683, Accuracy: 1734/5000 (35%)\n",
      "[epoch 2] loss: 1.7377496\n",
      "Test set: Average loss: 1.6424, Accuracy: 2101/5000 (42%)\n",
      "[epoch 3] loss: 1.4153308\n",
      "Test set: Average loss: 1.6129, Accuracy: 2092/5000 (42%)\n",
      "[epoch 4] loss: 1.1812365\n",
      "Test set: Average loss: 1.5385, Accuracy: 2221/5000 (44%)\n",
      "[epoch 5] loss: 0.9995370\n",
      "Test set: Average loss: 1.4662, Accuracy: 2390/5000 (48%)\n",
      "[epoch 6] loss: 0.7905991\n",
      "Test set: Average loss: 1.5267, Accuracy: 2444/5000 (49%)\n",
      "[epoch 7] loss: 0.6344402\n",
      "Test set: Average loss: 1.5855, Accuracy: 2375/5000 (48%)\n",
      "[epoch 8] loss: 0.5009061\n",
      "Test set: Average loss: 1.7176, Accuracy: 2310/5000 (46%)\n",
      "[epoch 9] loss: 0.4700002\n",
      "Test set: Average loss: 1.7689, Accuracy: 2337/5000 (47%)\n",
      "[epoch 10] loss: 0.3203738\n",
      "Test set: Average loss: 1.8420, Accuracy: 2376/5000 (48%)\n",
      "[epoch 11] loss: 0.2293173\n",
      "Test set: Average loss: 1.9402, Accuracy: 2310/5000 (46%)\n",
      "[epoch 12] loss: 0.1861860\n",
      "Test set: Average loss: 1.9523, Accuracy: 2370/5000 (47%)\n",
      "[epoch 13] loss: 0.1199983\n",
      "Test set: Average loss: 2.1165, Accuracy: 2325/5000 (46%)\n",
      "[epoch 14] loss: 0.0774630\n",
      "Test set: Average loss: 2.1480, Accuracy: 2343/5000 (47%)\n",
      "[epoch 15] loss: 0.0593085\n",
      "Test set: Average loss: 2.1451, Accuracy: 2393/5000 (48%)\n",
      "[epoch 16] loss: 0.0363401\n",
      "Test set: Average loss: 2.2492, Accuracy: 2344/5000 (47%)\n",
      "[epoch 17] loss: 0.0257539\n",
      "Test set: Average loss: 2.4667, Accuracy: 2318/5000 (46%)\n",
      "[epoch 18] loss: 0.0197471\n",
      "Test set: Average loss: 2.3626, Accuracy: 2356/5000 (47%)\n",
      "[epoch 19] loss: 0.0148188\n",
      "Test set: Average loss: 2.3972, Accuracy: 2355/5000 (47%)\n",
      "[epoch 20] loss: 0.0098498\n",
      "Test set: Average loss: 2.4507, Accuracy: 2370/5000 (47%)\n",
      "[epoch 21] loss: 0.0081008\n",
      "Test set: Average loss: 2.4756, Accuracy: 2348/5000 (47%)\n",
      "[epoch 22] loss: 0.0069922\n",
      "Test set: Average loss: 2.4747, Accuracy: 2375/5000 (48%)\n",
      "[epoch 23] loss: 0.0059175\n",
      "Test set: Average loss: 2.4964, Accuracy: 2371/5000 (47%)\n",
      "[epoch 24] loss: 0.0053304\n",
      "Test set: Average loss: 2.5320, Accuracy: 2364/5000 (47%)\n",
      "[epoch 25] loss: 0.0048332\n",
      "Test set: Average loss: 2.5541, Accuracy: 2359/5000 (47%)\n",
      "[epoch 26] loss: 0.0044844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.5687, Accuracy: 2354/5000 (47%)\n",
      "[epoch 27] loss: 0.0041805\n",
      "Test set: Average loss: 2.5843, Accuracy: 2365/5000 (47%)\n",
      "[epoch 28] loss: 0.0038975\n",
      "Test set: Average loss: 2.5995, Accuracy: 2362/5000 (47%)\n",
      "[epoch 29] loss: 0.0036109\n",
      "Test set: Average loss: 2.6167, Accuracy: 2361/5000 (47%)\n",
      "[epoch 30] loss: 0.0034265\n",
      "Test set: Average loss: 2.6330, Accuracy: 2361/5000 (47%)\n",
      "[epoch 31] loss: 0.0032043\n",
      "Test set: Average loss: 2.6457, Accuracy: 2356/5000 (47%)\n",
      "[epoch 32] loss: 0.0030245\n",
      "Test set: Average loss: 2.6689, Accuracy: 2359/5000 (47%)\n",
      "[epoch 33] loss: 0.0028402\n",
      "Test set: Average loss: 2.6770, Accuracy: 2352/5000 (47%)\n",
      "[epoch 34] loss: 0.0026979\n",
      "Test set: Average loss: 2.6855, Accuracy: 2354/5000 (47%)\n",
      "[epoch 35] loss: 0.0025773\n",
      "Test set: Average loss: 2.7033, Accuracy: 2356/5000 (47%)\n",
      "[epoch 36] loss: 0.0024559\n",
      "Test set: Average loss: 2.7167, Accuracy: 2348/5000 (47%)\n",
      "[epoch 37] loss: 0.0023340\n",
      "Test set: Average loss: 2.7266, Accuracy: 2348/5000 (47%)\n",
      "[epoch 38] loss: 0.0022407\n",
      "Test set: Average loss: 2.7388, Accuracy: 2351/5000 (47%)\n",
      "[epoch 39] loss: 0.0021442\n",
      "Test set: Average loss: 2.7567, Accuracy: 2353/5000 (47%)\n",
      "[epoch 40] loss: 0.0020420\n",
      "Test set: Average loss: 2.7648, Accuracy: 2354/5000 (47%)\n",
      "[epoch 41] loss: 0.0019614\n",
      "Test set: Average loss: 2.7721, Accuracy: 2341/5000 (47%)\n",
      "[epoch 42] loss: 0.0018713\n",
      "Test set: Average loss: 2.7833, Accuracy: 2349/5000 (47%)\n",
      "[epoch 43] loss: 0.0017965\n",
      "Test set: Average loss: 2.7981, Accuracy: 2352/5000 (47%)\n",
      "[epoch 44] loss: 0.0017202\n",
      "Test set: Average loss: 2.8075, Accuracy: 2356/5000 (47%)\n",
      "[epoch 45] loss: 0.0016583\n",
      "Test set: Average loss: 2.8142, Accuracy: 2349/5000 (47%)\n",
      "[epoch 46] loss: 0.0015816\n",
      "Test set: Average loss: 2.8222, Accuracy: 2347/5000 (47%)\n",
      "[epoch 47] loss: 0.0015259\n",
      "Test set: Average loss: 2.8368, Accuracy: 2351/5000 (47%)\n",
      "[epoch 48] loss: 0.0014796\n",
      "Test set: Average loss: 2.8469, Accuracy: 2352/5000 (47%)\n",
      "[epoch 49] loss: 0.0014505\n",
      "Test set: Average loss: 2.8486, Accuracy: 2347/5000 (47%)\n",
      "[epoch 50] loss: 0.0013825\n",
      "Test set: Average loss: 2.8630, Accuracy: 2345/5000 (47%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5267, Accuracy: 2444/5000 (49%)\n",
      "Test\n",
      "Test set: Average loss: 1.5195, Accuracy: 4855/10000 (49%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3056, Accuracy: 501/5000 (10%)\n",
      "[epoch 1] loss: 1.9605558\n",
      "Test set: Average loss: 1.7452, Accuracy: 1876/5000 (38%)\n",
      "[epoch 2] loss: 1.4386757\n",
      "Test set: Average loss: 1.4728, Accuracy: 2286/5000 (46%)\n",
      "[epoch 3] loss: 1.1317217\n",
      "Test set: Average loss: 1.3549, Accuracy: 2630/5000 (53%)\n",
      "[epoch 4] loss: 0.9728287\n",
      "Test set: Average loss: 1.5365, Accuracy: 2476/5000 (50%)\n",
      "[epoch 5] loss: 0.9098447\n",
      "Test set: Average loss: 1.4260, Accuracy: 2583/5000 (52%)\n",
      "[epoch 6] loss: 0.7154979\n",
      "Test set: Average loss: 1.4801, Accuracy: 2581/5000 (52%)\n",
      "[epoch 7] loss: 0.5715203\n",
      "Test set: Average loss: 1.6150, Accuracy: 2575/5000 (52%)\n",
      "[epoch 8] loss: 0.5080663\n",
      "Test set: Average loss: 1.7751, Accuracy: 2455/5000 (49%)\n",
      "[epoch 9] loss: 0.3417727\n",
      "Test set: Average loss: 1.7792, Accuracy: 2503/5000 (50%)\n",
      "[epoch 10] loss: 0.2121331\n",
      "Test set: Average loss: 1.8932, Accuracy: 2544/5000 (51%)\n",
      "[epoch 11] loss: 0.1952221\n",
      "Test set: Average loss: 2.0635, Accuracy: 2480/5000 (50%)\n",
      "[epoch 12] loss: 0.1361236\n",
      "Test set: Average loss: 2.1107, Accuracy: 2527/5000 (51%)\n",
      "[epoch 13] loss: 0.1003676\n",
      "Test set: Average loss: 2.2755, Accuracy: 2415/5000 (48%)\n",
      "[epoch 14] loss: 0.1296090\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2621, Accuracy: 2498/5000 (50%)\n",
      "[epoch 15] loss: 0.0489925\n",
      "Test set: Average loss: 2.2134, Accuracy: 2537/5000 (51%)\n",
      "[epoch 16] loss: 0.0331623\n",
      "Test set: Average loss: 2.2060, Accuracy: 2538/5000 (51%)\n",
      "[epoch 17] loss: 0.0282695\n",
      "Test set: Average loss: 2.2064, Accuracy: 2539/5000 (51%)\n",
      "[epoch 18] loss: 0.0265923\n",
      "Test set: Average loss: 2.2094, Accuracy: 2546/5000 (51%)\n",
      "[epoch 19] loss: 0.0240997\n",
      "Test set: Average loss: 2.2179, Accuracy: 2554/5000 (51%)\n",
      "[epoch 20] loss: 0.0225843\n",
      "Test set: Average loss: 2.2266, Accuracy: 2557/5000 (51%)\n",
      "[epoch 21] loss: 0.0214391\n",
      "Test set: Average loss: 2.2319, Accuracy: 2563/5000 (51%)\n",
      "[epoch 22] loss: 0.0211677\n",
      "Test set: Average loss: 2.2392, Accuracy: 2569/5000 (51%)\n",
      "[epoch 23] loss: 0.0198568\n",
      "Test set: Average loss: 2.2512, Accuracy: 2560/5000 (51%)\n",
      "[epoch 24] loss: 0.0190194\n",
      "Test set: Average loss: 2.2551, Accuracy: 2558/5000 (51%)\n",
      "[epoch 25] loss: 0.0182414\n",
      "Test set: Average loss: 2.2612, Accuracy: 2568/5000 (51%)\n",
      "[epoch 26] loss: 0.0174274\n",
      "Test set: Average loss: 2.2711, Accuracy: 2560/5000 (51%)\n",
      "[epoch 27] loss: 0.0167711\n",
      "Test set: Average loss: 2.2805, Accuracy: 2559/5000 (51%)\n",
      "[epoch 28] loss: 0.0161219\n",
      "Test set: Average loss: 2.2874, Accuracy: 2563/5000 (51%)\n",
      "[epoch 29] loss: 0.0154938\n",
      "Test set: Average loss: 2.2947, Accuracy: 2564/5000 (51%)\n",
      "[epoch 30] loss: 0.0151999\n",
      "Test set: Average loss: 2.3016, Accuracy: 2566/5000 (51%)\n",
      "[epoch 31] loss: 0.0147621\n",
      "Test set: Average loss: 2.3093, Accuracy: 2567/5000 (51%)\n",
      "[epoch 32] loss: 0.0140400\n",
      "Test set: Average loss: 2.3168, Accuracy: 2564/5000 (51%)\n",
      "[epoch 33] loss: 0.0137567\n",
      "Test set: Average loss: 2.3240, Accuracy: 2562/5000 (51%)\n",
      "[epoch 34] loss: 0.0133664\n",
      "Test set: Average loss: 2.3315, Accuracy: 2561/5000 (51%)\n",
      "[epoch 35] loss: 0.0128089\n",
      "Test set: Average loss: 2.3373, Accuracy: 2557/5000 (51%)\n",
      "[epoch 36] loss: 0.0125688\n",
      "Test set: Average loss: 2.3444, Accuracy: 2557/5000 (51%)\n",
      "[epoch 37] loss: 0.0122418\n",
      "Test set: Average loss: 2.3528, Accuracy: 2559/5000 (51%)\n",
      "[epoch 38] loss: 0.0117289\n",
      "Test set: Average loss: 2.3590, Accuracy: 2565/5000 (51%)\n",
      "[epoch 39] loss: 0.0115809\n",
      "Test set: Average loss: 2.3696, Accuracy: 2560/5000 (51%)\n",
      "[epoch 40] loss: 0.0112905\n",
      "Test set: Average loss: 2.3761, Accuracy: 2561/5000 (51%)\n",
      "[epoch 41] loss: 0.0108857\n",
      "Test set: Average loss: 2.3784, Accuracy: 2563/5000 (51%)\n",
      "[epoch 42] loss: 0.0107472\n",
      "Test set: Average loss: 2.3899, Accuracy: 2555/5000 (51%)\n",
      "[epoch 43] loss: 0.0104059\n",
      "Test set: Average loss: 2.3951, Accuracy: 2556/5000 (51%)\n",
      "[epoch 44] loss: 0.0101023\n",
      "Test set: Average loss: 2.3987, Accuracy: 2560/5000 (51%)\n",
      "[epoch 45] loss: 0.0099854\n",
      "Test set: Average loss: 2.4094, Accuracy: 2548/5000 (51%)\n",
      "[epoch 46] loss: 0.0096543\n",
      "Test set: Average loss: 2.4170, Accuracy: 2562/5000 (51%)\n",
      "[epoch 47] loss: 0.0093375\n",
      "Test set: Average loss: 2.4220, Accuracy: 2561/5000 (51%)\n",
      "[epoch 48] loss: 0.0091271\n",
      "Test set: Average loss: 2.4296, Accuracy: 2557/5000 (51%)\n",
      "[epoch 49] loss: 0.0089769\n",
      "Test set: Average loss: 2.4340, Accuracy: 2559/5000 (51%)\n",
      "[epoch 50] loss: 0.0087962\n",
      "Test set: Average loss: 2.4427, Accuracy: 2556/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3549, Accuracy: 2630/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.3212, Accuracy: 5476/10000 (55%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3018, Accuracy: 479/5000 (10%)\n",
      "[epoch 1] loss: 1.9171216\n",
      "Test set: Average loss: 1.6204, Accuracy: 2216/5000 (44%)\n",
      "[epoch 2] loss: 1.3687612\n",
      "Test set: Average loss: 1.5893, Accuracy: 2203/5000 (44%)\n",
      "[epoch 3] loss: 1.1220452\n",
      "Test set: Average loss: 1.4962, Accuracy: 2331/5000 (47%)\n",
      "[epoch 4] loss: 0.9854667\n",
      "Test set: Average loss: 1.4078, Accuracy: 2537/5000 (51%)\n",
      "[epoch 5] loss: 0.7723374\n",
      "Test set: Average loss: 1.4724, Accuracy: 2502/5000 (50%)\n",
      "[epoch 6] loss: 0.6075299\n",
      "Test set: Average loss: 1.4007, Accuracy: 2721/5000 (54%)\n",
      "[epoch 7] loss: 0.4925290\n",
      "Test set: Average loss: 1.6039, Accuracy: 2553/5000 (51%)\n",
      "[epoch 8] loss: 0.4441628\n",
      "Test set: Average loss: 1.7118, Accuracy: 2509/5000 (50%)\n",
      "[epoch 9] loss: 0.3539400\n",
      "Test set: Average loss: 1.6558, Accuracy: 2649/5000 (53%)\n",
      "[epoch 10] loss: 0.2473642\n",
      "Test set: Average loss: 2.0415, Accuracy: 2402/5000 (48%)\n",
      "[epoch 11] loss: 0.1971103\n",
      "Test set: Average loss: 1.9529, Accuracy: 2536/5000 (51%)\n",
      "[epoch 12] loss: 0.1736604\n",
      "Test set: Average loss: 2.0509, Accuracy: 2479/5000 (50%)\n",
      "[epoch 13] loss: 0.1947627\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2582, Accuracy: 2346/5000 (47%)\n",
      "[epoch 14] loss: 0.1095612\n",
      "Test set: Average loss: 2.0537, Accuracy: 2559/5000 (51%)\n",
      "[epoch 15] loss: 0.0454898\n",
      "Test set: Average loss: 2.0322, Accuracy: 2593/5000 (52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 0.0391148\n",
      "Test set: Average loss: 2.0138, Accuracy: 2617/5000 (52%)\n",
      "[epoch 17] loss: 0.0351116\n",
      "Test set: Average loss: 2.0107, Accuracy: 2625/5000 (52%)\n",
      "[epoch 18] loss: 0.0328137\n",
      "Test set: Average loss: 2.0152, Accuracy: 2617/5000 (52%)\n",
      "[epoch 19] loss: 0.0307889\n",
      "Test set: Average loss: 2.0247, Accuracy: 2619/5000 (52%)\n",
      "[epoch 20] loss: 0.0296874\n",
      "Test set: Average loss: 2.0311, Accuracy: 2620/5000 (52%)\n",
      "[epoch 21] loss: 0.0277527\n",
      "Test set: Average loss: 2.0383, Accuracy: 2618/5000 (52%)\n",
      "[epoch 22] loss: 0.0268578\n",
      "Test set: Average loss: 2.0458, Accuracy: 2625/5000 (52%)\n",
      "[epoch 23] loss: 0.0256223\n",
      "Test set: Average loss: 2.0532, Accuracy: 2622/5000 (52%)\n",
      "[epoch 24] loss: 0.0244505\n",
      "Test set: Average loss: 2.0628, Accuracy: 2632/5000 (53%)\n",
      "[epoch 25] loss: 0.0233373\n",
      "Test set: Average loss: 2.0703, Accuracy: 2633/5000 (53%)\n",
      "[epoch 26] loss: 0.0230718\n",
      "Test set: Average loss: 2.0763, Accuracy: 2634/5000 (53%)\n",
      "[epoch 27] loss: 0.0220240\n",
      "Test set: Average loss: 2.0876, Accuracy: 2630/5000 (53%)\n",
      "[epoch 28] loss: 0.0211085\n",
      "Test set: Average loss: 2.0943, Accuracy: 2629/5000 (53%)\n",
      "[epoch 29] loss: 0.0204076\n",
      "Test set: Average loss: 2.1018, Accuracy: 2620/5000 (52%)\n",
      "[epoch 30] loss: 0.0195320\n",
      "Test set: Average loss: 2.1094, Accuracy: 2631/5000 (53%)\n",
      "[epoch 31] loss: 0.0190231\n",
      "Test set: Average loss: 2.1163, Accuracy: 2628/5000 (53%)\n",
      "[epoch 32] loss: 0.0181126\n",
      "Test set: Average loss: 2.1256, Accuracy: 2630/5000 (53%)\n",
      "[epoch 33] loss: 0.0176427\n",
      "Test set: Average loss: 2.1386, Accuracy: 2622/5000 (52%)\n",
      "[epoch 34] loss: 0.0171113\n",
      "Test set: Average loss: 2.1438, Accuracy: 2622/5000 (52%)\n",
      "[epoch 35] loss: 0.0165482\n",
      "Test set: Average loss: 2.1480, Accuracy: 2630/5000 (53%)\n",
      "[epoch 36] loss: 0.0159767\n",
      "Test set: Average loss: 2.1589, Accuracy: 2632/5000 (53%)\n",
      "[epoch 37] loss: 0.0154645\n",
      "Test set: Average loss: 2.1649, Accuracy: 2624/5000 (52%)\n",
      "[epoch 38] loss: 0.0151506\n",
      "Test set: Average loss: 2.1751, Accuracy: 2633/5000 (53%)\n",
      "[epoch 39] loss: 0.0146707\n",
      "Test set: Average loss: 2.1825, Accuracy: 2633/5000 (53%)\n",
      "[epoch 40] loss: 0.0141772\n",
      "Test set: Average loss: 2.1886, Accuracy: 2631/5000 (53%)\n",
      "[epoch 41] loss: 0.0137205\n",
      "Test set: Average loss: 2.1971, Accuracy: 2626/5000 (53%)\n",
      "[epoch 42] loss: 0.0132922\n",
      "Test set: Average loss: 2.2030, Accuracy: 2630/5000 (53%)\n",
      "[epoch 43] loss: 0.0130494\n",
      "Test set: Average loss: 2.2103, Accuracy: 2632/5000 (53%)\n",
      "[epoch 44] loss: 0.0126777\n",
      "Test set: Average loss: 2.2187, Accuracy: 2632/5000 (53%)\n",
      "[epoch 45] loss: 0.0124750\n",
      "Test set: Average loss: 2.2266, Accuracy: 2642/5000 (53%)\n",
      "[epoch 46] loss: 0.0119001\n",
      "Test set: Average loss: 2.2344, Accuracy: 2625/5000 (52%)\n",
      "[epoch 47] loss: 0.0115846\n",
      "Test set: Average loss: 2.2411, Accuracy: 2631/5000 (53%)\n",
      "[epoch 48] loss: 0.0114135\n",
      "Test set: Average loss: 2.2476, Accuracy: 2633/5000 (53%)\n",
      "[epoch 49] loss: 0.0110791\n",
      "Test set: Average loss: 2.2546, Accuracy: 2632/5000 (53%)\n",
      "[epoch 50] loss: 0.0106926\n",
      "Test set: Average loss: 2.2595, Accuracy: 2625/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4007, Accuracy: 2721/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.3895, Accuracy: 5476/10000 (55%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2994, Accuracy: 771/5000 (15%)\n",
      "[epoch 1] loss: 2.0019938\n",
      "Test set: Average loss: 1.6247, Accuracy: 2139/5000 (43%)\n",
      "[epoch 2] loss: 1.4821850\n",
      "Test set: Average loss: 1.4698, Accuracy: 2350/5000 (47%)\n",
      "[epoch 3] loss: 1.2469583\n",
      "Test set: Average loss: 1.3886, Accuracy: 2531/5000 (51%)\n",
      "[epoch 4] loss: 1.0166554\n",
      "Test set: Average loss: 1.3908, Accuracy: 2593/5000 (52%)\n",
      "[epoch 5] loss: 0.8473271\n",
      "Test set: Average loss: 1.5065, Accuracy: 2556/5000 (51%)\n",
      "[epoch 6] loss: 0.6797744\n",
      "Test set: Average loss: 1.5122, Accuracy: 2631/5000 (53%)\n",
      "[epoch 7] loss: 0.5296654\n",
      "Test set: Average loss: 1.5070, Accuracy: 2651/5000 (53%)\n",
      "[epoch 8] loss: 0.4405257\n",
      "Test set: Average loss: 1.7360, Accuracy: 2525/5000 (50%)\n",
      "[epoch 9] loss: 0.3480220\n",
      "Test set: Average loss: 1.8594, Accuracy: 2404/5000 (48%)\n",
      "[epoch 10] loss: 0.2950956\n",
      "Test set: Average loss: 1.9224, Accuracy: 2487/5000 (50%)\n",
      "[epoch 11] loss: 0.2277152\n",
      "Test set: Average loss: 2.0082, Accuracy: 2494/5000 (50%)\n",
      "[epoch 12] loss: 0.2040652\n",
      "Test set: Average loss: 2.1134, Accuracy: 2471/5000 (49%)\n",
      "[epoch 13] loss: 0.1757747\n",
      "Test set: Average loss: 2.1675, Accuracy: 2487/5000 (50%)\n",
      "[epoch 14] loss: 0.0903360\n",
      "Test set: Average loss: 2.3163, Accuracy: 2435/5000 (49%)\n",
      "[epoch 15] loss: 0.0916684\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4601, Accuracy: 2402/5000 (48%)\n",
      "[epoch 16] loss: 0.0514160\n",
      "Test set: Average loss: 2.3612, Accuracy: 2471/5000 (49%)\n",
      "[epoch 17] loss: 0.0235745\n",
      "Test set: Average loss: 2.3478, Accuracy: 2512/5000 (50%)\n",
      "[epoch 18] loss: 0.0191542\n",
      "Test set: Average loss: 2.3514, Accuracy: 2511/5000 (50%)\n",
      "[epoch 19] loss: 0.0168944\n",
      "Test set: Average loss: 2.3562, Accuracy: 2523/5000 (50%)\n",
      "[epoch 20] loss: 0.0158200\n",
      "Test set: Average loss: 2.3600, Accuracy: 2516/5000 (50%)\n",
      "[epoch 21] loss: 0.0152089\n",
      "Test set: Average loss: 2.3671, Accuracy: 2520/5000 (50%)\n",
      "[epoch 22] loss: 0.0142416\n",
      "Test set: Average loss: 2.3746, Accuracy: 2519/5000 (50%)\n",
      "[epoch 23] loss: 0.0136648\n",
      "Test set: Average loss: 2.3832, Accuracy: 2519/5000 (50%)\n",
      "[epoch 24] loss: 0.0132974\n",
      "Test set: Average loss: 2.3883, Accuracy: 2519/5000 (50%)\n",
      "[epoch 25] loss: 0.0125966\n",
      "Test set: Average loss: 2.3960, Accuracy: 2515/5000 (50%)\n",
      "[epoch 26] loss: 0.0122823\n",
      "Test set: Average loss: 2.4044, Accuracy: 2517/5000 (50%)\n",
      "[epoch 27] loss: 0.0117390\n",
      "Test set: Average loss: 2.4120, Accuracy: 2518/5000 (50%)\n",
      "[epoch 28] loss: 0.0114067\n",
      "Test set: Average loss: 2.4183, Accuracy: 2518/5000 (50%)\n",
      "[epoch 29] loss: 0.0109853\n",
      "Test set: Average loss: 2.4248, Accuracy: 2514/5000 (50%)\n",
      "[epoch 30] loss: 0.0107640\n",
      "Test set: Average loss: 2.4318, Accuracy: 2513/5000 (50%)\n",
      "[epoch 31] loss: 0.0104359\n",
      "Test set: Average loss: 2.4382, Accuracy: 2511/5000 (50%)\n",
      "[epoch 32] loss: 0.0102774\n",
      "Test set: Average loss: 2.4464, Accuracy: 2510/5000 (50%)\n",
      "[epoch 33] loss: 0.0098952\n",
      "Test set: Average loss: 2.4530, Accuracy: 2516/5000 (50%)\n",
      "[epoch 34] loss: 0.0096002\n",
      "Test set: Average loss: 2.4581, Accuracy: 2514/5000 (50%)\n",
      "[epoch 35] loss: 0.0093536\n",
      "Test set: Average loss: 2.4663, Accuracy: 2520/5000 (50%)\n",
      "[epoch 36] loss: 0.0091654\n",
      "Test set: Average loss: 2.4733, Accuracy: 2509/5000 (50%)\n",
      "[epoch 37] loss: 0.0089727\n",
      "Test set: Average loss: 2.4806, Accuracy: 2515/5000 (50%)\n",
      "[epoch 38] loss: 0.0086188\n",
      "Test set: Average loss: 2.4855, Accuracy: 2515/5000 (50%)\n",
      "[epoch 39] loss: 0.0084306\n",
      "Test set: Average loss: 2.4909, Accuracy: 2509/5000 (50%)\n",
      "[epoch 40] loss: 0.0082510\n",
      "Test set: Average loss: 2.4993, Accuracy: 2510/5000 (50%)\n",
      "[epoch 41] loss: 0.0080652\n",
      "Test set: Average loss: 2.5054, Accuracy: 2513/5000 (50%)\n",
      "[epoch 42] loss: 0.0079201\n",
      "Test set: Average loss: 2.5097, Accuracy: 2509/5000 (50%)\n",
      "[epoch 43] loss: 0.0076839\n",
      "Test set: Average loss: 2.5169, Accuracy: 2511/5000 (50%)\n",
      "[epoch 44] loss: 0.0075335\n",
      "Test set: Average loss: 2.5222, Accuracy: 2513/5000 (50%)\n",
      "[epoch 45] loss: 0.0073796\n",
      "Test set: Average loss: 2.5280, Accuracy: 2509/5000 (50%)\n",
      "[epoch 46] loss: 0.0072172\n",
      "Test set: Average loss: 2.5352, Accuracy: 2516/5000 (50%)\n",
      "[epoch 47] loss: 0.0070546\n",
      "Test set: Average loss: 2.5415, Accuracy: 2509/5000 (50%)\n",
      "[epoch 48] loss: 0.0068614\n",
      "Test set: Average loss: 2.5468, Accuracy: 2514/5000 (50%)\n",
      "[epoch 49] loss: 0.0068816\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5506, Accuracy: 2509/5000 (50%)\n",
      "[epoch 50] loss: 0.0066418\n",
      "Test set: Average loss: 2.5513, Accuracy: 2509/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5070, Accuracy: 2651/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.4857, Accuracy: 5315/10000 (53%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 564/5000 (11%)\n",
      "[epoch 1] loss: 1.8611123\n",
      "Test set: Average loss: 1.6079, Accuracy: 2147/5000 (43%)\n",
      "[epoch 2] loss: 1.3943876\n",
      "Test set: Average loss: 1.4326, Accuracy: 2333/5000 (47%)\n",
      "[epoch 3] loss: 1.1527949\n",
      "Test set: Average loss: 1.4867, Accuracy: 2463/5000 (49%)\n",
      "[epoch 4] loss: 1.0328672\n",
      "Test set: Average loss: 1.4020, Accuracy: 2599/5000 (52%)\n",
      "[epoch 5] loss: 0.8723599\n",
      "Test set: Average loss: 1.3311, Accuracy: 2794/5000 (56%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 0.7093242\n",
      "Test set: Average loss: 1.4857, Accuracy: 2646/5000 (53%)\n",
      "[epoch 7] loss: 0.5817199\n",
      "Test set: Average loss: 1.6272, Accuracy: 2589/5000 (52%)\n",
      "[epoch 8] loss: 0.4632516\n",
      "Test set: Average loss: 1.7601, Accuracy: 2657/5000 (53%)\n",
      "[epoch 9] loss: 0.3538466\n",
      "Test set: Average loss: 1.7882, Accuracy: 2630/5000 (53%)\n",
      "[epoch 10] loss: 0.2790193\n",
      "Test set: Average loss: 1.8552, Accuracy: 2702/5000 (54%)\n",
      "[epoch 11] loss: 0.2636599\n",
      "Test set: Average loss: 2.1582, Accuracy: 2468/5000 (49%)\n",
      "[epoch 12] loss: 0.2494385\n",
      "Test set: Average loss: 2.0971, Accuracy: 2560/5000 (51%)\n",
      "[epoch 13] loss: 0.1342247\n",
      "Test set: Average loss: 2.0992, Accuracy: 2648/5000 (53%)\n",
      "[epoch 14] loss: 0.1900281\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.4960, Accuracy: 2399/5000 (48%)\n",
      "[epoch 15] loss: 0.1144292\n",
      "Test set: Average loss: 2.2299, Accuracy: 2610/5000 (52%)\n",
      "[epoch 16] loss: 0.0520080\n",
      "Test set: Average loss: 2.1853, Accuracy: 2634/5000 (53%)\n",
      "[epoch 17] loss: 0.0402622\n",
      "Test set: Average loss: 2.1958, Accuracy: 2635/5000 (53%)\n",
      "[epoch 18] loss: 0.0359648\n",
      "Test set: Average loss: 2.2160, Accuracy: 2627/5000 (53%)\n",
      "[epoch 19] loss: 0.0315408\n",
      "Test set: Average loss: 2.2267, Accuracy: 2623/5000 (52%)\n",
      "[epoch 20] loss: 0.0289644\n",
      "Test set: Average loss: 2.2437, Accuracy: 2620/5000 (52%)\n",
      "[epoch 21] loss: 0.0264538\n",
      "Test set: Average loss: 2.2607, Accuracy: 2630/5000 (53%)\n",
      "[epoch 22] loss: 0.0250993\n",
      "Test set: Average loss: 2.2697, Accuracy: 2636/5000 (53%)\n",
      "[epoch 23] loss: 0.0234870\n",
      "Test set: Average loss: 2.2845, Accuracy: 2636/5000 (53%)\n",
      "[epoch 24] loss: 0.0224262\n",
      "Test set: Average loss: 2.2941, Accuracy: 2644/5000 (53%)\n",
      "[epoch 25] loss: 0.0205214\n",
      "Test set: Average loss: 2.3065, Accuracy: 2643/5000 (53%)\n",
      "[epoch 26] loss: 0.0197626\n",
      "Test set: Average loss: 2.3174, Accuracy: 2648/5000 (53%)\n",
      "[epoch 27] loss: 0.0186513\n",
      "Test set: Average loss: 2.3295, Accuracy: 2650/5000 (53%)\n",
      "[epoch 28] loss: 0.0177246\n",
      "Test set: Average loss: 2.3410, Accuracy: 2648/5000 (53%)\n",
      "[epoch 29] loss: 0.0169091\n",
      "Test set: Average loss: 2.3519, Accuracy: 2654/5000 (53%)\n",
      "[epoch 30] loss: 0.0161723\n",
      "Test set: Average loss: 2.3594, Accuracy: 2646/5000 (53%)\n",
      "[epoch 31] loss: 0.0155019\n",
      "Test set: Average loss: 2.3723, Accuracy: 2646/5000 (53%)\n",
      "[epoch 32] loss: 0.0150972\n",
      "Test set: Average loss: 2.3808, Accuracy: 2644/5000 (53%)\n",
      "[epoch 33] loss: 0.0142987\n",
      "Test set: Average loss: 2.3928, Accuracy: 2639/5000 (53%)\n",
      "[epoch 34] loss: 0.0139223\n",
      "Test set: Average loss: 2.4000, Accuracy: 2642/5000 (53%)\n",
      "[epoch 35] loss: 0.0134006\n",
      "Test set: Average loss: 2.4123, Accuracy: 2642/5000 (53%)\n",
      "[epoch 36] loss: 0.0127872\n",
      "Test set: Average loss: 2.4207, Accuracy: 2644/5000 (53%)\n",
      "[epoch 37] loss: 0.0122524\n",
      "Test set: Average loss: 2.4322, Accuracy: 2638/5000 (53%)\n",
      "[epoch 38] loss: 0.0118934\n",
      "Test set: Average loss: 2.4370, Accuracy: 2645/5000 (53%)\n",
      "[epoch 39] loss: 0.0116239\n",
      "Test set: Average loss: 2.4480, Accuracy: 2640/5000 (53%)\n",
      "[epoch 40] loss: 0.0110877\n",
      "Test set: Average loss: 2.4575, Accuracy: 2642/5000 (53%)\n",
      "[epoch 41] loss: 0.0107286\n",
      "Test set: Average loss: 2.4676, Accuracy: 2642/5000 (53%)\n",
      "[epoch 42] loss: 0.0102477\n",
      "Test set: Average loss: 2.4731, Accuracy: 2635/5000 (53%)\n",
      "[epoch 43] loss: 0.0100157\n",
      "Test set: Average loss: 2.4809, Accuracy: 2636/5000 (53%)\n",
      "[epoch 44] loss: 0.0096617\n",
      "Test set: Average loss: 2.4914, Accuracy: 2635/5000 (53%)\n",
      "[epoch 45] loss: 0.0093943\n",
      "Test set: Average loss: 2.4982, Accuracy: 2638/5000 (53%)\n",
      "[epoch 46] loss: 0.0092517\n",
      "Test set: Average loss: 2.5103, Accuracy: 2640/5000 (53%)\n",
      "[epoch 47] loss: 0.0089156\n",
      "Test set: Average loss: 2.5172, Accuracy: 2642/5000 (53%)\n",
      "[epoch 48] loss: 0.0085874\n",
      "Test set: Average loss: 2.5240, Accuracy: 2640/5000 (53%)\n",
      "[epoch 49] loss: 0.0083704\n",
      "Test set: Average loss: 2.5305, Accuracy: 2631/5000 (53%)\n",
      "[epoch 50] loss: 0.0082194\n",
      "Test set: Average loss: 2.5420, Accuracy: 2641/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3311, Accuracy: 2794/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.3083, Accuracy: 5593/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3058, Accuracy: 488/5000 (10%)\n",
      "[epoch 1] loss: 1.8528740\n",
      "Test set: Average loss: 1.6804, Accuracy: 1893/5000 (38%)\n",
      "[epoch 2] loss: 1.2838290\n",
      "Test set: Average loss: 1.4521, Accuracy: 2452/5000 (49%)\n",
      "[epoch 3] loss: 1.0744509\n",
      "Test set: Average loss: 1.6032, Accuracy: 2254/5000 (45%)\n",
      "[epoch 4] loss: 0.9161955\n",
      "Test set: Average loss: 1.4436, Accuracy: 2504/5000 (50%)\n",
      "[epoch 5] loss: 0.7761424\n",
      "Test set: Average loss: 1.5169, Accuracy: 2484/5000 (50%)\n",
      "[epoch 6] loss: 0.6060251\n",
      "Test set: Average loss: 1.6396, Accuracy: 2501/5000 (50%)\n",
      "[epoch 7] loss: 0.5328473\n",
      "Test set: Average loss: 1.6429, Accuracy: 2593/5000 (52%)\n",
      "[epoch 8] loss: 0.4201917\n",
      "Test set: Average loss: 1.7652, Accuracy: 2624/5000 (52%)\n",
      "[epoch 9] loss: 0.3754246\n",
      "Test set: Average loss: 1.8588, Accuracy: 2540/5000 (51%)\n",
      "[epoch 10] loss: 0.2948175\n",
      "Test set: Average loss: 1.9897, Accuracy: 2563/5000 (51%)\n",
      "[epoch 11] loss: 0.2848899\n",
      "Test set: Average loss: 2.0157, Accuracy: 2579/5000 (52%)\n",
      "[epoch 12] loss: 0.1732219\n",
      "Test set: Average loss: 2.2340, Accuracy: 2478/5000 (50%)\n",
      "[epoch 13] loss: 0.0902312\n",
      "Test set: Average loss: 2.2580, Accuracy: 2545/5000 (51%)\n",
      "[epoch 14] loss: 0.0665429\n",
      "Test set: Average loss: 2.4517, Accuracy: 2498/5000 (50%)\n",
      "[epoch 15] loss: 0.0549472\n",
      "Test set: Average loss: 2.5496, Accuracy: 2474/5000 (49%)\n",
      "[epoch 16] loss: 0.0386939\n",
      "Test set: Average loss: 2.5469, Accuracy: 2531/5000 (51%)\n",
      "[epoch 17] loss: 0.0286934\n",
      "Test set: Average loss: 2.5532, Accuracy: 2533/5000 (51%)\n",
      "[epoch 18] loss: 0.0149764\n",
      "Test set: Average loss: 2.5890, Accuracy: 2553/5000 (51%)\n",
      "[epoch 19] loss: 0.0078847\n",
      "Test set: Average loss: 2.6479, Accuracy: 2565/5000 (51%)\n",
      "[epoch 20] loss: 0.0061023\n",
      "Test set: Average loss: 2.6790, Accuracy: 2568/5000 (51%)\n",
      "[epoch 21] loss: 0.0054958\n",
      "Test set: Average loss: 2.7149, Accuracy: 2566/5000 (51%)\n",
      "[epoch 22] loss: 0.0047508\n",
      "Test set: Average loss: 2.7361, Accuracy: 2561/5000 (51%)\n",
      "[epoch 23] loss: 0.0042254\n",
      "Test set: Average loss: 2.7781, Accuracy: 2582/5000 (52%)\n",
      "[epoch 24] loss: 0.0038621\n",
      "Test set: Average loss: 2.7948, Accuracy: 2582/5000 (52%)\n",
      "[epoch 25] loss: 0.0034246\n",
      "Test set: Average loss: 2.8198, Accuracy: 2577/5000 (52%)\n",
      "[epoch 26] loss: 0.0031183\n",
      "Test set: Average loss: 2.8441, Accuracy: 2569/5000 (51%)\n",
      "[epoch 27] loss: 0.0029531\n",
      "Test set: Average loss: 2.8746, Accuracy: 2584/5000 (52%)\n",
      "[epoch 28] loss: 0.0026482\n",
      "Test set: Average loss: 2.8883, Accuracy: 2568/5000 (51%)\n",
      "[epoch 29] loss: 0.0024951\n",
      "Test set: Average loss: 2.9121, Accuracy: 2571/5000 (51%)\n",
      "[epoch 30] loss: 0.0023342\n",
      "Test set: Average loss: 2.9302, Accuracy: 2571/5000 (51%)\n",
      "[epoch 31] loss: 0.0022062\n",
      "Test set: Average loss: 2.9513, Accuracy: 2574/5000 (51%)\n",
      "[epoch 32] loss: 0.0021125\n",
      "Test set: Average loss: 2.9698, Accuracy: 2573/5000 (51%)\n",
      "[epoch 33] loss: 0.0019004\n",
      "Test set: Average loss: 2.9876, Accuracy: 2578/5000 (52%)\n",
      "[epoch 34] loss: 0.0017966\n",
      "Test set: Average loss: 3.0085, Accuracy: 2578/5000 (52%)\n",
      "[epoch 35] loss: 0.0017255\n",
      "Test set: Average loss: 3.0238, Accuracy: 2568/5000 (51%)\n",
      "[epoch 36] loss: 0.0016431\n",
      "Test set: Average loss: 3.0408, Accuracy: 2582/5000 (52%)\n",
      "[epoch 37] loss: 0.0015195\n",
      "Test set: Average loss: 3.0542, Accuracy: 2567/5000 (51%)\n",
      "[epoch 38] loss: 0.0014719\n",
      "Test set: Average loss: 3.0720, Accuracy: 2567/5000 (51%)\n",
      "[epoch 39] loss: 0.0013694\n",
      "Test set: Average loss: 3.0841, Accuracy: 2571/5000 (51%)\n",
      "[epoch 40] loss: 0.0013193\n",
      "Test set: Average loss: 3.1010, Accuracy: 2569/5000 (51%)\n",
      "[epoch 41] loss: 0.0012591\n",
      "Test set: Average loss: 3.1149, Accuracy: 2577/5000 (52%)\n",
      "[epoch 42] loss: 0.0012141\n",
      "Test set: Average loss: 3.1261, Accuracy: 2568/5000 (51%)\n",
      "[epoch 43] loss: 0.0011590\n",
      "Test set: Average loss: 3.1442, Accuracy: 2571/5000 (51%)\n",
      "[epoch 44] loss: 0.0010836\n",
      "Test set: Average loss: 3.1578, Accuracy: 2569/5000 (51%)\n",
      "[epoch 45] loss: 0.0010550\n",
      "Test set: Average loss: 3.1673, Accuracy: 2567/5000 (51%)\n",
      "[epoch 46] loss: 0.0010086\n",
      "Test set: Average loss: 3.1834, Accuracy: 2571/5000 (51%)\n",
      "[epoch 47] loss: 0.0009650\n",
      "Test set: Average loss: 3.1972, Accuracy: 2570/5000 (51%)\n",
      "[epoch 48] loss: 0.0009302\n",
      "Test set: Average loss: 3.2090, Accuracy: 2574/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 49] loss: 0.0009003\n",
      "Test set: Average loss: 3.2199, Accuracy: 2569/5000 (51%)\n",
      "[epoch 50] loss: 0.0008562\n",
      "Test set: Average loss: 3.2306, Accuracy: 2573/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7652, Accuracy: 2624/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.7461, Accuracy: 5271/10000 (53%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 447/5000 (9%)\n",
      "[epoch 1] loss: 1.9410066\n",
      "Test set: Average loss: 1.6560, Accuracy: 2033/5000 (41%)\n",
      "[epoch 2] loss: 1.4130136\n",
      "Test set: Average loss: 1.4405, Accuracy: 2441/5000 (49%)\n",
      "[epoch 3] loss: 1.2097369\n",
      "Test set: Average loss: 1.4766, Accuracy: 2480/5000 (50%)\n",
      "[epoch 4] loss: 1.1214132\n",
      "Test set: Average loss: 1.3937, Accuracy: 2620/5000 (52%)\n",
      "[epoch 5] loss: 0.8669518\n",
      "Test set: Average loss: 1.4129, Accuracy: 2583/5000 (52%)\n",
      "[epoch 6] loss: 0.7533212\n",
      "Test set: Average loss: 1.4497, Accuracy: 2616/5000 (52%)\n",
      "[epoch 7] loss: 0.6354630\n",
      "Test set: Average loss: 1.6020, Accuracy: 2564/5000 (51%)\n",
      "[epoch 8] loss: 0.5292028\n",
      "Test set: Average loss: 1.7006, Accuracy: 2514/5000 (50%)\n",
      "[epoch 9] loss: 0.4000272\n",
      "Test set: Average loss: 1.8287, Accuracy: 2433/5000 (49%)\n",
      "[epoch 10] loss: 0.3491417\n",
      "Test set: Average loss: 1.9318, Accuracy: 2493/5000 (50%)\n",
      "[epoch 11] loss: 0.2173081\n",
      "Test set: Average loss: 2.1015, Accuracy: 2475/5000 (50%)\n",
      "[epoch 12] loss: 0.1724560\n",
      "Test set: Average loss: 2.1584, Accuracy: 2544/5000 (51%)\n",
      "[epoch 13] loss: 0.1240842\n",
      "Test set: Average loss: 2.3668, Accuracy: 2384/5000 (48%)\n",
      "[epoch 14] loss: 0.1136575\n",
      "Test set: Average loss: 2.4391, Accuracy: 2474/5000 (49%)\n",
      "[epoch 15] loss: 0.0975999\n",
      "Test set: Average loss: 2.4949, Accuracy: 2500/5000 (50%)\n",
      "[epoch 16] loss: 0.0478977\n",
      "Test set: Average loss: 2.6762, Accuracy: 2436/5000 (49%)\n",
      "[epoch 17] loss: 0.0320927\n",
      "Test set: Average loss: 2.7360, Accuracy: 2481/5000 (50%)\n",
      "[epoch 18] loss: 0.0145251\n",
      "Test set: Average loss: 2.7003, Accuracy: 2492/5000 (50%)\n",
      "[epoch 19] loss: 0.0090222\n",
      "Test set: Average loss: 2.7562, Accuracy: 2506/5000 (50%)\n",
      "[epoch 20] loss: 0.0065975\n",
      "Test set: Average loss: 2.7947, Accuracy: 2508/5000 (50%)\n",
      "[epoch 21] loss: 0.0051028\n",
      "Test set: Average loss: 2.8269, Accuracy: 2509/5000 (50%)\n",
      "[epoch 22] loss: 0.0043047\n",
      "Test set: Average loss: 2.8589, Accuracy: 2513/5000 (50%)\n",
      "[epoch 23] loss: 0.0039062\n",
      "Test set: Average loss: 2.8822, Accuracy: 2499/5000 (50%)\n",
      "[epoch 24] loss: 0.0034363\n",
      "Test set: Average loss: 2.9073, Accuracy: 2514/5000 (50%)\n",
      "[epoch 25] loss: 0.0031432\n",
      "Test set: Average loss: 2.9358, Accuracy: 2506/5000 (50%)\n",
      "[epoch 26] loss: 0.0029041\n",
      "Test set: Average loss: 2.9557, Accuracy: 2503/5000 (50%)\n",
      "[epoch 27] loss: 0.0026859\n",
      "Test set: Average loss: 2.9739, Accuracy: 2512/5000 (50%)\n",
      "[epoch 28] loss: 0.0025404\n",
      "Test set: Average loss: 3.0009, Accuracy: 2503/5000 (50%)\n",
      "[epoch 29] loss: 0.0023625\n",
      "Test set: Average loss: 3.0192, Accuracy: 2508/5000 (50%)\n",
      "[epoch 30] loss: 0.0021516\n",
      "Test set: Average loss: 3.0338, Accuracy: 2507/5000 (50%)\n",
      "[epoch 31] loss: 0.0020384\n",
      "Test set: Average loss: 3.0557, Accuracy: 2506/5000 (50%)\n",
      "[epoch 32] loss: 0.0019192\n",
      "Test set: Average loss: 3.0702, Accuracy: 2504/5000 (50%)\n",
      "[epoch 33] loss: 0.0017855\n",
      "Test set: Average loss: 3.0874, Accuracy: 2507/5000 (50%)\n",
      "[epoch 34] loss: 0.0017462\n",
      "Test set: Average loss: 3.1046, Accuracy: 2510/5000 (50%)\n",
      "[epoch 35] loss: 0.0015925\n",
      "Test set: Average loss: 3.1165, Accuracy: 2501/5000 (50%)\n",
      "[epoch 36] loss: 0.0015289\n",
      "Test set: Average loss: 3.1386, Accuracy: 2511/5000 (50%)\n",
      "[epoch 37] loss: 0.0014699\n",
      "Test set: Average loss: 3.1522, Accuracy: 2504/5000 (50%)\n",
      "[epoch 38] loss: 0.0013700\n",
      "Test set: Average loss: 3.1674, Accuracy: 2502/5000 (50%)\n",
      "[epoch 39] loss: 0.0013227\n",
      "Test set: Average loss: 3.1787, Accuracy: 2501/5000 (50%)\n",
      "[epoch 40] loss: 0.0012422\n",
      "Test set: Average loss: 3.1956, Accuracy: 2505/5000 (50%)\n",
      "[epoch 41] loss: 0.0011917\n",
      "Test set: Average loss: 3.2082, Accuracy: 2505/5000 (50%)\n",
      "[epoch 42] loss: 0.0011421\n",
      "Test set: Average loss: 3.2210, Accuracy: 2500/5000 (50%)\n",
      "[epoch 43] loss: 0.0010901\n",
      "Test set: Average loss: 3.2349, Accuracy: 2509/5000 (50%)\n",
      "[epoch 44] loss: 0.0010368\n",
      "Test set: Average loss: 3.2464, Accuracy: 2505/5000 (50%)\n",
      "[epoch 45] loss: 0.0010294\n",
      "Test set: Average loss: 3.2561, Accuracy: 2504/5000 (50%)\n",
      "[epoch 46] loss: 0.0009537\n",
      "Test set: Average loss: 3.2741, Accuracy: 2504/5000 (50%)\n",
      "[epoch 47] loss: 0.0009143\n",
      "Test set: Average loss: 3.2855, Accuracy: 2507/5000 (50%)\n",
      "[epoch 48] loss: 0.0008896\n",
      "Test set: Average loss: 3.2962, Accuracy: 2505/5000 (50%)\n",
      "[epoch 49] loss: 0.0008380\n",
      "Test set: Average loss: 3.3088, Accuracy: 2506/5000 (50%)\n",
      "[epoch 50] loss: 0.0008110\n",
      "Test set: Average loss: 3.3194, Accuracy: 2500/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3937, Accuracy: 2620/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.3756, Accuracy: 5262/10000 (53%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3038, Accuracy: 353/5000 (7%)\n",
      "[epoch 1] loss: 1.7512350\n",
      "Test set: Average loss: 1.4687, Accuracy: 2409/5000 (48%)\n",
      "[epoch 2] loss: 1.2871018\n",
      "Test set: Average loss: 1.3377, Accuracy: 2634/5000 (53%)\n",
      "[epoch 3] loss: 1.0747783\n",
      "Test set: Average loss: 1.4657, Accuracy: 2390/5000 (48%)\n",
      "[epoch 4] loss: 0.9378738\n",
      "Test set: Average loss: 1.3368, Accuracy: 2712/5000 (54%)\n",
      "[epoch 5] loss: 0.7830909\n",
      "Test set: Average loss: 1.3610, Accuracy: 2785/5000 (56%)\n",
      "[epoch 6] loss: 0.6511814\n",
      "Test set: Average loss: 1.4654, Accuracy: 2724/5000 (54%)\n",
      "[epoch 7] loss: 0.6179461\n",
      "Test set: Average loss: 1.6399, Accuracy: 2651/5000 (53%)\n",
      "[epoch 8] loss: 0.5054427\n",
      "Test set: Average loss: 1.7959, Accuracy: 2556/5000 (51%)\n",
      "[epoch 9] loss: 0.5000298\n",
      "Test set: Average loss: 2.1044, Accuracy: 2335/5000 (47%)\n",
      "[epoch 10] loss: 0.3860317\n",
      "Test set: Average loss: 2.1065, Accuracy: 2506/5000 (50%)\n",
      "[epoch 11] loss: 0.3441539\n",
      "Test set: Average loss: 1.9902, Accuracy: 2575/5000 (52%)\n",
      "[epoch 12] loss: 0.2613409\n",
      "Test set: Average loss: 2.1114, Accuracy: 2573/5000 (51%)\n",
      "[epoch 13] loss: 0.1436345\n",
      "Test set: Average loss: 2.2712, Accuracy: 2532/5000 (51%)\n",
      "[epoch 14] loss: 0.0981513\n",
      "Test set: Average loss: 2.3975, Accuracy: 2577/5000 (52%)\n",
      "[epoch 15] loss: 0.0773547\n",
      "Test set: Average loss: 2.4169, Accuracy: 2609/5000 (52%)\n",
      "[epoch 16] loss: 0.0634440\n",
      "Test set: Average loss: 2.4969, Accuracy: 2579/5000 (52%)\n",
      "[epoch 17] loss: 0.0343149\n",
      "Test set: Average loss: 2.6347, Accuracy: 2575/5000 (52%)\n",
      "[epoch 18] loss: 0.0250800\n",
      "Test set: Average loss: 2.7236, Accuracy: 2603/5000 (52%)\n",
      "[epoch 19] loss: 0.0146215\n",
      "Test set: Average loss: 2.7255, Accuracy: 2617/5000 (52%)\n",
      "[epoch 20] loss: 0.0078067\n",
      "Test set: Average loss: 2.7703, Accuracy: 2622/5000 (52%)\n",
      "[epoch 21] loss: 0.0054596\n",
      "Test set: Average loss: 2.7984, Accuracy: 2627/5000 (53%)\n",
      "[epoch 22] loss: 0.0045356\n",
      "Test set: Average loss: 2.8390, Accuracy: 2621/5000 (52%)\n",
      "[epoch 23] loss: 0.0039159\n",
      "Test set: Average loss: 2.8820, Accuracy: 2630/5000 (53%)\n",
      "[epoch 24] loss: 0.0035836\n",
      "Test set: Average loss: 2.9082, Accuracy: 2632/5000 (53%)\n",
      "[epoch 25] loss: 0.0032803\n",
      "Test set: Average loss: 2.9355, Accuracy: 2625/5000 (52%)\n",
      "[epoch 26] loss: 0.0029597\n",
      "Test set: Average loss: 2.9640, Accuracy: 2630/5000 (53%)\n",
      "[epoch 27] loss: 0.0026855\n",
      "Test set: Average loss: 2.9877, Accuracy: 2633/5000 (53%)\n",
      "[epoch 28] loss: 0.0024508\n",
      "Test set: Average loss: 3.0098, Accuracy: 2626/5000 (53%)\n",
      "[epoch 29] loss: 0.0022297\n",
      "Test set: Average loss: 3.0357, Accuracy: 2632/5000 (53%)\n",
      "[epoch 30] loss: 0.0021373\n",
      "Test set: Average loss: 3.0556, Accuracy: 2635/5000 (53%)\n",
      "[epoch 31] loss: 0.0019242\n",
      "Test set: Average loss: 3.0743, Accuracy: 2630/5000 (53%)\n",
      "[epoch 32] loss: 0.0018322\n",
      "Test set: Average loss: 3.0962, Accuracy: 2631/5000 (53%)\n",
      "[epoch 33] loss: 0.0017132\n",
      "Test set: Average loss: 3.1145, Accuracy: 2626/5000 (53%)\n",
      "[epoch 34] loss: 0.0016139\n",
      "Test set: Average loss: 3.1322, Accuracy: 2628/5000 (53%)\n",
      "[epoch 35] loss: 0.0015437\n",
      "Test set: Average loss: 3.1539, Accuracy: 2631/5000 (53%)\n",
      "[epoch 36] loss: 0.0014468\n",
      "Test set: Average loss: 3.1725, Accuracy: 2625/5000 (52%)\n",
      "[epoch 37] loss: 0.0013650\n",
      "Test set: Average loss: 3.1916, Accuracy: 2626/5000 (53%)\n",
      "[epoch 38] loss: 0.0012962\n",
      "Test set: Average loss: 3.2051, Accuracy: 2625/5000 (52%)\n",
      "[epoch 39] loss: 0.0012323\n",
      "Test set: Average loss: 3.2220, Accuracy: 2624/5000 (52%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40] loss: 0.0011554\n",
      "Test set: Average loss: 3.2370, Accuracy: 2627/5000 (53%)\n",
      "[epoch 41] loss: 0.0011076\n",
      "Test set: Average loss: 3.2518, Accuracy: 2622/5000 (52%)\n",
      "[epoch 42] loss: 0.0010473\n",
      "Test set: Average loss: 3.2686, Accuracy: 2623/5000 (52%)\n",
      "[epoch 43] loss: 0.0009922\n",
      "Test set: Average loss: 3.2810, Accuracy: 2622/5000 (52%)\n",
      "[epoch 44] loss: 0.0009480\n",
      "Test set: Average loss: 3.2988, Accuracy: 2625/5000 (52%)\n",
      "[epoch 45] loss: 0.0009092\n",
      "Test set: Average loss: 3.3110, Accuracy: 2622/5000 (52%)\n",
      "[epoch 46] loss: 0.0008686\n",
      "Test set: Average loss: 3.3238, Accuracy: 2624/5000 (52%)\n",
      "[epoch 47] loss: 0.0008301\n",
      "Test set: Average loss: 3.3390, Accuracy: 2621/5000 (52%)\n",
      "[epoch 48] loss: 0.0007906\n",
      "Test set: Average loss: 3.3533, Accuracy: 2618/5000 (52%)\n",
      "[epoch 49] loss: 0.0007593\n",
      "Test set: Average loss: 3.3641, Accuracy: 2622/5000 (52%)\n",
      "[epoch 50] loss: 0.0007397\n",
      "Test set: Average loss: 3.3776, Accuracy: 2627/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3610, Accuracy: 2785/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.3285, Accuracy: 5624/10000 (56%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 492/5000 (10%)\n",
      "[epoch 1] loss: 1.7411767\n",
      "Test set: Average loss: 1.5910, Accuracy: 2096/5000 (42%)\n",
      "[epoch 2] loss: 1.2532697\n",
      "Test set: Average loss: 1.5667, Accuracy: 2344/5000 (47%)\n",
      "[epoch 3] loss: 1.0313902\n",
      "Test set: Average loss: 1.3585, Accuracy: 2681/5000 (54%)\n",
      "[epoch 4] loss: 0.8903079\n",
      "Test set: Average loss: 1.5440, Accuracy: 2548/5000 (51%)\n",
      "[epoch 5] loss: 0.7924332\n",
      "Test set: Average loss: 1.5116, Accuracy: 2598/5000 (52%)\n",
      "[epoch 6] loss: 0.7257711\n",
      "Test set: Average loss: 1.5388, Accuracy: 2585/5000 (52%)\n",
      "[epoch 7] loss: 0.6159471\n",
      "Test set: Average loss: 1.8835, Accuracy: 2364/5000 (47%)\n",
      "[epoch 8] loss: 0.5629794\n",
      "Test set: Average loss: 1.7331, Accuracy: 2601/5000 (52%)\n",
      "[epoch 9] loss: 0.4078911\n",
      "Test set: Average loss: 1.8764, Accuracy: 2475/5000 (50%)\n",
      "[epoch 10] loss: 0.3119118\n",
      "Test set: Average loss: 1.8969, Accuracy: 2574/5000 (51%)\n",
      "[epoch 11] loss: 0.2503112\n",
      "Test set: Average loss: 2.0322, Accuracy: 2597/5000 (52%)\n",
      "[epoch 12] loss: 0.1861767\n",
      "Test set: Average loss: 2.1739, Accuracy: 2562/5000 (51%)\n",
      "[epoch 13] loss: 0.1192863\n",
      "Test set: Average loss: 2.2651, Accuracy: 2536/5000 (51%)\n",
      "[epoch 14] loss: 0.1776280\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5259, Accuracy: 2414/5000 (48%)\n",
      "[epoch 15] loss: 0.0819996\n",
      "Test set: Average loss: 2.3582, Accuracy: 2532/5000 (51%)\n",
      "[epoch 16] loss: 0.0442354\n",
      "Test set: Average loss: 2.3655, Accuracy: 2547/5000 (51%)\n",
      "[epoch 17] loss: 0.0353829\n",
      "Test set: Average loss: 2.3680, Accuracy: 2560/5000 (51%)\n",
      "[epoch 18] loss: 0.0305263\n",
      "Test set: Average loss: 2.3819, Accuracy: 2564/5000 (51%)\n",
      "[epoch 19] loss: 0.0275945\n",
      "Test set: Average loss: 2.3924, Accuracy: 2562/5000 (51%)\n",
      "[epoch 20] loss: 0.0251979\n",
      "Test set: Average loss: 2.4216, Accuracy: 2552/5000 (51%)\n",
      "[epoch 21] loss: 0.0235918\n",
      "Test set: Average loss: 2.4146, Accuracy: 2565/5000 (51%)\n",
      "[epoch 22] loss: 0.0216579\n",
      "Test set: Average loss: 2.4303, Accuracy: 2559/5000 (51%)\n",
      "[epoch 23] loss: 0.0214070\n",
      "Test set: Average loss: 2.4415, Accuracy: 2578/5000 (52%)\n",
      "[epoch 24] loss: 0.0192223\n",
      "Test set: Average loss: 2.4569, Accuracy: 2574/5000 (51%)\n",
      "[epoch 25] loss: 0.0184116\n",
      "Test set: Average loss: 2.4648, Accuracy: 2575/5000 (52%)\n",
      "[epoch 26] loss: 0.3988813\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4851, Accuracy: 2555/5000 (51%)\n",
      "[epoch 27] loss: 0.0220868\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5022, Accuracy: 2538/5000 (51%)\n",
      "[epoch 28] loss: 0.0224513\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5011, Accuracy: 2541/5000 (51%)\n",
      "[epoch 29] loss: 0.0221449\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 30] loss: 0.0224714\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 31] loss: 0.0221120\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 32] loss: 0.0221195\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 33] loss: 0.0218529\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 34] loss: 0.0220021\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 35] loss: 0.0231030\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 36] loss: 0.0221935\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 37] loss: 0.0222573\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 38] loss: 0.0219000\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 39] loss: 0.0223692\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 40] loss: 0.0222201\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 41] loss: 0.0223608\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 42] loss: 0.0220029\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 43] loss: 0.0220865\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 44] loss: 0.0225694\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 45] loss: 0.0220919\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 46] loss: 0.0219534\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 47] loss: 0.0218475\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 48] loss: 0.0221648\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 49] loss: 0.0223634\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "[epoch 50] loss: 0.0223109\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.5010, Accuracy: 2541/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3585, Accuracy: 2681/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.3155, Accuracy: 5396/10000 (54%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3053, Accuracy: 532/5000 (11%)\n",
      "[epoch 1] loss: 1.8261043\n",
      "Test set: Average loss: 1.5890, Accuracy: 2161/5000 (43%)\n",
      "[epoch 2] loss: 1.3983746\n",
      "Test set: Average loss: 1.4923, Accuracy: 2343/5000 (47%)\n",
      "[epoch 3] loss: 1.1898547\n",
      "Test set: Average loss: 1.3636, Accuracy: 2601/5000 (52%)\n",
      "[epoch 4] loss: 0.9856977\n",
      "Test set: Average loss: 1.3929, Accuracy: 2635/5000 (53%)\n",
      "[epoch 5] loss: 0.9500132\n",
      "Test set: Average loss: 1.3784, Accuracy: 2672/5000 (53%)\n",
      "[epoch 6] loss: 0.7369626\n",
      "Test set: Average loss: 1.5336, Accuracy: 2562/5000 (51%)\n",
      "[epoch 7] loss: 0.6270147\n",
      "Test set: Average loss: 1.7555, Accuracy: 2510/5000 (50%)\n",
      "[epoch 8] loss: 0.6177559\n",
      "Test set: Average loss: 1.7714, Accuracy: 2391/5000 (48%)\n",
      "[epoch 9] loss: 0.5295588\n",
      "Test set: Average loss: 1.8228, Accuracy: 2450/5000 (49%)\n",
      "[epoch 10] loss: 0.3250906\n",
      "Test set: Average loss: 1.9616, Accuracy: 2448/5000 (49%)\n",
      "[epoch 11] loss: 0.2853942\n",
      "Test set: Average loss: 2.1004, Accuracy: 2475/5000 (50%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] loss: 0.2247909\n",
      "Test set: Average loss: 2.3262, Accuracy: 2451/5000 (49%)\n",
      "[epoch 13] loss: 0.3306723\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5489, Accuracy: 2297/5000 (46%)\n",
      "[epoch 14] loss: 0.1430386\n",
      "Test set: Average loss: 2.2297, Accuracy: 2497/5000 (50%)\n",
      "[epoch 15] loss: 0.0742668\n",
      "Test set: Average loss: 2.2182, Accuracy: 2528/5000 (51%)\n",
      "[epoch 16] loss: 0.0628071\n",
      "Test set: Average loss: 2.2369, Accuracy: 2545/5000 (51%)\n",
      "[epoch 17] loss: 0.0558361\n",
      "Test set: Average loss: 2.2570, Accuracy: 2544/5000 (51%)\n",
      "[epoch 18] loss: 0.0510962\n",
      "Test set: Average loss: 2.2753, Accuracy: 2547/5000 (51%)\n",
      "[epoch 19] loss: 0.0474094\n",
      "Test set: Average loss: 2.2922, Accuracy: 2543/5000 (51%)\n",
      "[epoch 20] loss: 0.0432750\n",
      "Test set: Average loss: 2.3107, Accuracy: 2552/5000 (51%)\n",
      "[epoch 21] loss: 0.0398216\n",
      "Test set: Average loss: 2.3299, Accuracy: 2542/5000 (51%)\n",
      "[epoch 22] loss: 0.0379774\n",
      "Test set: Average loss: 2.3485, Accuracy: 2551/5000 (51%)\n",
      "[epoch 23] loss: 0.0356891\n",
      "Test set: Average loss: 2.3630, Accuracy: 2543/5000 (51%)\n",
      "[epoch 24] loss: 0.0334035\n",
      "Test set: Average loss: 2.3804, Accuracy: 2545/5000 (51%)\n",
      "[epoch 25] loss: 0.0316990\n",
      "Test set: Average loss: 2.3955, Accuracy: 2546/5000 (51%)\n",
      "[epoch 26] loss: 0.0301143\n",
      "Test set: Average loss: 2.4129, Accuracy: 2546/5000 (51%)\n",
      "[epoch 27] loss: 0.0284930\n",
      "Test set: Average loss: 2.4251, Accuracy: 2545/5000 (51%)\n",
      "[epoch 28] loss: 0.0268474\n",
      "Test set: Average loss: 2.4444, Accuracy: 2546/5000 (51%)\n",
      "[epoch 29] loss: 0.0257657\n",
      "Test set: Average loss: 2.4560, Accuracy: 2552/5000 (51%)\n",
      "[epoch 30] loss: 0.0245486\n",
      "Test set: Average loss: 2.4700, Accuracy: 2544/5000 (51%)\n",
      "[epoch 31] loss: 0.0230843\n",
      "Test set: Average loss: 2.4817, Accuracy: 2532/5000 (51%)\n",
      "[epoch 32] loss: 0.0223267\n",
      "Test set: Average loss: 2.5003, Accuracy: 2531/5000 (51%)\n",
      "[epoch 33] loss: 0.0211795\n",
      "Test set: Average loss: 2.5140, Accuracy: 2539/5000 (51%)\n",
      "[epoch 34] loss: 0.0201225\n",
      "Test set: Average loss: 2.5259, Accuracy: 2533/5000 (51%)\n",
      "[epoch 35] loss: 0.0194405\n",
      "Test set: Average loss: 2.5401, Accuracy: 2532/5000 (51%)\n",
      "[epoch 36] loss: 0.0186722\n",
      "Test set: Average loss: 2.5512, Accuracy: 2525/5000 (50%)\n",
      "[epoch 37] loss: 0.0182760\n",
      "Test set: Average loss: 2.5692, Accuracy: 2541/5000 (51%)\n",
      "[epoch 38] loss: 0.0175795\n",
      "Test set: Average loss: 2.5794, Accuracy: 2527/5000 (51%)\n",
      "[epoch 39] loss: 0.0165761\n",
      "Test set: Average loss: 2.5974, Accuracy: 2532/5000 (51%)\n",
      "[epoch 40] loss: 0.0156287\n",
      "Test set: Average loss: 2.6089, Accuracy: 2533/5000 (51%)\n",
      "[epoch 41] loss: 0.0150909\n",
      "Test set: Average loss: 2.6211, Accuracy: 2527/5000 (51%)\n",
      "[epoch 42] loss: 0.0146602\n",
      "Test set: Average loss: 2.6348, Accuracy: 2529/5000 (51%)\n",
      "[epoch 43] loss: 0.0141130\n",
      "Test set: Average loss: 2.6480, Accuracy: 2530/5000 (51%)\n",
      "[epoch 44] loss: 0.0134947\n",
      "Test set: Average loss: 2.6588, Accuracy: 2528/5000 (51%)\n",
      "[epoch 45] loss: 0.0131427\n",
      "Test set: Average loss: 2.6732, Accuracy: 2528/5000 (51%)\n",
      "[epoch 46] loss: 0.0126864\n",
      "Test set: Average loss: 2.6858, Accuracy: 2533/5000 (51%)\n",
      "[epoch 47] loss: 0.0120206\n",
      "Test set: Average loss: 2.6996, Accuracy: 2524/5000 (50%)\n",
      "[epoch 48] loss: 0.0116431\n",
      "Test set: Average loss: 2.7098, Accuracy: 2527/5000 (51%)\n",
      "[epoch 49] loss: 0.0112013\n",
      "Test set: Average loss: 2.7239, Accuracy: 2526/5000 (51%)\n",
      "[epoch 50] loss: 0.0109602\n",
      "Test set: Average loss: 2.7364, Accuracy: 2530/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3784, Accuracy: 2672/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.3355, Accuracy: 5488/10000 (55%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3044, Accuracy: 419/5000 (8%)\n",
      "[epoch 1] loss: 1.5417850\n",
      "Test set: Average loss: 1.3690, Accuracy: 2547/5000 (51%)\n",
      "[epoch 2] loss: 1.1330669\n",
      "Test set: Average loss: 1.2803, Accuracy: 2790/5000 (56%)\n",
      "[epoch 3] loss: 1.0958729\n",
      "Test set: Average loss: 1.3711, Accuracy: 2548/5000 (51%)\n",
      "[epoch 4] loss: 0.9532827\n",
      "Test set: Average loss: 1.2990, Accuracy: 2794/5000 (56%)\n",
      "[epoch 5] loss: 0.8799220\n",
      "Test set: Average loss: 1.3381, Accuracy: 2760/5000 (55%)\n",
      "[epoch 6] loss: 0.8538944\n",
      "Test set: Average loss: 1.4275, Accuracy: 2698/5000 (54%)\n",
      "[epoch 7] loss: 0.7445997\n",
      "Test set: Average loss: 1.4707, Accuracy: 2753/5000 (55%)\n",
      "[epoch 8] loss: 0.7037626\n",
      "Test set: Average loss: 1.5312, Accuracy: 2686/5000 (54%)\n",
      "[epoch 9] loss: 0.6269276\n",
      "Test set: Average loss: 1.6063, Accuracy: 2711/5000 (54%)\n",
      "[epoch 10] loss: 0.5468949\n",
      "Test set: Average loss: 1.7775, Accuracy: 2569/5000 (51%)\n",
      "[epoch 11] loss: 0.5556799\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7560, Accuracy: 2660/5000 (53%)\n",
      "[epoch 12] loss: 0.2967228\n",
      "Test set: Average loss: 1.7228, Accuracy: 2796/5000 (56%)\n",
      "[epoch 13] loss: 0.3736293\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.7587, Accuracy: 2789/5000 (56%)\n",
      "[epoch 14] loss: 0.2394246\n",
      "Test set: Average loss: 1.7487, Accuracy: 2788/5000 (56%)\n",
      "[epoch 15] loss: 0.2235709\n",
      "Test set: Average loss: 1.7471, Accuracy: 2797/5000 (56%)\n",
      "[epoch 16] loss: 0.2175369\n",
      "Test set: Average loss: 1.7501, Accuracy: 2794/5000 (56%)\n",
      "[epoch 17] loss: 0.2143597\n",
      "Test set: Average loss: 1.7531, Accuracy: 2796/5000 (56%)\n",
      "[epoch 18] loss: 0.2124119\n",
      "Test set: Average loss: 1.7573, Accuracy: 2798/5000 (56%)\n",
      "[epoch 19] loss: 0.2106133\n",
      "Test set: Average loss: 1.7613, Accuracy: 2793/5000 (56%)\n",
      "[epoch 20] loss: 0.2094748\n",
      "Test set: Average loss: 1.7653, Accuracy: 2795/5000 (56%)\n",
      "[epoch 21] loss: 0.2082715\n",
      "Test set: Average loss: 1.7685, Accuracy: 2798/5000 (56%)\n",
      "[epoch 22] loss: 0.2058386\n",
      "Test set: Average loss: 1.7726, Accuracy: 2795/5000 (56%)\n",
      "[epoch 23] loss: 0.2068359\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.7768, Accuracy: 2797/5000 (56%)\n",
      "[epoch 24] loss: 0.2840354\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.7770, Accuracy: 2800/5000 (56%)\n",
      "[epoch 25] loss: 0.2019707\n",
      "Test set: Average loss: 1.7770, Accuracy: 2800/5000 (56%)\n",
      "[epoch 26] loss: 0.2010347\n",
      "Test set: Average loss: 1.7770, Accuracy: 2800/5000 (56%)\n",
      "[epoch 27] loss: 0.2020945\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 28] loss: 0.2013881\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 29] loss: 0.2056064\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 30] loss: 0.2015628\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 31] loss: 0.2013615\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 32] loss: 0.2018198\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 33] loss: 0.2020627\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 34] loss: 0.2048229\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 35] loss: 0.2036282\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 36] loss: 0.2015946\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 37] loss: 0.2066380\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 38] loss: 0.2022047\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 39] loss: 0.2018094\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 40] loss: 0.2011119\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 41] loss: 0.2023977\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 42] loss: 0.2019504\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 43] loss: 0.2063951\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 44] loss: 0.2012184\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 45] loss: 0.2034715\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 46] loss: 0.2033508\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 47] loss: 0.2021997\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 48] loss: 0.2104719\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 49] loss: 0.2029439\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "[epoch 50] loss: 0.2038846\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7771, Accuracy: 2800/5000 (56%)\n",
      "Test\n",
      "Test set: Average loss: 1.7372, Accuracy: 5524/10000 (55%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 331/5000 (7%)\n",
      "[epoch 1] loss: 1.5295402\n",
      "Test set: Average loss: 1.3024, Accuracy: 2768/5000 (55%)\n",
      "[epoch 2] loss: 1.1357872\n",
      "Test set: Average loss: 1.4292, Accuracy: 2588/5000 (52%)\n",
      "[epoch 3] loss: 1.0686766\n",
      "Test set: Average loss: 1.3984, Accuracy: 2650/5000 (53%)\n",
      "[epoch 4] loss: 1.0420074\n",
      "Test set: Average loss: 1.4509, Accuracy: 2595/5000 (52%)\n",
      "[epoch 5] loss: 1.0006767\n",
      "Test set: Average loss: 1.4770, Accuracy: 2530/5000 (51%)\n",
      "[epoch 6] loss: 0.8204296\n",
      "Test set: Average loss: 1.4444, Accuracy: 2745/5000 (55%)\n",
      "[epoch 7] loss: 0.7991019\n",
      "Test set: Average loss: 1.5860, Accuracy: 2619/5000 (52%)\n",
      "[epoch 8] loss: 0.7317465\n",
      "Test set: Average loss: 1.5662, Accuracy: 2695/5000 (54%)\n",
      "[epoch 9] loss: 0.6382136\n",
      "Test set: Average loss: 1.7745, Accuracy: 2592/5000 (52%)\n",
      "[epoch 10] loss: 0.5477306\n",
      "Test set: Average loss: 1.8941, Accuracy: 2531/5000 (51%)\n",
      "[epoch 11] loss: 0.5221182\n",
      "Test set: Average loss: 1.8595, Accuracy: 2605/5000 (52%)\n",
      "[epoch 12] loss: 0.5019201\n",
      "Test set: Average loss: 2.1649, Accuracy: 2313/5000 (46%)\n",
      "[epoch 13] loss: 0.6648847\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3277, Accuracy: 2363/5000 (47%)\n",
      "[epoch 14] loss: 0.3651279\n",
      "Test set: Average loss: 1.8805, Accuracy: 2639/5000 (53%)\n",
      "[epoch 15] loss: 0.2115659\n",
      "Test set: Average loss: 1.9197, Accuracy: 2663/5000 (53%)\n",
      "[epoch 16] loss: 0.1914867\n",
      "Test set: Average loss: 1.9389, Accuracy: 2660/5000 (53%)\n",
      "[epoch 17] loss: 0.1745584\n",
      "Test set: Average loss: 1.9792, Accuracy: 2646/5000 (53%)\n",
      "[epoch 18] loss: 0.1618254\n",
      "Test set: Average loss: 2.0267, Accuracy: 2649/5000 (53%)\n",
      "[epoch 19] loss: 0.1536100\n",
      "Test set: Average loss: 2.0547, Accuracy: 2635/5000 (53%)\n",
      "[epoch 20] loss: 0.1442331\n",
      "Test set: Average loss: 2.0925, Accuracy: 2648/5000 (53%)\n",
      "[epoch 21] loss: 0.1348482\n",
      "Test set: Average loss: 2.1290, Accuracy: 2645/5000 (53%)\n",
      "[epoch 22] loss: 0.1279983\n",
      "Test set: Average loss: 2.1614, Accuracy: 2622/5000 (52%)\n",
      "[epoch 23] loss: 0.1163430\n",
      "Test set: Average loss: 2.1998, Accuracy: 2604/5000 (52%)\n",
      "[epoch 24] loss: 0.1099111\n",
      "Test set: Average loss: 2.2300, Accuracy: 2617/5000 (52%)\n",
      "[epoch 25] loss: 0.1028297\n",
      "Test set: Average loss: 2.2757, Accuracy: 2611/5000 (52%)\n",
      "[epoch 26] loss: 0.0975792\n",
      "Test set: Average loss: 2.3109, Accuracy: 2621/5000 (52%)\n",
      "[epoch 27] loss: 0.0903137\n",
      "Test set: Average loss: 2.3552, Accuracy: 2616/5000 (52%)\n",
      "[epoch 28] loss: 0.0859044\n",
      "Test set: Average loss: 2.3851, Accuracy: 2604/5000 (52%)\n",
      "[epoch 29] loss: 0.0794297\n",
      "Test set: Average loss: 2.4343, Accuracy: 2607/5000 (52%)\n",
      "[epoch 30] loss: 0.0736363\n",
      "Test set: Average loss: 2.4658, Accuracy: 2613/5000 (52%)\n",
      "[epoch 31] loss: 0.0690910\n",
      "Test set: Average loss: 2.5148, Accuracy: 2591/5000 (52%)\n",
      "[epoch 32] loss: 0.0638932\n",
      "Test set: Average loss: 2.5538, Accuracy: 2585/5000 (52%)\n",
      "[epoch 33] loss: 0.0603637\n",
      "Test set: Average loss: 2.5875, Accuracy: 2587/5000 (52%)\n",
      "[epoch 34] loss: 0.0580106\n",
      "Test set: Average loss: 2.6403, Accuracy: 2589/5000 (52%)\n",
      "[epoch 35] loss: 0.1829211\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.6745, Accuracy: 2577/5000 (52%)\n",
      "[epoch 36] loss: 0.0526469\n",
      "Test set: Average loss: 2.6737, Accuracy: 2576/5000 (52%)\n",
      "[epoch 37] loss: 0.0466570\n",
      "Test set: Average loss: 2.6719, Accuracy: 2581/5000 (52%)\n",
      "[epoch 38] loss: 0.0444076\n",
      "Test set: Average loss: 2.6735, Accuracy: 2584/5000 (52%)\n",
      "[epoch 39] loss: 0.0435847\n",
      "Test set: Average loss: 2.6772, Accuracy: 2590/5000 (52%)\n",
      "[epoch 40] loss: 0.2446799\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.6805, Accuracy: 2586/5000 (52%)\n",
      "[epoch 41] loss: 0.0429609\n",
      "Test set: Average loss: 2.6807, Accuracy: 2582/5000 (52%)\n",
      "[epoch 42] loss: 0.2196861\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.6813, Accuracy: 2585/5000 (52%)\n",
      "[epoch 43] loss: 0.0426356\n",
      "Test set: Average loss: 2.6814, Accuracy: 2584/5000 (52%)\n",
      "[epoch 44] loss: 0.0424641\n",
      "Test set: Average loss: 2.6814, Accuracy: 2584/5000 (52%)\n",
      "[epoch 45] loss: 0.0423043\n",
      "Test set: Average loss: 2.6815, Accuracy: 2584/5000 (52%)\n",
      "[epoch 46] loss: 0.0421933\n",
      "Test set: Average loss: 2.6815, Accuracy: 2584/5000 (52%)\n",
      "[epoch 47] loss: 0.0428953\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.6816, Accuracy: 2584/5000 (52%)\n",
      "[epoch 48] loss: 0.0421765\n",
      "Test set: Average loss: 2.6816, Accuracy: 2584/5000 (52%)\n",
      "[epoch 49] loss: 0.2049567\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.6946, Accuracy: 2579/5000 (52%)\n",
      "[epoch 50] loss: 0.0424973\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.6816, Accuracy: 2584/5000 (52%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3024, Accuracy: 2768/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.2861, Accuracy: 5564/10000 (56%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 311/5000 (6%)\n",
      "[epoch 1] loss: 1.5715045\n",
      "Test set: Average loss: 1.4159, Accuracy: 2469/5000 (49%)\n",
      "[epoch 2] loss: 1.2444787\n",
      "Test set: Average loss: 1.2676, Accuracy: 2755/5000 (55%)\n",
      "[epoch 3] loss: 1.0921471\n",
      "Test set: Average loss: 1.2421, Accuracy: 2897/5000 (58%)\n",
      "[epoch 4] loss: 1.0198424\n",
      "Test set: Average loss: 1.4874, Accuracy: 2529/5000 (51%)\n",
      "[epoch 5] loss: 0.9660878\n",
      "Test set: Average loss: 1.3400, Accuracy: 2731/5000 (55%)\n",
      "[epoch 6] loss: 0.8256892\n",
      "Test set: Average loss: 1.4519, Accuracy: 2686/5000 (54%)\n",
      "[epoch 7] loss: 0.8561905\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6277, Accuracy: 2549/5000 (51%)\n",
      "[epoch 8] loss: 0.5811864\n",
      "Test set: Average loss: 1.3843, Accuracy: 2797/5000 (56%)\n",
      "[epoch 9] loss: 0.4783666\n",
      "Test set: Average loss: 1.4061, Accuracy: 2807/5000 (56%)\n",
      "[epoch 10] loss: 0.4601478\n",
      "Test set: Average loss: 1.4186, Accuracy: 2847/5000 (57%)\n",
      "[epoch 11] loss: 0.4313903\n",
      "Test set: Average loss: 1.4423, Accuracy: 2813/5000 (56%)\n",
      "[epoch 12] loss: 0.4098546\n",
      "Test set: Average loss: 1.4779, Accuracy: 2826/5000 (57%)\n",
      "[epoch 13] loss: 0.4080482\n",
      "Test set: Average loss: 1.5017, Accuracy: 2814/5000 (56%)\n",
      "[epoch 14] loss: 0.3886203\n",
      "Test set: Average loss: 1.5174, Accuracy: 2813/5000 (56%)\n",
      "[epoch 15] loss: 0.3665877\n",
      "Test set: Average loss: 1.5389, Accuracy: 2815/5000 (56%)\n",
      "[epoch 16] loss: 0.3532741\n",
      "Test set: Average loss: 1.5719, Accuracy: 2814/5000 (56%)\n",
      "[epoch 17] loss: 0.3442554\n",
      "Test set: Average loss: 1.5939, Accuracy: 2824/5000 (56%)\n",
      "[epoch 18] loss: 0.3272726\n",
      "Test set: Average loss: 1.6198, Accuracy: 2803/5000 (56%)\n",
      "[epoch 19] loss: 0.3162256\n",
      "Test set: Average loss: 1.6695, Accuracy: 2792/5000 (56%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] loss: 0.3045327\n",
      "Test set: Average loss: 1.6680, Accuracy: 2798/5000 (56%)\n",
      "[epoch 21] loss: 0.2972226\n",
      "Test set: Average loss: 1.7102, Accuracy: 2796/5000 (56%)\n",
      "[epoch 22] loss: 0.2826548\n",
      "Test set: Average loss: 1.7550, Accuracy: 2748/5000 (55%)\n",
      "[epoch 23] loss: 0.2728512\n",
      "Test set: Average loss: 1.7850, Accuracy: 2764/5000 (55%)\n",
      "[epoch 24] loss: 0.2668958\n",
      "Test set: Average loss: 1.7861, Accuracy: 2752/5000 (55%)\n",
      "[epoch 25] loss: 0.3309388\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8624, Accuracy: 2730/5000 (55%)\n",
      "[epoch 26] loss: 0.2376382\n",
      "Test set: Average loss: 1.8408, Accuracy: 2740/5000 (55%)\n",
      "[epoch 27] loss: 0.3574350\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8375, Accuracy: 2753/5000 (55%)\n",
      "[epoch 28] loss: 0.2143538\n",
      "Test set: Average loss: 1.8380, Accuracy: 2746/5000 (55%)\n",
      "[epoch 29] loss: 0.2140776\n",
      "Test set: Average loss: 1.8380, Accuracy: 2747/5000 (55%)\n",
      "[epoch 30] loss: 0.2124404\n",
      "Test set: Average loss: 1.8379, Accuracy: 2747/5000 (55%)\n",
      "[epoch 31] loss: 0.2124704\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8381, Accuracy: 2744/5000 (55%)\n",
      "[epoch 32] loss: 0.2168790\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 33] loss: 0.2112365\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 34] loss: 0.2123173\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 35] loss: 0.2117540\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 36] loss: 0.2113657\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 37] loss: 0.2126369\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 38] loss: 0.2193839\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 39] loss: 0.2131347\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 40] loss: 0.2115827\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 41] loss: 0.2176023\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 42] loss: 0.2118454\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 43] loss: 0.2119485\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 44] loss: 0.2218547\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 45] loss: 0.3824654\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 46] loss: 0.2118786\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 47] loss: 0.2191679\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 48] loss: 0.2133149\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 49] loss: 0.2119792\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "[epoch 50] loss: 0.2149447\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8382, Accuracy: 2744/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2421, Accuracy: 2897/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.2211, Accuracy: 5778/10000 (58%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3021, Accuracy: 383/5000 (8%)\n",
      "[epoch 1] loss: 1.4051807\n",
      "Test set: Average loss: 1.2924, Accuracy: 2778/5000 (56%)\n",
      "[epoch 2] loss: 1.1794522\n",
      "Test set: Average loss: 1.2401, Accuracy: 2830/5000 (57%)\n",
      "[epoch 3] loss: 1.0468693\n",
      "Test set: Average loss: 1.2256, Accuracy: 2845/5000 (57%)\n",
      "[epoch 4] loss: 1.0073450\n",
      "Test set: Average loss: 1.2243, Accuracy: 2891/5000 (58%)\n",
      "[epoch 5] loss: 0.9765801\n",
      "Test set: Average loss: 1.3486, Accuracy: 2703/5000 (54%)\n",
      "[epoch 6] loss: 0.9424352\n",
      "Test set: Average loss: 1.3564, Accuracy: 2788/5000 (56%)\n",
      "[epoch 7] loss: 0.8795813\n",
      "Test set: Average loss: 1.4217, Accuracy: 2693/5000 (54%)\n",
      "[epoch 8] loss: 0.8555214\n",
      "Test set: Average loss: 1.3539, Accuracy: 2787/5000 (56%)\n",
      "[epoch 9] loss: 0.8055581\n",
      "Test set: Average loss: 1.4527, Accuracy: 2743/5000 (55%)\n",
      "[epoch 10] loss: 0.7811203\n",
      "Test set: Average loss: 1.4129, Accuracy: 2802/5000 (56%)\n",
      "[epoch 11] loss: 0.7556662\n",
      "Test set: Average loss: 1.4774, Accuracy: 2756/5000 (55%)\n",
      "[epoch 12] loss: 0.7133304\n",
      "Test set: Average loss: 1.5484, Accuracy: 2748/5000 (55%)\n",
      "[epoch 13] loss: 0.7163372\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5144, Accuracy: 2737/5000 (55%)\n",
      "[epoch 14] loss: 0.4811236\n",
      "Test set: Average loss: 1.4486, Accuracy: 2867/5000 (57%)\n",
      "[epoch 15] loss: 0.4238928\n",
      "Test set: Average loss: 1.4780, Accuracy: 2871/5000 (57%)\n",
      "[epoch 16] loss: 0.4027984\n",
      "Test set: Average loss: 1.5178, Accuracy: 2864/5000 (57%)\n",
      "[epoch 17] loss: 0.3898404\n",
      "Test set: Average loss: 1.5504, Accuracy: 2875/5000 (58%)\n",
      "[epoch 18] loss: 0.3740133\n",
      "Test set: Average loss: 1.5763, Accuracy: 2863/5000 (57%)\n",
      "[epoch 19] loss: 0.3604788\n",
      "Test set: Average loss: 1.6022, Accuracy: 2877/5000 (58%)\n",
      "[epoch 20] loss: 0.3541088\n",
      "Test set: Average loss: 1.6373, Accuracy: 2843/5000 (57%)\n",
      "[epoch 21] loss: 0.3409407\n",
      "Test set: Average loss: 1.6719, Accuracy: 2838/5000 (57%)\n",
      "[epoch 22] loss: 0.3298147\n",
      "Test set: Average loss: 1.7008, Accuracy: 2837/5000 (57%)\n",
      "[epoch 23] loss: 0.3200536\n",
      "Test set: Average loss: 1.7382, Accuracy: 2843/5000 (57%)\n",
      "[epoch 24] loss: 0.3105640\n",
      "Test set: Average loss: 1.7656, Accuracy: 2817/5000 (56%)\n",
      "[epoch 25] loss: 0.3028907\n",
      "Test set: Average loss: 1.8033, Accuracy: 2804/5000 (56%)\n",
      "[epoch 26] loss: 0.2989489\n",
      "Test set: Average loss: 1.8261, Accuracy: 2805/5000 (56%)\n",
      "[epoch 27] loss: 0.2891431\n",
      "Test set: Average loss: 1.8607, Accuracy: 2810/5000 (56%)\n",
      "[epoch 28] loss: 0.2772109\n",
      "Test set: Average loss: 1.8925, Accuracy: 2805/5000 (56%)\n",
      "[epoch 29] loss: 0.2688106\n",
      "Test set: Average loss: 1.9336, Accuracy: 2818/5000 (56%)\n",
      "[epoch 30] loss: 0.2622623\n",
      "Test set: Average loss: 1.9634, Accuracy: 2793/5000 (56%)\n",
      "[epoch 31] loss: 0.2530397\n",
      "Test set: Average loss: 1.9971, Accuracy: 2782/5000 (56%)\n",
      "[epoch 32] loss: 0.2449234\n",
      "Test set: Average loss: 2.0336, Accuracy: 2766/5000 (55%)\n",
      "[epoch 33] loss: 0.2395009\n",
      "Test set: Average loss: 2.0697, Accuracy: 2765/5000 (55%)\n",
      "[epoch 34] loss: 0.2355484\n",
      "Test set: Average loss: 2.1069, Accuracy: 2782/5000 (56%)\n",
      "[epoch 35] loss: 0.2242312\n",
      "Test set: Average loss: 2.1456, Accuracy: 2756/5000 (55%)\n",
      "[epoch 36] loss: 0.2169940\n",
      "Test set: Average loss: 2.1820, Accuracy: 2757/5000 (55%)\n",
      "[epoch 37] loss: 0.2108764\n",
      "Test set: Average loss: 2.2250, Accuracy: 2764/5000 (55%)\n",
      "[epoch 38] loss: 0.2021856\n",
      "Test set: Average loss: 2.2560, Accuracy: 2752/5000 (55%)\n",
      "[epoch 39] loss: 0.1948170\n",
      "Test set: Average loss: 2.2787, Accuracy: 2750/5000 (55%)\n",
      "[epoch 40] loss: 0.1905604\n",
      "Test set: Average loss: 2.3279, Accuracy: 2746/5000 (55%)\n",
      "[epoch 41] loss: 0.1816408\n",
      "Test set: Average loss: 2.3674, Accuracy: 2733/5000 (55%)\n",
      "[epoch 42] loss: 0.1757179\n",
      "Test set: Average loss: 2.4113, Accuracy: 2758/5000 (55%)\n",
      "[epoch 43] loss: 0.2400295\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4430, Accuracy: 2754/5000 (55%)\n",
      "[epoch 44] loss: 0.1458268\n",
      "Test set: Average loss: 2.4334, Accuracy: 2735/5000 (55%)\n",
      "[epoch 45] loss: 0.1410790\n",
      "Test set: Average loss: 2.4392, Accuracy: 2739/5000 (55%)\n",
      "[epoch 46] loss: 0.1401070\n",
      "Test set: Average loss: 2.4441, Accuracy: 2736/5000 (55%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47] loss: 0.1390978\n",
      "Test set: Average loss: 2.4494, Accuracy: 2734/5000 (55%)\n",
      "[epoch 48] loss: 0.1390581\n",
      "Test set: Average loss: 2.4538, Accuracy: 2743/5000 (55%)\n",
      "[epoch 49] loss: 0.1378203\n",
      "Test set: Average loss: 2.4592, Accuracy: 2736/5000 (55%)\n",
      "[epoch 50] loss: 0.1370278\n",
      "Test set: Average loss: 2.4648, Accuracy: 2742/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2243, Accuracy: 2891/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.1998, Accuracy: 5841/10000 (58%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3004, Accuracy: 592/5000 (12%)\n",
      "[epoch 1] loss: 1.4095518\n",
      "Test set: Average loss: 1.3207, Accuracy: 2677/5000 (54%)\n",
      "[epoch 2] loss: 1.1460913\n",
      "Test set: Average loss: 1.2813, Accuracy: 2740/5000 (55%)\n",
      "[epoch 3] loss: 1.0772910\n",
      "Test set: Average loss: 1.2924, Accuracy: 2767/5000 (55%)\n",
      "[epoch 4] loss: 1.0153792\n",
      "Test set: Average loss: 1.2833, Accuracy: 2734/5000 (55%)\n",
      "[epoch 5] loss: 0.9465462\n",
      "Test set: Average loss: 1.3264, Accuracy: 2714/5000 (54%)\n",
      "[epoch 6] loss: 0.9051605\n",
      "Test set: Average loss: 1.3244, Accuracy: 2780/5000 (56%)\n",
      "[epoch 7] loss: 0.8839486\n",
      "Test set: Average loss: 1.4013, Accuracy: 2741/5000 (55%)\n",
      "[epoch 8] loss: 0.8329085\n",
      "Test set: Average loss: 1.3744, Accuracy: 2734/5000 (55%)\n",
      "[epoch 9] loss: 0.7680117\n",
      "Test set: Average loss: 1.5508, Accuracy: 2698/5000 (54%)\n",
      "[epoch 10] loss: 0.7691664\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4770, Accuracy: 2790/5000 (56%)\n",
      "[epoch 11] loss: 0.5294511\n",
      "Test set: Average loss: 1.3930, Accuracy: 2880/5000 (58%)\n",
      "[epoch 12] loss: 0.4764210\n",
      "Test set: Average loss: 1.4125, Accuracy: 2888/5000 (58%)\n",
      "[epoch 13] loss: 0.4557712\n",
      "Test set: Average loss: 1.4439, Accuracy: 2872/5000 (57%)\n",
      "[epoch 14] loss: 0.4428216\n",
      "Test set: Average loss: 1.4754, Accuracy: 2867/5000 (57%)\n",
      "[epoch 15] loss: 0.4316741\n",
      "Test set: Average loss: 1.5333, Accuracy: 2853/5000 (57%)\n",
      "[epoch 16] loss: 0.4186351\n",
      "Test set: Average loss: 1.5369, Accuracy: 2865/5000 (57%)\n",
      "[epoch 17] loss: 0.4055940\n",
      "Test set: Average loss: 1.5745, Accuracy: 2855/5000 (57%)\n",
      "[epoch 18] loss: 0.3936621\n",
      "Test set: Average loss: 1.5912, Accuracy: 2840/5000 (57%)\n",
      "[epoch 19] loss: 0.3826433\n",
      "Test set: Average loss: 1.6262, Accuracy: 2840/5000 (57%)\n",
      "[epoch 20] loss: 0.3732985\n",
      "Test set: Average loss: 1.6633, Accuracy: 2813/5000 (56%)\n",
      "[epoch 21] loss: 0.3699355\n",
      "Test set: Average loss: 1.6973, Accuracy: 2829/5000 (57%)\n",
      "[epoch 22] loss: 0.3581757\n",
      "Test set: Average loss: 1.7241, Accuracy: 2782/5000 (56%)\n",
      "[epoch 23] loss: 0.3451915\n",
      "Test set: Average loss: 1.7485, Accuracy: 2816/5000 (56%)\n",
      "[epoch 24] loss: 0.3377131\n",
      "Test set: Average loss: 1.7711, Accuracy: 2821/5000 (56%)\n",
      "[epoch 25] loss: 0.3290840\n",
      "Test set: Average loss: 1.8111, Accuracy: 2783/5000 (56%)\n",
      "[epoch 26] loss: 0.3177731\n",
      "Test set: Average loss: 1.8502, Accuracy: 2808/5000 (56%)\n",
      "[epoch 27] loss: 0.3120230\n",
      "Test set: Average loss: 1.8912, Accuracy: 2780/5000 (56%)\n",
      "[epoch 28] loss: 0.2990696\n",
      "Test set: Average loss: 1.9261, Accuracy: 2787/5000 (56%)\n",
      "[epoch 29] loss: 0.2968326\n",
      "Test set: Average loss: 1.9407, Accuracy: 2777/5000 (56%)\n",
      "[epoch 30] loss: 0.2832468\n",
      "Test set: Average loss: 1.9713, Accuracy: 2778/5000 (56%)\n",
      "[epoch 31] loss: 0.2769364\n",
      "Test set: Average loss: 2.0131, Accuracy: 2804/5000 (56%)\n",
      "[epoch 32] loss: 0.2662890\n",
      "Test set: Average loss: 2.0724, Accuracy: 2785/5000 (56%)\n",
      "[epoch 33] loss: 0.2666588\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0945, Accuracy: 2789/5000 (56%)\n",
      "[epoch 34] loss: 0.2341154\n",
      "Test set: Average loss: 2.0833, Accuracy: 2776/5000 (56%)\n",
      "[epoch 35] loss: 0.2252996\n",
      "Test set: Average loss: 2.0843, Accuracy: 2769/5000 (55%)\n",
      "[epoch 36] loss: 0.2241022\n",
      "Test set: Average loss: 2.0936, Accuracy: 2768/5000 (55%)\n",
      "[epoch 37] loss: 0.2261398\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0975, Accuracy: 2766/5000 (55%)\n",
      "[epoch 38] loss: 0.2198860\n",
      "Test set: Average loss: 2.0969, Accuracy: 2765/5000 (55%)\n",
      "[epoch 39] loss: 0.2192915\n",
      "Test set: Average loss: 2.0967, Accuracy: 2769/5000 (55%)\n",
      "[epoch 40] loss: 0.2231738\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0967, Accuracy: 2773/5000 (55%)\n",
      "[epoch 41] loss: 0.2183879\n",
      "Test set: Average loss: 2.0968, Accuracy: 2773/5000 (55%)\n",
      "[epoch 42] loss: 0.2188164\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 43] loss: 0.2185009\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 44] loss: 0.2190113\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 45] loss: 0.2187375\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 46] loss: 0.2184775\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 47] loss: 0.2186533\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 48] loss: 0.2184640\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 49] loss: 0.2189902\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "[epoch 50] loss: 0.2185438\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0969, Accuracy: 2773/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4125, Accuracy: 2888/5000 (58%)\n",
      "Test\n",
      "Test set: Average loss: 1.3659, Accuracy: 5824/10000 (58%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3029, Accuracy: 566/5000 (11%)\n",
      "[epoch 1] loss: 1.4437660\n",
      "Test set: Average loss: 1.4544, Accuracy: 2452/5000 (49%)\n",
      "[epoch 2] loss: 1.2105617\n",
      "Test set: Average loss: 1.3058, Accuracy: 2690/5000 (54%)\n",
      "[epoch 3] loss: 1.0897260\n",
      "Test set: Average loss: 1.3268, Accuracy: 2716/5000 (54%)\n",
      "[epoch 4] loss: 1.0371265\n",
      "Test set: Average loss: 1.2832, Accuracy: 2831/5000 (57%)\n",
      "[epoch 5] loss: 1.0046651\n",
      "Test set: Average loss: 1.2927, Accuracy: 2783/5000 (56%)\n",
      "[epoch 6] loss: 0.9581152\n",
      "Test set: Average loss: 1.2983, Accuracy: 2815/5000 (56%)\n",
      "[epoch 7] loss: 0.9042280\n",
      "Test set: Average loss: 1.4691, Accuracy: 2652/5000 (53%)\n",
      "[epoch 8] loss: 0.9036053\n",
      "Test set: Average loss: 1.4021, Accuracy: 2722/5000 (54%)\n",
      "[epoch 9] loss: 0.8514950\n",
      "Test set: Average loss: 1.5068, Accuracy: 2605/5000 (52%)\n",
      "[epoch 10] loss: 0.8228616\n",
      "Test set: Average loss: 1.5131, Accuracy: 2667/5000 (53%)\n",
      "[epoch 11] loss: 0.7647468\n",
      "Test set: Average loss: 1.4555, Accuracy: 2719/5000 (54%)\n",
      "[epoch 12] loss: 0.7390182\n",
      "Test set: Average loss: 1.5333, Accuracy: 2715/5000 (54%)\n",
      "[epoch 13] loss: 0.7204037\n",
      "Test set: Average loss: 1.4872, Accuracy: 2758/5000 (55%)\n",
      "[epoch 14] loss: 0.7047794\n",
      "Test set: Average loss: 1.5332, Accuracy: 2697/5000 (54%)\n",
      "[epoch 15] loss: 0.6607650\n",
      "Test set: Average loss: 1.7692, Accuracy: 2650/5000 (53%)\n",
      "[epoch 16] loss: 0.6668882\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5840, Accuracy: 2762/5000 (55%)\n",
      "[epoch 17] loss: 0.4211525\n",
      "Test set: Average loss: 1.5455, Accuracy: 2817/5000 (56%)\n",
      "[epoch 18] loss: 0.3716102\n",
      "Test set: Average loss: 1.5794, Accuracy: 2816/5000 (56%)\n",
      "[epoch 19] loss: 0.3557886\n",
      "Test set: Average loss: 1.6220, Accuracy: 2813/5000 (56%)\n",
      "[epoch 20] loss: 0.3386004\n",
      "Test set: Average loss: 1.6535, Accuracy: 2809/5000 (56%)\n",
      "[epoch 21] loss: 0.3270422\n",
      "Test set: Average loss: 1.6952, Accuracy: 2802/5000 (56%)\n",
      "[epoch 22] loss: 0.3182853\n",
      "Test set: Average loss: 1.7238, Accuracy: 2825/5000 (56%)\n",
      "[epoch 23] loss: 0.3074549\n",
      "Test set: Average loss: 1.7592, Accuracy: 2788/5000 (56%)\n",
      "[epoch 24] loss: 0.2952897\n",
      "Test set: Average loss: 1.7949, Accuracy: 2786/5000 (56%)\n",
      "[epoch 25] loss: 0.2877873\n",
      "Test set: Average loss: 1.8386, Accuracy: 2783/5000 (56%)\n",
      "[epoch 26] loss: 0.2767848\n",
      "Test set: Average loss: 1.8644, Accuracy: 2744/5000 (55%)\n",
      "[epoch 27] loss: 0.2667844\n",
      "Test set: Average loss: 1.8930, Accuracy: 2771/5000 (55%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] loss: 0.2601129\n",
      "Test set: Average loss: 1.9567, Accuracy: 2766/5000 (55%)\n",
      "[epoch 29] loss: 0.2540870\n",
      "Test set: Average loss: 1.9812, Accuracy: 2773/5000 (55%)\n",
      "[epoch 30] loss: 0.2481414\n",
      "Test set: Average loss: 2.0064, Accuracy: 2732/5000 (55%)\n",
      "[epoch 31] loss: 0.2373581\n",
      "Test set: Average loss: 2.0387, Accuracy: 2756/5000 (55%)\n",
      "[epoch 32] loss: 0.2303051\n",
      "Test set: Average loss: 2.0769, Accuracy: 2750/5000 (55%)\n",
      "[epoch 33] loss: 0.2251599\n",
      "Test set: Average loss: 2.1167, Accuracy: 2724/5000 (54%)\n",
      "[epoch 34] loss: 0.2176207\n",
      "Test set: Average loss: 2.1589, Accuracy: 2759/5000 (55%)\n",
      "[epoch 35] loss: 0.2090079\n",
      "Test set: Average loss: 2.1855, Accuracy: 2748/5000 (55%)\n",
      "[epoch 36] loss: 0.1991589\n",
      "Test set: Average loss: 2.2219, Accuracy: 2730/5000 (55%)\n",
      "[epoch 37] loss: 0.1925959\n",
      "Test set: Average loss: 2.2613, Accuracy: 2736/5000 (55%)\n",
      "[epoch 38] loss: 0.1889870\n",
      "Test set: Average loss: 2.2964, Accuracy: 2723/5000 (54%)\n",
      "[epoch 39] loss: 0.1848565\n",
      "Test set: Average loss: 2.3440, Accuracy: 2721/5000 (54%)\n",
      "[epoch 40] loss: 0.1721303\n",
      "Test set: Average loss: 2.3865, Accuracy: 2717/5000 (54%)\n",
      "[epoch 41] loss: 0.1655858\n",
      "Test set: Average loss: 2.4207, Accuracy: 2721/5000 (54%)\n",
      "[epoch 42] loss: 0.1627674\n",
      "Test set: Average loss: 2.4685, Accuracy: 2698/5000 (54%)\n",
      "[epoch 43] loss: 0.1535897\n",
      "Test set: Average loss: 2.5107, Accuracy: 2714/5000 (54%)\n",
      "[epoch 44] loss: 0.1489828\n",
      "Test set: Average loss: 2.5337, Accuracy: 2704/5000 (54%)\n",
      "[epoch 45] loss: 0.1405892\n",
      "Test set: Average loss: 2.5850, Accuracy: 2707/5000 (54%)\n",
      "[epoch 46] loss: 0.1361418\n",
      "Test set: Average loss: 2.6267, Accuracy: 2703/5000 (54%)\n",
      "[epoch 47] loss: 0.1317478\n",
      "Test set: Average loss: 2.6614, Accuracy: 2703/5000 (54%)\n",
      "[epoch 48] loss: 0.1214929\n",
      "Test set: Average loss: 2.7056, Accuracy: 2717/5000 (54%)\n",
      "[epoch 49] loss: 0.1176476\n",
      "Test set: Average loss: 2.7482, Accuracy: 2696/5000 (54%)\n",
      "[epoch 50] loss: 0.1154759\n",
      "Test set: Average loss: 2.7954, Accuracy: 2683/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2832, Accuracy: 2831/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.2629, Accuracy: 5701/10000 (57%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 720/5000 (14%)\n",
      "[epoch 1] loss: 1.3007199\n",
      "Test set: Average loss: 1.3510, Accuracy: 2626/5000 (53%)\n",
      "[epoch 2] loss: 1.1205264\n",
      "Test set: Average loss: 1.2373, Accuracy: 2829/5000 (57%)\n",
      "[epoch 3] loss: 1.0541274\n",
      "Test set: Average loss: 1.2523, Accuracy: 2841/5000 (57%)\n",
      "[epoch 4] loss: 1.0327210\n",
      "Test set: Average loss: 1.1555, Accuracy: 2980/5000 (60%)\n",
      "[epoch 5] loss: 0.9971996\n",
      "Test set: Average loss: 1.2554, Accuracy: 2855/5000 (57%)\n",
      "[epoch 6] loss: 0.9602123\n",
      "Test set: Average loss: 1.1886, Accuracy: 2967/5000 (59%)\n",
      "[epoch 7] loss: 0.9256715\n",
      "Test set: Average loss: 1.2301, Accuracy: 2900/5000 (58%)\n",
      "[epoch 8] loss: 0.9103218\n",
      "Test set: Average loss: 1.2232, Accuracy: 2881/5000 (58%)\n",
      "[epoch 9] loss: 0.8798280\n",
      "Test set: Average loss: 1.2289, Accuracy: 2934/5000 (59%)\n",
      "[epoch 10] loss: 0.8586599\n",
      "Test set: Average loss: 1.2489, Accuracy: 2895/5000 (58%)\n",
      "[epoch 11] loss: 0.8171991\n",
      "Test set: Average loss: 1.2262, Accuracy: 3024/5000 (60%)\n",
      "[epoch 12] loss: 0.8108945\n",
      "Test set: Average loss: 1.2213, Accuracy: 3010/5000 (60%)\n",
      "[epoch 13] loss: 0.7819766\n",
      "Test set: Average loss: 1.3107, Accuracy: 2880/5000 (58%)\n",
      "[epoch 14] loss: 0.7463144\n",
      "Test set: Average loss: 1.2929, Accuracy: 2906/5000 (58%)\n",
      "[epoch 15] loss: 0.7355158\n",
      "Test set: Average loss: 1.3241, Accuracy: 2880/5000 (58%)\n",
      "[epoch 16] loss: 0.7027778\n",
      "Test set: Average loss: 1.2938, Accuracy: 2965/5000 (59%)\n",
      "[epoch 17] loss: 0.6488359\n",
      "Test set: Average loss: 1.3537, Accuracy: 2953/5000 (59%)\n",
      "[epoch 18] loss: 0.6271981\n",
      "Test set: Average loss: 1.4020, Accuracy: 2886/5000 (58%)\n",
      "[epoch 19] loss: 0.5649967\n",
      "Test set: Average loss: 1.4148, Accuracy: 2926/5000 (59%)\n",
      "[epoch 20] loss: 0.5230478\n",
      "Test set: Average loss: 1.4930, Accuracy: 2824/5000 (56%)\n",
      "[epoch 21] loss: 0.4749449\n",
      "Test set: Average loss: 1.4403, Accuracy: 2982/5000 (60%)\n",
      "[epoch 22] loss: 0.4244350\n",
      "Test set: Average loss: 1.5166, Accuracy: 2909/5000 (58%)\n",
      "[epoch 23] loss: 0.3654511\n",
      "Test set: Average loss: 1.5894, Accuracy: 2862/5000 (57%)\n",
      "[epoch 24] loss: 0.3098752\n",
      "Test set: Average loss: 1.5718, Accuracy: 2982/5000 (60%)\n",
      "[epoch 25] loss: 0.2725704\n",
      "Test set: Average loss: 1.6818, Accuracy: 2894/5000 (58%)\n",
      "[epoch 26] loss: 0.2225890\n",
      "Test set: Average loss: 1.7064, Accuracy: 2885/5000 (58%)\n",
      "[epoch 27] loss: 0.1716796\n",
      "Test set: Average loss: 1.7458, Accuracy: 2971/5000 (59%)\n",
      "[epoch 28] loss: 0.1426035\n",
      "Test set: Average loss: 1.9040, Accuracy: 2889/5000 (58%)\n",
      "[epoch 29] loss: 0.1331537\n",
      "Test set: Average loss: 1.8787, Accuracy: 2941/5000 (59%)\n",
      "[epoch 30] loss: 0.1179860\n",
      "Test set: Average loss: 1.9711, Accuracy: 2872/5000 (57%)\n",
      "[epoch 31] loss: 0.1078096\n",
      "Test set: Average loss: 1.9894, Accuracy: 2927/5000 (59%)\n",
      "[epoch 32] loss: 0.0513858\n",
      "Test set: Average loss: 2.1346, Accuracy: 2858/5000 (57%)\n",
      "[epoch 33] loss: 0.1601618\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0933, Accuracy: 2891/5000 (58%)\n",
      "[epoch 34] loss: 0.0484405\n",
      "Test set: Average loss: 1.9929, Accuracy: 3008/5000 (60%)\n",
      "[epoch 35] loss: 0.0223968\n",
      "Test set: Average loss: 2.0047, Accuracy: 3003/5000 (60%)\n",
      "[epoch 36] loss: 0.0165576\n",
      "Test set: Average loss: 2.0180, Accuracy: 3018/5000 (60%)\n",
      "[epoch 37] loss: 0.0134544\n",
      "Test set: Average loss: 2.0376, Accuracy: 3021/5000 (60%)\n",
      "[epoch 38] loss: 0.0114364\n",
      "Test set: Average loss: 2.0538, Accuracy: 3032/5000 (61%)\n",
      "[epoch 39] loss: 0.0099308\n",
      "Test set: Average loss: 2.0664, Accuracy: 3033/5000 (61%)\n",
      "[epoch 40] loss: 0.0087259\n",
      "Test set: Average loss: 2.0817, Accuracy: 3029/5000 (61%)\n",
      "[epoch 41] loss: 0.0077187\n",
      "Test set: Average loss: 2.0981, Accuracy: 3031/5000 (61%)\n",
      "[epoch 42] loss: 0.0068718\n",
      "Test set: Average loss: 2.1153, Accuracy: 3038/5000 (61%)\n",
      "[epoch 43] loss: 0.0061508\n",
      "Test set: Average loss: 2.1324, Accuracy: 3032/5000 (61%)\n",
      "[epoch 44] loss: 0.0055054\n",
      "Test set: Average loss: 2.1510, Accuracy: 3041/5000 (61%)\n",
      "[epoch 45] loss: 0.0049312\n",
      "Test set: Average loss: 2.1686, Accuracy: 3044/5000 (61%)\n",
      "[epoch 46] loss: 0.0044076\n",
      "Test set: Average loss: 2.1859, Accuracy: 3040/5000 (61%)\n",
      "[epoch 47] loss: 0.0039556\n",
      "Test set: Average loss: 2.2080, Accuracy: 3050/5000 (61%)\n",
      "[epoch 48] loss: 0.0035470\n",
      "Test set: Average loss: 2.2251, Accuracy: 3045/5000 (61%)\n",
      "[epoch 49] loss: 0.0031815\n",
      "Test set: Average loss: 2.2492, Accuracy: 3049/5000 (61%)\n",
      "[epoch 50] loss: 0.0028354\n",
      "Test set: Average loss: 2.2722, Accuracy: 3047/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2080, Accuracy: 3050/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.1615, Accuracy: 6168/10000 (62%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 770/5000 (15%)\n",
      "[epoch 1] loss: 1.3268026\n",
      "Test set: Average loss: 1.2279, Accuracy: 2820/5000 (56%)\n",
      "[epoch 2] loss: 1.1343400\n",
      "Test set: Average loss: 1.2301, Accuracy: 2848/5000 (57%)\n",
      "[epoch 3] loss: 1.0752091\n",
      "Test set: Average loss: 1.2058, Accuracy: 2847/5000 (57%)\n",
      "[epoch 4] loss: 1.0165398\n",
      "Test set: Average loss: 1.2694, Accuracy: 2801/5000 (56%)\n",
      "[epoch 5] loss: 0.9741390\n",
      "Test set: Average loss: 1.2468, Accuracy: 2858/5000 (57%)\n",
      "[epoch 6] loss: 0.9520900\n",
      "Test set: Average loss: 1.2125, Accuracy: 2979/5000 (60%)\n",
      "[epoch 7] loss: 0.9391524\n",
      "Test set: Average loss: 1.2858, Accuracy: 2785/5000 (56%)\n",
      "[epoch 8] loss: 0.9129458\n",
      "Test set: Average loss: 1.3256, Accuracy: 2817/5000 (56%)\n",
      "[epoch 9] loss: 0.8823761\n",
      "Test set: Average loss: 1.2634, Accuracy: 2873/5000 (57%)\n",
      "[epoch 10] loss: 0.8738288\n",
      "Test set: Average loss: 1.2606, Accuracy: 2870/5000 (57%)\n",
      "[epoch 11] loss: 0.8216690\n",
      "Test set: Average loss: 1.2835, Accuracy: 2868/5000 (57%)\n",
      "[epoch 12] loss: 0.8051864\n",
      "Test set: Average loss: 1.3495, Accuracy: 2840/5000 (57%)\n",
      "[epoch 13] loss: 0.7870474\n",
      "Test set: Average loss: 1.2813, Accuracy: 2911/5000 (58%)\n",
      "[epoch 14] loss: 0.7646683\n",
      "Test set: Average loss: 1.3824, Accuracy: 2792/5000 (56%)\n",
      "[epoch 15] loss: 0.7188954\n",
      "Test set: Average loss: 1.3238, Accuracy: 2912/5000 (58%)\n",
      "[epoch 16] loss: 0.6895839\n",
      "Test set: Average loss: 1.3644, Accuracy: 2876/5000 (58%)\n",
      "[epoch 17] loss: 0.6482862\n",
      "Test set: Average loss: 1.3797, Accuracy: 2914/5000 (58%)\n",
      "[epoch 18] loss: 0.6073242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3950, Accuracy: 2928/5000 (59%)\n",
      "[epoch 19] loss: 0.5876798\n",
      "Test set: Average loss: 1.4907, Accuracy: 2830/5000 (57%)\n",
      "[epoch 20] loss: 0.5211244\n",
      "Test set: Average loss: 1.4546, Accuracy: 2898/5000 (58%)\n",
      "[epoch 21] loss: 0.4703569\n",
      "Test set: Average loss: 1.5383, Accuracy: 2886/5000 (58%)\n",
      "[epoch 22] loss: 0.4486434\n",
      "Test set: Average loss: 1.5274, Accuracy: 2910/5000 (58%)\n",
      "[epoch 23] loss: 0.3829874\n",
      "Test set: Average loss: 1.5575, Accuracy: 2936/5000 (59%)\n",
      "[epoch 24] loss: 0.3321316\n",
      "Test set: Average loss: 1.6326, Accuracy: 2991/5000 (60%)\n",
      "[epoch 25] loss: 0.2673052\n",
      "Test set: Average loss: 1.7312, Accuracy: 2923/5000 (58%)\n",
      "[epoch 26] loss: 0.2311587\n",
      "Test set: Average loss: 1.7835, Accuracy: 2836/5000 (57%)\n",
      "[epoch 27] loss: 0.1884725\n",
      "Test set: Average loss: 1.7611, Accuracy: 2940/5000 (59%)\n",
      "[epoch 28] loss: 0.1611833\n",
      "Test set: Average loss: 1.9257, Accuracy: 2856/5000 (57%)\n",
      "[epoch 29] loss: 0.1135246\n",
      "Test set: Average loss: 1.9347, Accuracy: 2944/5000 (59%)\n",
      "[epoch 30] loss: 0.1465093\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0031, Accuracy: 2883/5000 (58%)\n",
      "[epoch 31] loss: 0.0448601\n",
      "Test set: Average loss: 1.9442, Accuracy: 2973/5000 (59%)\n",
      "[epoch 32] loss: 0.0275668\n",
      "Test set: Average loss: 1.9583, Accuracy: 2981/5000 (60%)\n",
      "[epoch 33] loss: 0.0229558\n",
      "Test set: Average loss: 1.9721, Accuracy: 2981/5000 (60%)\n",
      "[epoch 34] loss: 0.0199367\n",
      "Test set: Average loss: 1.9853, Accuracy: 2995/5000 (60%)\n",
      "[epoch 35] loss: 0.0176337\n",
      "Test set: Average loss: 2.0067, Accuracy: 2996/5000 (60%)\n",
      "[epoch 36] loss: 0.0158658\n",
      "Test set: Average loss: 2.0231, Accuracy: 2994/5000 (60%)\n",
      "[epoch 37] loss: 0.0142840\n",
      "Test set: Average loss: 2.0399, Accuracy: 3007/5000 (60%)\n",
      "[epoch 38] loss: 0.0129297\n",
      "Test set: Average loss: 2.0599, Accuracy: 2998/5000 (60%)\n",
      "[epoch 39] loss: 0.0116943\n",
      "Test set: Average loss: 2.0801, Accuracy: 3000/5000 (60%)\n",
      "[epoch 40] loss: 0.0105613\n",
      "Test set: Average loss: 2.1021, Accuracy: 3002/5000 (60%)\n",
      "[epoch 41] loss: 0.0095544\n",
      "Test set: Average loss: 2.1201, Accuracy: 3005/5000 (60%)\n",
      "[epoch 42] loss: 0.0086787\n",
      "Test set: Average loss: 2.1453, Accuracy: 2996/5000 (60%)\n",
      "[epoch 43] loss: 0.0077909\n",
      "Test set: Average loss: 2.1725, Accuracy: 3001/5000 (60%)\n",
      "[epoch 44] loss: 0.0070264\n",
      "Test set: Average loss: 2.2009, Accuracy: 2999/5000 (60%)\n",
      "[epoch 45] loss: 0.0063686\n",
      "Test set: Average loss: 2.2215, Accuracy: 3007/5000 (60%)\n",
      "[epoch 46] loss: 0.0056914\n",
      "Test set: Average loss: 2.2474, Accuracy: 3003/5000 (60%)\n",
      "[epoch 47] loss: 0.0050854\n",
      "Test set: Average loss: 2.2767, Accuracy: 3006/5000 (60%)\n",
      "[epoch 48] loss: 0.0045352\n",
      "Test set: Average loss: 2.3098, Accuracy: 3000/5000 (60%)\n",
      "[epoch 49] loss: 0.0040501\n",
      "Test set: Average loss: 2.3429, Accuracy: 3006/5000 (60%)\n",
      "[epoch 50] loss: 0.0035839\n",
      "Test set: Average loss: 2.3697, Accuracy: 3009/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3697, Accuracy: 3009/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.2622, Accuracy: 6150/10000 (62%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3038, Accuracy: 319/5000 (6%)\n",
      "[epoch 1] loss: 1.3216958\n",
      "Test set: Average loss: 1.2300, Accuracy: 2832/5000 (57%)\n",
      "[epoch 2] loss: 1.1403183\n",
      "Test set: Average loss: 1.2173, Accuracy: 2898/5000 (58%)\n",
      "[epoch 3] loss: 1.0929144\n",
      "Test set: Average loss: 1.1777, Accuracy: 2980/5000 (60%)\n",
      "[epoch 4] loss: 1.0523673\n",
      "Test set: Average loss: 1.2818, Accuracy: 2815/5000 (56%)\n",
      "[epoch 5] loss: 1.0208824\n",
      "Test set: Average loss: 1.2682, Accuracy: 2885/5000 (58%)\n",
      "[epoch 6] loss: 0.9847836\n",
      "Test set: Average loss: 1.3488, Accuracy: 2718/5000 (54%)\n",
      "[epoch 7] loss: 0.9566754\n",
      "Test set: Average loss: 1.1912, Accuracy: 2990/5000 (60%)\n",
      "[epoch 8] loss: 0.9386257\n",
      "Test set: Average loss: 1.2224, Accuracy: 2967/5000 (59%)\n",
      "[epoch 9] loss: 0.9150976\n",
      "Test set: Average loss: 1.2454, Accuracy: 2905/5000 (58%)\n",
      "[epoch 10] loss: 0.9012325\n",
      "Test set: Average loss: 1.2495, Accuracy: 2882/5000 (58%)\n",
      "[epoch 11] loss: 0.8716245\n",
      "Test set: Average loss: 1.3601, Accuracy: 2748/5000 (55%)\n",
      "[epoch 12] loss: 0.8444705\n",
      "Test set: Average loss: 1.2515, Accuracy: 2957/5000 (59%)\n",
      "[epoch 13] loss: 0.8057593\n",
      "Test set: Average loss: 1.2350, Accuracy: 2921/5000 (58%)\n",
      "[epoch 14] loss: 0.7955553\n",
      "Test set: Average loss: 1.2837, Accuracy: 2916/5000 (58%)\n",
      "[epoch 15] loss: 0.7427763\n",
      "Test set: Average loss: 1.2926, Accuracy: 2915/5000 (58%)\n",
      "[epoch 16] loss: 0.7255472\n",
      "Test set: Average loss: 1.3387, Accuracy: 2868/5000 (57%)\n",
      "[epoch 17] loss: 0.6792768\n",
      "Test set: Average loss: 1.3487, Accuracy: 2915/5000 (58%)\n",
      "[epoch 18] loss: 0.6408294\n",
      "Test set: Average loss: 1.4267, Accuracy: 2802/5000 (56%)\n",
      "[epoch 19] loss: 0.5941665\n",
      "Test set: Average loss: 1.3817, Accuracy: 2927/5000 (59%)\n",
      "[epoch 20] loss: 0.5546820\n",
      "Test set: Average loss: 1.4695, Accuracy: 2851/5000 (57%)\n",
      "[epoch 21] loss: 0.4961091\n",
      "Test set: Average loss: 1.5076, Accuracy: 2904/5000 (58%)\n",
      "[epoch 22] loss: 0.4498621\n",
      "Test set: Average loss: 1.5505, Accuracy: 2844/5000 (57%)\n",
      "[epoch 23] loss: 0.4105617\n",
      "Test set: Average loss: 1.5508, Accuracy: 2906/5000 (58%)\n",
      "[epoch 24] loss: 0.3619962\n",
      "Test set: Average loss: 1.6397, Accuracy: 2847/5000 (57%)\n",
      "[epoch 25] loss: 0.2979186\n",
      "Test set: Average loss: 1.6703, Accuracy: 2880/5000 (58%)\n",
      "[epoch 26] loss: 0.2307980\n",
      "Test set: Average loss: 1.7437, Accuracy: 2878/5000 (58%)\n",
      "[epoch 27] loss: 0.2199176\n",
      "Test set: Average loss: 1.8127, Accuracy: 2857/5000 (57%)\n",
      "[epoch 28] loss: 0.1636703\n",
      "Test set: Average loss: 1.8399, Accuracy: 2898/5000 (58%)\n",
      "[epoch 29] loss: 0.1032510\n",
      "Test set: Average loss: 1.9326, Accuracy: 2909/5000 (58%)\n",
      "[epoch 30] loss: 0.0890820\n",
      "Test set: Average loss: 2.0423, Accuracy: 2899/5000 (58%)\n",
      "[epoch 31] loss: 0.1212827\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2148, Accuracy: 2745/5000 (55%)\n",
      "[epoch 32] loss: 0.0548574\n",
      "Test set: Average loss: 2.0151, Accuracy: 2952/5000 (59%)\n",
      "[epoch 33] loss: 0.0257587\n",
      "Test set: Average loss: 2.0255, Accuracy: 2965/5000 (59%)\n",
      "[epoch 34] loss: 0.0203371\n",
      "Test set: Average loss: 2.0412, Accuracy: 2959/5000 (59%)\n",
      "[epoch 35] loss: 0.0171929\n",
      "Test set: Average loss: 2.0594, Accuracy: 2959/5000 (59%)\n",
      "[epoch 36] loss: 0.0150153\n",
      "Test set: Average loss: 2.0738, Accuracy: 2961/5000 (59%)\n",
      "[epoch 37] loss: 0.0132975\n",
      "Test set: Average loss: 2.0930, Accuracy: 2947/5000 (59%)\n",
      "[epoch 38] loss: 0.0118796\n",
      "Test set: Average loss: 2.1029, Accuracy: 2954/5000 (59%)\n",
      "[epoch 39] loss: 0.0106619\n",
      "Test set: Average loss: 2.1258, Accuracy: 2950/5000 (59%)\n",
      "[epoch 40] loss: 0.0096346\n",
      "Test set: Average loss: 2.1430, Accuracy: 2945/5000 (59%)\n",
      "[epoch 41] loss: 0.0086776\n",
      "Test set: Average loss: 2.1654, Accuracy: 2955/5000 (59%)\n",
      "[epoch 42] loss: 0.0078336\n",
      "Test set: Average loss: 2.1882, Accuracy: 2952/5000 (59%)\n",
      "[epoch 43] loss: 0.0070791\n",
      "Test set: Average loss: 2.2081, Accuracy: 2944/5000 (59%)\n",
      "[epoch 44] loss: 0.0063892\n",
      "Test set: Average loss: 2.2314, Accuracy: 2960/5000 (59%)\n",
      "[epoch 45] loss: 0.0057630\n",
      "Test set: Average loss: 2.2567, Accuracy: 2957/5000 (59%)\n",
      "[epoch 46] loss: 0.0051866\n",
      "Test set: Average loss: 2.2853, Accuracy: 2965/5000 (59%)\n",
      "[epoch 47] loss: 0.0046390\n",
      "Test set: Average loss: 2.3036, Accuracy: 2954/5000 (59%)\n",
      "[epoch 48] loss: 0.0041830\n",
      "Test set: Average loss: 2.3330, Accuracy: 2958/5000 (59%)\n",
      "[epoch 49] loss: 0.0037261\n",
      "Test set: Average loss: 2.3565, Accuracy: 2955/5000 (59%)\n",
      "[epoch 50] loss: 0.0033354\n",
      "Test set: Average loss: 2.3876, Accuracy: 2962/5000 (59%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.1912, Accuracy: 2990/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 1.1640, Accuracy: 6007/10000 (60%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3011, Accuracy: 611/5000 (12%)\n",
      "[epoch 1] loss: 1.2618602\n",
      "Test set: Average loss: 1.2815, Accuracy: 2806/5000 (56%)\n",
      "[epoch 2] loss: 1.1243938\n",
      "Test set: Average loss: 1.1845, Accuracy: 2943/5000 (59%)\n",
      "[epoch 3] loss: 1.0682094\n",
      "Test set: Average loss: 1.1956, Accuracy: 2914/5000 (58%)\n",
      "[epoch 4] loss: 1.0171771\n",
      "Test set: Average loss: 1.1523, Accuracy: 2964/5000 (59%)\n",
      "[epoch 5] loss: 0.9996155\n",
      "Test set: Average loss: 1.1475, Accuracy: 3030/5000 (61%)\n",
      "[epoch 6] loss: 0.9677919\n",
      "Test set: Average loss: 1.1681, Accuracy: 3004/5000 (60%)\n",
      "[epoch 7] loss: 0.9456233\n",
      "Test set: Average loss: 1.2417, Accuracy: 2847/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 0.9178436\n",
      "Test set: Average loss: 1.1637, Accuracy: 2999/5000 (60%)\n",
      "[epoch 9] loss: 0.9033720\n",
      "Test set: Average loss: 1.2181, Accuracy: 2969/5000 (59%)\n",
      "[epoch 10] loss: 0.8712463\n",
      "Test set: Average loss: 1.1584, Accuracy: 3061/5000 (61%)\n",
      "[epoch 11] loss: 0.8353372\n",
      "Test set: Average loss: 1.1316, Accuracy: 3052/5000 (61%)\n",
      "[epoch 12] loss: 0.8013219\n",
      "Test set: Average loss: 1.1694, Accuracy: 3057/5000 (61%)\n",
      "[epoch 13] loss: 0.7693257\n",
      "Test set: Average loss: 1.2174, Accuracy: 2995/5000 (60%)\n",
      "[epoch 14] loss: 0.7549258\n",
      "Test set: Average loss: 1.1887, Accuracy: 3096/5000 (62%)\n",
      "[epoch 15] loss: 0.7070776\n",
      "Test set: Average loss: 1.2094, Accuracy: 3050/5000 (61%)\n",
      "[epoch 16] loss: 0.6593017\n",
      "Test set: Average loss: 1.2608, Accuracy: 2999/5000 (60%)\n",
      "[epoch 17] loss: 0.6111398\n",
      "Test set: Average loss: 1.3282, Accuracy: 2965/5000 (59%)\n",
      "[epoch 18] loss: 0.5585967\n",
      "Test set: Average loss: 1.2652, Accuracy: 3051/5000 (61%)\n",
      "[epoch 19] loss: 0.5050112\n",
      "Test set: Average loss: 1.3216, Accuracy: 3059/5000 (61%)\n",
      "[epoch 20] loss: 0.4413052\n",
      "Test set: Average loss: 1.3743, Accuracy: 3024/5000 (60%)\n",
      "[epoch 21] loss: 0.3781210\n",
      "Test set: Average loss: 1.4182, Accuracy: 2994/5000 (60%)\n",
      "[epoch 22] loss: 0.3428697\n",
      "Test set: Average loss: 1.4711, Accuracy: 3032/5000 (61%)\n",
      "[epoch 23] loss: 0.2727747\n",
      "Test set: Average loss: 1.4967, Accuracy: 3049/5000 (61%)\n",
      "[epoch 24] loss: 0.2128047\n",
      "Test set: Average loss: 1.5595, Accuracy: 3048/5000 (61%)\n",
      "[epoch 25] loss: 0.1894935\n",
      "Test set: Average loss: 1.6614, Accuracy: 3016/5000 (60%)\n",
      "[epoch 26] loss: 0.1375452\n",
      "Test set: Average loss: 1.7757, Accuracy: 3013/5000 (60%)\n",
      "[epoch 27] loss: 0.1158576\n",
      "Test set: Average loss: 2.0020, Accuracy: 2915/5000 (58%)\n",
      "[epoch 28] loss: 0.1770248\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7950, Accuracy: 3035/5000 (61%)\n",
      "[epoch 29] loss: 0.0435890\n",
      "Test set: Average loss: 1.7579, Accuracy: 3068/5000 (61%)\n",
      "[epoch 30] loss: 0.0249870\n",
      "Test set: Average loss: 1.7689, Accuracy: 3077/5000 (62%)\n",
      "[epoch 31] loss: 0.0188339\n",
      "Test set: Average loss: 1.7828, Accuracy: 3080/5000 (62%)\n",
      "[epoch 32] loss: 0.0152455\n",
      "Test set: Average loss: 1.8042, Accuracy: 3090/5000 (62%)\n",
      "[epoch 33] loss: 0.0127020\n",
      "Test set: Average loss: 1.8204, Accuracy: 3096/5000 (62%)\n",
      "[epoch 34] loss: 0.0106535\n",
      "Test set: Average loss: 1.8450, Accuracy: 3088/5000 (62%)\n",
      "[epoch 35] loss: 0.0090896\n",
      "Test set: Average loss: 1.8572, Accuracy: 3096/5000 (62%)\n",
      "[epoch 36] loss: 0.0077324\n",
      "Test set: Average loss: 1.8854, Accuracy: 3103/5000 (62%)\n",
      "[epoch 37] loss: 0.0066121\n",
      "Test set: Average loss: 1.9061, Accuracy: 3103/5000 (62%)\n",
      "[epoch 38] loss: 0.0056288\n",
      "Test set: Average loss: 1.9298, Accuracy: 3114/5000 (62%)\n",
      "[epoch 39] loss: 0.0047907\n",
      "Test set: Average loss: 1.9586, Accuracy: 3105/5000 (62%)\n",
      "[epoch 40] loss: 0.0040595\n",
      "Test set: Average loss: 1.9930, Accuracy: 3110/5000 (62%)\n",
      "[epoch 41] loss: 0.0034304\n",
      "Test set: Average loss: 2.0201, Accuracy: 3111/5000 (62%)\n",
      "[epoch 42] loss: 0.0028917\n",
      "Test set: Average loss: 2.0487, Accuracy: 3111/5000 (62%)\n",
      "[epoch 43] loss: 0.0024206\n",
      "Test set: Average loss: 2.0736, Accuracy: 3117/5000 (62%)\n",
      "[epoch 44] loss: 0.0020175\n",
      "Test set: Average loss: 2.1121, Accuracy: 3123/5000 (62%)\n",
      "[epoch 45] loss: 0.0016778\n",
      "Test set: Average loss: 2.1458, Accuracy: 3131/5000 (63%)\n",
      "[epoch 46] loss: 0.0013886\n",
      "Test set: Average loss: 2.1882, Accuracy: 3116/5000 (62%)\n",
      "[epoch 47] loss: 0.0011425\n",
      "Test set: Average loss: 2.2189, Accuracy: 3124/5000 (62%)\n",
      "[epoch 48] loss: 0.0009403\n",
      "Test set: Average loss: 2.2559, Accuracy: 3120/5000 (62%)\n",
      "[epoch 49] loss: 0.0007725\n",
      "Test set: Average loss: 2.2945, Accuracy: 3123/5000 (62%)\n",
      "[epoch 50] loss: 0.0006303\n",
      "Test set: Average loss: 2.3255, Accuracy: 3116/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1458, Accuracy: 3131/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.0526, Accuracy: 6391/10000 (64%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3059, Accuracy: 482/5000 (10%)\n",
      "[epoch 1] loss: 1.2652807\n",
      "Test set: Average loss: 1.1769, Accuracy: 2902/5000 (58%)\n",
      "[epoch 2] loss: 1.1183654\n",
      "Test set: Average loss: 1.2463, Accuracy: 2832/5000 (57%)\n",
      "[epoch 3] loss: 1.0661388\n",
      "Test set: Average loss: 1.2155, Accuracy: 2937/5000 (59%)\n",
      "[epoch 4] loss: 1.0314271\n",
      "Test set: Average loss: 1.1666, Accuracy: 2933/5000 (59%)\n",
      "[epoch 5] loss: 1.0004820\n",
      "Test set: Average loss: 1.1647, Accuracy: 2977/5000 (60%)\n",
      "[epoch 6] loss: 0.9770961\n",
      "Test set: Average loss: 1.1711, Accuracy: 2984/5000 (60%)\n",
      "[epoch 7] loss: 0.9422427\n",
      "Test set: Average loss: 1.1668, Accuracy: 2990/5000 (60%)\n",
      "[epoch 8] loss: 0.9161492\n",
      "Test set: Average loss: 1.1888, Accuracy: 2971/5000 (59%)\n",
      "[epoch 9] loss: 0.8913064\n",
      "Test set: Average loss: 1.1586, Accuracy: 3068/5000 (61%)\n",
      "[epoch 10] loss: 0.8706784\n",
      "Test set: Average loss: 1.1328, Accuracy: 3034/5000 (61%)\n",
      "[epoch 11] loss: 0.8445609\n",
      "Test set: Average loss: 1.1614, Accuracy: 3088/5000 (62%)\n",
      "[epoch 12] loss: 0.8033870\n",
      "Test set: Average loss: 1.1869, Accuracy: 3001/5000 (60%)\n",
      "[epoch 13] loss: 0.7810640\n",
      "Test set: Average loss: 1.2516, Accuracy: 3001/5000 (60%)\n",
      "[epoch 14] loss: 0.7495985\n",
      "Test set: Average loss: 1.2435, Accuracy: 3006/5000 (60%)\n",
      "[epoch 15] loss: 0.7026278\n",
      "Test set: Average loss: 1.2114, Accuracy: 3065/5000 (61%)\n",
      "[epoch 16] loss: 0.6683613\n",
      "Test set: Average loss: 1.2472, Accuracy: 3040/5000 (61%)\n",
      "[epoch 17] loss: 0.6035561\n",
      "Test set: Average loss: 1.2963, Accuracy: 2973/5000 (59%)\n",
      "[epoch 18] loss: 0.5677401\n",
      "Test set: Average loss: 1.3116, Accuracy: 3015/5000 (60%)\n",
      "[epoch 19] loss: 0.5070122\n",
      "Test set: Average loss: 1.2948, Accuracy: 3010/5000 (60%)\n",
      "[epoch 20] loss: 0.4482017\n",
      "Test set: Average loss: 1.3550, Accuracy: 3055/5000 (61%)\n",
      "[epoch 21] loss: 0.3743928\n",
      "Test set: Average loss: 1.4309, Accuracy: 2964/5000 (59%)\n",
      "[epoch 22] loss: 0.3185499\n",
      "Test set: Average loss: 1.5004, Accuracy: 3019/5000 (60%)\n",
      "[epoch 23] loss: 0.2571299\n",
      "Test set: Average loss: 1.5256, Accuracy: 3032/5000 (61%)\n",
      "[epoch 24] loss: 0.2078305\n",
      "Test set: Average loss: 1.6325, Accuracy: 2980/5000 (60%)\n",
      "[epoch 25] loss: 0.1551967\n",
      "Test set: Average loss: 1.6982, Accuracy: 3037/5000 (61%)\n",
      "[epoch 26] loss: 0.1532564\n",
      "Test set: Average loss: 1.7111, Accuracy: 3073/5000 (61%)\n",
      "[epoch 27] loss: 0.1073749\n",
      "Test set: Average loss: 1.8231, Accuracy: 3061/5000 (61%)\n",
      "[epoch 28] loss: 0.1047337\n",
      "Test set: Average loss: 1.8796, Accuracy: 3007/5000 (60%)\n",
      "[epoch 29] loss: 0.0831287\n",
      "Test set: Average loss: 1.9705, Accuracy: 3053/5000 (61%)\n",
      "[epoch 30] loss: 0.1123058\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0217, Accuracy: 2952/5000 (59%)\n",
      "[epoch 31] loss: 0.0357214\n",
      "Test set: Average loss: 1.9451, Accuracy: 3081/5000 (62%)\n",
      "[epoch 32] loss: 0.0142262\n",
      "Test set: Average loss: 1.9496, Accuracy: 3097/5000 (62%)\n",
      "[epoch 33] loss: 0.0104641\n",
      "Test set: Average loss: 1.9567, Accuracy: 3109/5000 (62%)\n",
      "[epoch 34] loss: 0.0083861\n",
      "Test set: Average loss: 1.9681, Accuracy: 3128/5000 (63%)\n",
      "[epoch 35] loss: 0.0069963\n",
      "Test set: Average loss: 1.9796, Accuracy: 3133/5000 (63%)\n",
      "[epoch 36] loss: 0.0059293\n",
      "Test set: Average loss: 1.9936, Accuracy: 3133/5000 (63%)\n",
      "[epoch 37] loss: 0.0050694\n",
      "Test set: Average loss: 2.0083, Accuracy: 3130/5000 (63%)\n",
      "[epoch 38] loss: 0.0043635\n",
      "Test set: Average loss: 2.0220, Accuracy: 3133/5000 (63%)\n",
      "[epoch 39] loss: 0.0037451\n",
      "Test set: Average loss: 2.0453, Accuracy: 3137/5000 (63%)\n",
      "[epoch 40] loss: 0.0032267\n",
      "Test set: Average loss: 2.0651, Accuracy: 3146/5000 (63%)\n",
      "[epoch 41] loss: 0.0027685\n",
      "Test set: Average loss: 2.0853, Accuracy: 3133/5000 (63%)\n",
      "[epoch 42] loss: 0.0023701\n",
      "Test set: Average loss: 2.1048, Accuracy: 3147/5000 (63%)\n",
      "[epoch 43] loss: 0.0020261\n",
      "Test set: Average loss: 2.1298, Accuracy: 3153/5000 (63%)\n",
      "[epoch 44] loss: 0.0017178\n",
      "Test set: Average loss: 2.1571, Accuracy: 3146/5000 (63%)\n",
      "[epoch 45] loss: 0.0014535\n",
      "Test set: Average loss: 2.1817, Accuracy: 3145/5000 (63%)\n",
      "[epoch 46] loss: 0.0012231\n",
      "Test set: Average loss: 2.2147, Accuracy: 3155/5000 (63%)\n",
      "[epoch 47] loss: 0.0010280\n",
      "Test set: Average loss: 2.2421, Accuracy: 3141/5000 (63%)\n",
      "[epoch 48] loss: 0.0008568\n",
      "Test set: Average loss: 2.2746, Accuracy: 3135/5000 (63%)\n",
      "[epoch 49] loss: 0.0007123\n",
      "Test set: Average loss: 2.3079, Accuracy: 3152/5000 (63%)\n",
      "[epoch 50] loss: 0.0005880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3407, Accuracy: 3149/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2147, Accuracy: 3155/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.1405, Accuracy: 6399/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3022, Accuracy: 541/5000 (11%)\n",
      "[epoch 1] loss: 1.2656785\n",
      "Test set: Average loss: 1.2758, Accuracy: 2843/5000 (57%)\n",
      "[epoch 2] loss: 1.1415435\n",
      "Test set: Average loss: 1.2044, Accuracy: 2924/5000 (58%)\n",
      "[epoch 3] loss: 1.0930758\n",
      "Test set: Average loss: 1.3076, Accuracy: 2742/5000 (55%)\n",
      "[epoch 4] loss: 1.0516163\n",
      "Test set: Average loss: 1.1438, Accuracy: 3028/5000 (61%)\n",
      "[epoch 5] loss: 1.0145425\n",
      "Test set: Average loss: 1.1962, Accuracy: 2945/5000 (59%)\n",
      "[epoch 6] loss: 0.9832694\n",
      "Test set: Average loss: 1.2113, Accuracy: 2920/5000 (58%)\n",
      "[epoch 7] loss: 0.9634780\n",
      "Test set: Average loss: 1.1894, Accuracy: 2980/5000 (60%)\n",
      "[epoch 8] loss: 0.9393856\n",
      "Test set: Average loss: 1.1138, Accuracy: 3069/5000 (61%)\n",
      "[epoch 9] loss: 0.9118022\n",
      "Test set: Average loss: 1.1435, Accuracy: 3043/5000 (61%)\n",
      "[epoch 10] loss: 0.8773247\n",
      "Test set: Average loss: 1.1613, Accuracy: 3033/5000 (61%)\n",
      "[epoch 11] loss: 0.8494895\n",
      "Test set: Average loss: 1.1475, Accuracy: 3061/5000 (61%)\n",
      "[epoch 12] loss: 0.8192250\n",
      "Test set: Average loss: 1.2248, Accuracy: 2992/5000 (60%)\n",
      "[epoch 13] loss: 0.7837470\n",
      "Test set: Average loss: 1.1861, Accuracy: 2995/5000 (60%)\n",
      "[epoch 14] loss: 0.7391723\n",
      "Test set: Average loss: 1.2229, Accuracy: 3006/5000 (60%)\n",
      "[epoch 15] loss: 0.7059417\n",
      "Test set: Average loss: 1.2364, Accuracy: 3034/5000 (61%)\n",
      "[epoch 16] loss: 0.6437888\n",
      "Test set: Average loss: 1.2499, Accuracy: 3017/5000 (60%)\n",
      "[epoch 17] loss: 0.5994073\n",
      "Test set: Average loss: 1.2321, Accuracy: 3094/5000 (62%)\n",
      "[epoch 18] loss: 0.5344954\n",
      "Test set: Average loss: 1.2963, Accuracy: 3078/5000 (62%)\n",
      "[epoch 19] loss: 0.4794502\n",
      "Test set: Average loss: 1.3377, Accuracy: 3080/5000 (62%)\n",
      "[epoch 20] loss: 0.4248804\n",
      "Test set: Average loss: 1.3802, Accuracy: 3047/5000 (61%)\n",
      "[epoch 21] loss: 0.3393391\n",
      "Test set: Average loss: 1.3939, Accuracy: 3066/5000 (61%)\n",
      "[epoch 22] loss: 0.2902001\n",
      "Test set: Average loss: 1.4790, Accuracy: 3007/5000 (60%)\n",
      "[epoch 23] loss: 0.2203415\n",
      "Test set: Average loss: 1.5650, Accuracy: 3042/5000 (61%)\n",
      "[epoch 24] loss: 0.1676353\n",
      "Test set: Average loss: 1.6786, Accuracy: 2989/5000 (60%)\n",
      "[epoch 25] loss: 0.1330035\n",
      "Test set: Average loss: 1.6692, Accuracy: 3100/5000 (62%)\n",
      "[epoch 26] loss: 0.0986025\n",
      "Test set: Average loss: 1.7501, Accuracy: 3013/5000 (60%)\n",
      "[epoch 27] loss: 0.1009358\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9779, Accuracy: 2917/5000 (58%)\n",
      "[epoch 28] loss: 0.0464680\n",
      "Test set: Average loss: 1.7817, Accuracy: 3092/5000 (62%)\n",
      "[epoch 29] loss: 0.0203333\n",
      "Test set: Average loss: 1.7918, Accuracy: 3095/5000 (62%)\n",
      "[epoch 30] loss: 0.0152847\n",
      "Test set: Average loss: 1.8072, Accuracy: 3105/5000 (62%)\n",
      "[epoch 31] loss: 0.0123642\n",
      "Test set: Average loss: 1.8237, Accuracy: 3108/5000 (62%)\n",
      "[epoch 32] loss: 0.0103505\n",
      "Test set: Average loss: 1.8384, Accuracy: 3121/5000 (62%)\n",
      "[epoch 33] loss: 0.0088019\n",
      "Test set: Average loss: 1.8573, Accuracy: 3125/5000 (62%)\n",
      "[epoch 34] loss: 0.0075165\n",
      "Test set: Average loss: 1.8783, Accuracy: 3122/5000 (62%)\n",
      "[epoch 35] loss: 0.0064711\n",
      "Test set: Average loss: 1.8968, Accuracy: 3134/5000 (63%)\n",
      "[epoch 36] loss: 0.0055346\n",
      "Test set: Average loss: 1.9224, Accuracy: 3140/5000 (63%)\n",
      "[epoch 37] loss: 0.0047450\n",
      "Test set: Average loss: 1.9460, Accuracy: 3139/5000 (63%)\n",
      "[epoch 38] loss: 0.0040593\n",
      "Test set: Average loss: 1.9715, Accuracy: 3139/5000 (63%)\n",
      "[epoch 39] loss: 0.0034771\n",
      "Test set: Average loss: 1.9970, Accuracy: 3141/5000 (63%)\n",
      "[epoch 40] loss: 0.0029407\n",
      "Test set: Average loss: 2.0300, Accuracy: 3145/5000 (63%)\n",
      "[epoch 41] loss: 0.0024765\n",
      "Test set: Average loss: 2.0535, Accuracy: 3136/5000 (63%)\n",
      "[epoch 42] loss: 0.0020776\n",
      "Test set: Average loss: 2.0928, Accuracy: 3135/5000 (63%)\n",
      "[epoch 43] loss: 0.0017325\n",
      "Test set: Average loss: 2.1301, Accuracy: 3140/5000 (63%)\n",
      "[epoch 44] loss: 0.0014488\n",
      "Test set: Average loss: 2.1602, Accuracy: 3143/5000 (63%)\n",
      "[epoch 45] loss: 0.0012015\n",
      "Test set: Average loss: 2.1981, Accuracy: 3142/5000 (63%)\n",
      "[epoch 46] loss: 0.0009934\n",
      "Test set: Average loss: 2.2246, Accuracy: 3136/5000 (63%)\n",
      "[epoch 47] loss: 0.0008156\n",
      "Test set: Average loss: 2.2664, Accuracy: 3146/5000 (63%)\n",
      "[epoch 48] loss: 0.0006663\n",
      "Test set: Average loss: 2.3012, Accuracy: 3146/5000 (63%)\n",
      "[epoch 49] loss: 0.0005460\n",
      "Test set: Average loss: 2.3436, Accuracy: 3147/5000 (63%)\n",
      "[epoch 50] loss: 0.0004457\n",
      "Test set: Average loss: 2.3782, Accuracy: 3139/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3436, Accuracy: 3147/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.2517, Accuracy: 6366/10000 (64%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3062, Accuracy: 389/5000 (8%)\n",
      "[epoch 1] loss: 1.2337292\n",
      "Test set: Average loss: 1.1586, Accuracy: 2968/5000 (59%)\n",
      "[epoch 2] loss: 1.1048014\n",
      "Test set: Average loss: 1.1328, Accuracy: 3054/5000 (61%)\n",
      "[epoch 3] loss: 1.0531643\n",
      "Test set: Average loss: 1.0947, Accuracy: 3076/5000 (62%)\n",
      "[epoch 4] loss: 1.0244967\n",
      "Test set: Average loss: 1.1301, Accuracy: 3015/5000 (60%)\n",
      "[epoch 5] loss: 0.9899418\n",
      "Test set: Average loss: 1.1154, Accuracy: 3031/5000 (61%)\n",
      "[epoch 6] loss: 0.9690223\n",
      "Test set: Average loss: 1.1332, Accuracy: 3033/5000 (61%)\n",
      "[epoch 7] loss: 0.9450592\n",
      "Test set: Average loss: 1.1432, Accuracy: 3003/5000 (60%)\n",
      "[epoch 8] loss: 0.9144757\n",
      "Test set: Average loss: 1.1093, Accuracy: 3065/5000 (61%)\n",
      "[epoch 9] loss: 0.8883332\n",
      "Test set: Average loss: 1.1273, Accuracy: 3060/5000 (61%)\n",
      "[epoch 10] loss: 0.8601517\n",
      "Test set: Average loss: 1.1969, Accuracy: 2976/5000 (60%)\n",
      "[epoch 11] loss: 0.8253174\n",
      "Test set: Average loss: 1.1225, Accuracy: 3103/5000 (62%)\n",
      "[epoch 12] loss: 0.7844978\n",
      "Test set: Average loss: 1.1394, Accuracy: 3071/5000 (61%)\n",
      "[epoch 13] loss: 0.7466406\n",
      "Test set: Average loss: 1.0907, Accuracy: 3201/5000 (64%)\n",
      "[epoch 14] loss: 0.6958072\n",
      "Test set: Average loss: 1.1479, Accuracy: 3092/5000 (62%)\n",
      "[epoch 15] loss: 0.6471364\n",
      "Test set: Average loss: 1.1221, Accuracy: 3177/5000 (64%)\n",
      "[epoch 16] loss: 0.5920382\n",
      "Test set: Average loss: 1.1724, Accuracy: 3175/5000 (64%)\n",
      "[epoch 17] loss: 0.5345680\n",
      "Test set: Average loss: 1.1781, Accuracy: 3156/5000 (63%)\n",
      "[epoch 18] loss: 0.4836872\n",
      "Test set: Average loss: 1.2541, Accuracy: 3177/5000 (64%)\n",
      "[epoch 19] loss: 0.4050375\n",
      "Test set: Average loss: 1.3077, Accuracy: 3117/5000 (62%)\n",
      "[epoch 20] loss: 0.3470114\n",
      "Test set: Average loss: 1.3371, Accuracy: 3145/5000 (63%)\n",
      "[epoch 21] loss: 0.2748691\n",
      "Test set: Average loss: 1.4124, Accuracy: 3101/5000 (62%)\n",
      "[epoch 22] loss: 0.2285403\n",
      "Test set: Average loss: 1.4787, Accuracy: 3177/5000 (64%)\n",
      "[epoch 23] loss: 0.1600385\n",
      "Test set: Average loss: 1.5521, Accuracy: 3151/5000 (63%)\n",
      "[epoch 24] loss: 0.1202258\n",
      "Test set: Average loss: 1.6715, Accuracy: 3143/5000 (63%)\n",
      "[epoch 25] loss: 0.1098328\n",
      "Test set: Average loss: 1.8234, Accuracy: 3081/5000 (62%)\n",
      "[epoch 26] loss: 0.1545765\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7907, Accuracy: 3119/5000 (62%)\n",
      "[epoch 27] loss: 0.0421187\n",
      "Test set: Average loss: 1.6930, Accuracy: 3227/5000 (65%)\n",
      "[epoch 28] loss: 0.0181497\n",
      "Test set: Average loss: 1.6976, Accuracy: 3234/5000 (65%)\n",
      "[epoch 29] loss: 0.0130192\n",
      "Test set: Average loss: 1.7203, Accuracy: 3245/5000 (65%)\n",
      "[epoch 30] loss: 0.0100907\n",
      "Test set: Average loss: 1.7355, Accuracy: 3243/5000 (65%)\n",
      "[epoch 31] loss: 0.0080651\n",
      "Test set: Average loss: 1.7544, Accuracy: 3240/5000 (65%)\n",
      "[epoch 32] loss: 0.0065929\n",
      "Test set: Average loss: 1.7762, Accuracy: 3239/5000 (65%)\n",
      "[epoch 33] loss: 0.0053793\n",
      "Test set: Average loss: 1.8021, Accuracy: 3231/5000 (65%)\n",
      "[epoch 34] loss: 0.0043593\n",
      "Test set: Average loss: 1.8249, Accuracy: 3242/5000 (65%)\n",
      "[epoch 35] loss: 0.0035459\n",
      "Test set: Average loss: 1.8498, Accuracy: 3236/5000 (65%)\n",
      "[epoch 36] loss: 0.0028626\n",
      "Test set: Average loss: 1.8814, Accuracy: 3240/5000 (65%)\n",
      "[epoch 37] loss: 0.0022906\n",
      "Test set: Average loss: 1.9135, Accuracy: 3254/5000 (65%)\n",
      "[epoch 38] loss: 0.0018330\n",
      "Test set: Average loss: 1.9500, Accuracy: 3245/5000 (65%)\n",
      "[epoch 39] loss: 0.0014468\n",
      "Test set: Average loss: 1.9841, Accuracy: 3244/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40] loss: 0.0011417\n",
      "Test set: Average loss: 2.0208, Accuracy: 3250/5000 (65%)\n",
      "[epoch 41] loss: 0.0008933\n",
      "Test set: Average loss: 2.0650, Accuracy: 3249/5000 (65%)\n",
      "[epoch 42] loss: 0.0006971\n",
      "Test set: Average loss: 2.0963, Accuracy: 3258/5000 (65%)\n",
      "[epoch 43] loss: 0.0005366\n",
      "Test set: Average loss: 2.1403, Accuracy: 3258/5000 (65%)\n",
      "[epoch 44] loss: 0.0004179\n",
      "Test set: Average loss: 2.1780, Accuracy: 3268/5000 (65%)\n",
      "[epoch 45] loss: 0.0003208\n",
      "Test set: Average loss: 2.2255, Accuracy: 3258/5000 (65%)\n",
      "[epoch 46] loss: 0.0002460\n",
      "Test set: Average loss: 2.2726, Accuracy: 3270/5000 (65%)\n",
      "[epoch 47] loss: 0.0001885\n",
      "Test set: Average loss: 2.3142, Accuracy: 3256/5000 (65%)\n",
      "[epoch 48] loss: 0.0001431\n",
      "Test set: Average loss: 2.3586, Accuracy: 3266/5000 (65%)\n",
      "[epoch 49] loss: 0.0001091\n",
      "Test set: Average loss: 2.4108, Accuracy: 3269/5000 (65%)\n",
      "[epoch 50] loss: 0.0000829\n",
      "Test set: Average loss: 2.4528, Accuracy: 3261/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2726, Accuracy: 3270/5000 (65%)\n",
      "Test\n",
      "Test set: Average loss: 2.2155, Accuracy: 6606/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 448/5000 (9%)\n",
      "[epoch 1] loss: 1.2345585\n",
      "Test set: Average loss: 1.2604, Accuracy: 2803/5000 (56%)\n",
      "[epoch 2] loss: 1.1109473\n",
      "Test set: Average loss: 1.1577, Accuracy: 2969/5000 (59%)\n",
      "[epoch 3] loss: 1.0615098\n",
      "Test set: Average loss: 1.0990, Accuracy: 3058/5000 (61%)\n",
      "[epoch 4] loss: 1.0211484\n",
      "Test set: Average loss: 1.2048, Accuracy: 2879/5000 (58%)\n",
      "[epoch 5] loss: 0.9931095\n",
      "Test set: Average loss: 1.0720, Accuracy: 3135/5000 (63%)\n",
      "[epoch 6] loss: 0.9725564\n",
      "Test set: Average loss: 1.1636, Accuracy: 2995/5000 (60%)\n",
      "[epoch 7] loss: 0.9461295\n",
      "Test set: Average loss: 1.1028, Accuracy: 3082/5000 (62%)\n",
      "[epoch 8] loss: 0.9194110\n",
      "Test set: Average loss: 1.1057, Accuracy: 3059/5000 (61%)\n",
      "[epoch 9] loss: 0.8883662\n",
      "Test set: Average loss: 1.0946, Accuracy: 3110/5000 (62%)\n",
      "[epoch 10] loss: 0.8530642\n",
      "Test set: Average loss: 1.1652, Accuracy: 3016/5000 (60%)\n",
      "[epoch 11] loss: 0.8323843\n",
      "Test set: Average loss: 1.1440, Accuracy: 3079/5000 (62%)\n",
      "[epoch 12] loss: 0.7789952\n",
      "Test set: Average loss: 1.1665, Accuracy: 3074/5000 (61%)\n",
      "[epoch 13] loss: 0.7335561\n",
      "Test set: Average loss: 1.2181, Accuracy: 2969/5000 (59%)\n",
      "[epoch 14] loss: 0.6980071\n",
      "Test set: Average loss: 1.2168, Accuracy: 3011/5000 (60%)\n",
      "[epoch 15] loss: 0.6473017\n",
      "Test set: Average loss: 1.1108, Accuracy: 3175/5000 (64%)\n",
      "[epoch 16] loss: 0.6080611\n",
      "Test set: Average loss: 1.1966, Accuracy: 3126/5000 (63%)\n",
      "[epoch 17] loss: 0.5355463\n",
      "Test set: Average loss: 1.2211, Accuracy: 3142/5000 (63%)\n",
      "[epoch 18] loss: 0.4759972\n",
      "Test set: Average loss: 1.2886, Accuracy: 3087/5000 (62%)\n",
      "[epoch 19] loss: 0.4166431\n",
      "Test set: Average loss: 1.2710, Accuracy: 3185/5000 (64%)\n",
      "[epoch 20] loss: 0.3397579\n",
      "Test set: Average loss: 1.3338, Accuracy: 3094/5000 (62%)\n",
      "[epoch 21] loss: 0.2717093\n",
      "Test set: Average loss: 1.4246, Accuracy: 3110/5000 (62%)\n",
      "[epoch 22] loss: 0.2319795\n",
      "Test set: Average loss: 1.4911, Accuracy: 3109/5000 (62%)\n",
      "[epoch 23] loss: 0.1649705\n",
      "Test set: Average loss: 1.5519, Accuracy: 3091/5000 (62%)\n",
      "[epoch 24] loss: 0.1361577\n",
      "Test set: Average loss: 1.6177, Accuracy: 3134/5000 (63%)\n",
      "[epoch 25] loss: 0.1046442\n",
      "Test set: Average loss: 1.7446, Accuracy: 3109/5000 (62%)\n",
      "[epoch 26] loss: 0.1028890\n",
      "Test set: Average loss: 1.8420, Accuracy: 3037/5000 (61%)\n",
      "[epoch 27] loss: 0.1133961\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7965, Accuracy: 3149/5000 (63%)\n",
      "[epoch 28] loss: 0.0348923\n",
      "Test set: Average loss: 1.7414, Accuracy: 3220/5000 (64%)\n",
      "[epoch 29] loss: 0.0137051\n",
      "Test set: Average loss: 1.7484, Accuracy: 3210/5000 (64%)\n",
      "[epoch 30] loss: 0.0097636\n",
      "Test set: Average loss: 1.7609, Accuracy: 3214/5000 (64%)\n",
      "[epoch 31] loss: 0.0075876\n",
      "Test set: Average loss: 1.7791, Accuracy: 3213/5000 (64%)\n",
      "[epoch 32] loss: 0.0060617\n",
      "Test set: Average loss: 1.7956, Accuracy: 3226/5000 (65%)\n",
      "[epoch 33] loss: 0.0049172\n",
      "Test set: Average loss: 1.8190, Accuracy: 3230/5000 (65%)\n",
      "[epoch 34] loss: 0.0040027\n",
      "Test set: Average loss: 1.8368, Accuracy: 3236/5000 (65%)\n",
      "[epoch 35] loss: 0.0032624\n",
      "Test set: Average loss: 1.8607, Accuracy: 3236/5000 (65%)\n",
      "[epoch 36] loss: 0.0026510\n",
      "Test set: Average loss: 1.8863, Accuracy: 3247/5000 (65%)\n",
      "[epoch 37] loss: 0.0021424\n",
      "Test set: Average loss: 1.9126, Accuracy: 3248/5000 (65%)\n",
      "[epoch 38] loss: 0.0017192\n",
      "Test set: Average loss: 1.9410, Accuracy: 3237/5000 (65%)\n",
      "[epoch 39] loss: 0.0013765\n",
      "Test set: Average loss: 1.9752, Accuracy: 3251/5000 (65%)\n",
      "[epoch 40] loss: 0.0010940\n",
      "Test set: Average loss: 2.0083, Accuracy: 3245/5000 (65%)\n",
      "[epoch 41] loss: 0.0008658\n",
      "Test set: Average loss: 2.0469, Accuracy: 3251/5000 (65%)\n",
      "[epoch 42] loss: 0.0006792\n",
      "Test set: Average loss: 2.0812, Accuracy: 3262/5000 (65%)\n",
      "[epoch 43] loss: 0.0005293\n",
      "Test set: Average loss: 2.1187, Accuracy: 3262/5000 (65%)\n",
      "[epoch 44] loss: 0.0004117\n",
      "Test set: Average loss: 2.1576, Accuracy: 3269/5000 (65%)\n",
      "[epoch 45] loss: 0.0003196\n",
      "Test set: Average loss: 2.1980, Accuracy: 3268/5000 (65%)\n",
      "[epoch 46] loss: 0.0002455\n",
      "Test set: Average loss: 2.2425, Accuracy: 3282/5000 (66%)\n",
      "[epoch 47] loss: 0.0001887\n",
      "Test set: Average loss: 2.2765, Accuracy: 3271/5000 (65%)\n",
      "[epoch 48] loss: 0.0001438\n",
      "Test set: Average loss: 2.3233, Accuracy: 3278/5000 (66%)\n",
      "[epoch 49] loss: 0.0001093\n",
      "Test set: Average loss: 2.3716, Accuracy: 3285/5000 (66%)\n",
      "[epoch 50] loss: 0.0000835\n",
      "Test set: Average loss: 2.4106, Accuracy: 3286/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4106, Accuracy: 3286/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.3691, Accuracy: 6588/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3000, Accuracy: 567/5000 (11%)\n",
      "[epoch 1] loss: 1.2385989\n",
      "Test set: Average loss: 1.2489, Accuracy: 2792/5000 (56%)\n",
      "[epoch 2] loss: 1.1222747\n",
      "Test set: Average loss: 1.1650, Accuracy: 2964/5000 (59%)\n",
      "[epoch 3] loss: 1.0679373\n",
      "Test set: Average loss: 1.1480, Accuracy: 2972/5000 (59%)\n",
      "[epoch 4] loss: 1.0361239\n",
      "Test set: Average loss: 1.1436, Accuracy: 3003/5000 (60%)\n",
      "[epoch 5] loss: 1.0040296\n",
      "Test set: Average loss: 1.1572, Accuracy: 3013/5000 (60%)\n",
      "[epoch 6] loss: 0.9870685\n",
      "Test set: Average loss: 1.1456, Accuracy: 3029/5000 (61%)\n",
      "[epoch 7] loss: 0.9557101\n",
      "Test set: Average loss: 1.1076, Accuracy: 3048/5000 (61%)\n",
      "[epoch 8] loss: 0.9267302\n",
      "Test set: Average loss: 1.1395, Accuracy: 3020/5000 (60%)\n",
      "[epoch 9] loss: 0.8916679\n",
      "Test set: Average loss: 1.1371, Accuracy: 3062/5000 (61%)\n",
      "[epoch 10] loss: 0.8682096\n",
      "Test set: Average loss: 1.0595, Accuracy: 3181/5000 (64%)\n",
      "[epoch 11] loss: 0.8336210\n",
      "Test set: Average loss: 1.1590, Accuracy: 3050/5000 (61%)\n",
      "[epoch 12] loss: 0.8000233\n",
      "Test set: Average loss: 1.0895, Accuracy: 3196/5000 (64%)\n",
      "[epoch 13] loss: 0.7665125\n",
      "Test set: Average loss: 1.1521, Accuracy: 3115/5000 (62%)\n",
      "[epoch 14] loss: 0.7196379\n",
      "Test set: Average loss: 1.1666, Accuracy: 3088/5000 (62%)\n",
      "[epoch 15] loss: 0.6760232\n",
      "Test set: Average loss: 1.1543, Accuracy: 3136/5000 (63%)\n",
      "[epoch 16] loss: 0.6305926\n",
      "Test set: Average loss: 1.2382, Accuracy: 3093/5000 (62%)\n",
      "[epoch 17] loss: 0.5750653\n",
      "Test set: Average loss: 1.1920, Accuracy: 3108/5000 (62%)\n",
      "[epoch 18] loss: 0.5143918\n",
      "Test set: Average loss: 1.2005, Accuracy: 3176/5000 (64%)\n",
      "[epoch 19] loss: 0.4384296\n",
      "Test set: Average loss: 1.2551, Accuracy: 3200/5000 (64%)\n",
      "[epoch 20] loss: 0.3612321\n",
      "Test set: Average loss: 1.3562, Accuracy: 3127/5000 (63%)\n",
      "[epoch 21] loss: 0.3154756\n",
      "Test set: Average loss: 1.3973, Accuracy: 3156/5000 (63%)\n",
      "[epoch 22] loss: 0.2414884\n",
      "Test set: Average loss: 1.4599, Accuracy: 3100/5000 (62%)\n",
      "[epoch 23] loss: 0.1893012\n",
      "Test set: Average loss: 1.5213, Accuracy: 3216/5000 (64%)\n",
      "[epoch 24] loss: 0.1259607\n",
      "Test set: Average loss: 1.6647, Accuracy: 3133/5000 (63%)\n",
      "[epoch 25] loss: 0.1136024\n",
      "Test set: Average loss: 1.7874, Accuracy: 3068/5000 (61%)\n",
      "[epoch 26] loss: 0.1450228\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8304, Accuracy: 3067/5000 (61%)\n",
      "[epoch 27] loss: 0.0428153\n",
      "Test set: Average loss: 1.6742, Accuracy: 3230/5000 (65%)\n",
      "[epoch 28] loss: 0.0188114\n",
      "Test set: Average loss: 1.6830, Accuracy: 3244/5000 (65%)\n",
      "[epoch 29] loss: 0.0135215\n",
      "Test set: Average loss: 1.6971, Accuracy: 3252/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 30] loss: 0.0104733\n",
      "Test set: Average loss: 1.7089, Accuracy: 3242/5000 (65%)\n",
      "[epoch 31] loss: 0.0083890\n",
      "Test set: Average loss: 1.7312, Accuracy: 3241/5000 (65%)\n",
      "[epoch 32] loss: 0.0068071\n",
      "Test set: Average loss: 1.7544, Accuracy: 3250/5000 (65%)\n",
      "[epoch 33] loss: 0.0055841\n",
      "Test set: Average loss: 1.7752, Accuracy: 3248/5000 (65%)\n",
      "[epoch 34] loss: 0.0045454\n",
      "Test set: Average loss: 1.8004, Accuracy: 3257/5000 (65%)\n",
      "[epoch 35] loss: 0.0036878\n",
      "Test set: Average loss: 1.8278, Accuracy: 3276/5000 (66%)\n",
      "[epoch 36] loss: 0.0029693\n",
      "Test set: Average loss: 1.8609, Accuracy: 3269/5000 (65%)\n",
      "[epoch 37] loss: 0.0023867\n",
      "Test set: Average loss: 1.8902, Accuracy: 3278/5000 (66%)\n",
      "[epoch 38] loss: 0.0019003\n",
      "Test set: Average loss: 1.9224, Accuracy: 3275/5000 (66%)\n",
      "[epoch 39] loss: 0.0015016\n",
      "Test set: Average loss: 1.9611, Accuracy: 3293/5000 (66%)\n",
      "[epoch 40] loss: 0.0011808\n",
      "Test set: Average loss: 2.0012, Accuracy: 3281/5000 (66%)\n",
      "[epoch 41] loss: 0.0009238\n",
      "Test set: Average loss: 2.0365, Accuracy: 3283/5000 (66%)\n",
      "[epoch 42] loss: 0.0007183\n",
      "Test set: Average loss: 2.0775, Accuracy: 3280/5000 (66%)\n",
      "[epoch 43] loss: 0.0005563\n",
      "Test set: Average loss: 2.1232, Accuracy: 3278/5000 (66%)\n",
      "[epoch 44] loss: 0.0004291\n",
      "Test set: Average loss: 2.1616, Accuracy: 3282/5000 (66%)\n",
      "[epoch 45] loss: 0.0003281\n",
      "Test set: Average loss: 2.2086, Accuracy: 3287/5000 (66%)\n",
      "[epoch 46] loss: 0.0002520\n",
      "Test set: Average loss: 2.2535, Accuracy: 3290/5000 (66%)\n",
      "[epoch 47] loss: 0.0001924\n",
      "Test set: Average loss: 2.2976, Accuracy: 3277/5000 (66%)\n",
      "[epoch 48] loss: 0.0001458\n",
      "Test set: Average loss: 2.3425, Accuracy: 3276/5000 (66%)\n",
      "[epoch 49] loss: 0.0001109\n",
      "Test set: Average loss: 2.3954, Accuracy: 3281/5000 (66%)\n",
      "[epoch 50] loss: 0.0000839\n",
      "Test set: Average loss: 2.4384, Accuracy: 3277/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9611, Accuracy: 3293/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.9094, Accuracy: 6529/10000 (65%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3050, Accuracy: 533/5000 (11%)\n",
      "[epoch 1] loss: 1.2255377\n",
      "Test set: Average loss: 1.2668, Accuracy: 2718/5000 (54%)\n",
      "[epoch 2] loss: 1.0983851\n",
      "Test set: Average loss: 1.1353, Accuracy: 3037/5000 (61%)\n",
      "[epoch 3] loss: 1.0552371\n",
      "Test set: Average loss: 1.1362, Accuracy: 3043/5000 (61%)\n",
      "[epoch 4] loss: 1.0201470\n",
      "Test set: Average loss: 1.2068, Accuracy: 2905/5000 (58%)\n",
      "[epoch 5] loss: 0.9910812\n",
      "Test set: Average loss: 1.1330, Accuracy: 3061/5000 (61%)\n",
      "[epoch 6] loss: 0.9621525\n",
      "Test set: Average loss: 1.1309, Accuracy: 3073/5000 (61%)\n",
      "[epoch 7] loss: 0.9367343\n",
      "Test set: Average loss: 1.0565, Accuracy: 3177/5000 (64%)\n",
      "[epoch 8] loss: 0.8956820\n",
      "Test set: Average loss: 1.1314, Accuracy: 3024/5000 (60%)\n",
      "[epoch 9] loss: 0.8764693\n",
      "Test set: Average loss: 1.0815, Accuracy: 3165/5000 (63%)\n",
      "[epoch 10] loss: 0.8378855\n",
      "Test set: Average loss: 1.0630, Accuracy: 3206/5000 (64%)\n",
      "[epoch 11] loss: 0.8015682\n",
      "Test set: Average loss: 1.0829, Accuracy: 3161/5000 (63%)\n",
      "[epoch 12] loss: 0.7645871\n",
      "Test set: Average loss: 1.1379, Accuracy: 3071/5000 (61%)\n",
      "[epoch 13] loss: 0.7224049\n",
      "Test set: Average loss: 1.0837, Accuracy: 3194/5000 (64%)\n",
      "[epoch 14] loss: 0.6753145\n",
      "Test set: Average loss: 1.1102, Accuracy: 3183/5000 (64%)\n",
      "[epoch 15] loss: 0.6165812\n",
      "Test set: Average loss: 1.1170, Accuracy: 3210/5000 (64%)\n",
      "[epoch 16] loss: 0.5492681\n",
      "Test set: Average loss: 1.1620, Accuracy: 3192/5000 (64%)\n",
      "[epoch 17] loss: 0.4933365\n",
      "Test set: Average loss: 1.3136, Accuracy: 3097/5000 (62%)\n",
      "[epoch 18] loss: 0.4174130\n",
      "Test set: Average loss: 1.2584, Accuracy: 3255/5000 (65%)\n",
      "[epoch 19] loss: 0.3401163\n",
      "Test set: Average loss: 1.3512, Accuracy: 3123/5000 (62%)\n",
      "[epoch 20] loss: 0.2638684\n",
      "Test set: Average loss: 1.3450, Accuracy: 3216/5000 (64%)\n",
      "[epoch 21] loss: 0.2005661\n",
      "Test set: Average loss: 1.4325, Accuracy: 3239/5000 (65%)\n",
      "[epoch 22] loss: 0.1689905\n",
      "Test set: Average loss: 1.5477, Accuracy: 3261/5000 (65%)\n",
      "[epoch 23] loss: 0.1504865\n",
      "Test set: Average loss: 1.6220, Accuracy: 3202/5000 (64%)\n",
      "[epoch 24] loss: 0.1231834\n",
      "Test set: Average loss: 1.7455, Accuracy: 3118/5000 (62%)\n",
      "[epoch 25] loss: 0.1349545\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8080, Accuracy: 3108/5000 (62%)\n",
      "[epoch 26] loss: 0.0436417\n",
      "Test set: Average loss: 1.6729, Accuracy: 3258/5000 (65%)\n",
      "[epoch 27] loss: 0.0165441\n",
      "Test set: Average loss: 1.6838, Accuracy: 3273/5000 (65%)\n",
      "[epoch 28] loss: 0.0111636\n",
      "Test set: Average loss: 1.6980, Accuracy: 3279/5000 (66%)\n",
      "[epoch 29] loss: 0.0082733\n",
      "Test set: Average loss: 1.7104, Accuracy: 3277/5000 (66%)\n",
      "[epoch 30] loss: 0.0062943\n",
      "Test set: Average loss: 1.7365, Accuracy: 3285/5000 (66%)\n",
      "[epoch 31] loss: 0.0048620\n",
      "Test set: Average loss: 1.7523, Accuracy: 3304/5000 (66%)\n",
      "[epoch 32] loss: 0.0037864\n",
      "Test set: Average loss: 1.7868, Accuracy: 3287/5000 (66%)\n",
      "[epoch 33] loss: 0.0029090\n",
      "Test set: Average loss: 1.8081, Accuracy: 3295/5000 (66%)\n",
      "[epoch 34] loss: 0.0022412\n",
      "Test set: Average loss: 1.8417, Accuracy: 3293/5000 (66%)\n",
      "[epoch 35] loss: 0.0016964\n",
      "Test set: Average loss: 1.8757, Accuracy: 3303/5000 (66%)\n",
      "[epoch 36] loss: 0.0012853\n",
      "Test set: Average loss: 1.9248, Accuracy: 3289/5000 (66%)\n",
      "[epoch 37] loss: 0.0009607\n",
      "Test set: Average loss: 1.9603, Accuracy: 3293/5000 (66%)\n",
      "[epoch 38] loss: 0.0007126\n",
      "Test set: Average loss: 1.9972, Accuracy: 3311/5000 (66%)\n",
      "[epoch 39] loss: 0.0005242\n",
      "Test set: Average loss: 2.0386, Accuracy: 3317/5000 (66%)\n",
      "[epoch 40] loss: 0.0003850\n",
      "Test set: Average loss: 2.0970, Accuracy: 3317/5000 (66%)\n",
      "[epoch 41] loss: 0.0002820\n",
      "Test set: Average loss: 2.1383, Accuracy: 3307/5000 (66%)\n",
      "[epoch 42] loss: 0.0002032\n",
      "Test set: Average loss: 2.1926, Accuracy: 3308/5000 (66%)\n",
      "[epoch 43] loss: 0.0001470\n",
      "Test set: Average loss: 2.2418, Accuracy: 3307/5000 (66%)\n",
      "[epoch 44] loss: 0.0001063\n",
      "Test set: Average loss: 2.2916, Accuracy: 3304/5000 (66%)\n",
      "[epoch 45] loss: 0.0000760\n",
      "Test set: Average loss: 2.3435, Accuracy: 3312/5000 (66%)\n",
      "[epoch 46] loss: 0.0000546\n",
      "Test set: Average loss: 2.3929, Accuracy: 3312/5000 (66%)\n",
      "[epoch 47] loss: 0.0000389\n",
      "Test set: Average loss: 2.4486, Accuracy: 3319/5000 (66%)\n",
      "[epoch 48] loss: 0.0000276\n",
      "Test set: Average loss: 2.5008, Accuracy: 3309/5000 (66%)\n",
      "[epoch 49] loss: 0.0000196\n",
      "Test set: Average loss: 2.5648, Accuracy: 3312/5000 (66%)\n",
      "[epoch 50] loss: 0.0000139\n",
      "Test set: Average loss: 2.6191, Accuracy: 3315/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4486, Accuracy: 3319/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.4394, Accuracy: 6708/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 514/5000 (10%)\n",
      "[epoch 1] loss: 1.2318457\n",
      "Test set: Average loss: 1.2520, Accuracy: 2765/5000 (55%)\n",
      "[epoch 2] loss: 1.1132469\n",
      "Test set: Average loss: 1.1575, Accuracy: 2992/5000 (60%)\n",
      "[epoch 3] loss: 1.0498372\n",
      "Test set: Average loss: 1.1781, Accuracy: 2906/5000 (58%)\n",
      "[epoch 4] loss: 1.0221860\n",
      "Test set: Average loss: 1.1297, Accuracy: 3041/5000 (61%)\n",
      "[epoch 5] loss: 0.9927067\n",
      "Test set: Average loss: 1.1523, Accuracy: 2982/5000 (60%)\n",
      "[epoch 6] loss: 0.9651614\n",
      "Test set: Average loss: 1.0717, Accuracy: 3143/5000 (63%)\n",
      "[epoch 7] loss: 0.9344783\n",
      "Test set: Average loss: 1.1285, Accuracy: 3032/5000 (61%)\n",
      "[epoch 8] loss: 0.9056182\n",
      "Test set: Average loss: 1.1047, Accuracy: 3059/5000 (61%)\n",
      "[epoch 9] loss: 0.8740874\n",
      "Test set: Average loss: 1.1528, Accuracy: 3006/5000 (60%)\n",
      "[epoch 10] loss: 0.8392912\n",
      "Test set: Average loss: 1.1260, Accuracy: 3140/5000 (63%)\n",
      "[epoch 11] loss: 0.7956901\n",
      "Test set: Average loss: 1.0738, Accuracy: 3206/5000 (64%)\n",
      "[epoch 12] loss: 0.7593135\n",
      "Test set: Average loss: 1.1010, Accuracy: 3169/5000 (63%)\n",
      "[epoch 13] loss: 0.7156658\n",
      "Test set: Average loss: 1.1277, Accuracy: 3192/5000 (64%)\n",
      "[epoch 14] loss: 0.6689526\n",
      "Test set: Average loss: 1.2247, Accuracy: 3017/5000 (60%)\n",
      "[epoch 15] loss: 0.6117293\n",
      "Test set: Average loss: 1.1898, Accuracy: 3116/5000 (62%)\n",
      "[epoch 16] loss: 0.5521318\n",
      "Test set: Average loss: 1.1728, Accuracy: 3210/5000 (64%)\n",
      "[epoch 17] loss: 0.4807756\n",
      "Test set: Average loss: 1.2416, Accuracy: 3153/5000 (63%)\n",
      "[epoch 18] loss: 0.4046104\n",
      "Test set: Average loss: 1.2532, Accuracy: 3269/5000 (65%)\n",
      "[epoch 19] loss: 0.3375424\n",
      "Test set: Average loss: 1.3065, Accuracy: 3215/5000 (64%)\n",
      "[epoch 20] loss: 0.2541147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4372, Accuracy: 3127/5000 (63%)\n",
      "[epoch 21] loss: 0.2116869\n",
      "Test set: Average loss: 1.4639, Accuracy: 3202/5000 (64%)\n",
      "[epoch 22] loss: 0.1601208\n",
      "Test set: Average loss: 1.6272, Accuracy: 3150/5000 (63%)\n",
      "[epoch 23] loss: 0.1576865\n",
      "Test set: Average loss: 1.6734, Accuracy: 3117/5000 (62%)\n",
      "[epoch 24] loss: 0.1231487\n",
      "Test set: Average loss: 1.7180, Accuracy: 3157/5000 (63%)\n",
      "[epoch 25] loss: 0.1285956\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8604, Accuracy: 3072/5000 (61%)\n",
      "[epoch 26] loss: 0.0420291\n",
      "Test set: Average loss: 1.7021, Accuracy: 3233/5000 (65%)\n",
      "[epoch 27] loss: 0.0153627\n",
      "Test set: Average loss: 1.7102, Accuracy: 3256/5000 (65%)\n",
      "[epoch 28] loss: 0.0104601\n",
      "Test set: Average loss: 1.7224, Accuracy: 3268/5000 (65%)\n",
      "[epoch 29] loss: 0.0078142\n",
      "Test set: Average loss: 1.7428, Accuracy: 3275/5000 (66%)\n",
      "[epoch 30] loss: 0.0060494\n",
      "Test set: Average loss: 1.7640, Accuracy: 3280/5000 (66%)\n",
      "[epoch 31] loss: 0.0047279\n",
      "Test set: Average loss: 1.7932, Accuracy: 3284/5000 (66%)\n",
      "[epoch 32] loss: 0.0036763\n",
      "Test set: Average loss: 1.8204, Accuracy: 3286/5000 (66%)\n",
      "[epoch 33] loss: 0.0028593\n",
      "Test set: Average loss: 1.8511, Accuracy: 3277/5000 (66%)\n",
      "[epoch 34] loss: 0.0021914\n",
      "Test set: Average loss: 1.8822, Accuracy: 3285/5000 (66%)\n",
      "[epoch 35] loss: 0.0016727\n",
      "Test set: Average loss: 1.9205, Accuracy: 3296/5000 (66%)\n",
      "[epoch 36] loss: 0.0012644\n",
      "Test set: Average loss: 1.9614, Accuracy: 3288/5000 (66%)\n",
      "[epoch 37] loss: 0.0009498\n",
      "Test set: Average loss: 2.0027, Accuracy: 3287/5000 (66%)\n",
      "[epoch 38] loss: 0.0007040\n",
      "Test set: Average loss: 2.0451, Accuracy: 3280/5000 (66%)\n",
      "[epoch 39] loss: 0.0005195\n",
      "Test set: Average loss: 2.0870, Accuracy: 3276/5000 (66%)\n",
      "[epoch 40] loss: 0.0003798\n",
      "Test set: Average loss: 2.1363, Accuracy: 3282/5000 (66%)\n",
      "[epoch 41] loss: 0.0002783\n",
      "Test set: Average loss: 2.1861, Accuracy: 3277/5000 (66%)\n",
      "[epoch 42] loss: 0.0002032\n",
      "Test set: Average loss: 2.2360, Accuracy: 3273/5000 (65%)\n",
      "[epoch 43] loss: 0.0001469\n",
      "Test set: Average loss: 2.2887, Accuracy: 3279/5000 (66%)\n",
      "[epoch 44] loss: 0.0001060\n",
      "Test set: Average loss: 2.3403, Accuracy: 3275/5000 (66%)\n",
      "[epoch 45] loss: 0.0000761\n",
      "Test set: Average loss: 2.3915, Accuracy: 3286/5000 (66%)\n",
      "[epoch 46] loss: 0.0000546\n",
      "Test set: Average loss: 2.4462, Accuracy: 3281/5000 (66%)\n",
      "[epoch 47] loss: 0.0000391\n",
      "Test set: Average loss: 2.4901, Accuracy: 3274/5000 (65%)\n",
      "[epoch 48] loss: 0.0000278\n",
      "Test set: Average loss: 2.5589, Accuracy: 3276/5000 (66%)\n",
      "[epoch 49] loss: 0.0000199\n",
      "Test set: Average loss: 2.6020, Accuracy: 3279/5000 (66%)\n",
      "[epoch 50] loss: 0.0000140\n",
      "Test set: Average loss: 2.6584, Accuracy: 3293/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.9205, Accuracy: 3296/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.8733, Accuracy: 6714/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2988, Accuracy: 578/5000 (12%)\n",
      "[epoch 1] loss: 1.2434151\n",
      "Test set: Average loss: 1.2596, Accuracy: 2760/5000 (55%)\n",
      "[epoch 2] loss: 1.1131000\n",
      "Test set: Average loss: 1.1607, Accuracy: 3007/5000 (60%)\n",
      "[epoch 3] loss: 1.0737662\n",
      "Test set: Average loss: 1.1304, Accuracy: 2977/5000 (60%)\n",
      "[epoch 4] loss: 1.0269946\n",
      "Test set: Average loss: 1.2066, Accuracy: 2898/5000 (58%)\n",
      "[epoch 5] loss: 1.0131321\n",
      "Test set: Average loss: 1.1577, Accuracy: 3012/5000 (60%)\n",
      "[epoch 6] loss: 0.9834292\n",
      "Test set: Average loss: 1.1092, Accuracy: 3095/5000 (62%)\n",
      "[epoch 7] loss: 0.9474240\n",
      "Test set: Average loss: 1.0860, Accuracy: 3127/5000 (63%)\n",
      "[epoch 8] loss: 0.9248602\n",
      "Test set: Average loss: 1.0503, Accuracy: 3170/5000 (63%)\n",
      "[epoch 9] loss: 0.8853077\n",
      "Test set: Average loss: 1.0944, Accuracy: 3076/5000 (62%)\n",
      "[epoch 10] loss: 0.8583371\n",
      "Test set: Average loss: 1.1148, Accuracy: 3085/5000 (62%)\n",
      "[epoch 11] loss: 0.8244057\n",
      "Test set: Average loss: 1.1193, Accuracy: 3075/5000 (62%)\n",
      "[epoch 12] loss: 0.7791286\n",
      "Test set: Average loss: 1.0698, Accuracy: 3212/5000 (64%)\n",
      "[epoch 13] loss: 0.7313530\n",
      "Test set: Average loss: 1.1300, Accuracy: 3170/5000 (63%)\n",
      "[epoch 14] loss: 0.6880056\n",
      "Test set: Average loss: 1.1086, Accuracy: 3190/5000 (64%)\n",
      "[epoch 15] loss: 0.6237702\n",
      "Test set: Average loss: 1.1763, Accuracy: 3148/5000 (63%)\n",
      "[epoch 16] loss: 0.5652359\n",
      "Test set: Average loss: 1.1575, Accuracy: 3205/5000 (64%)\n",
      "[epoch 17] loss: 0.5022957\n",
      "Test set: Average loss: 1.2204, Accuracy: 3203/5000 (64%)\n",
      "[epoch 18] loss: 0.4140935\n",
      "Test set: Average loss: 1.2313, Accuracy: 3205/5000 (64%)\n",
      "[epoch 19] loss: 0.3562283\n",
      "Test set: Average loss: 1.2929, Accuracy: 3159/5000 (63%)\n",
      "[epoch 20] loss: 0.2745503\n",
      "Test set: Average loss: 1.3726, Accuracy: 3224/5000 (64%)\n",
      "[epoch 21] loss: 0.1995132\n",
      "Test set: Average loss: 1.4783, Accuracy: 3183/5000 (64%)\n",
      "[epoch 22] loss: 0.1678583\n",
      "Test set: Average loss: 1.5644, Accuracy: 3180/5000 (64%)\n",
      "[epoch 23] loss: 0.1419808\n",
      "Test set: Average loss: 1.6793, Accuracy: 3155/5000 (63%)\n",
      "[epoch 24] loss: 0.1167860\n",
      "Test set: Average loss: 1.7739, Accuracy: 3150/5000 (63%)\n",
      "[epoch 25] loss: 0.1366932\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8227, Accuracy: 3128/5000 (63%)\n",
      "[epoch 26] loss: 0.0497014\n",
      "Test set: Average loss: 1.6726, Accuracy: 3265/5000 (65%)\n",
      "[epoch 27] loss: 0.0178795\n",
      "Test set: Average loss: 1.6738, Accuracy: 3266/5000 (65%)\n",
      "[epoch 28] loss: 0.0118930\n",
      "Test set: Average loss: 1.6859, Accuracy: 3272/5000 (65%)\n",
      "[epoch 29] loss: 0.0087296\n",
      "Test set: Average loss: 1.7020, Accuracy: 3275/5000 (66%)\n",
      "[epoch 30] loss: 0.0066179\n",
      "Test set: Average loss: 1.7224, Accuracy: 3293/5000 (66%)\n",
      "[epoch 31] loss: 0.0050866\n",
      "Test set: Average loss: 1.7455, Accuracy: 3281/5000 (66%)\n",
      "[epoch 32] loss: 0.0039088\n",
      "Test set: Average loss: 1.7654, Accuracy: 3275/5000 (66%)\n",
      "[epoch 33] loss: 0.0029860\n",
      "Test set: Average loss: 1.7972, Accuracy: 3271/5000 (65%)\n",
      "[epoch 34] loss: 0.0022816\n",
      "Test set: Average loss: 1.8268, Accuracy: 3277/5000 (66%)\n",
      "[epoch 35] loss: 0.0017269\n",
      "Test set: Average loss: 1.8590, Accuracy: 3285/5000 (66%)\n",
      "[epoch 36] loss: 0.0012955\n",
      "Test set: Average loss: 1.9011, Accuracy: 3284/5000 (66%)\n",
      "[epoch 37] loss: 0.0009634\n",
      "Test set: Average loss: 1.9374, Accuracy: 3290/5000 (66%)\n",
      "[epoch 38] loss: 0.0007149\n",
      "Test set: Average loss: 1.9826, Accuracy: 3283/5000 (66%)\n",
      "[epoch 39] loss: 0.0005264\n",
      "Test set: Average loss: 2.0245, Accuracy: 3284/5000 (66%)\n",
      "[epoch 40] loss: 0.0003827\n",
      "Test set: Average loss: 2.0777, Accuracy: 3283/5000 (66%)\n",
      "[epoch 41] loss: 0.0002792\n",
      "Test set: Average loss: 2.1138, Accuracy: 3283/5000 (66%)\n",
      "[epoch 42] loss: 0.0002030\n",
      "Test set: Average loss: 2.1694, Accuracy: 3291/5000 (66%)\n",
      "[epoch 43] loss: 0.0001458\n",
      "Test set: Average loss: 2.2179, Accuracy: 3288/5000 (66%)\n",
      "[epoch 44] loss: 0.0001053\n",
      "Test set: Average loss: 2.2740, Accuracy: 3298/5000 (66%)\n",
      "[epoch 45] loss: 0.0000756\n",
      "Test set: Average loss: 2.3191, Accuracy: 3281/5000 (66%)\n",
      "[epoch 46] loss: 0.0000540\n",
      "Test set: Average loss: 2.3785, Accuracy: 3293/5000 (66%)\n",
      "[epoch 47] loss: 0.0000384\n",
      "Test set: Average loss: 2.4294, Accuracy: 3291/5000 (66%)\n",
      "[epoch 48] loss: 0.0000273\n",
      "Test set: Average loss: 2.4873, Accuracy: 3301/5000 (66%)\n",
      "[epoch 49] loss: 0.0000194\n",
      "Test set: Average loss: 2.5348, Accuracy: 3293/5000 (66%)\n",
      "[epoch 50] loss: 0.0000137\n",
      "Test set: Average loss: 2.5966, Accuracy: 3290/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4873, Accuracy: 3301/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.4122, Accuracy: 6696/10000 (67%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3050, Accuracy: 482/5000 (10%)\n",
      "[epoch 1] loss: 1.2317469\n",
      "Test set: Average loss: 1.1352, Accuracy: 3000/5000 (60%)\n",
      "[epoch 2] loss: 1.1035702\n",
      "Test set: Average loss: 1.2309, Accuracy: 2844/5000 (57%)\n",
      "[epoch 3] loss: 1.0515494\n",
      "Test set: Average loss: 1.0862, Accuracy: 3116/5000 (62%)\n",
      "[epoch 4] loss: 1.0153614\n",
      "Test set: Average loss: 1.1136, Accuracy: 2998/5000 (60%)\n",
      "[epoch 5] loss: 0.9882333\n",
      "Test set: Average loss: 1.0984, Accuracy: 3136/5000 (63%)\n",
      "[epoch 6] loss: 0.9558832\n",
      "Test set: Average loss: 1.0438, Accuracy: 3175/5000 (64%)\n",
      "[epoch 7] loss: 0.9243422\n",
      "Test set: Average loss: 1.0967, Accuracy: 3143/5000 (63%)\n",
      "[epoch 8] loss: 0.8883007\n",
      "Test set: Average loss: 1.0670, Accuracy: 3170/5000 (63%)\n",
      "[epoch 9] loss: 0.8605345\n",
      "Test set: Average loss: 1.0438, Accuracy: 3228/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 0.8173405\n",
      "Test set: Average loss: 1.1078, Accuracy: 3128/5000 (63%)\n",
      "[epoch 11] loss: 0.7769818\n",
      "Test set: Average loss: 1.0381, Accuracy: 3263/5000 (65%)\n",
      "[epoch 12] loss: 0.7362552\n",
      "Test set: Average loss: 1.0913, Accuracy: 3192/5000 (64%)\n",
      "[epoch 13] loss: 0.6894239\n",
      "Test set: Average loss: 1.0695, Accuracy: 3231/5000 (65%)\n",
      "[epoch 14] loss: 0.6290597\n",
      "Test set: Average loss: 1.0817, Accuracy: 3246/5000 (65%)\n",
      "[epoch 15] loss: 0.5655586\n",
      "Test set: Average loss: 1.1173, Accuracy: 3230/5000 (65%)\n",
      "[epoch 16] loss: 0.4897746\n",
      "Test set: Average loss: 1.1820, Accuracy: 3218/5000 (64%)\n",
      "[epoch 17] loss: 0.4236873\n",
      "Test set: Average loss: 1.2315, Accuracy: 3231/5000 (65%)\n",
      "[epoch 18] loss: 0.3433113\n",
      "Test set: Average loss: 1.2355, Accuracy: 3269/5000 (65%)\n",
      "[epoch 19] loss: 0.3016434\n",
      "Test set: Average loss: 1.3387, Accuracy: 3219/5000 (64%)\n",
      "[epoch 20] loss: 0.2188429\n",
      "Test set: Average loss: 1.3678, Accuracy: 3252/5000 (65%)\n",
      "[epoch 21] loss: 0.2009846\n",
      "Test set: Average loss: 1.4453, Accuracy: 3243/5000 (65%)\n",
      "[epoch 22] loss: 0.1537123\n",
      "Test set: Average loss: 1.5690, Accuracy: 3205/5000 (64%)\n",
      "[epoch 23] loss: 0.1573417\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6386, Accuracy: 3244/5000 (65%)\n",
      "[epoch 24] loss: 0.0526922\n",
      "Test set: Average loss: 1.5321, Accuracy: 3338/5000 (67%)\n",
      "[epoch 25] loss: 0.0215119\n",
      "Test set: Average loss: 1.5363, Accuracy: 3347/5000 (67%)\n",
      "[epoch 26] loss: 0.0141431\n",
      "Test set: Average loss: 1.5507, Accuracy: 3359/5000 (67%)\n",
      "[epoch 27] loss: 0.0101456\n",
      "Test set: Average loss: 1.5827, Accuracy: 3365/5000 (67%)\n",
      "[epoch 28] loss: 0.0074581\n",
      "Test set: Average loss: 1.6035, Accuracy: 3361/5000 (67%)\n",
      "[epoch 29] loss: 0.0055471\n",
      "Test set: Average loss: 1.6386, Accuracy: 3360/5000 (67%)\n",
      "[epoch 30] loss: 0.0041066\n",
      "Test set: Average loss: 1.6736, Accuracy: 3358/5000 (67%)\n",
      "[epoch 31] loss: 0.0029794\n",
      "Test set: Average loss: 1.7092, Accuracy: 3367/5000 (67%)\n",
      "[epoch 32] loss: 0.0021559\n",
      "Test set: Average loss: 1.7506, Accuracy: 3371/5000 (67%)\n",
      "[epoch 33] loss: 0.0015471\n",
      "Test set: Average loss: 1.7991, Accuracy: 3392/5000 (68%)\n",
      "[epoch 34] loss: 0.0010981\n",
      "Test set: Average loss: 1.8459, Accuracy: 3383/5000 (68%)\n",
      "[epoch 35] loss: 0.0007732\n",
      "Test set: Average loss: 1.9036, Accuracy: 3388/5000 (68%)\n",
      "[epoch 36] loss: 0.0005434\n",
      "Test set: Average loss: 1.9487, Accuracy: 3393/5000 (68%)\n",
      "[epoch 37] loss: 0.0003778\n",
      "Test set: Average loss: 2.0113, Accuracy: 3382/5000 (68%)\n",
      "[epoch 38] loss: 0.0002616\n",
      "Test set: Average loss: 2.0593, Accuracy: 3393/5000 (68%)\n",
      "[epoch 39] loss: 0.0001799\n",
      "Test set: Average loss: 2.1104, Accuracy: 3401/5000 (68%)\n",
      "[epoch 40] loss: 0.0001235\n",
      "Test set: Average loss: 2.1744, Accuracy: 3382/5000 (68%)\n",
      "[epoch 41] loss: 0.0000848\n",
      "Test set: Average loss: 2.2354, Accuracy: 3373/5000 (67%)\n",
      "[epoch 42] loss: 0.0000572\n",
      "Test set: Average loss: 2.2909, Accuracy: 3389/5000 (68%)\n",
      "[epoch 43] loss: 0.0000391\n",
      "Test set: Average loss: 2.3485, Accuracy: 3391/5000 (68%)\n",
      "[epoch 44] loss: 0.0000264\n",
      "Test set: Average loss: 2.4106, Accuracy: 3376/5000 (68%)\n",
      "[epoch 45] loss: 0.0000177\n",
      "Test set: Average loss: 2.4717, Accuracy: 3396/5000 (68%)\n",
      "[epoch 46] loss: 0.0000119\n",
      "Test set: Average loss: 2.5359, Accuracy: 3382/5000 (68%)\n",
      "[epoch 47] loss: 0.0000080\n",
      "Test set: Average loss: 2.5965, Accuracy: 3392/5000 (68%)\n",
      "[epoch 48] loss: 0.0000053\n",
      "Test set: Average loss: 2.6532, Accuracy: 3378/5000 (68%)\n",
      "[epoch 49] loss: 0.0000036\n",
      "Test set: Average loss: 2.7185, Accuracy: 3395/5000 (68%)\n",
      "[epoch 50] loss: 0.0000023\n",
      "Test set: Average loss: 2.7708, Accuracy: 3389/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1104, Accuracy: 3401/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.1112, Accuracy: 6844/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3002, Accuracy: 730/5000 (15%)\n",
      "[epoch 1] loss: 1.2194311\n",
      "Test set: Average loss: 1.1334, Accuracy: 3035/5000 (61%)\n",
      "[epoch 2] loss: 1.0975320\n",
      "Test set: Average loss: 1.2361, Accuracy: 2836/5000 (57%)\n",
      "[epoch 3] loss: 1.0541005\n",
      "Test set: Average loss: 1.1636, Accuracy: 2932/5000 (59%)\n",
      "[epoch 4] loss: 1.0267740\n",
      "Test set: Average loss: 1.0826, Accuracy: 3089/5000 (62%)\n",
      "[epoch 5] loss: 0.9854540\n",
      "Test set: Average loss: 1.1347, Accuracy: 3008/5000 (60%)\n",
      "[epoch 6] loss: 0.9572720\n",
      "Test set: Average loss: 1.0718, Accuracy: 3135/5000 (63%)\n",
      "[epoch 7] loss: 0.9217010\n",
      "Test set: Average loss: 1.1062, Accuracy: 3101/5000 (62%)\n",
      "[epoch 8] loss: 0.8913717\n",
      "Test set: Average loss: 1.0699, Accuracy: 3144/5000 (63%)\n",
      "[epoch 9] loss: 0.8522207\n",
      "Test set: Average loss: 1.1097, Accuracy: 3123/5000 (62%)\n",
      "[epoch 10] loss: 0.8270765\n",
      "Test set: Average loss: 1.0415, Accuracy: 3199/5000 (64%)\n",
      "[epoch 11] loss: 0.7873111\n",
      "Test set: Average loss: 1.0940, Accuracy: 3158/5000 (63%)\n",
      "[epoch 12] loss: 0.7366902\n",
      "Test set: Average loss: 1.0750, Accuracy: 3200/5000 (64%)\n",
      "[epoch 13] loss: 0.7011416\n",
      "Test set: Average loss: 1.0443, Accuracy: 3258/5000 (65%)\n",
      "[epoch 14] loss: 0.6424149\n",
      "Test set: Average loss: 1.1212, Accuracy: 3219/5000 (64%)\n",
      "[epoch 15] loss: 0.5785091\n",
      "Test set: Average loss: 1.1413, Accuracy: 3246/5000 (65%)\n",
      "[epoch 16] loss: 0.5022336\n",
      "Test set: Average loss: 1.1652, Accuracy: 3272/5000 (65%)\n",
      "[epoch 17] loss: 0.4325957\n",
      "Test set: Average loss: 1.2089, Accuracy: 3249/5000 (65%)\n",
      "[epoch 18] loss: 0.3630406\n",
      "Test set: Average loss: 1.2850, Accuracy: 3216/5000 (64%)\n",
      "[epoch 19] loss: 0.2912584\n",
      "Test set: Average loss: 1.3417, Accuracy: 3238/5000 (65%)\n",
      "[epoch 20] loss: 0.2264681\n",
      "Test set: Average loss: 1.4456, Accuracy: 3236/5000 (65%)\n",
      "[epoch 21] loss: 0.1914772\n",
      "Test set: Average loss: 1.5611, Accuracy: 3192/5000 (64%)\n",
      "[epoch 22] loss: 0.1568085\n",
      "Test set: Average loss: 1.5557, Accuracy: 3218/5000 (64%)\n",
      "[epoch 23] loss: 0.1394657\n",
      "Test set: Average loss: 1.7121, Accuracy: 3192/5000 (64%)\n",
      "[epoch 24] loss: 0.1481805\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7910, Accuracy: 3197/5000 (64%)\n",
      "[epoch 25] loss: 0.0439161\n",
      "Test set: Average loss: 1.6526, Accuracy: 3285/5000 (66%)\n",
      "[epoch 26] loss: 0.0168687\n",
      "Test set: Average loss: 1.6708, Accuracy: 3293/5000 (66%)\n",
      "[epoch 27] loss: 0.0110507\n",
      "Test set: Average loss: 1.6897, Accuracy: 3284/5000 (66%)\n",
      "[epoch 28] loss: 0.0079422\n",
      "Test set: Average loss: 1.7154, Accuracy: 3298/5000 (66%)\n",
      "[epoch 29] loss: 0.0058565\n",
      "Test set: Average loss: 1.7424, Accuracy: 3294/5000 (66%)\n",
      "[epoch 30] loss: 0.0043517\n",
      "Test set: Average loss: 1.7737, Accuracy: 3296/5000 (66%)\n",
      "[epoch 31] loss: 0.0032161\n",
      "Test set: Average loss: 1.8074, Accuracy: 3289/5000 (66%)\n",
      "[epoch 32] loss: 0.0023461\n",
      "Test set: Average loss: 1.8459, Accuracy: 3304/5000 (66%)\n",
      "[epoch 33] loss: 0.0016957\n",
      "Test set: Average loss: 1.8869, Accuracy: 3310/5000 (66%)\n",
      "[epoch 34] loss: 0.0012090\n",
      "Test set: Average loss: 1.9303, Accuracy: 3309/5000 (66%)\n",
      "[epoch 35] loss: 0.0008564\n",
      "Test set: Average loss: 1.9744, Accuracy: 3309/5000 (66%)\n",
      "[epoch 36] loss: 0.0006046\n",
      "Test set: Average loss: 2.0275, Accuracy: 3310/5000 (66%)\n",
      "[epoch 37] loss: 0.0004219\n",
      "Test set: Average loss: 2.0825, Accuracy: 3318/5000 (66%)\n",
      "[epoch 38] loss: 0.0002922\n",
      "Test set: Average loss: 2.1372, Accuracy: 3322/5000 (66%)\n",
      "[epoch 39] loss: 0.0002017\n",
      "Test set: Average loss: 2.1902, Accuracy: 3322/5000 (66%)\n",
      "[epoch 40] loss: 0.0001390\n",
      "Test set: Average loss: 2.2454, Accuracy: 3330/5000 (67%)\n",
      "[epoch 41] loss: 0.0000944\n",
      "Test set: Average loss: 2.3026, Accuracy: 3326/5000 (67%)\n",
      "[epoch 42] loss: 0.0000643\n",
      "Test set: Average loss: 2.3601, Accuracy: 3335/5000 (67%)\n",
      "[epoch 43] loss: 0.0000437\n",
      "Test set: Average loss: 2.4325, Accuracy: 3338/5000 (67%)\n",
      "[epoch 44] loss: 0.0000294\n",
      "Test set: Average loss: 2.4907, Accuracy: 3331/5000 (67%)\n",
      "[epoch 45] loss: 0.0000198\n",
      "Test set: Average loss: 2.5500, Accuracy: 3330/5000 (67%)\n",
      "[epoch 46] loss: 0.0000133\n",
      "Test set: Average loss: 2.6150, Accuracy: 3341/5000 (67%)\n",
      "[epoch 47] loss: 0.0000089\n",
      "Test set: Average loss: 2.6732, Accuracy: 3339/5000 (67%)\n",
      "[epoch 48] loss: 0.0000059\n",
      "Test set: Average loss: 2.7440, Accuracy: 3342/5000 (67%)\n",
      "[epoch 49] loss: 0.0000039\n",
      "Test set: Average loss: 2.8004, Accuracy: 3348/5000 (67%)\n",
      "[epoch 50] loss: 0.0000026\n",
      "Test set: Average loss: 2.8672, Accuracy: 3327/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.8004, Accuracy: 3348/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.6518, Accuracy: 6775/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3021, Accuracy: 526/5000 (11%)\n",
      "[epoch 1] loss: 1.2246268\n",
      "Test set: Average loss: 1.2266, Accuracy: 2841/5000 (57%)\n",
      "[epoch 2] loss: 1.1066317\n",
      "Test set: Average loss: 1.1688, Accuracy: 3008/5000 (60%)\n",
      "[epoch 3] loss: 1.0575727\n",
      "Test set: Average loss: 1.1277, Accuracy: 3023/5000 (60%)\n",
      "[epoch 4] loss: 1.0256445\n",
      "Test set: Average loss: 1.0797, Accuracy: 3125/5000 (62%)\n",
      "[epoch 5] loss: 0.9903314\n",
      "Test set: Average loss: 1.1406, Accuracy: 3007/5000 (60%)\n",
      "[epoch 6] loss: 0.9649308\n",
      "Test set: Average loss: 1.0684, Accuracy: 3090/5000 (62%)\n",
      "[epoch 7] loss: 0.9309100\n",
      "Test set: Average loss: 1.0853, Accuracy: 3138/5000 (63%)\n",
      "[epoch 8] loss: 0.8967497\n",
      "Test set: Average loss: 1.0755, Accuracy: 3108/5000 (62%)\n",
      "[epoch 9] loss: 0.8621116\n",
      "Test set: Average loss: 1.0715, Accuracy: 3150/5000 (63%)\n",
      "[epoch 10] loss: 0.8263435\n",
      "Test set: Average loss: 1.0723, Accuracy: 3194/5000 (64%)\n",
      "[epoch 11] loss: 0.7816249\n",
      "Test set: Average loss: 1.0556, Accuracy: 3251/5000 (65%)\n",
      "[epoch 12] loss: 0.7410297\n",
      "Test set: Average loss: 1.0967, Accuracy: 3200/5000 (64%)\n",
      "[epoch 13] loss: 0.6907308\n",
      "Test set: Average loss: 1.0555, Accuracy: 3260/5000 (65%)\n",
      "[epoch 14] loss: 0.6289559\n",
      "Test set: Average loss: 1.0710, Accuracy: 3259/5000 (65%)\n",
      "[epoch 15] loss: 0.5690412\n",
      "Test set: Average loss: 1.0878, Accuracy: 3278/5000 (66%)\n",
      "[epoch 16] loss: 0.4921036\n",
      "Test set: Average loss: 1.1609, Accuracy: 3259/5000 (65%)\n",
      "[epoch 17] loss: 0.4233123\n",
      "Test set: Average loss: 1.2208, Accuracy: 3233/5000 (65%)\n",
      "[epoch 18] loss: 0.3474553\n",
      "Test set: Average loss: 1.3040, Accuracy: 3213/5000 (64%)\n",
      "[epoch 19] loss: 0.2786875\n",
      "Test set: Average loss: 1.3033, Accuracy: 3264/5000 (65%)\n",
      "[epoch 20] loss: 0.2068477\n",
      "Test set: Average loss: 1.4662, Accuracy: 3212/5000 (64%)\n",
      "[epoch 21] loss: 0.1861758\n",
      "Test set: Average loss: 1.5507, Accuracy: 3233/5000 (65%)\n",
      "[epoch 22] loss: 0.1599505\n",
      "Test set: Average loss: 1.5652, Accuracy: 3183/5000 (64%)\n",
      "[epoch 23] loss: 0.1354349\n",
      "Test set: Average loss: 1.6760, Accuracy: 3180/5000 (64%)\n",
      "[epoch 24] loss: 0.1365355\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8236, Accuracy: 3076/5000 (62%)\n",
      "[epoch 25] loss: 0.0573272\n",
      "Test set: Average loss: 1.6218, Accuracy: 3301/5000 (66%)\n",
      "[epoch 26] loss: 0.0184721\n",
      "Test set: Average loss: 1.6303, Accuracy: 3316/5000 (66%)\n",
      "[epoch 27] loss: 0.0113505\n",
      "Test set: Average loss: 1.6440, Accuracy: 3324/5000 (66%)\n",
      "[epoch 28] loss: 0.0079658\n",
      "Test set: Average loss: 1.6653, Accuracy: 3322/5000 (66%)\n",
      "[epoch 29] loss: 0.0058447\n",
      "Test set: Average loss: 1.6882, Accuracy: 3333/5000 (67%)\n",
      "[epoch 30] loss: 0.0042950\n",
      "Test set: Average loss: 1.7170, Accuracy: 3329/5000 (67%)\n",
      "[epoch 31] loss: 0.0031402\n",
      "Test set: Average loss: 1.7531, Accuracy: 3333/5000 (67%)\n",
      "[epoch 32] loss: 0.0022876\n",
      "Test set: Average loss: 1.8113, Accuracy: 3335/5000 (67%)\n",
      "[epoch 33] loss: 0.0016394\n",
      "Test set: Average loss: 1.8257, Accuracy: 3342/5000 (67%)\n",
      "[epoch 34] loss: 0.0011687\n",
      "Test set: Average loss: 1.8681, Accuracy: 3348/5000 (67%)\n",
      "[epoch 35] loss: 0.0008220\n",
      "Test set: Average loss: 1.9111, Accuracy: 3359/5000 (67%)\n",
      "[epoch 36] loss: 0.0005768\n",
      "Test set: Average loss: 1.9574, Accuracy: 3341/5000 (67%)\n",
      "[epoch 37] loss: 0.0004005\n",
      "Test set: Average loss: 2.0108, Accuracy: 3362/5000 (67%)\n",
      "[epoch 38] loss: 0.0002775\n",
      "Test set: Average loss: 2.0609, Accuracy: 3363/5000 (67%)\n",
      "[epoch 39] loss: 0.0001903\n",
      "Test set: Average loss: 2.1140, Accuracy: 3374/5000 (67%)\n",
      "[epoch 40] loss: 0.0001298\n",
      "Test set: Average loss: 2.1730, Accuracy: 3365/5000 (67%)\n",
      "[epoch 41] loss: 0.0000882\n",
      "Test set: Average loss: 2.2258, Accuracy: 3368/5000 (67%)\n",
      "[epoch 42] loss: 0.0000601\n",
      "Test set: Average loss: 2.2769, Accuracy: 3380/5000 (68%)\n",
      "[epoch 43] loss: 0.0000404\n",
      "Test set: Average loss: 2.3393, Accuracy: 3369/5000 (67%)\n",
      "[epoch 44] loss: 0.0000271\n",
      "Test set: Average loss: 2.3971, Accuracy: 3375/5000 (68%)\n",
      "[epoch 45] loss: 0.0000182\n",
      "Test set: Average loss: 2.4542, Accuracy: 3367/5000 (67%)\n",
      "[epoch 46] loss: 0.0000122\n",
      "Test set: Average loss: 2.5181, Accuracy: 3379/5000 (68%)\n",
      "[epoch 47] loss: 0.0000081\n",
      "Test set: Average loss: 2.5777, Accuracy: 3382/5000 (68%)\n",
      "[epoch 48] loss: 0.0000054\n",
      "Test set: Average loss: 2.6393, Accuracy: 3374/5000 (67%)\n",
      "[epoch 49] loss: 0.0000036\n",
      "Test set: Average loss: 2.7024, Accuracy: 3380/5000 (68%)\n",
      "[epoch 50] loss: 0.0000024\n",
      "Test set: Average loss: 2.7523, Accuracy: 3371/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5777, Accuracy: 3382/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.5225, Accuracy: 6862/10000 (69%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 499/5000 (10%)\n",
      "[epoch 1] loss: 1.2004898\n",
      "Test set: Average loss: 1.1559, Accuracy: 2993/5000 (60%)\n",
      "[epoch 2] loss: 1.0888002\n",
      "Test set: Average loss: 1.0902, Accuracy: 3097/5000 (62%)\n",
      "[epoch 3] loss: 1.0447346\n",
      "Test set: Average loss: 1.0774, Accuracy: 3153/5000 (63%)\n",
      "[epoch 4] loss: 1.0088448\n",
      "Test set: Average loss: 1.2082, Accuracy: 2920/5000 (58%)\n",
      "[epoch 5] loss: 0.9755275\n",
      "Test set: Average loss: 1.0600, Accuracy: 3131/5000 (63%)\n",
      "[epoch 6] loss: 0.9414734\n",
      "Test set: Average loss: 1.0592, Accuracy: 3185/5000 (64%)\n",
      "[epoch 7] loss: 0.9094091\n",
      "Test set: Average loss: 1.1054, Accuracy: 3107/5000 (62%)\n",
      "[epoch 8] loss: 0.8717549\n",
      "Test set: Average loss: 1.0086, Accuracy: 3259/5000 (65%)\n",
      "[epoch 9] loss: 0.8340124\n",
      "Test set: Average loss: 1.0394, Accuracy: 3214/5000 (64%)\n",
      "[epoch 10] loss: 0.8048404\n",
      "Test set: Average loss: 1.0120, Accuracy: 3272/5000 (65%)\n",
      "[epoch 11] loss: 0.7414688\n",
      "Test set: Average loss: 1.0091, Accuracy: 3277/5000 (66%)\n",
      "[epoch 12] loss: 0.7054301\n",
      "Test set: Average loss: 1.0097, Accuracy: 3330/5000 (67%)\n",
      "[epoch 13] loss: 0.6421981\n",
      "Test set: Average loss: 0.9987, Accuracy: 3347/5000 (67%)\n",
      "[epoch 14] loss: 0.5773415\n",
      "Test set: Average loss: 1.0856, Accuracy: 3283/5000 (66%)\n",
      "[epoch 15] loss: 0.5078776\n",
      "Test set: Average loss: 1.1046, Accuracy: 3332/5000 (67%)\n",
      "[epoch 16] loss: 0.4367023\n",
      "Test set: Average loss: 1.1437, Accuracy: 3314/5000 (66%)\n",
      "[epoch 17] loss: 0.3562695\n",
      "Test set: Average loss: 1.2967, Accuracy: 3210/5000 (64%)\n",
      "[epoch 18] loss: 0.3014055\n",
      "Test set: Average loss: 1.2547, Accuracy: 3358/5000 (67%)\n",
      "[epoch 19] loss: 0.2388705\n",
      "Test set: Average loss: 1.3474, Accuracy: 3297/5000 (66%)\n",
      "[epoch 20] loss: 0.1978850\n",
      "Test set: Average loss: 1.4622, Accuracy: 3277/5000 (66%)\n",
      "[epoch 21] loss: 0.1796189\n",
      "Test set: Average loss: 1.5087, Accuracy: 3282/5000 (66%)\n",
      "[epoch 22] loss: 0.1530405\n",
      "Test set: Average loss: 1.5626, Accuracy: 3290/5000 (66%)\n",
      "[epoch 23] loss: 0.1624348\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6488, Accuracy: 3236/5000 (65%)\n",
      "[epoch 24] loss: 0.0543162\n",
      "Test set: Average loss: 1.5334, Accuracy: 3361/5000 (67%)\n",
      "[epoch 25] loss: 0.0196426\n",
      "Test set: Average loss: 1.5456, Accuracy: 3367/5000 (67%)\n",
      "[epoch 26] loss: 0.0122398\n",
      "Test set: Average loss: 1.5980, Accuracy: 3382/5000 (68%)\n",
      "[epoch 27] loss: 0.0084453\n",
      "Test set: Average loss: 1.5863, Accuracy: 3391/5000 (68%)\n",
      "[epoch 28] loss: 0.0059892\n",
      "Test set: Average loss: 1.6220, Accuracy: 3390/5000 (68%)\n",
      "[epoch 29] loss: 0.0042102\n",
      "Test set: Average loss: 1.6560, Accuracy: 3391/5000 (68%)\n",
      "[epoch 30] loss: 0.0029357\n",
      "Test set: Average loss: 1.6955, Accuracy: 3401/5000 (68%)\n",
      "[epoch 31] loss: 0.0020332\n",
      "Test set: Average loss: 1.7359, Accuracy: 3396/5000 (68%)\n",
      "[epoch 32] loss: 0.0013855\n",
      "Test set: Average loss: 1.7857, Accuracy: 3403/5000 (68%)\n",
      "[epoch 33] loss: 0.0009404\n",
      "Test set: Average loss: 1.8409, Accuracy: 3409/5000 (68%)\n",
      "[epoch 34] loss: 0.0006297\n",
      "Test set: Average loss: 1.8941, Accuracy: 3418/5000 (68%)\n",
      "[epoch 35] loss: 0.0004219\n",
      "Test set: Average loss: 1.9483, Accuracy: 3417/5000 (68%)\n",
      "[epoch 36] loss: 0.0002785\n",
      "Test set: Average loss: 2.0110, Accuracy: 3420/5000 (68%)\n",
      "[epoch 37] loss: 0.0001841\n",
      "Test set: Average loss: 2.0669, Accuracy: 3415/5000 (68%)\n",
      "[epoch 38] loss: 0.0001198\n",
      "Test set: Average loss: 2.1279, Accuracy: 3432/5000 (69%)\n",
      "[epoch 39] loss: 0.0000786\n",
      "Test set: Average loss: 2.2259, Accuracy: 3419/5000 (68%)\n",
      "[epoch 40] loss: 0.0000509\n",
      "Test set: Average loss: 2.2584, Accuracy: 3428/5000 (69%)\n",
      "[epoch 41] loss: 0.0000326\n",
      "Test set: Average loss: 2.3332, Accuracy: 3420/5000 (68%)\n",
      "[epoch 42] loss: 0.0000211\n",
      "Test set: Average loss: 2.3936, Accuracy: 3425/5000 (68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 43] loss: 0.0000135\n",
      "Test set: Average loss: 2.4657, Accuracy: 3432/5000 (69%)\n",
      "[epoch 44] loss: 0.0000086\n",
      "Test set: Average loss: 2.5259, Accuracy: 3427/5000 (69%)\n",
      "[epoch 45] loss: 0.0000055\n",
      "Test set: Average loss: 2.5944, Accuracy: 3435/5000 (69%)\n",
      "[epoch 46] loss: 0.0000034\n",
      "Test set: Average loss: 2.6697, Accuracy: 3426/5000 (69%)\n",
      "[epoch 47] loss: 0.0000022\n",
      "Test set: Average loss: 2.7242, Accuracy: 3432/5000 (69%)\n",
      "[epoch 48] loss: 0.0000014\n",
      "Test set: Average loss: 2.7839, Accuracy: 3426/5000 (69%)\n",
      "[epoch 49] loss: 0.0000008\n",
      "Test set: Average loss: 2.8334, Accuracy: 3422/5000 (68%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 2.8700, Accuracy: 3414/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.5944, Accuracy: 3435/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.5128, Accuracy: 6949/10000 (69%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3020, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 1.2233894\n",
      "Test set: Average loss: 1.1531, Accuracy: 2981/5000 (60%)\n",
      "[epoch 2] loss: 1.0971701\n",
      "Test set: Average loss: 1.1522, Accuracy: 3009/5000 (60%)\n",
      "[epoch 3] loss: 1.0508519\n",
      "Test set: Average loss: 1.1403, Accuracy: 2985/5000 (60%)\n",
      "[epoch 4] loss: 1.0169283\n",
      "Test set: Average loss: 1.1529, Accuracy: 2971/5000 (59%)\n",
      "[epoch 5] loss: 0.9816322\n",
      "Test set: Average loss: 1.0516, Accuracy: 3188/5000 (64%)\n",
      "[epoch 6] loss: 0.9440099\n",
      "Test set: Average loss: 1.0741, Accuracy: 3145/5000 (63%)\n",
      "[epoch 7] loss: 0.9081753\n",
      "Test set: Average loss: 1.0554, Accuracy: 3176/5000 (64%)\n",
      "[epoch 8] loss: 0.8685496\n",
      "Test set: Average loss: 1.0622, Accuracy: 3168/5000 (63%)\n",
      "[epoch 9] loss: 0.8430664\n",
      "Test set: Average loss: 1.0666, Accuracy: 3147/5000 (63%)\n",
      "[epoch 10] loss: 0.8032120\n",
      "Test set: Average loss: 1.0062, Accuracy: 3302/5000 (66%)\n",
      "[epoch 11] loss: 0.7598631\n",
      "Test set: Average loss: 1.0123, Accuracy: 3299/5000 (66%)\n",
      "[epoch 12] loss: 0.7021422\n",
      "Test set: Average loss: 1.0437, Accuracy: 3238/5000 (65%)\n",
      "[epoch 13] loss: 0.6453702\n",
      "Test set: Average loss: 1.0777, Accuracy: 3274/5000 (65%)\n",
      "[epoch 14] loss: 0.5794260\n",
      "Test set: Average loss: 1.0757, Accuracy: 3272/5000 (65%)\n",
      "[epoch 15] loss: 0.5172149\n",
      "Test set: Average loss: 1.1045, Accuracy: 3315/5000 (66%)\n",
      "[epoch 16] loss: 0.4414640\n",
      "Test set: Average loss: 1.1929, Accuracy: 3273/5000 (65%)\n",
      "[epoch 17] loss: 0.3585562\n",
      "Test set: Average loss: 1.2648, Accuracy: 3239/5000 (65%)\n",
      "[epoch 18] loss: 0.3000041\n",
      "Test set: Average loss: 1.3074, Accuracy: 3298/5000 (66%)\n",
      "[epoch 19] loss: 0.2361579\n",
      "Test set: Average loss: 1.4413, Accuracy: 3235/5000 (65%)\n",
      "[epoch 20] loss: 0.2099996\n",
      "Test set: Average loss: 1.5020, Accuracy: 3276/5000 (66%)\n",
      "[epoch 21] loss: 0.1683682\n",
      "Test set: Average loss: 1.5493, Accuracy: 3251/5000 (65%)\n",
      "[epoch 22] loss: 0.1666383\n",
      "Test set: Average loss: 1.5550, Accuracy: 3268/5000 (65%)\n",
      "[epoch 23] loss: 0.1535000\n",
      "Test set: Average loss: 1.6316, Accuracy: 3237/5000 (65%)\n",
      "[epoch 24] loss: 0.1415865\n",
      "Test set: Average loss: 1.7594, Accuracy: 3256/5000 (65%)\n",
      "[epoch 25] loss: 0.1300677\n",
      "Test set: Average loss: 1.8559, Accuracy: 3165/5000 (63%)\n",
      "[epoch 26] loss: 0.1479880\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8278, Accuracy: 3231/5000 (65%)\n",
      "[epoch 27] loss: 0.0400124\n",
      "Test set: Average loss: 1.7412, Accuracy: 3315/5000 (66%)\n",
      "[epoch 28] loss: 0.0131369\n",
      "Test set: Average loss: 1.7537, Accuracy: 3304/5000 (66%)\n",
      "[epoch 29] loss: 0.0080656\n",
      "Test set: Average loss: 1.7660, Accuracy: 3317/5000 (66%)\n",
      "[epoch 30] loss: 0.0055527\n",
      "Test set: Average loss: 1.7903, Accuracy: 3318/5000 (66%)\n",
      "[epoch 31] loss: 0.0039240\n",
      "Test set: Average loss: 1.8078, Accuracy: 3315/5000 (66%)\n",
      "[epoch 32] loss: 0.0027651\n",
      "Test set: Average loss: 1.8395, Accuracy: 3335/5000 (67%)\n",
      "[epoch 33] loss: 0.0019270\n",
      "Test set: Average loss: 1.8724, Accuracy: 3322/5000 (66%)\n",
      "[epoch 34] loss: 0.0013313\n",
      "Test set: Average loss: 1.9148, Accuracy: 3340/5000 (67%)\n",
      "[epoch 35] loss: 0.0009089\n",
      "Test set: Average loss: 1.9543, Accuracy: 3336/5000 (67%)\n",
      "[epoch 36] loss: 0.0006118\n",
      "Test set: Average loss: 2.0095, Accuracy: 3342/5000 (67%)\n",
      "[epoch 37] loss: 0.0004069\n",
      "Test set: Average loss: 2.0573, Accuracy: 3344/5000 (67%)\n",
      "[epoch 38] loss: 0.0002704\n",
      "Test set: Average loss: 2.1185, Accuracy: 3342/5000 (67%)\n",
      "[epoch 39] loss: 0.0001765\n",
      "Test set: Average loss: 2.1689, Accuracy: 3360/5000 (67%)\n",
      "[epoch 40] loss: 0.0001150\n",
      "Test set: Average loss: 2.2234, Accuracy: 3358/5000 (67%)\n",
      "[epoch 41] loss: 0.0000743\n",
      "Test set: Average loss: 2.2911, Accuracy: 3361/5000 (67%)\n",
      "[epoch 42] loss: 0.0000482\n",
      "Test set: Average loss: 2.3587, Accuracy: 3371/5000 (67%)\n",
      "[epoch 43] loss: 0.0000309\n",
      "Test set: Average loss: 2.4276, Accuracy: 3353/5000 (67%)\n",
      "[epoch 44] loss: 0.0000197\n",
      "Test set: Average loss: 2.4852, Accuracy: 3362/5000 (67%)\n",
      "[epoch 45] loss: 0.0000126\n",
      "Test set: Average loss: 2.5502, Accuracy: 3368/5000 (67%)\n",
      "[epoch 46] loss: 0.0000080\n",
      "Test set: Average loss: 2.6151, Accuracy: 3378/5000 (68%)\n",
      "[epoch 47] loss: 0.0000050\n",
      "Test set: Average loss: 2.6909, Accuracy: 3368/5000 (67%)\n",
      "[epoch 48] loss: 0.0000032\n",
      "Test set: Average loss: 2.7531, Accuracy: 3372/5000 (67%)\n",
      "[epoch 49] loss: 0.0000020\n",
      "Test set: Average loss: 2.8168, Accuracy: 3370/5000 (67%)\n",
      "[epoch 50] loss: 0.0000012\n",
      "Test set: Average loss: 2.8789, Accuracy: 3372/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6151, Accuracy: 3378/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.5123, Accuracy: 6887/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 463/5000 (9%)\n",
      "[epoch 1] loss: 1.2095230\n",
      "Test set: Average loss: 1.1376, Accuracy: 3030/5000 (61%)\n",
      "[epoch 2] loss: 1.0989272\n",
      "Test set: Average loss: 1.0967, Accuracy: 3084/5000 (62%)\n",
      "[epoch 3] loss: 1.0415257\n",
      "Test set: Average loss: 1.1994, Accuracy: 2884/5000 (58%)\n",
      "[epoch 4] loss: 1.0200159\n",
      "Test set: Average loss: 1.0779, Accuracy: 3126/5000 (63%)\n",
      "[epoch 5] loss: 0.9838388\n",
      "Test set: Average loss: 1.0975, Accuracy: 3112/5000 (62%)\n",
      "[epoch 6] loss: 0.9398412\n",
      "Test set: Average loss: 1.0674, Accuracy: 3121/5000 (62%)\n",
      "[epoch 7] loss: 0.9024519\n",
      "Test set: Average loss: 1.0011, Accuracy: 3260/5000 (65%)\n",
      "[epoch 8] loss: 0.8697678\n",
      "Test set: Average loss: 1.0851, Accuracy: 3123/5000 (62%)\n",
      "[epoch 9] loss: 0.8315045\n",
      "Test set: Average loss: 1.0625, Accuracy: 3225/5000 (64%)\n",
      "[epoch 10] loss: 0.7995821\n",
      "Test set: Average loss: 1.0830, Accuracy: 3188/5000 (64%)\n",
      "[epoch 11] loss: 0.7557134\n",
      "Test set: Average loss: 1.0847, Accuracy: 3195/5000 (64%)\n",
      "[epoch 12] loss: 0.7030685\n",
      "Test set: Average loss: 1.0567, Accuracy: 3289/5000 (66%)\n",
      "[epoch 13] loss: 0.6514585\n",
      "Test set: Average loss: 1.0326, Accuracy: 3274/5000 (65%)\n",
      "[epoch 14] loss: 0.5883347\n",
      "Test set: Average loss: 1.0780, Accuracy: 3295/5000 (66%)\n",
      "[epoch 15] loss: 0.5200585\n",
      "Test set: Average loss: 1.1062, Accuracy: 3276/5000 (66%)\n",
      "[epoch 16] loss: 0.4393242\n",
      "Test set: Average loss: 1.1287, Accuracy: 3259/5000 (65%)\n",
      "[epoch 17] loss: 0.3705869\n",
      "Test set: Average loss: 1.2335, Accuracy: 3217/5000 (64%)\n",
      "[epoch 18] loss: 0.3070823\n",
      "Test set: Average loss: 1.3098, Accuracy: 3232/5000 (65%)\n",
      "[epoch 19] loss: 0.2456755\n",
      "Test set: Average loss: 1.3879, Accuracy: 3242/5000 (65%)\n",
      "[epoch 20] loss: 0.2012563\n",
      "Test set: Average loss: 1.4305, Accuracy: 3218/5000 (64%)\n",
      "[epoch 21] loss: 0.1798427\n",
      "Test set: Average loss: 1.5360, Accuracy: 3234/5000 (65%)\n",
      "[epoch 22] loss: 0.1775641\n",
      "Test set: Average loss: 1.6093, Accuracy: 3220/5000 (64%)\n",
      "[epoch 23] loss: 0.1421296\n",
      "Test set: Average loss: 1.7135, Accuracy: 3226/5000 (65%)\n",
      "[epoch 24] loss: 0.1545134\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7144, Accuracy: 3240/5000 (65%)\n",
      "[epoch 25] loss: 0.0540163\n",
      "Test set: Average loss: 1.5886, Accuracy: 3317/5000 (66%)\n",
      "[epoch 26] loss: 0.0186310\n",
      "Test set: Average loss: 1.5982, Accuracy: 3332/5000 (67%)\n",
      "[epoch 27] loss: 0.0112622\n",
      "Test set: Average loss: 1.6205, Accuracy: 3337/5000 (67%)\n",
      "[epoch 28] loss: 0.0077129\n",
      "Test set: Average loss: 1.6484, Accuracy: 3361/5000 (67%)\n",
      "[epoch 29] loss: 0.0054552\n",
      "Test set: Average loss: 1.6799, Accuracy: 3365/5000 (67%)\n",
      "[epoch 30] loss: 0.0037975\n",
      "Test set: Average loss: 1.7119, Accuracy: 3361/5000 (67%)\n",
      "[epoch 31] loss: 0.0026493\n",
      "Test set: Average loss: 1.7488, Accuracy: 3378/5000 (68%)\n",
      "[epoch 32] loss: 0.0018240\n",
      "Test set: Average loss: 1.7942, Accuracy: 3387/5000 (68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] loss: 0.0012438\n",
      "Test set: Average loss: 1.8386, Accuracy: 3386/5000 (68%)\n",
      "[epoch 34] loss: 0.0008394\n",
      "Test set: Average loss: 1.8881, Accuracy: 3401/5000 (68%)\n",
      "[epoch 35] loss: 0.0005615\n",
      "Test set: Average loss: 1.9512, Accuracy: 3384/5000 (68%)\n",
      "[epoch 36] loss: 0.0003751\n",
      "Test set: Average loss: 2.0079, Accuracy: 3393/5000 (68%)\n",
      "[epoch 37] loss: 0.0002461\n",
      "Test set: Average loss: 2.0641, Accuracy: 3393/5000 (68%)\n",
      "[epoch 38] loss: 0.0001625\n",
      "Test set: Average loss: 2.1220, Accuracy: 3391/5000 (68%)\n",
      "[epoch 39] loss: 0.0001052\n",
      "Test set: Average loss: 2.1875, Accuracy: 3402/5000 (68%)\n",
      "[epoch 40] loss: 0.0000683\n",
      "Test set: Average loss: 2.2548, Accuracy: 3403/5000 (68%)\n",
      "[epoch 41] loss: 0.0000441\n",
      "Test set: Average loss: 2.3111, Accuracy: 3406/5000 (68%)\n",
      "[epoch 42] loss: 0.0000283\n",
      "Test set: Average loss: 2.3886, Accuracy: 3391/5000 (68%)\n",
      "[epoch 43] loss: 0.0000182\n",
      "Test set: Average loss: 2.4499, Accuracy: 3407/5000 (68%)\n",
      "[epoch 44] loss: 0.0000116\n",
      "Test set: Average loss: 2.5188, Accuracy: 3399/5000 (68%)\n",
      "[epoch 45] loss: 0.0000073\n",
      "Test set: Average loss: 2.5831, Accuracy: 3416/5000 (68%)\n",
      "[epoch 46] loss: 0.0000046\n",
      "Test set: Average loss: 2.6589, Accuracy: 3416/5000 (68%)\n",
      "[epoch 47] loss: 0.0000029\n",
      "Test set: Average loss: 2.7250, Accuracy: 3412/5000 (68%)\n",
      "[epoch 48] loss: 0.0000018\n",
      "Test set: Average loss: 2.7921, Accuracy: 3401/5000 (68%)\n",
      "[epoch 49] loss: 0.0000011\n",
      "Test set: Average loss: 2.8550, Accuracy: 3403/5000 (68%)\n",
      "[epoch 50] loss: 0.0000007\n",
      "Test set: Average loss: 2.8965, Accuracy: 3402/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6589, Accuracy: 3416/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6667, Accuracy: 6900/10000 (69%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3006, Accuracy: 771/5000 (15%)\n",
      "[epoch 1] loss: 1.1987644\n",
      "Test set: Average loss: 1.1726, Accuracy: 2989/5000 (60%)\n",
      "[epoch 2] loss: 1.0895205\n",
      "Test set: Average loss: 1.1136, Accuracy: 3026/5000 (61%)\n",
      "[epoch 3] loss: 1.0372920\n",
      "Test set: Average loss: 1.1114, Accuracy: 3074/5000 (61%)\n",
      "[epoch 4] loss: 0.9978968\n",
      "Test set: Average loss: 1.0770, Accuracy: 3119/5000 (62%)\n",
      "[epoch 5] loss: 0.9633347\n",
      "Test set: Average loss: 1.0572, Accuracy: 3148/5000 (63%)\n",
      "[epoch 6] loss: 0.9324387\n",
      "Test set: Average loss: 1.0707, Accuracy: 3123/5000 (62%)\n",
      "[epoch 7] loss: 0.8909338\n",
      "Test set: Average loss: 1.0025, Accuracy: 3285/5000 (66%)\n",
      "[epoch 8] loss: 0.8483574\n",
      "Test set: Average loss: 1.0088, Accuracy: 3261/5000 (65%)\n",
      "[epoch 9] loss: 0.8158280\n",
      "Test set: Average loss: 1.0065, Accuracy: 3300/5000 (66%)\n",
      "[epoch 10] loss: 0.7695943\n",
      "Test set: Average loss: 0.9963, Accuracy: 3316/5000 (66%)\n",
      "[epoch 11] loss: 0.7230284\n",
      "Test set: Average loss: 0.9872, Accuracy: 3339/5000 (67%)\n",
      "[epoch 12] loss: 0.6652134\n",
      "Test set: Average loss: 0.9777, Accuracy: 3344/5000 (67%)\n",
      "[epoch 13] loss: 0.6100381\n",
      "Test set: Average loss: 1.0115, Accuracy: 3358/5000 (67%)\n",
      "[epoch 14] loss: 0.5382013\n",
      "Test set: Average loss: 1.0966, Accuracy: 3285/5000 (66%)\n",
      "[epoch 15] loss: 0.4719091\n",
      "Test set: Average loss: 1.1012, Accuracy: 3370/5000 (67%)\n",
      "[epoch 16] loss: 0.3970374\n",
      "Test set: Average loss: 1.1405, Accuracy: 3354/5000 (67%)\n",
      "[epoch 17] loss: 0.3400723\n",
      "Test set: Average loss: 1.2030, Accuracy: 3340/5000 (67%)\n",
      "[epoch 18] loss: 0.2794441\n",
      "Test set: Average loss: 1.2769, Accuracy: 3326/5000 (67%)\n",
      "[epoch 19] loss: 0.2304552\n",
      "Test set: Average loss: 1.3508, Accuracy: 3363/5000 (67%)\n",
      "[epoch 20] loss: 0.2027909\n",
      "Test set: Average loss: 1.4015, Accuracy: 3333/5000 (67%)\n",
      "[epoch 21] loss: 0.1855627\n",
      "Test set: Average loss: 1.5240, Accuracy: 3339/5000 (67%)\n",
      "[epoch 22] loss: 0.1791212\n",
      "Test set: Average loss: 1.5576, Accuracy: 3281/5000 (66%)\n",
      "[epoch 23] loss: 0.1741721\n",
      "Test set: Average loss: 1.6417, Accuracy: 3301/5000 (66%)\n",
      "[epoch 24] loss: 0.1725361\n",
      "Test set: Average loss: 1.6309, Accuracy: 3276/5000 (66%)\n",
      "[epoch 25] loss: 0.1478599\n",
      "Test set: Average loss: 1.7100, Accuracy: 3266/5000 (65%)\n",
      "[epoch 26] loss: 0.1566986\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7548, Accuracy: 3291/5000 (66%)\n",
      "[epoch 27] loss: 0.0544135\n",
      "Test set: Average loss: 1.6279, Accuracy: 3377/5000 (68%)\n",
      "[epoch 28] loss: 0.0174748\n",
      "Test set: Average loss: 1.6416, Accuracy: 3400/5000 (68%)\n",
      "[epoch 29] loss: 0.0098806\n",
      "Test set: Average loss: 1.6639, Accuracy: 3402/5000 (68%)\n",
      "[epoch 30] loss: 0.0064710\n",
      "Test set: Average loss: 1.6932, Accuracy: 3404/5000 (68%)\n",
      "[epoch 31] loss: 0.0043461\n",
      "Test set: Average loss: 1.7255, Accuracy: 3398/5000 (68%)\n",
      "[epoch 32] loss: 0.0029220\n",
      "Test set: Average loss: 1.7592, Accuracy: 3390/5000 (68%)\n",
      "[epoch 33] loss: 0.0019482\n",
      "Test set: Average loss: 1.8021, Accuracy: 3382/5000 (68%)\n",
      "[epoch 34] loss: 0.0012789\n",
      "Test set: Average loss: 1.8557, Accuracy: 3395/5000 (68%)\n",
      "[epoch 35] loss: 0.0008301\n",
      "Test set: Average loss: 1.9115, Accuracy: 3399/5000 (68%)\n",
      "[epoch 36] loss: 0.0005344\n",
      "Test set: Average loss: 1.9682, Accuracy: 3379/5000 (68%)\n",
      "[epoch 37] loss: 0.0003391\n",
      "Test set: Average loss: 2.0229, Accuracy: 3379/5000 (68%)\n",
      "[epoch 38] loss: 0.0002132\n",
      "Test set: Average loss: 2.0924, Accuracy: 3390/5000 (68%)\n",
      "[epoch 39] loss: 0.0001340\n",
      "Test set: Average loss: 2.1535, Accuracy: 3380/5000 (68%)\n",
      "[epoch 40] loss: 0.0000831\n",
      "Test set: Average loss: 2.2218, Accuracy: 3383/5000 (68%)\n",
      "[epoch 41] loss: 0.0000518\n",
      "Test set: Average loss: 2.2975, Accuracy: 3383/5000 (68%)\n",
      "[epoch 42] loss: 0.0000320\n",
      "Test set: Average loss: 2.3679, Accuracy: 3384/5000 (68%)\n",
      "[epoch 43] loss: 0.0000195\n",
      "Test set: Average loss: 2.4300, Accuracy: 3393/5000 (68%)\n",
      "[epoch 44] loss: 0.0000118\n",
      "Test set: Average loss: 2.5129, Accuracy: 3384/5000 (68%)\n",
      "[epoch 45] loss: 0.0000072\n",
      "Test set: Average loss: 2.5865, Accuracy: 3390/5000 (68%)\n",
      "[epoch 46] loss: 0.0000044\n",
      "Test set: Average loss: 2.6645, Accuracy: 3383/5000 (68%)\n",
      "[epoch 47] loss: 0.0000026\n",
      "Test set: Average loss: 2.7389, Accuracy: 3386/5000 (68%)\n",
      "[epoch 48] loss: 0.0000016\n",
      "Test set: Average loss: 2.8039, Accuracy: 3386/5000 (68%)\n",
      "[epoch 49] loss: 0.0000009\n",
      "Test set: Average loss: 2.8584, Accuracy: 3383/5000 (68%)\n",
      "[epoch 50] loss: 0.0000006\n",
      "Test set: Average loss: 2.9020, Accuracy: 3377/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6932, Accuracy: 3404/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 1.6841, Accuracy: 6822/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3061, Accuracy: 603/5000 (12%)\n",
      "[epoch 1] loss: 1.1962671\n",
      "Test set: Average loss: 1.2024, Accuracy: 2892/5000 (58%)\n",
      "[epoch 2] loss: 1.0928770\n",
      "Test set: Average loss: 1.1841, Accuracy: 2905/5000 (58%)\n",
      "[epoch 3] loss: 1.0512470\n",
      "Test set: Average loss: 1.0831, Accuracy: 3115/5000 (62%)\n",
      "[epoch 4] loss: 1.0177541\n",
      "Test set: Average loss: 1.0814, Accuracy: 3127/5000 (63%)\n",
      "[epoch 5] loss: 0.9790186\n",
      "Test set: Average loss: 1.0487, Accuracy: 3184/5000 (64%)\n",
      "[epoch 6] loss: 0.9417021\n",
      "Test set: Average loss: 1.0656, Accuracy: 3184/5000 (64%)\n",
      "[epoch 7] loss: 0.9016673\n",
      "Test set: Average loss: 1.0709, Accuracy: 3142/5000 (63%)\n",
      "[epoch 8] loss: 0.8752217\n",
      "Test set: Average loss: 0.9936, Accuracy: 3276/5000 (66%)\n",
      "[epoch 9] loss: 0.8352272\n",
      "Test set: Average loss: 1.0314, Accuracy: 3265/5000 (65%)\n",
      "[epoch 10] loss: 0.7936114\n",
      "Test set: Average loss: 0.9947, Accuracy: 3317/5000 (66%)\n",
      "[epoch 11] loss: 0.7431297\n",
      "Test set: Average loss: 0.9869, Accuracy: 3335/5000 (67%)\n",
      "[epoch 12] loss: 0.6913051\n",
      "Test set: Average loss: 1.0004, Accuracy: 3359/5000 (67%)\n",
      "[epoch 13] loss: 0.6329075\n",
      "Test set: Average loss: 1.0699, Accuracy: 3277/5000 (66%)\n",
      "[epoch 14] loss: 0.5653739\n",
      "Test set: Average loss: 1.0486, Accuracy: 3344/5000 (67%)\n",
      "[epoch 15] loss: 0.5007143\n",
      "Test set: Average loss: 1.0986, Accuracy: 3370/5000 (67%)\n",
      "[epoch 16] loss: 0.4292186\n",
      "Test set: Average loss: 1.1646, Accuracy: 3346/5000 (67%)\n",
      "[epoch 17] loss: 0.3500607\n",
      "Test set: Average loss: 1.2288, Accuracy: 3319/5000 (66%)\n",
      "[epoch 18] loss: 0.2949321\n",
      "Test set: Average loss: 1.2662, Accuracy: 3308/5000 (66%)\n",
      "[epoch 19] loss: 0.2526992\n",
      "Test set: Average loss: 1.3355, Accuracy: 3307/5000 (66%)\n",
      "[epoch 20] loss: 0.2097157\n",
      "Test set: Average loss: 1.4011, Accuracy: 3317/5000 (66%)\n",
      "[epoch 21] loss: 0.1861794\n",
      "Test set: Average loss: 1.4850, Accuracy: 3305/5000 (66%)\n",
      "[epoch 22] loss: 0.1827188\n",
      "Test set: Average loss: 1.6066, Accuracy: 3257/5000 (65%)\n",
      "[epoch 23] loss: 0.1673128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6480, Accuracy: 3249/5000 (65%)\n",
      "[epoch 24] loss: 0.1520080\n",
      "Test set: Average loss: 1.6616, Accuracy: 3275/5000 (66%)\n",
      "[epoch 25] loss: 0.1503092\n",
      "Test set: Average loss: 1.7303, Accuracy: 3280/5000 (66%)\n",
      "[epoch 26] loss: 0.1630289\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7306, Accuracy: 3313/5000 (66%)\n",
      "[epoch 27] loss: 0.0536305\n",
      "Test set: Average loss: 1.5994, Accuracy: 3403/5000 (68%)\n",
      "[epoch 28] loss: 0.0170406\n",
      "Test set: Average loss: 1.6218, Accuracy: 3410/5000 (68%)\n",
      "[epoch 29] loss: 0.0095904\n",
      "Test set: Average loss: 1.6479, Accuracy: 3409/5000 (68%)\n",
      "[epoch 30] loss: 0.0063154\n",
      "Test set: Average loss: 1.6653, Accuracy: 3420/5000 (68%)\n",
      "[epoch 31] loss: 0.0042381\n",
      "Test set: Average loss: 1.7026, Accuracy: 3421/5000 (68%)\n",
      "[epoch 32] loss: 0.0028409\n",
      "Test set: Average loss: 1.7457, Accuracy: 3425/5000 (68%)\n",
      "[epoch 33] loss: 0.0018880\n",
      "Test set: Average loss: 1.7812, Accuracy: 3436/5000 (69%)\n",
      "[epoch 34] loss: 0.0012357\n",
      "Test set: Average loss: 1.8286, Accuracy: 3432/5000 (69%)\n",
      "[epoch 35] loss: 0.0007998\n",
      "Test set: Average loss: 1.8801, Accuracy: 3450/5000 (69%)\n",
      "[epoch 36] loss: 0.0005071\n",
      "Test set: Average loss: 1.9449, Accuracy: 3447/5000 (69%)\n",
      "[epoch 37] loss: 0.0003215\n",
      "Test set: Average loss: 1.9976, Accuracy: 3439/5000 (69%)\n",
      "[epoch 38] loss: 0.0002017\n",
      "Test set: Average loss: 2.0546, Accuracy: 3445/5000 (69%)\n",
      "[epoch 39] loss: 0.0001255\n",
      "Test set: Average loss: 2.1187, Accuracy: 3447/5000 (69%)\n",
      "[epoch 40] loss: 0.0000779\n",
      "Test set: Average loss: 2.1910, Accuracy: 3452/5000 (69%)\n",
      "[epoch 41] loss: 0.0000481\n",
      "Test set: Average loss: 2.2547, Accuracy: 3445/5000 (69%)\n",
      "[epoch 42] loss: 0.0000294\n",
      "Test set: Average loss: 2.3359, Accuracy: 3456/5000 (69%)\n",
      "[epoch 43] loss: 0.0000180\n",
      "Test set: Average loss: 2.4055, Accuracy: 3454/5000 (69%)\n",
      "[epoch 44] loss: 0.0000109\n",
      "Test set: Average loss: 2.4813, Accuracy: 3438/5000 (69%)\n",
      "[epoch 45] loss: 0.0000066\n",
      "Test set: Average loss: 2.5515, Accuracy: 3447/5000 (69%)\n",
      "[epoch 46] loss: 0.0000039\n",
      "Test set: Average loss: 2.6276, Accuracy: 3456/5000 (69%)\n",
      "[epoch 47] loss: 0.0000024\n",
      "Test set: Average loss: 2.6906, Accuracy: 3454/5000 (69%)\n",
      "[epoch 48] loss: 0.0000014\n",
      "Test set: Average loss: 2.7615, Accuracy: 3459/5000 (69%)\n",
      "[epoch 49] loss: 0.0000008\n",
      "Test set: Average loss: 2.8159, Accuracy: 3446/5000 (69%)\n",
      "[epoch 50] loss: 0.0000005\n",
      "Test set: Average loss: 2.8593, Accuracy: 3439/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7615, Accuracy: 3459/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.7510, Accuracy: 6901/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3011, Accuracy: 569/5000 (11%)\n",
      "[epoch 1] loss: 1.2063681\n",
      "Test set: Average loss: 1.2057, Accuracy: 2825/5000 (56%)\n",
      "[epoch 2] loss: 1.0910258\n",
      "Test set: Average loss: 1.1307, Accuracy: 3008/5000 (60%)\n",
      "[epoch 3] loss: 1.0479832\n",
      "Test set: Average loss: 1.0856, Accuracy: 3087/5000 (62%)\n",
      "[epoch 4] loss: 1.0080999\n",
      "Test set: Average loss: 1.0905, Accuracy: 3093/5000 (62%)\n",
      "[epoch 5] loss: 0.9699391\n",
      "Test set: Average loss: 1.0679, Accuracy: 3124/5000 (62%)\n",
      "[epoch 6] loss: 0.9330359\n",
      "Test set: Average loss: 1.0539, Accuracy: 3159/5000 (63%)\n",
      "[epoch 7] loss: 0.8988099\n",
      "Test set: Average loss: 1.0155, Accuracy: 3273/5000 (65%)\n",
      "[epoch 8] loss: 0.8641773\n",
      "Test set: Average loss: 1.0338, Accuracy: 3240/5000 (65%)\n",
      "[epoch 9] loss: 0.8256251\n",
      "Test set: Average loss: 1.0423, Accuracy: 3160/5000 (63%)\n",
      "[epoch 10] loss: 0.7810141\n",
      "Test set: Average loss: 1.0127, Accuracy: 3294/5000 (66%)\n",
      "[epoch 11] loss: 0.7348253\n",
      "Test set: Average loss: 1.0062, Accuracy: 3300/5000 (66%)\n",
      "[epoch 12] loss: 0.6790733\n",
      "Test set: Average loss: 1.0361, Accuracy: 3324/5000 (66%)\n",
      "[epoch 13] loss: 0.6210434\n",
      "Test set: Average loss: 1.0452, Accuracy: 3296/5000 (66%)\n",
      "[epoch 14] loss: 0.5563775\n",
      "Test set: Average loss: 1.0861, Accuracy: 3308/5000 (66%)\n",
      "[epoch 15] loss: 0.4900152\n",
      "Test set: Average loss: 1.1006, Accuracy: 3299/5000 (66%)\n",
      "[epoch 16] loss: 0.4206030\n",
      "Test set: Average loss: 1.1638, Accuracy: 3322/5000 (66%)\n",
      "[epoch 17] loss: 0.3579068\n",
      "Test set: Average loss: 1.2404, Accuracy: 3313/5000 (66%)\n",
      "[epoch 18] loss: 0.2970137\n",
      "Test set: Average loss: 1.2851, Accuracy: 3306/5000 (66%)\n",
      "[epoch 19] loss: 0.2427886\n",
      "Test set: Average loss: 1.4196, Accuracy: 3268/5000 (65%)\n",
      "[epoch 20] loss: 0.2160651\n",
      "Test set: Average loss: 1.4234, Accuracy: 3260/5000 (65%)\n",
      "[epoch 21] loss: 0.1811410\n",
      "Test set: Average loss: 1.6192, Accuracy: 3211/5000 (64%)\n",
      "[epoch 22] loss: 0.1838526\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5462, Accuracy: 3289/5000 (66%)\n",
      "[epoch 23] loss: 0.0644544\n",
      "Test set: Average loss: 1.4940, Accuracy: 3349/5000 (67%)\n",
      "[epoch 24] loss: 0.0260494\n",
      "Test set: Average loss: 1.5139, Accuracy: 3377/5000 (68%)\n",
      "[epoch 25] loss: 0.0160083\n",
      "Test set: Average loss: 1.5378, Accuracy: 3378/5000 (68%)\n",
      "[epoch 26] loss: 0.0107028\n",
      "Test set: Average loss: 1.5645, Accuracy: 3391/5000 (68%)\n",
      "[epoch 27] loss: 0.0073860\n",
      "Test set: Average loss: 1.6032, Accuracy: 3413/5000 (68%)\n",
      "[epoch 28] loss: 0.0050154\n",
      "Test set: Average loss: 1.6433, Accuracy: 3389/5000 (68%)\n",
      "[epoch 29] loss: 0.0033644\n",
      "Test set: Average loss: 1.6973, Accuracy: 3415/5000 (68%)\n",
      "[epoch 30] loss: 0.0022683\n",
      "Test set: Average loss: 1.7392, Accuracy: 3415/5000 (68%)\n",
      "[epoch 31] loss: 0.0014958\n",
      "Test set: Average loss: 1.8059, Accuracy: 3402/5000 (68%)\n",
      "[epoch 32] loss: 0.0009838\n",
      "Test set: Average loss: 1.8574, Accuracy: 3420/5000 (68%)\n",
      "[epoch 33] loss: 0.0006344\n",
      "Test set: Average loss: 1.9126, Accuracy: 3419/5000 (68%)\n",
      "[epoch 34] loss: 0.0004121\n",
      "Test set: Average loss: 1.9785, Accuracy: 3420/5000 (68%)\n",
      "[epoch 35] loss: 0.0002640\n",
      "Test set: Average loss: 2.0405, Accuracy: 3418/5000 (68%)\n",
      "[epoch 36] loss: 0.0001676\n",
      "Test set: Average loss: 2.1087, Accuracy: 3428/5000 (69%)\n",
      "[epoch 37] loss: 0.0001063\n",
      "Test set: Average loss: 2.1755, Accuracy: 3428/5000 (69%)\n",
      "[epoch 38] loss: 0.0000663\n",
      "Test set: Average loss: 2.2479, Accuracy: 3434/5000 (69%)\n",
      "[epoch 39] loss: 0.0000418\n",
      "Test set: Average loss: 2.3109, Accuracy: 3431/5000 (69%)\n",
      "[epoch 40] loss: 0.0000259\n",
      "Test set: Average loss: 2.3917, Accuracy: 3432/5000 (69%)\n",
      "[epoch 41] loss: 0.0000160\n",
      "Test set: Average loss: 2.4671, Accuracy: 3438/5000 (69%)\n",
      "[epoch 42] loss: 0.0000099\n",
      "Test set: Average loss: 2.5418, Accuracy: 3430/5000 (69%)\n",
      "[epoch 43] loss: 0.0000060\n",
      "Test set: Average loss: 2.6247, Accuracy: 3439/5000 (69%)\n",
      "[epoch 44] loss: 0.0000037\n",
      "Test set: Average loss: 2.6917, Accuracy: 3430/5000 (69%)\n",
      "[epoch 45] loss: 0.0000022\n",
      "Test set: Average loss: 2.7617, Accuracy: 3436/5000 (69%)\n",
      "[epoch 46] loss: 0.0000013\n",
      "Test set: Average loss: 2.8331, Accuracy: 3434/5000 (69%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 2.8920, Accuracy: 3430/5000 (69%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 2.9264, Accuracy: 3414/5000 (68%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 2.9437, Accuracy: 3426/5000 (69%)\n",
      "[epoch 50] loss: 0.0005653\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 3.1517, Accuracy: 3325/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6247, Accuracy: 3439/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.5773, Accuracy: 6949/10000 (69%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3044, Accuracy: 478/5000 (10%)\n",
      "[epoch 1] loss: 1.1896583\n",
      "Test set: Average loss: 1.2192, Accuracy: 2875/5000 (58%)\n",
      "[epoch 2] loss: 1.0899595\n",
      "Test set: Average loss: 1.0843, Accuracy: 3097/5000 (62%)\n",
      "[epoch 3] loss: 1.0434472\n",
      "Test set: Average loss: 1.0819, Accuracy: 3157/5000 (63%)\n",
      "[epoch 4] loss: 1.0035372\n",
      "Test set: Average loss: 1.1045, Accuracy: 3090/5000 (62%)\n",
      "[epoch 5] loss: 0.9684949\n",
      "Test set: Average loss: 1.0601, Accuracy: 3155/5000 (63%)\n",
      "[epoch 6] loss: 0.9281254\n",
      "Test set: Average loss: 1.0350, Accuracy: 3199/5000 (64%)\n",
      "[epoch 7] loss: 0.8887081\n",
      "Test set: Average loss: 1.0065, Accuracy: 3297/5000 (66%)\n",
      "[epoch 8] loss: 0.8490346\n",
      "Test set: Average loss: 0.9972, Accuracy: 3303/5000 (66%)\n",
      "[epoch 9] loss: 0.8103742\n",
      "Test set: Average loss: 1.0005, Accuracy: 3234/5000 (65%)\n",
      "[epoch 10] loss: 0.7622031\n",
      "Test set: Average loss: 0.9923, Accuracy: 3336/5000 (67%)\n",
      "[epoch 11] loss: 0.7058051\n",
      "Test set: Average loss: 0.9849, Accuracy: 3324/5000 (66%)\n",
      "[epoch 12] loss: 0.6580087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.9723, Accuracy: 3404/5000 (68%)\n",
      "[epoch 13] loss: 0.5878444\n",
      "Test set: Average loss: 0.9984, Accuracy: 3380/5000 (68%)\n",
      "[epoch 14] loss: 0.5310129\n",
      "Test set: Average loss: 1.0753, Accuracy: 3348/5000 (67%)\n",
      "[epoch 15] loss: 0.4650441\n",
      "Test set: Average loss: 1.1190, Accuracy: 3332/5000 (67%)\n",
      "[epoch 16] loss: 0.3996916\n",
      "Test set: Average loss: 1.1480, Accuracy: 3342/5000 (67%)\n",
      "[epoch 17] loss: 0.3473728\n",
      "Test set: Average loss: 1.2057, Accuracy: 3355/5000 (67%)\n",
      "[epoch 18] loss: 0.2887110\n",
      "Test set: Average loss: 1.2565, Accuracy: 3354/5000 (67%)\n",
      "[epoch 19] loss: 0.2507539\n",
      "Test set: Average loss: 1.3398, Accuracy: 3366/5000 (67%)\n",
      "[epoch 20] loss: 0.2319163\n",
      "Test set: Average loss: 1.3903, Accuracy: 3303/5000 (66%)\n",
      "[epoch 21] loss: 0.2015201\n",
      "Test set: Average loss: 1.5108, Accuracy: 3328/5000 (67%)\n",
      "[epoch 22] loss: 0.1964715\n",
      "Test set: Average loss: 1.5603, Accuracy: 3277/5000 (66%)\n",
      "[epoch 23] loss: 0.1882037\n",
      "Test set: Average loss: 1.6261, Accuracy: 3266/5000 (65%)\n",
      "[epoch 24] loss: 0.1759804\n",
      "Test set: Average loss: 1.6348, Accuracy: 3323/5000 (66%)\n",
      "[epoch 25] loss: 0.1729164\n",
      "Test set: Average loss: 1.6518, Accuracy: 3287/5000 (66%)\n",
      "[epoch 26] loss: 0.1694362\n",
      "Test set: Average loss: 1.6440, Accuracy: 3318/5000 (66%)\n",
      "[epoch 27] loss: 0.1677032\n",
      "Test set: Average loss: 1.7369, Accuracy: 3321/5000 (66%)\n",
      "[epoch 28] loss: 0.1529022\n",
      "Test set: Average loss: 1.6920, Accuracy: 3342/5000 (67%)\n",
      "[epoch 29] loss: 0.1922756\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7579, Accuracy: 3267/5000 (65%)\n",
      "[epoch 30] loss: 0.0645281\n",
      "Test set: Average loss: 1.6660, Accuracy: 3366/5000 (67%)\n",
      "[epoch 31] loss: 0.0216258\n",
      "Test set: Average loss: 1.6869, Accuracy: 3385/5000 (68%)\n",
      "[epoch 32] loss: 0.0110981\n",
      "Test set: Average loss: 1.7018, Accuracy: 3390/5000 (68%)\n",
      "[epoch 33] loss: 0.0069168\n",
      "Test set: Average loss: 1.7283, Accuracy: 3400/5000 (68%)\n",
      "[epoch 34] loss: 0.0044334\n",
      "Test set: Average loss: 1.7569, Accuracy: 3409/5000 (68%)\n",
      "[epoch 35] loss: 0.0028608\n",
      "Test set: Average loss: 1.7934, Accuracy: 3421/5000 (68%)\n",
      "[epoch 36] loss: 0.0018154\n",
      "Test set: Average loss: 1.8398, Accuracy: 3419/5000 (68%)\n",
      "[epoch 37] loss: 0.0011463\n",
      "Test set: Average loss: 1.8910, Accuracy: 3430/5000 (69%)\n",
      "[epoch 38] loss: 0.0007138\n",
      "Test set: Average loss: 1.9445, Accuracy: 3435/5000 (69%)\n",
      "[epoch 39] loss: 0.0004442\n",
      "Test set: Average loss: 2.0099, Accuracy: 3434/5000 (69%)\n",
      "[epoch 40] loss: 0.0002672\n",
      "Test set: Average loss: 2.0718, Accuracy: 3441/5000 (69%)\n",
      "[epoch 41] loss: 0.0001632\n",
      "Test set: Average loss: 2.1409, Accuracy: 3450/5000 (69%)\n",
      "[epoch 42] loss: 0.0000981\n",
      "Test set: Average loss: 2.2106, Accuracy: 3439/5000 (69%)\n",
      "[epoch 43] loss: 0.0000585\n",
      "Test set: Average loss: 2.2869, Accuracy: 3433/5000 (69%)\n",
      "[epoch 44] loss: 0.0000348\n",
      "Test set: Average loss: 2.3578, Accuracy: 3453/5000 (69%)\n",
      "[epoch 45] loss: 0.0002280\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.4161, Accuracy: 3414/5000 (68%)\n",
      "[epoch 46] loss: 0.0001592\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.4044, Accuracy: 3415/5000 (68%)\n",
      "[epoch 47] loss: 0.0000826\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.4045, Accuracy: 3418/5000 (68%)\n",
      "[epoch 48] loss: 0.0000798\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.4046, Accuracy: 3418/5000 (68%)\n",
      "[epoch 49] loss: 0.0000794\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.4046, Accuracy: 3418/5000 (68%)\n",
      "[epoch 50] loss: 0.0000794\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.4046, Accuracy: 3418/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3578, Accuracy: 3453/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.3404, Accuracy: 6989/10000 (70%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3044, Accuracy: 509/5000 (10%)\n",
      "[epoch 1] loss: 1.1876795\n",
      "Test set: Average loss: 1.1165, Accuracy: 3022/5000 (60%)\n",
      "[epoch 2] loss: 1.0864797\n",
      "Test set: Average loss: 1.1224, Accuracy: 3046/5000 (61%)\n",
      "[epoch 3] loss: 1.0412298\n",
      "Test set: Average loss: 1.1537, Accuracy: 2958/5000 (59%)\n",
      "[epoch 4] loss: 1.0031236\n",
      "Test set: Average loss: 1.1081, Accuracy: 3069/5000 (61%)\n",
      "[epoch 5] loss: 0.9606467\n",
      "Test set: Average loss: 1.0508, Accuracy: 3184/5000 (64%)\n",
      "[epoch 6] loss: 0.9238171\n",
      "Test set: Average loss: 0.9833, Accuracy: 3258/5000 (65%)\n",
      "[epoch 7] loss: 0.8873572\n",
      "Test set: Average loss: 1.0258, Accuracy: 3221/5000 (64%)\n",
      "[epoch 8] loss: 0.8434389\n",
      "Test set: Average loss: 1.0248, Accuracy: 3212/5000 (64%)\n",
      "[epoch 9] loss: 0.8070366\n",
      "Test set: Average loss: 0.9637, Accuracy: 3343/5000 (67%)\n",
      "[epoch 10] loss: 0.7544341\n",
      "Test set: Average loss: 0.9729, Accuracy: 3338/5000 (67%)\n",
      "[epoch 11] loss: 0.7063042\n",
      "Test set: Average loss: 0.9977, Accuracy: 3352/5000 (67%)\n",
      "[epoch 12] loss: 0.6476885\n",
      "Test set: Average loss: 0.9650, Accuracy: 3396/5000 (68%)\n",
      "[epoch 13] loss: 0.5873120\n",
      "Test set: Average loss: 1.0178, Accuracy: 3392/5000 (68%)\n",
      "[epoch 14] loss: 0.5250928\n",
      "Test set: Average loss: 1.1354, Accuracy: 3282/5000 (66%)\n",
      "[epoch 15] loss: 0.4567894\n",
      "Test set: Average loss: 1.1091, Accuracy: 3317/5000 (66%)\n",
      "[epoch 16] loss: 0.3862013\n",
      "Test set: Average loss: 1.1944, Accuracy: 3306/5000 (66%)\n",
      "[epoch 17] loss: 0.3355536\n",
      "Test set: Average loss: 1.1826, Accuracy: 3366/5000 (67%)\n",
      "[epoch 18] loss: 0.2851931\n",
      "Test set: Average loss: 1.3055, Accuracy: 3367/5000 (67%)\n",
      "[epoch 19] loss: 0.2555791\n",
      "Test set: Average loss: 1.3070, Accuracy: 3376/5000 (68%)\n",
      "[epoch 20] loss: 0.2209167\n",
      "Test set: Average loss: 1.3898, Accuracy: 3389/5000 (68%)\n",
      "[epoch 21] loss: 0.2101346\n",
      "Test set: Average loss: 1.4569, Accuracy: 3382/5000 (68%)\n",
      "[epoch 22] loss: 0.1807443\n",
      "Test set: Average loss: 1.4836, Accuracy: 3351/5000 (67%)\n",
      "[epoch 23] loss: 0.1879947\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5784, Accuracy: 3365/5000 (67%)\n",
      "[epoch 24] loss: 0.0679157\n",
      "Test set: Average loss: 1.4547, Accuracy: 3427/5000 (69%)\n",
      "[epoch 25] loss: 0.0248048\n",
      "Test set: Average loss: 1.4690, Accuracy: 3457/5000 (69%)\n",
      "[epoch 26] loss: 0.0143165\n",
      "Test set: Average loss: 1.4968, Accuracy: 3454/5000 (69%)\n",
      "[epoch 27] loss: 0.0091514\n",
      "Test set: Average loss: 1.5265, Accuracy: 3448/5000 (69%)\n",
      "[epoch 28] loss: 0.0059655\n",
      "Test set: Average loss: 1.5615, Accuracy: 3454/5000 (69%)\n",
      "[epoch 29] loss: 0.0038976\n",
      "Test set: Average loss: 1.6060, Accuracy: 3462/5000 (69%)\n",
      "[epoch 30] loss: 0.0025113\n",
      "Test set: Average loss: 1.6594, Accuracy: 3466/5000 (69%)\n",
      "[epoch 31] loss: 0.0015969\n",
      "Test set: Average loss: 1.7053, Accuracy: 3466/5000 (69%)\n",
      "[epoch 32] loss: 0.0010093\n",
      "Test set: Average loss: 1.7613, Accuracy: 3467/5000 (69%)\n",
      "[epoch 33] loss: 0.0006317\n",
      "Test set: Average loss: 1.8215, Accuracy: 3485/5000 (70%)\n",
      "[epoch 34] loss: 0.0003889\n",
      "Test set: Average loss: 1.8830, Accuracy: 3473/5000 (69%)\n",
      "[epoch 35] loss: 0.0002393\n",
      "Test set: Average loss: 1.9531, Accuracy: 3490/5000 (70%)\n",
      "[epoch 36] loss: 0.0001458\n",
      "Test set: Average loss: 2.0184, Accuracy: 3472/5000 (69%)\n",
      "[epoch 37] loss: 0.0000889\n",
      "Test set: Average loss: 2.0901, Accuracy: 3475/5000 (70%)\n",
      "[epoch 38] loss: 0.0000529\n",
      "Test set: Average loss: 2.1621, Accuracy: 3460/5000 (69%)\n",
      "[epoch 39] loss: 0.0000318\n",
      "Test set: Average loss: 2.2304, Accuracy: 3493/5000 (70%)\n",
      "[epoch 40] loss: 0.0000187\n",
      "Test set: Average loss: 2.3032, Accuracy: 3489/5000 (70%)\n",
      "[epoch 41] loss: 0.0000111\n",
      "Test set: Average loss: 2.3816, Accuracy: 3484/5000 (70%)\n",
      "[epoch 42] loss: 0.0000065\n",
      "Test set: Average loss: 2.4589, Accuracy: 3491/5000 (70%)\n",
      "[epoch 43] loss: 0.0000038\n",
      "Test set: Average loss: 2.5356, Accuracy: 3487/5000 (70%)\n",
      "[epoch 44] loss: 0.0000022\n",
      "Test set: Average loss: 2.6105, Accuracy: 3494/5000 (70%)\n",
      "[epoch 45] loss: 0.0000012\n",
      "Test set: Average loss: 2.6684, Accuracy: 3491/5000 (70%)\n",
      "[epoch 46] loss: 0.0000007\n",
      "Test set: Average loss: 2.7248, Accuracy: 3487/5000 (70%)\n",
      "[epoch 47] loss: 0.0000004\n",
      "Test set: Average loss: 2.7561, Accuracy: 3481/5000 (70%)\n",
      "[epoch 48] loss: 0.0000003\n",
      "Test set: Average loss: 2.7755, Accuracy: 3494/5000 (70%)\n",
      "[epoch 49] loss: 0.0000002\n",
      "Test set: Average loss: 2.7953, Accuracy: 3475/5000 (70%)\n",
      "[epoch 50] loss: 0.0016637\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.8548, Accuracy: 3476/5000 (70%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7755, Accuracy: 3494/5000 (70%)\n",
      "Test\n",
      "Test set: Average loss: 2.8901, Accuracy: 6908/10000 (69%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.2990, Accuracy: 625/5000 (12%)\n",
      "[epoch 1] loss: 1.1997830\n",
      "Test set: Average loss: 1.2136, Accuracy: 2849/5000 (57%)\n",
      "[epoch 2] loss: 1.0963409\n",
      "Test set: Average loss: 1.0761, Accuracy: 3113/5000 (62%)\n",
      "[epoch 3] loss: 1.0462990\n",
      "Test set: Average loss: 1.1501, Accuracy: 2978/5000 (60%)\n",
      "[epoch 4] loss: 1.0089930\n",
      "Test set: Average loss: 1.0446, Accuracy: 3202/5000 (64%)\n",
      "[epoch 5] loss: 0.9617132\n",
      "Test set: Average loss: 1.0401, Accuracy: 3207/5000 (64%)\n",
      "[epoch 6] loss: 0.9266410\n",
      "Test set: Average loss: 1.0497, Accuracy: 3149/5000 (63%)\n",
      "[epoch 7] loss: 0.8843064\n",
      "Test set: Average loss: 1.0473, Accuracy: 3213/5000 (64%)\n",
      "[epoch 8] loss: 0.8552520\n",
      "Test set: Average loss: 1.0239, Accuracy: 3220/5000 (64%)\n",
      "[epoch 9] loss: 0.8128253\n",
      "Test set: Average loss: 0.9793, Accuracy: 3320/5000 (66%)\n",
      "[epoch 10] loss: 0.7616471\n",
      "Test set: Average loss: 1.0114, Accuracy: 3244/5000 (65%)\n",
      "[epoch 11] loss: 0.7160303\n",
      "Test set: Average loss: 1.0459, Accuracy: 3283/5000 (66%)\n",
      "[epoch 12] loss: 0.6615282\n",
      "Test set: Average loss: 1.0073, Accuracy: 3318/5000 (66%)\n",
      "[epoch 13] loss: 0.5981625\n",
      "Test set: Average loss: 1.0494, Accuracy: 3324/5000 (66%)\n",
      "[epoch 14] loss: 0.5346036\n",
      "Test set: Average loss: 1.0593, Accuracy: 3339/5000 (67%)\n",
      "[epoch 15] loss: 0.4678473\n",
      "Test set: Average loss: 1.0803, Accuracy: 3385/5000 (68%)\n",
      "[epoch 16] loss: 0.4007556\n",
      "Test set: Average loss: 1.1650, Accuracy: 3318/5000 (66%)\n",
      "[epoch 17] loss: 0.3435521\n",
      "Test set: Average loss: 1.1966, Accuracy: 3319/5000 (66%)\n",
      "[epoch 18] loss: 0.2953624\n",
      "Test set: Average loss: 1.2728, Accuracy: 3369/5000 (67%)\n",
      "[epoch 19] loss: 0.2543163\n",
      "Test set: Average loss: 1.3793, Accuracy: 3278/5000 (66%)\n",
      "[epoch 20] loss: 0.2228241\n",
      "Test set: Average loss: 1.4331, Accuracy: 3310/5000 (66%)\n",
      "[epoch 21] loss: 0.2204537\n",
      "Test set: Average loss: 1.5359, Accuracy: 3326/5000 (67%)\n",
      "[epoch 22] loss: 0.1920167\n",
      "Test set: Average loss: 1.5859, Accuracy: 3285/5000 (66%)\n",
      "[epoch 23] loss: 0.1993693\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6477, Accuracy: 3261/5000 (65%)\n",
      "[epoch 24] loss: 0.0754527\n",
      "Test set: Average loss: 1.5284, Accuracy: 3391/5000 (68%)\n",
      "[epoch 25] loss: 0.0295666\n",
      "Test set: Average loss: 1.5381, Accuracy: 3415/5000 (68%)\n",
      "[epoch 26] loss: 0.0170049\n",
      "Test set: Average loss: 1.5631, Accuracy: 3404/5000 (68%)\n",
      "[epoch 27] loss: 0.0108247\n",
      "Test set: Average loss: 1.5953, Accuracy: 3416/5000 (68%)\n",
      "[epoch 28] loss: 0.0070434\n",
      "Test set: Average loss: 1.6416, Accuracy: 3427/5000 (69%)\n",
      "[epoch 29] loss: 0.0045949\n",
      "Test set: Average loss: 1.6820, Accuracy: 3418/5000 (68%)\n",
      "[epoch 30] loss: 0.0029805\n",
      "Test set: Average loss: 1.7404, Accuracy: 3419/5000 (68%)\n",
      "[epoch 31] loss: 0.0019030\n",
      "Test set: Average loss: 1.7936, Accuracy: 3432/5000 (69%)\n",
      "[epoch 32] loss: 0.0012100\n",
      "Test set: Average loss: 1.8554, Accuracy: 3418/5000 (68%)\n",
      "[epoch 33] loss: 0.0009933\n",
      "Test set: Average loss: 1.9087, Accuracy: 3430/5000 (69%)\n",
      "[epoch 34] loss: 0.0005257\n",
      "Test set: Average loss: 1.9558, Accuracy: 3416/5000 (68%)\n",
      "[epoch 35] loss: 0.0003601\n",
      "Test set: Average loss: 2.0248, Accuracy: 3423/5000 (68%)\n",
      "[epoch 36] loss: 0.0002359\n",
      "Test set: Average loss: 2.0880, Accuracy: 3418/5000 (68%)\n",
      "[epoch 37] loss: 0.0001478\n",
      "Test set: Average loss: 2.1632, Accuracy: 3410/5000 (68%)\n",
      "[epoch 38] loss: 0.0000905\n",
      "Test set: Average loss: 2.2533, Accuracy: 3407/5000 (68%)\n",
      "[epoch 39] loss: 0.0000551\n",
      "Test set: Average loss: 2.3277, Accuracy: 3417/5000 (68%)\n",
      "[epoch 40] loss: 0.0000327\n",
      "Test set: Average loss: 2.4004, Accuracy: 3409/5000 (68%)\n",
      "[epoch 41] loss: 0.0000195\n",
      "Test set: Average loss: 2.4900, Accuracy: 3418/5000 (68%)\n",
      "[epoch 42] loss: 0.0000115\n",
      "Test set: Average loss: 2.5698, Accuracy: 3410/5000 (68%)\n",
      "[epoch 43] loss: 0.0000067\n",
      "Test set: Average loss: 2.6564, Accuracy: 3413/5000 (68%)\n",
      "[epoch 44] loss: 0.0000039\n",
      "Test set: Average loss: 2.7366, Accuracy: 3418/5000 (68%)\n",
      "[epoch 45] loss: 0.0000023\n",
      "Test set: Average loss: 2.8159, Accuracy: 3408/5000 (68%)\n",
      "[epoch 46] loss: 0.0000013\n",
      "Test set: Average loss: 2.9041, Accuracy: 3405/5000 (68%)\n",
      "[epoch 47] loss: 0.0000008\n",
      "Test set: Average loss: 2.9591, Accuracy: 3413/5000 (68%)\n",
      "[epoch 48] loss: 0.0000004\n",
      "Test set: Average loss: 2.9919, Accuracy: 3401/5000 (68%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 3.0151, Accuracy: 3417/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 3.0897, Accuracy: 3396/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7936, Accuracy: 3432/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 1.6871, Accuracy: 7003/10000 (70%)\n"
     ]
    }
   ],
   "source": [
    "# train the SimEc\n",
    "w = 0.7\n",
    "S = w*S_lin + (1.-w)*S_class\n",
    "S_ll = S[:n_targets, :]\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = SimilarityEncoder(cnn, 512, n_targets)\n",
    "model.fit(X, S, epochs=50, lr=0.0001, s_ll_reg=100., S_ll=S_ll, orth_reg=0.1)\n",
    "print(check_similarity_match(model.predict(X[:n_targets]), S_ll, X_embed_is_S_approx=True))\n",
    "print(check_similarity_match(model.transform(X[:n_targets]), S_ll))\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.model.embedding_net.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_se_t1_mix7 = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_se_t1_mix7.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T02:54:43.685831Z",
     "start_time": "2019-07-24T23:59:53.598300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.0051339\n",
      "[epoch 2] loss: 0.0010615\n",
      "[epoch 3] loss: 0.0008651\n",
      "[epoch 4] loss: 0.0008000\n",
      "[epoch 5] loss: 0.0007678\n",
      "[epoch 6] loss: 0.0007464\n",
      "[epoch 7] loss: 0.0007293\n",
      "[epoch 8] loss: 0.0007158\n",
      "[epoch 9] loss: 0.0007043\n",
      "[epoch 10] loss: 0.0006969\n",
      "[epoch 11] loss: 0.0006883\n",
      "[epoch 12] loss: 0.0006821\n",
      "[epoch 13] loss: 0.0006780\n",
      "[epoch 14] loss: 0.0006729\n",
      "[epoch 15] loss: 0.0006696\n",
      "[epoch 16] loss: 0.0006660\n",
      "[epoch 17] loss: 0.0006627\n",
      "[epoch 18] loss: 0.0006600\n",
      "[epoch 19] loss: 0.0006630\n",
      "[epoch 20] loss: 0.0006784\n",
      "[epoch 21] loss: 0.0006643\n",
      "[epoch 22] loss: 0.0006557\n",
      "[epoch 23] loss: 0.0006508\n",
      "[epoch 24] loss: 0.0006478\n",
      "[epoch 25] loss: 0.0006458\n",
      "[epoch 26] loss: 0.0006426\n",
      "[epoch 27] loss: 0.0006402\n",
      "[epoch 28] loss: 0.0006380\n",
      "[epoch 29] loss: 0.0006358\n",
      "[epoch 30] loss: 0.0006338\n",
      "[epoch 31] loss: 0.0006326\n",
      "[epoch 32] loss: 0.0006311\n",
      "[epoch 33] loss: 0.0006293\n",
      "[epoch 34] loss: 0.0006284\n",
      "[epoch 35] loss: 0.0006270\n",
      "[epoch 36] loss: 0.0006256\n",
      "[epoch 37] loss: 0.0006240\n",
      "[epoch 38] loss: 0.0006231\n",
      "[epoch 39] loss: 0.0006222\n",
      "[epoch 40] loss: 0.0006208\n",
      "[epoch 41] loss: 0.0006196\n",
      "[epoch 42] loss: 0.0006183\n",
      "[epoch 43] loss: 0.0006178\n",
      "[epoch 44] loss: 0.0006166\n",
      "[epoch 45] loss: 0.0006150\n",
      "[epoch 46] loss: 0.0006149\n",
      "[epoch 47] loss: 0.0006140\n",
      "[epoch 48] loss: 0.0006135\n",
      "[epoch 49] loss: 0.0006125\n",
      "[epoch 50] loss: 0.0006118\n",
      "(0.0006189959098772349, 0.7842459973103791, 0.8928166768211571)\n",
      "(0.0008453307970694191, 0.7146901600172628, 0.8672812251909221)\n",
      "Took 902 sec to train.\n",
      "25\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3013, Accuracy: 606/5000 (12%)\n",
      "[epoch 1] loss: 2.2936306\n",
      "Test set: Average loss: 2.2883, Accuracy: 653/5000 (13%)\n",
      "[epoch 2] loss: 2.2008123\n",
      "Test set: Average loss: 2.2760, Accuracy: 640/5000 (13%)\n",
      "[epoch 3] loss: 2.0630934\n",
      "Test set: Average loss: 2.2896, Accuracy: 665/5000 (13%)\n",
      "[epoch 4] loss: 1.8796146\n",
      "Test set: Average loss: 2.4004, Accuracy: 714/5000 (14%)\n",
      "[epoch 5] loss: 1.7051613\n",
      "Test set: Average loss: 2.4943, Accuracy: 805/5000 (16%)\n",
      "[epoch 6] loss: 1.5259613\n",
      "Test set: Average loss: 2.5109, Accuracy: 840/5000 (17%)\n",
      "[epoch 7] loss: 1.3266602\n",
      "Test set: Average loss: 2.5628, Accuracy: 903/5000 (18%)\n",
      "[epoch 8] loss: 1.1667310\n",
      "Test set: Average loss: 2.5872, Accuracy: 988/5000 (20%)\n",
      "[epoch 9] loss: 0.9749284\n",
      "Test set: Average loss: 2.6429, Accuracy: 1022/5000 (20%)\n",
      "[epoch 10] loss: 0.7939031\n",
      "Test set: Average loss: 2.7707, Accuracy: 1015/5000 (20%)\n",
      "[epoch 11] loss: 0.6506159\n",
      "Test set: Average loss: 2.9329, Accuracy: 963/5000 (19%)\n",
      "[epoch 12] loss: 0.5198894\n",
      "Test set: Average loss: 3.1398, Accuracy: 908/5000 (18%)\n",
      "[epoch 13] loss: 0.4043823\n",
      "Test set: Average loss: 3.4200, Accuracy: 897/5000 (18%)\n",
      "[epoch 14] loss: 0.3129726\n",
      "Test set: Average loss: 3.7558, Accuracy: 878/5000 (18%)\n",
      "[epoch 15] loss: 0.2331139\n",
      "Test set: Average loss: 4.1102, Accuracy: 859/5000 (17%)\n",
      "[epoch 16] loss: 0.1703190\n",
      "Test set: Average loss: 4.4251, Accuracy: 888/5000 (18%)\n",
      "[epoch 17] loss: 0.1250481\n",
      "Test set: Average loss: 4.6639, Accuracy: 890/5000 (18%)\n",
      "[epoch 18] loss: 0.0858847\n",
      "Test set: Average loss: 4.8855, Accuracy: 886/5000 (18%)\n",
      "[epoch 19] loss: 0.0588660\n",
      "Test set: Average loss: 5.1448, Accuracy: 894/5000 (18%)\n",
      "[epoch 20] loss: 0.0419968\n",
      "Test set: Average loss: 5.4430, Accuracy: 894/5000 (18%)\n",
      "[epoch 21] loss: 0.0290740\n",
      "Test set: Average loss: 5.7662, Accuracy: 874/5000 (17%)\n",
      "[epoch 22] loss: 0.0192644\n",
      "Test set: Average loss: 6.1012, Accuracy: 862/5000 (17%)\n",
      "[epoch 23] loss: 0.0127550\n",
      "Test set: Average loss: 6.4341, Accuracy: 858/5000 (17%)\n",
      "[epoch 24] loss: 0.0088304\n",
      "Test set: Average loss: 6.7513, Accuracy: 865/5000 (17%)\n",
      "[epoch 25] loss: 0.0065278\n",
      "Test set: Average loss: 7.0421, Accuracy: 861/5000 (17%)\n",
      "[epoch 26] loss: 0.0051417\n",
      "Test set: Average loss: 7.2996, Accuracy: 856/5000 (17%)\n",
      "[epoch 27] loss: 0.0041958\n",
      "Test set: Average loss: 7.5213, Accuracy: 854/5000 (17%)\n",
      "[epoch 28] loss: 0.0034251\n",
      "Test set: Average loss: 7.7088, Accuracy: 851/5000 (17%)\n",
      "[epoch 29] loss: 0.0027435\n",
      "Test set: Average loss: 7.8661, Accuracy: 850/5000 (17%)\n",
      "[epoch 30] loss: 0.0021634\n",
      "Test set: Average loss: 7.9985, Accuracy: 847/5000 (17%)\n",
      "[epoch 31] loss: 0.0017097\n",
      "Test set: Average loss: 8.1108, Accuracy: 842/5000 (17%)\n",
      "[epoch 32] loss: 0.0013817\n",
      "Test set: Average loss: 8.2068, Accuracy: 842/5000 (17%)\n",
      "[epoch 33] loss: 0.0011538\n",
      "Test set: Average loss: 8.2896, Accuracy: 842/5000 (17%)\n",
      "[epoch 34] loss: 0.0009952\n",
      "Test set: Average loss: 8.3616, Accuracy: 845/5000 (17%)\n",
      "[epoch 35] loss: 0.0008788\n",
      "Test set: Average loss: 8.4247, Accuracy: 844/5000 (17%)\n",
      "[epoch 36] loss: 0.0007852\n",
      "Test set: Average loss: 8.4802, Accuracy: 841/5000 (17%)\n",
      "[epoch 37] loss: 0.0007029\n",
      "Test set: Average loss: 8.5296, Accuracy: 832/5000 (17%)\n",
      "[epoch 38] loss: 0.0006270\n",
      "Test set: Average loss: 8.5738, Accuracy: 833/5000 (17%)\n",
      "[epoch 39] loss: 0.0005569\n",
      "Test set: Average loss: 8.6137, Accuracy: 833/5000 (17%)\n",
      "[epoch 40] loss: 0.0004942\n",
      "Test set: Average loss: 8.6500, Accuracy: 833/5000 (17%)\n",
      "[epoch 41] loss: 0.0004396\n",
      "Test set: Average loss: 8.6833, Accuracy: 838/5000 (17%)\n",
      "[epoch 42] loss: 0.0003936\n",
      "Test set: Average loss: 8.7139, Accuracy: 833/5000 (17%)\n",
      "[epoch 43] loss: 0.0003556\n",
      "Test set: Average loss: 8.7423, Accuracy: 833/5000 (17%)\n",
      "[epoch 44] loss: 0.0003245\n",
      "Test set: Average loss: 8.7685, Accuracy: 832/5000 (17%)\n",
      "[epoch 45] loss: 0.0002991\n",
      "Test set: Average loss: 8.7928, Accuracy: 832/5000 (17%)\n",
      "[epoch 46] loss: 0.0002781\n",
      "Test set: Average loss: 8.8153, Accuracy: 835/5000 (17%)\n",
      "[epoch 47] loss: 0.0002608\n",
      "Test set: Average loss: 8.8362, Accuracy: 836/5000 (17%)\n",
      "[epoch 48] loss: 0.0002463\n",
      "Test set: Average loss: 8.8554, Accuracy: 836/5000 (17%)\n",
      "[epoch 49] loss: 0.0002337\n",
      "Test set: Average loss: 8.8732, Accuracy: 839/5000 (17%)\n",
      "[epoch 50] loss: 0.0002228\n",
      "Test set: Average loss: 8.8897, Accuracy: 836/5000 (17%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6429, Accuracy: 1022/5000 (20%)\n",
      "Test\n",
      "Test set: Average loss: 2.5851, Accuracy: 2172/10000 (22%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 540/5000 (11%)\n",
      "[epoch 1] loss: 2.3056016\n",
      "Test set: Average loss: 2.2886, Accuracy: 790/5000 (16%)\n",
      "[epoch 2] loss: 2.2146564\n",
      "Test set: Average loss: 2.2768, Accuracy: 822/5000 (16%)\n",
      "[epoch 3] loss: 2.0853410\n",
      "Test set: Average loss: 2.2878, Accuracy: 802/5000 (16%)\n",
      "[epoch 4] loss: 1.9103061\n",
      "Test set: Average loss: 2.3710, Accuracy: 809/5000 (16%)\n",
      "[epoch 5] loss: 1.7238754\n",
      "Test set: Average loss: 2.5091, Accuracy: 890/5000 (18%)\n",
      "[epoch 6] loss: 1.5551333\n",
      "Test set: Average loss: 2.5805, Accuracy: 1067/5000 (21%)\n",
      "[epoch 7] loss: 1.3695239\n",
      "Test set: Average loss: 2.6185, Accuracy: 1116/5000 (22%)\n",
      "[epoch 8] loss: 1.1818241\n",
      "Test set: Average loss: 2.6421, Accuracy: 1095/5000 (22%)\n",
      "[epoch 9] loss: 0.9790639\n",
      "Test set: Average loss: 2.6730, Accuracy: 1104/5000 (22%)\n",
      "[epoch 10] loss: 0.7793451\n",
      "Test set: Average loss: 2.7142, Accuracy: 1147/5000 (23%)\n",
      "[epoch 11] loss: 0.6037180\n",
      "Test set: Average loss: 2.7759, Accuracy: 1168/5000 (23%)\n",
      "[epoch 12] loss: 0.4604925\n",
      "Test set: Average loss: 2.9093, Accuracy: 1146/5000 (23%)\n",
      "[epoch 13] loss: 0.3496554\n",
      "Test set: Average loss: 3.1188, Accuracy: 1117/5000 (22%)\n",
      "[epoch 14] loss: 0.2609632\n",
      "Test set: Average loss: 3.3716, Accuracy: 1092/5000 (22%)\n",
      "[epoch 15] loss: 0.1911413\n",
      "Test set: Average loss: 3.6484, Accuracy: 1056/5000 (21%)\n",
      "[epoch 16] loss: 0.1402095\n",
      "Test set: Average loss: 3.9412, Accuracy: 1042/5000 (21%)\n",
      "[epoch 17] loss: 0.1056351\n",
      "Test set: Average loss: 4.2319, Accuracy: 1010/5000 (20%)\n",
      "[epoch 18] loss: 0.0804411\n",
      "Test set: Average loss: 4.5040, Accuracy: 988/5000 (20%)\n",
      "[epoch 19] loss: 0.0598678\n",
      "Test set: Average loss: 4.7542, Accuracy: 977/5000 (20%)\n",
      "[epoch 20] loss: 0.0426783\n",
      "Test set: Average loss: 4.9873, Accuracy: 968/5000 (19%)\n",
      "[epoch 21] loss: 0.0291231\n",
      "Test set: Average loss: 5.2070, Accuracy: 961/5000 (19%)\n",
      "[epoch 22] loss: 0.0193520\n",
      "Test set: Average loss: 5.4132, Accuracy: 941/5000 (19%)\n",
      "[epoch 23] loss: 0.0127569\n",
      "Test set: Average loss: 5.6039, Accuracy: 922/5000 (18%)\n",
      "[epoch 24] loss: 0.0084632\n",
      "Test set: Average loss: 5.7777, Accuracy: 914/5000 (18%)\n",
      "[epoch 25] loss: 0.0057205\n",
      "Test set: Average loss: 5.9351, Accuracy: 920/5000 (18%)\n",
      "[epoch 26] loss: 0.0039791\n",
      "Test set: Average loss: 6.0772, Accuracy: 913/5000 (18%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27] loss: 0.0028593\n",
      "Test set: Average loss: 6.2058, Accuracy: 914/5000 (18%)\n",
      "[epoch 28] loss: 0.0021226\n",
      "Test set: Average loss: 6.3223, Accuracy: 915/5000 (18%)\n",
      "[epoch 29] loss: 0.0016249\n",
      "Test set: Average loss: 6.4281, Accuracy: 911/5000 (18%)\n",
      "[epoch 30] loss: 0.0012783\n",
      "Test set: Average loss: 6.5244, Accuracy: 908/5000 (18%)\n",
      "[epoch 31] loss: 0.0010311\n",
      "Test set: Average loss: 6.6120, Accuracy: 909/5000 (18%)\n",
      "[epoch 32] loss: 0.0008503\n",
      "Test set: Average loss: 6.6920, Accuracy: 905/5000 (18%)\n",
      "[epoch 33] loss: 0.0007159\n",
      "Test set: Average loss: 6.7649, Accuracy: 906/5000 (18%)\n",
      "[epoch 34] loss: 0.0006143\n",
      "Test set: Average loss: 6.8314, Accuracy: 898/5000 (18%)\n",
      "[epoch 35] loss: 0.0005363\n",
      "Test set: Average loss: 6.8922, Accuracy: 897/5000 (18%)\n",
      "[epoch 36] loss: 0.0004755\n",
      "Test set: Average loss: 6.9477, Accuracy: 895/5000 (18%)\n",
      "[epoch 37] loss: 0.0004274\n",
      "Test set: Average loss: 6.9984, Accuracy: 889/5000 (18%)\n",
      "[epoch 38] loss: 0.0003888\n",
      "Test set: Average loss: 7.0447, Accuracy: 894/5000 (18%)\n",
      "[epoch 39] loss: 0.0003573\n",
      "Test set: Average loss: 7.0870, Accuracy: 895/5000 (18%)\n",
      "[epoch 40] loss: 0.0003313\n",
      "Test set: Average loss: 7.1257, Accuracy: 891/5000 (18%)\n",
      "[epoch 41] loss: 0.0003096\n",
      "Test set: Average loss: 7.1610, Accuracy: 885/5000 (18%)\n",
      "[epoch 42] loss: 0.0002914\n",
      "Test set: Average loss: 7.1932, Accuracy: 886/5000 (18%)\n",
      "[epoch 43] loss: 0.0002757\n",
      "Test set: Average loss: 7.2227, Accuracy: 883/5000 (18%)\n",
      "[epoch 44] loss: 0.0002622\n",
      "Test set: Average loss: 7.2497, Accuracy: 882/5000 (18%)\n",
      "[epoch 45] loss: 0.0002504\n",
      "Test set: Average loss: 7.2744, Accuracy: 883/5000 (18%)\n",
      "[epoch 46] loss: 0.0002400\n",
      "Test set: Average loss: 7.2970, Accuracy: 881/5000 (18%)\n",
      "[epoch 47] loss: 0.0002306\n",
      "Test set: Average loss: 7.3176, Accuracy: 881/5000 (18%)\n",
      "[epoch 48] loss: 0.0002222\n",
      "Test set: Average loss: 7.3366, Accuracy: 878/5000 (18%)\n",
      "[epoch 49] loss: 0.0002146\n",
      "Test set: Average loss: 7.3540, Accuracy: 880/5000 (18%)\n",
      "[epoch 50] loss: 0.0002076\n",
      "Test set: Average loss: 7.3699, Accuracy: 881/5000 (18%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7759, Accuracy: 1168/5000 (23%)\n",
      "Test\n",
      "Test set: Average loss: 2.7719, Accuracy: 2324/10000 (23%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3029, Accuracy: 389/5000 (8%)\n",
      "[epoch 1] loss: 2.2925804\n",
      "Test set: Average loss: 2.2920, Accuracy: 534/5000 (11%)\n",
      "[epoch 2] loss: 2.2018239\n",
      "Test set: Average loss: 2.2872, Accuracy: 581/5000 (12%)\n",
      "[epoch 3] loss: 2.0762708\n",
      "Test set: Average loss: 2.3183, Accuracy: 561/5000 (11%)\n",
      "[epoch 4] loss: 1.9033426\n",
      "Test set: Average loss: 2.4895, Accuracy: 547/5000 (11%)\n",
      "[epoch 5] loss: 1.7487940\n",
      "Test set: Average loss: 2.7197, Accuracy: 602/5000 (12%)\n",
      "[epoch 6] loss: 1.6509892\n",
      "Test set: Average loss: 2.7118, Accuracy: 757/5000 (15%)\n",
      "[epoch 7] loss: 1.4784241\n",
      "Test set: Average loss: 2.6022, Accuracy: 835/5000 (17%)\n",
      "[epoch 8] loss: 1.2784567\n",
      "Test set: Average loss: 2.4901, Accuracy: 845/5000 (17%)\n",
      "[epoch 9] loss: 1.0697303\n",
      "Test set: Average loss: 2.4586, Accuracy: 859/5000 (17%)\n",
      "[epoch 10] loss: 0.8853765\n",
      "Test set: Average loss: 2.5249, Accuracy: 883/5000 (18%)\n",
      "[epoch 11] loss: 0.7242283\n",
      "Test set: Average loss: 2.6774, Accuracy: 887/5000 (18%)\n",
      "[epoch 12] loss: 0.5729772\n",
      "Test set: Average loss: 2.9170, Accuracy: 879/5000 (18%)\n",
      "[epoch 13] loss: 0.4330633\n",
      "Test set: Average loss: 3.2265, Accuracy: 853/5000 (17%)\n",
      "[epoch 14] loss: 0.3061463\n",
      "Test set: Average loss: 3.5995, Accuracy: 841/5000 (17%)\n",
      "[epoch 15] loss: 0.2125578\n",
      "Test set: Average loss: 3.9902, Accuracy: 860/5000 (17%)\n",
      "[epoch 16] loss: 0.1499313\n",
      "Test set: Average loss: 4.3416, Accuracy: 875/5000 (18%)\n",
      "[epoch 17] loss: 0.0985860\n",
      "Test set: Average loss: 4.6547, Accuracy: 866/5000 (17%)\n",
      "[epoch 18] loss: 0.0607858\n",
      "Test set: Average loss: 4.9514, Accuracy: 874/5000 (17%)\n",
      "[epoch 19] loss: 0.0393023\n",
      "Test set: Average loss: 5.2338, Accuracy: 871/5000 (17%)\n",
      "[epoch 20] loss: 0.0269015\n",
      "Test set: Average loss: 5.4964, Accuracy: 869/5000 (17%)\n",
      "[epoch 21] loss: 0.0186394\n",
      "Test set: Average loss: 5.7370, Accuracy: 874/5000 (17%)\n",
      "[epoch 22] loss: 0.0127989\n",
      "Test set: Average loss: 5.9573, Accuracy: 871/5000 (17%)\n",
      "[epoch 23] loss: 0.0087170\n",
      "Test set: Average loss: 6.1599, Accuracy: 858/5000 (17%)\n",
      "[epoch 24] loss: 0.0059472\n",
      "Test set: Average loss: 6.3465, Accuracy: 854/5000 (17%)\n",
      "[epoch 25] loss: 0.0041020\n",
      "Test set: Average loss: 6.5183, Accuracy: 847/5000 (17%)\n",
      "[epoch 26] loss: 0.0028871\n",
      "Test set: Average loss: 6.6764, Accuracy: 837/5000 (17%)\n",
      "[epoch 27] loss: 0.0020916\n",
      "Test set: Average loss: 6.8216, Accuracy: 828/5000 (17%)\n",
      "[epoch 28] loss: 0.0015685\n",
      "Test set: Average loss: 6.9548, Accuracy: 830/5000 (17%)\n",
      "[epoch 29] loss: 0.0012175\n",
      "Test set: Average loss: 7.0769, Accuracy: 826/5000 (17%)\n",
      "[epoch 30] loss: 0.0009771\n",
      "Test set: Average loss: 7.1886, Accuracy: 825/5000 (16%)\n",
      "[epoch 31] loss: 0.0008075\n",
      "Test set: Average loss: 7.2907, Accuracy: 826/5000 (17%)\n",
      "[epoch 32] loss: 0.0006838\n",
      "Test set: Average loss: 7.3839, Accuracy: 823/5000 (16%)\n",
      "[epoch 33] loss: 0.0005909\n",
      "Test set: Average loss: 7.4688, Accuracy: 820/5000 (16%)\n",
      "[epoch 34] loss: 0.0005193\n",
      "Test set: Average loss: 7.5460, Accuracy: 822/5000 (16%)\n",
      "[epoch 35] loss: 0.0004624\n",
      "Test set: Average loss: 7.6161, Accuracy: 819/5000 (16%)\n",
      "[epoch 36] loss: 0.0004166\n",
      "Test set: Average loss: 7.6796, Accuracy: 816/5000 (16%)\n",
      "[epoch 37] loss: 0.0003787\n",
      "Test set: Average loss: 7.7372, Accuracy: 810/5000 (16%)\n",
      "[epoch 38] loss: 0.0003470\n",
      "Test set: Average loss: 7.7891, Accuracy: 810/5000 (16%)\n",
      "[epoch 39] loss: 0.0003202\n",
      "Test set: Average loss: 7.8361, Accuracy: 806/5000 (16%)\n",
      "[epoch 40] loss: 0.0002973\n",
      "Test set: Average loss: 7.8784, Accuracy: 806/5000 (16%)\n",
      "[epoch 41] loss: 0.0002774\n",
      "Test set: Average loss: 7.9166, Accuracy: 806/5000 (16%)\n",
      "[epoch 42] loss: 0.0002600\n",
      "Test set: Average loss: 7.9510, Accuracy: 806/5000 (16%)\n",
      "[epoch 43] loss: 0.0002447\n",
      "Test set: Average loss: 7.9820, Accuracy: 806/5000 (16%)\n",
      "[epoch 44] loss: 0.0002311\n",
      "Test set: Average loss: 8.0099, Accuracy: 804/5000 (16%)\n",
      "[epoch 45] loss: 0.0002190\n",
      "Test set: Average loss: 8.0350, Accuracy: 808/5000 (16%)\n",
      "[epoch 46] loss: 0.0002081\n",
      "Test set: Average loss: 8.0576, Accuracy: 808/5000 (16%)\n",
      "[epoch 47] loss: 0.0001984\n",
      "Test set: Average loss: 8.0780, Accuracy: 807/5000 (16%)\n",
      "[epoch 48] loss: 0.0001897\n",
      "Test set: Average loss: 8.0964, Accuracy: 809/5000 (16%)\n",
      "[epoch 49] loss: 0.0001817\n",
      "Test set: Average loss: 8.1130, Accuracy: 811/5000 (16%)\n",
      "[epoch 50] loss: 0.0001745\n",
      "Test set: Average loss: 8.1280, Accuracy: 808/5000 (16%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6774, Accuracy: 887/5000 (18%)\n",
      "Test\n",
      "Test set: Average loss: 2.6937, Accuracy: 1739/10000 (17%)\n",
      "50\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3043, Accuracy: 397/5000 (8%)\n",
      "[epoch 1] loss: 2.2912357\n",
      "Test set: Average loss: 2.2676, Accuracy: 1033/5000 (21%)\n",
      "[epoch 2] loss: 2.1151292\n",
      "Test set: Average loss: 2.2293, Accuracy: 864/5000 (17%)\n",
      "[epoch 3] loss: 1.8809380\n",
      "Test set: Average loss: 2.3443, Accuracy: 878/5000 (18%)\n",
      "[epoch 4] loss: 1.6684702\n",
      "Test set: Average loss: 2.4475, Accuracy: 1121/5000 (22%)\n",
      "[epoch 5] loss: 1.5103095\n",
      "Test set: Average loss: 2.4556, Accuracy: 1210/5000 (24%)\n",
      "[epoch 6] loss: 1.3872976\n",
      "Test set: Average loss: 2.4622, Accuracy: 1233/5000 (25%)\n",
      "[epoch 7] loss: 1.2606061\n",
      "Test set: Average loss: 2.3522, Accuracy: 1204/5000 (24%)\n",
      "[epoch 8] loss: 0.9967072\n",
      "Test set: Average loss: 2.4194, Accuracy: 1180/5000 (24%)\n",
      "[epoch 9] loss: 0.8921992\n",
      "Test set: Average loss: 2.4666, Accuracy: 1258/5000 (25%)\n",
      "[epoch 10] loss: 0.7170523\n",
      "Test set: Average loss: 2.5032, Accuracy: 1346/5000 (27%)\n",
      "[epoch 11] loss: 0.5207382\n",
      "Test set: Average loss: 2.6690, Accuracy: 1284/5000 (26%)\n",
      "[epoch 12] loss: 0.4345469\n",
      "Test set: Average loss: 3.0153, Accuracy: 1179/5000 (24%)\n",
      "[epoch 13] loss: 0.3553414\n",
      "Test set: Average loss: 3.3174, Accuracy: 1185/5000 (24%)\n",
      "[epoch 14] loss: 0.2529326\n",
      "Test set: Average loss: 3.2789, Accuracy: 1282/5000 (26%)\n",
      "[epoch 15] loss: 0.1728829\n",
      "Test set: Average loss: 3.2131, Accuracy: 1402/5000 (28%)\n",
      "[epoch 16] loss: 0.1270124\n",
      "Test set: Average loss: 3.3132, Accuracy: 1431/5000 (29%)\n",
      "[epoch 17] loss: 0.0864236\n",
      "Test set: Average loss: 3.5728, Accuracy: 1349/5000 (27%)\n",
      "[epoch 18] loss: 0.0542978\n",
      "Test set: Average loss: 3.7850, Accuracy: 1312/5000 (26%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] loss: 0.0385330\n",
      "Test set: Average loss: 3.8964, Accuracy: 1316/5000 (26%)\n",
      "[epoch 20] loss: 0.0266723\n",
      "Test set: Average loss: 3.9327, Accuracy: 1355/5000 (27%)\n",
      "[epoch 21] loss: 0.0187249\n",
      "Test set: Average loss: 3.9825, Accuracy: 1366/5000 (27%)\n",
      "[epoch 22] loss: 0.0153429\n",
      "Test set: Average loss: 4.0787, Accuracy: 1379/5000 (28%)\n",
      "[epoch 23] loss: 0.0117141\n",
      "Test set: Average loss: 4.1987, Accuracy: 1373/5000 (27%)\n",
      "[epoch 24] loss: 0.0093253\n",
      "Test set: Average loss: 4.3472, Accuracy: 1346/5000 (27%)\n",
      "[epoch 25] loss: 0.0069039\n",
      "Test set: Average loss: 4.5013, Accuracy: 1317/5000 (26%)\n",
      "[epoch 26] loss: 0.0061415\n",
      "Test set: Average loss: 4.6144, Accuracy: 1306/5000 (26%)\n",
      "[epoch 27] loss: 0.0050345\n",
      "Test set: Average loss: 4.6828, Accuracy: 1293/5000 (26%)\n",
      "[epoch 28] loss: 0.0037368\n",
      "Test set: Average loss: 4.7236, Accuracy: 1293/5000 (26%)\n",
      "[epoch 29] loss: 0.0034984\n",
      "Test set: Average loss: 4.7497, Accuracy: 1290/5000 (26%)\n",
      "[epoch 30] loss: 0.0030653\n",
      "Test set: Average loss: 4.7687, Accuracy: 1283/5000 (26%)\n",
      "[epoch 31] loss: 0.0025567\n",
      "Test set: Average loss: 4.7841, Accuracy: 1284/5000 (26%)\n",
      "[epoch 32] loss: 0.0028033\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.7983, Accuracy: 1290/5000 (26%)\n",
      "[epoch 33] loss: 0.0024942\n",
      "Test set: Average loss: 4.7996, Accuracy: 1288/5000 (26%)\n",
      "[epoch 34] loss: 0.0023541\n",
      "Test set: Average loss: 4.8008, Accuracy: 1291/5000 (26%)\n",
      "[epoch 35] loss: 0.0023461\n",
      "Test set: Average loss: 4.8022, Accuracy: 1290/5000 (26%)\n",
      "[epoch 36] loss: 0.0023397\n",
      "Test set: Average loss: 4.8033, Accuracy: 1291/5000 (26%)\n",
      "[epoch 37] loss: 0.0022977\n",
      "Test set: Average loss: 4.8044, Accuracy: 1287/5000 (26%)\n",
      "[epoch 38] loss: 0.0024259\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.8057, Accuracy: 1285/5000 (26%)\n",
      "[epoch 39] loss: 0.0022432\n",
      "Test set: Average loss: 4.8058, Accuracy: 1284/5000 (26%)\n",
      "[epoch 40] loss: 0.0023666\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 41] loss: 0.0023059\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 42] loss: 0.0020948\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 43] loss: 0.0023754\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 44] loss: 0.0023115\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 45] loss: 0.0023874\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 46] loss: 0.0023910\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 47] loss: 0.0024285\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 48] loss: 0.0021929\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 49] loss: 0.0023676\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "[epoch 50] loss: 0.0021805\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 4.8059, Accuracy: 1284/5000 (26%)\n",
      "Validation:\n",
      "Test set: Average loss: 3.3132, Accuracy: 1431/5000 (29%)\n",
      "Test\n",
      "Test set: Average loss: 3.2540, Accuracy: 2920/10000 (29%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 522/5000 (10%)\n",
      "[epoch 1] loss: 2.2954973\n",
      "Test set: Average loss: 2.2597, Accuracy: 1050/5000 (21%)\n",
      "[epoch 2] loss: 2.1403203\n",
      "Test set: Average loss: 2.2033, Accuracy: 1139/5000 (23%)\n",
      "[epoch 3] loss: 1.9064132\n",
      "Test set: Average loss: 2.1871, Accuracy: 1150/5000 (23%)\n",
      "[epoch 4] loss: 1.6590011\n",
      "Test set: Average loss: 2.1526, Accuracy: 1368/5000 (27%)\n",
      "[epoch 5] loss: 1.3327978\n",
      "Test set: Average loss: 2.1454, Accuracy: 1409/5000 (28%)\n",
      "[epoch 6] loss: 1.1598181\n",
      "Test set: Average loss: 2.2312, Accuracy: 1393/5000 (28%)\n",
      "[epoch 7] loss: 0.9237240\n",
      "Test set: Average loss: 2.2565, Accuracy: 1345/5000 (27%)\n",
      "[epoch 8] loss: 0.7177175\n",
      "Test set: Average loss: 2.3357, Accuracy: 1374/5000 (27%)\n",
      "[epoch 9] loss: 0.6374331\n",
      "Test set: Average loss: 2.4722, Accuracy: 1381/5000 (28%)\n",
      "[epoch 10] loss: 0.4417792\n",
      "Test set: Average loss: 2.6833, Accuracy: 1286/5000 (26%)\n",
      "[epoch 11] loss: 0.3022517\n",
      "Test set: Average loss: 2.8080, Accuracy: 1277/5000 (26%)\n",
      "[epoch 12] loss: 0.2294299\n",
      "Test set: Average loss: 2.9080, Accuracy: 1311/5000 (26%)\n",
      "[epoch 13] loss: 0.1678676\n",
      "Test set: Average loss: 3.0335, Accuracy: 1297/5000 (26%)\n",
      "[epoch 14] loss: 0.1164441\n",
      "Test set: Average loss: 3.1515, Accuracy: 1301/5000 (26%)\n",
      "[epoch 15] loss: 0.0691947\n",
      "Test set: Average loss: 3.3683, Accuracy: 1232/5000 (25%)\n",
      "[epoch 16] loss: 0.0492083\n",
      "Test set: Average loss: 3.6301, Accuracy: 1163/5000 (23%)\n",
      "[epoch 17] loss: 0.0325277\n",
      "Test set: Average loss: 3.8144, Accuracy: 1167/5000 (23%)\n",
      "[epoch 18] loss: 0.0299656\n",
      "Test set: Average loss: 3.9238, Accuracy: 1171/5000 (23%)\n",
      "[epoch 19] loss: 0.0173941\n",
      "Test set: Average loss: 3.9702, Accuracy: 1205/5000 (24%)\n",
      "[epoch 20] loss: 0.0116796\n",
      "Test set: Average loss: 4.0370, Accuracy: 1222/5000 (24%)\n",
      "[epoch 21] loss: 0.0114915\n",
      "Test set: Average loss: 4.1127, Accuracy: 1221/5000 (24%)\n",
      "[epoch 22] loss: 0.0083992\n",
      "Test set: Average loss: 4.1930, Accuracy: 1215/5000 (24%)\n",
      "[epoch 23] loss: 0.0063057\n",
      "Test set: Average loss: 4.2717, Accuracy: 1209/5000 (24%)\n",
      "[epoch 24] loss: 0.0054894\n",
      "Test set: Average loss: 4.3489, Accuracy: 1186/5000 (24%)\n",
      "[epoch 25] loss: 0.0040722\n",
      "Test set: Average loss: 4.4255, Accuracy: 1180/5000 (24%)\n",
      "[epoch 26] loss: 0.0036002\n",
      "Test set: Average loss: 4.4914, Accuracy: 1167/5000 (23%)\n",
      "[epoch 27] loss: 0.0028956\n",
      "Test set: Average loss: 4.5441, Accuracy: 1154/5000 (23%)\n",
      "[epoch 28] loss: 0.0027876\n",
      "Test set: Average loss: 4.5876, Accuracy: 1155/5000 (23%)\n",
      "[epoch 29] loss: 0.0025183\n",
      "Test set: Average loss: 4.6217, Accuracy: 1160/5000 (23%)\n",
      "[epoch 30] loss: 0.0022712\n",
      "Test set: Average loss: 4.6480, Accuracy: 1151/5000 (23%)\n",
      "[epoch 31] loss: 0.0020595\n",
      "Test set: Average loss: 4.6694, Accuracy: 1157/5000 (23%)\n",
      "[epoch 32] loss: 0.0020150\n",
      "Test set: Average loss: 4.6862, Accuracy: 1159/5000 (23%)\n",
      "[epoch 33] loss: 0.0018578\n",
      "Test set: Average loss: 4.6993, Accuracy: 1163/5000 (23%)\n",
      "[epoch 34] loss: 0.0017534\n",
      "Test set: Average loss: 4.7099, Accuracy: 1164/5000 (23%)\n",
      "[epoch 35] loss: 0.0015228\n",
      "Test set: Average loss: 4.7189, Accuracy: 1177/5000 (24%)\n",
      "[epoch 36] loss: 0.0014440\n",
      "Test set: Average loss: 4.7277, Accuracy: 1178/5000 (24%)\n",
      "[epoch 37] loss: 0.0014034\n",
      "Test set: Average loss: 4.7363, Accuracy: 1177/5000 (24%)\n",
      "[epoch 38] loss: 0.0013160\n",
      "Test set: Average loss: 4.7448, Accuracy: 1184/5000 (24%)\n",
      "[epoch 39] loss: 0.0013049\n",
      "Test set: Average loss: 4.7534, Accuracy: 1182/5000 (24%)\n",
      "[epoch 40] loss: 0.0012256\n",
      "Test set: Average loss: 4.7623, Accuracy: 1182/5000 (24%)\n",
      "[epoch 41] loss: 0.0011684\n",
      "Test set: Average loss: 4.7717, Accuracy: 1176/5000 (24%)\n",
      "[epoch 42] loss: 0.0011469\n",
      "Test set: Average loss: 4.7809, Accuracy: 1178/5000 (24%)\n",
      "[epoch 43] loss: 0.0011607\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.7902, Accuracy: 1179/5000 (24%)\n",
      "[epoch 44] loss: 0.0010869\n",
      "Test set: Average loss: 4.7912, Accuracy: 1179/5000 (24%)\n",
      "[epoch 45] loss: 0.0010120\n",
      "Test set: Average loss: 4.7920, Accuracy: 1180/5000 (24%)\n",
      "[epoch 46] loss: 0.0010315\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.7928, Accuracy: 1181/5000 (24%)\n",
      "[epoch 47] loss: 0.0010872\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.7929, Accuracy: 1181/5000 (24%)\n",
      "[epoch 48] loss: 0.0010356\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.7929, Accuracy: 1181/5000 (24%)\n",
      "[epoch 49] loss: 0.0010093\n",
      "Test set: Average loss: 4.7929, Accuracy: 1181/5000 (24%)\n",
      "[epoch 50] loss: 0.0010738\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 4.7929, Accuracy: 1181/5000 (24%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1454, Accuracy: 1409/5000 (28%)\n",
      "Test\n",
      "Test set: Average loss: 2.1320, Accuracy: 2782/10000 (28%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 400/5000 (8%)\n",
      "[epoch 1] loss: 2.2855140\n",
      "Test set: Average loss: 2.2703, Accuracy: 778/5000 (16%)\n",
      "[epoch 2] loss: 2.0998913\n",
      "Test set: Average loss: 2.2943, Accuracy: 772/5000 (15%)\n",
      "[epoch 3] loss: 1.8031548\n",
      "Test set: Average loss: 2.4461, Accuracy: 853/5000 (17%)\n",
      "[epoch 4] loss: 1.7107934\n",
      "Test set: Average loss: 2.3576, Accuracy: 936/5000 (19%)\n",
      "[epoch 5] loss: 1.4447638\n",
      "Test set: Average loss: 2.2278, Accuracy: 1138/5000 (23%)\n",
      "[epoch 6] loss: 1.3193354\n",
      "Test set: Average loss: 2.2395, Accuracy: 1180/5000 (24%)\n",
      "[epoch 7] loss: 1.0953750\n",
      "Test set: Average loss: 2.2451, Accuracy: 1243/5000 (25%)\n",
      "[epoch 8] loss: 0.9772930\n",
      "Test set: Average loss: 2.4273, Accuracy: 1196/5000 (24%)\n",
      "[epoch 9] loss: 0.7076075\n",
      "Test set: Average loss: 2.6761, Accuracy: 1138/5000 (23%)\n",
      "[epoch 10] loss: 0.5812548\n",
      "Test set: Average loss: 2.8091, Accuracy: 1162/5000 (23%)\n",
      "[epoch 11] loss: 0.4055907\n",
      "Test set: Average loss: 2.8616, Accuracy: 1228/5000 (25%)\n",
      "[epoch 12] loss: 0.3131917\n",
      "Test set: Average loss: 3.0353, Accuracy: 1197/5000 (24%)\n",
      "[epoch 13] loss: 0.2078638\n",
      "Test set: Average loss: 3.2620, Accuracy: 1186/5000 (24%)\n",
      "[epoch 14] loss: 0.1434365\n",
      "Test set: Average loss: 3.4999, Accuracy: 1183/5000 (24%)\n",
      "[epoch 15] loss: 0.1146654\n",
      "Test set: Average loss: 3.7434, Accuracy: 1162/5000 (23%)\n",
      "[epoch 16] loss: 0.0678062\n",
      "Test set: Average loss: 4.0016, Accuracy: 1094/5000 (22%)\n",
      "[epoch 17] loss: 0.0561222\n",
      "Test set: Average loss: 4.1511, Accuracy: 1085/5000 (22%)\n",
      "[epoch 18] loss: 0.0341197\n",
      "Test set: Average loss: 4.2294, Accuracy: 1125/5000 (22%)\n",
      "[epoch 19] loss: 0.0331456\n",
      "Test set: Average loss: 4.3481, Accuracy: 1137/5000 (23%)\n",
      "[epoch 20] loss: 0.0175831\n",
      "Test set: Average loss: 4.5219, Accuracy: 1116/5000 (22%)\n",
      "[epoch 21] loss: 0.0111459\n",
      "Test set: Average loss: 4.6977, Accuracy: 1097/5000 (22%)\n",
      "[epoch 22] loss: 0.0110173\n",
      "Test set: Average loss: 4.7833, Accuracy: 1092/5000 (22%)\n",
      "[epoch 23] loss: 0.0099990\n",
      "Test set: Average loss: 4.8125, Accuracy: 1093/5000 (22%)\n",
      "[epoch 24] loss: 0.0054800\n",
      "Test set: Average loss: 4.8055, Accuracy: 1120/5000 (22%)\n",
      "[epoch 25] loss: 0.0042572\n",
      "Test set: Average loss: 4.8261, Accuracy: 1137/5000 (23%)\n",
      "[epoch 26] loss: 0.0055191\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 4.8663, Accuracy: 1135/5000 (23%)\n",
      "[epoch 27] loss: 0.0041853\n",
      "Test set: Average loss: 4.8722, Accuracy: 1136/5000 (23%)\n",
      "[epoch 28] loss: 0.0040457\n",
      "Test set: Average loss: 4.8789, Accuracy: 1133/5000 (23%)\n",
      "[epoch 29] loss: 0.0049555\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 4.8864, Accuracy: 1134/5000 (23%)\n",
      "[epoch 30] loss: 0.0037676\n",
      "Test set: Average loss: 4.8873, Accuracy: 1133/5000 (23%)\n",
      "[epoch 31] loss: 0.0036243\n",
      "Test set: Average loss: 4.8881, Accuracy: 1133/5000 (23%)\n",
      "[epoch 32] loss: 0.0037864\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 4.8890, Accuracy: 1131/5000 (23%)\n",
      "[epoch 33] loss: 0.0038813\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 34] loss: 0.0045194\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 35] loss: 0.0043318\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 36] loss: 0.0042714\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 37] loss: 0.0034659\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 38] loss: 0.0038731\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 39] loss: 0.0038409\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 40] loss: 0.0038591\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 41] loss: 0.0036121\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 42] loss: 0.0035999\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 43] loss: 0.0039184\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 44] loss: 0.0045332\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 45] loss: 0.0044253\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 46] loss: 0.0044792\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 47] loss: 0.0043197\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 48] loss: 0.0043363\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 49] loss: 0.0036561\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "[epoch 50] loss: 0.0043826\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 4.8891, Accuracy: 1131/5000 (23%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2451, Accuracy: 1243/5000 (25%)\n",
      "Test\n",
      "Test set: Average loss: 2.2157, Accuracy: 2481/10000 (25%)\n",
      "100\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3050, Accuracy: 241/5000 (5%)\n",
      "[epoch 1] loss: 2.2506765\n",
      "Test set: Average loss: 2.2602, Accuracy: 915/5000 (18%)\n",
      "[epoch 2] loss: 2.1061348\n",
      "Test set: Average loss: 2.3574, Accuracy: 835/5000 (17%)\n",
      "[epoch 3] loss: 1.8860416\n",
      "Test set: Average loss: 2.2763, Accuracy: 1124/5000 (22%)\n",
      "[epoch 4] loss: 2.2832723\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0198, Accuracy: 1356/5000 (27%)\n",
      "[epoch 5] loss: 1.4860996\n",
      "Test set: Average loss: 2.0133, Accuracy: 1350/5000 (27%)\n",
      "[epoch 6] loss: 1.6016161\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0084, Accuracy: 1366/5000 (27%)\n",
      "[epoch 7] loss: 1.5805474\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0082, Accuracy: 1376/5000 (28%)\n",
      "[epoch 8] loss: 2.0656572\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 9] loss: 1.5223952\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 10] loss: 1.6380806\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 11] loss: 1.5402300\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 12] loss: 1.6004581\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 13] loss: 1.3363208\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 14] loss: 1.5662912\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 15] loss: 1.4196876\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 16] loss: 1.3947731\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 17] loss: 1.5362777\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 1.5130903\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 19] loss: 1.5351498\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 20] loss: 1.5817936\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 21] loss: 1.4079416\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 22] loss: 1.5131669\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 23] loss: 1.4649230\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 24] loss: 1.5962965\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 25] loss: 1.4936234\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 26] loss: 2.1340708\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 27] loss: 1.3847760\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 28] loss: 1.5769037\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 29] loss: 1.5648318\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 30] loss: 1.4103290\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 31] loss: 1.4315377\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 32] loss: 1.5450920\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 33] loss: 1.4873722\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 34] loss: 1.4741252\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 35] loss: 1.6142832\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 36] loss: 1.6259450\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 37] loss: 1.4512133\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 38] loss: 1.5779760\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 39] loss: 1.5276726\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 40] loss: 1.5243108\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 41] loss: 1.4622847\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 42] loss: 1.4598933\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 43] loss: 1.5927696\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 44] loss: 1.4559815\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 45] loss: 1.4638510\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-43.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 46] loss: 1.5795283\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-44.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 47] loss: 1.5959637\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-45.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 48] loss: 1.5636480\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-46.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 49] loss: 1.4334355\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-47.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "[epoch 50] loss: 1.5577645\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-48.\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0081, Accuracy: 1376/5000 (28%)\n",
      "Test\n",
      "Test set: Average loss: 1.9762, Accuracy: 2796/10000 (28%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3020, Accuracy: 507/5000 (10%)\n",
      "[epoch 1] loss: 2.2971677\n",
      "Test set: Average loss: 2.2146, Accuracy: 1195/5000 (24%)\n",
      "[epoch 2] loss: 2.0669028\n",
      "Test set: Average loss: 2.1142, Accuracy: 1179/5000 (24%)\n",
      "[epoch 3] loss: 1.8166800\n",
      "Test set: Average loss: 2.0302, Accuracy: 1358/5000 (27%)\n",
      "[epoch 4] loss: 1.5185717\n",
      "Test set: Average loss: 1.8968, Accuracy: 1672/5000 (33%)\n",
      "[epoch 5] loss: 1.3909184\n",
      "Test set: Average loss: 1.8520, Accuracy: 1704/5000 (34%)\n",
      "[epoch 6] loss: 1.1776118\n",
      "Test set: Average loss: 1.9037, Accuracy: 1718/5000 (34%)\n",
      "[epoch 7] loss: 2.0275763\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8787, Accuracy: 1749/5000 (35%)\n",
      "[epoch 8] loss: 1.0987639\n",
      "Test set: Average loss: 1.8743, Accuracy: 1748/5000 (35%)\n",
      "[epoch 9] loss: 1.0270696\n",
      "Test set: Average loss: 1.8413, Accuracy: 1809/5000 (36%)\n",
      "[epoch 10] loss: 0.8466876\n",
      "Test set: Average loss: 1.8245, Accuracy: 1853/5000 (37%)\n",
      "[epoch 11] loss: 0.9001628\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8204, Accuracy: 1863/5000 (37%)\n",
      "[epoch 12] loss: 0.7653137\n",
      "Test set: Average loss: 1.8183, Accuracy: 1869/5000 (37%)\n",
      "[epoch 13] loss: 0.7973457\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8169, Accuracy: 1869/5000 (37%)\n",
      "[epoch 14] loss: 0.7592324\n",
      "Test set: Average loss: 1.8166, Accuracy: 1868/5000 (37%)\n",
      "[epoch 15] loss: 0.9046735\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8163, Accuracy: 1867/5000 (37%)\n",
      "[epoch 16] loss: 0.8095545\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 17] loss: 0.7191006\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 18] loss: 0.8361112\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 19] loss: 1.0245694\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 20] loss: 0.7986204\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 21] loss: 0.6977240\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 22] loss: 0.9307535\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 23] loss: 0.9222908\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 24] loss: 0.9074443\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 25] loss: 0.8664402\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 26] loss: 0.7508252\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 27] loss: 0.7842757\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] loss: 0.8026732\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 29] loss: 0.7299942\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 30] loss: 0.8493375\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 31] loss: 0.8211547\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 32] loss: 0.8091769\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 33] loss: 0.9245508\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 34] loss: 0.7374310\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 35] loss: 0.8382151\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8205, Accuracy: 1863/5000 (37%)\n",
      "[epoch 36] loss: 0.8447229\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 37] loss: 0.8611881\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 38] loss: 0.8206809\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 39] loss: 0.9472392\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 40] loss: 0.9782220\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 41] loss: 0.8773294\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 42] loss: 0.8105386\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 43] loss: 0.8087877\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 44] loss: 0.8264659\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 45] loss: 0.8574357\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 46] loss: 0.9078849\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 47] loss: 0.8563898\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 48] loss: 1.8018344\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 49] loss: 0.8756764\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "[epoch 50] loss: 0.7690381\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 1.8162, Accuracy: 1867/5000 (37%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.8169, Accuracy: 1869/5000 (37%)\n",
      "Test\n",
      "Test set: Average loss: 1.7688, Accuracy: 3851/10000 (39%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3035, Accuracy: 482/5000 (10%)\n",
      "[epoch 1] loss: 2.2950191\n",
      "Test set: Average loss: 2.2617, Accuracy: 708/5000 (14%)\n",
      "[epoch 2] loss: 2.0429215\n",
      "Test set: Average loss: 2.3274, Accuracy: 884/5000 (18%)\n",
      "[epoch 3] loss: 1.7302248\n",
      "Test set: Average loss: 2.2483, Accuracy: 1100/5000 (22%)\n",
      "[epoch 4] loss: 1.6502272\n",
      "Test set: Average loss: 2.2787, Accuracy: 1088/5000 (22%)\n",
      "[epoch 5] loss: 1.5143870\n",
      "Test set: Average loss: 2.0026, Accuracy: 1353/5000 (27%)\n",
      "[epoch 6] loss: 1.3029913\n",
      "Test set: Average loss: 2.1779, Accuracy: 1238/5000 (25%)\n",
      "[epoch 7] loss: 1.3343510\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1203, Accuracy: 1406/5000 (28%)\n",
      "[epoch 8] loss: 1.0545290\n",
      "Test set: Average loss: 2.1047, Accuracy: 1428/5000 (29%)\n",
      "[epoch 9] loss: 2.1992813\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0730, Accuracy: 1433/5000 (29%)\n",
      "[epoch 10] loss: 1.0730317\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0689, Accuracy: 1438/5000 (29%)\n",
      "[epoch 11] loss: 1.0319697\n",
      "Test set: Average loss: 2.0684, Accuracy: 1438/5000 (29%)\n",
      "[epoch 12] loss: 1.0481261\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0679, Accuracy: 1440/5000 (29%)\n",
      "[epoch 13] loss: 1.0143708\n",
      "Test set: Average loss: 2.0678, Accuracy: 1440/5000 (29%)\n",
      "[epoch 14] loss: 0.9193029\n",
      "Test set: Average loss: 2.0678, Accuracy: 1440/5000 (29%)\n",
      "[epoch 15] loss: 1.2308660\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 16] loss: 1.0180657\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 17] loss: 1.1097023\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 18] loss: 1.0384927\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 19] loss: 1.2496627\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 20] loss: 1.1825559\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 21] loss: 1.1889740\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 22] loss: 1.0721804\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 23] loss: 1.0928548\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 24] loss: 1.0023132\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 25] loss: 0.9834401\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 26] loss: 0.9951398\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 27] loss: 1.0744148\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 28] loss: 1.0962076\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 29] loss: 1.0631033\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 30] loss: 1.1689775\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 31] loss: 1.1123299\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 32] loss: 1.0197439\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 33] loss: 1.0307169\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 34] loss: 1.2044437\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 35] loss: 1.1627684\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 36] loss: 1.1838008\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 37] loss: 0.9379058\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 38] loss: 1.0966708\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-31.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 39] loss: 1.0830259\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-32.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 40] loss: 1.0760262\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-33.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 41] loss: 1.2525097\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-34.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 42] loss: 0.9913681\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-35.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 43] loss: 1.0581186\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-36.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 44] loss: 0.9627009\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-37.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 45] loss: 1.1383609\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-38.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 46] loss: 1.0744722\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-39.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 47] loss: 1.1584373\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-40.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 48] loss: 1.0390411\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-41.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 49] loss: 0.9000844\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "[epoch 50] loss: 1.0005615\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-42.\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0677, Accuracy: 1440/5000 (29%)\n",
      "Test\n",
      "Test set: Average loss: 2.0711, Accuracy: 2869/10000 (29%)\n",
      "250\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 491/5000 (10%)\n",
      "[epoch 1] loss: 2.2189065\n",
      "Test set: Average loss: 2.0365, Accuracy: 1315/5000 (26%)\n",
      "[epoch 2] loss: 1.8724729\n",
      "Test set: Average loss: 1.8057, Accuracy: 1750/5000 (35%)\n",
      "[epoch 3] loss: 1.6092944\n",
      "Test set: Average loss: 1.8382, Accuracy: 1695/5000 (34%)\n",
      "[epoch 4] loss: 1.3562840\n",
      "Test set: Average loss: 1.6800, Accuracy: 2024/5000 (40%)\n",
      "[epoch 5] loss: 1.1448266\n",
      "Test set: Average loss: 1.5494, Accuracy: 2319/5000 (46%)\n",
      "[epoch 6] loss: 0.9273253\n",
      "Test set: Average loss: 1.6363, Accuracy: 2269/5000 (45%)\n",
      "[epoch 7] loss: 0.7822964\n",
      "Test set: Average loss: 1.8123, Accuracy: 2155/5000 (43%)\n",
      "[epoch 8] loss: 0.6790019\n",
      "Test set: Average loss: 1.8389, Accuracy: 2223/5000 (44%)\n",
      "[epoch 9] loss: 0.5751555\n",
      "Test set: Average loss: 1.8276, Accuracy: 2213/5000 (44%)\n",
      "[epoch 10] loss: 0.4280685\n",
      "Test set: Average loss: 1.9283, Accuracy: 2228/5000 (45%)\n",
      "[epoch 11] loss: 0.2769192\n",
      "Test set: Average loss: 2.0929, Accuracy: 2172/5000 (43%)\n",
      "[epoch 12] loss: 0.1696053\n",
      "Test set: Average loss: 2.1785, Accuracy: 2241/5000 (45%)\n",
      "[epoch 13] loss: 0.1281788\n",
      "Test set: Average loss: 2.2917, Accuracy: 2224/5000 (44%)\n",
      "[epoch 14] loss: 0.0964248\n",
      "Test set: Average loss: 2.5096, Accuracy: 2105/5000 (42%)\n",
      "[epoch 15] loss: 0.0731993\n",
      "Test set: Average loss: 2.4535, Accuracy: 2258/5000 (45%)\n",
      "[epoch 16] loss: 0.0402437\n",
      "Test set: Average loss: 2.7116, Accuracy: 2147/5000 (43%)\n",
      "[epoch 17] loss: 0.0285943\n",
      "Test set: Average loss: 2.7075, Accuracy: 2170/5000 (43%)\n",
      "[epoch 18] loss: 0.0261441\n",
      "Test set: Average loss: 2.7704, Accuracy: 2192/5000 (44%)\n",
      "[epoch 19] loss: 0.0187387\n",
      "Test set: Average loss: 2.8026, Accuracy: 2182/5000 (44%)\n",
      "[epoch 20] loss: 0.0153294\n",
      "Test set: Average loss: 2.8809, Accuracy: 2174/5000 (43%)\n",
      "[epoch 21] loss: 0.0113099\n",
      "Test set: Average loss: 2.9101, Accuracy: 2184/5000 (44%)\n",
      "[epoch 22] loss: 0.0089238\n",
      "Test set: Average loss: 2.9178, Accuracy: 2180/5000 (44%)\n",
      "[epoch 23] loss: 0.0076501\n",
      "Test set: Average loss: 2.9785, Accuracy: 2180/5000 (44%)\n",
      "[epoch 24] loss: 0.0063865\n",
      "Test set: Average loss: 2.9960, Accuracy: 2188/5000 (44%)\n",
      "[epoch 25] loss: 0.0056782\n",
      "Test set: Average loss: 3.0125, Accuracy: 2181/5000 (44%)\n",
      "[epoch 26] loss: 0.0052790\n",
      "Test set: Average loss: 3.0670, Accuracy: 2170/5000 (43%)\n",
      "[epoch 27] loss: 0.0047552\n",
      "Test set: Average loss: 3.1205, Accuracy: 2167/5000 (43%)\n",
      "[epoch 28] loss: 0.0042834\n",
      "Test set: Average loss: 3.1164, Accuracy: 2177/5000 (44%)\n",
      "[epoch 29] loss: 0.0039537\n",
      "Test set: Average loss: 3.1316, Accuracy: 2170/5000 (43%)\n",
      "[epoch 30] loss: 0.0036656\n",
      "Test set: Average loss: 3.1745, Accuracy: 2169/5000 (43%)\n",
      "[epoch 31] loss: 0.0034278\n",
      "Test set: Average loss: 3.1776, Accuracy: 2160/5000 (43%)\n",
      "[epoch 32] loss: 0.0032311\n",
      "Test set: Average loss: 3.1978, Accuracy: 2165/5000 (43%)\n",
      "[epoch 33] loss: 0.0030462\n",
      "Test set: Average loss: 3.2226, Accuracy: 2155/5000 (43%)\n",
      "[epoch 34] loss: 0.0028543\n",
      "Test set: Average loss: 3.2407, Accuracy: 2157/5000 (43%)\n",
      "[epoch 35] loss: 0.0027160\n",
      "Test set: Average loss: 3.2629, Accuracy: 2156/5000 (43%)\n",
      "[epoch 36] loss: 0.0025512\n",
      "Test set: Average loss: 3.2773, Accuracy: 2148/5000 (43%)\n",
      "[epoch 37] loss: 0.0024377\n",
      "Test set: Average loss: 3.2924, Accuracy: 2158/5000 (43%)\n",
      "[epoch 38] loss: 0.0023283\n",
      "Test set: Average loss: 3.3056, Accuracy: 2156/5000 (43%)\n",
      "[epoch 39] loss: 0.0021936\n",
      "Test set: Average loss: 3.3275, Accuracy: 2156/5000 (43%)\n",
      "[epoch 40] loss: 0.0020971\n",
      "Test set: Average loss: 3.3461, Accuracy: 2159/5000 (43%)\n",
      "[epoch 41] loss: 0.0020026\n",
      "Test set: Average loss: 3.3508, Accuracy: 2155/5000 (43%)\n",
      "[epoch 42] loss: 0.0019193\n",
      "Test set: Average loss: 3.3594, Accuracy: 2150/5000 (43%)\n",
      "[epoch 43] loss: 0.0018349\n",
      "Test set: Average loss: 3.3803, Accuracy: 2148/5000 (43%)\n",
      "[epoch 44] loss: 0.0017639\n",
      "Test set: Average loss: 3.3944, Accuracy: 2158/5000 (43%)\n",
      "[epoch 45] loss: 0.0016954\n",
      "Test set: Average loss: 3.4124, Accuracy: 2153/5000 (43%)\n",
      "[epoch 46] loss: 0.0016178\n",
      "Test set: Average loss: 3.4221, Accuracy: 2153/5000 (43%)\n",
      "[epoch 47] loss: 0.0015600\n",
      "Test set: Average loss: 3.4270, Accuracy: 2157/5000 (43%)\n",
      "[epoch 48] loss: 0.0014811\n",
      "Test set: Average loss: 3.4417, Accuracy: 2156/5000 (43%)\n",
      "[epoch 49] loss: 0.0014372\n",
      "Test set: Average loss: 3.4576, Accuracy: 2155/5000 (43%)\n",
      "[epoch 50] loss: 0.0013843\n",
      "Test set: Average loss: 3.4702, Accuracy: 2145/5000 (43%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5494, Accuracy: 2319/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.5273, Accuracy: 4711/10000 (47%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3004, Accuracy: 491/5000 (10%)\n",
      "[epoch 1] loss: 2.2151220\n",
      "Test set: Average loss: 2.0145, Accuracy: 1564/5000 (31%)\n",
      "[epoch 2] loss: 1.7623250\n",
      "Test set: Average loss: 1.7380, Accuracy: 1943/5000 (39%)\n",
      "[epoch 3] loss: 1.4858935\n",
      "Test set: Average loss: 1.6765, Accuracy: 1998/5000 (40%)\n",
      "[epoch 4] loss: 1.2438210\n",
      "Test set: Average loss: 1.5945, Accuracy: 2182/5000 (44%)\n",
      "[epoch 5] loss: 1.0357708\n",
      "Test set: Average loss: 1.5894, Accuracy: 2191/5000 (44%)\n",
      "[epoch 6] loss: 0.8224439\n",
      "Test set: Average loss: 1.4839, Accuracy: 2365/5000 (47%)\n",
      "[epoch 7] loss: 0.7208970\n",
      "Test set: Average loss: 1.7257, Accuracy: 2242/5000 (45%)\n",
      "[epoch 8] loss: 0.5883757\n",
      "Test set: Average loss: 1.7053, Accuracy: 2207/5000 (44%)\n",
      "[epoch 9] loss: 0.4476418\n",
      "Test set: Average loss: 1.7533, Accuracy: 2339/5000 (47%)\n",
      "[epoch 10] loss: 0.3325427\n",
      "Test set: Average loss: 1.8420, Accuracy: 2247/5000 (45%)\n",
      "[epoch 11] loss: 0.2425776\n",
      "Test set: Average loss: 1.9491, Accuracy: 2298/5000 (46%)\n",
      "[epoch 12] loss: 0.2217230\n",
      "Test set: Average loss: 1.9808, Accuracy: 2312/5000 (46%)\n",
      "[epoch 13] loss: 0.1611626\n",
      "Test set: Average loss: 2.0889, Accuracy: 2277/5000 (46%)\n",
      "[epoch 14] loss: 0.1154113\n",
      "Test set: Average loss: 2.2344, Accuracy: 2303/5000 (46%)\n",
      "[epoch 15] loss: 0.1045980\n",
      "Test set: Average loss: 2.3352, Accuracy: 2195/5000 (44%)\n",
      "[epoch 16] loss: 0.0681812\n",
      "Test set: Average loss: 2.2991, Accuracy: 2326/5000 (47%)\n",
      "[epoch 17] loss: 0.0463709\n",
      "Test set: Average loss: 2.3740, Accuracy: 2312/5000 (46%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.0322980\n",
      "Test set: Average loss: 2.3965, Accuracy: 2358/5000 (47%)\n",
      "[epoch 19] loss: 0.0202972\n",
      "Test set: Average loss: 2.4416, Accuracy: 2354/5000 (47%)\n",
      "[epoch 20] loss: 0.0152513\n",
      "Test set: Average loss: 2.5003, Accuracy: 2331/5000 (47%)\n",
      "[epoch 21] loss: 0.0129240\n",
      "Test set: Average loss: 2.5366, Accuracy: 2335/5000 (47%)\n",
      "[epoch 22] loss: 0.0103252\n",
      "Test set: Average loss: 2.5601, Accuracy: 2320/5000 (46%)\n",
      "[epoch 23] loss: 0.0083563\n",
      "Test set: Average loss: 2.6081, Accuracy: 2313/5000 (46%)\n",
      "[epoch 24] loss: 0.0074666\n",
      "Test set: Average loss: 2.6271, Accuracy: 2331/5000 (47%)\n",
      "[epoch 25] loss: 0.0064303\n",
      "Test set: Average loss: 2.6512, Accuracy: 2323/5000 (46%)\n",
      "[epoch 26] loss: 0.0058788\n",
      "Test set: Average loss: 2.6739, Accuracy: 2315/5000 (46%)\n",
      "[epoch 27] loss: 0.0054100\n",
      "Test set: Average loss: 2.7205, Accuracy: 2295/5000 (46%)\n",
      "[epoch 28] loss: 0.0049847\n",
      "Test set: Average loss: 2.7374, Accuracy: 2304/5000 (46%)\n",
      "[epoch 29] loss: 0.0045054\n",
      "Test set: Average loss: 2.7374, Accuracy: 2319/5000 (46%)\n",
      "[epoch 30] loss: 0.0041773\n",
      "Test set: Average loss: 2.7575, Accuracy: 2315/5000 (46%)\n",
      "[epoch 31] loss: 0.0038897\n",
      "Test set: Average loss: 2.7883, Accuracy: 2298/5000 (46%)\n",
      "[epoch 32] loss: 0.0035859\n",
      "Test set: Average loss: 2.8052, Accuracy: 2302/5000 (46%)\n",
      "[epoch 33] loss: 0.0033543\n",
      "Test set: Average loss: 2.8214, Accuracy: 2306/5000 (46%)\n",
      "[epoch 34] loss: 0.0031898\n",
      "Test set: Average loss: 2.8389, Accuracy: 2299/5000 (46%)\n",
      "[epoch 35] loss: 0.0029881\n",
      "Test set: Average loss: 2.8497, Accuracy: 2308/5000 (46%)\n",
      "[epoch 36] loss: 0.0028001\n",
      "Test set: Average loss: 2.8660, Accuracy: 2298/5000 (46%)\n",
      "[epoch 37] loss: 0.0026733\n",
      "Test set: Average loss: 2.8854, Accuracy: 2297/5000 (46%)\n",
      "[epoch 38] loss: 0.0025633\n",
      "Test set: Average loss: 2.8916, Accuracy: 2303/5000 (46%)\n",
      "[epoch 39] loss: 0.0024051\n",
      "Test set: Average loss: 2.9093, Accuracy: 2294/5000 (46%)\n",
      "[epoch 40] loss: 0.0022902\n",
      "Test set: Average loss: 2.9238, Accuracy: 2299/5000 (46%)\n",
      "[epoch 41] loss: 0.0022017\n",
      "Test set: Average loss: 2.9403, Accuracy: 2288/5000 (46%)\n",
      "[epoch 42] loss: 0.0020720\n",
      "Test set: Average loss: 2.9507, Accuracy: 2288/5000 (46%)\n",
      "[epoch 43] loss: 0.0019946\n",
      "Test set: Average loss: 2.9588, Accuracy: 2293/5000 (46%)\n",
      "[epoch 44] loss: 0.0018957\n",
      "Test set: Average loss: 2.9760, Accuracy: 2293/5000 (46%)\n",
      "[epoch 45] loss: 0.0018270\n",
      "Test set: Average loss: 2.9854, Accuracy: 2292/5000 (46%)\n",
      "[epoch 46] loss: 0.0017602\n",
      "Test set: Average loss: 2.9936, Accuracy: 2285/5000 (46%)\n",
      "[epoch 47] loss: 0.0016715\n",
      "Test set: Average loss: 3.0059, Accuracy: 2292/5000 (46%)\n",
      "[epoch 48] loss: 0.0016069\n",
      "Test set: Average loss: 3.0198, Accuracy: 2294/5000 (46%)\n",
      "[epoch 49] loss: 0.0015434\n",
      "Test set: Average loss: 3.0291, Accuracy: 2287/5000 (46%)\n",
      "[epoch 50] loss: 0.0014882\n",
      "Test set: Average loss: 3.0417, Accuracy: 2285/5000 (46%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4839, Accuracy: 2365/5000 (47%)\n",
      "Test\n",
      "Test set: Average loss: 1.4705, Accuracy: 4837/10000 (48%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3047, Accuracy: 518/5000 (10%)\n",
      "[epoch 1] loss: 2.2528653\n",
      "Test set: Average loss: 2.1090, Accuracy: 1305/5000 (26%)\n",
      "[epoch 2] loss: 1.8758919\n",
      "Test set: Average loss: 1.8023, Accuracy: 1849/5000 (37%)\n",
      "[epoch 3] loss: 1.6749015\n",
      "Test set: Average loss: 1.8576, Accuracy: 1796/5000 (36%)\n",
      "[epoch 4] loss: 1.3707837\n",
      "Test set: Average loss: 1.6494, Accuracy: 2075/5000 (42%)\n",
      "[epoch 5] loss: 1.1184188\n",
      "Test set: Average loss: 1.6000, Accuracy: 2249/5000 (45%)\n",
      "[epoch 6] loss: 0.9289997\n",
      "Test set: Average loss: 1.6683, Accuracy: 2287/5000 (46%)\n",
      "[epoch 7] loss: 0.7997916\n",
      "Test set: Average loss: 1.7251, Accuracy: 2205/5000 (44%)\n",
      "[epoch 8] loss: 0.6324814\n",
      "Test set: Average loss: 1.7691, Accuracy: 2265/5000 (45%)\n",
      "[epoch 9] loss: 0.4911736\n",
      "Test set: Average loss: 1.8465, Accuracy: 2268/5000 (45%)\n",
      "[epoch 10] loss: 0.3948664\n",
      "Test set: Average loss: 1.9204, Accuracy: 2246/5000 (45%)\n",
      "[epoch 11] loss: 0.3364928\n",
      "Test set: Average loss: 2.0948, Accuracy: 2167/5000 (43%)\n",
      "[epoch 12] loss: 0.2690758\n",
      "Test set: Average loss: 2.1266, Accuracy: 2173/5000 (43%)\n",
      "[epoch 13] loss: 0.1938790\n",
      "Test set: Average loss: 2.2138, Accuracy: 2187/5000 (44%)\n",
      "[epoch 14] loss: 0.1680078\n",
      "Test set: Average loss: 2.3933, Accuracy: 2108/5000 (42%)\n",
      "[epoch 15] loss: 0.1411965\n",
      "Test set: Average loss: 2.3352, Accuracy: 2244/5000 (45%)\n",
      "[epoch 16] loss: 0.0716133\n",
      "Test set: Average loss: 2.4951, Accuracy: 2184/5000 (44%)\n",
      "[epoch 17] loss: 0.0480844\n",
      "Test set: Average loss: 2.5684, Accuracy: 2200/5000 (44%)\n",
      "[epoch 18] loss: 0.0340358\n",
      "Test set: Average loss: 2.6304, Accuracy: 2204/5000 (44%)\n",
      "[epoch 19] loss: 0.0256536\n",
      "Test set: Average loss: 2.7476, Accuracy: 2204/5000 (44%)\n",
      "[epoch 20] loss: 0.0186533\n",
      "Test set: Average loss: 2.7572, Accuracy: 2223/5000 (44%)\n",
      "[epoch 21] loss: 0.0142932\n",
      "Test set: Average loss: 2.7535, Accuracy: 2230/5000 (45%)\n",
      "[epoch 22] loss: 0.0107796\n",
      "Test set: Average loss: 2.8579, Accuracy: 2214/5000 (44%)\n",
      "[epoch 23] loss: 0.0089976\n",
      "Test set: Average loss: 2.8721, Accuracy: 2227/5000 (45%)\n",
      "[epoch 24] loss: 0.0079939\n",
      "Test set: Average loss: 2.8928, Accuracy: 2226/5000 (45%)\n",
      "[epoch 25] loss: 0.0069942\n",
      "Test set: Average loss: 2.9266, Accuracy: 2234/5000 (45%)\n",
      "[epoch 26] loss: 0.0062274\n",
      "Test set: Average loss: 2.9533, Accuracy: 2240/5000 (45%)\n",
      "[epoch 27] loss: 0.0058114\n",
      "Test set: Average loss: 2.9717, Accuracy: 2232/5000 (45%)\n",
      "[epoch 28] loss: 0.0053167\n",
      "Test set: Average loss: 2.9976, Accuracy: 2230/5000 (45%)\n",
      "[epoch 29] loss: 0.0049535\n",
      "Test set: Average loss: 3.0232, Accuracy: 2226/5000 (45%)\n",
      "[epoch 30] loss: 0.0046333\n",
      "Test set: Average loss: 3.0375, Accuracy: 2237/5000 (45%)\n",
      "[epoch 31] loss: 0.0043206\n",
      "Test set: Average loss: 3.0586, Accuracy: 2232/5000 (45%)\n",
      "[epoch 32] loss: 0.0040135\n",
      "Test set: Average loss: 3.0857, Accuracy: 2228/5000 (45%)\n",
      "[epoch 33] loss: 0.0038475\n",
      "Test set: Average loss: 3.1034, Accuracy: 2224/5000 (44%)\n",
      "[epoch 34] loss: 0.0036424\n",
      "Test set: Average loss: 3.1191, Accuracy: 2227/5000 (45%)\n",
      "[epoch 35] loss: 0.0034423\n",
      "Test set: Average loss: 3.1364, Accuracy: 2233/5000 (45%)\n",
      "[epoch 36] loss: 0.0032301\n",
      "Test set: Average loss: 3.1555, Accuracy: 2222/5000 (44%)\n",
      "[epoch 37] loss: 0.0030556\n",
      "Test set: Average loss: 3.1802, Accuracy: 2218/5000 (44%)\n",
      "[epoch 38] loss: 0.0029006\n",
      "Test set: Average loss: 3.1892, Accuracy: 2226/5000 (45%)\n",
      "[epoch 39] loss: 0.0027165\n",
      "Test set: Average loss: 3.1940, Accuracy: 2228/5000 (45%)\n",
      "[epoch 40] loss: 0.0026254\n",
      "Test set: Average loss: 3.2128, Accuracy: 2230/5000 (45%)\n",
      "[epoch 41] loss: 0.0024685\n",
      "Test set: Average loss: 3.2321, Accuracy: 2223/5000 (44%)\n",
      "[epoch 42] loss: 0.0023892\n",
      "Test set: Average loss: 3.2463, Accuracy: 2219/5000 (44%)\n",
      "[epoch 43] loss: 0.0022704\n",
      "Test set: Average loss: 3.2649, Accuracy: 2218/5000 (44%)\n",
      "[epoch 44] loss: 0.0021714\n",
      "Test set: Average loss: 3.2814, Accuracy: 2215/5000 (44%)\n",
      "[epoch 45] loss: 0.0020980\n",
      "Test set: Average loss: 3.2934, Accuracy: 2220/5000 (44%)\n",
      "[epoch 46] loss: 0.0019956\n",
      "Test set: Average loss: 3.3014, Accuracy: 2219/5000 (44%)\n",
      "[epoch 47] loss: 0.0019269\n",
      "Test set: Average loss: 3.3082, Accuracy: 2221/5000 (44%)\n",
      "[epoch 48] loss: 0.0018539\n",
      "Test set: Average loss: 3.3264, Accuracy: 2221/5000 (44%)\n",
      "[epoch 49] loss: 0.0017908\n",
      "Test set: Average loss: 3.3393, Accuracy: 2217/5000 (44%)\n",
      "[epoch 50] loss: 0.0017006\n",
      "Test set: Average loss: 3.3533, Accuracy: 2213/5000 (44%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6683, Accuracy: 2287/5000 (46%)\n",
      "Test\n",
      "Test set: Average loss: 1.6765, Accuracy: 4519/10000 (45%)\n",
      "500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 497/5000 (10%)\n",
      "[epoch 1] loss: 2.1012615\n",
      "Test set: Average loss: 1.9109, Accuracy: 1613/5000 (32%)\n",
      "[epoch 2] loss: 1.6836012\n",
      "Test set: Average loss: 1.6153, Accuracy: 2161/5000 (43%)\n",
      "[epoch 3] loss: 1.3484574\n",
      "Test set: Average loss: 1.5036, Accuracy: 2295/5000 (46%)\n",
      "[epoch 4] loss: 1.1885973\n",
      "Test set: Average loss: 1.4970, Accuracy: 2301/5000 (46%)\n",
      "[epoch 5] loss: 0.9702955\n",
      "Test set: Average loss: 1.4974, Accuracy: 2460/5000 (49%)\n",
      "[epoch 6] loss: 0.7759478\n",
      "Test set: Average loss: 1.4968, Accuracy: 2558/5000 (51%)\n",
      "[epoch 7] loss: 0.6459639\n",
      "Test set: Average loss: 1.5915, Accuracy: 2561/5000 (51%)\n",
      "[epoch 8] loss: 0.5301347\n",
      "Test set: Average loss: 1.8726, Accuracy: 2338/5000 (47%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 0.4897057\n",
      "Test set: Average loss: 1.7701, Accuracy: 2504/5000 (50%)\n",
      "[epoch 10] loss: 0.3470612\n",
      "Test set: Average loss: 1.9027, Accuracy: 2481/5000 (50%)\n",
      "[epoch 11] loss: 0.2124341\n",
      "Test set: Average loss: 1.9523, Accuracy: 2474/5000 (49%)\n",
      "[epoch 12] loss: 0.1600358\n",
      "Test set: Average loss: 2.2044, Accuracy: 2439/5000 (49%)\n",
      "[epoch 13] loss: 0.1113891\n",
      "Test set: Average loss: 2.1650, Accuracy: 2496/5000 (50%)\n",
      "[epoch 14] loss: 0.0780439\n",
      "Test set: Average loss: 2.2743, Accuracy: 2524/5000 (50%)\n",
      "[epoch 15] loss: 0.0527479\n",
      "Test set: Average loss: 2.4806, Accuracy: 2415/5000 (48%)\n",
      "[epoch 16] loss: 0.0307079\n",
      "Test set: Average loss: 2.4108, Accuracy: 2521/5000 (50%)\n",
      "[epoch 17] loss: 0.0210420\n",
      "Test set: Average loss: 2.5427, Accuracy: 2494/5000 (50%)\n",
      "[epoch 18] loss: 0.0166839\n",
      "Test set: Average loss: 2.5458, Accuracy: 2494/5000 (50%)\n",
      "[epoch 19] loss: 0.0129955\n",
      "Test set: Average loss: 2.5976, Accuracy: 2521/5000 (50%)\n",
      "[epoch 20] loss: 0.0093880\n",
      "Test set: Average loss: 2.6413, Accuracy: 2506/5000 (50%)\n",
      "[epoch 21] loss: 0.0076520\n",
      "Test set: Average loss: 2.6983, Accuracy: 2482/5000 (50%)\n",
      "[epoch 22] loss: 0.0066537\n",
      "Test set: Average loss: 2.7254, Accuracy: 2505/5000 (50%)\n",
      "[epoch 23] loss: 0.0055179\n",
      "Test set: Average loss: 2.7545, Accuracy: 2510/5000 (50%)\n",
      "[epoch 24] loss: 0.0049146\n",
      "Test set: Average loss: 2.7910, Accuracy: 2500/5000 (50%)\n",
      "[epoch 25] loss: 0.0045342\n",
      "Test set: Average loss: 2.8107, Accuracy: 2501/5000 (50%)\n",
      "[epoch 26] loss: 0.0042014\n",
      "Test set: Average loss: 2.8399, Accuracy: 2509/5000 (50%)\n",
      "[epoch 27] loss: 0.0038290\n",
      "Test set: Average loss: 2.8651, Accuracy: 2497/5000 (50%)\n",
      "[epoch 28] loss: 0.0035456\n",
      "Test set: Average loss: 2.8770, Accuracy: 2505/5000 (50%)\n",
      "[epoch 29] loss: 0.0033461\n",
      "Test set: Average loss: 2.9073, Accuracy: 2500/5000 (50%)\n",
      "[epoch 30] loss: 0.0030383\n",
      "Test set: Average loss: 2.9295, Accuracy: 2502/5000 (50%)\n",
      "[epoch 31] loss: 0.0028543\n",
      "Test set: Average loss: 2.9442, Accuracy: 2495/5000 (50%)\n",
      "[epoch 32] loss: 0.0026764\n",
      "Test set: Average loss: 2.9664, Accuracy: 2505/5000 (50%)\n",
      "[epoch 33] loss: 0.0025005\n",
      "Test set: Average loss: 2.9917, Accuracy: 2494/5000 (50%)\n",
      "[epoch 34] loss: 0.0023703\n",
      "Test set: Average loss: 3.0035, Accuracy: 2503/5000 (50%)\n",
      "[epoch 35] loss: 0.0022361\n",
      "Test set: Average loss: 3.0227, Accuracy: 2493/5000 (50%)\n",
      "[epoch 36] loss: 0.0020903\n",
      "Test set: Average loss: 3.0378, Accuracy: 2499/5000 (50%)\n",
      "[epoch 37] loss: 0.0019784\n",
      "Test set: Average loss: 3.0568, Accuracy: 2488/5000 (50%)\n",
      "[epoch 38] loss: 0.0019314\n",
      "Test set: Average loss: 3.0689, Accuracy: 2496/5000 (50%)\n",
      "[epoch 39] loss: 0.0017945\n",
      "Test set: Average loss: 3.0789, Accuracy: 2496/5000 (50%)\n",
      "[epoch 40] loss: 0.0017148\n",
      "Test set: Average loss: 3.1031, Accuracy: 2492/5000 (50%)\n",
      "[epoch 41] loss: 0.0016041\n",
      "Test set: Average loss: 3.1157, Accuracy: 2497/5000 (50%)\n",
      "[epoch 42] loss: 0.0015552\n",
      "Test set: Average loss: 3.1277, Accuracy: 2490/5000 (50%)\n",
      "[epoch 43] loss: 0.0014850\n",
      "Test set: Average loss: 3.1430, Accuracy: 2498/5000 (50%)\n",
      "[epoch 44] loss: 0.0014176\n",
      "Test set: Average loss: 3.1517, Accuracy: 2489/5000 (50%)\n",
      "[epoch 45] loss: 0.0013363\n",
      "Test set: Average loss: 3.1649, Accuracy: 2490/5000 (50%)\n",
      "[epoch 46] loss: 0.0012927\n",
      "Test set: Average loss: 3.1819, Accuracy: 2490/5000 (50%)\n",
      "[epoch 47] loss: 0.0012453\n",
      "Test set: Average loss: 3.1951, Accuracy: 2490/5000 (50%)\n",
      "[epoch 48] loss: 0.0012070\n",
      "Test set: Average loss: 3.2081, Accuracy: 2493/5000 (50%)\n",
      "[epoch 49] loss: 0.0011263\n",
      "Test set: Average loss: 3.2205, Accuracy: 2487/5000 (50%)\n",
      "[epoch 50] loss: 0.0011076\n",
      "Test set: Average loss: 3.2288, Accuracy: 2485/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5915, Accuracy: 2561/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.5723, Accuracy: 5180/10000 (52%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3035, Accuracy: 520/5000 (10%)\n",
      "[epoch 1] loss: 2.0178964\n",
      "Test set: Average loss: 1.8904, Accuracy: 1478/5000 (30%)\n",
      "[epoch 2] loss: 1.5343776\n",
      "Test set: Average loss: 1.9001, Accuracy: 1525/5000 (30%)\n",
      "[epoch 3] loss: 1.3272810\n",
      "Test set: Average loss: 1.5106, Accuracy: 2287/5000 (46%)\n",
      "[epoch 4] loss: 1.0986005\n",
      "Test set: Average loss: 1.5191, Accuracy: 2383/5000 (48%)\n",
      "[epoch 5] loss: 0.9457744\n",
      "Test set: Average loss: 1.6567, Accuracy: 2155/5000 (43%)\n",
      "[epoch 6] loss: 0.8683239\n",
      "Test set: Average loss: 1.7178, Accuracy: 2239/5000 (45%)\n",
      "[epoch 7] loss: 0.7444539\n",
      "Test set: Average loss: 1.6903, Accuracy: 2196/5000 (44%)\n",
      "[epoch 8] loss: 0.5489028\n",
      "Test set: Average loss: 1.6561, Accuracy: 2410/5000 (48%)\n",
      "[epoch 9] loss: 0.3899480\n",
      "Test set: Average loss: 1.6844, Accuracy: 2521/5000 (50%)\n",
      "[epoch 10] loss: 0.2862464\n",
      "Test set: Average loss: 1.8499, Accuracy: 2414/5000 (48%)\n",
      "[epoch 11] loss: 0.2402276\n",
      "Test set: Average loss: 1.9076, Accuracy: 2497/5000 (50%)\n",
      "[epoch 12] loss: 0.1879999\n",
      "Test set: Average loss: 2.0128, Accuracy: 2501/5000 (50%)\n",
      "[epoch 13] loss: 0.1245667\n",
      "Test set: Average loss: 2.1715, Accuracy: 2460/5000 (49%)\n",
      "[epoch 14] loss: 0.0945360\n",
      "Test set: Average loss: 2.2325, Accuracy: 2447/5000 (49%)\n",
      "[epoch 15] loss: 0.0632164\n",
      "Test set: Average loss: 2.2485, Accuracy: 2443/5000 (49%)\n",
      "[epoch 16] loss: 0.0494256\n",
      "Test set: Average loss: 2.5249, Accuracy: 2407/5000 (48%)\n",
      "[epoch 17] loss: 0.0566675\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.5852, Accuracy: 2370/5000 (47%)\n",
      "[epoch 18] loss: 0.0347912\n",
      "Test set: Average loss: 2.4341, Accuracy: 2465/5000 (49%)\n",
      "[epoch 19] loss: 0.0152606\n",
      "Test set: Average loss: 2.4167, Accuracy: 2485/5000 (50%)\n",
      "[epoch 20] loss: 0.0140955\n",
      "Test set: Average loss: 2.4211, Accuracy: 2481/5000 (50%)\n",
      "[epoch 21] loss: 0.0130887\n",
      "Test set: Average loss: 2.4269, Accuracy: 2489/5000 (50%)\n",
      "[epoch 22] loss: 0.0123690\n",
      "Test set: Average loss: 2.4282, Accuracy: 2488/5000 (50%)\n",
      "[epoch 23] loss: 0.0117835\n",
      "Test set: Average loss: 2.4319, Accuracy: 2487/5000 (50%)\n",
      "[epoch 24] loss: 0.0113060\n",
      "Test set: Average loss: 2.4382, Accuracy: 2493/5000 (50%)\n",
      "[epoch 25] loss: 0.0110320\n",
      "Test set: Average loss: 2.4450, Accuracy: 2484/5000 (50%)\n",
      "[epoch 26] loss: 0.0106713\n",
      "Test set: Average loss: 2.4525, Accuracy: 2485/5000 (50%)\n",
      "[epoch 27] loss: 0.0103887\n",
      "Test set: Average loss: 2.4601, Accuracy: 2481/5000 (50%)\n",
      "[epoch 28] loss: 0.0101758\n",
      "Test set: Average loss: 2.4663, Accuracy: 2485/5000 (50%)\n",
      "[epoch 29] loss: 0.0098265\n",
      "Test set: Average loss: 2.4721, Accuracy: 2488/5000 (50%)\n",
      "[epoch 30] loss: 0.0097544\n",
      "Test set: Average loss: 2.4789, Accuracy: 2486/5000 (50%)\n",
      "[epoch 31] loss: 0.0094796\n",
      "Test set: Average loss: 2.4863, Accuracy: 2483/5000 (50%)\n",
      "[epoch 32] loss: 0.0091715\n",
      "Test set: Average loss: 2.4932, Accuracy: 2489/5000 (50%)\n",
      "[epoch 33] loss: 0.0090652\n",
      "Test set: Average loss: 2.5001, Accuracy: 2483/5000 (50%)\n",
      "[epoch 34] loss: 0.0087697\n",
      "Test set: Average loss: 2.5070, Accuracy: 2482/5000 (50%)\n",
      "[epoch 35] loss: 0.0085957\n",
      "Test set: Average loss: 2.5125, Accuracy: 2481/5000 (50%)\n",
      "[epoch 36] loss: 0.0084851\n",
      "Test set: Average loss: 2.5222, Accuracy: 2476/5000 (50%)\n",
      "[epoch 37] loss: 0.0081956\n",
      "Test set: Average loss: 2.5267, Accuracy: 2473/5000 (49%)\n",
      "[epoch 38] loss: 0.0080955\n",
      "Test set: Average loss: 2.5344, Accuracy: 2475/5000 (50%)\n",
      "[epoch 39] loss: 0.0079359\n",
      "Test set: Average loss: 2.5405, Accuracy: 2476/5000 (50%)\n",
      "[epoch 40] loss: 0.0077500\n",
      "Test set: Average loss: 2.5462, Accuracy: 2474/5000 (49%)\n",
      "[epoch 41] loss: 0.0075627\n",
      "Test set: Average loss: 2.5542, Accuracy: 2478/5000 (50%)\n",
      "[epoch 42] loss: 0.0073825\n",
      "Test set: Average loss: 2.5607, Accuracy: 2477/5000 (50%)\n",
      "[epoch 43] loss: 0.0072466\n",
      "Test set: Average loss: 2.5678, Accuracy: 2473/5000 (49%)\n",
      "[epoch 44] loss: 0.0073102\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.5732, Accuracy: 2468/5000 (49%)\n",
      "[epoch 45] loss: 0.0070645\n",
      "Test set: Average loss: 2.5740, Accuracy: 2472/5000 (49%)\n",
      "[epoch 46] loss: 0.0069767\n",
      "Test set: Average loss: 2.5748, Accuracy: 2472/5000 (49%)\n",
      "[epoch 47] loss: 0.0070535\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5756, Accuracy: 2473/5000 (49%)\n",
      "[epoch 48] loss: 0.0069073\n",
      "Test set: Average loss: 2.5757, Accuracy: 2472/5000 (49%)\n",
      "[epoch 49] loss: 0.0069451\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5757, Accuracy: 2472/5000 (49%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.0069386\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5758, Accuracy: 2472/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.6844, Accuracy: 2521/5000 (50%)\n",
      "Test\n",
      "Test set: Average loss: 1.6161, Accuracy: 5225/10000 (52%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3024, Accuracy: 639/5000 (13%)\n",
      "[epoch 1] loss: 2.0851583\n",
      "Test set: Average loss: 1.8777, Accuracy: 1554/5000 (31%)\n",
      "[epoch 2] loss: 1.6883141\n",
      "Test set: Average loss: 1.6275, Accuracy: 2133/5000 (43%)\n",
      "[epoch 3] loss: 1.4759557\n",
      "Test set: Average loss: 1.5455, Accuracy: 2226/5000 (45%)\n",
      "[epoch 4] loss: 1.2800748\n",
      "Test set: Average loss: 1.5125, Accuracy: 2408/5000 (48%)\n",
      "[epoch 5] loss: 1.0348374\n",
      "Test set: Average loss: 1.4949, Accuracy: 2460/5000 (49%)\n",
      "[epoch 6] loss: 0.9428523\n",
      "Test set: Average loss: 1.5391, Accuracy: 2416/5000 (48%)\n",
      "[epoch 7] loss: 0.7624392\n",
      "Test set: Average loss: 1.5505, Accuracy: 2503/5000 (50%)\n",
      "[epoch 8] loss: 0.5989467\n",
      "Test set: Average loss: 1.6137, Accuracy: 2479/5000 (50%)\n",
      "[epoch 9] loss: 0.4614045\n",
      "Test set: Average loss: 1.8386, Accuracy: 2381/5000 (48%)\n",
      "[epoch 10] loss: 0.3678262\n",
      "Test set: Average loss: 1.8855, Accuracy: 2399/5000 (48%)\n",
      "[epoch 11] loss: 0.2697983\n",
      "Test set: Average loss: 1.9256, Accuracy: 2480/5000 (50%)\n",
      "[epoch 12] loss: 0.2165635\n",
      "Test set: Average loss: 2.0285, Accuracy: 2418/5000 (48%)\n",
      "[epoch 13] loss: 0.1636088\n",
      "Test set: Average loss: 2.1925, Accuracy: 2451/5000 (49%)\n",
      "[epoch 14] loss: 0.0869318\n",
      "Test set: Average loss: 2.3173, Accuracy: 2398/5000 (48%)\n",
      "[epoch 15] loss: 0.0542444\n",
      "Test set: Average loss: 2.3786, Accuracy: 2448/5000 (49%)\n",
      "[epoch 16] loss: 0.0359722\n",
      "Test set: Average loss: 2.5645, Accuracy: 2395/5000 (48%)\n",
      "[epoch 17] loss: 0.0303865\n",
      "Test set: Average loss: 2.6563, Accuracy: 2379/5000 (48%)\n",
      "[epoch 18] loss: 0.0230997\n",
      "Test set: Average loss: 2.6399, Accuracy: 2414/5000 (48%)\n",
      "[epoch 19] loss: 0.0125494\n",
      "Test set: Average loss: 2.7017, Accuracy: 2408/5000 (48%)\n",
      "[epoch 20] loss: 0.0078249\n",
      "Test set: Average loss: 2.7298, Accuracy: 2442/5000 (49%)\n",
      "[epoch 21] loss: 0.0062095\n",
      "Test set: Average loss: 2.7646, Accuracy: 2428/5000 (49%)\n",
      "[epoch 22] loss: 0.0050930\n",
      "Test set: Average loss: 2.8089, Accuracy: 2426/5000 (49%)\n",
      "[epoch 23] loss: 0.0045994\n",
      "Test set: Average loss: 2.8260, Accuracy: 2421/5000 (48%)\n",
      "[epoch 24] loss: 0.0042096\n",
      "Test set: Average loss: 2.8572, Accuracy: 2429/5000 (49%)\n",
      "[epoch 25] loss: 0.0038097\n",
      "Test set: Average loss: 2.8826, Accuracy: 2434/5000 (49%)\n",
      "[epoch 26] loss: 0.0034692\n",
      "Test set: Average loss: 2.9078, Accuracy: 2427/5000 (49%)\n",
      "[epoch 27] loss: 0.0031694\n",
      "Test set: Average loss: 2.9291, Accuracy: 2423/5000 (48%)\n",
      "[epoch 28] loss: 0.0029477\n",
      "Test set: Average loss: 2.9489, Accuracy: 2428/5000 (49%)\n",
      "[epoch 29] loss: 0.0027805\n",
      "Test set: Average loss: 2.9714, Accuracy: 2423/5000 (48%)\n",
      "[epoch 30] loss: 0.0026436\n",
      "Test set: Average loss: 2.9886, Accuracy: 2428/5000 (49%)\n",
      "[epoch 31] loss: 0.0024162\n",
      "Test set: Average loss: 3.0142, Accuracy: 2427/5000 (49%)\n",
      "[epoch 32] loss: 0.0022598\n",
      "Test set: Average loss: 3.0291, Accuracy: 2428/5000 (49%)\n",
      "[epoch 33] loss: 0.0021842\n",
      "Test set: Average loss: 3.0458, Accuracy: 2429/5000 (49%)\n",
      "[epoch 34] loss: 0.0020366\n",
      "Test set: Average loss: 3.0654, Accuracy: 2433/5000 (49%)\n",
      "[epoch 35] loss: 0.0019191\n",
      "Test set: Average loss: 3.0810, Accuracy: 2432/5000 (49%)\n",
      "[epoch 36] loss: 0.0018288\n",
      "Test set: Average loss: 3.0959, Accuracy: 2428/5000 (49%)\n",
      "[epoch 37] loss: 0.0017471\n",
      "Test set: Average loss: 3.1167, Accuracy: 2431/5000 (49%)\n",
      "[epoch 38] loss: 0.0016395\n",
      "Test set: Average loss: 3.1320, Accuracy: 2427/5000 (49%)\n",
      "[epoch 39] loss: 0.0015627\n",
      "Test set: Average loss: 3.1435, Accuracy: 2432/5000 (49%)\n",
      "[epoch 40] loss: 0.0014899\n",
      "Test set: Average loss: 3.1589, Accuracy: 2429/5000 (49%)\n",
      "[epoch 41] loss: 0.0014155\n",
      "Test set: Average loss: 3.1728, Accuracy: 2435/5000 (49%)\n",
      "[epoch 42] loss: 0.0013583\n",
      "Test set: Average loss: 3.1889, Accuracy: 2437/5000 (49%)\n",
      "[epoch 43] loss: 0.0012971\n",
      "Test set: Average loss: 3.2020, Accuracy: 2435/5000 (49%)\n",
      "[epoch 44] loss: 0.0012503\n",
      "Test set: Average loss: 3.2149, Accuracy: 2430/5000 (49%)\n",
      "[epoch 45] loss: 0.0011924\n",
      "Test set: Average loss: 3.2321, Accuracy: 2428/5000 (49%)\n",
      "[epoch 46] loss: 0.0011590\n",
      "Test set: Average loss: 3.2420, Accuracy: 2435/5000 (49%)\n",
      "[epoch 47] loss: 0.0011069\n",
      "Test set: Average loss: 3.2508, Accuracy: 2427/5000 (49%)\n",
      "[epoch 48] loss: 0.0010615\n",
      "Test set: Average loss: 3.2670, Accuracy: 2427/5000 (49%)\n",
      "[epoch 49] loss: 0.0010214\n",
      "Test set: Average loss: 3.2804, Accuracy: 2428/5000 (49%)\n",
      "[epoch 50] loss: 0.0009821\n",
      "Test set: Average loss: 3.2891, Accuracy: 2424/5000 (48%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5505, Accuracy: 2503/5000 (50%)\n",
      "Test\n",
      "Test set: Average loss: 1.5565, Accuracy: 4925/10000 (49%)\n",
      "750\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3045, Accuracy: 525/5000 (10%)\n",
      "[epoch 1] loss: 2.0130308\n",
      "Test set: Average loss: 1.7296, Accuracy: 1992/5000 (40%)\n",
      "[epoch 2] loss: 1.5323054\n",
      "Test set: Average loss: 1.4702, Accuracy: 2421/5000 (48%)\n",
      "[epoch 3] loss: 1.2334135\n",
      "Test set: Average loss: 1.4308, Accuracy: 2564/5000 (51%)\n",
      "[epoch 4] loss: 1.0720804\n",
      "Test set: Average loss: 1.3415, Accuracy: 2694/5000 (54%)\n",
      "[epoch 5] loss: 0.9689155\n",
      "Test set: Average loss: 1.4530, Accuracy: 2560/5000 (51%)\n",
      "[epoch 6] loss: 0.8115760\n",
      "Test set: Average loss: 1.4737, Accuracy: 2607/5000 (52%)\n",
      "[epoch 7] loss: 0.6543456\n",
      "Test set: Average loss: 1.5307, Accuracy: 2623/5000 (52%)\n",
      "[epoch 8] loss: 0.5778250\n",
      "Test set: Average loss: 1.6506, Accuracy: 2528/5000 (51%)\n",
      "[epoch 9] loss: 0.4915028\n",
      "Test set: Average loss: 1.7854, Accuracy: 2526/5000 (51%)\n",
      "[epoch 10] loss: 0.4359038\n",
      "Test set: Average loss: 1.9893, Accuracy: 2458/5000 (49%)\n",
      "[epoch 11] loss: 0.3105435\n",
      "Test set: Average loss: 1.9489, Accuracy: 2494/5000 (50%)\n",
      "[epoch 12] loss: 0.2740639\n",
      "Test set: Average loss: 2.1316, Accuracy: 2536/5000 (51%)\n",
      "[epoch 13] loss: 0.2253291\n",
      "Test set: Average loss: 2.2815, Accuracy: 2451/5000 (49%)\n",
      "[epoch 14] loss: 0.2035453\n",
      "Test set: Average loss: 2.2711, Accuracy: 2464/5000 (49%)\n",
      "[epoch 15] loss: 0.1196004\n",
      "Test set: Average loss: 2.3049, Accuracy: 2569/5000 (51%)\n",
      "[epoch 16] loss: 0.0820208\n",
      "Test set: Average loss: 2.5356, Accuracy: 2522/5000 (50%)\n",
      "[epoch 17] loss: 0.0670298\n",
      "Test set: Average loss: 2.6163, Accuracy: 2487/5000 (50%)\n",
      "[epoch 18] loss: 0.0532119\n",
      "Test set: Average loss: 2.7742, Accuracy: 2431/5000 (49%)\n",
      "[epoch 19] loss: 0.0425674\n",
      "Test set: Average loss: 2.8374, Accuracy: 2486/5000 (50%)\n",
      "[epoch 20] loss: 0.0214875\n",
      "Test set: Average loss: 2.7651, Accuracy: 2508/5000 (50%)\n",
      "[epoch 21] loss: 0.0097135\n",
      "Test set: Average loss: 2.8046, Accuracy: 2515/5000 (50%)\n",
      "[epoch 22] loss: 0.0067672\n",
      "Test set: Average loss: 2.8596, Accuracy: 2506/5000 (50%)\n",
      "[epoch 23] loss: 0.0053666\n",
      "Test set: Average loss: 2.8922, Accuracy: 2508/5000 (50%)\n",
      "[epoch 24] loss: 0.0045178\n",
      "Test set: Average loss: 2.9325, Accuracy: 2512/5000 (50%)\n",
      "[epoch 25] loss: 0.0041200\n",
      "Test set: Average loss: 2.9567, Accuracy: 2509/5000 (50%)\n",
      "[epoch 26] loss: 0.0038674\n",
      "Test set: Average loss: 2.9762, Accuracy: 2522/5000 (50%)\n",
      "[epoch 27] loss: 0.0034388\n",
      "Test set: Average loss: 3.0009, Accuracy: 2511/5000 (50%)\n",
      "[epoch 28] loss: 0.0031339\n",
      "Test set: Average loss: 3.0242, Accuracy: 2513/5000 (50%)\n",
      "[epoch 29] loss: 0.0028860\n",
      "Test set: Average loss: 3.0533, Accuracy: 2514/5000 (50%)\n",
      "[epoch 30] loss: 0.0026974\n",
      "Test set: Average loss: 3.0675, Accuracy: 2518/5000 (50%)\n",
      "[epoch 31] loss: 0.0024925\n",
      "Test set: Average loss: 3.0918, Accuracy: 2522/5000 (50%)\n",
      "[epoch 32] loss: 0.0023189\n",
      "Test set: Average loss: 3.1065, Accuracy: 2515/5000 (50%)\n",
      "[epoch 33] loss: 0.0021883\n",
      "Test set: Average loss: 3.1245, Accuracy: 2514/5000 (50%)\n",
      "[epoch 34] loss: 0.0020398\n",
      "Test set: Average loss: 3.1497, Accuracy: 2511/5000 (50%)\n",
      "[epoch 35] loss: 0.0019327\n",
      "Test set: Average loss: 3.1647, Accuracy: 2512/5000 (50%)\n",
      "[epoch 36] loss: 0.0018324\n",
      "Test set: Average loss: 3.1765, Accuracy: 2510/5000 (50%)\n",
      "[epoch 37] loss: 0.0017534\n",
      "Test set: Average loss: 3.1910, Accuracy: 2516/5000 (50%)\n",
      "[epoch 38] loss: 0.0016512\n",
      "Test set: Average loss: 3.2127, Accuracy: 2507/5000 (50%)\n",
      "[epoch 39] loss: 0.0015380\n",
      "Test set: Average loss: 3.2293, Accuracy: 2509/5000 (50%)\n",
      "[epoch 40] loss: 0.0014821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 3.2432, Accuracy: 2504/5000 (50%)\n",
      "[epoch 41] loss: 0.0014072\n",
      "Test set: Average loss: 3.2568, Accuracy: 2501/5000 (50%)\n",
      "[epoch 42] loss: 0.0013428\n",
      "Test set: Average loss: 3.2731, Accuracy: 2500/5000 (50%)\n",
      "[epoch 43] loss: 0.0012864\n",
      "Test set: Average loss: 3.2866, Accuracy: 2504/5000 (50%)\n",
      "[epoch 44] loss: 0.0012231\n",
      "Test set: Average loss: 3.2952, Accuracy: 2501/5000 (50%)\n",
      "[epoch 45] loss: 0.0011861\n",
      "Test set: Average loss: 3.3115, Accuracy: 2506/5000 (50%)\n",
      "[epoch 46] loss: 0.0011309\n",
      "Test set: Average loss: 3.3296, Accuracy: 2503/5000 (50%)\n",
      "[epoch 47] loss: 0.0010910\n",
      "Test set: Average loss: 3.3417, Accuracy: 2508/5000 (50%)\n",
      "[epoch 48] loss: 0.0010352\n",
      "Test set: Average loss: 3.3484, Accuracy: 2505/5000 (50%)\n",
      "[epoch 49] loss: 0.0009859\n",
      "Test set: Average loss: 3.3641, Accuracy: 2497/5000 (50%)\n",
      "[epoch 50] loss: 0.0009486\n",
      "Test set: Average loss: 3.3796, Accuracy: 2495/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3415, Accuracy: 2694/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.3206, Accuracy: 5385/10000 (54%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3027, Accuracy: 498/5000 (10%)\n",
      "[epoch 1] loss: 1.9043512\n",
      "Test set: Average loss: 1.6674, Accuracy: 1923/5000 (38%)\n",
      "[epoch 2] loss: 1.3643329\n",
      "Test set: Average loss: 1.4860, Accuracy: 2423/5000 (48%)\n",
      "[epoch 3] loss: 1.1044326\n",
      "Test set: Average loss: 1.3968, Accuracy: 2562/5000 (51%)\n",
      "[epoch 4] loss: 0.8962594\n",
      "Test set: Average loss: 1.6314, Accuracy: 2362/5000 (47%)\n",
      "[epoch 5] loss: 0.8198998\n",
      "Test set: Average loss: 1.5432, Accuracy: 2456/5000 (49%)\n",
      "[epoch 6] loss: 0.6673060\n",
      "Test set: Average loss: 1.5983, Accuracy: 2501/5000 (50%)\n",
      "[epoch 7] loss: 0.5987747\n",
      "Test set: Average loss: 1.6632, Accuracy: 2493/5000 (50%)\n",
      "[epoch 8] loss: 0.4281467\n",
      "Test set: Average loss: 1.7039, Accuracy: 2588/5000 (52%)\n",
      "[epoch 9] loss: 0.3498295\n",
      "Test set: Average loss: 1.8232, Accuracy: 2563/5000 (51%)\n",
      "[epoch 10] loss: 0.2512876\n",
      "Test set: Average loss: 2.1957, Accuracy: 2390/5000 (48%)\n",
      "[epoch 11] loss: 0.1937019\n",
      "Test set: Average loss: 2.1115, Accuracy: 2475/5000 (50%)\n",
      "[epoch 12] loss: 0.1675831\n",
      "Test set: Average loss: 2.2353, Accuracy: 2496/5000 (50%)\n",
      "[epoch 13] loss: 0.1109585\n",
      "Test set: Average loss: 2.3808, Accuracy: 2461/5000 (49%)\n",
      "[epoch 14] loss: 0.0845250\n",
      "Test set: Average loss: 2.5249, Accuracy: 2510/5000 (50%)\n",
      "[epoch 15] loss: 0.0573211\n",
      "Test set: Average loss: 2.6031, Accuracy: 2475/5000 (50%)\n",
      "[epoch 16] loss: 0.0279338\n",
      "Test set: Average loss: 2.6454, Accuracy: 2516/5000 (50%)\n",
      "[epoch 17] loss: 0.0154117\n",
      "Test set: Average loss: 2.7091, Accuracy: 2525/5000 (50%)\n",
      "[epoch 18] loss: 0.0094809\n",
      "Test set: Average loss: 2.7663, Accuracy: 2520/5000 (50%)\n",
      "[epoch 19] loss: 0.0068378\n",
      "Test set: Average loss: 2.8248, Accuracy: 2514/5000 (50%)\n",
      "[epoch 20] loss: 0.0054964\n",
      "Test set: Average loss: 2.8589, Accuracy: 2528/5000 (51%)\n",
      "[epoch 21] loss: 0.0048304\n",
      "Test set: Average loss: 2.8925, Accuracy: 2533/5000 (51%)\n",
      "[epoch 22] loss: 0.0042474\n",
      "Test set: Average loss: 2.9289, Accuracy: 2519/5000 (50%)\n",
      "[epoch 23] loss: 0.0038573\n",
      "Test set: Average loss: 2.9622, Accuracy: 2513/5000 (50%)\n",
      "[epoch 24] loss: 0.0034339\n",
      "Test set: Average loss: 2.9929, Accuracy: 2515/5000 (50%)\n",
      "[epoch 25] loss: 0.0032354\n",
      "Test set: Average loss: 3.0181, Accuracy: 2532/5000 (51%)\n",
      "[epoch 26] loss: 0.0029469\n",
      "Test set: Average loss: 3.0431, Accuracy: 2510/5000 (50%)\n",
      "[epoch 27] loss: 0.0026986\n",
      "Test set: Average loss: 3.0694, Accuracy: 2515/5000 (50%)\n",
      "[epoch 28] loss: 0.0025236\n",
      "Test set: Average loss: 3.0964, Accuracy: 2497/5000 (50%)\n",
      "[epoch 29] loss: 0.0022976\n",
      "Test set: Average loss: 3.1142, Accuracy: 2516/5000 (50%)\n",
      "[epoch 30] loss: 0.0021746\n",
      "Test set: Average loss: 3.1345, Accuracy: 2507/5000 (50%)\n",
      "[epoch 31] loss: 0.0020257\n",
      "Test set: Average loss: 3.1566, Accuracy: 2510/5000 (50%)\n",
      "[epoch 32] loss: 0.0018754\n",
      "Test set: Average loss: 3.1742, Accuracy: 2511/5000 (50%)\n",
      "[epoch 33] loss: 0.0017705\n",
      "Test set: Average loss: 3.1956, Accuracy: 2516/5000 (50%)\n",
      "[epoch 34] loss: 0.0016669\n",
      "Test set: Average loss: 3.2314, Accuracy: 2499/5000 (50%)\n",
      "[epoch 35] loss: 0.0015609\n",
      "Test set: Average loss: 3.2338, Accuracy: 2514/5000 (50%)\n",
      "[epoch 36] loss: 0.0014853\n",
      "Test set: Average loss: 3.2484, Accuracy: 2504/5000 (50%)\n",
      "[epoch 37] loss: 0.0014219\n",
      "Test set: Average loss: 3.2671, Accuracy: 2510/5000 (50%)\n",
      "[epoch 38] loss: 0.0013491\n",
      "Test set: Average loss: 3.2790, Accuracy: 2514/5000 (50%)\n",
      "[epoch 39] loss: 0.0012707\n",
      "Test set: Average loss: 3.2980, Accuracy: 2504/5000 (50%)\n",
      "[epoch 40] loss: 0.0011986\n",
      "Test set: Average loss: 3.3125, Accuracy: 2513/5000 (50%)\n",
      "[epoch 41] loss: 0.0011673\n",
      "Test set: Average loss: 3.3304, Accuracy: 2503/5000 (50%)\n",
      "[epoch 42] loss: 0.0011184\n",
      "Test set: Average loss: 3.3416, Accuracy: 2505/5000 (50%)\n",
      "[epoch 43] loss: 0.0010607\n",
      "Test set: Average loss: 3.3576, Accuracy: 2508/5000 (50%)\n",
      "[epoch 44] loss: 0.0010047\n",
      "Test set: Average loss: 3.3706, Accuracy: 2507/5000 (50%)\n",
      "[epoch 45] loss: 0.0009707\n",
      "Test set: Average loss: 3.3842, Accuracy: 2507/5000 (50%)\n",
      "[epoch 46] loss: 0.0009279\n",
      "Test set: Average loss: 3.3998, Accuracy: 2508/5000 (50%)\n",
      "[epoch 47] loss: 0.0009162\n",
      "Test set: Average loss: 3.4124, Accuracy: 2502/5000 (50%)\n",
      "[epoch 48] loss: 0.0008652\n",
      "Test set: Average loss: 3.4220, Accuracy: 2505/5000 (50%)\n",
      "[epoch 49] loss: 0.0008250\n",
      "Test set: Average loss: 3.4369, Accuracy: 2500/5000 (50%)\n",
      "[epoch 50] loss: 0.0007780\n",
      "Test set: Average loss: 3.4506, Accuracy: 2504/5000 (50%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.7039, Accuracy: 2588/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.6617, Accuracy: 5198/10000 (52%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 610/5000 (12%)\n",
      "[epoch 1] loss: 1.9989975\n",
      "Test set: Average loss: 1.7072, Accuracy: 1960/5000 (39%)\n",
      "[epoch 2] loss: 1.6171569\n",
      "Test set: Average loss: 1.5146, Accuracy: 2294/5000 (46%)\n",
      "[epoch 3] loss: 1.3292071\n",
      "Test set: Average loss: 1.4318, Accuracy: 2433/5000 (49%)\n",
      "[epoch 4] loss: 1.2006423\n",
      "Test set: Average loss: 1.4570, Accuracy: 2354/5000 (47%)\n",
      "[epoch 5] loss: 1.0793245\n",
      "Test set: Average loss: 1.4488, Accuracy: 2500/5000 (50%)\n",
      "[epoch 6] loss: 0.8683209\n",
      "Test set: Average loss: 1.4698, Accuracy: 2542/5000 (51%)\n",
      "[epoch 7] loss: 0.7348130\n",
      "Test set: Average loss: 1.6008, Accuracy: 2418/5000 (48%)\n",
      "[epoch 8] loss: 0.6157940\n",
      "Test set: Average loss: 1.7322, Accuracy: 2473/5000 (49%)\n",
      "[epoch 9] loss: 0.4952010\n",
      "Test set: Average loss: 1.8447, Accuracy: 2394/5000 (48%)\n",
      "[epoch 10] loss: 0.3726361\n",
      "Test set: Average loss: 2.0303, Accuracy: 2326/5000 (47%)\n",
      "[epoch 11] loss: 0.4404057\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1131, Accuracy: 2355/5000 (47%)\n",
      "[epoch 12] loss: 0.2117184\n",
      "Test set: Average loss: 1.9592, Accuracy: 2427/5000 (49%)\n",
      "[epoch 13] loss: 0.1301922\n",
      "Test set: Average loss: 1.9615, Accuracy: 2463/5000 (49%)\n",
      "[epoch 14] loss: 0.1131772\n",
      "Test set: Average loss: 1.9885, Accuracy: 2466/5000 (49%)\n",
      "[epoch 15] loss: 0.1041478\n",
      "Test set: Average loss: 2.0106, Accuracy: 2464/5000 (49%)\n",
      "[epoch 16] loss: 0.0935239\n",
      "Test set: Average loss: 2.0306, Accuracy: 2472/5000 (49%)\n",
      "[epoch 17] loss: 0.0857524\n",
      "Test set: Average loss: 2.0552, Accuracy: 2476/5000 (50%)\n",
      "[epoch 18] loss: 0.0792952\n",
      "Test set: Average loss: 2.0902, Accuracy: 2461/5000 (49%)\n",
      "[epoch 19] loss: 0.0738757\n",
      "Test set: Average loss: 2.0959, Accuracy: 2462/5000 (49%)\n",
      "[epoch 20] loss: 0.0686432\n",
      "Test set: Average loss: 2.1191, Accuracy: 2458/5000 (49%)\n",
      "[epoch 21] loss: 0.0645606\n",
      "Test set: Average loss: 2.1379, Accuracy: 2464/5000 (49%)\n",
      "[epoch 22] loss: 0.0609154\n",
      "Test set: Average loss: 2.1606, Accuracy: 2452/5000 (49%)\n",
      "[epoch 23] loss: 0.0581027\n",
      "Test set: Average loss: 2.1769, Accuracy: 2453/5000 (49%)\n",
      "[epoch 24] loss: 0.0542645\n",
      "Test set: Average loss: 2.1947, Accuracy: 2461/5000 (49%)\n",
      "[epoch 25] loss: 0.0515901\n",
      "Test set: Average loss: 2.2118, Accuracy: 2468/5000 (49%)\n",
      "[epoch 26] loss: 0.0479662\n",
      "Test set: Average loss: 2.2337, Accuracy: 2464/5000 (49%)\n",
      "[epoch 27] loss: 0.0456261\n",
      "Test set: Average loss: 2.2480, Accuracy: 2473/5000 (49%)\n",
      "[epoch 28] loss: 0.0424834\n",
      "Test set: Average loss: 2.2651, Accuracy: 2468/5000 (49%)\n",
      "[epoch 29] loss: 0.0404720\n",
      "Test set: Average loss: 2.2889, Accuracy: 2472/5000 (49%)\n",
      "[epoch 30] loss: 0.0384215\n",
      "Test set: Average loss: 2.3011, Accuracy: 2476/5000 (50%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0362639\n",
      "Test set: Average loss: 2.3176, Accuracy: 2479/5000 (50%)\n",
      "[epoch 32] loss: 0.0347078\n",
      "Test set: Average loss: 2.3360, Accuracy: 2472/5000 (49%)\n",
      "[epoch 33] loss: 0.0328511\n",
      "Test set: Average loss: 2.3546, Accuracy: 2475/5000 (50%)\n",
      "[epoch 34] loss: 0.0310061\n",
      "Test set: Average loss: 2.3691, Accuracy: 2473/5000 (49%)\n",
      "[epoch 35] loss: 0.0297738\n",
      "Test set: Average loss: 2.3849, Accuracy: 2483/5000 (50%)\n",
      "[epoch 36] loss: 0.0280078\n",
      "Test set: Average loss: 2.4003, Accuracy: 2471/5000 (49%)\n",
      "[epoch 37] loss: 0.0270866\n",
      "Test set: Average loss: 2.4145, Accuracy: 2476/5000 (50%)\n",
      "[epoch 38] loss: 0.0257883\n",
      "Test set: Average loss: 2.4284, Accuracy: 2478/5000 (50%)\n",
      "[epoch 39] loss: 0.0246030\n",
      "Test set: Average loss: 2.4484, Accuracy: 2479/5000 (50%)\n",
      "[epoch 40] loss: 0.0232943\n",
      "Test set: Average loss: 2.4630, Accuracy: 2480/5000 (50%)\n",
      "[epoch 41] loss: 0.0221757\n",
      "Test set: Average loss: 2.4775, Accuracy: 2478/5000 (50%)\n",
      "[epoch 42] loss: 0.0211715\n",
      "Test set: Average loss: 2.4913, Accuracy: 2479/5000 (50%)\n",
      "[epoch 43] loss: 0.0206534\n",
      "Test set: Average loss: 2.5086, Accuracy: 2474/5000 (49%)\n",
      "[epoch 44] loss: 0.0194743\n",
      "Test set: Average loss: 2.5204, Accuracy: 2485/5000 (50%)\n",
      "[epoch 45] loss: 0.0187631\n",
      "Test set: Average loss: 2.5348, Accuracy: 2480/5000 (50%)\n",
      "[epoch 46] loss: 0.0180160\n",
      "Test set: Average loss: 2.5477, Accuracy: 2485/5000 (50%)\n",
      "[epoch 47] loss: 0.0171366\n",
      "Test set: Average loss: 2.5631, Accuracy: 2475/5000 (50%)\n",
      "[epoch 48] loss: 0.0165107\n",
      "Test set: Average loss: 2.5754, Accuracy: 2480/5000 (50%)\n",
      "[epoch 49] loss: 0.0157317\n",
      "Test set: Average loss: 2.5871, Accuracy: 2473/5000 (49%)\n",
      "[epoch 50] loss: 0.0150747\n",
      "Test set: Average loss: 2.6046, Accuracy: 2474/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4698, Accuracy: 2542/5000 (51%)\n",
      "Test\n",
      "Test set: Average loss: 1.4568, Accuracy: 5103/10000 (51%)\n",
      "1000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3021, Accuracy: 570/5000 (11%)\n",
      "[epoch 1] loss: 1.8997071\n",
      "Test set: Average loss: 1.6284, Accuracy: 2116/5000 (42%)\n",
      "[epoch 2] loss: 1.3455567\n",
      "Test set: Average loss: 1.5375, Accuracy: 2421/5000 (48%)\n",
      "[epoch 3] loss: 1.2527803\n",
      "Test set: Average loss: 1.4920, Accuracy: 2428/5000 (49%)\n",
      "[epoch 4] loss: 1.0594175\n",
      "Test set: Average loss: 1.4597, Accuracy: 2435/5000 (49%)\n",
      "[epoch 5] loss: 0.8874000\n",
      "Test set: Average loss: 1.4322, Accuracy: 2651/5000 (53%)\n",
      "[epoch 6] loss: 0.7694888\n",
      "Test set: Average loss: 1.4170, Accuracy: 2677/5000 (54%)\n",
      "[epoch 7] loss: 0.6688794\n",
      "Test set: Average loss: 1.5484, Accuracy: 2611/5000 (52%)\n",
      "[epoch 8] loss: 0.6165952\n",
      "Test set: Average loss: 1.6441, Accuracy: 2554/5000 (51%)\n",
      "[epoch 9] loss: 0.4973081\n",
      "Test set: Average loss: 1.9136, Accuracy: 2424/5000 (48%)\n",
      "[epoch 10] loss: 0.4344198\n",
      "Test set: Average loss: 1.8927, Accuracy: 2532/5000 (51%)\n",
      "[epoch 11] loss: 0.3659477\n",
      "Test set: Average loss: 1.9394, Accuracy: 2517/5000 (50%)\n",
      "[epoch 12] loss: 0.2842033\n",
      "Test set: Average loss: 2.1900, Accuracy: 2443/5000 (49%)\n",
      "[epoch 13] loss: 0.2174235\n",
      "Test set: Average loss: 2.4129, Accuracy: 2378/5000 (48%)\n",
      "[epoch 14] loss: 0.2850513\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3794, Accuracy: 2410/5000 (48%)\n",
      "[epoch 15] loss: 0.1157252\n",
      "Test set: Average loss: 2.2844, Accuracy: 2486/5000 (50%)\n",
      "[epoch 16] loss: 0.0689387\n",
      "Test set: Average loss: 2.2907, Accuracy: 2520/5000 (50%)\n",
      "[epoch 17] loss: 0.0552010\n",
      "Test set: Average loss: 2.3168, Accuracy: 2537/5000 (51%)\n",
      "[epoch 18] loss: 0.0476137\n",
      "Test set: Average loss: 2.3339, Accuracy: 2545/5000 (51%)\n",
      "[epoch 19] loss: 0.0421452\n",
      "Test set: Average loss: 2.3530, Accuracy: 2543/5000 (51%)\n",
      "[epoch 20] loss: 0.0389166\n",
      "Test set: Average loss: 2.3709, Accuracy: 2535/5000 (51%)\n",
      "[epoch 21] loss: 0.0353442\n",
      "Test set: Average loss: 2.3905, Accuracy: 2537/5000 (51%)\n",
      "[epoch 22] loss: 0.0335846\n",
      "Test set: Average loss: 2.4085, Accuracy: 2528/5000 (51%)\n",
      "[epoch 23] loss: 0.0315547\n",
      "Test set: Average loss: 2.4236, Accuracy: 2529/5000 (51%)\n",
      "[epoch 24] loss: 0.0290887\n",
      "Test set: Average loss: 2.4415, Accuracy: 2535/5000 (51%)\n",
      "[epoch 25] loss: 0.0280348\n",
      "Test set: Average loss: 2.4581, Accuracy: 2548/5000 (51%)\n",
      "[epoch 26] loss: 0.0259800\n",
      "Test set: Average loss: 2.4760, Accuracy: 2537/5000 (51%)\n",
      "[epoch 27] loss: 0.0252883\n",
      "Test set: Average loss: 2.4892, Accuracy: 2532/5000 (51%)\n",
      "[epoch 28] loss: 0.0242646\n",
      "Test set: Average loss: 2.5056, Accuracy: 2531/5000 (51%)\n",
      "[epoch 29] loss: 0.0228108\n",
      "Test set: Average loss: 2.5246, Accuracy: 2539/5000 (51%)\n",
      "[epoch 30] loss: 0.0210088\n",
      "Test set: Average loss: 2.5337, Accuracy: 2534/5000 (51%)\n",
      "[epoch 31] loss: 0.0201516\n",
      "Test set: Average loss: 2.5501, Accuracy: 2534/5000 (51%)\n",
      "[epoch 32] loss: 0.0194041\n",
      "Test set: Average loss: 2.5658, Accuracy: 2537/5000 (51%)\n",
      "[epoch 33] loss: 0.0186182\n",
      "Test set: Average loss: 2.5792, Accuracy: 2534/5000 (51%)\n",
      "[epoch 34] loss: 0.0178564\n",
      "Test set: Average loss: 2.5899, Accuracy: 2539/5000 (51%)\n",
      "[epoch 35] loss: 0.0170559\n",
      "Test set: Average loss: 2.6054, Accuracy: 2537/5000 (51%)\n",
      "[epoch 36] loss: 0.0162241\n",
      "Test set: Average loss: 2.6197, Accuracy: 2538/5000 (51%)\n",
      "[epoch 37] loss: 0.0157255\n",
      "Test set: Average loss: 2.6345, Accuracy: 2537/5000 (51%)\n",
      "[epoch 38] loss: 0.0149213\n",
      "Test set: Average loss: 2.6466, Accuracy: 2538/5000 (51%)\n",
      "[epoch 39] loss: 0.0145201\n",
      "Test set: Average loss: 2.6599, Accuracy: 2537/5000 (51%)\n",
      "[epoch 40] loss: 0.0142296\n",
      "Test set: Average loss: 2.6727, Accuracy: 2537/5000 (51%)\n",
      "[epoch 41] loss: 0.0133327\n",
      "Test set: Average loss: 2.6866, Accuracy: 2535/5000 (51%)\n",
      "[epoch 42] loss: 0.0128851\n",
      "Test set: Average loss: 2.6981, Accuracy: 2541/5000 (51%)\n",
      "[epoch 43] loss: 0.0125064\n",
      "Test set: Average loss: 2.7102, Accuracy: 2535/5000 (51%)\n",
      "[epoch 44] loss: 0.0122542\n",
      "Test set: Average loss: 2.7239, Accuracy: 2533/5000 (51%)\n",
      "[epoch 45] loss: 0.0117460\n",
      "Test set: Average loss: 2.7345, Accuracy: 2537/5000 (51%)\n",
      "[epoch 46] loss: 0.0112713\n",
      "Test set: Average loss: 2.7458, Accuracy: 2535/5000 (51%)\n",
      "[epoch 47] loss: 0.0106916\n",
      "Test set: Average loss: 2.7592, Accuracy: 2527/5000 (51%)\n",
      "[epoch 48] loss: 0.0104195\n",
      "Test set: Average loss: 2.7707, Accuracy: 2531/5000 (51%)\n",
      "[epoch 49] loss: 0.0102465\n",
      "Test set: Average loss: 2.7805, Accuracy: 2528/5000 (51%)\n",
      "[epoch 50] loss: 0.0098260\n",
      "Test set: Average loss: 2.7948, Accuracy: 2533/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4170, Accuracy: 2677/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.4091, Accuracy: 5316/10000 (53%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3011, Accuracy: 513/5000 (10%)\n",
      "[epoch 1] loss: 1.8441165\n",
      "Test set: Average loss: 1.7666, Accuracy: 1875/5000 (38%)\n",
      "[epoch 2] loss: 1.3568326\n",
      "Test set: Average loss: 1.4864, Accuracy: 2407/5000 (48%)\n",
      "[epoch 3] loss: 1.1212749\n",
      "Test set: Average loss: 1.4975, Accuracy: 2352/5000 (47%)\n",
      "[epoch 4] loss: 1.0008425\n",
      "Test set: Average loss: 1.3992, Accuracy: 2607/5000 (52%)\n",
      "[epoch 5] loss: 0.8679194\n",
      "Test set: Average loss: 1.4066, Accuracy: 2655/5000 (53%)\n",
      "[epoch 6] loss: 0.7352078\n",
      "Test set: Average loss: 1.4918, Accuracy: 2637/5000 (53%)\n",
      "[epoch 7] loss: 0.5886302\n",
      "Test set: Average loss: 1.5964, Accuracy: 2594/5000 (52%)\n",
      "[epoch 8] loss: 0.4668439\n",
      "Test set: Average loss: 1.6778, Accuracy: 2617/5000 (52%)\n",
      "[epoch 9] loss: 0.3635062\n",
      "Test set: Average loss: 1.8966, Accuracy: 2518/5000 (50%)\n",
      "[epoch 10] loss: 0.3278332\n",
      "Test set: Average loss: 2.1860, Accuracy: 2413/5000 (48%)\n",
      "[epoch 11] loss: 0.3778372\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1474, Accuracy: 2447/5000 (49%)\n",
      "[epoch 12] loss: 0.1999364\n",
      "Test set: Average loss: 1.9771, Accuracy: 2563/5000 (51%)\n",
      "[epoch 13] loss: 0.1258974\n",
      "Test set: Average loss: 2.0140, Accuracy: 2576/5000 (52%)\n",
      "[epoch 14] loss: 0.1059858\n",
      "Test set: Average loss: 2.0480, Accuracy: 2567/5000 (51%)\n",
      "[epoch 15] loss: 0.0947815\n",
      "Test set: Average loss: 2.0699, Accuracy: 2572/5000 (51%)\n",
      "[epoch 16] loss: 0.0900845\n",
      "Test set: Average loss: 2.0889, Accuracy: 2563/5000 (51%)\n",
      "[epoch 17] loss: 0.0864144\n",
      "Test set: Average loss: 2.1117, Accuracy: 2564/5000 (51%)\n",
      "[epoch 18] loss: 0.0796165\n",
      "Test set: Average loss: 2.1372, Accuracy: 2575/5000 (52%)\n",
      "[epoch 19] loss: 0.0708886\n",
      "Test set: Average loss: 2.1640, Accuracy: 2555/5000 (51%)\n",
      "[epoch 20] loss: 0.0672229\n",
      "Test set: Average loss: 2.1818, Accuracy: 2553/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21] loss: 0.0636241\n",
      "Test set: Average loss: 2.1986, Accuracy: 2553/5000 (51%)\n",
      "[epoch 22] loss: 0.0589166\n",
      "Test set: Average loss: 2.2269, Accuracy: 2545/5000 (51%)\n",
      "[epoch 23] loss: 0.0558106\n",
      "Test set: Average loss: 2.2406, Accuracy: 2556/5000 (51%)\n",
      "[epoch 24] loss: 0.0514813\n",
      "Test set: Average loss: 2.2619, Accuracy: 2551/5000 (51%)\n",
      "[epoch 25] loss: 0.0562354\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.2835, Accuracy: 2534/5000 (51%)\n",
      "[epoch 26] loss: 0.0447564\n",
      "Test set: Average loss: 2.2856, Accuracy: 2536/5000 (51%)\n",
      "[epoch 27] loss: 0.0456459\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.2875, Accuracy: 2535/5000 (51%)\n",
      "[epoch 28] loss: 0.0440920\n",
      "Test set: Average loss: 2.2876, Accuracy: 2536/5000 (51%)\n",
      "[epoch 29] loss: 0.0444936\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 30] loss: 0.0436386\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 31] loss: 0.0441949\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 32] loss: 0.0435914\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 33] loss: 0.0445864\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 34] loss: 0.0437580\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 35] loss: 0.0447849\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 36] loss: 0.0435096\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 37] loss: 0.0445154\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 38] loss: 0.0440777\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 39] loss: 0.0438415\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 40] loss: 0.0439776\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 41] loss: 0.0438207\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 42] loss: 0.0444260\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 43] loss: 0.0447229\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 44] loss: 0.0438534\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 45] loss: 0.0432894\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 46] loss: 0.0438134\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 47] loss: 0.0433531\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 48] loss: 0.0444576\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 49] loss: 0.0443620\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "[epoch 50] loss: 0.0432750\n",
      "Test set: Average loss: 2.2879, Accuracy: 2535/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4066, Accuracy: 2655/5000 (53%)\n",
      "Test\n",
      "Test set: Average loss: 1.3766, Accuracy: 5466/10000 (55%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3020, Accuracy: 552/5000 (11%)\n",
      "[epoch 1] loss: 1.9567465\n",
      "Test set: Average loss: 1.6643, Accuracy: 2053/5000 (41%)\n",
      "[epoch 2] loss: 1.5222723\n",
      "Test set: Average loss: 1.4610, Accuracy: 2325/5000 (46%)\n",
      "[epoch 3] loss: 1.3106193\n",
      "Test set: Average loss: 1.3796, Accuracy: 2526/5000 (51%)\n",
      "[epoch 4] loss: 1.1072687\n",
      "Test set: Average loss: 1.4918, Accuracy: 2475/5000 (50%)\n",
      "[epoch 5] loss: 1.0626938\n",
      "Test set: Average loss: 1.4331, Accuracy: 2522/5000 (50%)\n",
      "[epoch 6] loss: 0.8912180\n",
      "Test set: Average loss: 1.4811, Accuracy: 2538/5000 (51%)\n",
      "[epoch 7] loss: 0.7916773\n",
      "Test set: Average loss: 1.4662, Accuracy: 2584/5000 (52%)\n",
      "[epoch 8] loss: 0.6712112\n",
      "Test set: Average loss: 1.6240, Accuracy: 2554/5000 (51%)\n",
      "[epoch 9] loss: 0.5769753\n",
      "Test set: Average loss: 1.7104, Accuracy: 2467/5000 (49%)\n",
      "[epoch 10] loss: 0.4608864\n",
      "Test set: Average loss: 1.9319, Accuracy: 2410/5000 (48%)\n",
      "[epoch 11] loss: 0.3893944\n",
      "Test set: Average loss: 2.0501, Accuracy: 2452/5000 (49%)\n",
      "[epoch 12] loss: 0.3608402\n",
      "Test set: Average loss: 2.2944, Accuracy: 2373/5000 (47%)\n",
      "[epoch 13] loss: 0.3476459\n",
      "Test set: Average loss: 2.1875, Accuracy: 2465/5000 (49%)\n",
      "[epoch 14] loss: 0.2656761\n",
      "Test set: Average loss: 2.6091, Accuracy: 2283/5000 (46%)\n",
      "[epoch 15] loss: 0.1956784\n",
      "Test set: Average loss: 2.4651, Accuracy: 2447/5000 (49%)\n",
      "[epoch 16] loss: 0.1796146\n",
      "Test set: Average loss: 2.6308, Accuracy: 2382/5000 (48%)\n",
      "[epoch 17] loss: 0.1903149\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.7184, Accuracy: 2303/5000 (46%)\n",
      "[epoch 18] loss: 0.0749348\n",
      "Test set: Average loss: 2.6068, Accuracy: 2403/5000 (48%)\n",
      "[epoch 19] loss: 0.0403922\n",
      "Test set: Average loss: 2.6176, Accuracy: 2406/5000 (48%)\n",
      "[epoch 20] loss: 0.0334587\n",
      "Test set: Average loss: 2.6327, Accuracy: 2412/5000 (48%)\n",
      "[epoch 21] loss: 0.0294467\n",
      "Test set: Average loss: 2.6506, Accuracy: 2414/5000 (48%)\n",
      "[epoch 22] loss: 0.0269243\n",
      "Test set: Average loss: 2.6696, Accuracy: 2414/5000 (48%)\n",
      "[epoch 23] loss: 0.0248741\n",
      "Test set: Average loss: 2.6830, Accuracy: 2420/5000 (48%)\n",
      "[epoch 24] loss: 0.0239261\n",
      "Test set: Average loss: 2.6975, Accuracy: 2431/5000 (49%)\n",
      "[epoch 25] loss: 0.0218100\n",
      "Test set: Average loss: 2.7170, Accuracy: 2428/5000 (49%)\n",
      "[epoch 26] loss: 0.0208304\n",
      "Test set: Average loss: 2.7283, Accuracy: 2431/5000 (49%)\n",
      "[epoch 27] loss: 0.0191848\n",
      "Test set: Average loss: 2.7438, Accuracy: 2421/5000 (48%)\n",
      "[epoch 28] loss: 0.0183705\n",
      "Test set: Average loss: 2.7559, Accuracy: 2434/5000 (49%)\n",
      "[epoch 29] loss: 0.0175475\n",
      "Test set: Average loss: 2.7689, Accuracy: 2437/5000 (49%)\n",
      "[epoch 30] loss: 0.0170160\n",
      "Test set: Average loss: 2.7814, Accuracy: 2438/5000 (49%)\n",
      "[epoch 31] loss: 0.0159520\n",
      "Test set: Average loss: 2.7899, Accuracy: 2435/5000 (49%)\n",
      "[epoch 32] loss: 0.0152659\n",
      "Test set: Average loss: 2.8042, Accuracy: 2439/5000 (49%)\n",
      "[epoch 33] loss: 0.0149845\n",
      "Test set: Average loss: 2.8140, Accuracy: 2440/5000 (49%)\n",
      "[epoch 34] loss: 0.0145566\n",
      "Test set: Average loss: 2.8282, Accuracy: 2431/5000 (49%)\n",
      "[epoch 35] loss: 0.0138057\n",
      "Test set: Average loss: 2.8373, Accuracy: 2441/5000 (49%)\n",
      "[epoch 36] loss: 0.0131811\n",
      "Test set: Average loss: 2.8500, Accuracy: 2435/5000 (49%)\n",
      "[epoch 37] loss: 0.0126327\n",
      "Test set: Average loss: 2.8603, Accuracy: 2445/5000 (49%)\n",
      "[epoch 38] loss: 0.0122446\n",
      "Test set: Average loss: 2.8682, Accuracy: 2446/5000 (49%)\n",
      "[epoch 39] loss: 0.0119671\n",
      "Test set: Average loss: 2.8802, Accuracy: 2444/5000 (49%)\n",
      "[epoch 40] loss: 0.0115122\n",
      "Test set: Average loss: 2.8894, Accuracy: 2443/5000 (49%)\n",
      "[epoch 41] loss: 0.0109360\n",
      "Test set: Average loss: 2.9011, Accuracy: 2443/5000 (49%)\n",
      "[epoch 42] loss: 0.0107327\n",
      "Test set: Average loss: 2.9118, Accuracy: 2442/5000 (49%)\n",
      "[epoch 43] loss: 0.0102202\n",
      "Test set: Average loss: 2.9224, Accuracy: 2445/5000 (49%)\n",
      "[epoch 44] loss: 0.0100893\n",
      "Test set: Average loss: 2.9341, Accuracy: 2442/5000 (49%)\n",
      "[epoch 45] loss: 0.0096035\n",
      "Test set: Average loss: 2.9454, Accuracy: 2442/5000 (49%)\n",
      "[epoch 46] loss: 0.0093011\n",
      "Test set: Average loss: 2.9532, Accuracy: 2441/5000 (49%)\n",
      "[epoch 47] loss: 0.0090665\n",
      "Test set: Average loss: 2.9636, Accuracy: 2439/5000 (49%)\n",
      "[epoch 48] loss: 0.0087576\n",
      "Test set: Average loss: 2.9717, Accuracy: 2436/5000 (49%)\n",
      "[epoch 49] loss: 0.0084022\n",
      "Test set: Average loss: 2.9812, Accuracy: 2435/5000 (49%)\n",
      "[epoch 50] loss: 0.0083355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.9913, Accuracy: 2437/5000 (49%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.4662, Accuracy: 2584/5000 (52%)\n",
      "Test\n",
      "Test set: Average loss: 1.4538, Accuracy: 5313/10000 (53%)\n",
      "2500\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3023, Accuracy: 481/5000 (10%)\n",
      "[epoch 1] loss: 1.6789131\n",
      "Test set: Average loss: 1.4263, Accuracy: 2454/5000 (49%)\n",
      "[epoch 2] loss: 1.3066208\n",
      "Test set: Average loss: 1.3559, Accuracy: 2581/5000 (52%)\n",
      "[epoch 3] loss: 1.1836203\n",
      "Test set: Average loss: 1.3091, Accuracy: 2657/5000 (53%)\n",
      "[epoch 4] loss: 1.0837905\n",
      "Test set: Average loss: 1.3614, Accuracy: 2658/5000 (53%)\n",
      "[epoch 5] loss: 1.0253879\n",
      "Test set: Average loss: 1.3317, Accuracy: 2763/5000 (55%)\n",
      "[epoch 6] loss: 0.8969074\n",
      "Test set: Average loss: 1.4267, Accuracy: 2687/5000 (54%)\n",
      "[epoch 7] loss: 0.8154598\n",
      "Test set: Average loss: 1.5293, Accuracy: 2612/5000 (52%)\n",
      "[epoch 8] loss: 0.8101444\n",
      "Test set: Average loss: 1.7037, Accuracy: 2537/5000 (51%)\n",
      "[epoch 9] loss: 0.7564409\n",
      "Test set: Average loss: 1.6051, Accuracy: 2596/5000 (52%)\n",
      "[epoch 10] loss: 0.6572587\n",
      "Test set: Average loss: 1.7687, Accuracy: 2555/5000 (51%)\n",
      "[epoch 11] loss: 0.6114330\n",
      "Test set: Average loss: 1.7513, Accuracy: 2577/5000 (52%)\n",
      "[epoch 12] loss: 0.5328452\n",
      "Test set: Average loss: 1.8889, Accuracy: 2551/5000 (51%)\n",
      "[epoch 13] loss: 0.5716709\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.2495, Accuracy: 2377/5000 (48%)\n",
      "[epoch 14] loss: 0.3253438\n",
      "Test set: Average loss: 1.8582, Accuracy: 2650/5000 (53%)\n",
      "[epoch 15] loss: 0.2318944\n",
      "Test set: Average loss: 1.8876, Accuracy: 2667/5000 (53%)\n",
      "[epoch 16] loss: 0.2097754\n",
      "Test set: Average loss: 1.9125, Accuracy: 2667/5000 (53%)\n",
      "[epoch 17] loss: 0.1941729\n",
      "Test set: Average loss: 1.9460, Accuracy: 2676/5000 (54%)\n",
      "[epoch 18] loss: 0.1857494\n",
      "Test set: Average loss: 1.9885, Accuracy: 2669/5000 (53%)\n",
      "[epoch 19] loss: 0.3242128\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.0199, Accuracy: 2679/5000 (54%)\n",
      "[epoch 20] loss: 0.1595086\n",
      "Test set: Average loss: 2.0150, Accuracy: 2689/5000 (54%)\n",
      "[epoch 21] loss: 0.1575593\n",
      "Test set: Average loss: 2.0183, Accuracy: 2688/5000 (54%)\n",
      "[epoch 22] loss: 0.1544426\n",
      "Test set: Average loss: 2.0224, Accuracy: 2689/5000 (54%)\n",
      "[epoch 23] loss: 0.1519850\n",
      "Test set: Average loss: 2.0270, Accuracy: 2688/5000 (54%)\n",
      "[epoch 24] loss: 0.1524986\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.0306, Accuracy: 2686/5000 (54%)\n",
      "[epoch 25] loss: 0.1490142\n",
      "Test set: Average loss: 2.0312, Accuracy: 2686/5000 (54%)\n",
      "[epoch 26] loss: 0.1609086\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 27] loss: 0.1494317\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 28] loss: 0.1485270\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 29] loss: 0.1505191\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 30] loss: 0.1505293\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 31] loss: 0.1495016\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 32] loss: 0.1489766\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 33] loss: 0.1490670\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 34] loss: 0.1493313\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 35] loss: 0.1518445\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 36] loss: 0.1485957\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 37] loss: 0.1490544\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 38] loss: 0.1485412\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 39] loss: 0.1496159\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 40] loss: 0.1495915\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 41] loss: 0.1552491\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 42] loss: 0.1504277\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 43] loss: 0.1501285\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 44] loss: 0.1492606\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 45] loss: 0.1489738\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 46] loss: 0.1498706\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 47] loss: 0.1500328\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 48] loss: 0.1496454\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 49] loss: 0.1497686\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-29.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "[epoch 50] loss: 0.1486214\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-30.\n",
      "Test set: Average loss: 2.0317, Accuracy: 2685/5000 (54%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3317, Accuracy: 2763/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.3398, Accuracy: 5462/10000 (55%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 492/5000 (10%)\n",
      "[epoch 1] loss: 1.6719776\n",
      "Test set: Average loss: 1.4861, Accuracy: 2334/5000 (47%)\n",
      "[epoch 2] loss: 1.2631033\n",
      "Test set: Average loss: 1.3902, Accuracy: 2572/5000 (51%)\n",
      "[epoch 3] loss: 1.1497777\n",
      "Test set: Average loss: 1.3357, Accuracy: 2685/5000 (54%)\n",
      "[epoch 4] loss: 1.0514907\n",
      "Test set: Average loss: 1.3469, Accuracy: 2688/5000 (54%)\n",
      "[epoch 5] loss: 0.9077185\n",
      "Test set: Average loss: 1.3918, Accuracy: 2684/5000 (54%)\n",
      "[epoch 6] loss: 0.8610878\n",
      "Test set: Average loss: 1.3669, Accuracy: 2715/5000 (54%)\n",
      "[epoch 7] loss: 0.7626027\n",
      "Test set: Average loss: 1.5610, Accuracy: 2526/5000 (51%)\n",
      "[epoch 8] loss: 0.7307936\n",
      "Test set: Average loss: 1.5724, Accuracy: 2588/5000 (52%)\n",
      "[epoch 9] loss: 0.6967752\n",
      "Test set: Average loss: 1.8515, Accuracy: 2474/5000 (49%)\n",
      "[epoch 10] loss: 0.6903850\n",
      "Test set: Average loss: 1.8064, Accuracy: 2491/5000 (50%)\n",
      "[epoch 11] loss: 0.5594553\n",
      "Test set: Average loss: 1.8492, Accuracy: 2542/5000 (51%)\n",
      "[epoch 12] loss: 0.5393365\n",
      "Test set: Average loss: 1.9061, Accuracy: 2553/5000 (51%)\n",
      "[epoch 13] loss: 0.4009161\n",
      "Test set: Average loss: 2.1031, Accuracy: 2506/5000 (50%)\n",
      "[epoch 14] loss: 0.4472468\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.3868, Accuracy: 2336/5000 (47%)\n",
      "[epoch 15] loss: 0.2502064\n",
      "Test set: Average loss: 2.1301, Accuracy: 2589/5000 (52%)\n",
      "[epoch 16] loss: 0.1695639\n",
      "Test set: Average loss: 2.1556, Accuracy: 2558/5000 (51%)\n",
      "[epoch 17] loss: 0.1589687\n",
      "Test set: Average loss: 2.1975, Accuracy: 2571/5000 (51%)\n",
      "[epoch 18] loss: 0.1433640\n",
      "Test set: Average loss: 2.2388, Accuracy: 2566/5000 (51%)\n",
      "[epoch 19] loss: 0.1249150\n",
      "Test set: Average loss: 2.2672, Accuracy: 2573/5000 (51%)\n",
      "[epoch 20] loss: 0.1159503\n",
      "Test set: Average loss: 2.2962, Accuracy: 2564/5000 (51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21] loss: 0.1093226\n",
      "Test set: Average loss: 2.3314, Accuracy: 2557/5000 (51%)\n",
      "[epoch 22] loss: 0.1020597\n",
      "Test set: Average loss: 2.3704, Accuracy: 2562/5000 (51%)\n",
      "[epoch 23] loss: 0.0947632\n",
      "Test set: Average loss: 2.3975, Accuracy: 2564/5000 (51%)\n",
      "[epoch 24] loss: 0.0895471\n",
      "Test set: Average loss: 2.4313, Accuracy: 2592/5000 (52%)\n",
      "[epoch 25] loss: 0.0866555\n",
      "Test set: Average loss: 2.4680, Accuracy: 2561/5000 (51%)\n",
      "[epoch 26] loss: 0.0782333\n",
      "Test set: Average loss: 2.5262, Accuracy: 2560/5000 (51%)\n",
      "[epoch 27] loss: 0.0736293\n",
      "Test set: Average loss: 2.5511, Accuracy: 2582/5000 (52%)\n",
      "[epoch 28] loss: 0.0753212\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.6005, Accuracy: 2553/5000 (51%)\n",
      "[epoch 29] loss: 0.2398915\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.5997, Accuracy: 2556/5000 (51%)\n",
      "[epoch 30] loss: 0.2963636\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2553/5000 (51%)\n",
      "[epoch 31] loss: 0.0595717\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 32] loss: 0.0587264\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 33] loss: 0.0588008\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 34] loss: 0.0589319\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 35] loss: 0.0587099\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 36] loss: 0.0587313\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 37] loss: 0.0596135\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 38] loss: 0.0622494\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 39] loss: 0.0597740\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 40] loss: 0.0587600\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 41] loss: 0.0587272\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 42] loss: 0.0586560\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 43] loss: 0.0588620\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 44] loss: 0.0586862\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 45] loss: 0.0594604\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 46] loss: 0.0609707\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 47] loss: 0.0596653\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 48] loss: 0.0596511\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 49] loss: 0.0597635\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "[epoch 50] loss: 0.0593380\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 2.5995, Accuracy: 2554/5000 (51%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.3669, Accuracy: 2715/5000 (54%)\n",
      "Test\n",
      "Test set: Average loss: 1.3310, Accuracy: 5637/10000 (56%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3051, Accuracy: 499/5000 (10%)\n",
      "[epoch 1] loss: 1.7104367\n",
      "Test set: Average loss: 1.4634, Accuracy: 2383/5000 (48%)\n",
      "[epoch 2] loss: 1.2953240\n",
      "Test set: Average loss: 1.3476, Accuracy: 2591/5000 (52%)\n",
      "[epoch 3] loss: 1.1583109\n",
      "Test set: Average loss: 1.2925, Accuracy: 2759/5000 (55%)\n",
      "[epoch 4] loss: 1.0479434\n",
      "Test set: Average loss: 1.4170, Accuracy: 2526/5000 (51%)\n",
      "[epoch 5] loss: 0.9714330\n",
      "Test set: Average loss: 1.4273, Accuracy: 2632/5000 (53%)\n",
      "[epoch 6] loss: 0.9130389\n",
      "Test set: Average loss: 1.4299, Accuracy: 2687/5000 (54%)\n",
      "[epoch 7] loss: 0.8681161\n",
      "Test set: Average loss: 1.4222, Accuracy: 2694/5000 (54%)\n",
      "[epoch 8] loss: 0.7349083\n",
      "Test set: Average loss: 1.6326, Accuracy: 2479/5000 (50%)\n",
      "[epoch 9] loss: 0.7058858\n",
      "Test set: Average loss: 1.7275, Accuracy: 2522/5000 (50%)\n",
      "[epoch 10] loss: 0.6586745\n",
      "Test set: Average loss: 1.6207, Accuracy: 2680/5000 (54%)\n",
      "[epoch 11] loss: 0.5662851\n",
      "Test set: Average loss: 1.9476, Accuracy: 2522/5000 (50%)\n",
      "[epoch 12] loss: 0.5842033\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0439, Accuracy: 2422/5000 (48%)\n",
      "[epoch 13] loss: 0.4460842\n",
      "Test set: Average loss: 1.8069, Accuracy: 2659/5000 (53%)\n",
      "[epoch 14] loss: 0.2838715\n",
      "Test set: Average loss: 1.8210, Accuracy: 2659/5000 (53%)\n",
      "[epoch 15] loss: 0.4246766\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.8522, Accuracy: 2648/5000 (53%)\n",
      "[epoch 16] loss: 0.2295381\n",
      "Test set: Average loss: 1.8457, Accuracy: 2659/5000 (53%)\n",
      "[epoch 17] loss: 0.2239637\n",
      "Test set: Average loss: 1.8475, Accuracy: 2669/5000 (53%)\n",
      "[epoch 18] loss: 0.2228118\n",
      "Test set: Average loss: 1.8517, Accuracy: 2667/5000 (53%)\n",
      "[epoch 19] loss: 0.2205026\n",
      "Test set: Average loss: 1.8555, Accuracy: 2668/5000 (53%)\n",
      "[epoch 20] loss: 0.2199038\n",
      "Test set: Average loss: 1.8598, Accuracy: 2668/5000 (53%)\n",
      "[epoch 21] loss: 0.2198417\n",
      "Test set: Average loss: 1.8630, Accuracy: 2663/5000 (53%)\n",
      "[epoch 22] loss: 0.2187476\n",
      "Test set: Average loss: 1.8679, Accuracy: 2658/5000 (53%)\n",
      "[epoch 23] loss: 0.2188776\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.8706, Accuracy: 2659/5000 (53%)\n",
      "[epoch 24] loss: 0.2110808\n",
      "Test set: Average loss: 1.8710, Accuracy: 2661/5000 (53%)\n",
      "[epoch 25] loss: 0.2113210\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.8715, Accuracy: 2661/5000 (53%)\n",
      "[epoch 26] loss: 0.2109379\n",
      "Test set: Average loss: 1.8716, Accuracy: 2660/5000 (53%)\n",
      "[epoch 27] loss: 0.2107356\n",
      "Test set: Average loss: 1.8716, Accuracy: 2660/5000 (53%)\n",
      "[epoch 28] loss: 0.2107374\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 29] loss: 0.2125832\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 30] loss: 0.2131843\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 31] loss: 0.2108544\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 32] loss: 0.2122854\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 33] loss: 0.2106057\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 34] loss: 0.2130154\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 35] loss: 0.2108942\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 36] loss: 0.2150044\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 37] loss: 0.2246930\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 38] loss: 0.2151853\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 39] loss: 0.2126099\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40] loss: 0.2135054\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 41] loss: 0.2122502\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 42] loss: 0.2106582\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 43] loss: 0.2161198\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 44] loss: 0.2106772\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 45] loss: 0.2125332\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-24.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 46] loss: 0.2107811\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-25.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 47] loss: 0.2167110\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-26.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 48] loss: 0.2111636\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-27.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 49] loss: 0.2101555\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "[epoch 50] loss: 0.2107912\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-28.\n",
      "Test set: Average loss: 1.8717, Accuracy: 2660/5000 (53%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2925, Accuracy: 2759/5000 (55%)\n",
      "Test\n",
      "Test set: Average loss: 1.2655, Accuracy: 5567/10000 (56%)\n",
      "5000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3032, Accuracy: 507/5000 (10%)\n",
      "[epoch 1] loss: 1.4676022\n",
      "Test set: Average loss: 1.3586, Accuracy: 2617/5000 (52%)\n",
      "[epoch 2] loss: 1.1904029\n",
      "Test set: Average loss: 1.2323, Accuracy: 2826/5000 (57%)\n",
      "[epoch 3] loss: 1.1077096\n",
      "Test set: Average loss: 1.4385, Accuracy: 2511/5000 (50%)\n",
      "[epoch 4] loss: 1.0323273\n",
      "Test set: Average loss: 1.2481, Accuracy: 2843/5000 (57%)\n",
      "[epoch 5] loss: 0.9587011\n",
      "Test set: Average loss: 1.2982, Accuracy: 2830/5000 (57%)\n",
      "[epoch 6] loss: 0.9322815\n",
      "Test set: Average loss: 1.3405, Accuracy: 2749/5000 (55%)\n",
      "[epoch 7] loss: 0.8926567\n",
      "Test set: Average loss: 1.4576, Accuracy: 2681/5000 (54%)\n",
      "[epoch 8] loss: 0.8381824\n",
      "Test set: Average loss: 1.4303, Accuracy: 2719/5000 (54%)\n",
      "[epoch 9] loss: 0.8222519\n",
      "Test set: Average loss: 1.4151, Accuracy: 2752/5000 (55%)\n",
      "[epoch 10] loss: 0.7688458\n",
      "Test set: Average loss: 1.4454, Accuracy: 2777/5000 (56%)\n",
      "[epoch 11] loss: 0.7353116\n",
      "Test set: Average loss: 1.4781, Accuracy: 2795/5000 (56%)\n",
      "[epoch 12] loss: 0.6999127\n",
      "Test set: Average loss: 1.7083, Accuracy: 2589/5000 (52%)\n",
      "[epoch 13] loss: 0.7115573\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6475, Accuracy: 2616/5000 (52%)\n",
      "[epoch 14] loss: 0.4697761\n",
      "Test set: Average loss: 1.5007, Accuracy: 2846/5000 (57%)\n",
      "[epoch 15] loss: 0.4125850\n",
      "Test set: Average loss: 1.5386, Accuracy: 2854/5000 (57%)\n",
      "[epoch 16] loss: 0.3943915\n",
      "Test set: Average loss: 1.5754, Accuracy: 2840/5000 (57%)\n",
      "[epoch 17] loss: 0.3794673\n",
      "Test set: Average loss: 1.6113, Accuracy: 2842/5000 (57%)\n",
      "[epoch 18] loss: 0.3695627\n",
      "Test set: Average loss: 1.6464, Accuracy: 2818/5000 (56%)\n",
      "[epoch 19] loss: 0.3588408\n",
      "Test set: Average loss: 1.6793, Accuracy: 2844/5000 (57%)\n",
      "[epoch 20] loss: 0.3487240\n",
      "Test set: Average loss: 1.7155, Accuracy: 2833/5000 (57%)\n",
      "[epoch 21] loss: 0.3385247\n",
      "Test set: Average loss: 1.7525, Accuracy: 2822/5000 (56%)\n",
      "[epoch 22] loss: 0.3323400\n",
      "Test set: Average loss: 1.7833, Accuracy: 2827/5000 (57%)\n",
      "[epoch 23] loss: 0.3194019\n",
      "Test set: Average loss: 1.8057, Accuracy: 2819/5000 (56%)\n",
      "[epoch 24] loss: 0.3120294\n",
      "Test set: Average loss: 1.8345, Accuracy: 2835/5000 (57%)\n",
      "[epoch 25] loss: 0.3034397\n",
      "Test set: Average loss: 1.8850, Accuracy: 2791/5000 (56%)\n",
      "[epoch 26] loss: 0.2954512\n",
      "Test set: Average loss: 1.9086, Accuracy: 2814/5000 (56%)\n",
      "[epoch 27] loss: 0.2852394\n",
      "Test set: Average loss: 1.9462, Accuracy: 2791/5000 (56%)\n",
      "[epoch 28] loss: 0.2825851\n",
      "Test set: Average loss: 1.9792, Accuracy: 2816/5000 (56%)\n",
      "[epoch 29] loss: 0.2679636\n",
      "Test set: Average loss: 2.0087, Accuracy: 2793/5000 (56%)\n",
      "[epoch 30] loss: 0.2614303\n",
      "Test set: Average loss: 2.0495, Accuracy: 2793/5000 (56%)\n",
      "[epoch 31] loss: 0.2526979\n",
      "Test set: Average loss: 2.0950, Accuracy: 2778/5000 (56%)\n",
      "[epoch 32] loss: 0.2461585\n",
      "Test set: Average loss: 2.1161, Accuracy: 2792/5000 (56%)\n",
      "[epoch 33] loss: 0.2398857\n",
      "Test set: Average loss: 2.1607, Accuracy: 2767/5000 (55%)\n",
      "[epoch 34] loss: 0.2343175\n",
      "Test set: Average loss: 2.1984, Accuracy: 2766/5000 (55%)\n",
      "[epoch 35] loss: 0.2264008\n",
      "Test set: Average loss: 2.2267, Accuracy: 2768/5000 (55%)\n",
      "[epoch 36] loss: 0.2187040\n",
      "Test set: Average loss: 2.2740, Accuracy: 2782/5000 (56%)\n",
      "[epoch 37] loss: 0.2144764\n",
      "Test set: Average loss: 2.3086, Accuracy: 2766/5000 (55%)\n",
      "[epoch 38] loss: 0.2028171\n",
      "Test set: Average loss: 2.3549, Accuracy: 2746/5000 (55%)\n",
      "[epoch 39] loss: 0.2750321\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.3848, Accuracy: 2768/5000 (55%)\n",
      "[epoch 40] loss: 0.1731398\n",
      "Test set: Average loss: 2.3777, Accuracy: 2777/5000 (56%)\n",
      "[epoch 41] loss: 0.1678152\n",
      "Test set: Average loss: 2.3810, Accuracy: 2772/5000 (55%)\n",
      "[epoch 42] loss: 0.1668262\n",
      "Test set: Average loss: 2.3861, Accuracy: 2772/5000 (55%)\n",
      "[epoch 43] loss: 0.1659808\n",
      "Test set: Average loss: 2.3915, Accuracy: 2774/5000 (55%)\n",
      "[epoch 44] loss: 0.1647408\n",
      "Test set: Average loss: 2.3992, Accuracy: 2765/5000 (55%)\n",
      "[epoch 45] loss: 0.1658971\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 2.4013, Accuracy: 2776/5000 (56%)\n",
      "[epoch 46] loss: 0.1615287\n",
      "Test set: Average loss: 2.4016, Accuracy: 2776/5000 (56%)\n",
      "[epoch 47] loss: 0.1609199\n",
      "Test set: Average loss: 2.4020, Accuracy: 2773/5000 (55%)\n",
      "[epoch 48] loss: 0.1612681\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 2.4200, Accuracy: 2767/5000 (55%)\n",
      "[epoch 49] loss: 0.1605487\n",
      "Test set: Average loss: 2.4028, Accuracy: 2771/5000 (55%)\n",
      "[epoch 50] loss: 0.1604241\n",
      "Test set: Average loss: 2.4028, Accuracy: 2771/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5386, Accuracy: 2854/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.4943, Accuracy: 5773/10000 (58%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3025, Accuracy: 485/5000 (10%)\n",
      "[epoch 1] loss: 1.4764277\n",
      "Test set: Average loss: 1.2828, Accuracy: 2762/5000 (55%)\n",
      "[epoch 2] loss: 1.1976021\n",
      "Test set: Average loss: 1.3293, Accuracy: 2688/5000 (54%)\n",
      "[epoch 3] loss: 1.0986532\n",
      "Test set: Average loss: 1.3543, Accuracy: 2704/5000 (54%)\n",
      "[epoch 4] loss: 1.0338282\n",
      "Test set: Average loss: 1.3597, Accuracy: 2672/5000 (53%)\n",
      "[epoch 5] loss: 0.9684536\n",
      "Test set: Average loss: 1.2849, Accuracy: 2774/5000 (55%)\n",
      "[epoch 6] loss: 0.9172662\n",
      "Test set: Average loss: 1.3865, Accuracy: 2732/5000 (55%)\n",
      "[epoch 7] loss: 0.8835240\n",
      "Test set: Average loss: 1.4827, Accuracy: 2656/5000 (53%)\n",
      "[epoch 8] loss: 0.8329395\n",
      "Test set: Average loss: 1.3692, Accuracy: 2770/5000 (55%)\n",
      "[epoch 9] loss: 0.7809091\n",
      "Test set: Average loss: 1.4533, Accuracy: 2749/5000 (55%)\n",
      "[epoch 10] loss: 0.8044194\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4248, Accuracy: 2733/5000 (55%)\n",
      "[epoch 11] loss: 0.5576121\n",
      "Test set: Average loss: 1.3938, Accuracy: 2852/5000 (57%)\n",
      "[epoch 12] loss: 0.4880570\n",
      "Test set: Average loss: 1.4167, Accuracy: 2846/5000 (57%)\n",
      "[epoch 13] loss: 0.4639148\n",
      "Test set: Average loss: 1.4452, Accuracy: 2852/5000 (57%)\n",
      "[epoch 14] loss: 0.4531278\n",
      "Test set: Average loss: 1.4623, Accuracy: 2868/5000 (57%)\n",
      "[epoch 15] loss: 0.4348225\n",
      "Test set: Average loss: 1.5040, Accuracy: 2871/5000 (57%)\n",
      "[epoch 16] loss: 0.4247075\n",
      "Test set: Average loss: 1.5208, Accuracy: 2863/5000 (57%)\n",
      "[epoch 17] loss: 0.4120990\n",
      "Test set: Average loss: 1.5563, Accuracy: 2849/5000 (57%)\n",
      "[epoch 18] loss: 0.4031813\n",
      "Test set: Average loss: 1.5841, Accuracy: 2852/5000 (57%)\n",
      "[epoch 19] loss: 0.3942179\n",
      "Test set: Average loss: 1.6114, Accuracy: 2845/5000 (57%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] loss: 0.3795064\n",
      "Test set: Average loss: 1.6391, Accuracy: 2818/5000 (56%)\n",
      "[epoch 21] loss: 0.3711821\n",
      "Test set: Average loss: 1.6844, Accuracy: 2787/5000 (56%)\n",
      "[epoch 22] loss: 0.3623614\n",
      "Test set: Average loss: 1.6873, Accuracy: 2835/5000 (57%)\n",
      "[epoch 23] loss: 0.3508563\n",
      "Test set: Average loss: 1.7391, Accuracy: 2821/5000 (56%)\n",
      "[epoch 24] loss: 0.3416091\n",
      "Test set: Average loss: 1.7685, Accuracy: 2805/5000 (56%)\n",
      "[epoch 25] loss: 0.3316935\n",
      "Test set: Average loss: 1.7863, Accuracy: 2805/5000 (56%)\n",
      "[epoch 26] loss: 0.3204069\n",
      "Test set: Average loss: 1.8175, Accuracy: 2812/5000 (56%)\n",
      "[epoch 27] loss: 0.3129034\n",
      "Test set: Average loss: 1.8733, Accuracy: 2794/5000 (56%)\n",
      "[epoch 28] loss: 0.3083487\n",
      "Test set: Average loss: 1.8874, Accuracy: 2796/5000 (56%)\n",
      "[epoch 29] loss: 0.2966774\n",
      "Test set: Average loss: 1.9238, Accuracy: 2788/5000 (56%)\n",
      "[epoch 30] loss: 0.2870686\n",
      "Test set: Average loss: 1.9697, Accuracy: 2789/5000 (56%)\n",
      "[epoch 31] loss: 0.2799862\n",
      "Test set: Average loss: 1.9959, Accuracy: 2791/5000 (56%)\n",
      "[epoch 32] loss: 0.2747951\n",
      "Test set: Average loss: 2.0313, Accuracy: 2785/5000 (56%)\n",
      "[epoch 33] loss: 0.2722665\n",
      "Test set: Average loss: 2.0556, Accuracy: 2778/5000 (56%)\n",
      "[epoch 34] loss: 0.2563830\n",
      "Test set: Average loss: 2.0981, Accuracy: 2765/5000 (55%)\n",
      "[epoch 35] loss: 0.2492032\n",
      "Test set: Average loss: 2.1483, Accuracy: 2765/5000 (55%)\n",
      "[epoch 36] loss: 0.2440386\n",
      "Test set: Average loss: 2.1877, Accuracy: 2759/5000 (55%)\n",
      "[epoch 37] loss: 0.2360836\n",
      "Test set: Average loss: 2.2324, Accuracy: 2763/5000 (55%)\n",
      "[epoch 38] loss: 0.2306723\n",
      "Test set: Average loss: 2.2431, Accuracy: 2750/5000 (55%)\n",
      "[epoch 39] loss: 0.2211279\n",
      "Test set: Average loss: 2.2893, Accuracy: 2754/5000 (55%)\n",
      "[epoch 40] loss: 0.2131844\n",
      "Test set: Average loss: 2.3161, Accuracy: 2741/5000 (55%)\n",
      "[epoch 41] loss: 0.2074892\n",
      "Test set: Average loss: 2.3576, Accuracy: 2756/5000 (55%)\n",
      "[epoch 42] loss: 0.2025023\n",
      "Test set: Average loss: 2.4061, Accuracy: 2730/5000 (55%)\n",
      "[epoch 43] loss: 0.1942942\n",
      "Test set: Average loss: 2.4344, Accuracy: 2745/5000 (55%)\n",
      "[epoch 44] loss: 0.1913425\n",
      "Test set: Average loss: 2.4983, Accuracy: 2742/5000 (55%)\n",
      "[epoch 45] loss: 0.1851104\n",
      "Test set: Average loss: 2.5137, Accuracy: 2712/5000 (54%)\n",
      "[epoch 46] loss: 0.1791057\n",
      "Test set: Average loss: 2.5474, Accuracy: 2728/5000 (55%)\n",
      "[epoch 47] loss: 0.1739179\n",
      "Test set: Average loss: 2.6136, Accuracy: 2717/5000 (54%)\n",
      "[epoch 48] loss: 0.1707526\n",
      "Test set: Average loss: 2.6525, Accuracy: 2724/5000 (54%)\n",
      "[epoch 49] loss: 0.1627788\n",
      "Test set: Average loss: 2.6866, Accuracy: 2721/5000 (54%)\n",
      "[epoch 50] loss: 0.1524571\n",
      "Test set: Average loss: 2.7199, Accuracy: 2728/5000 (55%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.5040, Accuracy: 2871/5000 (57%)\n",
      "Test\n",
      "Test set: Average loss: 1.4572, Accuracy: 5847/10000 (58%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 484/5000 (10%)\n",
      "[epoch 1] loss: 1.5277389\n",
      "Test set: Average loss: 1.3030, Accuracy: 2637/5000 (53%)\n",
      "[epoch 2] loss: 1.2261650\n",
      "Test set: Average loss: 1.2736, Accuracy: 2723/5000 (54%)\n",
      "[epoch 3] loss: 1.1401894\n",
      "Test set: Average loss: 1.2762, Accuracy: 2694/5000 (54%)\n",
      "[epoch 4] loss: 1.0820615\n",
      "Test set: Average loss: 1.3105, Accuracy: 2734/5000 (55%)\n",
      "[epoch 5] loss: 1.0180372\n",
      "Test set: Average loss: 1.3119, Accuracy: 2684/5000 (54%)\n",
      "[epoch 6] loss: 0.9499672\n",
      "Test set: Average loss: 1.3085, Accuracy: 2823/5000 (56%)\n",
      "[epoch 7] loss: 0.8884823\n",
      "Test set: Average loss: 1.4371, Accuracy: 2669/5000 (53%)\n",
      "[epoch 8] loss: 0.8911369\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.4114, Accuracy: 2734/5000 (55%)\n",
      "[epoch 9] loss: 0.6397495\n",
      "Test set: Average loss: 1.2925, Accuracy: 2941/5000 (59%)\n",
      "[epoch 10] loss: 0.5815808\n",
      "Test set: Average loss: 1.3212, Accuracy: 2928/5000 (59%)\n",
      "[epoch 11] loss: 0.5600483\n",
      "Test set: Average loss: 1.3421, Accuracy: 2927/5000 (59%)\n",
      "[epoch 12] loss: 0.5432243\n",
      "Test set: Average loss: 1.3620, Accuracy: 2909/5000 (58%)\n",
      "[epoch 13] loss: 0.5292332\n",
      "Test set: Average loss: 1.3925, Accuracy: 2889/5000 (58%)\n",
      "[epoch 14] loss: 0.5199752\n",
      "Test set: Average loss: 1.4192, Accuracy: 2884/5000 (58%)\n",
      "[epoch 15] loss: 0.5041296\n",
      "Test set: Average loss: 1.4390, Accuracy: 2896/5000 (58%)\n",
      "[epoch 16] loss: 0.4913442\n",
      "Test set: Average loss: 1.4674, Accuracy: 2893/5000 (58%)\n",
      "[epoch 17] loss: 0.4797541\n",
      "Test set: Average loss: 1.5005, Accuracy: 2850/5000 (57%)\n",
      "[epoch 18] loss: 0.4711423\n",
      "Test set: Average loss: 1.5231, Accuracy: 2874/5000 (57%)\n",
      "[epoch 19] loss: 0.5225826\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 1.5531, Accuracy: 2859/5000 (57%)\n",
      "[epoch 20] loss: 0.4257330\n",
      "Test set: Average loss: 1.5403, Accuracy: 2854/5000 (57%)\n",
      "[epoch 21] loss: 0.4188777\n",
      "Test set: Average loss: 1.5424, Accuracy: 2865/5000 (57%)\n",
      "[epoch 22] loss: 0.4168855\n",
      "Test set: Average loss: 1.5456, Accuracy: 2873/5000 (57%)\n",
      "[epoch 23] loss: 0.4162996\n",
      "Test set: Average loss: 1.5476, Accuracy: 2870/5000 (57%)\n",
      "[epoch 24] loss: 0.4153228\n",
      "Test set: Average loss: 1.5524, Accuracy: 2867/5000 (57%)\n",
      "[epoch 25] loss: 0.4130974\n",
      "Test set: Average loss: 1.5544, Accuracy: 2872/5000 (57%)\n",
      "[epoch 26] loss: 0.4104719\n",
      "Test set: Average loss: 1.5577, Accuracy: 2872/5000 (57%)\n",
      "[epoch 27] loss: 0.4102190\n",
      "Test set: Average loss: 1.5615, Accuracy: 2870/5000 (57%)\n",
      "[epoch 28] loss: 0.4106206\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Test set: Average loss: 1.5647, Accuracy: 2881/5000 (58%)\n",
      "[epoch 29] loss: 0.4061609\n",
      "Test set: Average loss: 1.5650, Accuracy: 2878/5000 (58%)\n",
      "[epoch 30] loss: 0.4057383\n",
      "Test set: Average loss: 1.5653, Accuracy: 2877/5000 (58%)\n",
      "[epoch 31] loss: 0.4059677\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2877/5000 (58%)\n",
      "[epoch 32] loss: 0.4042618\n",
      "Test set: Average loss: 1.5656, Accuracy: 2877/5000 (58%)\n",
      "[epoch 33] loss: 0.4047855\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 34] loss: 0.4077148\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 35] loss: 0.4049186\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-10.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 36] loss: 0.4031682\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 37] loss: 0.4079289\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-11.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 38] loss: 0.4037887\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-12.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 39] loss: 0.4048735\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-13.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 40] loss: 0.4044124\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-14.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 41] loss: 0.4040160\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-15.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 42] loss: 0.4031420\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-16.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 43] loss: 0.4038029\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-17.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 44] loss: 0.4035041\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-18.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 45] loss: 0.4028776\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 46] loss: 0.4045729\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-19.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 47] loss: 0.4042682\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-20.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 48] loss: 0.4029809\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-21.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "[epoch 49] loss: 0.4037480\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-22.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] loss: 0.4032842\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-23.\n",
      "Test set: Average loss: 1.5656, Accuracy: 2876/5000 (58%)\n",
      "Validation:\n",
      "Test set: Average loss: 1.2925, Accuracy: 2941/5000 (59%)\n",
      "Test\n",
      "Test set: Average loss: 1.2539, Accuracy: 5923/10000 (59%)\n",
      "10000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 516/5000 (10%)\n",
      "[epoch 1] loss: 1.3718800\n",
      "Test set: Average loss: 1.3127, Accuracy: 2690/5000 (54%)\n",
      "[epoch 2] loss: 1.1771634\n",
      "Test set: Average loss: 1.2674, Accuracy: 2776/5000 (56%)\n",
      "[epoch 3] loss: 1.0880398\n",
      "Test set: Average loss: 1.2471, Accuracy: 2830/5000 (57%)\n",
      "[epoch 4] loss: 1.0446631\n",
      "Test set: Average loss: 1.2636, Accuracy: 2839/5000 (57%)\n",
      "[epoch 5] loss: 1.0120163\n",
      "Test set: Average loss: 1.2938, Accuracy: 2776/5000 (56%)\n",
      "[epoch 6] loss: 0.9749610\n",
      "Test set: Average loss: 1.1906, Accuracy: 2962/5000 (59%)\n",
      "[epoch 7] loss: 0.9289967\n",
      "Test set: Average loss: 1.2471, Accuracy: 2888/5000 (58%)\n",
      "[epoch 8] loss: 0.8997192\n",
      "Test set: Average loss: 1.2183, Accuracy: 2898/5000 (58%)\n",
      "[epoch 9] loss: 0.8871572\n",
      "Test set: Average loss: 1.2812, Accuracy: 2807/5000 (56%)\n",
      "[epoch 10] loss: 0.8625549\n",
      "Test set: Average loss: 1.3340, Accuracy: 2818/5000 (56%)\n",
      "[epoch 11] loss: 0.8246382\n",
      "Test set: Average loss: 1.2767, Accuracy: 2912/5000 (58%)\n",
      "[epoch 12] loss: 0.7990411\n",
      "Test set: Average loss: 1.2385, Accuracy: 2947/5000 (59%)\n",
      "[epoch 13] loss: 0.7766408\n",
      "Test set: Average loss: 1.3536, Accuracy: 2854/5000 (57%)\n",
      "[epoch 14] loss: 0.7505120\n",
      "Test set: Average loss: 1.2760, Accuracy: 2944/5000 (59%)\n",
      "[epoch 15] loss: 0.7347556\n",
      "Test set: Average loss: 1.3019, Accuracy: 2882/5000 (58%)\n",
      "[epoch 16] loss: 0.7047343\n",
      "Test set: Average loss: 1.3675, Accuracy: 2901/5000 (58%)\n",
      "[epoch 17] loss: 0.6605289\n",
      "Test set: Average loss: 1.3405, Accuracy: 2938/5000 (59%)\n",
      "[epoch 18] loss: 0.6281807\n",
      "Test set: Average loss: 1.4285, Accuracy: 2842/5000 (57%)\n",
      "[epoch 19] loss: 0.5790200\n",
      "Test set: Average loss: 1.3860, Accuracy: 2945/5000 (59%)\n",
      "[epoch 20] loss: 0.5371602\n",
      "Test set: Average loss: 1.4248, Accuracy: 2873/5000 (57%)\n",
      "[epoch 21] loss: 0.4774190\n",
      "Test set: Average loss: 1.5286, Accuracy: 2906/5000 (58%)\n",
      "[epoch 22] loss: 0.4348422\n",
      "Test set: Average loss: 1.5058, Accuracy: 2922/5000 (58%)\n",
      "[epoch 23] loss: 0.3972828\n",
      "Test set: Average loss: 1.5976, Accuracy: 2884/5000 (58%)\n",
      "[epoch 24] loss: 0.3278917\n",
      "Test set: Average loss: 1.6695, Accuracy: 2889/5000 (58%)\n",
      "[epoch 25] loss: 0.2621640\n",
      "Test set: Average loss: 1.6423, Accuracy: 2921/5000 (58%)\n",
      "[epoch 26] loss: 0.2310414\n",
      "Test set: Average loss: 1.8416, Accuracy: 2783/5000 (56%)\n",
      "[epoch 27] loss: 0.1962292\n",
      "Test set: Average loss: 1.9321, Accuracy: 2867/5000 (57%)\n",
      "[epoch 28] loss: 0.1446015\n",
      "Test set: Average loss: 1.9509, Accuracy: 2883/5000 (58%)\n",
      "[epoch 29] loss: 0.1128844\n",
      "Test set: Average loss: 1.9563, Accuracy: 2885/5000 (58%)\n",
      "[epoch 30] loss: 0.1327170\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.0346, Accuracy: 2933/5000 (59%)\n",
      "[epoch 31] loss: 0.0499098\n",
      "Test set: Average loss: 1.9961, Accuracy: 2922/5000 (58%)\n",
      "[epoch 32] loss: 0.0293660\n",
      "Test set: Average loss: 2.0045, Accuracy: 2951/5000 (59%)\n",
      "[epoch 33] loss: 0.0236925\n",
      "Test set: Average loss: 2.0206, Accuracy: 2940/5000 (59%)\n",
      "[epoch 34] loss: 0.0202870\n",
      "Test set: Average loss: 2.0432, Accuracy: 2955/5000 (59%)\n",
      "[epoch 35] loss: 0.0178128\n",
      "Test set: Average loss: 2.0587, Accuracy: 2954/5000 (59%)\n",
      "[epoch 36] loss: 0.0159487\n",
      "Test set: Average loss: 2.0785, Accuracy: 2960/5000 (59%)\n",
      "[epoch 37] loss: 0.0142224\n",
      "Test set: Average loss: 2.0958, Accuracy: 2959/5000 (59%)\n",
      "[epoch 38] loss: 0.0128719\n",
      "Test set: Average loss: 2.1171, Accuracy: 2956/5000 (59%)\n",
      "[epoch 39] loss: 0.0117125\n",
      "Test set: Average loss: 2.1399, Accuracy: 2960/5000 (59%)\n",
      "[epoch 40] loss: 0.0104991\n",
      "Test set: Average loss: 2.1608, Accuracy: 2960/5000 (59%)\n",
      "[epoch 41] loss: 0.0094644\n",
      "Test set: Average loss: 2.1832, Accuracy: 2958/5000 (59%)\n",
      "[epoch 42] loss: 0.0086319\n",
      "Test set: Average loss: 2.2082, Accuracy: 2960/5000 (59%)\n",
      "[epoch 43] loss: 0.0077251\n",
      "Test set: Average loss: 2.2293, Accuracy: 2971/5000 (59%)\n",
      "[epoch 44] loss: 0.0069833\n",
      "Test set: Average loss: 2.2596, Accuracy: 2977/5000 (60%)\n",
      "[epoch 45] loss: 0.0062886\n",
      "Test set: Average loss: 2.2808, Accuracy: 2974/5000 (59%)\n",
      "[epoch 46] loss: 0.0056622\n",
      "Test set: Average loss: 2.3038, Accuracy: 2966/5000 (59%)\n",
      "[epoch 47] loss: 0.0051229\n",
      "Test set: Average loss: 2.3351, Accuracy: 2966/5000 (59%)\n",
      "[epoch 48] loss: 0.0045517\n",
      "Test set: Average loss: 2.3621, Accuracy: 2967/5000 (59%)\n",
      "[epoch 49] loss: 0.0040646\n",
      "Test set: Average loss: 2.3938, Accuracy: 2972/5000 (59%)\n",
      "[epoch 50] loss: 0.0036061\n",
      "Test set: Average loss: 2.4269, Accuracy: 2979/5000 (60%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4269, Accuracy: 2979/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.3214, Accuracy: 6038/10000 (60%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3031, Accuracy: 498/5000 (10%)\n",
      "[epoch 1] loss: 1.3843775\n",
      "Test set: Average loss: 1.2191, Accuracy: 2845/5000 (57%)\n",
      "[epoch 2] loss: 1.1652668\n",
      "Test set: Average loss: 1.2625, Accuracy: 2782/5000 (56%)\n",
      "[epoch 3] loss: 1.0967315\n",
      "Test set: Average loss: 1.2355, Accuracy: 2843/5000 (57%)\n",
      "[epoch 4] loss: 1.0490146\n",
      "Test set: Average loss: 1.2082, Accuracy: 2914/5000 (58%)\n",
      "[epoch 5] loss: 1.0217040\n",
      "Test set: Average loss: 1.2005, Accuracy: 2903/5000 (58%)\n",
      "[epoch 6] loss: 0.9804609\n",
      "Test set: Average loss: 1.2132, Accuracy: 2916/5000 (58%)\n",
      "[epoch 7] loss: 0.9584328\n",
      "Test set: Average loss: 1.2354, Accuracy: 2907/5000 (58%)\n",
      "[epoch 8] loss: 0.9377329\n",
      "Test set: Average loss: 1.1993, Accuracy: 2925/5000 (58%)\n",
      "[epoch 9] loss: 0.9043977\n",
      "Test set: Average loss: 1.2111, Accuracy: 2939/5000 (59%)\n",
      "[epoch 10] loss: 0.8848602\n",
      "Test set: Average loss: 1.2065, Accuracy: 2930/5000 (59%)\n",
      "[epoch 11] loss: 0.8456533\n",
      "Test set: Average loss: 1.2380, Accuracy: 2910/5000 (58%)\n",
      "[epoch 12] loss: 0.8430875\n",
      "Test set: Average loss: 1.2585, Accuracy: 2876/5000 (58%)\n",
      "[epoch 13] loss: 0.7919070\n",
      "Test set: Average loss: 1.2551, Accuracy: 2942/5000 (59%)\n",
      "[epoch 14] loss: 0.7773556\n",
      "Test set: Average loss: 1.2867, Accuracy: 2920/5000 (58%)\n",
      "[epoch 15] loss: 0.7383938\n",
      "Test set: Average loss: 1.2904, Accuracy: 2906/5000 (58%)\n",
      "[epoch 16] loss: 0.7039834\n",
      "Test set: Average loss: 1.3386, Accuracy: 2887/5000 (58%)\n",
      "[epoch 17] loss: 0.6585055\n",
      "Test set: Average loss: 1.3383, Accuracy: 2937/5000 (59%)\n",
      "[epoch 18] loss: 0.6182494\n",
      "Test set: Average loss: 1.3932, Accuracy: 2900/5000 (58%)\n",
      "[epoch 19] loss: 0.5774136\n",
      "Test set: Average loss: 1.3943, Accuracy: 2919/5000 (58%)\n",
      "[epoch 20] loss: 0.5456091\n",
      "Test set: Average loss: 1.4256, Accuracy: 2849/5000 (57%)\n",
      "[epoch 21] loss: 0.4720617\n",
      "Test set: Average loss: 1.4827, Accuracy: 2930/5000 (59%)\n",
      "[epoch 22] loss: 0.4191711\n",
      "Test set: Average loss: 1.4791, Accuracy: 2962/5000 (59%)\n",
      "[epoch 23] loss: 0.3701084\n",
      "Test set: Average loss: 1.5504, Accuracy: 2922/5000 (58%)\n",
      "[epoch 24] loss: 0.3144472\n",
      "Test set: Average loss: 1.5757, Accuracy: 3008/5000 (60%)\n",
      "[epoch 25] loss: 0.2590385\n",
      "Test set: Average loss: 1.6450, Accuracy: 2925/5000 (58%)\n",
      "[epoch 26] loss: 0.1933004\n",
      "Test set: Average loss: 1.7001, Accuracy: 2981/5000 (60%)\n",
      "[epoch 27] loss: 0.1466647\n",
      "Test set: Average loss: 1.7093, Accuracy: 2966/5000 (59%)\n",
      "[epoch 28] loss: 0.1266729\n",
      "Test set: Average loss: 1.8878, Accuracy: 2934/5000 (59%)\n",
      "[epoch 29] loss: 0.1306744\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8643, Accuracy: 2918/5000 (58%)\n",
      "[epoch 30] loss: 0.0535225\n",
      "Test set: Average loss: 1.8099, Accuracy: 3028/5000 (61%)\n",
      "[epoch 31] loss: 0.0312524\n",
      "Test set: Average loss: 1.8343, Accuracy: 3024/5000 (60%)\n",
      "[epoch 32] loss: 0.0254247\n",
      "Test set: Average loss: 1.8552, Accuracy: 3012/5000 (60%)\n",
      "[epoch 33] loss: 0.0218560\n",
      "Test set: Average loss: 1.8733, Accuracy: 3034/5000 (61%)\n",
      "[epoch 34] loss: 0.0192113\n",
      "Test set: Average loss: 1.8904, Accuracy: 3018/5000 (60%)\n",
      "[epoch 35] loss: 0.0171450\n",
      "Test set: Average loss: 1.9125, Accuracy: 3022/5000 (60%)\n",
      "[epoch 36] loss: 0.0154801\n",
      "Test set: Average loss: 1.9325, Accuracy: 3026/5000 (61%)\n",
      "[epoch 37] loss: 0.0139452\n",
      "Test set: Average loss: 1.9500, Accuracy: 3018/5000 (60%)\n",
      "[epoch 38] loss: 0.0126196\n",
      "Test set: Average loss: 1.9705, Accuracy: 3023/5000 (60%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39] loss: 0.0114420\n",
      "Test set: Average loss: 1.9945, Accuracy: 3026/5000 (61%)\n",
      "[epoch 40] loss: 0.0103613\n",
      "Test set: Average loss: 2.0178, Accuracy: 3021/5000 (60%)\n",
      "[epoch 41] loss: 0.0093896\n",
      "Test set: Average loss: 2.0363, Accuracy: 3028/5000 (61%)\n",
      "[epoch 42] loss: 0.0084943\n",
      "Test set: Average loss: 2.0655, Accuracy: 3029/5000 (61%)\n",
      "[epoch 43] loss: 0.0076350\n",
      "Test set: Average loss: 2.0834, Accuracy: 3022/5000 (60%)\n",
      "[epoch 44] loss: 0.0068783\n",
      "Test set: Average loss: 2.1157, Accuracy: 3030/5000 (61%)\n",
      "[epoch 45] loss: 0.0061775\n",
      "Test set: Average loss: 2.1396, Accuracy: 3038/5000 (61%)\n",
      "[epoch 46] loss: 0.0055256\n",
      "Test set: Average loss: 2.1672, Accuracy: 3034/5000 (61%)\n",
      "[epoch 47] loss: 0.0049176\n",
      "Test set: Average loss: 2.1904, Accuracy: 3029/5000 (61%)\n",
      "[epoch 48] loss: 0.0043914\n",
      "Test set: Average loss: 2.2197, Accuracy: 3034/5000 (61%)\n",
      "[epoch 49] loss: 0.0038898\n",
      "Test set: Average loss: 2.2584, Accuracy: 3032/5000 (61%)\n",
      "[epoch 50] loss: 0.0034610\n",
      "Test set: Average loss: 2.2856, Accuracy: 3026/5000 (61%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1396, Accuracy: 3038/5000 (61%)\n",
      "Test\n",
      "Test set: Average loss: 2.1150, Accuracy: 6121/10000 (61%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3027, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 1.4043631\n",
      "Test set: Average loss: 1.2526, Accuracy: 2827/5000 (57%)\n",
      "[epoch 2] loss: 1.1932766\n",
      "Test set: Average loss: 1.3147, Accuracy: 2714/5000 (54%)\n",
      "[epoch 3] loss: 1.1172610\n",
      "Test set: Average loss: 1.1966, Accuracy: 2872/5000 (57%)\n",
      "[epoch 4] loss: 1.0664031\n",
      "Test set: Average loss: 1.2721, Accuracy: 2802/5000 (56%)\n",
      "[epoch 5] loss: 1.0301481\n",
      "Test set: Average loss: 1.2605, Accuracy: 2854/5000 (57%)\n",
      "[epoch 6] loss: 0.9937848\n",
      "Test set: Average loss: 1.1941, Accuracy: 2931/5000 (59%)\n",
      "[epoch 7] loss: 0.9607007\n",
      "Test set: Average loss: 1.2191, Accuracy: 2885/5000 (58%)\n",
      "[epoch 8] loss: 0.9231989\n",
      "Test set: Average loss: 1.2557, Accuracy: 2836/5000 (57%)\n",
      "[epoch 9] loss: 0.9148078\n",
      "Test set: Average loss: 1.2385, Accuracy: 2877/5000 (58%)\n",
      "[epoch 10] loss: 0.8808572\n",
      "Test set: Average loss: 1.2495, Accuracy: 2901/5000 (58%)\n",
      "[epoch 11] loss: 0.8738157\n",
      "Test set: Average loss: 1.2638, Accuracy: 2898/5000 (58%)\n",
      "[epoch 12] loss: 0.8486413\n",
      "Test set: Average loss: 1.3751, Accuracy: 2740/5000 (55%)\n",
      "[epoch 13] loss: 0.8273142\n",
      "Test set: Average loss: 1.2885, Accuracy: 2905/5000 (58%)\n",
      "[epoch 14] loss: 0.8003199\n",
      "Test set: Average loss: 1.3021, Accuracy: 2860/5000 (57%)\n",
      "[epoch 15] loss: 0.7550570\n",
      "Test set: Average loss: 1.3268, Accuracy: 2837/5000 (57%)\n",
      "[epoch 16] loss: 0.7160209\n",
      "Test set: Average loss: 1.3228, Accuracy: 2854/5000 (57%)\n",
      "[epoch 17] loss: 0.6739315\n",
      "Test set: Average loss: 1.3328, Accuracy: 2931/5000 (59%)\n",
      "[epoch 18] loss: 0.6235635\n",
      "Test set: Average loss: 1.4321, Accuracy: 2850/5000 (57%)\n",
      "[epoch 19] loss: 0.5981704\n",
      "Test set: Average loss: 1.4238, Accuracy: 2858/5000 (57%)\n",
      "[epoch 20] loss: 0.5433316\n",
      "Test set: Average loss: 1.4514, Accuracy: 2888/5000 (58%)\n",
      "[epoch 21] loss: 0.4990666\n",
      "Test set: Average loss: 1.5270, Accuracy: 2877/5000 (58%)\n",
      "[epoch 22] loss: 0.4593052\n",
      "Test set: Average loss: 1.6343, Accuracy: 2802/5000 (56%)\n",
      "[epoch 23] loss: 0.3805325\n",
      "Test set: Average loss: 1.5821, Accuracy: 2944/5000 (59%)\n",
      "[epoch 24] loss: 0.3408828\n",
      "Test set: Average loss: 1.6449, Accuracy: 2853/5000 (57%)\n",
      "[epoch 25] loss: 0.2824875\n",
      "Test set: Average loss: 1.7682, Accuracy: 2861/5000 (57%)\n",
      "[epoch 26] loss: 0.2076050\n",
      "Test set: Average loss: 1.7582, Accuracy: 2888/5000 (58%)\n",
      "[epoch 27] loss: 0.1712050\n",
      "Test set: Average loss: 1.8450, Accuracy: 2876/5000 (58%)\n",
      "[epoch 28] loss: 0.1570296\n",
      "Test set: Average loss: 1.8766, Accuracy: 2879/5000 (58%)\n",
      "[epoch 29] loss: 0.1062199\n",
      "Test set: Average loss: 2.0315, Accuracy: 2892/5000 (58%)\n",
      "[epoch 30] loss: 0.1435301\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 2.1333, Accuracy: 2815/5000 (56%)\n",
      "[epoch 31] loss: 0.0527222\n",
      "Test set: Average loss: 1.9979, Accuracy: 2924/5000 (58%)\n",
      "[epoch 32] loss: 0.0294210\n",
      "Test set: Average loss: 2.0129, Accuracy: 2932/5000 (59%)\n",
      "[epoch 33] loss: 0.0237251\n",
      "Test set: Average loss: 2.0322, Accuracy: 2948/5000 (59%)\n",
      "[epoch 34] loss: 0.0203022\n",
      "Test set: Average loss: 2.0459, Accuracy: 2953/5000 (59%)\n",
      "[epoch 35] loss: 0.0178401\n",
      "Test set: Average loss: 2.0684, Accuracy: 2950/5000 (59%)\n",
      "[epoch 36] loss: 0.0157523\n",
      "Test set: Average loss: 2.0852, Accuracy: 2961/5000 (59%)\n",
      "[epoch 37] loss: 0.0140711\n",
      "Test set: Average loss: 2.1022, Accuracy: 2960/5000 (59%)\n",
      "[epoch 38] loss: 0.0126266\n",
      "Test set: Average loss: 2.1212, Accuracy: 2952/5000 (59%)\n",
      "[epoch 39] loss: 0.0113768\n",
      "Test set: Average loss: 2.1432, Accuracy: 2952/5000 (59%)\n",
      "[epoch 40] loss: 0.0102419\n",
      "Test set: Average loss: 2.1635, Accuracy: 2963/5000 (59%)\n",
      "[epoch 41] loss: 0.0092230\n",
      "Test set: Average loss: 2.1852, Accuracy: 2957/5000 (59%)\n",
      "[epoch 42] loss: 0.0083365\n",
      "Test set: Average loss: 2.2096, Accuracy: 2960/5000 (59%)\n",
      "[epoch 43] loss: 0.0074890\n",
      "Test set: Average loss: 2.2348, Accuracy: 2961/5000 (59%)\n",
      "[epoch 44] loss: 0.0067248\n",
      "Test set: Average loss: 2.2594, Accuracy: 2968/5000 (59%)\n",
      "[epoch 45] loss: 0.0060563\n",
      "Test set: Average loss: 2.2838, Accuracy: 2963/5000 (59%)\n",
      "[epoch 46] loss: 0.0054168\n",
      "Test set: Average loss: 2.3108, Accuracy: 2972/5000 (59%)\n",
      "[epoch 47] loss: 0.0048531\n",
      "Test set: Average loss: 2.3410, Accuracy: 2975/5000 (60%)\n",
      "[epoch 48] loss: 0.0043256\n",
      "Test set: Average loss: 2.3693, Accuracy: 2972/5000 (59%)\n",
      "[epoch 49] loss: 0.0038399\n",
      "Test set: Average loss: 2.4198, Accuracy: 2969/5000 (59%)\n",
      "[epoch 50] loss: 0.0034136\n",
      "Test set: Average loss: 2.4290, Accuracy: 2966/5000 (59%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3410, Accuracy: 2975/5000 (60%)\n",
      "Test\n",
      "Test set: Average loss: 2.2507, Accuracy: 6028/10000 (60%)\n",
      "15000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 665/5000 (13%)\n",
      "[epoch 1] loss: 1.3159789\n",
      "Test set: Average loss: 1.2541, Accuracy: 2727/5000 (55%)\n",
      "[epoch 2] loss: 1.1451894\n",
      "Test set: Average loss: 1.2442, Accuracy: 2857/5000 (57%)\n",
      "[epoch 3] loss: 1.0942201\n",
      "Test set: Average loss: 1.1940, Accuracy: 2915/5000 (58%)\n",
      "[epoch 4] loss: 1.0450315\n",
      "Test set: Average loss: 1.1906, Accuracy: 2911/5000 (58%)\n",
      "[epoch 5] loss: 1.0058915\n",
      "Test set: Average loss: 1.1723, Accuracy: 2988/5000 (60%)\n",
      "[epoch 6] loss: 0.9903473\n",
      "Test set: Average loss: 1.2476, Accuracy: 2840/5000 (57%)\n",
      "[epoch 7] loss: 0.9567819\n",
      "Test set: Average loss: 1.1912, Accuracy: 2968/5000 (59%)\n",
      "[epoch 8] loss: 0.9297285\n",
      "Test set: Average loss: 1.1773, Accuracy: 2954/5000 (59%)\n",
      "[epoch 9] loss: 0.8850187\n",
      "Test set: Average loss: 1.2337, Accuracy: 2877/5000 (58%)\n",
      "[epoch 10] loss: 0.8686194\n",
      "Test set: Average loss: 1.2195, Accuracy: 2959/5000 (59%)\n",
      "[epoch 11] loss: 0.8392834\n",
      "Test set: Average loss: 1.3214, Accuracy: 2907/5000 (58%)\n",
      "[epoch 12] loss: 0.8104832\n",
      "Test set: Average loss: 1.1922, Accuracy: 3020/5000 (60%)\n",
      "[epoch 13] loss: 0.7868498\n",
      "Test set: Average loss: 1.1749, Accuracy: 3015/5000 (60%)\n",
      "[epoch 14] loss: 0.7363354\n",
      "Test set: Average loss: 1.2099, Accuracy: 3041/5000 (61%)\n",
      "[epoch 15] loss: 0.7185109\n",
      "Test set: Average loss: 1.1938, Accuracy: 3043/5000 (61%)\n",
      "[epoch 16] loss: 0.6605151\n",
      "Test set: Average loss: 1.2418, Accuracy: 3031/5000 (61%)\n",
      "[epoch 17] loss: 0.6224610\n",
      "Test set: Average loss: 1.2823, Accuracy: 2970/5000 (59%)\n",
      "[epoch 18] loss: 0.5717392\n",
      "Test set: Average loss: 1.2967, Accuracy: 3023/5000 (60%)\n",
      "[epoch 19] loss: 0.5209430\n",
      "Test set: Average loss: 1.3308, Accuracy: 3012/5000 (60%)\n",
      "[epoch 20] loss: 0.4615519\n",
      "Test set: Average loss: 1.3498, Accuracy: 3037/5000 (61%)\n",
      "[epoch 21] loss: 0.4138733\n",
      "Test set: Average loss: 1.3937, Accuracy: 3062/5000 (61%)\n",
      "[epoch 22] loss: 0.3401646\n",
      "Test set: Average loss: 1.4243, Accuracy: 3041/5000 (61%)\n",
      "[epoch 23] loss: 0.2770026\n",
      "Test set: Average loss: 1.5075, Accuracy: 3015/5000 (60%)\n",
      "[epoch 24] loss: 0.2288341\n",
      "Test set: Average loss: 1.6223, Accuracy: 2970/5000 (59%)\n",
      "[epoch 25] loss: 0.2047552\n",
      "Test set: Average loss: 1.6832, Accuracy: 2982/5000 (60%)\n",
      "[epoch 26] loss: 0.1364341\n",
      "Test set: Average loss: 1.6759, Accuracy: 3012/5000 (60%)\n",
      "[epoch 27] loss: 0.1009588\n",
      "Test set: Average loss: 1.7396, Accuracy: 3066/5000 (61%)\n",
      "[epoch 28] loss: 0.1320062\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8853, Accuracy: 3042/5000 (61%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] loss: 0.0440865\n",
      "Test set: Average loss: 1.7946, Accuracy: 3063/5000 (61%)\n",
      "[epoch 30] loss: 0.0233303\n",
      "Test set: Average loss: 1.8035, Accuracy: 3084/5000 (62%)\n",
      "[epoch 31] loss: 0.0177030\n",
      "Test set: Average loss: 1.8120, Accuracy: 3090/5000 (62%)\n",
      "[epoch 32] loss: 0.0144444\n",
      "Test set: Average loss: 1.8265, Accuracy: 3090/5000 (62%)\n",
      "[epoch 33] loss: 0.0121708\n",
      "Test set: Average loss: 1.8416, Accuracy: 3093/5000 (62%)\n",
      "[epoch 34] loss: 0.0103683\n",
      "Test set: Average loss: 1.8605, Accuracy: 3110/5000 (62%)\n",
      "[epoch 35] loss: 0.0088715\n",
      "Test set: Average loss: 1.8810, Accuracy: 3095/5000 (62%)\n",
      "[epoch 36] loss: 0.0076026\n",
      "Test set: Average loss: 1.9083, Accuracy: 3093/5000 (62%)\n",
      "[epoch 37] loss: 0.0065529\n",
      "Test set: Average loss: 1.9261, Accuracy: 3091/5000 (62%)\n",
      "[epoch 38] loss: 0.0056049\n",
      "Test set: Average loss: 1.9543, Accuracy: 3107/5000 (62%)\n",
      "[epoch 39] loss: 0.0047981\n",
      "Test set: Average loss: 1.9782, Accuracy: 3107/5000 (62%)\n",
      "[epoch 40] loss: 0.0040866\n",
      "Test set: Average loss: 2.0101, Accuracy: 3111/5000 (62%)\n",
      "[epoch 41] loss: 0.0034659\n",
      "Test set: Average loss: 2.0355, Accuracy: 3101/5000 (62%)\n",
      "[epoch 42] loss: 0.0029297\n",
      "Test set: Average loss: 2.0652, Accuracy: 3105/5000 (62%)\n",
      "[epoch 43] loss: 0.0024794\n",
      "Test set: Average loss: 2.1094, Accuracy: 3100/5000 (62%)\n",
      "[epoch 44] loss: 0.0020596\n",
      "Test set: Average loss: 2.1362, Accuracy: 3106/5000 (62%)\n",
      "[epoch 45] loss: 0.0017188\n",
      "Test set: Average loss: 2.1705, Accuracy: 3108/5000 (62%)\n",
      "[epoch 46] loss: 0.0014308\n",
      "Test set: Average loss: 2.2023, Accuracy: 3116/5000 (62%)\n",
      "[epoch 47] loss: 0.0011819\n",
      "Test set: Average loss: 2.2382, Accuracy: 3113/5000 (62%)\n",
      "[epoch 48] loss: 0.0009769\n",
      "Test set: Average loss: 2.2800, Accuracy: 3114/5000 (62%)\n",
      "[epoch 49] loss: 0.0008063\n",
      "Test set: Average loss: 2.3226, Accuracy: 3112/5000 (62%)\n",
      "[epoch 50] loss: 0.0006616\n",
      "Test set: Average loss: 2.3521, Accuracy: 3121/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3521, Accuracy: 3121/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.2845, Accuracy: 6342/10000 (63%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3047, Accuracy: 416/5000 (8%)\n",
      "[epoch 1] loss: 1.3164530\n",
      "Test set: Average loss: 1.2438, Accuracy: 2828/5000 (57%)\n",
      "[epoch 2] loss: 1.1372888\n",
      "Test set: Average loss: 1.2429, Accuracy: 2806/5000 (56%)\n",
      "[epoch 3] loss: 1.0944365\n",
      "Test set: Average loss: 1.2335, Accuracy: 2864/5000 (57%)\n",
      "[epoch 4] loss: 1.0523988\n",
      "Test set: Average loss: 1.1655, Accuracy: 2963/5000 (59%)\n",
      "[epoch 5] loss: 1.0185069\n",
      "Test set: Average loss: 1.1751, Accuracy: 2957/5000 (59%)\n",
      "[epoch 6] loss: 0.9959676\n",
      "Test set: Average loss: 1.1467, Accuracy: 3004/5000 (60%)\n",
      "[epoch 7] loss: 0.9590422\n",
      "Test set: Average loss: 1.2225, Accuracy: 2961/5000 (59%)\n",
      "[epoch 8] loss: 0.9370356\n",
      "Test set: Average loss: 1.1485, Accuracy: 3027/5000 (61%)\n",
      "[epoch 9] loss: 0.9064911\n",
      "Test set: Average loss: 1.1376, Accuracy: 2991/5000 (60%)\n",
      "[epoch 10] loss: 0.8764862\n",
      "Test set: Average loss: 1.1379, Accuracy: 3071/5000 (61%)\n",
      "[epoch 11] loss: 0.8542961\n",
      "Test set: Average loss: 1.1973, Accuracy: 2991/5000 (60%)\n",
      "[epoch 12] loss: 0.8271312\n",
      "Test set: Average loss: 1.2155, Accuracy: 2945/5000 (59%)\n",
      "[epoch 13] loss: 0.7850223\n",
      "Test set: Average loss: 1.2333, Accuracy: 2984/5000 (60%)\n",
      "[epoch 14] loss: 0.7420592\n",
      "Test set: Average loss: 1.2151, Accuracy: 2976/5000 (60%)\n",
      "[epoch 15] loss: 0.7135599\n",
      "Test set: Average loss: 1.1893, Accuracy: 3013/5000 (60%)\n",
      "[epoch 16] loss: 0.6681451\n",
      "Test set: Average loss: 1.2707, Accuracy: 2980/5000 (60%)\n",
      "[epoch 17] loss: 0.6269404\n",
      "Test set: Average loss: 1.2514, Accuracy: 2990/5000 (60%)\n",
      "[epoch 18] loss: 0.5748489\n",
      "Test set: Average loss: 1.2542, Accuracy: 3082/5000 (62%)\n",
      "[epoch 19] loss: 0.4977318\n",
      "Test set: Average loss: 1.2648, Accuracy: 3094/5000 (62%)\n",
      "[epoch 20] loss: 0.4577811\n",
      "Test set: Average loss: 1.3496, Accuracy: 3050/5000 (61%)\n",
      "[epoch 21] loss: 0.3825867\n",
      "Test set: Average loss: 1.3936, Accuracy: 3026/5000 (61%)\n",
      "[epoch 22] loss: 0.3304658\n",
      "Test set: Average loss: 1.4010, Accuracy: 3077/5000 (62%)\n",
      "[epoch 23] loss: 0.2531930\n",
      "Test set: Average loss: 1.4933, Accuracy: 3033/5000 (61%)\n",
      "[epoch 24] loss: 0.2141239\n",
      "Test set: Average loss: 1.6199, Accuracy: 2943/5000 (59%)\n",
      "[epoch 25] loss: 0.1754585\n",
      "Test set: Average loss: 1.6688, Accuracy: 3025/5000 (60%)\n",
      "[epoch 26] loss: 0.1241139\n",
      "Test set: Average loss: 1.7530, Accuracy: 3031/5000 (61%)\n",
      "[epoch 27] loss: 0.0960701\n",
      "Test set: Average loss: 1.7956, Accuracy: 3008/5000 (60%)\n",
      "[epoch 28] loss: 0.1188790\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9018, Accuracy: 3000/5000 (60%)\n",
      "[epoch 29] loss: 0.0426126\n",
      "Test set: Average loss: 1.8146, Accuracy: 3068/5000 (61%)\n",
      "[epoch 30] loss: 0.0193314\n",
      "Test set: Average loss: 1.8185, Accuracy: 3090/5000 (62%)\n",
      "[epoch 31] loss: 0.0146085\n",
      "Test set: Average loss: 1.8357, Accuracy: 3084/5000 (62%)\n",
      "[epoch 32] loss: 0.0119123\n",
      "Test set: Average loss: 1.8499, Accuracy: 3101/5000 (62%)\n",
      "[epoch 33] loss: 0.0099769\n",
      "Test set: Average loss: 1.8642, Accuracy: 3110/5000 (62%)\n",
      "[epoch 34] loss: 0.0084903\n",
      "Test set: Average loss: 1.8815, Accuracy: 3116/5000 (62%)\n",
      "[epoch 35] loss: 0.0073033\n",
      "Test set: Average loss: 1.9011, Accuracy: 3114/5000 (62%)\n",
      "[epoch 36] loss: 0.0062764\n",
      "Test set: Average loss: 1.9198, Accuracy: 3120/5000 (62%)\n",
      "[epoch 37] loss: 0.0054069\n",
      "Test set: Average loss: 1.9451, Accuracy: 3118/5000 (62%)\n",
      "[epoch 38] loss: 0.0046468\n",
      "Test set: Average loss: 1.9678, Accuracy: 3122/5000 (62%)\n",
      "[epoch 39] loss: 0.0039795\n",
      "Test set: Average loss: 1.9968, Accuracy: 3117/5000 (62%)\n",
      "[epoch 40] loss: 0.0033848\n",
      "Test set: Average loss: 2.0209, Accuracy: 3137/5000 (63%)\n",
      "[epoch 41] loss: 0.0028682\n",
      "Test set: Average loss: 2.0463, Accuracy: 3125/5000 (62%)\n",
      "[epoch 42] loss: 0.0024296\n",
      "Test set: Average loss: 2.0797, Accuracy: 3134/5000 (63%)\n",
      "[epoch 43] loss: 0.0020408\n",
      "Test set: Average loss: 2.1126, Accuracy: 3139/5000 (63%)\n",
      "[epoch 44] loss: 0.0017069\n",
      "Test set: Average loss: 2.1367, Accuracy: 3129/5000 (63%)\n",
      "[epoch 45] loss: 0.0014192\n",
      "Test set: Average loss: 2.1739, Accuracy: 3125/5000 (62%)\n",
      "[epoch 46] loss: 0.0011766\n",
      "Test set: Average loss: 2.2085, Accuracy: 3145/5000 (63%)\n",
      "[epoch 47] loss: 0.0009754\n",
      "Test set: Average loss: 2.2444, Accuracy: 3133/5000 (63%)\n",
      "[epoch 48] loss: 0.0008027\n",
      "Test set: Average loss: 2.2873, Accuracy: 3132/5000 (63%)\n",
      "[epoch 49] loss: 0.0006568\n",
      "Test set: Average loss: 2.3172, Accuracy: 3150/5000 (63%)\n",
      "[epoch 50] loss: 0.0005373\n",
      "Test set: Average loss: 2.3550, Accuracy: 3139/5000 (63%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3172, Accuracy: 3150/5000 (63%)\n",
      "Test\n",
      "Test set: Average loss: 2.2284, Accuracy: 6410/10000 (64%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3037, Accuracy: 482/5000 (10%)\n",
      "[epoch 1] loss: 1.3235802\n",
      "Test set: Average loss: 1.1860, Accuracy: 2922/5000 (58%)\n",
      "[epoch 2] loss: 1.1392159\n",
      "Test set: Average loss: 1.1573, Accuracy: 2956/5000 (59%)\n",
      "[epoch 3] loss: 1.0826210\n",
      "Test set: Average loss: 1.1500, Accuracy: 2991/5000 (60%)\n",
      "[epoch 4] loss: 1.0452617\n",
      "Test set: Average loss: 1.1529, Accuracy: 2931/5000 (59%)\n",
      "[epoch 5] loss: 1.0143609\n",
      "Test set: Average loss: 1.1821, Accuracy: 2939/5000 (59%)\n",
      "[epoch 6] loss: 0.9755184\n",
      "Test set: Average loss: 1.2054, Accuracy: 2917/5000 (58%)\n",
      "[epoch 7] loss: 0.9665984\n",
      "Test set: Average loss: 1.2118, Accuracy: 2919/5000 (58%)\n",
      "[epoch 8] loss: 0.9315064\n",
      "Test set: Average loss: 1.2190, Accuracy: 2937/5000 (59%)\n",
      "[epoch 9] loss: 0.9184637\n",
      "Test set: Average loss: 1.2166, Accuracy: 2969/5000 (59%)\n",
      "[epoch 10] loss: 0.8959824\n",
      "Test set: Average loss: 1.1747, Accuracy: 3007/5000 (60%)\n",
      "[epoch 11] loss: 0.8685918\n",
      "Test set: Average loss: 1.2027, Accuracy: 2964/5000 (59%)\n",
      "[epoch 12] loss: 0.8344906\n",
      "Test set: Average loss: 1.2108, Accuracy: 2972/5000 (59%)\n",
      "[epoch 13] loss: 0.8094949\n",
      "Test set: Average loss: 1.2562, Accuracy: 2892/5000 (58%)\n",
      "[epoch 14] loss: 0.7638379\n",
      "Test set: Average loss: 1.1859, Accuracy: 3022/5000 (60%)\n",
      "[epoch 15] loss: 0.7335598\n",
      "Test set: Average loss: 1.1968, Accuracy: 3042/5000 (61%)\n",
      "[epoch 16] loss: 0.6878049\n",
      "Test set: Average loss: 1.2692, Accuracy: 2995/5000 (60%)\n",
      "[epoch 17] loss: 0.6493080\n",
      "Test set: Average loss: 1.2016, Accuracy: 3045/5000 (61%)\n",
      "[epoch 18] loss: 0.5935305\n",
      "Test set: Average loss: 1.2638, Accuracy: 2990/5000 (60%)\n",
      "[epoch 19] loss: 0.5487779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.2775, Accuracy: 2968/5000 (59%)\n",
      "[epoch 20] loss: 0.4594543\n",
      "Test set: Average loss: 1.3423, Accuracy: 3027/5000 (61%)\n",
      "[epoch 21] loss: 0.4186958\n",
      "Test set: Average loss: 1.3450, Accuracy: 3086/5000 (62%)\n",
      "[epoch 22] loss: 0.3400002\n",
      "Test set: Average loss: 1.4578, Accuracy: 2972/5000 (59%)\n",
      "[epoch 23] loss: 0.2776138\n",
      "Test set: Average loss: 1.4425, Accuracy: 3013/5000 (60%)\n",
      "[epoch 24] loss: 0.2410144\n",
      "Test set: Average loss: 1.5985, Accuracy: 3004/5000 (60%)\n",
      "[epoch 25] loss: 0.1764890\n",
      "Test set: Average loss: 1.5676, Accuracy: 3057/5000 (61%)\n",
      "[epoch 26] loss: 0.1379360\n",
      "Test set: Average loss: 1.6832, Accuracy: 3023/5000 (60%)\n",
      "[epoch 27] loss: 0.1261918\n",
      "Test set: Average loss: 1.7530, Accuracy: 3029/5000 (61%)\n",
      "[epoch 28] loss: 0.1252699\n",
      "Test set: Average loss: 1.8691, Accuracy: 3026/5000 (61%)\n",
      "[epoch 29] loss: 0.1037267\n",
      "Test set: Average loss: 2.0300, Accuracy: 2907/5000 (58%)\n",
      "[epoch 30] loss: 0.1297657\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.9114, Accuracy: 2996/5000 (60%)\n",
      "[epoch 31] loss: 0.0362497\n",
      "Test set: Average loss: 1.8845, Accuracy: 3048/5000 (61%)\n",
      "[epoch 32] loss: 0.0172963\n",
      "Test set: Average loss: 1.8937, Accuracy: 3057/5000 (61%)\n",
      "[epoch 33] loss: 0.0128525\n",
      "Test set: Average loss: 1.9058, Accuracy: 3070/5000 (61%)\n",
      "[epoch 34] loss: 0.0104184\n",
      "Test set: Average loss: 1.9191, Accuracy: 3076/5000 (62%)\n",
      "[epoch 35] loss: 0.0087143\n",
      "Test set: Average loss: 1.9335, Accuracy: 3074/5000 (61%)\n",
      "[epoch 36] loss: 0.0073686\n",
      "Test set: Average loss: 1.9479, Accuracy: 3071/5000 (61%)\n",
      "[epoch 37] loss: 0.0062850\n",
      "Test set: Average loss: 1.9609, Accuracy: 3076/5000 (62%)\n",
      "[epoch 38] loss: 0.0053973\n",
      "Test set: Average loss: 1.9862, Accuracy: 3076/5000 (62%)\n",
      "[epoch 39] loss: 0.0046242\n",
      "Test set: Average loss: 2.0014, Accuracy: 3075/5000 (62%)\n",
      "[epoch 40] loss: 0.0039793\n",
      "Test set: Average loss: 2.0261, Accuracy: 3081/5000 (62%)\n",
      "[epoch 41] loss: 0.0034006\n",
      "Test set: Average loss: 2.0497, Accuracy: 3080/5000 (62%)\n",
      "[epoch 42] loss: 0.0029073\n",
      "Test set: Average loss: 2.0719, Accuracy: 3081/5000 (62%)\n",
      "[epoch 43] loss: 0.0024746\n",
      "Test set: Average loss: 2.0981, Accuracy: 3089/5000 (62%)\n",
      "[epoch 44] loss: 0.0021057\n",
      "Test set: Average loss: 2.1225, Accuracy: 3091/5000 (62%)\n",
      "[epoch 45] loss: 0.0017810\n",
      "Test set: Average loss: 2.1578, Accuracy: 3097/5000 (62%)\n",
      "[epoch 46] loss: 0.0014966\n",
      "Test set: Average loss: 2.1862, Accuracy: 3089/5000 (62%)\n",
      "[epoch 47] loss: 0.0012554\n",
      "Test set: Average loss: 2.2174, Accuracy: 3098/5000 (62%)\n",
      "[epoch 48] loss: 0.0010453\n",
      "Test set: Average loss: 2.2464, Accuracy: 3101/5000 (62%)\n",
      "[epoch 49] loss: 0.0008775\n",
      "Test set: Average loss: 2.2804, Accuracy: 3109/5000 (62%)\n",
      "[epoch 50] loss: 0.0007228\n",
      "Test set: Average loss: 2.3149, Accuracy: 3107/5000 (62%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2804, Accuracy: 3109/5000 (62%)\n",
      "Test\n",
      "Test set: Average loss: 2.2163, Accuracy: 6321/10000 (63%)\n",
      "20000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3040, Accuracy: 504/5000 (10%)\n",
      "[epoch 1] loss: 1.2943535\n",
      "Test set: Average loss: 1.2758, Accuracy: 2702/5000 (54%)\n",
      "[epoch 2] loss: 1.1327390\n",
      "Test set: Average loss: 1.1499, Accuracy: 2932/5000 (59%)\n",
      "[epoch 3] loss: 1.0739056\n",
      "Test set: Average loss: 1.1318, Accuracy: 3022/5000 (60%)\n",
      "[epoch 4] loss: 1.0334309\n",
      "Test set: Average loss: 1.1318, Accuracy: 3043/5000 (61%)\n",
      "[epoch 5] loss: 0.9990529\n",
      "Test set: Average loss: 1.2199, Accuracy: 2923/5000 (58%)\n",
      "[epoch 6] loss: 0.9748606\n",
      "Test set: Average loss: 1.1353, Accuracy: 3039/5000 (61%)\n",
      "[epoch 7] loss: 0.9515366\n",
      "Test set: Average loss: 1.1318, Accuracy: 3023/5000 (60%)\n",
      "[epoch 8] loss: 0.9312824\n",
      "Test set: Average loss: 1.1635, Accuracy: 2971/5000 (59%)\n",
      "[epoch 9] loss: 0.9001095\n",
      "Test set: Average loss: 1.1443, Accuracy: 3037/5000 (61%)\n",
      "[epoch 10] loss: 0.8697490\n",
      "Test set: Average loss: 1.1215, Accuracy: 3054/5000 (61%)\n",
      "[epoch 11] loss: 0.8442938\n",
      "Test set: Average loss: 1.1850, Accuracy: 2973/5000 (59%)\n",
      "[epoch 12] loss: 0.8041238\n",
      "Test set: Average loss: 1.0959, Accuracy: 3150/5000 (63%)\n",
      "[epoch 13] loss: 0.7675944\n",
      "Test set: Average loss: 1.1620, Accuracy: 3063/5000 (61%)\n",
      "[epoch 14] loss: 0.7300237\n",
      "Test set: Average loss: 1.1815, Accuracy: 3076/5000 (62%)\n",
      "[epoch 15] loss: 0.6819097\n",
      "Test set: Average loss: 1.1396, Accuracy: 3156/5000 (63%)\n",
      "[epoch 16] loss: 0.6265273\n",
      "Test set: Average loss: 1.1402, Accuracy: 3108/5000 (62%)\n",
      "[epoch 17] loss: 0.5776627\n",
      "Test set: Average loss: 1.2360, Accuracy: 3029/5000 (61%)\n",
      "[epoch 18] loss: 0.5130701\n",
      "Test set: Average loss: 1.2565, Accuracy: 3098/5000 (62%)\n",
      "[epoch 19] loss: 0.4556687\n",
      "Test set: Average loss: 1.2578, Accuracy: 3148/5000 (63%)\n",
      "[epoch 20] loss: 0.3880653\n",
      "Test set: Average loss: 1.3533, Accuracy: 3078/5000 (62%)\n",
      "[epoch 21] loss: 0.3194480\n",
      "Test set: Average loss: 1.3816, Accuracy: 3088/5000 (62%)\n",
      "[epoch 22] loss: 0.2480527\n",
      "Test set: Average loss: 1.4454, Accuracy: 3093/5000 (62%)\n",
      "[epoch 23] loss: 0.1976338\n",
      "Test set: Average loss: 1.5570, Accuracy: 3123/5000 (62%)\n",
      "[epoch 24] loss: 0.1572717\n",
      "Test set: Average loss: 1.5705, Accuracy: 3124/5000 (62%)\n",
      "[epoch 25] loss: 0.1346067\n",
      "Test set: Average loss: 1.7157, Accuracy: 3091/5000 (62%)\n",
      "[epoch 26] loss: 0.1038253\n",
      "Test set: Average loss: 1.7550, Accuracy: 3084/5000 (62%)\n",
      "[epoch 27] loss: 0.0953198\n",
      "Test set: Average loss: 1.9167, Accuracy: 3048/5000 (61%)\n",
      "[epoch 28] loss: 0.1355739\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7954, Accuracy: 3119/5000 (62%)\n",
      "[epoch 29] loss: 0.0378843\n",
      "Test set: Average loss: 1.7421, Accuracy: 3187/5000 (64%)\n",
      "[epoch 30] loss: 0.0157730\n",
      "Test set: Average loss: 1.7534, Accuracy: 3191/5000 (64%)\n",
      "[epoch 31] loss: 0.0108805\n",
      "Test set: Average loss: 1.7709, Accuracy: 3199/5000 (64%)\n",
      "[epoch 32] loss: 0.0083445\n",
      "Test set: Average loss: 1.7871, Accuracy: 3195/5000 (64%)\n",
      "[epoch 33] loss: 0.0066380\n",
      "Test set: Average loss: 1.8061, Accuracy: 3203/5000 (64%)\n",
      "[epoch 34] loss: 0.0053339\n",
      "Test set: Average loss: 1.8253, Accuracy: 3197/5000 (64%)\n",
      "[epoch 35] loss: 0.0043426\n",
      "Test set: Average loss: 1.8459, Accuracy: 3196/5000 (64%)\n",
      "[epoch 36] loss: 0.0035299\n",
      "Test set: Average loss: 1.8695, Accuracy: 3206/5000 (64%)\n",
      "[epoch 37] loss: 0.0028605\n",
      "Test set: Average loss: 1.8968, Accuracy: 3201/5000 (64%)\n",
      "[epoch 38] loss: 0.0023093\n",
      "Test set: Average loss: 1.9229, Accuracy: 3199/5000 (64%)\n",
      "[epoch 39] loss: 0.0018570\n",
      "Test set: Average loss: 1.9584, Accuracy: 3195/5000 (64%)\n",
      "[epoch 40] loss: 0.0014832\n",
      "Test set: Average loss: 1.9864, Accuracy: 3191/5000 (64%)\n",
      "[epoch 41] loss: 0.0011838\n",
      "Test set: Average loss: 2.0185, Accuracy: 3196/5000 (64%)\n",
      "[epoch 42] loss: 0.0009379\n",
      "Test set: Average loss: 2.0535, Accuracy: 3188/5000 (64%)\n",
      "[epoch 43] loss: 0.0007342\n",
      "Test set: Average loss: 2.0858, Accuracy: 3197/5000 (64%)\n",
      "[epoch 44] loss: 0.0005766\n",
      "Test set: Average loss: 2.1242, Accuracy: 3199/5000 (64%)\n",
      "[epoch 45] loss: 0.0004499\n",
      "Test set: Average loss: 2.1600, Accuracy: 3195/5000 (64%)\n",
      "[epoch 46] loss: 0.0003485\n",
      "Test set: Average loss: 2.1982, Accuracy: 3209/5000 (64%)\n",
      "[epoch 47] loss: 0.0002693\n",
      "Test set: Average loss: 2.2402, Accuracy: 3197/5000 (64%)\n",
      "[epoch 48] loss: 0.0002077\n",
      "Test set: Average loss: 2.2827, Accuracy: 3205/5000 (64%)\n",
      "[epoch 49] loss: 0.0001592\n",
      "Test set: Average loss: 2.3179, Accuracy: 3212/5000 (64%)\n",
      "[epoch 50] loss: 0.0001224\n",
      "Test set: Average loss: 2.3676, Accuracy: 3208/5000 (64%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3179, Accuracy: 3212/5000 (64%)\n",
      "Test\n",
      "Test set: Average loss: 2.3117, Accuracy: 6559/10000 (66%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3016, Accuracy: 515/5000 (10%)\n",
      "[epoch 1] loss: 1.2909243\n",
      "Test set: Average loss: 1.2376, Accuracy: 2826/5000 (57%)\n",
      "[epoch 2] loss: 1.1296628\n",
      "Test set: Average loss: 1.1805, Accuracy: 2960/5000 (59%)\n",
      "[epoch 3] loss: 1.0678976\n",
      "Test set: Average loss: 1.1327, Accuracy: 3001/5000 (60%)\n",
      "[epoch 4] loss: 1.0358734\n",
      "Test set: Average loss: 1.1022, Accuracy: 3046/5000 (61%)\n",
      "[epoch 5] loss: 1.0013056\n",
      "Test set: Average loss: 1.1799, Accuracy: 2936/5000 (59%)\n",
      "[epoch 6] loss: 0.9694815\n",
      "Test set: Average loss: 1.1531, Accuracy: 3020/5000 (60%)\n",
      "[epoch 7] loss: 0.9540230\n",
      "Test set: Average loss: 1.1094, Accuracy: 3079/5000 (62%)\n",
      "[epoch 8] loss: 0.9090683\n",
      "Test set: Average loss: 1.1382, Accuracy: 3053/5000 (61%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 0.8880003\n",
      "Test set: Average loss: 1.1279, Accuracy: 3066/5000 (61%)\n",
      "[epoch 10] loss: 0.8546108\n",
      "Test set: Average loss: 1.1294, Accuracy: 3102/5000 (62%)\n",
      "[epoch 11] loss: 0.8260582\n",
      "Test set: Average loss: 1.0883, Accuracy: 3161/5000 (63%)\n",
      "[epoch 12] loss: 0.7947177\n",
      "Test set: Average loss: 1.2166, Accuracy: 2981/5000 (60%)\n",
      "[epoch 13] loss: 0.7571470\n",
      "Test set: Average loss: 1.1738, Accuracy: 3024/5000 (60%)\n",
      "[epoch 14] loss: 0.7116898\n",
      "Test set: Average loss: 1.1477, Accuracy: 3119/5000 (62%)\n",
      "[epoch 15] loss: 0.6682229\n",
      "Test set: Average loss: 1.1826, Accuracy: 3130/5000 (63%)\n",
      "[epoch 16] loss: 0.6196953\n",
      "Test set: Average loss: 1.1512, Accuracy: 3184/5000 (64%)\n",
      "[epoch 17] loss: 0.5575367\n",
      "Test set: Average loss: 1.2023, Accuracy: 3152/5000 (63%)\n",
      "[epoch 18] loss: 0.5014929\n",
      "Test set: Average loss: 1.2806, Accuracy: 3143/5000 (63%)\n",
      "[epoch 19] loss: 0.4258285\n",
      "Test set: Average loss: 1.3304, Accuracy: 3141/5000 (63%)\n",
      "[epoch 20] loss: 0.3550959\n",
      "Test set: Average loss: 1.3513, Accuracy: 3151/5000 (63%)\n",
      "[epoch 21] loss: 0.2837761\n",
      "Test set: Average loss: 1.3483, Accuracy: 3200/5000 (64%)\n",
      "[epoch 22] loss: 0.2354018\n",
      "Test set: Average loss: 1.4255, Accuracy: 3172/5000 (63%)\n",
      "[epoch 23] loss: 0.1693766\n",
      "Test set: Average loss: 1.5522, Accuracy: 3200/5000 (64%)\n",
      "[epoch 24] loss: 0.1353704\n",
      "Test set: Average loss: 1.5708, Accuracy: 3168/5000 (63%)\n",
      "[epoch 25] loss: 0.1241910\n",
      "Test set: Average loss: 1.6818, Accuracy: 3098/5000 (62%)\n",
      "[epoch 26] loss: 0.1231273\n",
      "Test set: Average loss: 1.7510, Accuracy: 3150/5000 (63%)\n",
      "[epoch 27] loss: 0.0969019\n",
      "Test set: Average loss: 1.7730, Accuracy: 3185/5000 (64%)\n",
      "[epoch 28] loss: 0.0894206\n",
      "Test set: Average loss: 1.9486, Accuracy: 3146/5000 (63%)\n",
      "[epoch 29] loss: 0.1285048\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8882, Accuracy: 3178/5000 (64%)\n",
      "[epoch 30] loss: 0.0295988\n",
      "Test set: Average loss: 1.8411, Accuracy: 3240/5000 (65%)\n",
      "[epoch 31] loss: 0.0108884\n",
      "Test set: Average loss: 1.8540, Accuracy: 3250/5000 (65%)\n",
      "[epoch 32] loss: 0.0075379\n",
      "Test set: Average loss: 1.8679, Accuracy: 3265/5000 (65%)\n",
      "[epoch 33] loss: 0.0057969\n",
      "Test set: Average loss: 1.9014, Accuracy: 3266/5000 (65%)\n",
      "[epoch 34] loss: 0.0046548\n",
      "Test set: Average loss: 1.9020, Accuracy: 3273/5000 (65%)\n",
      "[epoch 35] loss: 0.0037646\n",
      "Test set: Average loss: 1.9170, Accuracy: 3267/5000 (65%)\n",
      "[epoch 36] loss: 0.0030709\n",
      "Test set: Average loss: 1.9360, Accuracy: 3274/5000 (65%)\n",
      "[epoch 37] loss: 0.0025064\n",
      "Test set: Average loss: 1.9584, Accuracy: 3272/5000 (65%)\n",
      "[epoch 38] loss: 0.0020455\n",
      "Test set: Average loss: 1.9802, Accuracy: 3282/5000 (66%)\n",
      "[epoch 39] loss: 0.0016560\n",
      "Test set: Average loss: 2.0050, Accuracy: 3283/5000 (66%)\n",
      "[epoch 40] loss: 0.0013343\n",
      "Test set: Average loss: 2.0331, Accuracy: 3297/5000 (66%)\n",
      "[epoch 41] loss: 0.0010708\n",
      "Test set: Average loss: 2.0571, Accuracy: 3305/5000 (66%)\n",
      "[epoch 42] loss: 0.0008526\n",
      "Test set: Average loss: 2.0929, Accuracy: 3296/5000 (66%)\n",
      "[epoch 43] loss: 0.0006774\n",
      "Test set: Average loss: 2.1205, Accuracy: 3294/5000 (66%)\n",
      "[epoch 44] loss: 0.0005349\n",
      "Test set: Average loss: 2.1549, Accuracy: 3287/5000 (66%)\n",
      "[epoch 45] loss: 0.0004163\n",
      "Test set: Average loss: 2.1907, Accuracy: 3292/5000 (66%)\n",
      "[epoch 46] loss: 0.0003237\n",
      "Test set: Average loss: 2.2222, Accuracy: 3302/5000 (66%)\n",
      "[epoch 47] loss: 0.0002504\n",
      "Test set: Average loss: 2.2616, Accuracy: 3291/5000 (66%)\n",
      "[epoch 48] loss: 0.0001933\n",
      "Test set: Average loss: 2.2947, Accuracy: 3287/5000 (66%)\n",
      "[epoch 49] loss: 0.0001487\n",
      "Test set: Average loss: 2.3401, Accuracy: 3294/5000 (66%)\n",
      "[epoch 50] loss: 0.0001129\n",
      "Test set: Average loss: 2.3814, Accuracy: 3298/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0571, Accuracy: 3305/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 1.9632, Accuracy: 6640/10000 (66%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3035, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 1.2879836\n",
      "Test set: Average loss: 1.2232, Accuracy: 2806/5000 (56%)\n",
      "[epoch 2] loss: 1.1414990\n",
      "Test set: Average loss: 1.2813, Accuracy: 2697/5000 (54%)\n",
      "[epoch 3] loss: 1.0815953\n",
      "Test set: Average loss: 1.1755, Accuracy: 2966/5000 (59%)\n",
      "[epoch 4] loss: 1.0401039\n",
      "Test set: Average loss: 1.1217, Accuracy: 3015/5000 (60%)\n",
      "[epoch 5] loss: 1.0192104\n",
      "Test set: Average loss: 1.1749, Accuracy: 2919/5000 (58%)\n",
      "[epoch 6] loss: 0.9750925\n",
      "Test set: Average loss: 1.1709, Accuracy: 2990/5000 (60%)\n",
      "[epoch 7] loss: 0.9682870\n",
      "Test set: Average loss: 1.1160, Accuracy: 3025/5000 (60%)\n",
      "[epoch 8] loss: 0.9341250\n",
      "Test set: Average loss: 1.1438, Accuracy: 3050/5000 (61%)\n",
      "[epoch 9] loss: 0.9053350\n",
      "Test set: Average loss: 1.1225, Accuracy: 3084/5000 (62%)\n",
      "[epoch 10] loss: 0.8763918\n",
      "Test set: Average loss: 1.1344, Accuracy: 3036/5000 (61%)\n",
      "[epoch 11] loss: 0.8445258\n",
      "Test set: Average loss: 1.0982, Accuracy: 3119/5000 (62%)\n",
      "[epoch 12] loss: 0.8172450\n",
      "Test set: Average loss: 1.1597, Accuracy: 3061/5000 (61%)\n",
      "[epoch 13] loss: 0.7786429\n",
      "Test set: Average loss: 1.1324, Accuracy: 3122/5000 (62%)\n",
      "[epoch 14] loss: 0.7396561\n",
      "Test set: Average loss: 1.1338, Accuracy: 3119/5000 (62%)\n",
      "[epoch 15] loss: 0.6866632\n",
      "Test set: Average loss: 1.1918, Accuracy: 3115/5000 (62%)\n",
      "[epoch 16] loss: 0.6497045\n",
      "Test set: Average loss: 1.1756, Accuracy: 3124/5000 (62%)\n",
      "[epoch 17] loss: 0.5847230\n",
      "Test set: Average loss: 1.2220, Accuracy: 3094/5000 (62%)\n",
      "[epoch 18] loss: 0.5292768\n",
      "Test set: Average loss: 1.1936, Accuracy: 3141/5000 (63%)\n",
      "[epoch 19] loss: 0.4783814\n",
      "Test set: Average loss: 1.2461, Accuracy: 3145/5000 (63%)\n",
      "[epoch 20] loss: 0.3906325\n",
      "Test set: Average loss: 1.3725, Accuracy: 3144/5000 (63%)\n",
      "[epoch 21] loss: 0.3359434\n",
      "Test set: Average loss: 1.3536, Accuracy: 3172/5000 (63%)\n",
      "[epoch 22] loss: 0.2543194\n",
      "Test set: Average loss: 1.4009, Accuracy: 3151/5000 (63%)\n",
      "[epoch 23] loss: 0.1994307\n",
      "Test set: Average loss: 1.5128, Accuracy: 3133/5000 (63%)\n",
      "[epoch 24] loss: 0.1597529\n",
      "Test set: Average loss: 1.5449, Accuracy: 3180/5000 (64%)\n",
      "[epoch 25] loss: 0.1061859\n",
      "Test set: Average loss: 1.6116, Accuracy: 3172/5000 (63%)\n",
      "[epoch 26] loss: 0.1312585\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7628, Accuracy: 3127/5000 (63%)\n",
      "[epoch 27] loss: 0.0410987\n",
      "Test set: Average loss: 1.6358, Accuracy: 3210/5000 (64%)\n",
      "[epoch 28] loss: 0.0188780\n",
      "Test set: Average loss: 1.6459, Accuracy: 3221/5000 (64%)\n",
      "[epoch 29] loss: 0.0138108\n",
      "Test set: Average loss: 1.6588, Accuracy: 3230/5000 (65%)\n",
      "[epoch 30] loss: 0.0108672\n",
      "Test set: Average loss: 1.6719, Accuracy: 3239/5000 (65%)\n",
      "[epoch 31] loss: 0.0088084\n",
      "Test set: Average loss: 1.6939, Accuracy: 3220/5000 (64%)\n",
      "[epoch 32] loss: 0.0071914\n",
      "Test set: Average loss: 1.7122, Accuracy: 3233/5000 (65%)\n",
      "[epoch 33] loss: 0.0059177\n",
      "Test set: Average loss: 1.7327, Accuracy: 3235/5000 (65%)\n",
      "[epoch 34] loss: 0.0048483\n",
      "Test set: Average loss: 1.7581, Accuracy: 3229/5000 (65%)\n",
      "[epoch 35] loss: 0.0039544\n",
      "Test set: Average loss: 1.7861, Accuracy: 3231/5000 (65%)\n",
      "[epoch 36] loss: 0.0032035\n",
      "Test set: Average loss: 1.8117, Accuracy: 3225/5000 (64%)\n",
      "[epoch 37] loss: 0.0025750\n",
      "Test set: Average loss: 1.8429, Accuracy: 3240/5000 (65%)\n",
      "[epoch 38] loss: 0.0020591\n",
      "Test set: Average loss: 1.8756, Accuracy: 3239/5000 (65%)\n",
      "[epoch 39] loss: 0.0016345\n",
      "Test set: Average loss: 1.9115, Accuracy: 3238/5000 (65%)\n",
      "[epoch 40] loss: 0.0012904\n",
      "Test set: Average loss: 1.9487, Accuracy: 3221/5000 (64%)\n",
      "[epoch 41] loss: 0.0010119\n",
      "Test set: Average loss: 1.9823, Accuracy: 3236/5000 (65%)\n",
      "[epoch 42] loss: 0.0007899\n",
      "Test set: Average loss: 2.0190, Accuracy: 3229/5000 (65%)\n",
      "[epoch 43] loss: 0.0006164\n",
      "Test set: Average loss: 2.0582, Accuracy: 3238/5000 (65%)\n",
      "[epoch 44] loss: 0.0004762\n",
      "Test set: Average loss: 2.1031, Accuracy: 3232/5000 (65%)\n",
      "[epoch 45] loss: 0.0003670\n",
      "Test set: Average loss: 2.1485, Accuracy: 3216/5000 (64%)\n",
      "[epoch 46] loss: 0.0002821\n",
      "Test set: Average loss: 2.1902, Accuracy: 3230/5000 (65%)\n",
      "[epoch 47] loss: 0.0002157\n",
      "Test set: Average loss: 2.2322, Accuracy: 3234/5000 (65%)\n",
      "[epoch 48] loss: 0.0001661\n",
      "Test set: Average loss: 2.2789, Accuracy: 3230/5000 (65%)\n",
      "[epoch 49] loss: 0.0001262\n",
      "Test set: Average loss: 2.3272, Accuracy: 3242/5000 (65%)\n",
      "[epoch 50] loss: 0.0000958\n",
      "Test set: Average loss: 2.3677, Accuracy: 3239/5000 (65%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3272, Accuracy: 3242/5000 (65%)\n",
      "Test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3242, Accuracy: 6570/10000 (66%)\n",
      "25000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3039, Accuracy: 480/5000 (10%)\n",
      "[epoch 1] loss: 1.2635923\n",
      "Test set: Average loss: 1.1742, Accuracy: 2951/5000 (59%)\n",
      "[epoch 2] loss: 1.1213493\n",
      "Test set: Average loss: 1.2543, Accuracy: 2825/5000 (56%)\n",
      "[epoch 3] loss: 1.0725383\n",
      "Test set: Average loss: 1.1969, Accuracy: 2902/5000 (58%)\n",
      "[epoch 4] loss: 1.0334099\n",
      "Test set: Average loss: 1.1081, Accuracy: 3051/5000 (61%)\n",
      "[epoch 5] loss: 1.0039761\n",
      "Test set: Average loss: 1.1745, Accuracy: 2949/5000 (59%)\n",
      "[epoch 6] loss: 0.9755712\n",
      "Test set: Average loss: 1.1065, Accuracy: 3059/5000 (61%)\n",
      "[epoch 7] loss: 0.9412384\n",
      "Test set: Average loss: 1.1235, Accuracy: 3047/5000 (61%)\n",
      "[epoch 8] loss: 0.9125319\n",
      "Test set: Average loss: 1.1607, Accuracy: 3022/5000 (60%)\n",
      "[epoch 9] loss: 0.8787103\n",
      "Test set: Average loss: 1.1118, Accuracy: 3110/5000 (62%)\n",
      "[epoch 10] loss: 0.8428333\n",
      "Test set: Average loss: 1.0965, Accuracy: 3126/5000 (63%)\n",
      "[epoch 11] loss: 0.8117154\n",
      "Test set: Average loss: 1.0972, Accuracy: 3131/5000 (63%)\n",
      "[epoch 12] loss: 0.7659880\n",
      "Test set: Average loss: 1.1146, Accuracy: 3119/5000 (62%)\n",
      "[epoch 13] loss: 0.7272508\n",
      "Test set: Average loss: 1.1162, Accuracy: 3165/5000 (63%)\n",
      "[epoch 14] loss: 0.6734556\n",
      "Test set: Average loss: 1.1152, Accuracy: 3219/5000 (64%)\n",
      "[epoch 15] loss: 0.6355065\n",
      "Test set: Average loss: 1.1547, Accuracy: 3161/5000 (63%)\n",
      "[epoch 16] loss: 0.5734877\n",
      "Test set: Average loss: 1.1735, Accuracy: 3178/5000 (64%)\n",
      "[epoch 17] loss: 0.5037622\n",
      "Test set: Average loss: 1.1822, Accuracy: 3186/5000 (64%)\n",
      "[epoch 18] loss: 0.4267513\n",
      "Test set: Average loss: 1.2347, Accuracy: 3163/5000 (63%)\n",
      "[epoch 19] loss: 0.3568078\n",
      "Test set: Average loss: 1.2967, Accuracy: 3220/5000 (64%)\n",
      "[epoch 20] loss: 0.2944014\n",
      "Test set: Average loss: 1.3377, Accuracy: 3146/5000 (63%)\n",
      "[epoch 21] loss: 0.2284131\n",
      "Test set: Average loss: 1.4319, Accuracy: 3195/5000 (64%)\n",
      "[epoch 22] loss: 0.1665825\n",
      "Test set: Average loss: 1.5188, Accuracy: 3151/5000 (63%)\n",
      "[epoch 23] loss: 0.1852375\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6321, Accuracy: 3148/5000 (63%)\n",
      "[epoch 24] loss: 0.0602228\n",
      "Test set: Average loss: 1.4805, Accuracy: 3263/5000 (65%)\n",
      "[epoch 25] loss: 0.0289355\n",
      "Test set: Average loss: 1.4923, Accuracy: 3278/5000 (66%)\n",
      "[epoch 26] loss: 0.0202676\n",
      "Test set: Average loss: 1.5072, Accuracy: 3284/5000 (66%)\n",
      "[epoch 27] loss: 0.0154614\n",
      "Test set: Average loss: 1.5315, Accuracy: 3295/5000 (66%)\n",
      "[epoch 28] loss: 0.0119338\n",
      "Test set: Average loss: 1.5609, Accuracy: 3290/5000 (66%)\n",
      "[epoch 29] loss: 0.0093789\n",
      "Test set: Average loss: 1.5881, Accuracy: 3301/5000 (66%)\n",
      "[epoch 30] loss: 0.0072520\n",
      "Test set: Average loss: 1.6089, Accuracy: 3300/5000 (66%)\n",
      "[epoch 31] loss: 0.0056153\n",
      "Test set: Average loss: 1.6476, Accuracy: 3309/5000 (66%)\n",
      "[epoch 32] loss: 0.0043131\n",
      "Test set: Average loss: 1.6812, Accuracy: 3314/5000 (66%)\n",
      "[epoch 33] loss: 0.0032591\n",
      "Test set: Average loss: 1.7177, Accuracy: 3301/5000 (66%)\n",
      "[epoch 34] loss: 0.0024547\n",
      "Test set: Average loss: 1.7617, Accuracy: 3314/5000 (66%)\n",
      "[epoch 35] loss: 0.0018392\n",
      "Test set: Average loss: 1.8079, Accuracy: 3312/5000 (66%)\n",
      "[epoch 36] loss: 0.0013764\n",
      "Test set: Average loss: 1.8485, Accuracy: 3311/5000 (66%)\n",
      "[epoch 37] loss: 0.0010165\n",
      "Test set: Average loss: 1.8958, Accuracy: 3316/5000 (66%)\n",
      "[epoch 38] loss: 0.0007496\n",
      "Test set: Average loss: 1.9389, Accuracy: 3326/5000 (67%)\n",
      "[epoch 39] loss: 0.0005500\n",
      "Test set: Average loss: 1.9914, Accuracy: 3311/5000 (66%)\n",
      "[epoch 40] loss: 0.0004014\n",
      "Test set: Average loss: 2.0431, Accuracy: 3311/5000 (66%)\n",
      "[epoch 41] loss: 0.0002910\n",
      "Test set: Average loss: 2.0927, Accuracy: 3312/5000 (66%)\n",
      "[epoch 42] loss: 0.0002126\n",
      "Test set: Average loss: 2.1463, Accuracy: 3322/5000 (66%)\n",
      "[epoch 43] loss: 0.0001538\n",
      "Test set: Average loss: 2.1981, Accuracy: 3317/5000 (66%)\n",
      "[epoch 44] loss: 0.0001106\n",
      "Test set: Average loss: 2.2513, Accuracy: 3325/5000 (66%)\n",
      "[epoch 45] loss: 0.0000794\n",
      "Test set: Average loss: 2.3114, Accuracy: 3319/5000 (66%)\n",
      "[epoch 46] loss: 0.0000570\n",
      "Test set: Average loss: 2.3666, Accuracy: 3319/5000 (66%)\n",
      "[epoch 47] loss: 0.0000407\n",
      "Test set: Average loss: 2.4099, Accuracy: 3327/5000 (67%)\n",
      "[epoch 48] loss: 0.0000291\n",
      "Test set: Average loss: 2.4638, Accuracy: 3330/5000 (67%)\n",
      "[epoch 49] loss: 0.0000206\n",
      "Test set: Average loss: 2.5298, Accuracy: 3320/5000 (66%)\n",
      "[epoch 50] loss: 0.0000146\n",
      "Test set: Average loss: 2.5859, Accuracy: 3313/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.4638, Accuracy: 3330/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.4079, Accuracy: 6713/10000 (67%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3034, Accuracy: 520/5000 (10%)\n",
      "[epoch 1] loss: 1.2725239\n",
      "Test set: Average loss: 1.2765, Accuracy: 2758/5000 (55%)\n",
      "[epoch 2] loss: 1.1162877\n",
      "Test set: Average loss: 1.1615, Accuracy: 2949/5000 (59%)\n",
      "[epoch 3] loss: 1.0666143\n",
      "Test set: Average loss: 1.1569, Accuracy: 2970/5000 (59%)\n",
      "[epoch 4] loss: 1.0409404\n",
      "Test set: Average loss: 1.1045, Accuracy: 3057/5000 (61%)\n",
      "[epoch 5] loss: 0.9969578\n",
      "Test set: Average loss: 1.0996, Accuracy: 3095/5000 (62%)\n",
      "[epoch 6] loss: 0.9750627\n",
      "Test set: Average loss: 1.0798, Accuracy: 3120/5000 (62%)\n",
      "[epoch 7] loss: 0.9555762\n",
      "Test set: Average loss: 1.1263, Accuracy: 3057/5000 (61%)\n",
      "[epoch 8] loss: 0.9249665\n",
      "Test set: Average loss: 1.0980, Accuracy: 3097/5000 (62%)\n",
      "[epoch 9] loss: 0.8905029\n",
      "Test set: Average loss: 1.0663, Accuracy: 3107/5000 (62%)\n",
      "[epoch 10] loss: 0.8620734\n",
      "Test set: Average loss: 1.0909, Accuracy: 3115/5000 (62%)\n",
      "[epoch 11] loss: 0.8262674\n",
      "Test set: Average loss: 1.0825, Accuracy: 3131/5000 (63%)\n",
      "[epoch 12] loss: 0.7909068\n",
      "Test set: Average loss: 1.0599, Accuracy: 3200/5000 (64%)\n",
      "[epoch 13] loss: 0.7472641\n",
      "Test set: Average loss: 1.1159, Accuracy: 3152/5000 (63%)\n",
      "[epoch 14] loss: 0.7094461\n",
      "Test set: Average loss: 1.1441, Accuracy: 3121/5000 (62%)\n",
      "[epoch 15] loss: 0.6496011\n",
      "Test set: Average loss: 1.1235, Accuracy: 3168/5000 (63%)\n",
      "[epoch 16] loss: 0.6008992\n",
      "Test set: Average loss: 1.2187, Accuracy: 3105/5000 (62%)\n",
      "[epoch 17] loss: 0.5366622\n",
      "Test set: Average loss: 1.1679, Accuracy: 3176/5000 (64%)\n",
      "[epoch 18] loss: 0.4591783\n",
      "Test set: Average loss: 1.2413, Accuracy: 3181/5000 (64%)\n",
      "[epoch 19] loss: 0.4027958\n",
      "Test set: Average loss: 1.2777, Accuracy: 3148/5000 (63%)\n",
      "[epoch 20] loss: 0.3239557\n",
      "Test set: Average loss: 1.3425, Accuracy: 3144/5000 (63%)\n",
      "[epoch 21] loss: 0.2571341\n",
      "Test set: Average loss: 1.4221, Accuracy: 3135/5000 (63%)\n",
      "[epoch 22] loss: 0.1910734\n",
      "Test set: Average loss: 1.5272, Accuracy: 3190/5000 (64%)\n",
      "[epoch 23] loss: 0.1587175\n",
      "Test set: Average loss: 1.5146, Accuracy: 3228/5000 (65%)\n",
      "[epoch 24] loss: 0.1416490\n",
      "Test set: Average loss: 1.6962, Accuracy: 3170/5000 (63%)\n",
      "[epoch 25] loss: 0.1444066\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7092, Accuracy: 3148/5000 (63%)\n",
      "[epoch 26] loss: 0.0456668\n",
      "Test set: Average loss: 1.6228, Accuracy: 3227/5000 (65%)\n",
      "[epoch 27] loss: 0.0190870\n",
      "Test set: Average loss: 1.6361, Accuracy: 3240/5000 (65%)\n",
      "[epoch 28] loss: 0.0130186\n",
      "Test set: Average loss: 1.6493, Accuracy: 3231/5000 (65%)\n",
      "[epoch 29] loss: 0.0097544\n",
      "Test set: Average loss: 1.6681, Accuracy: 3256/5000 (65%)\n",
      "[epoch 30] loss: 0.0075410\n",
      "Test set: Average loss: 1.6884, Accuracy: 3249/5000 (65%)\n",
      "[epoch 31] loss: 0.0058725\n",
      "Test set: Average loss: 1.7136, Accuracy: 3249/5000 (65%)\n",
      "[epoch 32] loss: 0.0045482\n",
      "Test set: Average loss: 1.7434, Accuracy: 3256/5000 (65%)\n",
      "[epoch 33] loss: 0.0034845\n",
      "Test set: Average loss: 1.7763, Accuracy: 3263/5000 (65%)\n",
      "[epoch 34] loss: 0.0026796\n",
      "Test set: Average loss: 1.8139, Accuracy: 3273/5000 (65%)\n",
      "[epoch 35] loss: 0.0020368\n",
      "Test set: Average loss: 1.8560, Accuracy: 3270/5000 (65%)\n",
      "[epoch 36] loss: 0.0015367\n",
      "Test set: Average loss: 1.8957, Accuracy: 3270/5000 (65%)\n",
      "[epoch 37] loss: 0.0011499\n",
      "Test set: Average loss: 1.9381, Accuracy: 3262/5000 (65%)\n",
      "[epoch 38] loss: 0.0008571\n",
      "Test set: Average loss: 1.9779, Accuracy: 3268/5000 (65%)\n",
      "[epoch 39] loss: 0.0006342\n",
      "Test set: Average loss: 2.0260, Accuracy: 3282/5000 (66%)\n",
      "[epoch 40] loss: 0.0004629\n",
      "Test set: Average loss: 2.0764, Accuracy: 3273/5000 (65%)\n",
      "[epoch 41] loss: 0.0003397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.1290, Accuracy: 3287/5000 (66%)\n",
      "[epoch 42] loss: 0.0002475\n",
      "Test set: Average loss: 2.1684, Accuracy: 3285/5000 (66%)\n",
      "[epoch 43] loss: 0.0001790\n",
      "Test set: Average loss: 2.2222, Accuracy: 3289/5000 (66%)\n",
      "[epoch 44] loss: 0.0001302\n",
      "Test set: Average loss: 2.2760, Accuracy: 3285/5000 (66%)\n",
      "[epoch 45] loss: 0.0000935\n",
      "Test set: Average loss: 2.3407, Accuracy: 3302/5000 (66%)\n",
      "[epoch 46] loss: 0.0000669\n",
      "Test set: Average loss: 2.3882, Accuracy: 3296/5000 (66%)\n",
      "[epoch 47] loss: 0.0000480\n",
      "Test set: Average loss: 2.4376, Accuracy: 3290/5000 (66%)\n",
      "[epoch 48] loss: 0.0000343\n",
      "Test set: Average loss: 2.4913, Accuracy: 3292/5000 (66%)\n",
      "[epoch 49] loss: 0.0000244\n",
      "Test set: Average loss: 2.5465, Accuracy: 3288/5000 (66%)\n",
      "[epoch 50] loss: 0.0000174\n",
      "Test set: Average loss: 2.6103, Accuracy: 3289/5000 (66%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3407, Accuracy: 3302/5000 (66%)\n",
      "Test\n",
      "Test set: Average loss: 2.2345, Accuracy: 6684/10000 (67%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 624/5000 (12%)\n",
      "[epoch 1] loss: 1.2675046\n",
      "Test set: Average loss: 1.1704, Accuracy: 2950/5000 (59%)\n",
      "[epoch 2] loss: 1.1210903\n",
      "Test set: Average loss: 1.1633, Accuracy: 2926/5000 (59%)\n",
      "[epoch 3] loss: 1.0740074\n",
      "Test set: Average loss: 1.1257, Accuracy: 3002/5000 (60%)\n",
      "[epoch 4] loss: 1.0308312\n",
      "Test set: Average loss: 1.1260, Accuracy: 3037/5000 (61%)\n",
      "[epoch 5] loss: 1.0055356\n",
      "Test set: Average loss: 1.0917, Accuracy: 3091/5000 (62%)\n",
      "[epoch 6] loss: 0.9758776\n",
      "Test set: Average loss: 1.1059, Accuracy: 3011/5000 (60%)\n",
      "[epoch 7] loss: 0.9493486\n",
      "Test set: Average loss: 1.1500, Accuracy: 2984/5000 (60%)\n",
      "[epoch 8] loss: 0.9161476\n",
      "Test set: Average loss: 1.0742, Accuracy: 3160/5000 (63%)\n",
      "[epoch 9] loss: 0.8843746\n",
      "Test set: Average loss: 1.0726, Accuracy: 3126/5000 (63%)\n",
      "[epoch 10] loss: 0.8568519\n",
      "Test set: Average loss: 1.1261, Accuracy: 3081/5000 (62%)\n",
      "[epoch 11] loss: 0.8184215\n",
      "Test set: Average loss: 1.1393, Accuracy: 3066/5000 (61%)\n",
      "[epoch 12] loss: 0.7771374\n",
      "Test set: Average loss: 1.0730, Accuracy: 3160/5000 (63%)\n",
      "[epoch 13] loss: 0.7396458\n",
      "Test set: Average loss: 1.0935, Accuracy: 3194/5000 (64%)\n",
      "[epoch 14] loss: 0.6923667\n",
      "Test set: Average loss: 1.1210, Accuracy: 3176/5000 (64%)\n",
      "[epoch 15] loss: 0.6392629\n",
      "Test set: Average loss: 1.1141, Accuracy: 3198/5000 (64%)\n",
      "[epoch 16] loss: 0.5706644\n",
      "Test set: Average loss: 1.2075, Accuracy: 3137/5000 (63%)\n",
      "[epoch 17] loss: 0.5207799\n",
      "Test set: Average loss: 1.1781, Accuracy: 3193/5000 (64%)\n",
      "[epoch 18] loss: 0.4322100\n",
      "Test set: Average loss: 1.2472, Accuracy: 3201/5000 (64%)\n",
      "[epoch 19] loss: 0.3543065\n",
      "Test set: Average loss: 1.3030, Accuracy: 3166/5000 (63%)\n",
      "[epoch 20] loss: 0.2970660\n",
      "Test set: Average loss: 1.3934, Accuracy: 3197/5000 (64%)\n",
      "[epoch 21] loss: 0.2257738\n",
      "Test set: Average loss: 1.4053, Accuracy: 3252/5000 (65%)\n",
      "[epoch 22] loss: 0.1763467\n",
      "Test set: Average loss: 1.5339, Accuracy: 3178/5000 (64%)\n",
      "[epoch 23] loss: 0.1572824\n",
      "Test set: Average loss: 1.5700, Accuracy: 3189/5000 (64%)\n",
      "[epoch 24] loss: 0.1359167\n",
      "Test set: Average loss: 1.6479, Accuracy: 3153/5000 (63%)\n",
      "[epoch 25] loss: 0.1405042\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7162, Accuracy: 3194/5000 (64%)\n",
      "[epoch 26] loss: 0.0449641\n",
      "Test set: Average loss: 1.6169, Accuracy: 3286/5000 (66%)\n",
      "[epoch 27] loss: 0.0181397\n",
      "Test set: Average loss: 1.6223, Accuracy: 3283/5000 (66%)\n",
      "[epoch 28] loss: 0.0123261\n",
      "Test set: Average loss: 1.6388, Accuracy: 3293/5000 (66%)\n",
      "[epoch 29] loss: 0.0092160\n",
      "Test set: Average loss: 1.6555, Accuracy: 3303/5000 (66%)\n",
      "[epoch 30] loss: 0.0071103\n",
      "Test set: Average loss: 1.6749, Accuracy: 3302/5000 (66%)\n",
      "[epoch 31] loss: 0.0054935\n",
      "Test set: Average loss: 1.6977, Accuracy: 3313/5000 (66%)\n",
      "[epoch 32] loss: 0.0042451\n",
      "Test set: Average loss: 1.7234, Accuracy: 3310/5000 (66%)\n",
      "[epoch 33] loss: 0.0032834\n",
      "Test set: Average loss: 1.7518, Accuracy: 3322/5000 (66%)\n",
      "[epoch 34] loss: 0.0025023\n",
      "Test set: Average loss: 1.7839, Accuracy: 3332/5000 (67%)\n",
      "[epoch 35] loss: 0.0019059\n",
      "Test set: Average loss: 1.8194, Accuracy: 3332/5000 (67%)\n",
      "[epoch 36] loss: 0.0014291\n",
      "Test set: Average loss: 1.8590, Accuracy: 3325/5000 (66%)\n",
      "[epoch 37] loss: 0.0010674\n",
      "Test set: Average loss: 1.8971, Accuracy: 3338/5000 (67%)\n",
      "[epoch 38] loss: 0.0007953\n",
      "Test set: Average loss: 1.9388, Accuracy: 3336/5000 (67%)\n",
      "[epoch 39] loss: 0.0005863\n",
      "Test set: Average loss: 1.9830, Accuracy: 3338/5000 (67%)\n",
      "[epoch 40] loss: 0.0004294\n",
      "Test set: Average loss: 2.0255, Accuracy: 3348/5000 (67%)\n",
      "[epoch 41] loss: 0.0003133\n",
      "Test set: Average loss: 2.0696, Accuracy: 3350/5000 (67%)\n",
      "[epoch 42] loss: 0.0002290\n",
      "Test set: Average loss: 2.1236, Accuracy: 3345/5000 (67%)\n",
      "[epoch 43] loss: 0.0001657\n",
      "Test set: Average loss: 2.1671, Accuracy: 3348/5000 (67%)\n",
      "[epoch 44] loss: 0.0001195\n",
      "Test set: Average loss: 2.2197, Accuracy: 3336/5000 (67%)\n",
      "[epoch 45] loss: 0.0000862\n",
      "Test set: Average loss: 2.2585, Accuracy: 3344/5000 (67%)\n",
      "[epoch 46] loss: 0.0000616\n",
      "Test set: Average loss: 2.3201, Accuracy: 3350/5000 (67%)\n",
      "[epoch 47] loss: 0.0000442\n",
      "Test set: Average loss: 2.3634, Accuracy: 3338/5000 (67%)\n",
      "[epoch 48] loss: 0.0000314\n",
      "Test set: Average loss: 2.4191, Accuracy: 3340/5000 (67%)\n",
      "[epoch 49] loss: 0.0000225\n",
      "Test set: Average loss: 2.4744, Accuracy: 3337/5000 (67%)\n",
      "[epoch 50] loss: 0.0000159\n",
      "Test set: Average loss: 2.5273, Accuracy: 3346/5000 (67%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3201, Accuracy: 3350/5000 (67%)\n",
      "Test\n",
      "Test set: Average loss: 2.2734, Accuracy: 6741/10000 (67%)\n",
      "30000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 480/5000 (10%)\n",
      "[epoch 1] loss: 1.2577562\n",
      "Test set: Average loss: 1.1894, Accuracy: 2912/5000 (58%)\n",
      "[epoch 2] loss: 1.1209924\n",
      "Test set: Average loss: 1.1642, Accuracy: 2963/5000 (59%)\n",
      "[epoch 3] loss: 1.0662089\n",
      "Test set: Average loss: 1.1218, Accuracy: 3011/5000 (60%)\n",
      "[epoch 4] loss: 1.0347311\n",
      "Test set: Average loss: 1.2283, Accuracy: 2847/5000 (57%)\n",
      "[epoch 5] loss: 0.9961839\n",
      "Test set: Average loss: 1.0562, Accuracy: 3151/5000 (63%)\n",
      "[epoch 6] loss: 0.9686757\n",
      "Test set: Average loss: 1.0841, Accuracy: 3108/5000 (62%)\n",
      "[epoch 7] loss: 0.9300928\n",
      "Test set: Average loss: 1.1369, Accuracy: 3042/5000 (61%)\n",
      "[epoch 8] loss: 0.9034509\n",
      "Test set: Average loss: 1.0802, Accuracy: 3191/5000 (64%)\n",
      "[epoch 9] loss: 0.8732529\n",
      "Test set: Average loss: 1.0623, Accuracy: 3135/5000 (63%)\n",
      "[epoch 10] loss: 0.8367157\n",
      "Test set: Average loss: 1.0749, Accuracy: 3193/5000 (64%)\n",
      "[epoch 11] loss: 0.7908974\n",
      "Test set: Average loss: 1.0146, Accuracy: 3217/5000 (64%)\n",
      "[epoch 12] loss: 0.7485554\n",
      "Test set: Average loss: 1.0423, Accuracy: 3222/5000 (64%)\n",
      "[epoch 13] loss: 0.7095482\n",
      "Test set: Average loss: 1.0614, Accuracy: 3238/5000 (65%)\n",
      "[epoch 14] loss: 0.6501099\n",
      "Test set: Average loss: 1.0955, Accuracy: 3191/5000 (64%)\n",
      "[epoch 15] loss: 0.5897756\n",
      "Test set: Average loss: 1.1704, Accuracy: 3191/5000 (64%)\n",
      "[epoch 16] loss: 0.5232457\n",
      "Test set: Average loss: 1.1489, Accuracy: 3206/5000 (64%)\n",
      "[epoch 17] loss: 0.4559616\n",
      "Test set: Average loss: 1.1637, Accuracy: 3291/5000 (66%)\n",
      "[epoch 18] loss: 0.3818644\n",
      "Test set: Average loss: 1.2189, Accuracy: 3225/5000 (64%)\n",
      "[epoch 19] loss: 0.3024560\n",
      "Test set: Average loss: 1.2914, Accuracy: 3273/5000 (65%)\n",
      "[epoch 20] loss: 0.2523244\n",
      "Test set: Average loss: 1.3438, Accuracy: 3275/5000 (66%)\n",
      "[epoch 21] loss: 0.2081838\n",
      "Test set: Average loss: 1.4565, Accuracy: 3237/5000 (65%)\n",
      "[epoch 22] loss: 0.1649334\n",
      "Test set: Average loss: 1.5036, Accuracy: 3203/5000 (64%)\n",
      "[epoch 23] loss: 0.1414239\n",
      "Test set: Average loss: 1.6037, Accuracy: 3224/5000 (64%)\n",
      "[epoch 24] loss: 0.1500170\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7108, Accuracy: 3229/5000 (65%)\n",
      "[epoch 25] loss: 0.0539501\n",
      "Test set: Average loss: 1.5923, Accuracy: 3333/5000 (67%)\n",
      "[epoch 26] loss: 0.0199966\n",
      "Test set: Average loss: 1.5995, Accuracy: 3365/5000 (67%)\n",
      "[epoch 27] loss: 0.0129146\n",
      "Test set: Average loss: 1.6150, Accuracy: 3364/5000 (67%)\n",
      "[epoch 28] loss: 0.0091930\n",
      "Test set: Average loss: 1.6417, Accuracy: 3369/5000 (67%)\n",
      "[epoch 29] loss: 0.0067519\n",
      "Test set: Average loss: 1.6603, Accuracy: 3373/5000 (67%)\n",
      "[epoch 30] loss: 0.0050218\n",
      "Test set: Average loss: 1.6897, Accuracy: 3375/5000 (68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] loss: 0.0037085\n",
      "Test set: Average loss: 1.7254, Accuracy: 3380/5000 (68%)\n",
      "[epoch 32] loss: 0.0027032\n",
      "Test set: Average loss: 1.7652, Accuracy: 3375/5000 (68%)\n",
      "[epoch 33] loss: 0.0019601\n",
      "Test set: Average loss: 1.8005, Accuracy: 3388/5000 (68%)\n",
      "[epoch 34] loss: 0.0014062\n",
      "Test set: Average loss: 1.8413, Accuracy: 3378/5000 (68%)\n",
      "[epoch 35] loss: 0.0009976\n",
      "Test set: Average loss: 1.8932, Accuracy: 3368/5000 (67%)\n",
      "[epoch 36] loss: 0.0007062\n",
      "Test set: Average loss: 1.9438, Accuracy: 3380/5000 (68%)\n",
      "[epoch 37] loss: 0.0004930\n",
      "Test set: Average loss: 1.9898, Accuracy: 3374/5000 (67%)\n",
      "[epoch 38] loss: 0.0003439\n",
      "Test set: Average loss: 2.0381, Accuracy: 3379/5000 (68%)\n",
      "[epoch 39] loss: 0.0002380\n",
      "Test set: Average loss: 2.0950, Accuracy: 3377/5000 (68%)\n",
      "[epoch 40] loss: 0.0001645\n",
      "Test set: Average loss: 2.1426, Accuracy: 3379/5000 (68%)\n",
      "[epoch 41] loss: 0.0001132\n",
      "Test set: Average loss: 2.1988, Accuracy: 3384/5000 (68%)\n",
      "[epoch 42] loss: 0.0000771\n",
      "Test set: Average loss: 2.2556, Accuracy: 3400/5000 (68%)\n",
      "[epoch 43] loss: 0.0000529\n",
      "Test set: Average loss: 2.3214, Accuracy: 3381/5000 (68%)\n",
      "[epoch 44] loss: 0.0000359\n",
      "Test set: Average loss: 2.3700, Accuracy: 3387/5000 (68%)\n",
      "[epoch 45] loss: 0.0000243\n",
      "Test set: Average loss: 2.4395, Accuracy: 3386/5000 (68%)\n",
      "[epoch 46] loss: 0.0000164\n",
      "Test set: Average loss: 2.4951, Accuracy: 3382/5000 (68%)\n",
      "[epoch 47] loss: 0.0000110\n",
      "Test set: Average loss: 2.5541, Accuracy: 3381/5000 (68%)\n",
      "[epoch 48] loss: 0.0000074\n",
      "Test set: Average loss: 2.6108, Accuracy: 3383/5000 (68%)\n",
      "[epoch 49] loss: 0.0000050\n",
      "Test set: Average loss: 2.6728, Accuracy: 3381/5000 (68%)\n",
      "[epoch 50] loss: 0.0000033\n",
      "Test set: Average loss: 2.7315, Accuracy: 3384/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2556, Accuracy: 3400/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.1489, Accuracy: 6826/10000 (68%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3026, Accuracy: 474/5000 (9%)\n",
      "[epoch 1] loss: 1.2605062\n",
      "Test set: Average loss: 1.2061, Accuracy: 2888/5000 (58%)\n",
      "[epoch 2] loss: 1.1084057\n",
      "Test set: Average loss: 1.1919, Accuracy: 2927/5000 (59%)\n",
      "[epoch 3] loss: 1.0606547\n",
      "Test set: Average loss: 1.1330, Accuracy: 3029/5000 (61%)\n",
      "[epoch 4] loss: 1.0278105\n",
      "Test set: Average loss: 1.1311, Accuracy: 3004/5000 (60%)\n",
      "[epoch 5] loss: 0.9895871\n",
      "Test set: Average loss: 1.1243, Accuracy: 3056/5000 (61%)\n",
      "[epoch 6] loss: 0.9616327\n",
      "Test set: Average loss: 1.1031, Accuracy: 3071/5000 (61%)\n",
      "[epoch 7] loss: 0.9356834\n",
      "Test set: Average loss: 1.0897, Accuracy: 3168/5000 (63%)\n",
      "[epoch 8] loss: 0.9016503\n",
      "Test set: Average loss: 1.0589, Accuracy: 3197/5000 (64%)\n",
      "[epoch 9] loss: 0.8656430\n",
      "Test set: Average loss: 1.0946, Accuracy: 3089/5000 (62%)\n",
      "[epoch 10] loss: 0.8271973\n",
      "Test set: Average loss: 1.1178, Accuracy: 3126/5000 (63%)\n",
      "[epoch 11] loss: 0.7905212\n",
      "Test set: Average loss: 1.0804, Accuracy: 3183/5000 (64%)\n",
      "[epoch 12] loss: 0.7531210\n",
      "Test set: Average loss: 1.0873, Accuracy: 3182/5000 (64%)\n",
      "[epoch 13] loss: 0.7163845\n",
      "Test set: Average loss: 1.0756, Accuracy: 3200/5000 (64%)\n",
      "[epoch 14] loss: 0.6617866\n",
      "Test set: Average loss: 1.1712, Accuracy: 3090/5000 (62%)\n",
      "[epoch 15] loss: 0.6083776\n",
      "Test set: Average loss: 1.0583, Accuracy: 3268/5000 (65%)\n",
      "[epoch 16] loss: 0.5289774\n",
      "Test set: Average loss: 1.1395, Accuracy: 3245/5000 (65%)\n",
      "[epoch 17] loss: 0.4688056\n",
      "Test set: Average loss: 1.2129, Accuracy: 3225/5000 (64%)\n",
      "[epoch 18] loss: 0.3868661\n",
      "Test set: Average loss: 1.2827, Accuracy: 3231/5000 (65%)\n",
      "[epoch 19] loss: 0.3319688\n",
      "Test set: Average loss: 1.2697, Accuracy: 3239/5000 (65%)\n",
      "[epoch 20] loss: 0.2506372\n",
      "Test set: Average loss: 1.3463, Accuracy: 3277/5000 (66%)\n",
      "[epoch 21] loss: 0.1902356\n",
      "Test set: Average loss: 1.4201, Accuracy: 3276/5000 (66%)\n",
      "[epoch 22] loss: 0.1727456\n",
      "Test set: Average loss: 1.5208, Accuracy: 3242/5000 (65%)\n",
      "[epoch 23] loss: 0.1757271\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5732, Accuracy: 3201/5000 (64%)\n",
      "[epoch 24] loss: 0.0574537\n",
      "Test set: Average loss: 1.5079, Accuracy: 3315/5000 (66%)\n",
      "[epoch 25] loss: 0.0245133\n",
      "Test set: Average loss: 1.5143, Accuracy: 3331/5000 (67%)\n",
      "[epoch 26] loss: 0.0163559\n",
      "Test set: Average loss: 1.5294, Accuracy: 3322/5000 (66%)\n",
      "[epoch 27] loss: 0.0118465\n",
      "Test set: Average loss: 1.5590, Accuracy: 3336/5000 (67%)\n",
      "[epoch 28] loss: 0.0087377\n",
      "Test set: Average loss: 1.5838, Accuracy: 3340/5000 (67%)\n",
      "[epoch 29] loss: 0.0064676\n",
      "Test set: Average loss: 1.6153, Accuracy: 3348/5000 (67%)\n",
      "[epoch 30] loss: 0.0047730\n",
      "Test set: Average loss: 1.6477, Accuracy: 3363/5000 (67%)\n",
      "[epoch 31] loss: 0.0035096\n",
      "Test set: Average loss: 1.6856, Accuracy: 3355/5000 (67%)\n",
      "[epoch 32] loss: 0.0025309\n",
      "Test set: Average loss: 1.7283, Accuracy: 3369/5000 (67%)\n",
      "[epoch 33] loss: 0.0018208\n",
      "Test set: Average loss: 1.7738, Accuracy: 3364/5000 (67%)\n",
      "[epoch 34] loss: 0.0013001\n",
      "Test set: Average loss: 1.8184, Accuracy: 3357/5000 (67%)\n",
      "[epoch 35] loss: 0.0009288\n",
      "Test set: Average loss: 1.8571, Accuracy: 3351/5000 (67%)\n",
      "[epoch 36] loss: 0.0006518\n",
      "Test set: Average loss: 1.9048, Accuracy: 3361/5000 (67%)\n",
      "[epoch 37] loss: 0.0004570\n",
      "Test set: Average loss: 1.9592, Accuracy: 3352/5000 (67%)\n",
      "[epoch 38] loss: 0.0003182\n",
      "Test set: Average loss: 2.0090, Accuracy: 3363/5000 (67%)\n",
      "[epoch 39] loss: 0.0002204\n",
      "Test set: Average loss: 2.0655, Accuracy: 3356/5000 (67%)\n",
      "[epoch 40] loss: 0.0001525\n",
      "Test set: Average loss: 2.1211, Accuracy: 3370/5000 (67%)\n",
      "[epoch 41] loss: 0.0001046\n",
      "Test set: Average loss: 2.1794, Accuracy: 3367/5000 (67%)\n",
      "[epoch 42] loss: 0.0000720\n",
      "Test set: Average loss: 2.2295, Accuracy: 3361/5000 (67%)\n",
      "[epoch 43] loss: 0.0000487\n",
      "Test set: Average loss: 2.2948, Accuracy: 3362/5000 (67%)\n",
      "[epoch 44] loss: 0.0000330\n",
      "Test set: Average loss: 2.3463, Accuracy: 3369/5000 (67%)\n",
      "[epoch 45] loss: 0.0000225\n",
      "Test set: Average loss: 2.4036, Accuracy: 3366/5000 (67%)\n",
      "[epoch 46] loss: 0.0000152\n",
      "Test set: Average loss: 2.4654, Accuracy: 3373/5000 (67%)\n",
      "[epoch 47] loss: 0.0000102\n",
      "Test set: Average loss: 2.5245, Accuracy: 3368/5000 (67%)\n",
      "[epoch 48] loss: 0.0000068\n",
      "Test set: Average loss: 2.5893, Accuracy: 3371/5000 (67%)\n",
      "[epoch 49] loss: 0.0000046\n",
      "Test set: Average loss: 2.6484, Accuracy: 3380/5000 (68%)\n",
      "[epoch 50] loss: 0.0000030\n",
      "Test set: Average loss: 2.7062, Accuracy: 3380/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7062, Accuracy: 3380/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.6705, Accuracy: 6818/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3017, Accuracy: 407/5000 (8%)\n",
      "[epoch 1] loss: 1.2572345\n",
      "Test set: Average loss: 1.2184, Accuracy: 2855/5000 (57%)\n",
      "[epoch 2] loss: 1.1179297\n",
      "Test set: Average loss: 1.1106, Accuracy: 3039/5000 (61%)\n",
      "[epoch 3] loss: 1.0679549\n",
      "Test set: Average loss: 1.1082, Accuracy: 3025/5000 (60%)\n",
      "[epoch 4] loss: 1.0267759\n",
      "Test set: Average loss: 1.0897, Accuracy: 3090/5000 (62%)\n",
      "[epoch 5] loss: 1.0073990\n",
      "Test set: Average loss: 1.1068, Accuracy: 3096/5000 (62%)\n",
      "[epoch 6] loss: 0.9763947\n",
      "Test set: Average loss: 1.1270, Accuracy: 3033/5000 (61%)\n",
      "[epoch 7] loss: 0.9487562\n",
      "Test set: Average loss: 1.0737, Accuracy: 3133/5000 (63%)\n",
      "[epoch 8] loss: 0.9045769\n",
      "Test set: Average loss: 1.0639, Accuracy: 3156/5000 (63%)\n",
      "[epoch 9] loss: 0.8719728\n",
      "Test set: Average loss: 1.0789, Accuracy: 3169/5000 (63%)\n",
      "[epoch 10] loss: 0.8403666\n",
      "Test set: Average loss: 1.0738, Accuracy: 3189/5000 (64%)\n",
      "[epoch 11] loss: 0.8087498\n",
      "Test set: Average loss: 1.1180, Accuracy: 3085/5000 (62%)\n",
      "[epoch 12] loss: 0.7639459\n",
      "Test set: Average loss: 1.0720, Accuracy: 3183/5000 (64%)\n",
      "[epoch 13] loss: 0.7174982\n",
      "Test set: Average loss: 1.0661, Accuracy: 3210/5000 (64%)\n",
      "[epoch 14] loss: 0.6704466\n",
      "Test set: Average loss: 1.1374, Accuracy: 3110/5000 (62%)\n",
      "[epoch 15] loss: 0.6116227\n",
      "Test set: Average loss: 1.1075, Accuracy: 3222/5000 (64%)\n",
      "[epoch 16] loss: 0.5387431\n",
      "Test set: Average loss: 1.1227, Accuracy: 3196/5000 (64%)\n",
      "[epoch 17] loss: 0.4684571\n",
      "Test set: Average loss: 1.2384, Accuracy: 3176/5000 (64%)\n",
      "[epoch 18] loss: 0.3972940\n",
      "Test set: Average loss: 1.2451, Accuracy: 3204/5000 (64%)\n",
      "[epoch 19] loss: 0.3172775\n",
      "Test set: Average loss: 1.3121, Accuracy: 3205/5000 (64%)\n",
      "[epoch 20] loss: 0.2492119\n",
      "Test set: Average loss: 1.3906, Accuracy: 3272/5000 (65%)\n",
      "[epoch 21] loss: 0.2008661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4382, Accuracy: 3221/5000 (64%)\n",
      "[epoch 22] loss: 0.1789843\n",
      "Test set: Average loss: 1.4944, Accuracy: 3193/5000 (64%)\n",
      "[epoch 23] loss: 0.1574442\n",
      "Test set: Average loss: 1.6336, Accuracy: 3244/5000 (65%)\n",
      "[epoch 24] loss: 0.1167187\n",
      "Test set: Average loss: 1.7063, Accuracy: 3203/5000 (64%)\n",
      "[epoch 25] loss: 0.1361307\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.7495, Accuracy: 3192/5000 (64%)\n",
      "[epoch 26] loss: 0.0489977\n",
      "Test set: Average loss: 1.6516, Accuracy: 3312/5000 (66%)\n",
      "[epoch 27] loss: 0.0165975\n",
      "Test set: Average loss: 1.6525, Accuracy: 3323/5000 (66%)\n",
      "[epoch 28] loss: 0.0105348\n",
      "Test set: Average loss: 1.6742, Accuracy: 3339/5000 (67%)\n",
      "[epoch 29] loss: 0.0074426\n",
      "Test set: Average loss: 1.6900, Accuracy: 3349/5000 (67%)\n",
      "[epoch 30] loss: 0.0054656\n",
      "Test set: Average loss: 1.7166, Accuracy: 3350/5000 (67%)\n",
      "[epoch 31] loss: 0.0040343\n",
      "Test set: Average loss: 1.7408, Accuracy: 3354/5000 (67%)\n",
      "[epoch 32] loss: 0.0029660\n",
      "Test set: Average loss: 1.7766, Accuracy: 3357/5000 (67%)\n",
      "[epoch 33] loss: 0.0021632\n",
      "Test set: Average loss: 1.8137, Accuracy: 3370/5000 (67%)\n",
      "[epoch 34] loss: 0.0015622\n",
      "Test set: Average loss: 1.8574, Accuracy: 3364/5000 (67%)\n",
      "[epoch 35] loss: 0.0011148\n",
      "Test set: Average loss: 1.8929, Accuracy: 3354/5000 (67%)\n",
      "[epoch 36] loss: 0.0007895\n",
      "Test set: Average loss: 1.9343, Accuracy: 3367/5000 (67%)\n",
      "[epoch 37] loss: 0.0005553\n",
      "Test set: Average loss: 1.9851, Accuracy: 3372/5000 (67%)\n",
      "[epoch 38] loss: 0.0003872\n",
      "Test set: Average loss: 2.0368, Accuracy: 3366/5000 (67%)\n",
      "[epoch 39] loss: 0.0002671\n",
      "Test set: Average loss: 2.0829, Accuracy: 3375/5000 (68%)\n",
      "[epoch 40] loss: 0.0001849\n",
      "Test set: Average loss: 2.1351, Accuracy: 3380/5000 (68%)\n",
      "[epoch 41] loss: 0.0001268\n",
      "Test set: Average loss: 2.1911, Accuracy: 3372/5000 (67%)\n",
      "[epoch 42] loss: 0.0000860\n",
      "Test set: Average loss: 2.2533, Accuracy: 3367/5000 (67%)\n",
      "[epoch 43] loss: 0.0000589\n",
      "Test set: Average loss: 2.3030, Accuracy: 3389/5000 (68%)\n",
      "[epoch 44] loss: 0.0000398\n",
      "Test set: Average loss: 2.3701, Accuracy: 3375/5000 (68%)\n",
      "[epoch 45] loss: 0.0000270\n",
      "Test set: Average loss: 2.4262, Accuracy: 3378/5000 (68%)\n",
      "[epoch 46] loss: 0.0000181\n",
      "Test set: Average loss: 2.4834, Accuracy: 3385/5000 (68%)\n",
      "[epoch 47] loss: 0.0000122\n",
      "Test set: Average loss: 2.5465, Accuracy: 3385/5000 (68%)\n",
      "[epoch 48] loss: 0.0000081\n",
      "Test set: Average loss: 2.6078, Accuracy: 3388/5000 (68%)\n",
      "[epoch 49] loss: 0.0000054\n",
      "Test set: Average loss: 2.6684, Accuracy: 3381/5000 (68%)\n",
      "[epoch 50] loss: 0.0000036\n",
      "Test set: Average loss: 2.7292, Accuracy: 3386/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3030, Accuracy: 3389/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.2593, Accuracy: 6783/10000 (68%)\n",
      "35000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3043, Accuracy: 438/5000 (9%)\n",
      "[epoch 1] loss: 1.2413177\n",
      "Test set: Average loss: 1.2166, Accuracy: 2913/5000 (58%)\n",
      "[epoch 2] loss: 1.0980368\n",
      "Test set: Average loss: 1.1737, Accuracy: 2906/5000 (58%)\n",
      "[epoch 3] loss: 1.0480233\n",
      "Test set: Average loss: 1.1383, Accuracy: 3034/5000 (61%)\n",
      "[epoch 4] loss: 1.0142052\n",
      "Test set: Average loss: 1.0926, Accuracy: 3042/5000 (61%)\n",
      "[epoch 5] loss: 0.9796095\n",
      "Test set: Average loss: 1.0353, Accuracy: 3154/5000 (63%)\n",
      "[epoch 6] loss: 0.9508668\n",
      "Test set: Average loss: 1.0360, Accuracy: 3219/5000 (64%)\n",
      "[epoch 7] loss: 0.9081233\n",
      "Test set: Average loss: 1.0475, Accuracy: 3158/5000 (63%)\n",
      "[epoch 8] loss: 0.8728904\n",
      "Test set: Average loss: 1.1264, Accuracy: 3066/5000 (61%)\n",
      "[epoch 9] loss: 0.8362093\n",
      "Test set: Average loss: 1.0264, Accuracy: 3204/5000 (64%)\n",
      "[epoch 10] loss: 0.7973427\n",
      "Test set: Average loss: 1.0165, Accuracy: 3255/5000 (65%)\n",
      "[epoch 11] loss: 0.7505507\n",
      "Test set: Average loss: 1.0933, Accuracy: 3197/5000 (64%)\n",
      "[epoch 12] loss: 0.7066194\n",
      "Test set: Average loss: 1.0247, Accuracy: 3331/5000 (67%)\n",
      "[epoch 13] loss: 0.6452358\n",
      "Test set: Average loss: 1.0381, Accuracy: 3306/5000 (66%)\n",
      "[epoch 14] loss: 0.5838749\n",
      "Test set: Average loss: 1.0772, Accuracy: 3296/5000 (66%)\n",
      "[epoch 15] loss: 0.5165016\n",
      "Test set: Average loss: 1.0794, Accuracy: 3342/5000 (67%)\n",
      "[epoch 16] loss: 0.4529133\n",
      "Test set: Average loss: 1.1394, Accuracy: 3291/5000 (66%)\n",
      "[epoch 17] loss: 0.3761334\n",
      "Test set: Average loss: 1.1804, Accuracy: 3302/5000 (66%)\n",
      "[epoch 18] loss: 0.3117090\n",
      "Test set: Average loss: 1.2742, Accuracy: 3253/5000 (65%)\n",
      "[epoch 19] loss: 0.2577414\n",
      "Test set: Average loss: 1.3557, Accuracy: 3232/5000 (65%)\n",
      "[epoch 20] loss: 0.2178295\n",
      "Test set: Average loss: 1.4429, Accuracy: 3289/5000 (66%)\n",
      "[epoch 21] loss: 0.1810869\n",
      "Test set: Average loss: 1.4710, Accuracy: 3255/5000 (65%)\n",
      "[epoch 22] loss: 0.1689717\n",
      "Test set: Average loss: 1.6026, Accuracy: 3215/5000 (64%)\n",
      "[epoch 23] loss: 0.1516521\n",
      "Test set: Average loss: 1.5834, Accuracy: 3290/5000 (66%)\n",
      "[epoch 24] loss: 0.1328246\n",
      "Test set: Average loss: 1.7736, Accuracy: 3191/5000 (64%)\n",
      "[epoch 25] loss: 0.1538793\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6805, Accuracy: 3271/5000 (65%)\n",
      "[epoch 26] loss: 0.0540314\n",
      "Test set: Average loss: 1.6062, Accuracy: 3326/5000 (67%)\n",
      "[epoch 27] loss: 0.0179798\n",
      "Test set: Average loss: 1.6178, Accuracy: 3340/5000 (67%)\n",
      "[epoch 28] loss: 0.0106939\n",
      "Test set: Average loss: 1.6446, Accuracy: 3345/5000 (67%)\n",
      "[epoch 29] loss: 0.0072779\n",
      "Test set: Average loss: 1.6667, Accuracy: 3365/5000 (67%)\n",
      "[epoch 30] loss: 0.0050855\n",
      "Test set: Average loss: 1.6948, Accuracy: 3377/5000 (68%)\n",
      "[epoch 31] loss: 0.0035780\n",
      "Test set: Average loss: 1.7344, Accuracy: 3381/5000 (68%)\n",
      "[epoch 32] loss: 0.0024840\n",
      "Test set: Average loss: 1.7783, Accuracy: 3361/5000 (67%)\n",
      "[epoch 33] loss: 0.0017212\n",
      "Test set: Average loss: 1.8203, Accuracy: 3375/5000 (68%)\n",
      "[epoch 34] loss: 0.0011766\n",
      "Test set: Average loss: 1.8694, Accuracy: 3382/5000 (68%)\n",
      "[epoch 35] loss: 0.0007919\n",
      "Test set: Average loss: 1.9246, Accuracy: 3396/5000 (68%)\n",
      "[epoch 36] loss: 0.0005302\n",
      "Test set: Average loss: 1.9780, Accuracy: 3398/5000 (68%)\n",
      "[epoch 37] loss: 0.0003518\n",
      "Test set: Average loss: 2.0393, Accuracy: 3396/5000 (68%)\n",
      "[epoch 38] loss: 0.0002342\n",
      "Test set: Average loss: 2.0947, Accuracy: 3396/5000 (68%)\n",
      "[epoch 39] loss: 0.0001531\n",
      "Test set: Average loss: 2.1546, Accuracy: 3395/5000 (68%)\n",
      "[epoch 40] loss: 0.0000993\n",
      "Test set: Average loss: 2.2258, Accuracy: 3411/5000 (68%)\n",
      "[epoch 41] loss: 0.0000649\n",
      "Test set: Average loss: 2.2871, Accuracy: 3395/5000 (68%)\n",
      "[epoch 42] loss: 0.0000419\n",
      "Test set: Average loss: 2.3558, Accuracy: 3397/5000 (68%)\n",
      "[epoch 43] loss: 0.0000270\n",
      "Test set: Average loss: 2.4247, Accuracy: 3392/5000 (68%)\n",
      "[epoch 44] loss: 0.0000173\n",
      "Test set: Average loss: 2.4890, Accuracy: 3381/5000 (68%)\n",
      "[epoch 45] loss: 0.0000110\n",
      "Test set: Average loss: 2.5642, Accuracy: 3396/5000 (68%)\n",
      "[epoch 46] loss: 0.0000070\n",
      "Test set: Average loss: 2.6389, Accuracy: 3392/5000 (68%)\n",
      "[epoch 47] loss: 0.0000044\n",
      "Test set: Average loss: 2.7027, Accuracy: 3391/5000 (68%)\n",
      "[epoch 48] loss: 0.0000028\n",
      "Test set: Average loss: 2.7730, Accuracy: 3391/5000 (68%)\n",
      "[epoch 49] loss: 0.0000018\n",
      "Test set: Average loss: 2.8468, Accuracy: 3398/5000 (68%)\n",
      "[epoch 50] loss: 0.0000011\n",
      "Test set: Average loss: 2.8929, Accuracy: 3405/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2258, Accuracy: 3411/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.1263, Accuracy: 6889/10000 (69%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3006, Accuracy: 550/5000 (11%)\n",
      "[epoch 1] loss: 1.2431125\n",
      "Test set: Average loss: 1.2394, Accuracy: 2854/5000 (57%)\n",
      "[epoch 2] loss: 1.1016359\n",
      "Test set: Average loss: 1.1447, Accuracy: 3039/5000 (61%)\n",
      "[epoch 3] loss: 1.0542482\n",
      "Test set: Average loss: 1.1335, Accuracy: 3058/5000 (61%)\n",
      "[epoch 4] loss: 1.0118273\n",
      "Test set: Average loss: 1.0900, Accuracy: 3065/5000 (61%)\n",
      "[epoch 5] loss: 0.9789089\n",
      "Test set: Average loss: 1.0983, Accuracy: 3078/5000 (62%)\n",
      "[epoch 6] loss: 0.9492989\n",
      "Test set: Average loss: 1.1098, Accuracy: 3033/5000 (61%)\n",
      "[epoch 7] loss: 0.9177513\n",
      "Test set: Average loss: 1.0199, Accuracy: 3205/5000 (64%)\n",
      "[epoch 8] loss: 0.8858214\n",
      "Test set: Average loss: 1.0348, Accuracy: 3152/5000 (63%)\n",
      "[epoch 9] loss: 0.8460524\n",
      "Test set: Average loss: 1.1292, Accuracy: 3078/5000 (62%)\n",
      "[epoch 10] loss: 0.8139005\n",
      "Test set: Average loss: 1.0556, Accuracy: 3229/5000 (65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] loss: 0.7723772\n",
      "Test set: Average loss: 1.0712, Accuracy: 3223/5000 (64%)\n",
      "[epoch 12] loss: 0.7214348\n",
      "Test set: Average loss: 1.1200, Accuracy: 3214/5000 (64%)\n",
      "[epoch 13] loss: 0.6832536\n",
      "Test set: Average loss: 1.0986, Accuracy: 3237/5000 (65%)\n",
      "[epoch 14] loss: 0.6199605\n",
      "Test set: Average loss: 1.0551, Accuracy: 3256/5000 (65%)\n",
      "[epoch 15] loss: 0.5528376\n",
      "Test set: Average loss: 1.0865, Accuracy: 3332/5000 (67%)\n",
      "[epoch 16] loss: 0.4809781\n",
      "Test set: Average loss: 1.1450, Accuracy: 3254/5000 (65%)\n",
      "[epoch 17] loss: 0.4101723\n",
      "Test set: Average loss: 1.1994, Accuracy: 3299/5000 (66%)\n",
      "[epoch 18] loss: 0.3472316\n",
      "Test set: Average loss: 1.2260, Accuracy: 3299/5000 (66%)\n",
      "[epoch 19] loss: 0.2820377\n",
      "Test set: Average loss: 1.3307, Accuracy: 3296/5000 (66%)\n",
      "[epoch 20] loss: 0.2391605\n",
      "Test set: Average loss: 1.3705, Accuracy: 3305/5000 (66%)\n",
      "[epoch 21] loss: 0.1909256\n",
      "Test set: Average loss: 1.4450, Accuracy: 3263/5000 (65%)\n",
      "[epoch 22] loss: 0.1791092\n",
      "Test set: Average loss: 1.5676, Accuracy: 3281/5000 (66%)\n",
      "[epoch 23] loss: 0.1668867\n",
      "Test set: Average loss: 1.6424, Accuracy: 3248/5000 (65%)\n",
      "[epoch 24] loss: 0.1521771\n",
      "Test set: Average loss: 1.6706, Accuracy: 3286/5000 (66%)\n",
      "[epoch 25] loss: 0.1330252\n",
      "Test set: Average loss: 1.8630, Accuracy: 3206/5000 (64%)\n",
      "[epoch 26] loss: 0.1532196\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8069, Accuracy: 3230/5000 (65%)\n",
      "[epoch 27] loss: 0.0515832\n",
      "Test set: Average loss: 1.6693, Accuracy: 3325/5000 (66%)\n",
      "[epoch 28] loss: 0.0171445\n",
      "Test set: Average loss: 1.6926, Accuracy: 3338/5000 (67%)\n",
      "[epoch 29] loss: 0.0103158\n",
      "Test set: Average loss: 1.7050, Accuracy: 3355/5000 (67%)\n",
      "[epoch 30] loss: 0.0069003\n",
      "Test set: Average loss: 1.7232, Accuracy: 3356/5000 (67%)\n",
      "[epoch 31] loss: 0.0048539\n",
      "Test set: Average loss: 1.7519, Accuracy: 3360/5000 (67%)\n",
      "[epoch 32] loss: 0.0034124\n",
      "Test set: Average loss: 1.7812, Accuracy: 3380/5000 (68%)\n",
      "[epoch 33] loss: 0.0023767\n",
      "Test set: Average loss: 1.8145, Accuracy: 3370/5000 (67%)\n",
      "[epoch 34] loss: 0.0016343\n",
      "Test set: Average loss: 1.8477, Accuracy: 3377/5000 (68%)\n",
      "[epoch 35] loss: 0.0011192\n",
      "Test set: Average loss: 1.8981, Accuracy: 3381/5000 (68%)\n",
      "[epoch 36] loss: 0.0007536\n",
      "Test set: Average loss: 1.9420, Accuracy: 3386/5000 (68%)\n",
      "[epoch 37] loss: 0.0005022\n",
      "Test set: Average loss: 1.9881, Accuracy: 3389/5000 (68%)\n",
      "[epoch 38] loss: 0.0003354\n",
      "Test set: Average loss: 2.0448, Accuracy: 3391/5000 (68%)\n",
      "[epoch 39] loss: 0.0002206\n",
      "Test set: Average loss: 2.1111, Accuracy: 3388/5000 (68%)\n",
      "[epoch 40] loss: 0.0001452\n",
      "Test set: Average loss: 2.1515, Accuracy: 3404/5000 (68%)\n",
      "[epoch 41] loss: 0.0000942\n",
      "Test set: Average loss: 2.2189, Accuracy: 3406/5000 (68%)\n",
      "[epoch 42] loss: 0.0000613\n",
      "Test set: Average loss: 2.2871, Accuracy: 3398/5000 (68%)\n",
      "[epoch 43] loss: 0.0000395\n",
      "Test set: Average loss: 2.3442, Accuracy: 3408/5000 (68%)\n",
      "[epoch 44] loss: 0.0000256\n",
      "Test set: Average loss: 2.4121, Accuracy: 3393/5000 (68%)\n",
      "[epoch 45] loss: 0.0000163\n",
      "Test set: Average loss: 2.4721, Accuracy: 3404/5000 (68%)\n",
      "[epoch 46] loss: 0.0000105\n",
      "Test set: Average loss: 2.5386, Accuracy: 3406/5000 (68%)\n",
      "[epoch 47] loss: 0.0000066\n",
      "Test set: Average loss: 2.6099, Accuracy: 3388/5000 (68%)\n",
      "[epoch 48] loss: 0.0000042\n",
      "Test set: Average loss: 2.6712, Accuracy: 3405/5000 (68%)\n",
      "[epoch 49] loss: 0.0000027\n",
      "Test set: Average loss: 2.7291, Accuracy: 3399/5000 (68%)\n",
      "[epoch 50] loss: 0.0000017\n",
      "Test set: Average loss: 2.7904, Accuracy: 3397/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.3442, Accuracy: 3408/5000 (68%)\n",
      "Test\n",
      "Test set: Average loss: 2.2603, Accuracy: 6849/10000 (68%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3038, Accuracy: 534/5000 (11%)\n",
      "[epoch 1] loss: 1.2425834\n",
      "Test set: Average loss: 1.1635, Accuracy: 2918/5000 (58%)\n",
      "[epoch 2] loss: 1.1046955\n",
      "Test set: Average loss: 1.1281, Accuracy: 3023/5000 (60%)\n",
      "[epoch 3] loss: 1.0535446\n",
      "Test set: Average loss: 1.1452, Accuracy: 3023/5000 (60%)\n",
      "[epoch 4] loss: 1.0179511\n",
      "Test set: Average loss: 1.0985, Accuracy: 3061/5000 (61%)\n",
      "[epoch 5] loss: 0.9811130\n",
      "Test set: Average loss: 1.0421, Accuracy: 3153/5000 (63%)\n",
      "[epoch 6] loss: 0.9470773\n",
      "Test set: Average loss: 1.0653, Accuracy: 3150/5000 (63%)\n",
      "[epoch 7] loss: 0.9169538\n",
      "Test set: Average loss: 1.0729, Accuracy: 3119/5000 (62%)\n",
      "[epoch 8] loss: 0.8849790\n",
      "Test set: Average loss: 1.0637, Accuracy: 3166/5000 (63%)\n",
      "[epoch 9] loss: 0.8500608\n",
      "Test set: Average loss: 1.0779, Accuracy: 3134/5000 (63%)\n",
      "[epoch 10] loss: 0.8184495\n",
      "Test set: Average loss: 1.0293, Accuracy: 3250/5000 (65%)\n",
      "[epoch 11] loss: 0.7783023\n",
      "Test set: Average loss: 0.9821, Accuracy: 3315/5000 (66%)\n",
      "[epoch 12] loss: 0.7331257\n",
      "Test set: Average loss: 1.0266, Accuracy: 3281/5000 (66%)\n",
      "[epoch 13] loss: 0.6786842\n",
      "Test set: Average loss: 1.0873, Accuracy: 3208/5000 (64%)\n",
      "[epoch 14] loss: 0.6198292\n",
      "Test set: Average loss: 1.0462, Accuracy: 3325/5000 (66%)\n",
      "[epoch 15] loss: 0.5480279\n",
      "Test set: Average loss: 1.1390, Accuracy: 3250/5000 (65%)\n",
      "[epoch 16] loss: 0.4961749\n",
      "Test set: Average loss: 1.1123, Accuracy: 3322/5000 (66%)\n",
      "[epoch 17] loss: 0.4148230\n",
      "Test set: Average loss: 1.1607, Accuracy: 3316/5000 (66%)\n",
      "[epoch 18] loss: 0.3510908\n",
      "Test set: Average loss: 1.2085, Accuracy: 3315/5000 (66%)\n",
      "[epoch 19] loss: 0.2733328\n",
      "Test set: Average loss: 1.2879, Accuracy: 3319/5000 (66%)\n",
      "[epoch 20] loss: 0.2339079\n",
      "Test set: Average loss: 1.3547, Accuracy: 3301/5000 (66%)\n",
      "[epoch 21] loss: 0.1922940\n",
      "Test set: Average loss: 1.5090, Accuracy: 3270/5000 (65%)\n",
      "[epoch 22] loss: 0.1735380\n",
      "Test set: Average loss: 1.5726, Accuracy: 3226/5000 (65%)\n",
      "[epoch 23] loss: 0.1646177\n",
      "Test set: Average loss: 1.6119, Accuracy: 3270/5000 (65%)\n",
      "[epoch 24] loss: 0.1467935\n",
      "Test set: Average loss: 1.6918, Accuracy: 3225/5000 (64%)\n",
      "[epoch 25] loss: 0.1383743\n",
      "Test set: Average loss: 1.7519, Accuracy: 3239/5000 (65%)\n",
      "[epoch 26] loss: 0.1510203\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6546, Accuracy: 3274/5000 (65%)\n",
      "[epoch 27] loss: 0.0488386\n",
      "Test set: Average loss: 1.6117, Accuracy: 3318/5000 (66%)\n",
      "[epoch 28] loss: 0.0166635\n",
      "Test set: Average loss: 1.6222, Accuracy: 3351/5000 (67%)\n",
      "[epoch 29] loss: 0.0099344\n",
      "Test set: Average loss: 1.6392, Accuracy: 3364/5000 (67%)\n",
      "[epoch 30] loss: 0.0067707\n",
      "Test set: Average loss: 1.6644, Accuracy: 3366/5000 (67%)\n",
      "[epoch 31] loss: 0.0047507\n",
      "Test set: Average loss: 1.6988, Accuracy: 3371/5000 (67%)\n",
      "[epoch 32] loss: 0.0033168\n",
      "Test set: Average loss: 1.7272, Accuracy: 3381/5000 (68%)\n",
      "[epoch 33] loss: 0.0023130\n",
      "Test set: Average loss: 1.7646, Accuracy: 3378/5000 (68%)\n",
      "[epoch 34] loss: 0.0015996\n",
      "Test set: Average loss: 1.8023, Accuracy: 3381/5000 (68%)\n",
      "[epoch 35] loss: 0.0010834\n",
      "Test set: Average loss: 1.8530, Accuracy: 3392/5000 (68%)\n",
      "[epoch 36] loss: 0.0007376\n",
      "Test set: Average loss: 1.8998, Accuracy: 3379/5000 (68%)\n",
      "[epoch 37] loss: 0.0004938\n",
      "Test set: Average loss: 1.9473, Accuracy: 3408/5000 (68%)\n",
      "[epoch 38] loss: 0.0003288\n",
      "Test set: Average loss: 1.9998, Accuracy: 3412/5000 (68%)\n",
      "[epoch 39] loss: 0.0002173\n",
      "Test set: Average loss: 2.0674, Accuracy: 3403/5000 (68%)\n",
      "[epoch 40] loss: 0.0001422\n",
      "Test set: Average loss: 2.1152, Accuracy: 3403/5000 (68%)\n",
      "[epoch 41] loss: 0.0000930\n",
      "Test set: Average loss: 2.1706, Accuracy: 3402/5000 (68%)\n",
      "[epoch 42] loss: 0.0000604\n",
      "Test set: Average loss: 2.2288, Accuracy: 3412/5000 (68%)\n",
      "[epoch 43] loss: 0.0000391\n",
      "Test set: Average loss: 2.2955, Accuracy: 3407/5000 (68%)\n",
      "[epoch 44] loss: 0.0000252\n",
      "Test set: Average loss: 2.3492, Accuracy: 3418/5000 (68%)\n",
      "[epoch 45] loss: 0.0000161\n",
      "Test set: Average loss: 2.4183, Accuracy: 3417/5000 (68%)\n",
      "[epoch 46] loss: 0.0000103\n",
      "Test set: Average loss: 2.4803, Accuracy: 3423/5000 (68%)\n",
      "[epoch 47] loss: 0.0000066\n",
      "Test set: Average loss: 2.5474, Accuracy: 3413/5000 (68%)\n",
      "[epoch 48] loss: 0.0000042\n",
      "Test set: Average loss: 2.6060, Accuracy: 3410/5000 (68%)\n",
      "[epoch 49] loss: 0.0000026\n",
      "Test set: Average loss: 2.6596, Accuracy: 3430/5000 (69%)\n",
      "[epoch 50] loss: 0.0000016\n",
      "Test set: Average loss: 2.7282, Accuracy: 3410/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6596, Accuracy: 3430/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.5818, Accuracy: 6881/10000 (69%)\n",
      "40000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3028, Accuracy: 486/5000 (10%)\n",
      "[epoch 1] loss: 1.2365484\n",
      "Test set: Average loss: 1.1672, Accuracy: 2947/5000 (59%)\n",
      "[epoch 2] loss: 1.1034799\n",
      "Test set: Average loss: 1.1646, Accuracy: 2896/5000 (58%)\n",
      "[epoch 3] loss: 1.0402649\n",
      "Test set: Average loss: 1.1454, Accuracy: 3029/5000 (61%)\n",
      "[epoch 4] loss: 1.0120479\n",
      "Test set: Average loss: 1.0774, Accuracy: 3115/5000 (62%)\n",
      "[epoch 5] loss: 0.9698679\n",
      "Test set: Average loss: 1.0559, Accuracy: 3173/5000 (63%)\n",
      "[epoch 6] loss: 0.9293945\n",
      "Test set: Average loss: 1.0698, Accuracy: 3158/5000 (63%)\n",
      "[epoch 7] loss: 0.9014098\n",
      "Test set: Average loss: 1.0327, Accuracy: 3180/5000 (64%)\n",
      "[epoch 8] loss: 0.8573390\n",
      "Test set: Average loss: 1.0539, Accuracy: 3180/5000 (64%)\n",
      "[epoch 9] loss: 0.8200568\n",
      "Test set: Average loss: 1.0793, Accuracy: 3213/5000 (64%)\n",
      "[epoch 10] loss: 0.7754323\n",
      "Test set: Average loss: 1.0220, Accuracy: 3255/5000 (65%)\n",
      "[epoch 11] loss: 0.7309723\n",
      "Test set: Average loss: 1.0212, Accuracy: 3280/5000 (66%)\n",
      "[epoch 12] loss: 0.6801362\n",
      "Test set: Average loss: 1.0193, Accuracy: 3275/5000 (66%)\n",
      "[epoch 13] loss: 0.6191959\n",
      "Test set: Average loss: 1.0289, Accuracy: 3363/5000 (67%)\n",
      "[epoch 14] loss: 0.5554764\n",
      "Test set: Average loss: 1.0339, Accuracy: 3372/5000 (67%)\n",
      "[epoch 15] loss: 0.4909672\n",
      "Test set: Average loss: 1.1222, Accuracy: 3283/5000 (66%)\n",
      "[epoch 16] loss: 0.4215263\n",
      "Test set: Average loss: 1.1512, Accuracy: 3325/5000 (66%)\n",
      "[epoch 17] loss: 0.3644871\n",
      "Test set: Average loss: 1.2068, Accuracy: 3329/5000 (67%)\n",
      "[epoch 18] loss: 0.2999940\n",
      "Test set: Average loss: 1.2893, Accuracy: 3307/5000 (66%)\n",
      "[epoch 19] loss: 0.2594729\n",
      "Test set: Average loss: 1.3717, Accuracy: 3273/5000 (65%)\n",
      "[epoch 20] loss: 0.2206690\n",
      "Test set: Average loss: 1.4648, Accuracy: 3250/5000 (65%)\n",
      "[epoch 21] loss: 0.2050275\n",
      "Test set: Average loss: 1.4828, Accuracy: 3320/5000 (66%)\n",
      "[epoch 22] loss: 0.1781778\n",
      "Test set: Average loss: 1.5304, Accuracy: 3306/5000 (66%)\n",
      "[epoch 23] loss: 0.1695642\n",
      "Test set: Average loss: 1.6745, Accuracy: 3274/5000 (65%)\n",
      "[epoch 24] loss: 0.1663329\n",
      "Test set: Average loss: 1.6778, Accuracy: 3291/5000 (66%)\n",
      "[epoch 25] loss: 0.1649017\n",
      "Test set: Average loss: 1.6857, Accuracy: 3304/5000 (66%)\n",
      "[epoch 26] loss: 0.1604237\n",
      "Test set: Average loss: 1.6541, Accuracy: 3331/5000 (67%)\n",
      "[epoch 27] loss: 0.1592621\n",
      "Test set: Average loss: 1.7613, Accuracy: 3253/5000 (65%)\n",
      "[epoch 28] loss: 0.1452073\n",
      "Test set: Average loss: 1.7619, Accuracy: 3341/5000 (67%)\n",
      "[epoch 29] loss: 0.1469391\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.8779, Accuracy: 3234/5000 (65%)\n",
      "[epoch 30] loss: 0.0557160\n",
      "Test set: Average loss: 1.7535, Accuracy: 3352/5000 (67%)\n",
      "[epoch 31] loss: 0.0164865\n",
      "Test set: Average loss: 1.7566, Accuracy: 3375/5000 (68%)\n",
      "[epoch 32] loss: 0.0089562\n",
      "Test set: Average loss: 1.7726, Accuracy: 3369/5000 (67%)\n",
      "[epoch 33] loss: 0.0057938\n",
      "Test set: Average loss: 1.7866, Accuracy: 3377/5000 (68%)\n",
      "[epoch 34] loss: 0.0038916\n",
      "Test set: Average loss: 1.8148, Accuracy: 3381/5000 (68%)\n",
      "[epoch 35] loss: 0.0026015\n",
      "Test set: Average loss: 1.8524, Accuracy: 3382/5000 (68%)\n",
      "[epoch 36] loss: 0.0017283\n",
      "Test set: Average loss: 1.8933, Accuracy: 3387/5000 (68%)\n",
      "[epoch 37] loss: 0.0011365\n",
      "Test set: Average loss: 1.9345, Accuracy: 3399/5000 (68%)\n",
      "[epoch 38] loss: 0.0007396\n",
      "Test set: Average loss: 1.9839, Accuracy: 3402/5000 (68%)\n",
      "[epoch 39] loss: 0.0004756\n",
      "Test set: Average loss: 2.0348, Accuracy: 3411/5000 (68%)\n",
      "[epoch 40] loss: 0.0003027\n",
      "Test set: Average loss: 2.0893, Accuracy: 3416/5000 (68%)\n",
      "[epoch 41] loss: 0.0001914\n",
      "Test set: Average loss: 2.1481, Accuracy: 3418/5000 (68%)\n",
      "[epoch 42] loss: 0.0001210\n",
      "Test set: Average loss: 2.2135, Accuracy: 3414/5000 (68%)\n",
      "[epoch 43] loss: 0.0000754\n",
      "Test set: Average loss: 2.2766, Accuracy: 3418/5000 (68%)\n",
      "[epoch 44] loss: 0.0000468\n",
      "Test set: Average loss: 2.3371, Accuracy: 3428/5000 (69%)\n",
      "[epoch 45] loss: 0.0000289\n",
      "Test set: Average loss: 2.4105, Accuracy: 3424/5000 (68%)\n",
      "[epoch 46] loss: 0.0000179\n",
      "Test set: Average loss: 2.4800, Accuracy: 3428/5000 (69%)\n",
      "[epoch 47] loss: 0.0000109\n",
      "Test set: Average loss: 2.5532, Accuracy: 3437/5000 (69%)\n",
      "[epoch 48] loss: 0.0000067\n",
      "Test set: Average loss: 2.6233, Accuracy: 3440/5000 (69%)\n",
      "[epoch 49] loss: 0.0000040\n",
      "Test set: Average loss: 2.6970, Accuracy: 3443/5000 (69%)\n",
      "[epoch 50] loss: 0.0000024\n",
      "Test set: Average loss: 2.7622, Accuracy: 3444/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.7622, Accuracy: 3444/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.6224, Accuracy: 6949/10000 (69%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3035, Accuracy: 500/5000 (10%)\n",
      "[epoch 1] loss: 1.2290393\n",
      "Test set: Average loss: 1.3110, Accuracy: 2733/5000 (55%)\n",
      "[epoch 2] loss: 1.0964557\n",
      "Test set: Average loss: 1.1642, Accuracy: 2979/5000 (60%)\n",
      "[epoch 3] loss: 1.0468103\n",
      "Test set: Average loss: 1.1627, Accuracy: 2936/5000 (59%)\n",
      "[epoch 4] loss: 1.0074270\n",
      "Test set: Average loss: 1.0729, Accuracy: 3111/5000 (62%)\n",
      "[epoch 5] loss: 0.9669630\n",
      "Test set: Average loss: 1.0675, Accuracy: 3114/5000 (62%)\n",
      "[epoch 6] loss: 0.9411378\n",
      "Test set: Average loss: 1.0377, Accuracy: 3203/5000 (64%)\n",
      "[epoch 7] loss: 0.9120383\n",
      "Test set: Average loss: 1.0527, Accuracy: 3160/5000 (63%)\n",
      "[epoch 8] loss: 0.8724670\n",
      "Test set: Average loss: 1.0253, Accuracy: 3237/5000 (65%)\n",
      "[epoch 9] loss: 0.8375424\n",
      "Test set: Average loss: 1.0212, Accuracy: 3220/5000 (64%)\n",
      "[epoch 10] loss: 0.7894010\n",
      "Test set: Average loss: 1.0030, Accuracy: 3282/5000 (66%)\n",
      "[epoch 11] loss: 0.7467324\n",
      "Test set: Average loss: 1.0028, Accuracy: 3313/5000 (66%)\n",
      "[epoch 12] loss: 0.7010714\n",
      "Test set: Average loss: 0.9851, Accuracy: 3327/5000 (67%)\n",
      "[epoch 13] loss: 0.6400542\n",
      "Test set: Average loss: 1.0095, Accuracy: 3314/5000 (66%)\n",
      "[epoch 14] loss: 0.5747223\n",
      "Test set: Average loss: 1.0450, Accuracy: 3299/5000 (66%)\n",
      "[epoch 15] loss: 0.5111996\n",
      "Test set: Average loss: 1.0838, Accuracy: 3332/5000 (67%)\n",
      "[epoch 16] loss: 0.4315279\n",
      "Test set: Average loss: 1.1254, Accuracy: 3327/5000 (67%)\n",
      "[epoch 17] loss: 0.3720050\n",
      "Test set: Average loss: 1.1787, Accuracy: 3348/5000 (67%)\n",
      "[epoch 18] loss: 0.3113701\n",
      "Test set: Average loss: 1.2319, Accuracy: 3351/5000 (67%)\n",
      "[epoch 19] loss: 0.2723061\n",
      "Test set: Average loss: 1.3399, Accuracy: 3311/5000 (66%)\n",
      "[epoch 20] loss: 0.2350815\n",
      "Test set: Average loss: 1.4171, Accuracy: 3232/5000 (65%)\n",
      "[epoch 21] loss: 0.1972957\n",
      "Test set: Average loss: 1.4217, Accuracy: 3327/5000 (67%)\n",
      "[epoch 22] loss: 0.1916253\n",
      "Test set: Average loss: 1.4689, Accuracy: 3307/5000 (66%)\n",
      "[epoch 23] loss: 0.1764723\n",
      "Test set: Average loss: 1.5630, Accuracy: 3288/5000 (66%)\n",
      "[epoch 24] loss: 0.1685814\n",
      "Test set: Average loss: 1.6314, Accuracy: 3315/5000 (66%)\n",
      "[epoch 25] loss: 0.1545983\n",
      "Test set: Average loss: 1.6623, Accuracy: 3295/5000 (66%)\n",
      "[epoch 26] loss: 0.1707225\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6771, Accuracy: 3266/5000 (65%)\n",
      "[epoch 27] loss: 0.0523417\n",
      "Test set: Average loss: 1.6002, Accuracy: 3390/5000 (68%)\n",
      "[epoch 28] loss: 0.0172643\n",
      "Test set: Average loss: 1.6165, Accuracy: 3400/5000 (68%)\n",
      "[epoch 29] loss: 0.0102311\n",
      "Test set: Average loss: 1.6362, Accuracy: 3409/5000 (68%)\n",
      "[epoch 30] loss: 0.0067602\n",
      "Test set: Average loss: 1.6552, Accuracy: 3427/5000 (69%)\n",
      "[epoch 31] loss: 0.0045772\n",
      "Test set: Average loss: 1.6843, Accuracy: 3412/5000 (68%)\n",
      "[epoch 32] loss: 0.0030630\n",
      "Test set: Average loss: 1.7209, Accuracy: 3428/5000 (69%)\n",
      "[epoch 33] loss: 0.0020435\n",
      "Test set: Average loss: 1.7541, Accuracy: 3418/5000 (68%)\n",
      "[epoch 34] loss: 0.0013349\n",
      "Test set: Average loss: 1.8020, Accuracy: 3430/5000 (69%)\n",
      "[epoch 35] loss: 0.0008692\n",
      "Test set: Average loss: 1.8495, Accuracy: 3443/5000 (69%)\n",
      "[epoch 36] loss: 0.0005572\n",
      "Test set: Average loss: 1.8934, Accuracy: 3444/5000 (69%)\n",
      "[epoch 37] loss: 0.0003594\n",
      "Test set: Average loss: 1.9527, Accuracy: 3432/5000 (69%)\n",
      "[epoch 38] loss: 0.0002261\n",
      "Test set: Average loss: 2.0164, Accuracy: 3453/5000 (69%)\n",
      "[epoch 39] loss: 0.0001425\n",
      "Test set: Average loss: 2.0800, Accuracy: 3450/5000 (69%)\n",
      "[epoch 40] loss: 0.0000886\n",
      "Test set: Average loss: 2.1417, Accuracy: 3443/5000 (69%)\n",
      "[epoch 41] loss: 0.0000554\n",
      "Test set: Average loss: 2.2058, Accuracy: 3448/5000 (69%)\n",
      "[epoch 42] loss: 0.0000340\n",
      "Test set: Average loss: 2.2796, Accuracy: 3445/5000 (69%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 43] loss: 0.0000208\n",
      "Test set: Average loss: 2.3452, Accuracy: 3450/5000 (69%)\n",
      "[epoch 44] loss: 0.0000128\n",
      "Test set: Average loss: 2.4143, Accuracy: 3451/5000 (69%)\n",
      "[epoch 45] loss: 0.0000078\n",
      "Test set: Average loss: 2.4778, Accuracy: 3451/5000 (69%)\n",
      "[epoch 46] loss: 0.0000047\n",
      "Test set: Average loss: 2.5515, Accuracy: 3459/5000 (69%)\n",
      "[epoch 47] loss: 0.0000028\n",
      "Test set: Average loss: 2.6174, Accuracy: 3463/5000 (69%)\n",
      "[epoch 48] loss: 0.0000017\n",
      "Test set: Average loss: 2.6887, Accuracy: 3452/5000 (69%)\n",
      "[epoch 49] loss: 0.0000010\n",
      "Test set: Average loss: 2.7453, Accuracy: 3439/5000 (69%)\n",
      "[epoch 50] loss: 0.0000006\n",
      "Test set: Average loss: 2.7833, Accuracy: 3448/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.6174, Accuracy: 3463/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.6214, Accuracy: 6965/10000 (70%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3041, Accuracy: 307/5000 (6%)\n",
      "[epoch 1] loss: 1.2254695\n",
      "Test set: Average loss: 1.2300, Accuracy: 2851/5000 (57%)\n",
      "[epoch 2] loss: 1.0916814\n",
      "Test set: Average loss: 1.1480, Accuracy: 2998/5000 (60%)\n",
      "[epoch 3] loss: 1.0465190\n",
      "Test set: Average loss: 1.0782, Accuracy: 3125/5000 (62%)\n",
      "[epoch 4] loss: 1.0136102\n",
      "Test set: Average loss: 1.0649, Accuracy: 3111/5000 (62%)\n",
      "[epoch 5] loss: 0.9719908\n",
      "Test set: Average loss: 1.0764, Accuracy: 3140/5000 (63%)\n",
      "[epoch 6] loss: 0.9419479\n",
      "Test set: Average loss: 1.0296, Accuracy: 3231/5000 (65%)\n",
      "[epoch 7] loss: 0.8980832\n",
      "Test set: Average loss: 1.0390, Accuracy: 3174/5000 (63%)\n",
      "[epoch 8] loss: 0.8685639\n",
      "Test set: Average loss: 1.0357, Accuracy: 3203/5000 (64%)\n",
      "[epoch 9] loss: 0.8262919\n",
      "Test set: Average loss: 1.0514, Accuracy: 3194/5000 (64%)\n",
      "[epoch 10] loss: 0.7865277\n",
      "Test set: Average loss: 1.0353, Accuracy: 3271/5000 (65%)\n",
      "[epoch 11] loss: 0.7418086\n",
      "Test set: Average loss: 1.0598, Accuracy: 3216/5000 (64%)\n",
      "[epoch 12] loss: 0.6871306\n",
      "Test set: Average loss: 1.0394, Accuracy: 3322/5000 (66%)\n",
      "[epoch 13] loss: 0.6267090\n",
      "Test set: Average loss: 0.9999, Accuracy: 3384/5000 (68%)\n",
      "[epoch 14] loss: 0.5635400\n",
      "Test set: Average loss: 1.0653, Accuracy: 3309/5000 (66%)\n",
      "[epoch 15] loss: 0.4932122\n",
      "Test set: Average loss: 1.0972, Accuracy: 3355/5000 (67%)\n",
      "[epoch 16] loss: 0.4318555\n",
      "Test set: Average loss: 1.1426, Accuracy: 3339/5000 (67%)\n",
      "[epoch 17] loss: 0.3650283\n",
      "Test set: Average loss: 1.1860, Accuracy: 3330/5000 (67%)\n",
      "[epoch 18] loss: 0.3048410\n",
      "Test set: Average loss: 1.2188, Accuracy: 3361/5000 (67%)\n",
      "[epoch 19] loss: 0.2546781\n",
      "Test set: Average loss: 1.3619, Accuracy: 3327/5000 (67%)\n",
      "[epoch 20] loss: 0.2200821\n",
      "Test set: Average loss: 1.3760, Accuracy: 3308/5000 (66%)\n",
      "[epoch 21] loss: 0.1960105\n",
      "Test set: Average loss: 1.5258, Accuracy: 3264/5000 (65%)\n",
      "[epoch 22] loss: 0.1811719\n",
      "Test set: Average loss: 1.5457, Accuracy: 3291/5000 (66%)\n",
      "[epoch 23] loss: 0.1646818\n",
      "Test set: Average loss: 1.5825, Accuracy: 3309/5000 (66%)\n",
      "[epoch 24] loss: 0.1761030\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.6395, Accuracy: 3314/5000 (66%)\n",
      "[epoch 25] loss: 0.0628760\n",
      "Test set: Average loss: 1.5466, Accuracy: 3381/5000 (68%)\n",
      "[epoch 26] loss: 0.0222613\n",
      "Test set: Average loss: 1.5604, Accuracy: 3390/5000 (68%)\n",
      "[epoch 27] loss: 0.0130833\n",
      "Test set: Average loss: 1.5790, Accuracy: 3398/5000 (68%)\n",
      "[epoch 28] loss: 0.0086527\n",
      "Test set: Average loss: 1.6101, Accuracy: 3404/5000 (68%)\n",
      "[epoch 29] loss: 0.0059004\n",
      "Test set: Average loss: 1.6424, Accuracy: 3415/5000 (68%)\n",
      "[epoch 30] loss: 0.0039698\n",
      "Test set: Average loss: 1.6807, Accuracy: 3412/5000 (68%)\n",
      "[epoch 31] loss: 0.0026741\n",
      "Test set: Average loss: 1.7288, Accuracy: 3409/5000 (68%)\n",
      "[epoch 32] loss: 0.0017642\n",
      "Test set: Average loss: 1.7701, Accuracy: 3433/5000 (69%)\n",
      "[epoch 33] loss: 0.0011554\n",
      "Test set: Average loss: 1.8276, Accuracy: 3428/5000 (69%)\n",
      "[epoch 34] loss: 0.0007542\n",
      "Test set: Average loss: 1.8759, Accuracy: 3432/5000 (69%)\n",
      "[epoch 35] loss: 0.0004869\n",
      "Test set: Average loss: 1.9347, Accuracy: 3446/5000 (69%)\n",
      "[epoch 36] loss: 0.0003121\n",
      "Test set: Average loss: 1.9981, Accuracy: 3431/5000 (69%)\n",
      "[epoch 37] loss: 0.0001995\n",
      "Test set: Average loss: 2.0586, Accuracy: 3441/5000 (69%)\n",
      "[epoch 38] loss: 0.0001257\n",
      "Test set: Average loss: 2.1225, Accuracy: 3452/5000 (69%)\n",
      "[epoch 39] loss: 0.0000789\n",
      "Test set: Average loss: 2.1918, Accuracy: 3436/5000 (69%)\n",
      "[epoch 40] loss: 0.0000491\n",
      "Test set: Average loss: 2.2635, Accuracy: 3443/5000 (69%)\n",
      "[epoch 41] loss: 0.0000308\n",
      "Test set: Average loss: 2.3273, Accuracy: 3446/5000 (69%)\n",
      "[epoch 42] loss: 0.0000191\n",
      "Test set: Average loss: 2.3961, Accuracy: 3450/5000 (69%)\n",
      "[epoch 43] loss: 0.0000116\n",
      "Test set: Average loss: 2.4753, Accuracy: 3441/5000 (69%)\n",
      "[epoch 44] loss: 0.0000071\n",
      "Test set: Average loss: 2.5426, Accuracy: 3441/5000 (69%)\n",
      "[epoch 45] loss: 0.0000043\n",
      "Test set: Average loss: 2.6171, Accuracy: 3443/5000 (69%)\n",
      "[epoch 46] loss: 0.0000026\n",
      "Test set: Average loss: 2.6771, Accuracy: 3440/5000 (69%)\n",
      "[epoch 47] loss: 0.0000016\n",
      "Test set: Average loss: 2.7485, Accuracy: 3433/5000 (69%)\n",
      "[epoch 48] loss: 0.0000009\n",
      "Test set: Average loss: 2.8105, Accuracy: 3447/5000 (69%)\n",
      "[epoch 49] loss: 0.0000006\n",
      "Test set: Average loss: 2.8413, Accuracy: 3436/5000 (69%)\n",
      "[epoch 50] loss: 0.0000004\n",
      "Test set: Average loss: 2.8741, Accuracy: 3429/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1225, Accuracy: 3452/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.0656, Accuracy: 6980/10000 (70%)\n",
      "45000\n",
      "## seed: 11\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3036, Accuracy: 527/5000 (11%)\n",
      "[epoch 1] loss: 1.2173037\n",
      "Test set: Average loss: 1.1743, Accuracy: 2971/5000 (59%)\n",
      "[epoch 2] loss: 1.0920339\n",
      "Test set: Average loss: 1.1603, Accuracy: 3022/5000 (60%)\n",
      "[epoch 3] loss: 1.0350691\n",
      "Test set: Average loss: 1.0782, Accuracy: 3099/5000 (62%)\n",
      "[epoch 4] loss: 0.9959180\n",
      "Test set: Average loss: 1.1060, Accuracy: 3047/5000 (61%)\n",
      "[epoch 5] loss: 0.9638832\n",
      "Test set: Average loss: 1.0290, Accuracy: 3218/5000 (64%)\n",
      "[epoch 6] loss: 0.9234026\n",
      "Test set: Average loss: 1.0631, Accuracy: 3179/5000 (64%)\n",
      "[epoch 7] loss: 0.8852365\n",
      "Test set: Average loss: 1.0302, Accuracy: 3230/5000 (65%)\n",
      "[epoch 8] loss: 0.8453917\n",
      "Test set: Average loss: 0.9979, Accuracy: 3259/5000 (65%)\n",
      "[epoch 9] loss: 0.8088173\n",
      "Test set: Average loss: 0.9861, Accuracy: 3310/5000 (66%)\n",
      "[epoch 10] loss: 0.7587997\n",
      "Test set: Average loss: 0.9744, Accuracy: 3341/5000 (67%)\n",
      "[epoch 11] loss: 0.7074661\n",
      "Test set: Average loss: 0.9883, Accuracy: 3333/5000 (67%)\n",
      "[epoch 12] loss: 0.6528112\n",
      "Test set: Average loss: 1.0007, Accuracy: 3326/5000 (67%)\n",
      "[epoch 13] loss: 0.5992652\n",
      "Test set: Average loss: 1.0208, Accuracy: 3343/5000 (67%)\n",
      "[epoch 14] loss: 0.5307436\n",
      "Test set: Average loss: 1.0627, Accuracy: 3352/5000 (67%)\n",
      "[epoch 15] loss: 0.4645417\n",
      "Test set: Average loss: 1.0900, Accuracy: 3407/5000 (68%)\n",
      "[epoch 16] loss: 0.4043885\n",
      "Test set: Average loss: 1.1399, Accuracy: 3382/5000 (68%)\n",
      "[epoch 17] loss: 0.3449336\n",
      "Test set: Average loss: 1.2059, Accuracy: 3342/5000 (67%)\n",
      "[epoch 18] loss: 0.3098873\n",
      "Test set: Average loss: 1.3177, Accuracy: 3322/5000 (66%)\n",
      "[epoch 19] loss: 0.2618990\n",
      "Test set: Average loss: 1.3782, Accuracy: 3332/5000 (67%)\n",
      "[epoch 20] loss: 0.2377502\n",
      "Test set: Average loss: 1.4318, Accuracy: 3316/5000 (66%)\n",
      "[epoch 21] loss: 0.2155424\n",
      "Test set: Average loss: 1.4221, Accuracy: 3356/5000 (67%)\n",
      "[epoch 22] loss: 0.2077744\n",
      "Test set: Average loss: 1.5251, Accuracy: 3301/5000 (66%)\n",
      "[epoch 23] loss: 0.1851735\n",
      "Test set: Average loss: 1.6047, Accuracy: 3268/5000 (65%)\n",
      "[epoch 24] loss: 0.1931771\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5716, Accuracy: 3337/5000 (67%)\n",
      "[epoch 25] loss: 0.0761790\n",
      "Test set: Average loss: 1.5108, Accuracy: 3394/5000 (68%)\n",
      "[epoch 26] loss: 0.0286919\n",
      "Test set: Average loss: 1.5263, Accuracy: 3400/5000 (68%)\n",
      "[epoch 27] loss: 0.0158306\n",
      "Test set: Average loss: 1.5518, Accuracy: 3413/5000 (68%)\n",
      "[epoch 28] loss: 0.0099843\n",
      "Test set: Average loss: 1.5768, Accuracy: 3410/5000 (68%)\n",
      "[epoch 29] loss: 0.0065035\n",
      "Test set: Average loss: 1.6126, Accuracy: 3400/5000 (68%)\n",
      "[epoch 30] loss: 0.0042738\n",
      "Test set: Average loss: 1.6569, Accuracy: 3436/5000 (69%)\n",
      "[epoch 31] loss: 0.0027744\n",
      "Test set: Average loss: 1.7073, Accuracy: 3420/5000 (68%)\n",
      "[epoch 32] loss: 0.0017602\n",
      "Test set: Average loss: 1.7664, Accuracy: 3431/5000 (69%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] loss: 0.0011280\n",
      "Test set: Average loss: 1.8310, Accuracy: 3420/5000 (68%)\n",
      "[epoch 34] loss: 0.0006996\n",
      "Test set: Average loss: 1.8880, Accuracy: 3437/5000 (69%)\n",
      "[epoch 35] loss: 0.0004382\n",
      "Test set: Average loss: 1.9550, Accuracy: 3443/5000 (69%)\n",
      "[epoch 36] loss: 0.0002700\n",
      "Test set: Average loss: 2.0349, Accuracy: 3435/5000 (69%)\n",
      "[epoch 37] loss: 0.0001666\n",
      "Test set: Average loss: 2.1010, Accuracy: 3437/5000 (69%)\n",
      "[epoch 38] loss: 0.0001010\n",
      "Test set: Average loss: 2.1805, Accuracy: 3439/5000 (69%)\n",
      "[epoch 39] loss: 0.0191827\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Test set: Average loss: 2.2372, Accuracy: 3450/5000 (69%)\n",
      "[epoch 40] loss: 0.0000731\n",
      "Test set: Average loss: 2.2427, Accuracy: 3443/5000 (69%)\n",
      "[epoch 41] loss: 0.0000521\n",
      "Test set: Average loss: 2.2478, Accuracy: 3443/5000 (69%)\n",
      "[epoch 42] loss: 0.0000443\n",
      "Test set: Average loss: 2.2529, Accuracy: 3443/5000 (69%)\n",
      "[epoch 43] loss: 0.0000396\n",
      "Test set: Average loss: 2.2569, Accuracy: 3448/5000 (69%)\n",
      "[epoch 44] loss: 0.0000367\n",
      "Test set: Average loss: 2.2614, Accuracy: 3449/5000 (69%)\n",
      "[epoch 45] loss: 0.0000344\n",
      "Test set: Average loss: 2.2671, Accuracy: 3451/5000 (69%)\n",
      "[epoch 46] loss: 0.0000325\n",
      "Test set: Average loss: 2.2716, Accuracy: 3446/5000 (69%)\n",
      "[epoch 47] loss: 0.0000306\n",
      "Test set: Average loss: 2.2813, Accuracy: 3444/5000 (69%)\n",
      "[epoch 48] loss: 0.0000289\n",
      "Test set: Average loss: 2.2894, Accuracy: 3440/5000 (69%)\n",
      "[epoch 49] loss: 0.0000270\n",
      "Test set: Average loss: 2.3006, Accuracy: 3446/5000 (69%)\n",
      "[epoch 50] loss: 0.0000250\n",
      "Test set: Average loss: 2.3134, Accuracy: 3448/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.2671, Accuracy: 3451/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.1733, Accuracy: 7010/10000 (70%)\n",
      "## seed: 12\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3019, Accuracy: 539/5000 (11%)\n",
      "[epoch 1] loss: 1.2133260\n",
      "Test set: Average loss: 1.1310, Accuracy: 3000/5000 (60%)\n",
      "[epoch 2] loss: 1.0861394\n",
      "Test set: Average loss: 1.1506, Accuracy: 2956/5000 (59%)\n",
      "[epoch 3] loss: 1.0415539\n",
      "Test set: Average loss: 1.1222, Accuracy: 3006/5000 (60%)\n",
      "[epoch 4] loss: 1.0067494\n",
      "Test set: Average loss: 1.0306, Accuracy: 3161/5000 (63%)\n",
      "[epoch 5] loss: 0.9581778\n",
      "Test set: Average loss: 1.0544, Accuracy: 3163/5000 (63%)\n",
      "[epoch 6] loss: 0.9261079\n",
      "Test set: Average loss: 1.0763, Accuracy: 3125/5000 (62%)\n",
      "[epoch 7] loss: 0.8864664\n",
      "Test set: Average loss: 1.0151, Accuracy: 3244/5000 (65%)\n",
      "[epoch 8] loss: 0.8455032\n",
      "Test set: Average loss: 1.0220, Accuracy: 3247/5000 (65%)\n",
      "[epoch 9] loss: 0.8094000\n",
      "Test set: Average loss: 1.0308, Accuracy: 3254/5000 (65%)\n",
      "[epoch 10] loss: 0.7592517\n",
      "Test set: Average loss: 0.9761, Accuracy: 3351/5000 (67%)\n",
      "[epoch 11] loss: 0.7043756\n",
      "Test set: Average loss: 1.0155, Accuracy: 3339/5000 (67%)\n",
      "[epoch 12] loss: 0.6522014\n",
      "Test set: Average loss: 1.0144, Accuracy: 3392/5000 (68%)\n",
      "[epoch 13] loss: 0.6024963\n",
      "Test set: Average loss: 1.0002, Accuracy: 3349/5000 (67%)\n",
      "[epoch 14] loss: 0.5333409\n",
      "Test set: Average loss: 1.0805, Accuracy: 3322/5000 (66%)\n",
      "[epoch 15] loss: 0.4819669\n",
      "Test set: Average loss: 1.0819, Accuracy: 3341/5000 (67%)\n",
      "[epoch 16] loss: 0.4240950\n",
      "Test set: Average loss: 1.1569, Accuracy: 3316/5000 (66%)\n",
      "[epoch 17] loss: 0.3633311\n",
      "Test set: Average loss: 1.2016, Accuracy: 3317/5000 (66%)\n",
      "[epoch 18] loss: 0.3179518\n",
      "Test set: Average loss: 1.2366, Accuracy: 3383/5000 (68%)\n",
      "[epoch 19] loss: 0.2723864\n",
      "Test set: Average loss: 1.3093, Accuracy: 3363/5000 (67%)\n",
      "[epoch 20] loss: 0.2429894\n",
      "Test set: Average loss: 1.3388, Accuracy: 3330/5000 (67%)\n",
      "[epoch 21] loss: 0.2156349\n",
      "Test set: Average loss: 1.4441, Accuracy: 3299/5000 (66%)\n",
      "[epoch 22] loss: 0.2090129\n",
      "Test set: Average loss: 1.4555, Accuracy: 3297/5000 (66%)\n",
      "[epoch 23] loss: 0.1937745\n",
      "Test set: Average loss: 1.5242, Accuracy: 3359/5000 (67%)\n",
      "[epoch 24] loss: 0.1956567\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5812, Accuracy: 3332/5000 (67%)\n",
      "[epoch 25] loss: 0.0679726\n",
      "Test set: Average loss: 1.5043, Accuracy: 3404/5000 (68%)\n",
      "[epoch 26] loss: 0.0269948\n",
      "Test set: Average loss: 1.5295, Accuracy: 3408/5000 (68%)\n",
      "[epoch 27] loss: 0.0156175\n",
      "Test set: Average loss: 1.5570, Accuracy: 3439/5000 (69%)\n",
      "[epoch 28] loss: 0.0099685\n",
      "Test set: Average loss: 1.5874, Accuracy: 3428/5000 (69%)\n",
      "[epoch 29] loss: 0.0065415\n",
      "Test set: Average loss: 1.6284, Accuracy: 3419/5000 (68%)\n",
      "[epoch 30] loss: 0.0042962\n",
      "Test set: Average loss: 1.6677, Accuracy: 3442/5000 (69%)\n",
      "[epoch 31] loss: 0.0027455\n",
      "Test set: Average loss: 1.7161, Accuracy: 3440/5000 (69%)\n",
      "[epoch 32] loss: 0.0017672\n",
      "Test set: Average loss: 1.7782, Accuracy: 3441/5000 (69%)\n",
      "[epoch 33] loss: 0.0011133\n",
      "Test set: Average loss: 1.8420, Accuracy: 3446/5000 (69%)\n",
      "[epoch 34] loss: 0.0007038\n",
      "Test set: Average loss: 1.8957, Accuracy: 3445/5000 (69%)\n",
      "[epoch 35] loss: 0.0004368\n",
      "Test set: Average loss: 1.9619, Accuracy: 3446/5000 (69%)\n",
      "[epoch 36] loss: 0.0002711\n",
      "Test set: Average loss: 2.0356, Accuracy: 3453/5000 (69%)\n",
      "[epoch 37] loss: 0.0001667\n",
      "Test set: Average loss: 2.1042, Accuracy: 3458/5000 (69%)\n",
      "[epoch 38] loss: 0.0001014\n",
      "Test set: Average loss: 2.1850, Accuracy: 3451/5000 (69%)\n",
      "[epoch 39] loss: 0.0000615\n",
      "Test set: Average loss: 2.2516, Accuracy: 3448/5000 (69%)\n",
      "[epoch 40] loss: 0.0000369\n",
      "Test set: Average loss: 2.3382, Accuracy: 3440/5000 (69%)\n",
      "[epoch 41] loss: 0.0000222\n",
      "Test set: Average loss: 2.4149, Accuracy: 3439/5000 (69%)\n",
      "[epoch 42] loss: 0.0000131\n",
      "Test set: Average loss: 2.4894, Accuracy: 3449/5000 (69%)\n",
      "[epoch 43] loss: 0.0000078\n",
      "Test set: Average loss: 2.5730, Accuracy: 3441/5000 (69%)\n",
      "[epoch 44] loss: 0.0000046\n",
      "Test set: Average loss: 2.6562, Accuracy: 3446/5000 (69%)\n",
      "[epoch 45] loss: 0.0000027\n",
      "Test set: Average loss: 2.7283, Accuracy: 3438/5000 (69%)\n",
      "[epoch 46] loss: 0.0000015\n",
      "Test set: Average loss: 2.8060, Accuracy: 3440/5000 (69%)\n",
      "[epoch 47] loss: 0.0000009\n",
      "Test set: Average loss: 2.8753, Accuracy: 3433/5000 (69%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 2.9104, Accuracy: 3436/5000 (69%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 2.9430, Accuracy: 3437/5000 (69%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.9454, Accuracy: 3435/5000 (69%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.1042, Accuracy: 3458/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 1.9709, Accuracy: 7014/10000 (70%)\n",
      "## seed: 13\n",
      "Validation accuracy before training:\n",
      "Test set: Average loss: 2.3028, Accuracy: 546/5000 (11%)\n",
      "[epoch 1] loss: 1.2153999\n",
      "Test set: Average loss: 1.1851, Accuracy: 2917/5000 (58%)\n",
      "[epoch 2] loss: 1.0906235\n",
      "Test set: Average loss: 1.0957, Accuracy: 3025/5000 (60%)\n",
      "[epoch 3] loss: 1.0364843\n",
      "Test set: Average loss: 1.0837, Accuracy: 3114/5000 (62%)\n",
      "[epoch 4] loss: 0.9913462\n",
      "Test set: Average loss: 1.0645, Accuracy: 3134/5000 (63%)\n",
      "[epoch 5] loss: 0.9571528\n",
      "Test set: Average loss: 1.0150, Accuracy: 3208/5000 (64%)\n",
      "[epoch 6] loss: 0.9180576\n",
      "Test set: Average loss: 1.0674, Accuracy: 3140/5000 (63%)\n",
      "[epoch 7] loss: 0.8812587\n",
      "Test set: Average loss: 1.0279, Accuracy: 3223/5000 (64%)\n",
      "[epoch 8] loss: 0.8445494\n",
      "Test set: Average loss: 1.0208, Accuracy: 3221/5000 (64%)\n",
      "[epoch 9] loss: 0.8018414\n",
      "Test set: Average loss: 0.9702, Accuracy: 3328/5000 (67%)\n",
      "[epoch 10] loss: 0.7516464\n",
      "Test set: Average loss: 0.9823, Accuracy: 3325/5000 (66%)\n",
      "[epoch 11] loss: 0.6997924\n",
      "Test set: Average loss: 1.0058, Accuracy: 3333/5000 (67%)\n",
      "[epoch 12] loss: 0.6449283\n",
      "Test set: Average loss: 0.9807, Accuracy: 3378/5000 (68%)\n",
      "[epoch 13] loss: 0.5977206\n",
      "Test set: Average loss: 1.0810, Accuracy: 3252/5000 (65%)\n",
      "[epoch 14] loss: 0.5325984\n",
      "Test set: Average loss: 1.0460, Accuracy: 3331/5000 (67%)\n",
      "[epoch 15] loss: 0.4680546\n",
      "Test set: Average loss: 1.0923, Accuracy: 3342/5000 (67%)\n",
      "[epoch 16] loss: 0.4115709\n",
      "Test set: Average loss: 1.1371, Accuracy: 3344/5000 (67%)\n",
      "[epoch 17] loss: 0.3622227\n",
      "Test set: Average loss: 1.2140, Accuracy: 3277/5000 (66%)\n",
      "[epoch 18] loss: 0.3062050\n",
      "Test set: Average loss: 1.3989, Accuracy: 3244/5000 (65%)\n",
      "[epoch 19] loss: 0.2816855\n",
      "Test set: Average loss: 1.3264, Accuracy: 3347/5000 (67%)\n",
      "[epoch 20] loss: 0.2437827\n",
      "Test set: Average loss: 1.3699, Accuracy: 3344/5000 (67%)\n",
      "[epoch 21] loss: 0.2322211\n",
      "Test set: Average loss: 1.4673, Accuracy: 3285/5000 (66%)\n",
      "[epoch 22] loss: 0.2029801\n",
      "Test set: Average loss: 1.5154, Accuracy: 3296/5000 (66%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] loss: 0.1945760\n",
      "Test set: Average loss: 1.5604, Accuracy: 3291/5000 (66%)\n",
      "[epoch 24] loss: 0.1962680\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Test set: Average loss: 1.5358, Accuracy: 3328/5000 (67%)\n",
      "[epoch 25] loss: 0.0722295\n",
      "Test set: Average loss: 1.4917, Accuracy: 3371/5000 (67%)\n",
      "[epoch 26] loss: 0.0268091\n",
      "Test set: Average loss: 1.5105, Accuracy: 3393/5000 (68%)\n",
      "[epoch 27] loss: 0.0153384\n",
      "Test set: Average loss: 1.5336, Accuracy: 3385/5000 (68%)\n",
      "[epoch 28] loss: 0.0098642\n",
      "Test set: Average loss: 1.5630, Accuracy: 3421/5000 (68%)\n",
      "[epoch 29] loss: 0.0064481\n",
      "Test set: Average loss: 1.6026, Accuracy: 3405/5000 (68%)\n",
      "[epoch 30] loss: 0.0042325\n",
      "Test set: Average loss: 1.6453, Accuracy: 3421/5000 (68%)\n",
      "[epoch 31] loss: 0.0027328\n",
      "Test set: Average loss: 1.6929, Accuracy: 3426/5000 (69%)\n",
      "[epoch 32] loss: 0.0017535\n",
      "Test set: Average loss: 1.7525, Accuracy: 3427/5000 (69%)\n",
      "[epoch 33] loss: 0.0011171\n",
      "Test set: Average loss: 1.8113, Accuracy: 3418/5000 (68%)\n",
      "[epoch 34] loss: 0.0006984\n",
      "Test set: Average loss: 1.8671, Accuracy: 3438/5000 (69%)\n",
      "[epoch 35] loss: 0.0004360\n",
      "Test set: Average loss: 1.9452, Accuracy: 3436/5000 (69%)\n",
      "[epoch 36] loss: 0.0002696\n",
      "Test set: Average loss: 2.0058, Accuracy: 3438/5000 (69%)\n",
      "[epoch 37] loss: 0.0001668\n",
      "Test set: Average loss: 2.0834, Accuracy: 3455/5000 (69%)\n",
      "[epoch 38] loss: 0.0001005\n",
      "Test set: Average loss: 2.1681, Accuracy: 3437/5000 (69%)\n",
      "[epoch 39] loss: 0.0000610\n",
      "Test set: Average loss: 2.2291, Accuracy: 3443/5000 (69%)\n",
      "[epoch 40] loss: 0.0000369\n",
      "Test set: Average loss: 2.3199, Accuracy: 3449/5000 (69%)\n",
      "[epoch 41] loss: 0.0000221\n",
      "Test set: Average loss: 2.3885, Accuracy: 3440/5000 (69%)\n",
      "[epoch 42] loss: 0.0000131\n",
      "Test set: Average loss: 2.4715, Accuracy: 3442/5000 (69%)\n",
      "[epoch 43] loss: 0.0000077\n",
      "Test set: Average loss: 2.5509, Accuracy: 3438/5000 (69%)\n",
      "[epoch 44] loss: 0.0000046\n",
      "Test set: Average loss: 2.6314, Accuracy: 3435/5000 (69%)\n",
      "[epoch 45] loss: 0.0000027\n",
      "Test set: Average loss: 2.7052, Accuracy: 3428/5000 (69%)\n",
      "[epoch 46] loss: 0.0000015\n",
      "Test set: Average loss: 2.7863, Accuracy: 3436/5000 (69%)\n",
      "[epoch 47] loss: 0.0000009\n",
      "Test set: Average loss: 2.8508, Accuracy: 3431/5000 (69%)\n",
      "[epoch 48] loss: 0.0000005\n",
      "Test set: Average loss: 2.9015, Accuracy: 3421/5000 (68%)\n",
      "[epoch 49] loss: 0.0000003\n",
      "Test set: Average loss: 2.9241, Accuracy: 3416/5000 (68%)\n",
      "[epoch 50] loss: 0.0000002\n",
      "Test set: Average loss: 2.9369, Accuracy: 3414/5000 (68%)\n",
      "Validation:\n",
      "Test set: Average loss: 2.0834, Accuracy: 3455/5000 (69%)\n",
      "Test\n",
      "Test set: Average loss: 2.0087, Accuracy: 7022/10000 (70%)\n"
     ]
    }
   ],
   "source": [
    "# train the SimEc\n",
    "w = 0.9\n",
    "S = w*S_lin + (1.-w)*S_class\n",
    "S_ll = S[:n_targets, :]\n",
    "t0 = time()\n",
    "cnn = CNN()\n",
    "model = SimilarityEncoder(cnn, 512, n_targets)\n",
    "model.fit(X, S, epochs=50, lr=0.0001, s_ll_reg=100., S_ll=S_ll, orth_reg=0.1)\n",
    "print(check_similarity_match(model.predict(X[:n_targets]), S_ll, X_embed_is_S_approx=True))\n",
    "print(check_similarity_match(model.transform(X[:n_targets]), S_ll))\n",
    "# save the cnn state\n",
    "cnn_dict = deepcopy(model.model.embedding_net.state_dict())\n",
    "t1 = time()\n",
    "print(\"Took %.2d sec to train.\" % (t1 - t0))\n",
    "# use the pretrained model with the clf\n",
    "test_accuracies_se_t1_mix9 = []\n",
    "for n_train in n_training_examples:\n",
    "    print(n_train)\n",
    "    test_accuracies_se_t1_mix9.append(clf_with_ntrain(n_train, cnn_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T02:54:44.154439Z",
     "start_time": "2019-07-25T02:54:43.688094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training_examples = [25, 50, 100, 250, 500, 750, 1000, 2500, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000]\n",
      "test_accuracies_clf = [(0.1621, 0.007353910524340101), (0.19743333333333332, 0.013557859549189737), (0.21613333333333332, 0.0032293790252754346), (0.3024, 0.018181309083781617), (0.36036666666666667, 0.004135483311805557), (0.3839333333333333, 0.010612675859032392), (0.3823666666666667, 0.010506611674983), (0.44543333333333335, 0.008575287491131437), (0.4940666666666667, 0.010124996570644156), (0.5615333333333333, 0.003229379025275437), (0.6027, 0.010220567498921002), (0.6235666666666666, 0.006104825049818298), (0.6407333333333333, 0.003596603335865075), (0.6543333333333333, 0.0020270394394014224), (0.6615666666666666, 0.006613790306792481), (0.6781, 0.006255131226974115), (0.6809999999999999, 0.0045107279530766245)]\n",
      "test_accuracies_clf_pt = [(0.3495, 0.07030035561787722), (0.4467666666666667, 0.030813020335926533), (0.49183333333333334, 0.03235164429961619), (0.6055999999999999, 0.009021455906153213), (0.6333666666666667, 0.005349350947129527), (0.6475, 0.00555517776493243), (0.6535666666666667, 0.001878533707147403), (0.6691666666666666, 0.001359738536958064), (0.6787333333333333, 0.0006599663291074202), (0.6812666666666667, 0.002106075866524182), (0.6838333333333333, 0.0029397656747132384), (0.6788333333333334, 0.0005906681715556321), (0.6741333333333334, 0.001763204154058412), (0.6750333333333334, 0.0031510139461590897), (0.6760666666666667, 0.001322455628325146), (0.6753333333333335, 0.003227313984655873), (0.6787666666666666, 0.0014383632673594555)]\n",
      "test_accuracies_ae1l = [(0.16010000000000002, 0.007904850831398828), (0.19833333333333333, 0.007492366485667638), (0.2097, 0.02154313502410145), (0.2979, 0.008741090702347546), (0.3497333333333333, 0.006593094030035418), (0.35936666666666667, 0.014222361110432947), (0.3884666666666667, 0.008935820549277438), (0.44530000000000003, 0.00382186690854961), (0.4908666666666666, 0.00342960963117118), (0.5509333333333334, 0.009986769024842605), (0.5717666666666666, 0.0021249836600678884), (0.5868, 0.006531462317123172), (0.6084333333333334, 0.012174381115915336), (0.6062333333333333, 0.01318618806007089), (0.6249333333333333, 0.007711607412782962), (0.6314666666666667, 0.007172323348972928), (0.6456, 0.0072475283143059585)]\n",
      "test_accuracies_ae = [(0.16206666666666666, 0.003700750674600437), (0.19346666666666665, 0.010726084508751966), (0.2132666666666667, 0.01870496072050287), (0.3049, 0.01755961275199428), (0.35969999999999996, 0.0032782108941717815), (0.3760333333333334, 0.009910376156108082), (0.38210000000000005, 0.013364380519375635), (0.4614666666666667, 0.016061617463865703), (0.5139333333333332, 0.005118159391378452), (0.5696333333333333, 0.0010402991022885242), (0.5961666666666666, 0.003402286812653439), (0.6123666666666666, 0.00012472191289250042), (0.6365333333333333, 0.007344083030273811), (0.6408, 0.004490731195102497), (0.6602, 0.002041241452319317), (0.6635333333333333, 0.002456736769691771), (0.6686333333333333, 0.007149048110685038)]\n",
      "test_accuracies_se = [(0.16116666666666668, 0.002397684067780599), (0.20123333333333335, 0.009722939656068822), (0.20196666666666666, 0.01404215874508697), (0.3123, 0.00899333086236686), (0.35776666666666673, 0.004169998667732246), (0.3734, 0.002290560339014618), (0.3922666666666667, 0.004696334267868461), (0.4425333333333333, 0.00931390835733791), (0.49146666666666666, 0.004759084879353256), (0.5468000000000001, 0.0013490737563231928), (0.5917666666666667, 0.007102268808079687), (0.6213666666666667, 0.01062115289829161), (0.6429333333333334, 0.005067763039273057), (0.6465666666666666, 0.0112422813026934), (0.6625, 0.006328243568848075), (0.6661333333333334, 0.0032826141344293805), (0.6726333333333333, 0.008775850702670127)]\n",
      "test_accuracies_se_t1_mix = [(0.19193333333333332, 0.009336071027055345), (0.2399, 0.010503650159190699), (0.2615, 0.03592185964005762), (0.39146666666666663, 0.009107262059599585), (0.4502333333333333, 0.009602198822260577), (0.4755, 0.010050207294711204), (0.4744333333333333, 0.004496912521077351), (0.5335000000000001, 0.008472701261502546), (0.5646333333333333, 0.00299592315581616), (0.5939333333333333, 0.004205023450852817), (0.6298666666666667, 0.0027920522121829285), (0.6422333333333333, 0.0046147107770211655), (0.6587333333333334, 0.0026712460679532203), (0.6703333333333333, 0.00356495285928005), (0.6734, 0.0038995726261561534), (0.6815666666666668, 0.004305293898859377), (0.6873, 0.0024124676163629374)]\n",
      "test_accuracies_se_t1_mix9 = [(0.20783333333333331, 0.02478391055144894), (0.27276666666666666, 0.018329272277486146), (0.3172, 0.048104954699767326), (0.46890000000000004, 0.013075167302944921), (0.511, 0.013209844813622902), (0.5228666666666667, 0.011715042561690595), (0.5364999999999999, 0.007142828571371426), (0.5555333333333333, 0.007191816336797122), (0.5847666666666667, 0.006123905797954626), (0.6062333333333333, 0.004168399639616559), (0.6357666666666666, 0.0037985377303495307), (0.6589666666666667, 0.003587323359956402), (0.6712666666666668, 0.0023271346234276236), (0.6809, 0.001867261809888105), (0.6873, 0.0017281975195754446), (0.6964666666666667, 0.0012657891697364987), (0.7015333333333333, 0.0004988876515698929)]\n",
      "test_accuracies_se_t1_mix7 = [(0.24783333333333335, 0.01497405163014414), (0.31396666666666667, 0.01790611317089471), (0.3419666666666667, 0.028868475693892948), (0.49720000000000003, 0.009940824915468553), (0.5422333333333333, 0.0075896127847356115), (0.5375333333333333, 0.01539574255724254), (0.5502666666666666, 0.009365658308712523), (0.5621999999999999, 0.011151083654365903), (0.5788666666666668, 0.0062376990059547196), (0.6108333333333333, 0.007202931501980439), (0.6385333333333333, 0.0014055445761538506), (0.6574333333333333, 0.0032887011958454694), (0.6706, 0.0007483314773547949), (0.6827, 0.00374966665185055), (0.6911999999999999, 0.002669581740023454), (0.6890666666666667, 0.005235986588557624), (0.6966666666666667, 0.004187547678003882)]\n",
      "test_accuracies_se_t1_mix5 = [(0.2627, 0.031073246799564837), (0.3131333333333333, 0.03331159291031011), (0.3578333333333334, 0.05769138198687527), (0.5193333333333333, 0.007969246444231007), (0.5541, 0.012356644636254074), (0.5696666666666667, 0.008625672276537197), (0.5560666666666667, 0.005845416057808791), (0.5878333333333333, 0.019833361344518057), (0.5882999999999999, 0.008819674975114822), (0.6126666666666667, 0.0030728199137310974), (0.6405333333333333, 0.00865653253650419), (0.6656666666666666, 0.0014659088951530438), (0.6756333333333333, 0.004169998667732288), (0.6835, 0.004526219909225183), (0.6876333333333333, 0.0026029897340472752), (0.6966333333333333, 0.001203698005684524), (0.7029, 0.0036175498153676673)]\n",
      "test_accuracies_se_t1 = [(0.29616666666666663, 0.05793504025103364), (0.3484333333333334, 0.038607800017900824), (0.4068333333333333, 0.04925101239794185), (0.5209333333333334, 0.012211833969101008), (0.5482333333333334, 0.01674720540534715), (0.5569666666666667, 0.003936439451529201), (0.5654333333333333, 0.007271099565326344), (0.5854666666666667, 0.006723259791367729), (0.5954666666666667, 0.00196015872373186), (0.6154, 0.004459446901429227), (0.6425000000000001, 0.005012650662739885), (0.6610999999999999, 0.0036120169803956683), (0.6728333333333333, 0.001948218559493635), (0.6833333333333335, 0.00360123435628522), (0.6867666666666666, 0.0018803073034893679), (0.6942, 0.0024344746182013706), (0.6951999999999999, 0.00296984848098349)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mean_std(test_accs, c, label):\n",
    "    data_mean = np.array([t[0] for t in test_accs])\n",
    "    data_std = np.array([t[1] for t in test_accs])\n",
    "    plt.plot(n_training_examples, data_mean, color=c, linewidth=1.8, label=label)\n",
    "    plt.plot(n_training_examples, data_mean+data_std, \"--\", color=c, linewidth=0.5, alpha=0.5)\n",
    "    plt.plot(n_training_examples, data_mean-data_std, \"--\", color=c, linewidth=0.5, alpha=0.5)\n",
    "    plt.fill_between(n_training_examples, data_mean+data_std, data_mean-data_std, color=c, alpha=0.05)\n",
    "\n",
    "colors = get_colors(17)\n",
    "plt.figure()\n",
    "plot_mean_std(test_accuracies_clf, c=\"k\", label=\"no pretraining\")\n",
    "plot_mean_std(test_accuracies_clf_pt, c=colors[0], label=\"CLF labels\")\n",
    "plot_mean_std(test_accuracies_ae1l, c=colors[2], label=\"AE (1l decoder)\")\n",
    "plot_mean_std(test_accuracies_ae, c=colors[4], label=\"AE (full)\")\n",
    "plot_mean_std(test_accuracies_se, c=colors[6], label=\"SimEc (linear K)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix, c=colors[8], label=\"SimEc (0.95*linK + 0.05*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix9, c=colors[10], label=\"SimEc (0.9*linK + 0.1*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix7, c=colors[12], label=\"SimEc (0.7*linK + 0.3*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix5, c=colors[14], label=\"SimEc (0.5*linK + 0.5*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1, c=colors[16], label=\"SimEc (classes)\")\n",
    "plt.xlabel(\"Number of training examples for classifier\")\n",
    "plt.xticks([25, 5000, 10000, 20000, 30000, 45000], [25, 5000, 10000, 20000, 30000, 45000])\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.ylim(0.5, 0.71)\n",
    "l = plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.);\n",
    "plt.savefig('img_simec.pdf', dpi=300, bbox_inches=\"tight\", bbox_extra_artists=[l])\n",
    "print(\"n_training_examples =\", n_training_examples)\n",
    "print(\"test_accuracies_clf =\", test_accuracies_clf)\n",
    "print(\"test_accuracies_clf_pt =\", test_accuracies_clf_pt)\n",
    "print(\"test_accuracies_ae1l =\", test_accuracies_ae1l)\n",
    "print(\"test_accuracies_ae =\", test_accuracies_ae)\n",
    "print(\"test_accuracies_se =\", test_accuracies_se)\n",
    "print(\"test_accuracies_se_t1_mix =\", test_accuracies_se_t1_mix)\n",
    "print(\"test_accuracies_se_t1_mix9 =\", test_accuracies_se_t1_mix9)\n",
    "print(\"test_accuracies_se_t1_mix7 =\", test_accuracies_se_t1_mix7)\n",
    "print(\"test_accuracies_se_t1_mix5 =\", test_accuracies_se_t1_mix5)\n",
    "print(\"test_accuracies_se_t1 =\", test_accuracies_se_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:44:53.594570Z",
     "start_time": "2019-10-31T14:44:52.938129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def get_colors(N=100):\n",
    "    HSV_tuples = [(x * 1. / (N+1), 1., 0.8) for x in range(N)]\n",
    "    return [colorsys.hsv_to_rgb(*x) for x in HSV_tuples]\n",
    "\n",
    "\n",
    "n_training_examples = [25, 50, 100, 250, 500, 750, 1000, 2500, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000]\n",
    "test_accuracies_clf = [(0.1621, 0.007353910524340101), (0.19743333333333332, 0.013557859549189737), (0.21613333333333332, 0.0032293790252754346), (0.3024, 0.018181309083781617), (0.36036666666666667, 0.004135483311805557), (0.3839333333333333, 0.010612675859032392), (0.3823666666666667, 0.010506611674983), (0.44543333333333335, 0.008575287491131437), (0.4940666666666667, 0.010124996570644156), (0.5615333333333333, 0.003229379025275437), (0.6027, 0.010220567498921002), (0.6235666666666666, 0.006104825049818298), (0.6407333333333333, 0.003596603335865075), (0.6543333333333333, 0.0020270394394014224), (0.6615666666666666, 0.006613790306792481), (0.6781, 0.006255131226974115), (0.6809999999999999, 0.0045107279530766245)]\n",
    "test_accuracies_clf_pt = [(0.3495, 0.07030035561787722), (0.4467666666666667, 0.030813020335926533), (0.49183333333333334, 0.03235164429961619), (0.6055999999999999, 0.009021455906153213), (0.6333666666666667, 0.005349350947129527), (0.6475, 0.00555517776493243), (0.6535666666666667, 0.001878533707147403), (0.6691666666666666, 0.001359738536958064), (0.6787333333333333, 0.0006599663291074202), (0.6812666666666667, 0.002106075866524182), (0.6838333333333333, 0.0029397656747132384), (0.6788333333333334, 0.0005906681715556321), (0.6741333333333334, 0.001763204154058412), (0.6750333333333334, 0.0031510139461590897), (0.6760666666666667, 0.001322455628325146), (0.6753333333333335, 0.003227313984655873), (0.6787666666666666, 0.0014383632673594555)]\n",
    "test_accuracies_ae1l = [(0.16010000000000002, 0.007904850831398828), (0.19833333333333333, 0.007492366485667638), (0.2097, 0.02154313502410145), (0.2979, 0.008741090702347546), (0.3497333333333333, 0.006593094030035418), (0.35936666666666667, 0.014222361110432947), (0.3884666666666667, 0.008935820549277438), (0.44530000000000003, 0.00382186690854961), (0.4908666666666666, 0.00342960963117118), (0.5509333333333334, 0.009986769024842605), (0.5717666666666666, 0.0021249836600678884), (0.5868, 0.006531462317123172), (0.6084333333333334, 0.012174381115915336), (0.6062333333333333, 0.01318618806007089), (0.6249333333333333, 0.007711607412782962), (0.6314666666666667, 0.007172323348972928), (0.6456, 0.0072475283143059585)]\n",
    "test_accuracies_ae = [(0.16206666666666666, 0.003700750674600437), (0.19346666666666665, 0.010726084508751966), (0.2132666666666667, 0.01870496072050287), (0.3049, 0.01755961275199428), (0.35969999999999996, 0.0032782108941717815), (0.3760333333333334, 0.009910376156108082), (0.38210000000000005, 0.013364380519375635), (0.4614666666666667, 0.016061617463865703), (0.5139333333333332, 0.005118159391378452), (0.5696333333333333, 0.0010402991022885242), (0.5961666666666666, 0.003402286812653439), (0.6123666666666666, 0.00012472191289250042), (0.6365333333333333, 0.007344083030273811), (0.6408, 0.004490731195102497), (0.6602, 0.002041241452319317), (0.6635333333333333, 0.002456736769691771), (0.6686333333333333, 0.007149048110685038)]\n",
    "test_accuracies_se = [(0.16116666666666668, 0.002397684067780599), (0.20123333333333335, 0.009722939656068822), (0.20196666666666666, 0.01404215874508697), (0.3123, 0.00899333086236686), (0.35776666666666673, 0.004169998667732246), (0.3734, 0.002290560339014618), (0.3922666666666667, 0.004696334267868461), (0.4425333333333333, 0.00931390835733791), (0.49146666666666666, 0.004759084879353256), (0.5468000000000001, 0.0013490737563231928), (0.5917666666666667, 0.007102268808079687), (0.6213666666666667, 0.01062115289829161), (0.6429333333333334, 0.005067763039273057), (0.6465666666666666, 0.0112422813026934), (0.6625, 0.006328243568848075), (0.6661333333333334, 0.0032826141344293805), (0.6726333333333333, 0.008775850702670127)]\n",
    "test_accuracies_se_t1_mix = [(0.19193333333333332, 0.009336071027055345), (0.2399, 0.010503650159190699), (0.2615, 0.03592185964005762), (0.39146666666666663, 0.009107262059599585), (0.4502333333333333, 0.009602198822260577), (0.4755, 0.010050207294711204), (0.4744333333333333, 0.004496912521077351), (0.5335000000000001, 0.008472701261502546), (0.5646333333333333, 0.00299592315581616), (0.5939333333333333, 0.004205023450852817), (0.6298666666666667, 0.0027920522121829285), (0.6422333333333333, 0.0046147107770211655), (0.6587333333333334, 0.0026712460679532203), (0.6703333333333333, 0.00356495285928005), (0.6734, 0.0038995726261561534), (0.6815666666666668, 0.004305293898859377), (0.6873, 0.0024124676163629374)]\n",
    "test_accuracies_se_t1_mix9 = [(0.20783333333333331, 0.02478391055144894), (0.27276666666666666, 0.018329272277486146), (0.3172, 0.048104954699767326), (0.46890000000000004, 0.013075167302944921), (0.511, 0.013209844813622902), (0.5228666666666667, 0.011715042561690595), (0.5364999999999999, 0.007142828571371426), (0.5555333333333333, 0.007191816336797122), (0.5847666666666667, 0.006123905797954626), (0.6062333333333333, 0.004168399639616559), (0.6357666666666666, 0.0037985377303495307), (0.6589666666666667, 0.003587323359956402), (0.6712666666666668, 0.0023271346234276236), (0.6809, 0.001867261809888105), (0.6873, 0.0017281975195754446), (0.6964666666666667, 0.0012657891697364987), (0.7015333333333333, 0.0004988876515698929)]\n",
    "test_accuracies_se_t1_mix7 = [(0.24783333333333335, 0.01497405163014414), (0.31396666666666667, 0.01790611317089471), (0.3419666666666667, 0.028868475693892948), (0.49720000000000003, 0.009940824915468553), (0.5422333333333333, 0.0075896127847356115), (0.5375333333333333, 0.01539574255724254), (0.5502666666666666, 0.009365658308712523), (0.5621999999999999, 0.011151083654365903), (0.5788666666666668, 0.0062376990059547196), (0.6108333333333333, 0.007202931501980439), (0.6385333333333333, 0.0014055445761538506), (0.6574333333333333, 0.0032887011958454694), (0.6706, 0.0007483314773547949), (0.6827, 0.00374966665185055), (0.6911999999999999, 0.002669581740023454), (0.6890666666666667, 0.005235986588557624), (0.6966666666666667, 0.004187547678003882)]\n",
    "test_accuracies_se_t1_mix5 = [(0.2627, 0.031073246799564837), (0.3131333333333333, 0.03331159291031011), (0.3578333333333334, 0.05769138198687527), (0.5193333333333333, 0.007969246444231007), (0.5541, 0.012356644636254074), (0.5696666666666667, 0.008625672276537197), (0.5560666666666667, 0.005845416057808791), (0.5878333333333333, 0.019833361344518057), (0.5882999999999999, 0.008819674975114822), (0.6126666666666667, 0.0030728199137310974), (0.6405333333333333, 0.00865653253650419), (0.6656666666666666, 0.0014659088951530438), (0.6756333333333333, 0.004169998667732288), (0.6835, 0.004526219909225183), (0.6876333333333333, 0.0026029897340472752), (0.6966333333333333, 0.001203698005684524), (0.7029, 0.0036175498153676673)]\n",
    "test_accuracies_se_t1 = [(0.29616666666666663, 0.05793504025103364), (0.3484333333333334, 0.038607800017900824), (0.4068333333333333, 0.04925101239794185), (0.5209333333333334, 0.012211833969101008), (0.5482333333333334, 0.01674720540534715), (0.5569666666666667, 0.003936439451529201), (0.5654333333333333, 0.007271099565326344), (0.5854666666666667, 0.006723259791367729), (0.5954666666666667, 0.00196015872373186), (0.6154, 0.004459446901429227), (0.6425000000000001, 0.005012650662739885), (0.6610999999999999, 0.0036120169803956683), (0.6728333333333333, 0.001948218559493635), (0.6833333333333335, 0.00360123435628522), (0.6867666666666666, 0.0018803073034893679), (0.6942, 0.0024344746182013706), (0.6951999999999999, 0.00296984848098349)]\n",
    "def plot_mean_std(test_accs, c, label):\n",
    "    data_mean = np.array([t[0] for t in test_accs])\n",
    "    data_std = np.array([t[1] for t in test_accs])\n",
    "    plt.plot(n_training_examples, data_mean, color=c, linewidth=1.8, label=label)\n",
    "    plt.plot(n_training_examples, data_mean+data_std, \"--\", color=c, linewidth=0.5, alpha=0.5)\n",
    "    plt.plot(n_training_examples, data_mean-data_std, \"--\", color=c, linewidth=0.5, alpha=0.5)\n",
    "    plt.fill_between(n_training_examples, data_mean+data_std, data_mean-data_std, color=c, alpha=0.05)\n",
    "\n",
    "colors = get_colors(17)\n",
    "plt.figure()\n",
    "plot_mean_std(test_accuracies_clf, c=\"k\", label=\"no pre-training\")\n",
    "plot_mean_std(test_accuracies_clf_pt, c=colors[0], label=\"CLF labels\")\n",
    "plot_mean_std(test_accuracies_ae1l, c=colors[2], label=\"AE (linear)\")\n",
    "plot_mean_std(test_accuracies_ae, c=colors[4], label=\"AE (regular)\")\n",
    "plot_mean_std(test_accuracies_se, c=colors[6], label=\"SimEc (linear Kernel)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix, c=colors[8], label=\"SimEc (0.95*linK + 0.05*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix9, c=colors[10], label=\"SimEc (0.9*linK + 0.1*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix7, c=colors[12], label=\"SimEc (0.7*linK + 0.3*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1_mix5, c=colors[14], label=\"SimEc (0.5*linK + 0.5*cls)\")\n",
    "plot_mean_std(test_accuracies_se_t1, c=colors[16], label=\"SimEc (classes)\")\n",
    "plt.xlabel(\"Number of training examples for classifier\", fontsize=13)\n",
    "plt.xticks([25, 5000, 10000, 20000, 30000, 45000], [25, 5000, 10000, 20000, 30000, 45000])\n",
    "plt.ylabel(\"Test accuracy\", fontsize=13)\n",
    "plt.ylim(0.5, 0.71)\n",
    "l = plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.);\n",
    "plt.savefig('img_simec.pdf', dpi=300, bbox_inches=\"tight\", bbox_extra_artists=[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
